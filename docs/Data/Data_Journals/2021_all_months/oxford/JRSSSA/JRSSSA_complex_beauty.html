<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>JRSSSA_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="jrsssa---119">JRSSSA - 119</h2>
<ul>
<li><details>
<summary>
(2021). Contents of volume 184, 2021. <em>Journal of the Royal
Statistical Society: Series A (Statistics in Society)</em>,
<em>184</em>(4), 1622–1625. (<a
href="https://doi.org/10.1111/rssa.12770">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive = {J},
  doi     = {10.1111/rssa.12770},
  journal = {Journal of the Royal Statistical Society: Series a},
  number  = {4},
  pages   = {1622-1625},
  title   = {Contents of volume 184, 2021},
  volume  = {184},
  year    = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Referees. <em>Journal of the Royal Statistical Society:
Series A (Statistics in Society)</em>, <em>184</em>(4), 1614–1621. (<a
href="https://doi.org/10.1111/rssa.12774">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive = {J},
  doi     = {10.1111/rssa.12774},
  journal = {Journal of the Royal Statistical Society: Series a},
  number  = {4},
  pages   = {1614-1621},
  title   = {Referees},
  volume  = {184},
  year    = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). R markdown cookbook yihui xie, christophe dervieux, emily
riederer, chapman and hall/CRC press, pp. Xxix + 329 ISBN 9780367563837.
<em>Journal of the Royal Statistical Society: Series A (Statistics in
Society)</em>, <em>184</em>(4), 1613. (<a
href="https://doi.org/10.1111/rssa.12743">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive = {J},
  author  = {Shalabh},
  doi     = {10.1111/rssa.12743},
  journal = {Journal of the Royal Statistical Society: Series a},
  number  = {4},
  pages   = {1613},
  title   = {R markdown cookbook yihui xie, christophe dervieux, emily riederer, chapman and Hall/CRC press, pp. xxix + 329 ISBN 9780367563837},
  volume  = {184},
  year    = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Statistics for data science and policy analysis azizur
rahman (editor), 2020 singapore, springer XV+ 386 pp., €207.99
(hardcover) ISBN 978-981-15-1734-1. <em>Journal of the Royal Statistical
Society: Series A (Statistics in Society)</em>, <em>184</em>(4), 1612.
(<a href="https://doi.org/10.1111/rssa.12744">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive = {J},
  author  = {Md Moyazzem Hossain},
  doi     = {10.1111/rssa.12744},
  journal = {Journal of the Royal Statistical Society: Series a},
  number  = {4},
  pages   = {1612},
  title   = {Statistics for data science and policy analysis azizur rahman (editor), 2020 singapore, springer XV+ 386 pp., €207.99 (hardcover) ISBN 978-981-15-1734-1},
  volume  = {184},
  year    = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Advanced statistics with applications in r. Eugene
demidenko, 2020 wiley series in probability and statistics, john wiley
and sons, USA. <em>Journal of the Royal Statistical Society: Series A
(Statistics in Society)</em>, <em>184</em>(4), 1610–1611. (<a
href="https://doi.org/10.1111/rssa.12727">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive = {J},
  author  = {Adrian Gepp},
  doi     = {10.1111/rssa.12727},
  journal = {Journal of the Royal Statistical Society: Series a},
  number  = {4},
  pages   = {1610-1611},
  title   = {Advanced statistics with applications in r. eugene demidenko, 2020 wiley series in probability and statistics, john wiley and sons, USA},
  volume  = {184},
  year    = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Probability companion for engineering and computer science
a. Prügel-bennett, 2019 cambridge university press, cambridge 457p.
39.99 GBP ISBN 978-1-108-72770-9. <em>Journal of the Royal Statistical
Society: Series A (Statistics in Society)</em>, <em>184</em>(4),
1609–1610. (<a href="https://doi.org/10.1111/rssa.12725">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive = {J},
  author  = {Sebastian Dietz},
  doi     = {10.1111/rssa.12725},
  journal = {Journal of the Royal Statistical Society: Series a},
  number  = {4},
  pages   = {1609-1610},
  title   = {Probability companion for engineering and computer science a. prügel-bennett, 2019 cambridge university press, cambridge 457p. 39.99 GBP ISBN 978-1-108-72770-9},
  volume  = {184},
  year    = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A computational approach to statistical learning taylor
arnold, michael kane, bryan w. Lewis, CRC press, boca raton, FL. 374p.,
ISBN: 9780367570613. <em>Journal of the Royal Statistical Society:
Series A (Statistics in Society)</em>, <em>184</em>(4), 1608. (<a
href="https://doi.org/10.1111/rssa.12723">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive = {J},
  author  = {Stanley E. Lazic},
  doi     = {10.1111/rssa.12723},
  journal = {Journal of the Royal Statistical Society: Series a},
  number  = {4},
  pages   = {1608},
  title   = {A computational approach to statistical learning taylor arnold, michael kane, bryan w. lewis, CRC press, boca raton, FL. 374p., ISBN: 9780367570613},
  volume  = {184},
  year    = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Bayesian cost-effectiveness analysis of medical treatments
elias moreno, francisco jose vazquez-polo, miguel angel
negrin-hernandez. 2020. Taylor &amp; francis group, LLC. CRC press,
283p, ISBN 9780367731878. <em>Journal of the Royal Statistical Society:
Series A (Statistics in Society)</em>, <em>184</em>(4), 1608–1609. (<a
href="https://doi.org/10.1111/rssa.12724">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive = {J},
  author  = {Min-Hua Jen},
  doi     = {10.1111/rssa.12724},
  journal = {Journal of the Royal Statistical Society: Series a},
  number  = {4},
  pages   = {1608-1609},
  title   = {Bayesian cost-effectiveness analysis of medical treatments elias moreno, francisco jose vazquez-polo, miguel angel negrin-hernandez. 2020. taylor &amp; francis group, LLC. CRC press, 283p, ISBN 9780367731878},
  volume  = {184},
  year    = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Lars lyberg, (1944–2021). <em>Journal of the Royal
Statistical Society: Series A (Statistics in Society)</em>,
<em>184</em>(4), 1606–1607. (<a
href="https://doi.org/10.1111/rssa.12694">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive = {J},
  author  = {Dennis Trewin},
  doi     = {10.1111/rssa.12694},
  journal = {Journal of the Royal Statistical Society: Series a},
  number  = {4},
  pages   = {1606-1607},
  title   = {Lars lyberg, (1944–2021)},
  volume  = {184},
  year    = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). David wishart (1943–2020). <em>Journal of the Royal
Statistical Society: Series A (Statistics in Society)</em>,
<em>184</em>(4), 1604–1605. (<a
href="https://doi.org/10.1111/rssa.12690">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive = {J},
  author  = {Sarah Barker and Shirley Coleman},
  doi     = {10.1111/rssa.12690},
  journal = {Journal of the Royal Statistical Society: Series a},
  number  = {4},
  pages   = {1604-1605},
  title   = {David wishart (1943–2020)},
  volume  = {184},
  year    = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Kenneth (ken) ronald walter brewer (1931–2021). <em>Journal
of the Royal Statistical Society: Series A (Statistics in Society)</em>,
<em>184</em>(4), 1602–1604. (<a
href="https://doi.org/10.1111/rssa.12729">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive = {J},
  author  = {Stephen Horn and Raymond Chambers and William Gross},
  doi     = {10.1111/rssa.12729},
  journal = {Journal of the Royal Statistical Society: Series a},
  number  = {4},
  pages   = {1602-1604},
  title   = {Kenneth (Ken) ronald walter brewer (1931–2021)},
  volume  = {184},
  year    = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). William gilmore stevenson (1943–2021). <em>Journal of the
Royal Statistical Society: Series A (Statistics in Society)</em>,
<em>184</em>(4), 1600–1601. (<a
href="https://doi.org/10.1111/rssa.12726">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive = {J},
  author  = {John Mallon and Vivienne Stevenson and Gilbert MacKenzie},
  doi     = {10.1111/rssa.12726},
  journal = {Journal of the Royal Statistical Society: Series a},
  number  = {4},
  pages   = {1600-1601},
  title   = {William gilmore stevenson (1943–2021)},
  volume  = {184},
  year    = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Roger david elston (1928–2021). <em>Journal of the Royal
Statistical Society: Series A (Statistics in Society)</em>,
<em>184</em>(4), 1599–1600. (<a
href="https://doi.org/10.1111/rssa.12735">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive = {J},
  author  = {Eric Page and David A. Elston},
  doi     = {10.1111/rssa.12735},
  journal = {Journal of the Royal Statistical Society: Series a},
  number  = {4},
  pages   = {1599-1600},
  title   = {Roger david elston (1928–2021)},
  volume  = {184},
  year    = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Partially pooled propensity score models for average
treatment effect estimation with multilevel data. <em>Journal of the
Royal Statistical Society: Series A (Statistics in Society)</em>,
<em>184</em>(4), 1578–1598. (<a
href="https://doi.org/10.1111/rssa.12741">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Causal inference analyses often use existing observational data, which in many cases has some clustering of individuals. In this paper, we discuss propensity score weighting methods in a multilevel setting where within clusters individuals share unmeasured confounders that are related to treatment assignment and the potential outcomes. We focus in particular on settings where models with fixed cluster effects are either not feasible or not useful due to the presence of a large number of small clusters. We found, both through numerical experiments and theoretical derivations, that a strategy of grouping clusters with similar treatment prevalence and estimating propensity scores within such cluster groups is effective in reducing bias from unmeasured cluster-level covariates under mild conditions on the outcome model. We apply our proposed method in evaluating the effectiveness of centre-based pre-school programme participation on children’s achievement at kindergarten, using the Early Childhood Longitudinal Study Kindergarten data.},
  archive  = {J},
  author   = {Youjin Lee and Trang Q. Nguyen and Elizabeth A. Stuart},
  doi      = {10.1111/rssa.12741},
  journal  = {Journal of the Royal Statistical Society: Series a},
  number   = {4},
  pages    = {1578-1598},
  title    = {Partially pooled propensity score models for average treatment effect estimation with multilevel data},
  volume   = {184},
  year     = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Social and material vulnerability in the face of seismic
hazard: An analysis of the italian case. <em>Journal of the Royal
Statistical Society: Series A (Statistics in Society)</em>,
<em>184</em>(4), 1549–1577. (<a
href="https://doi.org/10.1111/rssa.12739">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {The assessment of the vulnerability of a community endangerd by seismic hazard is of paramount importance for planning a precision policy aimed at the prevention and reduction of its seismic risk. We aim at measuring the vulnerability of the Italian municipalities exposed to seismic hazard, by analysing the open data offered by the Mappa dei Rischi dei Comuni Italiani provided by ISTAT, the Italian National Institute of Statistics. Encompassing the Index of Social and Material Vulnerability already computed by ISTAT, we also consider as referents of the latent social and material vulnerability of a community, its demographic dynamics and the age of the building stock where the community resides. Fusing the analyses of different indicators, within the context of seismic risk we offer a tentative ranking of the Italian municipalities in terms of their social and material vulnerability, together with differential profiles of their dominant fragilities which constitute the basis for planning precision policies aimed at seismic risk prevention and reduction.},
  archive  = {J},
  author   = {Oleksandr Didkovskyi and Giovanni Azzone and Alessandra Menafoglio and Piercesare Secchi},
  doi      = {10.1111/rssa.12739},
  journal  = {Journal of the Royal Statistical Society: Series a},
  number   = {4},
  pages    = {1549-1577},
  title    = {Social and material vulnerability in the face of seismic hazard: An analysis of the italian case},
  volume   = {184},
  year     = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Covariate selection for generalizing experimental results:
Application to a large-scale development program in uganda*. <em>Journal
of the Royal Statistical Society: Series A (Statistics in Society)</em>,
<em>184</em>(4), 1524–1548. (<a
href="https://doi.org/10.1111/rssa.12734">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Generalizing estimates of causal effects from an experiment to a target population is of interest to scientists. However, researchers are usually constrained by available covariate information. Analysts can often collect many fewer variables from population samples than from experimental samples, which has limited applicability of existing approaches that assume rich covariate data from both experimental and population samples. In this article, we examine how to select covariates necessary for generalizing experimental results under such data constraints. In our concrete context of a large-scale development program in Uganda, although more than 40 pre-treatment covariates are available in the experiment, only 8 of them were also measured in a target population. We propose a method to estimate a separating set—a set of variables affecting both the sampling mechanism and treatment effect heterogeneity—and show that the population average treatment effect (PATE) can be identified by adjusting for estimated separating sets. Our algorithm only requires a rich set of covariates in the experimental data, not in the target population, by incorporating researcher-specific constraints on what variables are measured in the population data. Analysing the development experiment in Uganda, we show that the proposed algorithm can allow for the PATE estimation in situations where conventional methods fail due to data requirements.},
  archive  = {J},
  author   = {Naoki Egami and Erin Hartman},
  doi      = {10.1111/rssa.12734},
  journal  = {Journal of the Royal Statistical Society: Series a},
  number   = {4},
  pages    = {1524-1548},
  title    = {Covariate selection for generalizing experimental results: Application to a large-scale development program in uganda*},
  volume   = {184},
  year     = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Domain prediction with grouped income data. <em>Journal of
the Royal Statistical Society: Series A (Statistics in Society)</em>,
<em>184</em>(4), 1501–1523. (<a
href="https://doi.org/10.1111/rssa.12736">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {One popular small area estimation method for estimating poverty and inequality indicators is the empirical best predictor under the unit-level nested error regression model with a continuous dependent variable. However, parameter estimation is more challenging when the response variable is grouped due to data confidentiality concerns or concerns about survey response burden. The work in this paper proposes methodology that enables fitting a nested error regression model when the dependent variable is grouped. Model parameters are then used for small area prediction of finite population parameters of interest. Model fitting in the case of a grouped response variable is based on the use of a stochastic expectation–maximization algorithm. Since the stochastic expectation–maximization algorithm relies on the Gaussian assumptions of the unit-level error terms, adaptive transformations are incorporated for handling departures from normality. The estimation of the mean squared error of the small area parameters is facilitated by a parametric bootstrap that captures the additional uncertainty due to the grouping mechanism and the possible use of adaptive transformations. The empirical properties of the proposed methodology are assessed by using model-based simulations and its relevance is illustrated by estimating deprivation indicators for municipalities in the Mexican state of Chiapas.},
  archive  = {J},
  author   = {Paul Walter and Marcus Groß and Timo Schmid and Nikos Tzavidis},
  doi      = {10.1111/rssa.12736},
  journal  = {Journal of the Royal Statistical Society: Series a},
  number   = {4},
  pages    = {1501-1523},
  title    = {Domain prediction with grouped income data},
  volume   = {184},
  year     = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Analysis of longitudinal advice-seeking networks following
implementation of high stakes testing. <em>Journal of the Royal
Statistical Society: Series A (Statistics in Society)</em>,
<em>184</em>(4), 1475–1500. (<a
href="https://doi.org/10.1111/rssa.12708">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Teacher interactions around instructional practices have been a topic of study for a long time. Previous studies concerning such interactions have focused on questions pertaining to cross-sectional networks. In fact, very few studies have considered longitudinal networks and still fewer have employed longitudinal network models to study changes in such interactions. We analyse teachers’ advice-seeking networks, observed annually between 2010 and 2013, in schools within a district where several initiatives were implemented starting in 2011. We assess whether formal structures, teaching assignment and leadership position, and teacher characteristics, gender and experience, are associated with advice-seeking ties, and the extent to which these associations change over time. To analyse the advice-seeking networks, we implement a Bayesian longitudinal latent space network model with covariates and random sender-receiver effects. Within the Bayesian framework, we address practical aspects of a principled network analysis such as missing ties and yearly immigration and emigration of teachers. Goodness of model fit assessment is conducted using posterior predictive checks. Our results demonstrate that while some of the associations between observed covariates and teachers’ interactions varied in 2011, most were otherwise stable. In 2011, we found decreases in the associations with same grade assignment, leadership position, and teaching in the same school.},
  archive  = {J},
  author   = {Samrachana Adhikari and Tracy Sweet and Brian Junker},
  doi      = {10.1111/rssa.12708},
  journal  = {Journal of the Royal Statistical Society: Series a},
  number   = {4},
  pages    = {1475-1500},
  title    = {Analysis of longitudinal advice-seeking networks following implementation of high stakes testing},
  volume   = {184},
  year     = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Using linked consumer registers to estimate residential
moves in the united kingdom. <em>Journal of the Royal Statistical
Society: Series A (Statistics in Society)</em>, <em>184</em>(4),
1452–1474. (<a href="https://doi.org/10.1111/rssa.12713">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {This paper argues that frequently updated data on the nature of residential moves and the circumstances of movers in the United Kingdom are insufficient for many research purposes. Accordingly, we develop previous research reported in this Journal to re-purpose consumer and administrative data in order to develop annual estimates of residential mobility between all UK neighbourhoods. We use a unique digital corpus of linked individual and household-level consumer registers compiled by the UK Consumer Data Research Centre, comprising over 143 million unique address records pertaining to the entire UK adult population over the period 1997–2016. We describe how records pertaining to individuals vacating a property can be assigned to their most probable residential destination, based on novel methods of matching names, assessing household composition, and using information on the date and probable distance of residential moves. We believe that the results of this analysis contribute highly granular, frequently updated estimates of residential moves that can be used to chart population-wide outcomes of residential mobility and migration behaviour, as well as the socio-spatial characteristics of the sedentary population.},
  archive  = {J},
  author   = {Justin T. van Dijk and Guy Lansley and Paul A. Longley},
  doi      = {10.1111/rssa.12713},
  journal  = {Journal of the Royal Statistical Society: Series a},
  number   = {4},
  pages    = {1452-1474},
  title    = {Using linked consumer registers to estimate residential moves in the united kingdom},
  volume   = {184},
  year     = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Clustering longitudinal life-course sequences using mixtures
of exponential-distance models. <em>Journal of the Royal Statistical
Society: Series A (Statistics in Society)</em>, <em>184</em>(4),
1414–1451. (<a href="https://doi.org/10.1111/rssa.12712">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Sequence analysis is an increasingly popular approach for analysing life courses represented by ordered collections of activities experienced by subjects over time. Here, we analyse a survey data set containing information on the career trajectories of a cohort of Northern Irish youths tracked between the ages of 16 and 22. We propose a novel, model-based clustering approach suited to the analysis of such data from a holistic perspective, with the aims of estimating the number of typical career trajectories, identifying the relevant features of these patterns, and assessing the extent to which such patterns are shaped by background characteristics. Several criteria exist for measuring pairwise dissimilarities among categorical sequences. Typically, dissimilarity matrices are employed as input to heuristic clustering algorithms. The family of methods we develop instead clusters sequences directly using mixtures of exponential-distance models. Basing the models on weighted variants of the Hamming distance metric permits closed-form expressions for parameter estimation. Simultaneously allowing the component membership probabilities to depend on fixed covariates and accommodating sampling weights in the clustering process yields new insights on the Northern Irish data. In particular, we find that school examination performance is the single most important predictor of cluster membership.},
  archive  = {J},
  author   = {Keefe Murphy and T. Brendan Murphy and Raffaella Piccarreta and I. Claire Gormley},
  doi      = {10.1111/rssa.12712},
  journal  = {Journal of the Royal Statistical Society: Series a},
  number   = {4},
  pages    = {1414-1451},
  title    = {Clustering longitudinal life-course sequences using mixtures of exponential-distance models},
  volume   = {184},
  year     = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Propensity score analysis for a semi-continuous exposure
variable: A study of gestational alcohol exposure and childhood
cognition. <em>Journal of the Royal Statistical Society: Series A
(Statistics in Society)</em>, <em>184</em>(4), 1390–1413. (<a
href="https://doi.org/10.1111/rssa.12716">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Propensity score methodology has become increasingly popular in recent years as a tool for estimating causal effects in observational studies. Much of the related research has been directed at settings with binary or discrete exposure variables with more recent work involving continuous exposure variables. In environmental epidemiology, a substantial proportion of individuals is often completely unexposed while others may experience heavy exposure leading to an exposure distribution with a point mass at zero and a heavy right tail. We suggest a new approach to handle this type of exposure data by constructing a propensity score based on a two-part model and show how this model can be used to more reliably adjust for covariates of a semi-continuous exposure variable. We also consider the case when a misspecified propensity score is used in a regression adjustment and derive an explicit form of the bias. We show that the potential bias gets smaller as the estimated propensity score gets closer to the true expectation of the exposure variable given a set of observed covariates. While this result pertains to a more general setting, we use it to evaluate the potential bias in settings in which the true exposure has a semi-continuous structure. We also evaluate and compare the performance of our proposed method through simulation studies relative to a simpler linear regression-based propensity score for a continuous exposure variable as well as through direct covariate adjustment. Overall, we find that using a propensity score constructed via a two-part model significantly improves the regression estimate when the exposure variable is semi-continuous in nature. Specifically when the proportion of non-exposed subjects is high and the effects of covariates on exposure and outcome are strong, the proposed two-part propensity score method outperforms the more standard competing methods. We illustrate our method using data from the Detroit Longitudinal Cohort Study in which the exposure variable reflects gestational alcohol exposure featuring zero values and a long tail.},
  archive  = {J},
  author   = {Tugba Akkaya Hocagil and Richard J. Cook and Sandra W. Jacobson and Joseph L. Jacobson and Louise M. Ryan},
  doi      = {10.1111/rssa.12716},
  journal  = {Journal of the Royal Statistical Society: Series a},
  number   = {4},
  pages    = {1390-1413},
  title    = {Propensity score analysis for a semi-continuous exposure variable: A study of gestational alcohol exposure and childhood cognition},
  volume   = {184},
  year     = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Two-phase sampling designs for data validation in settings
with covariate measurement error and continuous outcome. <em>Journal of
the Royal Statistical Society: Series A (Statistics in Society)</em>,
<em>184</em>(4), 1368–1389. (<a
href="https://doi.org/10.1111/rssa.12689">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Measurement errors are present in many data collection procedures and can harm analyses by biasing estimates. To correct for measurement error, researchers often validate a subsample of records and then incorporate the information learned from this validation sample into estimation. In practice, the validation sample is often selected using simple random sampling (SRS). However, SRS leads to inefficient estimates because it ignores information on the error-prone variables, which can be highly correlated to the unknown truth. Applying and extending ideas from the two-phase sampling literature, we propose optimal and nearly optimal designs for selecting the validation sample in the classical measurement-error framework. We target designs to improve the efficiency of model-based and design-based estimators, and show how the resulting designs compare to each other. Our results suggest that sampling schemes that extract more information from the error-prone data are substantially more efficient than SRS, for both design- and model-based estimators. The optimal procedure, however, depends on the analysis method, and can differ substantially. This is supported by theory and simulations. We illustrate the various designs using data from an HIV cohort study.},
  archive  = {J},
  author   = {Gustavo Amorim and Ran Tao and Sarah Lotspeich and Pamela A. Shaw and Thomas Lumley and Bryan E. Shepherd},
  doi      = {10.1111/rssa.12689},
  journal  = {Journal of the Royal Statistical Society: Series a},
  number   = {4},
  pages    = {1368-1389},
  title    = {Two-phase sampling designs for data validation in settings with covariate measurement error and continuous outcome},
  volume   = {184},
  year     = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Modified poisson regression analysis of grouped and
right-censored counts. <em>Journal of the Royal Statistical Society:
Series A (Statistics in Society)</em>, <em>184</em>(4), 1347–1367. (<a
href="https://doi.org/10.1111/rssa.12678">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Grouped and right-censored (GRC) counts are widely used in criminology, demography, epidemiology, marketing, sociology, psychology and other related disciplines to study behavioural and event frequencies, especially when sensitive research topics or individuals with possibly lower cognitive capacities are at stake. Yet, the co-existence of grouping and right-censoring poses major difficulties in regression analysis. To implement generalised linear regression of GRC counts, we derive modified Poisson estimators and their asymptotic properties, develop a hybrid line search algorithm for parameter inference, demonstrate the finite-sample performance of these estimators via simulation, and evaluate its empirical applicability based on survey data of drug use in America. This method has a clear methodological advantage over the ordered logistic model for analysing GRC counts.},
  archive  = {J},
  author   = {Qiang Fu and Tian-Yi Zhou and Xin Guo},
  doi      = {10.1111/rssa.12678},
  journal  = {Journal of the Royal Statistical Society: Series a},
  number   = {4},
  pages    = {1347-1367},
  title    = {Modified poisson regression analysis of grouped and right-censored counts},
  volume   = {184},
  year     = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Machine learning approaches to identify thresholds in a
heat-health warning system context. <em>Journal of the Royal Statistical
Society: Series A (Statistics in Society)</em>, <em>184</em>(4),
1326–1346. (<a href="https://doi.org/10.1111/rssa.12745">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {During the last two decades, a number of countries or cities established heat-health warning systems in order to alert public health authorities when some heat indicator exceeds a predetermined threshold. Different methods were considered to establish thresholds all over the world, each with its own strengths and weaknesses. The common ground is that current methods are based on exposure-response function estimates that can fail in many situations. The present paper aims at proposing several data-driven methods to establish thresholds using historical data of health issues and environmental indicators. The proposed methods are model-based regression trees (MOB), multivariate adaptive regression splines (MARS), the patient rule-induction method (PRIM) and adaptive index models (AIM). These methods focus on finding relevant splits in the association between indicators and the health outcome but do it in different fashions. A simulation study and a real-world case study hereby compare the discussed methods. Results show that proposed methods are better at predicting adverse days than current thresholds and benchmark methods. The results nonetheless suggest that PRIM is overall the more reliable method with low variability of results according to the scenario or case.},
  archive  = {J},
  author   = {Pierre Masselot and Fateh Chebana and Céline Campagna and Éric Lavigne and Taha B.M.J. Ouarda and Pierre Gosselin},
  doi      = {10.1111/rssa.12745},
  journal  = {Journal of the Royal Statistical Society: Series a},
  number   = {4},
  pages    = {1326-1346},
  title    = {Machine learning approaches to identify thresholds in a heat-health warning system context},
  volume   = {184},
  year     = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A computationally efficient, high-dimensional multiple
changepoint procedure with application to global terrorism incidence.
<em>Journal of the Royal Statistical Society: Series A (Statistics in
Society)</em>, <em>184</em>(4), 1303–1325. (<a
href="https://doi.org/10.1111/rssa.12695">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Detecting changepoints in data sets with many variates is a data science challenge of increasing importance. Motivated by the problem of detecting changes in the incidence of terrorism from a global terrorism database, we propose a novel approach to multiple changepoint detection in multivariate time series. Our method, which we call SUBSET, is a model-based approach which uses a penalised likelihood to detect changes for a wide class of parametric settings. We provide theory that guides the choice of penalties to use for SUBSET, and that shows it has high power to detect changes regardless of whether only a few variates or many variates change. Empirical results show that SUBSET out-performs many existing approaches for detecting changes in mean in Gaussian data; additionally, unlike these alternative methods, it can be easily extended to non-Gaussian settings such as are appropriate for modelling counts of terrorist events.},
  archive  = {J},
  author   = {S. O. Tickle and I. A. Eckley and P. Fearnhead},
  doi      = {10.1111/rssa.12695},
  journal  = {Journal of the Royal Statistical Society: Series a},
  number   = {4},
  pages    = {1303-1325},
  title    = {A computationally efficient, high-dimensional multiple changepoint procedure with application to global terrorism incidence},
  volume   = {184},
  year     = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Filtering the intensity of public concern from social media
count data with jumps. <em>Journal of the Royal Statistical Society:
Series A (Statistics in Society)</em>, <em>184</em>(4), 1283–1302. (<a
href="https://doi.org/10.1111/rssa.12704">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Count time series obtained from online social media data, such as Twitter, have drawn increasing interest among academics and market analysts over the past decade. Transforming Web activity records into counts yields time series with peculiar features, including the coexistence of smooth paths and sudden jumps, as well as cross-sectional and temporal dependence. Using Twitter posts about country risks for the United Kingdom and the United States, this paper proposes an innovative state space model for multivariate count data with jumps. We use the proposed model to assess the impact of public concerns in these countries on market systems. To do so, public concerns inferred from Twitter data are unpacked into country-specific persistent terms, risk social amplification events and co-movements of the country series. The identified components are then used to investigate the existence and magnitude of country-risk spillovers and social amplification effects on the volatility of financial markets.},
  archive  = {J},
  author   = {Matteo Iacopini and Carlo R.M.A. Santagiustina},
  doi      = {10.1111/rssa.12704},
  journal  = {Journal of the Royal Statistical Society: Series a},
  number   = {4},
  pages    = {1283-1302},
  title    = {Filtering the intensity of public concern from social media count data with jumps},
  volume   = {184},
  year     = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Estimation of the prevalence of chronic kidney disease in
people with diabetes by combining information from multiple routine data
collections. <em>Journal of the Royal Statistical Society: Series A
(Statistics in Society)</em>, <em>184</em>(4), 1260–1282. (<a
href="https://doi.org/10.1111/rssa.12682">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Health care claims databases maintained by social insurance institutions provide rich and sometimes easily accessible data sources for epidemiological research. Interpreting the registered claims, for example, drug prescriptions, as proxies for the condition of interest, for example, diabetes, they allow for nationwide prevalence estimation. We illustrate a more subtle use of health care claims data in estimating the stage-specific prevalence of chronic kidney disease in the Austrian population with diabetes. The main difficulty was that information on the type of disease (chronic or acute) and information on the stage of disease were only available for small, almost disjoint subsets of the health care claims data. Using high-dimensional regression models, we could combine the information and provide nationwide estimates of the stage-specific prevalence of diabetic chronic kidney disease. Validating our estimates by comparing to other studies, we found the level of agreement satisfying.},
  archive  = {J},
  author   = {Angelika Geroldinger and Milan Hronsky and Florian Endel and Gottfried Endel and Rainer Oberbauer and Georg Heinze},
  doi      = {10.1111/rssa.12682},
  journal  = {Journal of the Royal Statistical Society: Series a},
  number   = {4},
  pages    = {1260-1282},
  title    = {Estimation of the prevalence of chronic kidney disease in people with diabetes by combining information from multiple routine data collections},
  volume   = {184},
  year     = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Using text mining to track outbreak trends in global
surveillance of emerging diseases: ProMED-mail. <em>Journal of the Royal
Statistical Society: Series A (Statistics in Society)</em>,
<em>184</em>(4), 1245–1259. (<a
href="https://doi.org/10.1111/rssa.12721">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {ProMED-mail (Program for Monitoring Emerging Disease) is an international disease outbreak monitoring and early warning system. Every year, users contribute thousands of reports that include reference to infectious diseases and toxins. However, due to the uneven distribution of the reports for each disease, traditional statistics-based text mining techniques, represented by term frequency-related algorithm, are not suitable. Thus, we conducted a study in three steps (i) report filtering, (ii) keyword extraction from reports and finally (iii) word co-occurrence network analysis to fill the gap between ProMED and its utilization. The keyword extraction was performed with the TextRank algorithm, keywords co-occurrence networks were then produced using the top keywords from each document and multiple network centrality measures were computed to analyse the co-occurrence networks. We used two major outbreaks in recent years, Ebola, 2014 and Zika 2015, as cases to illustrate and validate the process. We found that the extracted information structures are consistent with World Health Organisation description of the timeline and phases of the epidemics. Our research presents a pipeline that can extract and organize the information to characterize the evolution of epidemic outbreaks. It also highlights the potential for ProMED to be utilized in monitoring, evaluating and improving responses to outbreaks.},
  archive  = {J},
  author   = {Jingxian You and Paul Expert and Céire Costelloe},
  doi      = {10.1111/rssa.12721},
  journal  = {Journal of the Royal Statistical Society: Series a},
  number   = {4},
  pages    = {1245-1259},
  title    = {Using text mining to track outbreak trends in global surveillance of emerging diseases: ProMED-mail},
  volume   = {184},
  year     = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Spatio-temporal mixed membership models for criminal
activity. <em>Journal of the Royal Statistical Society: Series A
(Statistics in Society)</em>, <em>184</em>(4), 1220–1244. (<a
href="https://doi.org/10.1111/rssa.12642">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {We suggest a probabilistic approach to study crime data in London and highlight the benefits of defining a statistical joint crime distribution model which provides insights into urban criminal activity. This is achieved by developing a hierarchical mixture model for observations, crime occurrences over a geographical study area, that are grouped according to multiple time stamps and crime categories. The mixture components correspond to spatial crime distributions over the study area and the goal is to infer, based on the observations, how and to what degree the latent distributions are shared across the groups.},
  archive  = {J},
  author   = {Seppo Virtanen and Mark Girolami},
  doi      = {10.1111/rssa.12642},
  journal  = {Journal of the Royal Statistical Society: Series a},
  number   = {4},
  pages    = {1220-1244},
  title    = {Spatio-temporal mixed membership models for criminal activity},
  volume   = {184},
  year     = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Personalised need of care in an ageing society: The making
of a prediction tool based on register data. <em>Journal of the Royal
Statistical Society: Series A (Statistics in Society)</em>,
<em>184</em>(4), 1199–1219. (<a
href="https://doi.org/10.1111/rssa.12644">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Danish municipalities monitor older persons who are at high risk of declining health and would later need home care services. However, there is no established strategy yet on how to accurately identify those who are at high risk. Therefore, there is great potential to optimise the municipalities’ prevention strategies. Denmark’s comprehensive set of electronic population registers provide longitudinal data that cover individual and household socio-demographics and medical history. Using these data, we developed and applied recurrent neural networks to predict the risk of a need of care services in the future and thus identify individuals who would benefit the most from the municipalities’ prevention strategies. We compared our recurrent neural network model to prediction models based on Cox regression and Fine–Gray regression in terms of calibration and discrimination. Challenges for the prediction modelling were the competing risk of death and the longitudinal information on the registered life course data.},
  archive  = {J},
  author   = {Marvin N. Wright and Sasmita Kusumastuti and Laust H. Mortensen and Rudi G. J. Westendorp and Thomas A. Gerds},
  doi      = {10.1111/rssa.12644},
  journal  = {Journal of the Royal Statistical Society: Series a},
  number   = {4},
  pages    = {1199-1219},
  title    = {Personalised need of care in an ageing society: The making of a prediction tool based on register data},
  volume   = {184},
  year     = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Functional ANOVA modelling of pedestrian counts on streets
in three european cities. <em>Journal of the Royal Statistical Society:
Series A (Statistics in Society)</em>, <em>184</em>(4), 1176–1198. (<a
href="https://doi.org/10.1111/rssa.12646">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {The relation between pedestrian flows, the structure of the city and the street network is of central interest in urban research. However, studies of this have traditionally been based on small data sets and simplistic statistical methods. Because of a recent large-scale cross-country pedestrian survey, there is now enough data available to study this in greater detail than before, using modern statistical methods. We propose a functional ANOVA model to explain how the pedestrian flow for a street varies over the day based on its density type, describing the nearby buildings, and street type, describing its role in the city’s overall street network. The model is formulated and estimated in a Bayesian framework using hour-by-hour pedestrian counts from the three European cities, Amsterdam, London and Stockholm. To assess the predictive power of the model, which could be of interest when building new neighbourhoods, it is compared with four common methods from machine learning, including neural networks and random forests. The results indicate that this model works well but that there is room for improvement in capturing the variability in the data, especially between cities.},
  archive  = {J},
  author   = {David Bolin and Vilhelm Verendel and Meta Berghauser Pont and Ioanna Stavroulaki and Oscar Ivarsson and Erik Håkansson},
  doi      = {10.1111/rssa.12646},
  journal  = {Journal of the Royal Statistical Society: Series a},
  number   = {4},
  pages    = {1176-1198},
  title    = {Functional ANOVA modelling of pedestrian counts on streets in three european cities},
  volume   = {184},
  year     = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Enhancing (publications on) data quality: Deeper data
minding and fuller data confession. <em>Journal of the Royal Statistical
Society: Series A (Statistics in Society)</em>, <em>184</em>(4),
1161–1175. (<a href="https://doi.org/10.1111/rssa.12762">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Statistics typically treats data as inputs for analysis, whereas the broader data science enterprise deals with the entire data life cycle, including the phases that output data. This commentary argues that it would benefit statistics and (data) science if we statisticians were also to treat data as products in and of themselves, and accordingly subject them to data minding , a stringent quality inspection process that scrutinizes data conceptualization, data pre-processing, data curation and data provenance, in addition to data collection, the traditional objective of our emphasis before data analysis. A concrete step in promoting deeper data minding is to encourage fuller data confession in (statistical) publications, that is, to entice—or at least not to disincentivize—the authors into providing more details on the genealogy of a given body of data, including an account of its deliberations, especially with respect to sources of adverse influence on data quality. The collection of articles in this special issue (on data science for societies) provides both the inspiration and aspiration for deeper data minding and fuller data confession.},
  archive  = {J},
  author   = {Xiao-Li Meng},
  doi      = {10.1111/rssa.12762},
  journal  = {Journal of the Royal Statistical Society: Series a},
  number   = {4},
  pages    = {1161-1175},
  title    = {Enhancing (publications on) data quality: Deeper data minding and fuller data confession},
  volume   = {184},
  year     = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Data science for society: Challenges, developments and
applications. <em>Journal of the Royal Statistical Society: Series A
(Statistics in Society)</em>, <em>184</em>(4), 1159–1160. (<a
href="https://doi.org/10.1111/rssa.12763">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive = {J},
  author  = {Pia Hardelid and Peter Christen and Elizabeth Williamson and Katie Harron and Bianca L. De Stavola},
  doi     = {10.1111/rssa.12763},
  journal = {Journal of the Royal Statistical Society: Series a},
  number  = {4},
  pages   = {1159-1160},
  title   = {Data science for society: Challenges, developments and applications},
  volume  = {184},
  year    = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021c). Statistical inference via data science chester ismay,
albert y. Kim, (2019). Chapman and hall/CRC press. Pp. Xiii + 430. ISBN
9780367409876. <em>Journal of the Royal Statistical Society: Series A
(Statistics in Society)</em>, <em>184</em>(3), 1155. (<a
href="https://doi.org/10.1111/rssa.12707">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive = {J},
  author  = {Shalabh},
  doi     = {10.1111/rssa.12707},
  journal = {Journal of the Royal Statistical Society: Series a},
  number  = {3},
  pages   = {1155},
  title   = {Statistical inference via data science chester ismay, albert y. kim, (2019). chapman and Hall/CRC press. pp. xiii + 430. ISBN 9780367409876},
  volume  = {184},
  year    = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Analyzing high-dimensional gene expression and DNA
methylation data with r hongmei zhang, (2020). Chapman &amp; hall/CRC
press mathematical and computational biology 202 pages, £59.99
(paperback), £150.00 (hardbound), £53.99 (e-book). ISBN 9780367495169.
<em>Journal of the Royal Statistical Society: Series A (Statistics in
Society)</em>, <em>184</em>(3), 1154. (<a
href="https://doi.org/10.1111/rssa.12706">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive = {J},
  author  = {Anoop Chaturvedi},
  doi     = {10.1111/rssa.12706},
  journal = {Journal of the Royal Statistical Society: Series a},
  number  = {3},
  pages   = {1154},
  title   = {Analyzing high-dimensional gene expression and DNA methylation data with r hongmei zhang, (2020). chapman &amp; Hall/CRC press mathematical and computational biology 202 pages, £59.99 (Paperback), £150.00 (Hardbound), £53.99 (e-book). ISBN 9780367495169},
  volume  = {184},
  year    = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Dark data: Why what you don’t know matters david j. Hand,
(2020). Princeton, NJ: Princeton university press. Xii + 330pp. ISBN
9780691182377. <em>Journal of the Royal Statistical Society: Series A
(Statistics in Society)</em>, <em>184</em>(3), 1153. (<a
href="https://doi.org/10.1111/rssa.12705">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive = {J},
  author  = {Ian Jolliffe},
  doi     = {10.1111/rssa.12705},
  journal = {Journal of the Royal Statistical Society: Series a},
  number  = {3},
  pages   = {1153},
  title   = {Dark data: why what you don’t know matters david j. hand, (2020). princeton, NJ: princeton university press. xii + 330pp. ISBN 9780691182377},
  volume  = {184},
  year    = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The equation of knowledge: From bayes’ rule to a unified
philosophy of science lê nguyên hoang, 2020. CRC press, boca raton xii +
460 pp., ISBN 9780367428150. <em>Journal of the Royal Statistical
Society: Series A (Statistics in Society)</em>, <em>184</em>(3),
1151–1152. (<a href="https://doi.org/10.1111/rssa.12693">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive = {J},
  author  = {Simon French},
  doi     = {10.1111/rssa.12693},
  journal = {Journal of the Royal Statistical Society: Series a},
  number  = {3},
  pages   = {1151-1152},
  title   = {The equation of knowledge: From bayes’ rule to a unified philosophy of science lê nguyên hoang, 2020. CRC press, boca raton xii + 460 pp., ISBN 9780367428150},
  volume  = {184},
  year    = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Interactive web-based data visualization with r, plotly,
and shiny carson sievert; chapman &amp; hall/CRC; 2020; ISBN
978-1-138-33145-7. <em>Journal of the Royal Statistical Society: Series
A (Statistics in Society)</em>, <em>184</em>(3), 1150. (<a
href="https://doi.org/10.1111/rssa.12692">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive = {J},
  author  = {Shalabh},
  doi     = {10.1111/rssa.12692},
  journal = {Journal of the Royal Statistical Society: Series a},
  number  = {3},
  pages   = {1150},
  title   = {Interactive web-based data visualization with r, plotly, and shiny carson sievert; chapman &amp; Hall/CRC; 2020; ISBN 978-1-138-33145-7},
  volume  = {184},
  year    = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Michael hills (7 june 1934–7 january 2021). <em>Journal of
the Royal Statistical Society: Series A (Statistics in Society)</em>,
<em>184</em>(3), 1149. (<a
href="https://doi.org/10.1111/rssa.12728">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive = {J},
  author  = {Bianca L. De Stavola},
  doi     = {10.1111/rssa.12728},
  journal = {Journal of the Royal Statistical Society: Series a},
  number  = {3},
  pages   = {1149},
  title   = {Michael hills (7 june 1934–7 january 2021)},
  volume  = {184},
  year    = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). John haigh 1941–2021. <em>Journal of the Royal Statistical
Society: Series A (Statistics in Society)</em>, <em>184</em>(3),
1146–1148. (<a href="https://doi.org/10.1111/rssa.12698">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive = {J},
  author  = {Charles M. Goldie},
  doi     = {10.1111/rssa.12698},
  journal = {Journal of the Royal Statistical Society: Series a},
  number  = {3},
  pages   = {1146-1148},
  title   = {John haigh 1941–2021},
  volume  = {184},
  year    = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Predicting individual effects in fixed effects panel probit
models. <em>Journal of the Royal Statistical Society: Series A
(Statistics in Society)</em>, <em>184</em>(3), 1109–1145. (<a
href="https://doi.org/10.1111/rssa.12722">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Many applied settings in empirical economics require estimation of a large number of individual effects, like teacher effects or location effects; in health economics, prominent examples include patient effects, doctor effects or hospital effects. Increasingly, these effects are the object of interest of the estimation, and predicted effects are often used for further descriptive and regression analyses. To avoid imposing distributional assumptions on these effects, they are typically estimated via fixed effects methods. In short panels, the conventional maximum likelihood estimator for fixed effects binary response models provides poor estimates of these individual effects since the finite sample bias is typically substantial. We present a bias-reduced fixed effects estimator that provides better estimates of the individual effects in these models by removing the first-order asymptotic bias. An additional, practical advantage of the estimator is that it provides finite predictions for all individual effects in the sample, including those for which the corresponding dependent variable has identical outcomes in all time periods over time (either all zeros or ones); for these, the maximum likelihood prediction is infinite. We illustrate the approach in simulation experiments and in an application to health care utilization.},
  archive  = {J},
  author   = {Johannes S. Kunz and Kevin E. Staub and Rainer Winkelmann},
  doi      = {10.1111/rssa.12722},
  journal  = {Journal of the Royal Statistical Society: Series a},
  number   = {3},
  pages    = {1109-1145},
  title    = {Predicting individual effects in fixed effects panel probit models},
  volume   = {184},
  year     = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Generating poisson-distributed differentially private
synthetic data. <em>Journal of the Royal Statistical Society: Series A
(Statistics in Society)</em>, <em>184</em>(3), 1093–1108. (<a
href="https://doi.org/10.1111/rssa.12711">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {The dissemination of synthetic data can be an effective means of making information from sensitive data publicly available with a reduced risk of disclosure. While mechanisms exist for synthesizing data that satisfy formal privacy guarantees, these mechanisms do not typically resemble the models an end-user might use to analyse the data. More recently, the use of methods from the disease mapping literature has been proposed to generate spatially referenced synthetic data with high utility but without formal privacy guarantees. The objective for this paper is to help bridge the gap between the disease mapping and the differential privacy literatures. In particular, we generalize an approach for generating differentially private synthetic data currently used by the US Census Bureau to the case of Poisson-distributed count data in a way that accommodates heterogeneity in population sizes and allows for the infusion of prior information regarding the underlying event rates. Following a pair of small simulation studies, we illustrate the utility of the synthetic data produced by this approach using publicly available, county-level heart disease-related death counts. This study demonstrates the benefits of the proposed approach’s flexibility with respect to heterogeneity in population sizes and event rates while motivating further research to improve its utility.},
  archive  = {J},
  author   = {Harrison Quick},
  doi      = {10.1111/rssa.12711},
  journal  = {Journal of the Royal Statistical Society: Series a},
  number   = {3},
  pages    = {1093-1108},
  title    = {Generating poisson-distributed differentially private synthetic data},
  volume   = {184},
  year     = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Long-term spatial modelling for characteristics of extreme
heat events. <em>Journal of the Royal Statistical Society: Series A
(Statistics in Society)</em>, <em>184</em>(3), 1070–1092. (<a
href="https://doi.org/10.1111/rssa.12710">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {There is increasing evidence that global warming manifests itself in more frequent warm days and that heat waves will become more frequent. Presently, a formal definition of a heat wave is not agreed upon in the literature. To avoid this debate, we consider extreme heat events, which, at a given location, are well-defined as a run of consecutive days above an associated local threshold. Characteristics of extreme heat events (EHEs) are of primary interest, such as incidence and duration, as well as the magnitude of the average exceedance and maximum exceedance above the threshold during the EHE. Using approximately 60-year time series of daily maximum temperature data collected at 18 locations in a given region, we propose a spatio-temporal model to study the characteristics of EHEs over time. The model enables prediction of the behaviour of EHE characteristics at unobserved locations within the region. Specifically, our approach employs a two-state space–time model for EHEs with local thresholds where one state defines above threshold daily maximum temperatures and the other below threshold temperatures. We show that our model is able to recover the EHE characteristics of interest and outperforms a corresponding autoregressive model that ignores thresholds based on out-of-sample prediction.},
  archive  = {J},
  author   = {Erin M. Schliep and Alan E. Gelfand and Jesús Abaurrea and Jesús Asín and María A. Beamonte and Ana C. Cebrián},
  doi      = {10.1111/rssa.12710},
  journal  = {Journal of the Royal Statistical Society: Series a},
  number   = {3},
  pages    = {1070-1092},
  title    = {Long-term spatial modelling for characteristics of extreme heat events},
  volume   = {184},
  year     = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The effects of question, respondent and interviewer
characteristics on two types of item nonresponse. <em>Journal of the
Royal Statistical Society: Series A (Statistics in Society)</em>,
<em>184</em>(3), 1052–1069. (<a
href="https://doi.org/10.1111/rssa.12703">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {In this article, we examine two types of item nonresponse in a face-to-face population survey: ‘don’t know’ (DK) and ‘item refusal’ (REF). Based on the cognitive model of survey response, the theory of survey satisficing and previous research, we derive explanatory variables on three levels: question, respondent and interviewer characteristics. The results of our cross-classified model show that while the two levels question and respondents’ characteristics affected both types of item nonresponse, interviewer characteristics affected only DK answers. Our results also confirm that DK and REF are substantially different item nonresponse types resulting from distinguishable disruptions of the cognitive response process. Since most results are in line with prior theoretical predictions, they suggest that survey practitioners are well-advised by continuing to follow the large body of practical guidance derived from the theories tested here.},
  archive  = {J},
  author   = {Henning Silber and Joss Roßmann and Tobias Gummer and Stefan Zins and Kai Willem Weyandt},
  doi      = {10.1111/rssa.12703},
  journal  = {Journal of the Royal Statistical Society: Series a},
  number   = {3},
  pages    = {1052-1069},
  title    = {The effects of question, respondent and interviewer characteristics on two types of item nonresponse},
  volume   = {184},
  year     = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Estimation of causal effects with small data in the presence
of trapdoor variables. <em>Journal of the Royal Statistical Society:
Series A (Statistics in Society)</em>, <em>184</em>(3), 1030–1051. (<a
href="https://doi.org/10.1111/rssa.12699">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {We consider the problem of estimating causal effects of interventions from observational data when well-known back-door and front-door adjustments are not applicable. We show that when an identifiable causal effect is subject to an implicit functional constraint that is not deducible from conditional independence relations, the estimator of the causal effect can exhibit bias in small samples. This bias is related to variables that we call trapdoor variables . We use simulated data to study different strategies to account for trapdoor variables and suggest how the related trapdoor bias might be minimized. The importance of trapdoor variables in causal effect estimation is illustrated with real data from the Life Course 1971–2002 study. Using this data set, we estimate the causal effect of education on income in the Finnish context. Bayesian modelling allows us to take the parameter uncertainty into account and to present the estimated causal effects as posterior distributions.},
  archive  = {J},
  author   = {Jouni Helske and Santtu Tikka and Juha Karvanen},
  doi      = {10.1111/rssa.12699},
  journal  = {Journal of the Royal Statistical Society: Series a},
  number   = {3},
  pages    = {1030-1051},
  title    = {Estimation of causal effects with small data in the presence of trapdoor variables},
  volume   = {184},
  year     = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Linearization and variance estimation of the bonferroni
inequality index. <em>Journal of the Royal Statistical Society: Series A
(Statistics in Society)</em>, <em>184</em>(3), 1008–1029. (<a
href="https://doi.org/10.1111/rssa.12701">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {The study of income inequality is important for predicting the wealth of a country. There is an increasing number of publications where the authors call for the use of several indices simultaneously to better account for the wealth distribution. Due to the fact that income data are usually collected through sample surveys, the sampling properties of income inequality measures should not be overlooked. The most widely used inequality measure is the Gini index, and its inferential aspects have been deeply investigated. An alternative inequality index could be the Bonferroni inequality index, although less attention on its inference has been paid in the literature. The aim of this paper is to address the inference of the Bonferroni index in a finite population framework. The Bonferroni index is linearized by differentiation with respect to the sample indicators which allows for conducting a valid inference. Furthermore, the linearized variables are used to evaluate the effects of the different observations on the Bonferroni and Gini indices. The result demonstrates once for all that the former is more sensitive to the lowest incomes in the distribution than the latter.},
  archive  = {J},
  author   = {Ziqing Dong and Yves Tillé and Giovanni M. Giorgi and Alessio Guandalini},
  doi      = {10.1111/rssa.12701},
  journal  = {Journal of the Royal Statistical Society: Series a},
  number   = {3},
  pages    = {1008-1029},
  title    = {Linearization and variance estimation of the bonferroni inequality index},
  volume   = {184},
  year     = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multilevel time series modelling of mobility trends in the
netherlands for small domains. <em>Journal of the Royal Statistical
Society: Series A (Statistics in Society)</em>, <em>184</em>(3),
985–1007. (<a href="https://doi.org/10.1111/rssa.12700">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {The purpose of the Dutch Travel Survey is to produce reliable estimates on mobility of the Dutch population. In this paper mobility trends are estimated at several aggregation levels, using multilevel time series models. The models account for discontinuities induced by two survey redesigns and outliers due to less reliable outcomes in one particular year. The input for the model is direct annual estimates with their standard errors for the period 1999–2017 for a detailed cross-classification in 504 domains. Appropriate transformations for the direct estimates and generalized variance functions to smooth the standard errors of the direct estimates are proposed. The models are fitted in an hierarchical Bayesian framework using MCMC simulations. From the model outputs smooth trend estimates are computed at the most detailed domain level. Predictions at higher aggregation levels obtained by aggregation of the most detailed domain predictions result in a numerically consistent set of trend estimates for all target variables.},
  archive  = {J},
  author   = {Harm Jan Boonstra and Jan van den Brakel and Sumonkanti Das},
  doi      = {10.1111/rssa.12700},
  journal  = {Journal of the Royal Statistical Society: Series a},
  number   = {3},
  pages    = {985-1007},
  title    = {Multilevel time series modelling of mobility trends in the netherlands for small domains},
  volume   = {184},
  year     = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Inequality measurement with grouped data: Parametric and
non-parametric methods. <em>Journal of the Royal Statistical Society:
Series A (Statistics in Society)</em>, <em>184</em>(3), 964–984. (<a
href="https://doi.org/10.1111/rssa.12702">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Grouped data in the form of income shares have conventionally been used to estimate income inequality due to the lack of individual records. We present a systematic evaluation of the performance of parametric distributions and non-parametric techniques to estimate economic inequality using more than 3300 data sets. We also provide guidance on the choice between these two approaches and their estimation, for which we develop the GB2group R package. Our results indicate that even the simplest parametric models provide reliable estimates of inequality measures. The non-parametric approach, however, fails to represent income distributions accurately.},
  archive  = {J},
  author   = {Vanesa Jorda and José María Sarabia and Markus Jäntti},
  doi      = {10.1111/rssa.12702},
  journal  = {Journal of the Royal Statistical Society: Series a},
  number   = {3},
  pages    = {964-984},
  title    = {Inequality measurement with grouped data: Parametric and non-parametric methods},
  volume   = {184},
  year     = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Combining non-probability and probability survey samples
through mass imputation. <em>Journal of the Royal Statistical Society:
Series A (Statistics in Society)</em>, <em>184</em>(3), 941–963. (<a
href="https://doi.org/10.1111/rssa.12696">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Analysis of non-probability survey samples requires auxiliary information at the population level. Such information may also be obtained from an existing probability survey sample from the same finite population. Mass imputation has been used in practice for combining non-probability and probability survey samples and making inferences on the parameters of interest using the information collected only in the non-probability sample for the study variables. Under the assumption that the conditional mean function from the non-probability sample can be transported to the probability sample, we establish the consistency of the mass imputation estimator and derive its asymptotic variance formula. Variance estimators are developed using either linearization or bootstrap. Finite sample performances of the mass imputation estimator are investigated through simulation studies. We also address important practical issues of the method through the analysis of a real-world non-probability survey sample collected by the Pew Research Centre.},
  archive  = {J},
  author   = {Jae Kwang Kim and Seho Park and Yilin Chen and Changbao Wu},
  doi      = {10.1111/rssa.12696},
  journal  = {Journal of the Royal Statistical Society: Series a},
  number   = {3},
  pages    = {941-963},
  title    = {Combining non-probability and probability survey samples through mass imputation},
  volume   = {184},
  year     = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A comparison of prior elicitation aggregation using the
classical method and SHELF. <em>Journal of the Royal Statistical
Society: Series A (Statistics in Society)</em>, <em>184</em>(3),
920–940. (<a href="https://doi.org/10.1111/rssa.12691">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Subjective Bayesian prior distributions elicited from experts can be aggregated together to form group priors. This paper compares aggregated priors formed by equal weight aggregation, the classical method and the Sheffield elicitation framework to each other and individual expert priors, using an expert elicitation carried out for a clinical trial. Aggregation methods and individual expert prior distributions are compared using proper scoring rules to compare the informativeness and calibration of the distributions. The three aggregation methods outperform the individual experts, and the Sheffield elicitation framework performs best among them.},
  archive  = {J},
  author   = {Cameron J. Williams and Kevin J. Wilson and Nina Wilson},
  doi      = {10.1111/rssa.12691},
  journal  = {Journal of the Royal Statistical Society: Series a},
  number   = {3},
  pages    = {920-940},
  title    = {A comparison of prior elicitation aggregation using the classical method and SHELF},
  volume   = {184},
  year     = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). When zero may not be zero: A cautionary note on the use of
inter-rater reliability in evaluating grant peer review. <em>Journal of
the Royal Statistical Society: Series A (Statistics in Society)</em>,
<em>184</em>(3), 904–919. (<a
href="https://doi.org/10.1111/rssa.12681">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Considerable attention has focused on studying reviewer agreement via inter-rater reliability (IRR) as a way to assess the quality of the peer review process. Inspired by a recent study that reported an IRR of zero in the mock peer review of top-quality grant proposals, we use real data from a complete range of submissions to the National Institutes of Health and to the American Institute of Biological Sciences to bring awareness to two important issues with using IRR for assessing peer review quality. First, we demonstrate that estimating local IRR from subsets of restricted-quality proposals will likely result in zero estimates under many scenarios. In both data sets, we find that zero local IRR estimates are more likely when subsets of top-quality proposals rather than bottom-quality proposals are considered. However, zero estimates from range-restricted data should not be interpreted as indicating arbitrariness in peer review. On the contrary, despite different scoring scales used by the two agencies, when complete ranges of proposals are considered, IRR estimates are above 0.6 which indicates good reviewer agreement. Furthermore, we demonstrate that, with a small number of reviewers per proposal, zero estimates of IRR are possible even when the true value is not zero.},
  archive  = {J},
  author   = {Elena A. Erosheva and Patrícia Martinková and Carole J. Lee},
  doi      = {10.1111/rssa.12681},
  journal  = {Journal of the Royal Statistical Society: Series a},
  number   = {3},
  pages    = {904-919},
  title    = {When zero may not be zero: A cautionary note on the use of inter-rater reliability in evaluating grant peer review},
  volume   = {184},
  year     = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A simple framework to identify optimal cost-effective risk
thresholds for a single screen: Comparison to decision curve analysis.
<em>Journal of the Royal Statistical Society: Series A (Statistics in
Society)</em>, <em>184</em>(3), 887–903. (<a
href="https://doi.org/10.1111/rssa.12680">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Decision curve analysis (DCA) is a popular approach for assessing biomarkers and risk models, but does not require costs and thus cannot identify optimal risk thresholds for actions. Full decision analyses can identify optimal thresholds, but typically used methods are complex and often difficult to understand. We develop a simple framework to calculate the incremental net benefit for a single-time screen as a function of costs (for tests and treatments) and effectiveness (life-years gained). We provide simple expressions for the optimal cost-effective risk threshold and, equally importantly, for the monetary value of life-years gained associated with the risk threshold. We consider the controversy over the risk threshold to screen women for mutations in BRCA1/2 . Importantly, most, and sometimes even all, of the thresholds identified by DCA are infeasible based on their associated dollars per life-year gained. Our simple framework facilitates sensitivity analyses to cost and effectiveness parameters. The proposed approach estimates optimal risk thresholds in a simple and transparent manner, provides intuition about which quantities are critical, and may serve as a bridge between DCA and a full decision analysis.},
  archive  = {J},
  author   = {Hormuzd A. Katki and Ionut Bebu},
  doi      = {10.1111/rssa.12680},
  journal  = {Journal of the Royal Statistical Society: Series a},
  number   = {3},
  pages    = {887-903},
  title    = {A simple framework to identify optimal cost-effective risk thresholds for a single screen: Comparison to decision curve analysis},
  volume   = {184},
  year     = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The design of replication studies. <em>Journal of the Royal
Statistical Society: Series A (Statistics in Society)</em>,
<em>184</em>(3), 868–886. (<a
href="https://doi.org/10.1111/rssa.12688">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Empirical evaluations of replication have become increasingly common, but there has been no unified approach to doing so. Some evaluations conduct only a single replication study while others run several, usually across multiple laboratories. Designing such programs has largely contended with difficult issues about which experimental components are necessary for a set of studies to be considered replications. However, another important consideration is that replication studies be designed to support sufficiently sensitive analyses. For instance, if hypothesis tests are to be conducted about replication, studies should be designed to ensure these tests are well-powered; if not, it can be difficult to determine conclusively if replication attempts succeeded or failed. This paper describes methods for designing ensembles of replication studies to ensure that they are both adequately sensitive and cost-efficient. It describes two potential analyses of replication studies—hypothesis tests and variance component estimation—and approaches to obtaining optimal designs for them. Using these results, it assesses the statistical power, precision of point estimators and optimality of the design used by the Many Labs Project and finds that while it may have been sufficiently powered to detect some larger differences between studies, other designs would have been less costly and/or produced more precise estimates or higher-powered hypothesis tests.},
  archive  = {J},
  author   = {Larry V. Hedges and Jacob M. Schauer},
  doi      = {10.1111/rssa.12688},
  journal  = {Journal of the Royal Statistical Society: Series a},
  number   = {3},
  pages    = {868-886},
  title    = {The design of replication studies},
  volume   = {184},
  year     = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Modelling non-linear age-period-cohort effects and
covariates, with an application to english obesity 2001–2014.
<em>Journal of the Royal Statistical Society: Series A (Statistics in
Society)</em>, <em>184</em>(3), 842–867. (<a
href="https://doi.org/10.1111/rssa.12685">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {We develop an age-period-cohort model for repeated cross-section data with individual covariates, which identifies the non-linear effects of age, period and cohort. This is done for both continuous and binary dependent variables. The age, period and cohort effects in the model are represented by a parametrization with freely varying parameters that separates the identified non-linear effects and the unidentifiable linear effects. We develop a test of the parametrization against a more general ‘time-saturated’ model. The method is applied to analyse the obesity epidemic in England using survey data. The main non-linear effects we find in English obesity data are age-related among women and cohort-related among men.},
  archive  = {J},
  author   = {Zoë Fannon and Christiaan Monden and Bent Nielsen},
  doi      = {10.1111/rssa.12685},
  journal  = {Journal of the Royal Statistical Society: Series a},
  number   = {3},
  pages    = {842-867},
  title    = {Modelling non-linear age-period-cohort effects and covariates, with an application to english obesity 2001–2014},
  volume   = {184},
  year     = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Pension eligibility rules and the local causal effect of
retirement on cognitive functioning*. <em>Journal of the Royal
Statistical Society: Series A (Statistics in Society)</em>,
<em>184</em>(3), 812–841. (<a
href="https://doi.org/10.1111/rssa.12683">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {We propose an identification framework to evaluate the exclusion restriction in a fuzzy regression discontinuity setting, by adopting results from the literature on partial identification with invalid instrumental variables. With this framework, we provide new estimates of the effect of retirement on cognitive functioning and the first empirical analysis of the validity of an age-based instrumental variable for retirement. Point estimates suggest an insignificant negative effect of retirement on cognitive functioning. Partial identification regions qualify this finding by suggesting that if retirement is, in fact, detrimental for cognitive functioning, then large drops are unlikely. Second, data alone cannot identify the sign of the treatment effect. In fact, our results support improvements in cognitive functioning following retirement. The bounds analysis suggest that, when studying the impact of retirement, the validity of eligibility as an instrumental variable depends on the time period considered for the analysis and that violations of the exclusion restriction are likely already in very small intervals of 8 months around the cut-off in regression discontinuity designs.},
  archive  = {J},
  author   = {Eduardo Fé},
  doi      = {10.1111/rssa.12683},
  journal  = {Journal of the Royal Statistical Society: Series a},
  number   = {3},
  pages    = {812-841},
  title    = {Pension eligibility rules and the local causal effect of retirement on cognitive functioning*},
  volume   = {184},
  year     = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Removing the influence of group variables in
high-dimensional predictive modelling. <em>Journal of the Royal
Statistical Society: Series A (Statistics in Society)</em>,
<em>184</em>(3), 791–811. (<a
href="https://doi.org/10.1111/rssa.12613">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {In many application areas, predictive models are used to support or make important decisions. There is increasing awareness that these models may contain spurious or otherwise undesirable correlations. Such correlations may arise from a variety of sources, including batch effects, systematic measurement errors or sampling bias. Without explicit adjustment, machine learning algorithms trained using these data can produce out-of-sample predictions which propagate these undesirable correlations. We propose a method to pre-process the training data, producing an adjusted dataset that is statistically independent of the nuisance variables with minimum information loss. We develop a conceptually simple approach for creating an adjusted dataset in high-dimensional settings based on a constrained form of matrix decomposition. The resulting dataset can then be used in any predictive algorithm with the guarantee that predictions will be statistically independent of the nuisance variables. We develop a scalable algorithm for implementing the method, along with theory support in the form of independence guarantees and optimality. The method is illustrated on some simulation examples and applied to two case studies: removing machine-specific correlations from brain scan data, and removing ethnicity information from a dataset used to predict recidivism. That the motivation for removing undesirable correlations is quite different in the two applications illustrates the broad applicability of our approach.},
  archive  = {J},
  author   = {Emanuele Aliverti and Kristian Lum and James E. Johndrow and David B. Dunson},
  doi      = {10.1111/rssa.12613},
  journal  = {Journal of the Royal Statistical Society: Series a},
  number   = {3},
  pages    = {791-811},
  title    = {Removing the influence of group variables in high-dimensional predictive modelling},
  volume   = {184},
  year     = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Handbook of mixture analysis s. Frühwirth-schnatter, g.
Celeux and c.p. Robert, 2019. Chapman and hall/CRC handbooks of modern
statistical methods series, boca raton. 522 pp., 52.99 GBP. ISBN
978-0-367-732066. <em>Journal of the Royal Statistical Society: Series A
(Statistics in Society)</em>, <em>184</em>(2), 787–788. (<a
href="https://doi.org/10.1111/rssa.12673">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive = {J},
  author  = {Virgilio Gómez-Rubio},
  doi     = {10.1111/rssa.12673},
  journal = {Journal of the Royal Statistical Society: Series a},
  number  = {2},
  pages   = {787-788},
  title   = {Handbook of mixture analysis s. frühwirth-schnatter, g. celeux and C.P. robert, 2019. chapman and Hall/CRC handbooks of modern statistical methods series, boca raton. 522 pp., 52.99 GBP. ISBN 978-0-367-732066},
  volume  = {184},
  year    = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Tobias (toby) lewis 1918-2020. <em>Journal of the Royal
Statistical Society: Series A (Statistics in Society)</em>,
<em>184</em>(2), 784–786. (<a
href="https://doi.org/10.1111/rssa.12675">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive = {J},
  author  = {Vic Barnett and Kevin McConway},
  doi     = {10.1111/rssa.12675},
  journal = {Journal of the Royal Statistical Society: Series a},
  number  = {2},
  pages   = {784-786},
  title   = {Tobias (Toby) lewis 1918-2020},
  volume  = {184},
  year    = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Health aid, governance and infant mortality. <em>Journal of
the Royal Statistical Society: Series A (Statistics in Society)</em>,
<em>184</em>(2), 761–783. (<a
href="https://doi.org/10.1111/rssa.12679">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {We investigate the impact of health aid on infant mortality conditional on the quality of governance. Our analysis applies instrumental variable estimation with health aid instrumented by donor government fractionalization interacted with the probability of allocating health aid to a recipient country. Using panel data for 96 recipient countries for the 2002–2015 period, we find that the effectiveness of health aid in reducing infant mortality is conditional on good governance. The results are robust in a variety of ways. Our findings reaffirm the importance of improving the quality of governance in recipient countries.},
  archive  = {J},
  author   = {Chris Doucouliagos and Jack Hennessy and Debdulal Mallick},
  doi      = {10.1111/rssa.12679},
  journal  = {Journal of the Royal Statistical Society: Series a},
  number   = {2},
  pages    = {761-783},
  title    = {Health aid, governance and infant mortality},
  volume   = {184},
  year     = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Missing, presumed different: Quantifying the risk of
attrition bias in education evaluations. <em>Journal of the Royal
Statistical Society: Series A (Statistics in Society)</em>,
<em>184</em>(2), 732–760. (<a
href="https://doi.org/10.1111/rssa.12677">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {We estimate the magnitude of attrition bias for 10 randomized controlled trials (RCTs) in education. We make use of a unique feature of administrative school data in England that allows us to analyse post-test academic outcomes for nearly all students, including those who originally dropped out of the RCTs we analyse. We find that the typical magnitude of attrition bias is 0.015 effect size units (ES), with no estimate greater than 0.034 ES. This suggests that, in practice, the risk of attrition bias is limited. However, this risk should not be ignored as we find some evidence against the common ‘Missing At Random’ assumption. Attrition appears to be more problematic for treated units. We recommend that researchers incorporate uncertainty due to attrition bias, as well as performing sensitivity analyses based on the types of attrition mechanisms that are observed in practice.},
  archive  = {J},
  author   = {Ben Weidmann and Luke Miratrix},
  doi      = {10.1111/rssa.12677},
  journal  = {Journal of the Royal Statistical Society: Series a},
  number   = {2},
  pages    = {732-760},
  title    = {Missing, presumed different: Quantifying the risk of attrition bias in education evaluations},
  volume   = {184},
  year     = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The effect of the brexit referendum result on subjective
well-being*. <em>Journal of the Royal Statistical Society: Series A
(Statistics in Society)</em>, <em>184</em>(2), 707–731. (<a
href="https://doi.org/10.1111/rssa.12676">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {We study the effect of the Brexit referendum result on subjective well-being in the United Kingdom. Using a quasi-experimental design, we find that the referendum’s outcome led to an overall decrease in subjective well-being in the United Kingdom compared to a control group. The effect is driven by individuals who hold an overall positive image of the European Union and shows little signs of adaptation during the Brexit transition period. Economic expectations are potential mechanisms of this effect.},
  archive  = {J},
  author   = {Georgios Kavetsos and Ichiro Kawachi and Ilias Kyriopoulos and Sotiris Vandoros},
  doi      = {10.1111/rssa.12676},
  journal  = {Journal of the Royal Statistical Society: Series a},
  number   = {2},
  pages    = {707-731},
  title    = {The effect of the brexit referendum result on subjective well-being*},
  volume   = {184},
  year     = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Nowcasting monthly GDP with big data: A model averaging
approach. <em>Journal of the Royal Statistical Society: Series A
(Statistics in Society)</em>, <em>184</em>(2), 683–706. (<a
href="https://doi.org/10.1111/rssa.12645">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Gross domestic product (GDP) is the most comprehensive and authoritative measure of economic activity. The macroeconomic literature has focused on nowcasting and forecasting this measure at the monthly frequency, using related high-frequency indicators. We address the issue of estimating monthly GDP using a large-dimensional set of monthly indicators, by pooling the disaggregate estimates arising from simple and feasible bivariate models that consider one indicator at a time in conjunction to GDP. Our base model handles mixed-frequency data and ragged-edge data structure with any pattern of missingness. Our methodology enables to distil the common component of the available economic indicators, so that the monthly GDP estimates arise from the projection of the quarterly figures on the space spanned by the common component. The weights used for the combination reflect the ability to nowcast quarterly GDP and are obtained as a function of the regularized estimator of the high-dimensional covariance matrix of the nowcasting errors. A recursive nowcasting and forecasting experiment with data on euro area GDP illustrates that the optimal weights adapt to the information set available in real time and vary according to the phase of the business cycle.},
  archive  = {J},
  author   = {Tommaso Proietti and Alessandro Giovannelli},
  doi      = {10.1111/rssa.12645},
  journal  = {Journal of the Royal Statistical Society: Series a},
  number   = {2},
  pages    = {683-706},
  title    = {Nowcasting monthly GDP with big data: A model averaging approach},
  volume   = {184},
  year     = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Exploiting new forms of data to study the private rented
sector: Strengths and limitations of a database of rental listings.
<em>Journal of the Royal Statistical Society: Series A (Statistics in
Society)</em>, <em>184</em>(2), 663–682. (<a
href="https://doi.org/10.1111/rssa.12643">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Reviews of official statistics for UK housing have noted that developments have not kept pace with real-world change, particularly the rapid growth of private renting. This paper examines the potential value of big data in this context. We report on the construction of a dataset from the on-line adverts of one national lettings agency, describing the content of the dataset and efforts to validate it against external sources. The paper specifically examines what these data might add to our understanding of changing volumes and rents in the private rented sector. Fluctuations in market share across advertising platforms make assessment of volume problematic, while rental prices appear more robust through comparison with other reference information. Focussing on one urban area, we illustrate how the dataset can shed new light on local changes. Lastly, we discuss the issues involved in making more routine use of this kind of data.},
  archive  = {J},
  author   = {Mark Livingston and Francesca Pannullo and Adrian W. Bowman and E. Marian Scott and Nick Bailey},
  doi      = {10.1111/rssa.12643},
  journal  = {Journal of the Royal Statistical Society: Series a},
  number   = {2},
  pages    = {663-682},
  title    = {Exploiting new forms of data to study the private rented sector: Strengths and limitations of a database of rental listings},
  volume   = {184},
  year     = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Leveraging auxiliary information on marginal distributions
in nonignorable models for item and unit nonresponse. <em>Journal of the
Royal Statistical Society: Series A (Statistics in Society)</em>,
<em>184</em>(2), 643–662. (<a
href="https://doi.org/10.1111/rssa.12635">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Often, government agencies and survey organizations know the population counts or percentages for some of the variables in a survey. These may be available from auxiliary sources, for example administrative databases or other high-quality surveys. We present and illustrate a model-based framework for leveraging such auxiliary marginal information when handling unit and item nonresponse. We show how one can use the margins to specify different missingness mechanisms for each type of nonresponse. We use the framework to impute missing values in voter turnout in a subset of data from the US Current Population Survey. In doing so, we examine the sensitivity of results to different assumptions about the unit and item nonresponse.},
  archive  = {J},
  author   = {Olanrewaju Akande and Gabriel Madson and D. Sunshine Hillygus and Jerome P. Reiter},
  doi      = {10.1111/rssa.12635},
  journal  = {Journal of the Royal Statistical Society: Series a},
  number   = {2},
  pages    = {643-662},
  title    = {Leveraging auxiliary information on marginal distributions in nonignorable models for item and unit nonresponse},
  volume   = {184},
  year     = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A seasonal dynamic measurement model for summer learning
loss. <em>Journal of the Royal Statistical Society: Series A (Statistics
in Society)</em>, <em>184</em>(2), 616–642. (<a
href="https://doi.org/10.1111/rssa.12634">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Research conducted in US schools shows summer learning loss in test scores. If this summer loss is not incorporated into models of student ability growth, assumptions will be violated because fall scores will be overestimated and spring scores will be underestimated, which can be particularly problematic when evaluating teacher or school effectiveness. Statistical methods for summer loss have remained relatively undeveloped and often rely on lagged-time or piecewise models, which commonly saturate the mean structure and become reparameterizations of empirical means. Compound polynomial models have recently been introduced and simultaneously model within-year and between-year growth processes in test scores. However, these models operate with polynomial functions of time, which can have limited interpretative utility. In this article, we propose incorporating seasonality within the dynamic measurement modelling (DMM) framework. DMM reparametrizes non-linear growth models to directly estimate interpretable quantities (e.g. learning capacity as an upper asymptote on growth). Borrowing from ecological models proposed for body mass of cold-climate species, we show how DMM can incorporate seasonality to provide more interpretable parameters as well as to explicitly include summer learning loss as a parameter in the model.},
  archive  = {J},
  author   = {Daniel McNeish and Denis Dumas},
  doi      = {10.1111/rssa.12634},
  journal  = {Journal of the Royal Statistical Society: Series a},
  number   = {2},
  pages    = {616-642},
  title    = {A seasonal dynamic measurement model for summer learning loss},
  volume   = {184},
  year     = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Consistent aggregation with superlative and other price
indices. <em>Journal of the Royal Statistical Society: Series A
(Statistics in Society)</em>, <em>184</em>(2), 589–615. (<a
href="https://doi.org/10.1111/rssa.12633">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Various fields of economic analysis (e.g. growth and productivity) and economic policy (e.g. monetary and social policy) rely on accurate measures of price change. Unfortunately, the price index formulae that most price statisticians consider as particularly accurate—the superlative indices of Fisher, Törnqvist, and Walsh—are believed to violate the property of consistency in aggregation. This property, however, is indispensable for economic studies that attempt to disaggregate the overall result into the contributions of individual entities such as sectors of the economy or groups of products. The present paper introduces a thoroughly motivated formal definition of consistency in aggregation and proves that, contrary to general perception, the three superlative price indices can be considered as consistent in aggregation. Furthermore, many other price indices are shown to be consistent in aggregation. The theoretical findings are applied to the Swedish consumer price index.},
  archive  = {J},
  author   = {Ludwig von Auer and Jochen Wengenroth},
  doi      = {10.1111/rssa.12633},
  journal  = {Journal of the Royal Statistical Society: Series a},
  number   = {2},
  pages    = {589-615},
  title    = {Consistent aggregation with superlative and other price indices},
  volume   = {184},
  year     = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Proxy expenditure weights for consumer price index: Audit
sampling inference for big-data statistics. <em>Journal of the Royal
Statistical Society: Series A (Statistics in Society)</em>,
<em>184</em>(2), 571–588. (<a
href="https://doi.org/10.1111/rssa.12632">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Purchase data from retail chains can provide proxy measures of private household expenditure on items that are the most troublesome to collect in the traditional expenditure survey. Due to the inevitable coverage and selection errors, bias must exist in these proxy measures. Moreover, given the sheer amount of data, the bias completely dominates the variance. To investigate the potential of replacing costly and burdensome surveys by non-survey big-data sources, we propose an audit sampling inference approach, which does not require linking the audit sample and the big-data source at the individual level. It turns out that one is unable to reject a null hypothesis of unbiased big-data estimation at the chosen size, because the audit sampling variance is too large compared to the bias of the big-data estimate. For the same reason, audit sampling fails to yield a meaningful mean squared error estimate. We propose a novel accuracy measure that is generally applicable in such situations. This can provide a necessary part of the statistical argument for the uptake of non-survey big-data sources, in replacement of traditional survey sampling. An application to disaggregated food price indices is used to demonstrate the proposed approach.},
  archive  = {J},
  author   = {Li-Chun Zhang},
  doi      = {10.1111/rssa.12632},
  journal  = {Journal of the Royal Statistical Society: Series a},
  number   = {2},
  pages    = {571-588},
  title    = {Proxy expenditure weights for consumer price index: Audit sampling inference for big-data statistics},
  volume   = {184},
  year     = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Quantifying longevity gaps using micro-level lifetime data.
<em>Journal of the Royal Statistical Society: Series A (Statistics in
Society)</em>, <em>184</em>(2), 548–570. (<a
href="https://doi.org/10.1111/rssa.12631">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Using flexible Poisson regressions, we analyse a huge micro-level lifetime dataset from a Dutch pension fund, including categorical, continuous and spatial risk factors collected on participants in the fund. The availability of granular lifetime data allows us to quantify the longevity gap between the national population and the fund on the one hand, and between participants within the fund on the other hand. We identify the most important risk factors using statistical criteria that measure the in- and out-of-sample performance of the regression models. We evaluate the financial performance of the models by introducing a novel type of backtest, which selects the risk factors that contribute most to an accurate prediction of future pension liabilities. For this portfolio, the most relevant risk factors (next to age and gender) are the salary, the time spent in disability and working at irregular hours. The resulting personalized mortality risk profiles show substantial differences between the remaining life expectancies for the most-favourable and least-favourable risk profiles. Our method to estimate these longevity gaps will help policymakers to assess wanted and unwanted consequences of longevity risk sharing in pension schemes.},
  archive  = {J},
  author   = {Frank van Berkum and Katrien Antonio and Michel Vellekoop},
  doi      = {10.1111/rssa.12631},
  journal  = {Journal of the Royal Statistical Society: Series a},
  number   = {2},
  pages    = {548-570},
  title    = {Quantifying longevity gaps using micro-level lifetime data},
  volume   = {184},
  year     = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Linkage-data linear regression. <em>Journal of the Royal
Statistical Society: Series A (Statistics in Society)</em>,
<em>184</em>(2), 522–547. (<a
href="https://doi.org/10.1111/rssa.12630">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Data linkage is increasingly being used to combine data from different sources with the aim of identifying and bringing together records from separate files, which correspond to the same entities. Usually, data linkage is not a trivial procedure and linkage errors, false and missed links, are unavoidable. In these cases, standard statistical techniques may produce misleading inference. In this paper, we propose a method for secondary linear regression analysis, where the linked data have to be prepared by someone else, and neither the match-key variables nor the unlinked records are available to the analyst. We develop also a diagnostic test for the assumption of non-informative linkage errors, which is required for all existing secondary analysis adjustment methods. Our approach provides important advantages: it relies on the realistic assumption that the probabilities of correct linkage vary across the records but it does not assume that one is able to estimate the probability of correct linkage for each individual record. Moreover, it accommodates in a simple manner the general situation where the files are of different sizes and none of them is a subset of another. The proposed methodology of adjustment and testing is studied by simulation and applied to real data.},
  archive  = {J},
  author   = {Li-Chun Zhang and Tiziana Tuoto},
  doi      = {10.1111/rssa.12630},
  journal  = {Journal of the Royal Statistical Society: Series a},
  number   = {2},
  pages    = {522-547},
  title    = {Linkage-data linear regression},
  volume   = {184},
  year     = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Beyond generalization of the ATE: Designing randomized
trials to understand treatment effect heterogeneity. <em>Journal of the
Royal Statistical Society: Series A (Statistics in Society)</em>,
<em>184</em>(2), 504–521. (<a
href="https://doi.org/10.1111/rssa.12629">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Researchers conducting randomized trials have increasingly shifted focus from the average treatment effect to understanding moderators of treatment effects. Current methods for exploring moderation focus on model selection and hypothesis tests. At the same time, recent developments in the design of randomized trials have argued for the need for population-based recruitment in order to generalize well. In this paper, we show that a different population-based recruitment strategy can be implemented to increase the precision of estimates of treatment effect moderators, and we explore the trade-offs between optimal designs for the average treatment effect and moderator effects.},
  archive  = {J},
  author   = {Elizabeth Tipton},
  doi      = {10.1111/rssa.12629},
  journal  = {Journal of the Royal Statistical Society: Series a},
  number   = {2},
  pages    = {504-521},
  title    = {Beyond generalization of the ATE: Designing randomized trials to understand treatment effect heterogeneity},
  volume   = {184},
  year     = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Estimating event-rates from unreliable historical records.
<em>Journal of the Royal Statistical Society: Series A (Statistics in
Society)</em>, <em>184</em>(2), 494–503. (<a
href="https://doi.org/10.1111/rssa.12625">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {It is natural, when contemplating an historical record of events, to base a simple estimator of the event-rate on that recent part of the record where the recording probability is thought to be effectively 1. After all, this avoids the downward bias which would be incurred by ‘overshooting’ into a time where the recording probability was less than 1. However, there is a trade-off, because overshooting also decreases the variance of the event-rate estimator. In fact, it is always beneficial to overshoot, measured in terms of the risk of the estimator. Perhaps surprisingly, the beneficial overshoot can often be large. This paper provides these theoretical results, along with some illustrations.},
  archive  = {J},
  author   = {Jonathan Rougier},
  doi      = {10.1111/rssa.12625},
  journal  = {Journal of the Royal Statistical Society: Series a},
  number   = {2},
  pages    = {494-503},
  title    = {Estimating event-rates from unreliable historical records},
  volume   = {184},
  year     = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Sample size determination for risk-based tax auditing.
<em>Journal of the Royal Statistical Society: Series A (Statistics in
Society)</em>, <em>184</em>(2), 479–493. (<a
href="https://doi.org/10.1111/rssa.12618">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {A modern system of Revenue Administration requires an effective and efficient management of compliance which in turn requires a well-designed taxpayers audit strategy. The selection of taxpayers to be audited by Revenue Authorities is a non-standard sample size determination problem, involving an initial random sample from the population and, based on the statistical information derived from it, a risk-based auditing scheme whose sole objective is to select for auditing the taxpayers with the highest estimated risk in the population. This paper provides a methodological approach that estimates the initial optimal random sample size such that the Revenue Administration Authority maximises their expected tax revenues. The methodology is illustrated using administrative data from the UK’s Revenue Authority, Her Majesty’s Revenue and Customs (HMRC).},
  archive  = {J},
  author   = {Petros Dellaportas and Evangelos Ioannidis and Christos Kotsogiannis},
  doi      = {10.1111/rssa.12618},
  journal  = {Journal of the Royal Statistical Society: Series a},
  number   = {2},
  pages    = {479-493},
  title    = {Sample size determination for risk-based tax auditing},
  volume   = {184},
  year     = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Author’s reply to the discussion of “testing by betting: A
strategy for statistical and scientific communication” by glenn shafer.
<em>Journal of the Royal Statistical Society: Series A (Statistics in
Society)</em>, <em>184</em>(2), 466–478. (<a
href="https://doi.org/10.1111/rssa.12672">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive = {J},
  author  = {Glenn Shafer},
  doi     = {10.1111/rssa.12672},
  journal = {Journal of the Royal Statistical Society: Series a},
  number  = {2},
  pages   = {466-478},
  title   = {Author&#39;s reply to the discussion of ‘Testing by betting: A strategy for statistical and scientific communication’ by glenn shafer},
  volume  = {184},
  year    = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Priyantha wijayatunga’s contribution to the discussion of
“testing by betting: A strategy for statistical and scientific
communication” by glenn shafer. <em>Journal of the Royal Statistical
Society: Series A (Statistics in Society)</em>, <em>184</em>(2),
465–466. (<a href="https://doi.org/10.1111/rssa.12670">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive = {J},
  author  = {Priyantha Wijayatunga},
  doi     = {10.1111/rssa.12670},
  journal = {Journal of the Royal Statistical Society: Series a},
  number  = {2},
  pages   = {465-466},
  title   = {Priyantha wijayatunga’s contribution to the discussion of ‘Testing by betting: A strategy for statistical and scientific communication’ by glenn shafer},
  volume  = {184},
  year    = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Ruodu wang’s contribution to the discussion of “testing by
betting: A strategy for statistical and scientific communication” by
glenn shafer. <em>Journal of the Royal Statistical Society: Series A
(Statistics in Society)</em>, <em>184</em>(2), 463–464. (<a
href="https://doi.org/10.1111/rssa.12669">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive = {J},
  author  = {Ruodu Wang},
  doi     = {10.1111/rssa.12669},
  journal = {Journal of the Royal Statistical Society: Series a},
  number  = {2},
  pages   = {463-464},
  title   = {Ruodu wang’s contribution to the discussion of ‘Testing by betting: A strategy for statistical and scientific communication’ by glenn shafer},
  volume  = {184},
  year    = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Paul vos’s contribution to the discussion of “testing by
betting: A strategy for statistical and scientific communication” by
glenn shafer. <em>Journal of the Royal Statistical Society: Series A
(Statistics in Society)</em>, <em>184</em>(2), 461–462. (<a
href="https://doi.org/10.1111/rssa.12668">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive = {J},
  author  = {Paul Vos},
  doi     = {10.1111/rssa.12668},
  journal = {Journal of the Royal Statistical Society: Series a},
  number  = {2},
  pages   = {461-462},
  title   = {Paul vos’s contribution to the discussion of ‘Testing by betting: A strategy for statistical and scientific communication’ by glenn shafer},
  volume  = {184},
  year    = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Judith ter schure’s contribution to the discussion of
“testing by betting: A strategy for statistical and scientific
communication” by glenn shafer. <em>Journal of the Royal Statistical
Society: Series A (Statistics in Society)</em>, <em>184</em>(2),
460–461. (<a href="https://doi.org/10.1111/rssa.12667">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive = {J},
  author  = {Judith ter Schure},
  doi     = {10.1111/rssa.12667},
  journal = {Journal of the Royal Statistical Society: Series a},
  number  = {2},
  pages   = {460-461},
  title   = {Judith ter schure’s contribution to the discussion of ‘Testing by betting: A strategy for statistical and scientific communication’ by glenn shafer},
  volume  = {184},
  year    = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Stephen senn’s contribution to the discussion of “testing by
betting: A strategy for statistical and scientific communication” by
glenn shafer. <em>Journal of the Royal Statistical Society: Series A
(Statistics in Society)</em>, <em>184</em>(2), 459–460. (<a
href="https://doi.org/10.1111/rssa.12666">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive = {J},
  author  = {Stephen Senn},
  doi     = {10.1111/rssa.12666},
  journal = {Journal of the Royal Statistical Society: Series a},
  number  = {2},
  pages   = {459-460},
  title   = {Stephen senn’s contribution to the discussion of ‘Testing by betting: A strategy for statistical and scientific communication’ by glenn shafer},
  volume  = {184},
  year    = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Jorge mateu’s contribution to the discussion of “testing by
betting: A strategy for statistical and scientific communication” by
glenn shafer. <em>Journal of the Royal Statistical Society: Series A
(Statistics in Society)</em>, <em>184</em>(2), 458. (<a
href="https://doi.org/10.1111/rssa.12664">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive = {J},
  author  = {Jorge Mateu},
  doi     = {10.1111/rssa.12664},
  journal = {Journal of the Royal Statistical Society: Series a},
  number  = {2},
  pages   = {458},
  title   = {Jorge mateu’s contribution to the discussion of ‘Testing by betting: A strategy for statistical and scientific communication’ by glenn shafer},
  volume  = {184},
  year    = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Ryan martin’s contribution to the discussion of “testing by
betting: A strategy for statistical and scientific communication” by
glenn shafer. <em>Journal of the Royal Statistical Society: Series A
(Statistics in Society)</em>, <em>184</em>(2), 456–457. (<a
href="https://doi.org/10.1111/rssa.12665">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive = {J},
  author  = {Ryan Martin},
  doi     = {10.1111/rssa.12665},
  journal = {Journal of the Royal Statistical Society: Series a},
  number  = {2},
  pages   = {456-457},
  title   = {Ryan martin’s contribution to the discussion of ‘Testing by betting: A strategy for statistical and scientific communication’ by glenn shafer},
  volume  = {184},
  year    = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Nick longford’s contribution to the discussion of “testing
by betting: A strategy for statistical and scientific communication” by
glenn shafer. <em>Journal of the Royal Statistical Society: Series A
(Statistics in Society)</em>, <em>184</em>(2), 455–456. (<a
href="https://doi.org/10.1111/rssa.12663">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive = {J},
  author  = {Nick Longford},
  doi     = {10.1111/rssa.12663},
  journal = {Journal of the Royal Statistical Society: Series a},
  number  = {2},
  pages   = {455-456},
  title   = {Nick longford’s contribution to the discussion of ‘Testing by betting: A strategy for statistical and scientific communication’ by glenn shafer},
  volume  = {184},
  year    = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Tze leung lai and anna choi’s contribution to the discussion
of “testing by betting: A strategy for statistical and scientific
communication” by glenn shafer. <em>Journal of the Royal Statistical
Society: Series A (Statistics in Society)</em>, <em>184</em>(2),
454–455. (<a href="https://doi.org/10.1111/rssa.12662">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive = {J},
  author  = {Tze Leung Lai and Anna Choi},
  doi     = {10.1111/rssa.12662},
  journal = {Journal of the Royal Statistical Society: Series a},
  number  = {2},
  pages   = {454-455},
  title   = {Tze leung lai and anna choi&#39;s contribution to the discussion of ‘Testing by betting: A strategy for statistical and scientific communication’ by glenn shafer},
  volume  = {184},
  year    = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021c). Kuldeep kumar’s contribution to the discussion of “testing
by betting: A strategy for statistical and scientific communication” by
glenn shafer. <em>Journal of the Royal Statistical Society: Series A
(Statistics in Society)</em>, <em>184</em>(2), 453–454. (<a
href="https://doi.org/10.1111/rssa.12661">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive = {J},
  author  = {Kuldeep Kumar},
  doi     = {10.1111/rssa.12661},
  journal = {Journal of the Royal Statistical Society: Series a},
  number  = {2},
  pages   = {453-454},
  title   = {Kuldeep kumar’s contribution to the discussion of ‘Testing by betting: A strategy for statistical and scientific communication’ by glenn shafer},
  volume  = {184},
  year    = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Chloe krakauer and kenneth rice’s contribution to the
discussion of “testing by betting: A strategy for statistical and
scientific communication” by glenn shafer. <em>Journal of the Royal
Statistical Society: Series A (Statistics in Society)</em>,
<em>184</em>(2), 452–453. (<a
href="https://doi.org/10.1111/rssa.12660">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive = {J},
  author  = {Chloe Krakauer and Kenneth Rice},
  doi     = {10.1111/rssa.12660},
  journal = {Journal of the Royal Statistical Society: Series a},
  number  = {2},
  pages   = {452-453},
  title   = {Chloe krakauer and kenneth rice’s contribution to the discussion of ‘Testing by betting: A strategy for statistical and scientific communication’ by glenn shafer},
  volume  = {184},
  year    = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Sander greenland’s contribution to the discussion of
“testing by betting: A strategy for statistical and scientific
communication” by glenn shafer. <em>Journal of the Royal Statistical
Society: Series A (Statistics in Society)</em>, <em>184</em>(2),
450–451. (<a href="https://doi.org/10.1111/rssa.12659">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive = {J},
  author  = {Sander Greenland},
  doi     = {10.1111/rssa.12659},
  journal = {Journal of the Royal Statistical Society: Series a},
  number  = {2},
  pages   = {450-451},
  title   = {Sander greenland’s contribution to the discussion of ‘Testing by betting: A strategy for statistical and scientific communication’ by glenn shafer},
  volume  = {184},
  year    = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Christine p. Chai’s contribution to the discussion of
“testing by betting: A strategy for statistical and scientific
communication” by glenn shafer. <em>Journal of the Royal Statistical
Society: Series A (Statistics in Society)</em>, <em>184</em>(2),
449–450. (<a href="https://doi.org/10.1111/rssa.12658">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive = {J},
  author  = {Christine P. Chai},
  doi     = {10.1111/rssa.12658},
  journal = {Journal of the Royal Statistical Society: Series a},
  number  = {2},
  pages   = {449-450},
  title   = {Christine p. chai’s contribution to the discussion of ‘Testing by betting: A strategy for statistical and scientific communication’ by glenn shafer},
  volume  = {184},
  year    = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A distillation of the live chat during the discussion of
“testing by betting: A strategy for statistical and scientific
communication” by glenn shafer. <em>Journal of the Royal Statistical
Society: Series A (Statistics in Society)</em>, <em>184</em>(2), 448.
(<a href="https://doi.org/10.1111/rssa.12671">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive = {J},
  author  = {Paul A. Smith},
  doi     = {10.1111/rssa.12671},
  journal = {Journal of the Royal Statistical Society: Series a},
  number  = {2},
  pages   = {448},
  title   = {A distillation of the live chat during the discussion of ‘Testing by betting: A strategy for statistical and scientific communication’ by glenn shafer},
  volume  = {184},
  year    = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Christian hennig’s contribution to the discussion of
“testing by betting: A strategy for statistical and scientific
communication” by glenn shafer. <em>Journal of the Royal Statistical
Society: Series A (Statistics in Society)</em>, <em>184</em>(2),
446–447. (<a href="https://doi.org/10.1111/rssa.12657">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive = {J},
  author  = {Christian Hennig},
  doi     = {10.1111/rssa.12657},
  journal = {Journal of the Royal Statistical Society: Series a},
  number  = {2},
  pages   = {446-447},
  title   = {Christian hennig’s contribution to the discussion of ‘Testing by betting: A strategy for statistical and scientific communication’ by glenn shafer},
  volume  = {184},
  year    = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Vladimir vovk’s contribution to the discussion of “testing
by betting: A strategy for statistical and scientific communication” by
glenn shafer. <em>Journal of the Royal Statistical Society: Series A
(Statistics in Society)</em>, <em>184</em>(2), 445–446. (<a
href="https://doi.org/10.1111/rssa.12656">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive = {J},
  author  = {Vladimir Vovk},
  doi     = {10.1111/rssa.12656},
  journal = {Journal of the Royal Statistical Society: Series a},
  number  = {2},
  pages   = {445-446},
  title   = {Vladimir vovk’s contribution to the discussion of ‘Testing by betting: A strategy for statistical and scientific communication’ by glenn shafer},
  volume  = {184},
  year    = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Arthur paul pedersen’s contribution to the discussion of
“testing by betting: A strategy for statistical and scientific
communication” by glenn shafer. <em>Journal of the Royal Statistical
Society: Series A (Statistics in Society)</em>, <em>184</em>(2),
443–444. (<a href="https://doi.org/10.1111/rssa.12655">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive = {J},
  author  = {Arthur Paul Pedersen},
  doi     = {10.1111/rssa.12655},
  journal = {Journal of the Royal Statistical Society: Series a},
  number  = {2},
  pages   = {443-444},
  title   = {Arthur paul pedersen’s contribution to the discussion of ‘Testing by betting: A strategy for statistical and scientific communication’ by glenn shafer},
  volume  = {184},
  year    = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Xiao-li meng’s contribution to the discussion of “testing
by betting: A strategy for statistical and scientific communication” by
glenn shafer. <em>Journal of the Royal Statistical Society: Series A
(Statistics in Society)</em>, <em>184</em>(2), 442–443. (<a
href="https://doi.org/10.1111/rssa.12654">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive = {J},
  author  = {Xiao-Li Meng},
  doi     = {10.1111/rssa.12654},
  journal = {Journal of the Royal Statistical Society: Series a},
  number  = {2},
  pages   = {442-443},
  title   = {Xiao-li meng’s contribution to the discussion of ‘Testing by betting: A strategy for statistical and scientific communication’ by glenn shafer},
  volume  = {184},
  year    = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Peter d. Grünwald’s contribution to the discussion of
“testing by betting: A strategy for statistical and scientific
communication” by glenn shafer. <em>Journal of the Royal Statistical
Society: Series A (Statistics in Society)</em>, <em>184</em>(2),
440–441. (<a href="https://doi.org/10.1111/rssa.12653">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive = {J},
  author  = {Peter D. Grünwald},
  doi     = {10.1111/rssa.12653},
  journal = {Journal of the Royal Statistical Society: Series a},
  number  = {2},
  pages   = {440-441},
  title   = {Peter d. grünwald’s contribution to the discussion of ‘Testing by betting: A strategy for statistical and scientific communication’ by glenn shafer},
  volume  = {184},
  year    = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Aaditya ramdas’s contribution to the discussion of “testing
by betting: A strategy for statistical and scientific communication” by
glenn shafer. <em>Journal of the Royal Statistical Society: Series A
(Statistics in Society)</em>, <em>184</em>(2), 438–440. (<a
href="https://doi.org/10.1111/rssa.12652">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive = {J},
  author  = {Aaditya Ramdas},
  doi     = {10.1111/rssa.12652},
  journal = {Journal of the Royal Statistical Society: Series a},
  number  = {2},
  pages   = {438-440},
  title   = {Aaditya ramdas’s contribution to the discussion of ‘Testing by betting: A strategy for statistical and scientific communication’ by glenn shafer},
  volume  = {184},
  year    = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Barbara osimani’s contribution to the discussion of “testing
by betting: A strategy for statistical and scientific communication” by
glenn shafer. <em>Journal of the Royal Statistical Society: Series A
(Statistics in Society)</em>, <em>184</em>(2), 437–438. (<a
href="https://doi.org/10.1111/rssa.12651">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive = {J},
  author  = {Barbara Osimani},
  doi     = {10.1111/rssa.12651},
  journal = {Journal of the Royal Statistical Society: Series a},
  number  = {2},
  pages   = {437-438},
  title   = {Barbara osimani’s contribution to the discussion of ‘Testing by betting: A strategy for statistical and scientific communication’ by glenn shafer},
  volume  = {184},
  year    = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Harry crane’s contribution to the discussion of “testing by
betting: A strategy for statistical and scientific communication” by
glenn shafer. <em>Journal of the Royal Statistical Society: Series A
(Statistics in Society)</em>, <em>184</em>(2), 436–437. (<a
href="https://doi.org/10.1111/rssa.12650">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive = {J},
  author  = {Harry Crane},
  doi     = {10.1111/rssa.12650},
  journal = {Journal of the Royal Statistical Society: Series a},
  number  = {2},
  pages   = {436-437},
  title   = {Harry crane’s contribution to the discussion of ‘Testing by betting: A strategy for statistical and scientific communication’ by glenn shafer},
  volume  = {184},
  year    = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Seconder of the vote of thanks to glenn shafer and
contribution to the discussion of “testing by betting: A strategy for
statistical and scientific communication.” <em>Journal of the Royal
Statistical Society: Series A (Statistics in Society)</em>,
<em>184</em>(2), 434–435. (<a
href="https://doi.org/10.1111/rssa.12649">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive = {J},
  author  = {Frank P. A. Coolen},
  doi     = {10.1111/rssa.12649},
  journal = {Journal of the Royal Statistical Society: Series a},
  number  = {2},
  pages   = {434-435},
  title   = {Seconder of the vote of thanks to glenn shafer and contribution to the discussion of ‘Testing by betting: A strategy for statistical and scientific communication’},
  volume  = {184},
  year    = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Proposer of the vote of thanks to glenn shafer and
contribution to the discussion of “testing by betting: A strategy for
statistical and scientific communication.” <em>Journal of the Royal
Statistical Society: Series A (Statistics in Society)</em>,
<em>184</em>(2), 432–433. (<a
href="https://doi.org/10.1111/rssa.12648">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive = {J},
  author  = {Philip Dawid},
  doi     = {10.1111/rssa.12648},
  journal = {Journal of the Royal Statistical Society: Series a},
  number  = {2},
  pages   = {432-433},
  title   = {Proposer of the vote of thanks to glenn shafer and contribution to the discussion of ‘Testing by betting: A strategy for statistical and scientific communication’},
  volume  = {184},
  year    = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Testing by betting: A strategy for statistical and
scientific communication. <em>Journal of the Royal Statistical Society:
Series A (Statistics in Society)</em>, <em>184</em>(2), 407–431. (<a
href="https://doi.org/10.1111/rssa.12647">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {The most widely used concept of statistical inference—the p -value—is too complicated for effective communication to a wide audience. This paper introduces a simpler way of reporting statistical evidence: report the outcome of a bet against the null hypothesis. This leads to a new role for likelihood, to alternatives to power and confidence, and to a framework for meta-analysis that accommodates both planned and opportunistic testing of statistical hypotheses and probabilistic forecasts. This framework builds on the foundation for mathematical probability developed in previous work by Vladimir Vovk and myself.},
  archive  = {J},
  author   = {Glenn Shafer},
  doi      = {10.1111/rssa.12647},
  journal  = {Journal of the Royal Statistical Society: Series a},
  number   = {2},
  pages    = {407-431},
  title    = {Testing by betting: A strategy for statistical and scientific communication},
  volume   = {184},
  year     = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Handbook of financial risk management t. Roncalli, 2020.
Chapman and hall/CRC financial mathematics series, boca raton. 1142 pp.,
230.00 GBP. ISBN 978-1-138-50187-4. <em>Journal of the Royal Statistical
Society: Series A (Statistics in Society)</em>, <em>184</em>(1),
402–403. (<a href="https://doi.org/10.1111/rssa.12641">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive = {J},
  author  = {Sebastian Dietz},
  doi     = {10.1111/rssa.12641},
  journal = {Journal of the Royal Statistical Society: Series a},
  number  = {1},
  pages   = {402-403},
  title   = {Handbook of financial risk management t. roncalli, 2020. chapman and Hall/CRC financial mathematics series, boca raton. 1142 pp., 230.00 GBP. ISBN 978-1-138-50187-4},
  volume  = {184},
  year    = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). <em>Journal of the Royal Statistical Society: Series A
(Statistics in Society)</em>, <em>184</em>(1), 401. (<a
href="https://doi.org/10.1111/rssa.12637">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive = {J},
  author  = {Kuldeep Kumar},
  doi     = {10.1111/rssa.12637},
  journal = {Journal of the Royal Statistical Society: Series a},
  number  = {1},
  pages   = {401},
  title   = {Statistics and health care fraud: How to save BillionsTahir ekin (2019) boca raton, chapman Hall/CRC press 140+xvii pp $46.99 ISBN 9781138197428},
  volume  = {184},
  year    = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021c). R visualizations – derive meaning from DataD.w. Gerbing,
2020. Chapman and hall/CRC press, boca raton. 237 pp. 68,99 GBP. ISBN
978-1-138-59963-5. <em>Journal of the Royal Statistical Society: Series
A (Statistics in Society)</em>, <em>184</em>(1), 401–402. (<a
href="https://doi.org/10.1111/rssa.12640">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive = {J},
  author  = {Sebastian Dietz},
  doi     = {10.1111/rssa.12640},
  journal = {Journal of the Royal Statistical Society: Series a},
  number  = {1},
  pages   = {401-402},
  title   = {R visualizations – derive meaning from DataD.W. gerbing, 2020. chapman and Hall/CRC press, boca raton. 237 pp. 68,99 GBP. ISBN 978-1-138-59963-5},
  volume  = {184},
  year    = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). <em>Journal of the Royal Statistical Society: Series A
(Statistics in Society)</em>, <em>184</em>(1), 400. (<a
href="https://doi.org/10.1111/rssa.12636">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive = {J},
  author  = {Kuldeep Kumar},
  doi     = {10.1111/rssa.12636},
  journal = {Journal of the Royal Statistical Society: Series a},
  number  = {1},
  pages   = {400},
  title   = {Time series clustering and classificationMaharaj e. a., D&#39;Urso p., caiado j., 2019. boca raton, chapman Hall/CRC press. 227+xv pp $284.00. ISBN 978-1-4987-7321-8 (Hardback).},
  volume  = {184},
  year    = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Flavia jolliffe 1942–2020. <em>Journal of the Royal
Statistical Society: Series A (Statistics in Society)</em>,
<em>184</em>(1), 398–399. (<a
href="https://doi.org/10.1111/rssa.12639">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive = {J},
  author  = {Gerald Goodall},
  doi     = {10.1111/rssa.12639},
  journal = {Journal of the Royal Statistical Society: Series a},
  number  = {1},
  pages   = {398-399},
  title   = {Flavia jolliffe 1942–2020},
  volume  = {184},
  year    = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Mervyn stone, 1932–2020. <em>Journal of the Royal
Statistical Society: Series A (Statistics in Society)</em>,
<em>184</em>(1), 396–398. (<a
href="https://doi.org/10.1111/rssa.12638">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive = {J},
  author  = {Rex Galbraith},
  doi     = {10.1111/rssa.12638},
  journal = {Journal of the Royal Statistical Society: Series a},
  number  = {1},
  pages   = {396-398},
  title   = {Mervyn stone, 1932–2020},
  volume  = {184},
  year    = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Ranking, and other properties, of elite swimmers using
extreme value theory. <em>Journal of the Royal Statistical Society:
Series A (Statistics in Society)</em>, <em>184</em>(1), 368–395. (<a
href="https://doi.org/10.1111/rssa.12628">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {The International Swimming Federation (FINA) uses a very simple points system with the aim to rank swimmers across all swimming events. The points acquired is a function of the ratio of the recorded time and the current world record for that event. With some world records considered ‘better’ than others however, bias is introduced between events, with some being much harder to attain points where the world record is hard to beat. A model based on extreme value theory is introduced, where swim times are modelled through their rate of occurrence, and with the distribution of the best times following a generalised Pareto distribution. Within this framework, the strength of a particular swim is judged based on its position compared to the whole distribution of swim times, rather than just the world record. This model also accounts for the date of the swim, as training methods improve over the years, as well as changes in technology, such as full body suits. The parameters of the generalised Pareto distribution, for each of the 34 individual long course events, will be shown to vary with covariates, leading to a novel single unified description of swim quality over all events and time. This structure, which allows information to be shared across all strokes, distances, and genders, improves the predictive power as well as the model robustness compared to equivalent independent models. A by-product of the model is that it is possible to estimate other features of interest, such as the ultimate possible time, the distribution of new world records for any event, and to correct swim times for the effect of full body suits. The methods will be illustrated using a dataset of the best 500 swim times for each event in the period 2001–2018.},
  archive  = {J},
  author   = {Harry Spearing and Jonathan Tawn and David Irons and Tim Paulden and Grace Bennett},
  doi      = {10.1111/rssa.12628},
  journal  = {Journal of the Royal Statistical Society: Series a},
  number   = {1},
  pages    = {368-395},
  title    = {Ranking, and other properties, of elite swimmers using extreme value theory},
  volume   = {184},
  year     = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). On probability distributions of the time deviation law of
container liner ships under interference uncertainty. <em>Journal of the
Royal Statistical Society: Series A (Statistics in Society)</em>,
<em>184</em>(1), 354–367. (<a
href="https://doi.org/10.1111/rssa.12627">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Container liner shipping is a kind of transportation mode that is operated according to a schedule. Although the goal is to operate container liner ships on time, the actual arrival time and handling time often deviate from the schedule due to uncertain factors. The identification of a proper probability distribution to describe time deviation law will have a significant impact on accurately recognizing the uncertainty of the operation of container liner ships. In view of this problem, this paper discusses the basic characteristics of container liner ships’ operation time, analyses the properties of relevant probability distributions, and selects representative container ports around the world to collect data on the container liner ships’ operation time for statistical verification. The results show that under schedule constraints and interference uncertainty, the time deviation presents a specific state between a fixed length and random distribution that conforms to the properties of an Erlang distribution. Given that container liner shipping follows the same operation rules worldwide, it is reasonable to deduce that the time deviation law could be generalized to other container ports. Finally, the practical value of this study is demonstrated through quantitative evaluation of port congestion degree under various probabilistic models.},
  archive  = {J},
  author   = {Yunting Song and Nuo Wang},
  doi      = {10.1111/rssa.12627},
  journal  = {Journal of the Royal Statistical Society: Series a},
  number   = {1},
  pages    = {354-367},
  title    = {On probability distributions of the time deviation law of container liner ships under interference uncertainty},
  volume   = {184},
  year     = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A dynamic factor model approach to incorporate big data in
state space models for official statistics. <em>Journal of the Royal
Statistical Society: Series A (Statistics in Society)</em>,
<em>184</em>(1), 324–353. (<a
href="https://doi.org/10.1111/rssa.12626">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {In this paper we consider estimation of unobserved components in state space models using a dynamic factor approach to incorporate auxiliary information from high-dimensional data sources. We apply the methodology to unemployment estimation as done by Statistics Netherlands, who uses a multivariate state space model to produce monthly figures for unemployment using series observed with the labour force survey (LFS). We extend the model by including auxiliary series of Google Trends about job-search and economic uncertainty, and claimant counts, partially observed at higher frequencies. Our factor model allows for nowcasting the variable of interest, providing reliable unemployment estimates in real-time before LFS data become available.},
  archive  = {J},
  author   = {Caterina Schiavoni and Franz Palm and Stephan Smeekes and Jan van den Brakel},
  doi      = {10.1111/rssa.12626},
  journal  = {Journal of the Royal Statistical Society: Series a},
  number   = {1},
  pages    = {324-353},
  title    = {A dynamic factor model approach to incorporate big data in state space models for official statistics},
  volume   = {184},
  year     = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Do coefficients of variation of response propensities
approximate non-response biases during survey data collection?
<em>Journal of the Royal Statistical Society: Series A (Statistics in
Society)</em>, <em>184</em>(1), 301–323. (<a
href="https://doi.org/10.1111/rssa.12624">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {We evaluate the utility of coefficients of variation of response propensities (CVs) as measures of risks of survey variable non-response biases when monitoring survey data collection. CVs quantify variation in sample response propensities estimated given a set of auxiliary attribute covariates observed for all subjects. If auxiliary covariates and survey variables are correlated, low levels of propensity variation imply low bias risk. CVs can also be decomposed to measure associations between auxiliary covariates and propensity variation, informing collection method modifications and post-collection adjustments to improve dataset quality. Practitioners are interested in such approaches to managing bias risks, but risk indicator performance has received little attention. We describe relationships between CVs and expected biases and how they inform quality improvements during and post-data collection, expanding on previous work. Next, given auxiliary information from the concurrent 2011 UK census and details of interview attempts, we use CVs to quantify the representativeness of the UK Labour Force Survey dataset during data collection. Following this, we use survey data to evaluate inference based on CVs concerning survey variables with analogues measuring the same quantities among the auxiliary covariate set. Given our findings, we then offer advice on using CVs to monitor survey data collection.},
  archive  = {J},
  author   = {Jamie C. Moore and Gabriele B. Durrant and Peter W. F. Smith},
  doi      = {10.1111/rssa.12624},
  journal  = {Journal of the Royal Statistical Society: Series a},
  number   = {1},
  pages    = {301-323},
  title    = {Do coefficients of variation of response propensities approximate non-response biases during survey data collection?},
  volume   = {184},
  year     = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A double machine learning approach to estimate the effects
of musical practice on student’s skills. <em>Journal of the Royal
Statistical Society: Series A (Statistics in Society)</em>,
<em>184</em>(1), 282–300. (<a
href="https://doi.org/10.1111/rssa.12623">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {This study investigates the dose–response effects of making music on youth development. Identification is based on the conditional independence assumption and estimation is implemented using a recent double machine learning estimator. The study proposes solutions to two highly practically relevant questions that arise for these new methods: (i) How to investigate sensitivity of estimates to tuning parameter choices in the machine learning part? (ii) How to assess covariate balancing in high-dimensional settings? The results show that improvements in objectively measured cognitive skills require at least medium intensity, while improvements in school grades are already observed for low intensity of practice.},
  archive  = {J},
  author   = {Michael C. Knaus},
  doi      = {10.1111/rssa.12623},
  journal  = {Journal of the Royal Statistical Society: Series a},
  number   = {1},
  pages    = {282-300},
  title    = {A double machine learning approach to estimate the effects of musical practice on student’s skills},
  volume   = {184},
  year     = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Synthetic microdata for establishment surveys under
informative sampling. <em>Journal of the Royal Statistical Society:
Series A (Statistics in Society)</em>, <em>184</em>(1), 255–281. (<a
href="https://doi.org/10.1111/rssa.12622">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Many agencies are investigating whether releasing synthetic microdata could be a viable dissemination strategy for highly sensitive data, such as business data, for which disclosure avoidance regulations otherwise prohibit the release of public use microdata. However, existing methods assume that the original data either cover the entire population or comprise a simple random sample, which limits the application of these methods in the context of survey data with unequal weights. This paper discusses synthetic data generation under informative sampling. To utilise design information in survey weights, we rely on the pseudo likelihood approach when building a hierarchical Bayesian model to estimate the distribution of the finite population. Then, synthetic populations are randomly drawn from the estimated finite population density. We present the full conditional distributions of the Markov chain Monte Carlo algorithm for posterior inference with the pseudo likelihood function. Using simulation studies, we show that the suggested synthetic data approach offers high utility for design-based and model-based analyses while offering a high level of disclosure protection. We apply the proposed method to a subset of the 2012 U.S. Economic Census and evaluate results with utility metrics and disclosure avoidance metrics under data attacker scenarios commonly used for business data.},
  archive  = {J},
  author   = {Hang J. Kim and Jörg Drechsler and Katherine J. Thompson},
  doi      = {10.1111/rssa.12622},
  journal  = {Journal of the Royal Statistical Society: Series a},
  number   = {1},
  pages    = {255-281},
  title    = {Synthetic microdata for establishment surveys under informative sampling},
  volume   = {184},
  year     = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Did you conduct a sensitivity analysis? A new
weighting-based approach for evaluations of the average treatment effect
for the treated. <em>Journal of the Royal Statistical Society: Series A
(Statistics in Society)</em>, <em>184</em>(1), 227–254. (<a
href="https://doi.org/10.1111/rssa.12621">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {In non-experimental research, a sensitivity analysis helps determine whether a causal conclusion could be easily reversed in the presence of hidden bias. A new approach to sensitivity analysis on the basis of weighting extends and supplements propensity score weighting methods for identifying the average treatment effect for the treated (ATT). In its essence, the discrepancy between a new weight that adjusts for the omitted confounders and an initial weight that omits them captures the role of the confounders. This strategy is appealing for a number of reasons including that, regardless of how complex the data generation functions are, the number of sensitivity parameters remains small and their forms never change. A graphical display of the sensitivity parameter values facilitates a holistic assessment of the dominant potential bias. An application to the well-known LaLonde data lays out the implementation procedure and illustrates its broad utility. The data offer a prototypical example of non-experimental evaluations of the average impact of job training programmes for the participant population.},
  archive  = {J},
  author   = {Guanglei Hong and Fan Yang and Xu Qin},
  doi      = {10.1111/rssa.12621},
  journal  = {Journal of the Royal Statistical Society: Series a},
  number   = {1},
  pages    = {227-254},
  title    = {Did you conduct a sensitivity analysis? a new weighting-based approach for evaluations of the average treatment effect for the treated},
  volume   = {184},
  year     = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A dynamic separable network model with actor heterogeneity:
An application to global weapons transfers*. <em>Journal of the Royal
Statistical Society: Series A (Statistics in Society)</em>,
<em>184</em>(1), 201–226. (<a
href="https://doi.org/10.1111/rssa.12620">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {In this paper, we analyse the network of international major conventional weapons (MCW) transfers from 1950 to 2016, based on data from the Stockholm International Peace Research Institute (SIPRI). The dataset consists of yearly bilateral arms transfers between pairs of countries, which allows us to conceive of the individual relationships as part of an overall trade network. For the analysis, we extend the separable temporal exponential random graph model (STERGM) to account for time-varying effects on both the network level (trade network) and the actor level (country effects). Our investigation enables the identification of potentially differing driving forces that influence the formation of new trade relationships versus the persistence of existing ones. In accordance with political economy models, we expect security- and network-related covariates to be most important for the formation of transfers, whereas repeated transfers should prevalently be determined by the importers’ market size and military spending. Our proposed modelling approach corroborates the hypothesis and quantifies the corresponding effects. Additionally, we subject the time-varying heterogeneity effects to a functional principal component analysis. This analysis serves as an exploratory tool and allows us to identify countries with exceptional increases or decreases in their tendency to import and export weapons.},
  archive  = {J},
  author   = {Michael Lebacher and Paul W. Thurner and Göran Kauermann},
  doi      = {10.1111/rssa.12620},
  journal  = {Journal of the Royal Statistical Society: Series a},
  number   = {1},
  pages    = {201-226},
  title    = {A dynamic separable network model with actor heterogeneity: An application to global weapons transfers*},
  volume   = {184},
  year     = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A bayesian structural time series analysis of the effect of
basic income on crime: Evidence from the alaska permanent fund*.
<em>Journal of the Royal Statistical Society: Series A (Statistics in
Society)</em>, <em>184</em>(1), 179–200. (<a
href="https://doi.org/10.1111/rssa.12619">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {This paper examines the impact of Alaska’s Permanent Fund Dividend on crime. The Dividend has been payable annually to state residents since 1982 and is the world’s longest-running example of a basic income. Initially universal, from 1989 onwards eligibility was withdrawn from an increasing proportion of those in prison. A Bayesian structural time series estimator is used to simulate Alaskan crime rates in the counterfactual no-Dividend case. A comparison with actual rates provides an estimate of the Dividend’s impact. This does not provide strong evidence of an effect. However, incorporating information on Dividend amounts suggests the size of payments is important, with larger amounts reducing crime. There is no evidence that this effect is reinforced by the 1989 change to eligibility. The results demonstrate the potential for a basic income to encourage positive outcomes and lend support to payment being universal rather than conditional.},
  archive  = {J},
  author   = {Richard Dorsett},
  doi      = {10.1111/rssa.12619},
  journal  = {Journal of the Royal Statistical Society: Series a},
  number   = {1},
  pages    = {179-200},
  title    = {A bayesian structural time series analysis of the effect of basic income on crime: Evidence from the alaska permanent fund*},
  volume   = {184},
  year     = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Interviewer effects and the measurement of financial
literacy. <em>Journal of the Royal Statistical Society: Series A
(Statistics in Society)</em>, <em>184</em>(1), 150–178. (<a
href="https://doi.org/10.1111/rssa.12617">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {In this paper, we ask whether interviewers influence the answers to a standard set of survey questions on financial literacy. We study data from Germany&#39;s wealth survey, the Panel on Household Finances (PHF). We have access to extensive auxiliary data, including interviewer identifiers, background characteristics of interviewers and measures of interviewer activity through the survey. We find that interviewer effects explain a significant fraction of the variance of the financial literacy score, and intra-interviewer correlations are notably larger for the financial literacy score than for other survey variables. We explore how accounting for interviewer effects can improve estimates of the effects of financial literacy on financial behaviours and outcomes.},
  archive  = {J},
  author   = {Thomas F. Crossley and Tobias Schmidt and Panagiota Tzamourani and Joachim K. Winter},
  doi      = {10.1111/rssa.12617},
  journal  = {Journal of the Royal Statistical Society: Series a},
  number   = {1},
  pages    = {150-178},
  title    = {Interviewer effects and the measurement of financial literacy},
  volume   = {184},
  year     = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Measuring the impact of clean energy production on CO2
abatement in denmark: Upper bound estimation and forecasting*.
<em>Journal of the Royal Statistical Society: Series A (Statistics in
Society)</em>, <em>184</em>(1), 118–149. (<a
href="https://doi.org/10.1111/rssa.12616">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Using annual data from 1978 through 2016, and monthly data from January 2005 through November 2017 from Denmark, we provide a precise estimate of the upper bound on the potential impact of the adoption of wind energy on the reduction of CO 2 emissions from energy production. We separate causal impacts from endogenous effects in regressions using instrumental variables including average wind speed, and from spurious effects in dynamic systems using impulse-response analysis and cointegration techniques. A one percentage point increase in the share of wind in total energy production is found to cause a reduction in CO 2 emissions of the order 0.3\%, based on endogeneity-corrected regression, and 0.5\% over 2 years in a fractional vector error-correction model, after allowing the cumulative effects to take place. This corresponds to an upper bound estimate of 0.69 tonnes of CO 2 emissions avoided per additional MWh of wind energy produced. We find that after a structural break at the time of introduction of the EU ETS and the Kyoto Protocol in 2005, the country has been on track towards meeting its long-term goals for emission reduction and green energy production, but not before.},
  archive  = {J},
  author   = {Bent Jesper Christensen and Nabanita Datta Gupta and Paolo Santucci de Magistris},
  doi      = {10.1111/rssa.12616},
  journal  = {Journal of the Royal Statistical Society: Series a},
  number   = {1},
  pages    = {118-149},
  title    = {Measuring the impact of clean energy production on CO2 abatement in denmark: Upper bound estimation and forecasting*},
  volume   = {184},
  year     = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The effects of health on the extensive and intensive margins
of labour supply. <em>Journal of the Royal Statistical Society: Series A
(Statistics in Society)</em>, <em>184</em>(1), 87–117. (<a
href="https://doi.org/10.1111/rssa.12615">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Using the first seven waves of the Understanding Society data, this study estimates the effects of health on the extensive and intensive margins of the labour supply of the UK workers. Earlier studies on the effects of health on labour supply tend to focus on a binary measure of labour force participation or early retirement. The results show that health affects both the margins of labour supply for both males and females. From the preferred model, the results indicate that the effects of health on both the margins of labour supply are larger for females than for males. Furthermore, the results show that while at the extensive margin there does not appear to be a difference in the effect of health between the old and the young for both genders, for males the effect of health on hours worked, conditional on being employed, is larger for the old than for the young, but for females the effect on hours worked is larger for the young than for the old. The results also show that inadequately exploiting the longitudinal features of panel data might have led to bias estimates.},
  archive  = {J},
  author   = {Lixin Cai},
  doi      = {10.1111/rssa.12615},
  journal  = {Journal of the Royal Statistical Society: Series a},
  number   = {1},
  pages    = {87-117},
  title    = {The effects of health on the extensive and intensive margins of labour supply},
  volume   = {184},
  year     = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Estimating causal moderation effects with randomized
treatments and non-randomized moderators. <em>Journal of the Royal
Statistical Society: Series A (Statistics in Society)</em>,
<em>184</em>(1), 65–86. (<a
href="https://doi.org/10.1111/rssa.12614">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Researchers are often interested in analysing conditional treatment effects. One variant of this is ‘causal moderation’, which implies that intervention upon a third (moderator) variable would alter the treatment effect. This study considers the conditions under which causal moderation can be identified and presents a generalized framework for estimating causal moderation effects given randomized treatments and non-randomized moderators. As part of the estimation process, it allows researchers to implement their preferred method of covariate adjustment, including parametric and non-parametric methods, or alternative identification strategies of their choosing. In addition, it provides a set-up whereby sensitivity analysis designed for the average treatment effect context can be extended to the moderation context. To illustrate the methods, the study presents two applications: one dealing with the effect of using the term ‘welfare’ to describe public assistance in the United States, and one dealing with the effect of asylum seekers’ religion on European attitudes towards asylum seekers.},
  archive  = {J},
  author   = {Kirk Bansak},
  doi      = {10.1111/rssa.12614},
  journal  = {Journal of the Royal Statistical Society: Series a},
  number   = {1},
  pages    = {65-86},
  title    = {Estimating causal moderation effects with randomized treatments and non-randomized moderators},
  volume   = {184},
  year     = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Specification and testing of hierarchical ordered response
models with anchoring vignettes. <em>Journal of the Royal Statistical
Society: Series A (Statistics in Society)</em>, <em>184</em>(1), 31–64.
(<a href="https://doi.org/10.1111/rssa.12612">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Collection and analysis of self-reported information on an ordered Likert scale is ubiquitous across the social sciences. Inference from such analyses is valid where the response scale employed means the same thing to all individuals. That is, if there is no differential item functioning (DIF) present in the data. A priori this is unlikely to hold across all individuals and cohorts in any sample of data. For this reason, anchoring vignettes have been proposed as a way to correct for DIF when individuals self-assess their health (or well-being, or satisfaction levels, or disability levels, etc.) on an ordered categorical scale. Using an example of self-assessed pain, we illustrate the use of vignettes to adjust for DIF using the compound hierarchical ordered probit model ( CHOPIT ). The validity of this approach relies on the two underlying assumptions of response consistency ( RC ) and vignette equivalence ( VE ). Using a minor amendment to the specification of the standard CHOPIT model, we develop easy-to-implement score tests of the null hypothesis of RC and VE both separately and jointly. Monte Carlo simulations show that the tests have good size and power properties in finite samples. We illustrate the use of the tests by applying them to our empirical example. The tests should aid more robust analyses of self-reported survey outcomes collected alongside anchoring vignettes.},
  archive  = {J},
  author   = {William H. Greene and Mark N. Harris and Rachel J. Knott and Nigel Rice},
  doi      = {10.1111/rssa.12612},
  journal  = {Journal of the Royal Statistical Society: Series a},
  number   = {1},
  pages    = {31-64},
  title    = {Specification and testing of hierarchical ordered response models with anchoring vignettes},
  volume   = {184},
  year     = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Dynamic survival prediction combining landmarking with a
machine learning ensemble: Methodology and empirical comparison.
<em>Journal of the Royal Statistical Society: Series A (Statistics in
Society)</em>, <em>184</em>(1), 3–30. (<a
href="https://doi.org/10.1111/rssa.12611">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Dynamic prediction models provide predicted survival probabilities that can be updated over time for an individual as new measurements become available. Two techniques for dynamic survival prediction with longitudinal data dominate the statistical literature: joint modelling and landmarking. There is substantial interest in the use of machine learning methods for prediction; however, their use in the context of dynamic survival prediction has been limited. We show how landmarking can be combined with a machine learning ensemble—the Super Learner. The ensemble combines predictions from different machine learning and statistical algorithms with the goal of achieving improved performance. The proposed approach exploits discrete time survival analysis techniques to enable the use of machine learning algorithms for binary outcomes. We discuss practical and statistical considerations involved in implementing the ensemble. The methods are illustrated and compared using longitudinal data from the UK Cystic Fibrosis Registry. Standard landmarking and the landmark Super Learner approach resulted in similar cross-validated predictive performance, in this case, outperforming joint modelling.},
  archive  = {J},
  author   = {Kamaryn T. Tanner and Linda D. Sharples and Rhian M. Daniel and Ruth H. Keogh},
  doi      = {10.1111/rssa.12611},
  journal  = {Journal of the Royal Statistical Society: Series a},
  number   = {1},
  pages    = {3-30},
  title    = {Dynamic survival prediction combining landmarking with a machine learning ensemble: Methodology and empirical comparison},
  volume   = {184},
  year     = {2021},
}
</textarea>
</details></li>
</ul>

</body>
</html>
