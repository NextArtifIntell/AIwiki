<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>BIOMET_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="biomet---72">BIOMET - 72</h2>
<ul>
<li><details>
<summary>
(2021). Efficient bernoulli factory markov chain monte carlo for
intractable posteriors. <em>BIOMET</em>, <em>109</em>(2), 369–385. (<a
href="https://doi.org/10.1093/biomet/asab031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accept-reject-based Markov chain Monte Carlo algorithms have traditionally utilized acceptance probabilities that can be explicitly written as a function of the ratio of the target density at the two contested points. This feature is rendered almost useless in Bayesian posteriors with unknown functional forms. We introduce a new family of Markov chain Monte Carlo acceptance probabilities that has the distinguishing feature of not being a function of the ratio of the target density at the two points. We present two stable Bernoulli factories that generate events within this class of acceptance probabilities. The efficiency of our methods relies on obtaining reasonable local upper or lower bounds on the target density, and we present two classes of problems where such bounds are viable: Bayesian inference for diffusions, and Markov chain Monte Carlo on constrained spaces. The resulting portkey Barker’s algorithms are exact and computationally more efficient that the current state of the art.},
  archive      = {J_BIOMET},
  author       = {Vats, D and Gonçalves, F B and Łatuszyński, K and Roberts, G O},
  doi          = {10.1093/biomet/asab031},
  journal      = {Biometrika},
  number       = {2},
  pages        = {369-385},
  shortjournal = {Biometrika},
  title        = {Efficient bernoulli factory markov chain monte carlo for intractable posteriors},
  volume       = {109},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Admissible estimators of a multivariate normal mean vector
when the scale is unknown. <em>BIOMET</em>, <em>108</em>(4), 997–1003.
(<a href="https://doi.org/10.1093/biomet/asaa102">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study admissibility of a subclass of generalized Bayes estimators of a multivariate normal vector in the case where the variance is unknown, under scaled quadratic loss. Minimaxity is established for some of these estimators.},
  archive      = {J_BIOMET},
  author       = {Maruyama, Y and Strawderman, W E},
  doi          = {10.1093/biomet/asaa102},
  journal      = {Biometrika},
  number       = {4},
  pages        = {997-1003},
  shortjournal = {Biometrika},
  title        = {Admissible estimators of a multivariate normal mean vector when the scale is unknown},
  volume       = {108},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Nontestability of instrument validity under continuous
treatments. <em>BIOMET</em>, <em>108</em>(4), 989–995. (<a
href="https://doi.org/10.1093/biomet/asaa101">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This note presents a proof of the conjecture in Pearl (1995) about testing the validity of an instrumental variable in hidden variable models. It implies that instrument validity cannot be tested in the case where the endogenous treatment is continuously distributed. This stands in contrast to the classical testability results for instrument validity when the treatment is discrete. However, imposing weak structural assumptions on the model, such as continuity between the observable variables, can re-establish theoretical testability in the continuous setting.},
  archive      = {J_BIOMET},
  author       = {Gunsilius, F F},
  doi          = {10.1093/biomet/asaa101},
  journal      = {Biometrika},
  number       = {4},
  pages        = {989-995},
  shortjournal = {Biometrika},
  title        = {Nontestability of instrument validity under continuous treatments},
  volume       = {108},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Bagging cross-validated bandwidths with application to big
data. <em>BIOMET</em>, <em>108</em>(4), 981–988. (<a
href="https://doi.org/10.1093/biomet/asaa092">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hall &amp; Robinson (2009) proposed and analysed the use of bagged cross-validation to choose the bandwidth of a kernel density estimator. They established that bagging greatly reduces the noise inherent in ordinary cross-validation, and hence leads to a more efficient bandwidth selector. The asymptotic theory of Hall &amp; Robinson (2009) assumes that |$N$|⁠ , the number of bagged subsamples, is |$\infty$|⁠ . We expand upon their theoretical results by allowing |$N$| to be finite, as it is in practice. Our results indicate an important difference in the rate of convergence of the bagged cross-validation bandwidth for the cases |$N=\infty$| and |$N&lt;\infty$|⁠ . Simulations quantify the improvement in statistical efficiency and computational speed that can result from using bagged cross-validation as opposed to a binned implementation of ordinary cross-validation. The performance of the bagged bandwidth is also illustrated on a real, very large, dataset. Finally, a byproduct of our study is the correction of errors appearing in the Hall &amp; Robinson (2009) expression for the asymptotic mean squared error of the bagging selector.},
  archive      = {J_BIOMET},
  author       = {Barreiro-Ures, D and Cao, R and Francisco-Fernández, M and Hart, J D},
  doi          = {10.1093/biomet/asaa092},
  journal      = {Biometrika},
  number       = {4},
  pages        = {981-988},
  shortjournal = {Biometrika},
  title        = {Bagging cross-validated bandwidths with application to big data},
  volume       = {108},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). On semiparametric modelling, estimation and inference for
survival data subject to dependent censoring. <em>BIOMET</em>,
<em>108</em>(4), 965–979. (<a
href="https://doi.org/10.1093/biomet/asaa095">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When modelling survival data, it is common to assume that the survival time |$T$| is conditionally independent of the censoring time |$C$| given a set of covariates. However, there are numerous situations in which this assumption is not realistic. The goal of this paper is therefore to develop a semiparametric normal transformation model which assumes that, after a proper nonparametric monotone transformation, the vector |$(T, C)$| follows a linear model, and the vector of errors in this bivariate linear model follows a standard bivariate normal distribution with a possibly nondiagonal covariance matrix. We show that this semiparametric model is identifiable, and propose estimators of the nonparametric transformation, the regression coefficients and the correlation between the error terms. It is shown that the estimators of the model parameters and the transformation are consistent and asymptotically normal. We also assess the finite-sample performance of the proposed method by comparing it with an estimation method under a fully parametric model. Finally, our method is illustrated using data from the AIDS Clinical Trial Group 175 study.},
  archive      = {J_BIOMET},
  author       = {Deresa, N W and Van Keilegom, I},
  doi          = {10.1093/biomet/asaa095},
  journal      = {Biometrika},
  number       = {4},
  pages        = {965-979},
  shortjournal = {Biometrika},
  title        = {On semiparametric modelling, estimation and inference for survival data subject to dependent censoring},
  volume       = {108},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Maximum likelihood estimation for semiparametric regression
models with panel count data. <em>BIOMET</em>, <em>108</em>(4), 947–963.
(<a href="https://doi.org/10.1093/biomet/asaa091">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Panel count data, in which the observation for each study subject consists of the number of recurrent events between successive examinations, are commonly encountered in industrial reliability testing, medical research and other scientific investigations. We formulate the effects of potentially time-dependent covariates on one or more types of recurrent events through nonhomogeneous Poisson processes with random effects. We employ nonparametric maximum likelihood estimation under arbitrary examination schemes, and develop a simple and stable EM algorithm. We show that the resulting estimators of the regression parameters are consistent and asymptotically normal, with a covariance matrix that achieves the semiparametric efficiency bound and can be estimated using profile likelihood. We evaluate the performance of the proposed methods through simulation studies and analysis of data from a skin cancer clinical trial.},
  archive      = {J_BIOMET},
  author       = {Zeng, Donglin and Lin, D Y},
  doi          = {10.1093/biomet/asaa091},
  journal      = {Biometrika},
  number       = {4},
  pages        = {947-963},
  shortjournal = {Biometrika},
  title        = {Maximum likelihood estimation for semiparametric regression models with panel count data},
  volume       = {108},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Learning block structures in u-statistic-based matrices.
<em>BIOMET</em>, <em>108</em>(4), 933–946. (<a
href="https://doi.org/10.1093/biomet/asaa099">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce a conceptually simple, efficient and easily implemented approach for learning the block structure in a large matrix. Using the properties of U-statistics and large-dimensional random matrix theory, the group structure of many variables can be directly identified based on the eigenvalues and eigenvectors of the scaled sample matrix. We also establish the asymptotic properties of the proposed approach under mild conditions. The finite-sample performance of the approach is examined by extensive simulations and data examples.},
  archive      = {J_BIOMET},
  author       = {Zhang, Weiping and Jin, Baisuo and Bai, Zhidong},
  doi          = {10.1093/biomet/asaa099},
  journal      = {Biometrika},
  number       = {4},
  pages        = {933-946},
  shortjournal = {Biometrika},
  title        = {Learning block structures in U-statistic-based matrices},
  volume       = {108},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Covariate adaptive familywise error rate control for
genome-wide association studies. <em>BIOMET</em>, <em>108</em>(4),
915–931. (<a href="https://doi.org/10.1093/biomet/asaa098">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The familywise error rate has been widely used in genome-wide association studies. With the increasing availability of functional genomics data, it is possible to increase detection power by leveraging these genomic functional annotations. Previous efforts to accommodate covariates in multiple testing focused on false discovery rate control, while covariate-adaptive procedures controlling the familywise error rate remain underdeveloped. Here, we propose a novel covariate-adaptive procedure to control the familywise error rate that incorporates external covariates which are potentially informative of either the statistical power or the prior null probability. An efficient algorithm is developed to implement the proposed method. We prove its asymptotic validity and obtain the rate of convergence through a perturbation-type argument. Our numerical studies show that the new procedure is more powerful than competing methods and maintains robustness across different settings. We apply the proposed approach to the UK Biobank data and analyse 27 traits with 9 million single-nucleotide polymorphisms tested for associations. Seventy-five genomic annotations are used as covariates. Our approach detects more genome-wide significant loci than other methods in 21 out of the 27 traits.},
  archive      = {J_BIOMET},
  author       = {Zhou, Huijuan and Zhang, Xianyang and Chen, Jun},
  doi          = {10.1093/biomet/asaa098},
  journal      = {Biometrika},
  number       = {4},
  pages        = {915-931},
  shortjournal = {Biometrika},
  title        = {Covariate adaptive familywise error rate control for genome-wide association studies},
  volume       = {108},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Bio-equivalence tests in functional data by maximum
deviation. <em>BIOMET</em>, <em>108</em>(4), 895–913. (<a
href="https://doi.org/10.1093/biomet/asaa096">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the problem of testing equivalence of functional parameters, such as the mean or the variance function, in the two-sample functional data setting. In contrast to previous work where the functional problem is reduced to a multiple testing problem for the equivalence of scalar data by comparing the functions at each point, our approach is based on an estimate of a distance measuring the maximum deviation between the two functional parameters. Equivalence is claimed if the estimate for the maximum deviation does not exceed a given threshold. We propose a bootstrap procedure for obtaining quantiles of the distribution of the test statistic, and we prove consistency of the corresponding test in the large-sample scenario. As the methods proposed here avoid the use of the intersection-union principle, they are less conservative and more powerful than currently available approaches.},
  archive      = {J_BIOMET},
  author       = {Dette, Holger and Kokot, Kevin},
  doi          = {10.1093/biomet/asaa096},
  journal      = {Biometrika},
  number       = {4},
  pages        = {895-913},
  shortjournal = {Biometrika},
  title        = {Bio-equivalence tests in functional data by maximum deviation},
  volume       = {108},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Estimation of local treatment effects under the binary
instrumental variable model. <em>BIOMET</em>, <em>108</em>(4), 881–894.
(<a href="https://doi.org/10.1093/biomet/asab003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Instrumental variables are widely used to deal with unmeasured confounding in observational studies and imperfect randomized controlled trials. In these studies, researchers often target the so-called local average treatment effect as it is identifiable under mild conditions. In this paper we consider estimation of the local average treatment effect under the binary instrumental variable model. We discuss the challenges of causal estimation with a binary outcome and show that, surprisingly, it can be more difficult than in the case with a continuous outcome. We propose novel modelling and estimation procedures that improve upon existing proposals in terms of model congeniality, interpretability, robustness and efficiency. Our approach is illustrated via simulation studies and a real data analysis.},
  archive      = {J_BIOMET},
  author       = {Wang, Linbo and Zhang, Yuexia and Richardson, Thomas S and Robins, James M},
  doi          = {10.1093/biomet/asab003},
  journal      = {Biometrika},
  number       = {4},
  pages        = {881-894},
  shortjournal = {Biometrika},
  title        = {Estimation of local treatment effects under the binary instrumental variable model},
  volume       = {108},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Elicitation complexity of statistical properties.
<em>BIOMET</em>, <em>108</em>(4), 857–879. (<a
href="https://doi.org/10.1093/biomet/asaa093">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A property, or statistical functional, is said to be elicitable if it minimizes the expected loss for some loss function. The study of which properties are elicitable sheds light on the capabilities and limitations of point estimation and empirical risk minimization. While recent work has sought to identify which properties are elicitable, here we investigate a more nuanced question: how many dimensions are required to indirectly elicit a given property? This number is called the elicitation complexity of the property. We lay the foundation for a general theory of elicitation complexity, which includes several basic results on how elicitation complexity behaves and the complexity of standard properties of interest. Building on this foundation, our main result gives tight complexity bounds for the broad class of Bayes risks. We apply these results to several properties of interest, including variance, entropy, norms and several classes of financial risk measures. The article concludes with a discussion and open questions.},
  archive      = {J_BIOMET},
  author       = {Frongillo, Rafael M and Kash, Ian A},
  doi          = {10.1093/biomet/asaa093},
  journal      = {Biometrika},
  number       = {4},
  pages        = {857-879},
  shortjournal = {Biometrika},
  title        = {Elicitation complexity of statistical properties},
  volume       = {108},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A method of constructing maximin distance designs.
<em>BIOMET</em>, <em>108</em>(4), 845–855. (<a
href="https://doi.org/10.1093/biomet/asaa089">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An attractive type of space-filling design for computer experiments is the class of maximin distance designs. Algorithmic search is commonly used for finding such designs, but this approach becomes ineffective for large problems. Theoretical construction of maximin distance designs is challenging; some results have been obtained recently, often using highly specialized techniques. This article presents an easy-to-use method for constructing maximin distance designs. The method is versatile as it works with any distance measure. The basic idea is to construct large designs from small designs, and the method is effective because the quality of large designs is guaranteed by that of small designs, as evaluated by the maximin distance criterion.},
  archive      = {J_BIOMET},
  author       = {Li, Wenlong and Liu, Min-Qian and Tang, Boxin},
  doi          = {10.1093/biomet/asaa089},
  journal      = {Biometrika},
  number       = {4},
  pages        = {845-855},
  shortjournal = {Biometrika},
  title        = {A method of constructing maximin distance designs},
  volume       = {108},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Changepoint inference in the presence of missing covariates
for principal surrogate evaluation in vaccine trials. <em>BIOMET</em>,
<em>108</em>(4), 829–843. (<a
href="https://doi.org/10.1093/biomet/asaa100">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the use of threshold-based regression models to evaluate immune response biomarkers as principal surrogate markers of a vaccine’s protective effect. Threshold-based regression models, which allow the relationship between a clinical outcome and a covariate to change dramatically across a threshold value in the covariate, have been studied by various authors under fully observed data. Limited research, however, has examined these models in the presence of missing covariates, such as the counterfactual potential immune responses of a participant in the placebo arm of a standard vaccine trial had they been assigned to the vaccine arm instead. Based on a hinge model for a threshold effect of the principal surrogate on vaccine efficacy, we develop a regression method that consists of two components: (i) an estimated likelihood method for handling missing potential outcomes, and (ii) a penalty imposed on the estimated likelihood to ensure satisfactory finite-sample performance. We develop a method that allows joint estimation of all model parameters, as well as a two-step method that separates estimation of the threshold parameter from the rest of the parameters. Stable iterative algorithms are developed to implement the two methods, and the asymptotic properties of the proposed estimators are established. In simulation studies, the proposed estimators are shown to have satisfactory finite-sample performance. The proposed methods are applied to real data collected from dengue vaccine efficacy trials to predict how vaccine efficacy varies with an individual’s potential immune response if receiving the vaccine.},
  archive      = {J_BIOMET},
  author       = {Yang, Tao and Huang, Ying and Fong, Youyi},
  doi          = {10.1093/biomet/asaa100},
  journal      = {Biometrika},
  number       = {4},
  pages        = {829-843},
  shortjournal = {Biometrika},
  title        = {Changepoint inference in the presence of missing covariates for principal surrogate evaluation in vaccine trials},
  volume       = {108},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Regression adjustment in completely randomized experiments
with a diverging number of covariates. <em>BIOMET</em>, <em>108</em>(4),
815–828. (<a href="https://doi.org/10.1093/biomet/asaa103">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Randomized experiments have become important tools in empirical research. In a completely randomized treatment-control experiment, the simple difference in means of the outcome is un- biased for the average treatment effect, and covariate adjustment can further improve the efficiency without assuming a correctly specified outcome model. In modern applications, experimenters often have access to many covariates, motivating the need for a theory of covariate adjustment under the asymptotic regime with a diverging number of covariates. We study the asymptotic properties of covariate adjustment under the potential outcomes model and propose a bias-corrected estimator that is consistent and asymptotically normal under weaker conditions. Our theory is based purely on randomization without imposing any parametric outcome model assumptions. To prove the theoretical results, we develop novel vector and matrix concentration inequalities for sampling without replacement.},
  archive      = {J_BIOMET},
  author       = {Lei, Lihua and Ding, Peng},
  doi          = {10.1093/biomet/asaa103},
  journal      = {Biometrika},
  number       = {4},
  pages        = {815-828},
  shortjournal = {Biometrika},
  title        = {Regression adjustment in completely randomized experiments with a diverging number of covariates},
  volume       = {108},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Consistency guarantees for greedy permutation-based causal
inference algorithms. <em>BIOMET</em>, <em>108</em>(4), 795–814. (<a
href="https://doi.org/10.1093/biomet/asaa104">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Directed acyclic graphical models are widely used to represent complex causal systems. Since the basic task of learning such a model from data is NP-hard, a standard approach is greedy search over the space of directed acyclic graphs or Markov equivalence classes of directed acyclic graphs. As the space of directed acyclic graphs on |$p$| nodes and the associated space of Markov equivalence classes are both much larger than the space of permutations, it is desirable to consider permutation-based greedy searches. Here, we provide the first consistency guarantees, both uniform and high dimensional, of a greedy permutation-based search. This search corresponds to a simplex-like algorithm operating over the edge-graph of a subpolytope of the permutohedron, called a directed acyclic graph associahedron. Every vertex in this polytope is associated with a directed acyclic graph, and hence with a collection of permutations that are consistent with the directed acyclic graph ordering. A walk is performed on the edges of the polytope maximizing the sparsity of the associated directed acyclic graphs. We show via simulated and real data that this permutation search is competitive with current approaches.},
  archive      = {J_BIOMET},
  author       = {Solus, L and Wang, Y and Uhler, C},
  doi          = {10.1093/biomet/asaa104},
  journal      = {Biometrika},
  number       = {4},
  pages        = {795-814},
  shortjournal = {Biometrika},
  title        = {Consistency guarantees for greedy permutation-based causal inference algorithms},
  volume       = {108},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Rejoinder: “Event history and topological data analysis.”
<em>BIOMET</em>, <em>108</em>(4), 789–793. (<a
href="https://doi.org/10.1093/biomet/asab040">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_BIOMET},
  author       = {Garside, K and Gjoka, A and Henderson, R and Johnson, H and Makarenko, I},
  doi          = {10.1093/biomet/asab040},
  journal      = {Biometrika},
  number       = {4},
  pages        = {789-793},
  shortjournal = {Biometrika},
  title        = {Rejoinder: ‘Event history and topological data analysis’},
  volume       = {108},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Discussion of “event history and topological data analysis.”
<em>BIOMET</em>, <em>108</em>(4), 785–788. (<a
href="https://doi.org/10.1093/biomet/asab022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Garside et al. (2021) use event history methods to analyse topological data. We provide additional background on persistent homology to contrast the hazard estimators used in Garside et al. (2021) with standard approaches in topological data analysis. In particular, Garside et al.’s approach is a local method, which has advantages and disadvantages, whereas homology is global. We also provide more details on persistence landscapes and show how a more complete use of this statistic improves its performance.},
  archive      = {J_BIOMET},
  author       = {Bubenik, Peter},
  doi          = {10.1093/biomet/asab022},
  journal      = {Biometrika},
  number       = {4},
  pages        = {785-788},
  shortjournal = {Biometrika},
  title        = {Discussion of ‘Event history and topological data analysis’},
  volume       = {108},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Discussion of “event history and topological data analysis.”
<em>BIOMET</em>, <em>108</em>(4), 779–783. (<a
href="https://doi.org/10.1093/biomet/asab032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_BIOMET},
  author       = {Biscio, C A N and Møller, J},
  doi          = {10.1093/biomet/asab032},
  journal      = {Biometrika},
  number       = {4},
  pages        = {779-783},
  shortjournal = {Biometrika},
  title        = {Discussion of ‘Event history and topological data analysis’},
  volume       = {108},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Discussion of “event history and topological data analysis.”
<em>BIOMET</em>, <em>108</em>(4), 775–778. (<a
href="https://doi.org/10.1093/biomet/asab023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_BIOMET},
  author       = {Chung, Moo K and Ombao, Hernando},
  doi          = {10.1093/biomet/asab023},
  journal      = {Biometrika},
  number       = {4},
  pages        = {775-778},
  shortjournal = {Biometrika},
  title        = {Discussion of ‘Event history and topological data analysis’},
  volume       = {108},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Event history and topological data analysis.
<em>BIOMET</em>, <em>108</em>(4), 757–773. (<a
href="https://doi.org/10.1093/biomet/asaa097">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Persistent homology is used to track the appearance and disappearance of features as we move through a nested sequence of topological spaces. Equating the nested sequence to a filtration and the appearance and disappearance of features to events, we show that simple event history methods can be used for the analysis of topological data. We propose a version of the well-known Nelson–Aalen cumulative hazard estimator for the comparison of topological features of random fields and for testing parametric assumptions. We suggest a Cox proportional hazards approach for the analysis of embedded metric trees. The Nelson–Aalen method is illustrated on globally distributed climate data and on neutral hydrogen distribution in the Milky Way. The Cox method is used to compare vascular patterns in fundus images of the eyes of healthy and diabetic retinopathy patients.},
  archive      = {J_BIOMET},
  author       = {Garside, K and Gjoka, A and Henderson, R and Johnson, H and Makarenko, I},
  doi          = {10.1093/biomet/asaa097},
  journal      = {Biometrika},
  number       = {4},
  pages        = {757-773},
  shortjournal = {Biometrika},
  title        = {Event history and topological data analysis},
  volume       = {108},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Composite grid designs for adaptive computer experiments
with fast inference. <em>BIOMET</em>, <em>108</em>(3), 749–755. (<a
href="https://doi.org/10.1093/biomet/asaa084">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Experiments are often used to produce emulators of deterministic computer code. This article introduces composite grid experimental designs and a sequential method for building the designs for accurate emulation. Computational methods are developed that enable fast and exact Gaussian process inference even with large sample sizes. We demonstrate that the proposed approach can produce emulators that are orders of magnitude more accurate than current approximations at a comparable computational cost.},
  archive      = {J_BIOMET},
  author       = {Plumlee, M and Erickson, C B and Ankenman, B E and Lawrence, E},
  doi          = {10.1093/biomet/asaa084},
  journal      = {Biometrika},
  number       = {3},
  pages        = {749-755},
  shortjournal = {Biometrika},
  title        = {Composite grid designs for adaptive computer experiments with fast inference},
  volume       = {108},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). On the phase transition of wilks’ phenomenon.
<em>BIOMET</em>, <em>108</em>(3), 741–748. (<a
href="https://doi.org/10.1093/biomet/asaa078">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wilks’ theorem, which offers universal chi-squared approximations for likelihood ratio tests, is widely used in many scientific hypothesis testing problems. For modern datasets with increasing dimension, researchers have found that the conventional Wilks’ phenomenon of the likelihood ratio test statistic often fails. Although new approximations have been proposed in high-dimensional settings, there still lacks a clear statistical guideline regarding how to choose between the conventional and newly proposed approximations, especially for moderate-dimensional data. To address this issue, we develop the necessary and sufficient phase transition conditions for Wilks’ phenomenon under popular tests on multivariate mean and covariance structures. Moreover, we provide an in-depth analysis of the accuracy of chi-squared approximations by deriving their asymptotic biases. These results may provide helpful insights into the use of chi-squared approximations in scientific practices.},
  archive      = {J_BIOMET},
  author       = {He, Yinqiu and Meng, Bo and Zeng, Zhenghao and Xu, Gongjun},
  doi          = {10.1093/biomet/asaa078},
  journal      = {Biometrika},
  number       = {3},
  pages        = {741-748},
  shortjournal = {Biometrika},
  title        = {On the phase transition of wilks’ phenomenon},
  volume       = {108},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Assessing cure status prediction from survival data using
receiver operating characteristic curves. <em>BIOMET</em>,
<em>108</em>(3), 727–740. (<a
href="https://doi.org/10.1093/biomet/asaa080">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Survival analysis relies on the hypothesis that, if the follow-up is long enough, the event of interest will eventually be observed for all observations. This assumption, however, is often not realistic. The survival data then contain a cure fraction. A common approach to modelling and analysing this type of data consists in using cure models. Two types of information can therefore be obtained: the survival at a given time and the cure status, both possibly modelled as a function of the covariates. The cure status is often of interest to medical practitioners, and one is usually interested in predicting it based on markers. Receiver operating characteristic, Roc , curves are one way to evaluate the predicted performance; however, the classical Roc curve method is not appropriate since the cure status is partially unobserved due to the presence of censoring in survival data. We propose a Roc curve estimator that aims to evaluate the cured/noncured status classification performance from cure survival data. This estimator, which handles the presence of censoring, decomposes sensitivity and specificity by means of the definition of conditional probability, and estimates these two quantities by means of weighted empirical distribution functions. The mixture cure model is used to calculate the weights. Based on simulations, we demonstrate good performance of the proposed method, and compare it with the classical Roc curve nonparametric estimator that would be obtained if the cure status was fully observed. We also compare our proposed method with the Roc curves of Heagerty et al. (2000) for classical survival analysis. Finally, we illustrate the methodology on a breast cancer dataset.},
  archive      = {J_BIOMET},
  author       = {Amico, M and Van Keilegom, I and Han, B},
  doi          = {10.1093/biomet/asaa080},
  journal      = {Biometrika},
  number       = {3},
  pages        = {727-740},
  shortjournal = {Biometrika},
  title        = {Assessing cure status prediction from survival data using receiver operating characteristic curves},
  volume       = {108},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Basis expansions for functional snippets. <em>BIOMET</em>,
<em>108</em>(3), 709–726. (<a
href="https://doi.org/10.1093/biomet/asaa088">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Estimation of mean and covariance functions is fundamental for functional data analysis. While this topic has been studied extensively in the literature, a key assumption is that there are enough data in the domain of interest to estimate both the mean and covariance functions. We investigate mean and covariance estimation for functional snippets in which observations from a subject are available only in an interval of length strictly, and often much, shorter than the length of the whole interval of interest. For such a sampling plan, no data is available for direct estimation of the off-diagonal region of the covariance function. We tackle this challenge via a basis representation of the covariance function. The proposed estimator enjoys a convergence rate that is adaptive to the smoothness of the underlying covariance function, and has superior finite-sample performance in simulation studies.},
  archive      = {J_BIOMET},
  author       = {Lin, Zhenhua and Wang, Jane-Ling and Zhong, Qixian},
  doi          = {10.1093/biomet/asaa088},
  journal      = {Biometrika},
  number       = {3},
  pages        = {709-726},
  shortjournal = {Biometrika},
  title        = {Basis expansions for functional snippets},
  volume       = {108},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Optimal estimation of bacterial growth rates based on a
permuted monotone matrix. <em>BIOMET</em>, <em>108</em>(3), 693–708. (<a
href="https://doi.org/10.1093/biomet/asaa082">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Motivated by the problem of estimating bacterial growth rates for genome assemblies from shotgun metagenomic data, we consider the permuted monotone matrix model |$Y=\Theta\Pi+Z$| where |$Y\in \mathbb{R}^{n\times p}$| is observed, |$\Theta\in \mathbb{R}^{n\times p}$| is an unknown approximately rank-one signal matrix with monotone rows, |$\Pi \in \mathbb{R}^{p\times p}$| is an unknown permutation matrix, and |$Z\in \mathbb{R}^{n\times p}$| is the noise matrix. In this article we study estimation of the extreme values associated with the signal matrix |$\Theta$|⁠ , including its first and last columns and their difference. Treating these estimation problems as compound decision problems, minimax rate-optimal estimators are constructed using the spectral column-sorting method. Numerical experiments on simulated and synthetic microbiome metagenomic data are conducted, demonstrating the superiority of the proposed methods over existing alternatives. The methods are illustrated by comparing the growth rates of gut bacteria in inflammatory bowel disease patients and control subjects.},
  archive      = {J_BIOMET},
  author       = {Ma, Rong and Cai, T Tony and Li, Hongzhe},
  doi          = {10.1093/biomet/asaa082},
  journal      = {Biometrika},
  number       = {3},
  pages        = {693-708},
  shortjournal = {Biometrika},
  title        = {Optimal estimation of bacterial growth rates based on a permuted monotone matrix},
  volume       = {108},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Block bootstrap optimality and empirical block selection for
sample quantiles with dependent data. <em>BIOMET</em>, <em>108</em>(3),
675–692. (<a href="https://doi.org/10.1093/biomet/asaa075">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We establish a general theory of optimality for block bootstrap distribution estimation for sample quantiles under mild strong mixing conditions. In contrast to existing results, we study the block bootstrap for varying numbers of blocks. This corresponds to a hybrid between the sub- sampling bootstrap and the moving block bootstrap, in which the number of blocks is between 1 and the ratio of sample size to block length. The hybrid block bootstrap is shown to give theoretical benefits, and startling improvements in accuracy in distribution estimation in important practical settings. The conclusion that bootstrap samples should be of smaller size than the original sample has significant implications for computational efficiency and scalability of bootstrap methodologies with dependent data. Our main theorem determines the optimal number of blocks and block length to achieve the best possible convergence rate for the block bootstrap distribution estimator for sample quantiles. We propose an intuitive method for empirical selection of the optimal number and length of blocks, and demonstrate its value in a nontrivial example.},
  archive      = {J_BIOMET},
  author       = {Kuffner, T A and Lee, S M S and Young, G A},
  doi          = {10.1093/biomet/asaa075},
  journal      = {Biometrika},
  number       = {3},
  pages        = {675-692},
  shortjournal = {Biometrika},
  title        = {Block bootstrap optimality and empirical block selection for sample quantiles with dependent data},
  volume       = {108},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Jackknife empirical likelihood: Small bandwidth, sparse
network and high-dimensional asymptotics. <em>BIOMET</em>,
<em>108</em>(3), 661–674. (<a
href="https://doi.org/10.1093/biomet/asaa081">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article aims to shed light on inference problems for statistical models under alternative or nonstandard asymptotic frameworks from the perspective of the jackknife empirical likelihood. Examples include small-bandwidth asymptotics for semiparametric inference and goodness-of-fit testing, sparse-network asymptotics, many-covariates asymptotics for regression models, and many-weak-instruments asymptotics for instrumental variable regression. We first establish Wilks’ theorem for the jackknife empirical likelihood statistic in a general semiparametric inference problem under the conventional asymptotics. We then show that the jackknife empirical likelihood statistic may lose asymptotic pivotalness in the above nonstandard asymptotic frameworks, and argue that this phenomenon can be understood in terms of the emergence of Efron &amp; Stein (1981) ’s bias of the jackknife variance estimator at first order. Finally, we propose a modification of the jackknife empirical likelihood to recover asymptotic pivotalness under both conventional and nonstandard asymptotics. Our modification works for all of the above examples and provides a unified framework for investigating nonstandard asymptotic problems.},
  archive      = {J_BIOMET},
  author       = {Matsushita, Yukitoshi and Otsu, Taisuke},
  doi          = {10.1093/biomet/asaa081},
  journal      = {Biometrika},
  number       = {3},
  pages        = {661-674},
  shortjournal = {Biometrika},
  title        = {Jackknife empirical likelihood: Small bandwidth, sparse network and high-dimensional asymptotics},
  volume       = {108},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A parsimonious personalized dose-finding model via dimension
reduction. <em>BIOMET</em>, <em>108</em>(3), 643–659. (<a
href="https://doi.org/10.1093/biomet/asaa087">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning an individualized dose rule in personalized medicine is a challenging statistical problem. Existing methods often suffer from the curse of dimensionality, especially when the decision function is estimated nonparametrically. To tackle this problem, we propose a dimension reduction framework that effectively reduces the estimation to an optimization on a lower-dimensional subspace of the covariates. We exploit the fact that the individualized dose rule can be defined in a subspace spanned by a few linear combinations of the covariates to obtain a more parsimonious model. Owing to direct maximization of the value function, the proposed framework does not require the inverse probability of the propensity score under observational studies. This distinguishes our approach from the outcome-weighted learning framework, which also solves decision rules directly. Within the same framework, we further propose a pseudo-direct learning approach that focuses more on estimating the dimensionality-reduced subspace of the treatment outcome. Parameters in both approaches can be estimated efficiently using an orthogonality-constrained optimization algorithm on the Stiefel manifold. Under mild regularity assumptions, results on the asymptotic normality of the proposed estimators are established. We also derive the consistency and convergence rate of the value function under the estimated optimal dose rule. We evaluate the performance of the proposed approaches through extensive simulation studies and analysis of a pharmacogenetic dataset.},
  archive      = {J_BIOMET},
  author       = {Zhou, Wenzhuo and Zhu, Ruoqing and Zeng, Donglin},
  doi          = {10.1093/biomet/asaa087},
  journal      = {Biometrika},
  number       = {3},
  pages        = {643-659},
  shortjournal = {Biometrika},
  title        = {A parsimonious personalized dose-finding model via dimension reduction},
  volume       = {108},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Nonparametric efficient causal mediation with intermediate
confounders. <em>BIOMET</em>, <em>108</em>(3), 627–641. (<a
href="https://doi.org/10.1093/biomet/asaa085">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Interventional effects for mediation analysis were proposed as a solution to the lack of identifiability of natural (in)direct effects in the presence of a mediator-outcome confounder affected by exposure. We present a theoretical and computational study of the properties of the interventional (in)direct effect estimands based on the efficient influence function in the nonparametric statistical model. We use the efficient influence function to develop two asymptotically optimal nonparametric estimators that leverage data-adaptive regression for the estimation of nuisance parameters: a one-step estimator and a targeted minimum loss estimator. We further present results establishing the conditions under which these estimators are consistent, multiply robust, |$n^{1/2}$| -consistent and efficient. We illustrate the finite-sample performance of the estimators and corroborate our theoretical results in a simulation study. We also demonstrate the use of the estimators in our motivating application to elucidate the mechanisms behind the unintended harmful effects that a housing intervention had on risky behaviour in adolescent girls.},
  archive      = {J_BIOMET},
  author       = {Díaz, I and Hejazi, N S and Rudolph, K E and van Der Laan, M J},
  doi          = {10.1093/biomet/asaa085},
  journal      = {Biometrika},
  number       = {3},
  pages        = {627-641},
  shortjournal = {Biometrika},
  title        = {Nonparametric efficient causal mediation with intermediate confounders},
  volume       = {108},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Geometrically aware dynamic markov bases for statistical
linear inverse problems. <em>BIOMET</em>, <em>108</em>(3), 609–626. (<a
href="https://doi.org/10.1093/biomet/asaa083">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For statistical linear inverse problems involving count data, inference typically requires sampling a latent variable with conditional support comprising of the lattice points in a convex polytope. Irreducibility of random walk samplers is guaranteed only if a sufficiently rich array of sampling directions is available. In principle, this can be achieved by finding a Markov basis of moves ab initio, but in practice doing so may be computationally infeasible. What is more, the use of a full Markov basis can lead to very poor mixing. It is far simpler to find a lattice basis of moves, which can be tailored to the overall geometry of the polytope. However, a single lattice basis generally does not connect all points in the polytope. In response, we propose a dynamic lattice basis sampler. This sampler can access a sufficient variety of sampling directions to guarantee irreducibility, but also prefers moves that are well aligned to the polytope geometry, hence promoting good mixing. The probability with which the sampler selects different bases can be tuned. We present an efficient algorithm for updating the lattice basis, obviating the need for repeated matrix inversion.},
  archive      = {J_BIOMET},
  author       = {Hazelton, M L and Mcveagh, M R and van Brunt, B},
  doi          = {10.1093/biomet/asaa083},
  journal      = {Biometrika},
  number       = {3},
  pages        = {609-626},
  shortjournal = {Biometrika},
  title        = {Geometrically aware dynamic markov bases for statistical linear inverse problems},
  volume       = {108},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Componentwise approximate bayesian computation via
gibbs-like steps. <em>BIOMET</em>, <em>108</em>(3), 591–607. (<a
href="https://doi.org/10.1093/biomet/asaa090">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Approximate Bayesian computation methods are useful for generative models with intractable likelihoods. These methods are, however, sensitive to the dimension of the parameter space, requiring exponentially increasing resources as this dimension grows. To tackle this difficulty we explore a Gibbs version of the approximate Bayesian computation approach that runs component-wise approximate Bayesian computation steps aimed at the corresponding conditional posterior distributions, and based on summary statistics of reduced dimensions. While lacking the standard justifications for the Gibbs sampler, the resulting Markov chain is shown to converge in distribution under some partial independence conditions. The associated stationary distribution can further be shown to be close to the true posterior distribution, and some hierarchical versions of the proposed mechanism enjoy a closed-form limiting distribution. Experiments also demonstrate the gain in efficiency brought by the Gibbs version over the standard solution.},
  archive      = {J_BIOMET},
  author       = {Clarté, Grégoire and Robert, Christian P and Ryder, Robin J and Stoehr, Julien},
  doi          = {10.1093/biomet/asaa090},
  journal      = {Biometrika},
  number       = {3},
  pages        = {591-607},
  shortjournal = {Biometrika},
  title        = {Componentwise approximate bayesian computation via gibbs-like steps},
  volume       = {108},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Hypotheses on a tree: New error rates and testing
strategies. <em>BIOMET</em>, <em>108</em>(3), 575–590. (<a
href="https://doi.org/10.1093/biomet/asaa086">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce a multiple testing procedure that controls global error rates at multiple levels of resolution. Conceptually, we frame this problem as the selection of hypotheses that are organized hierarchically in a tree structure. We describe a fast algorithm and prove that it controls relevant error rates given certain assumptions on the dependence between the |$p$| -values. Through simulations, we demonstrate that the proposed procedure provides the desired guarantees under a range of dependency structures and that it has the potential to gain power over alternative methods. Finally, we apply the method to studies on the genetic regulation of gene expression across multiple tissues and on the relation between the gut microbiome and colorectal cancer.},
  archive      = {J_BIOMET},
  author       = {Bogomolov, Marina and Peterson, Christine B and Benjamini, Yoav and Sabatti, Chiara},
  doi          = {10.1093/biomet/asaa086},
  journal      = {Biometrika},
  number       = {3},
  pages        = {575-590},
  shortjournal = {Biometrika},
  title        = {Hypotheses on a tree: New error rates and testing strategies},
  volume       = {108},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). On order determination by predictor augmentation.
<em>BIOMET</em>, <em>108</em>(3), 557–574. (<a
href="https://doi.org/10.1093/biomet/asaa077">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In many dimension reduction problems in statistics and machine learning, such as in principal component analysis, canonical correlation analysis, independent component analysis and sufficient dimension reduction, it is important to determine the dimension of the reduced predictor, which often amounts to estimating the rank of a matrix. This problem is called order determination. In this article, we propose a novel and highly effective order-determination method based on the idea of predictor augmentation. We show that if the predictor is augmented by an artificially generated random vector, then the parts of the eigenvectors of the matrix induced by the augmentation display a pattern that reveals information about the order to be determined. This information, when combined with the information provided by the eigenvalues of the matrix, greatly enhances the accuracy of order determination.},
  archive      = {J_BIOMET},
  author       = {Luo, Wei and Li, Bing},
  doi          = {10.1093/biomet/asaa077},
  journal      = {Biometrika},
  number       = {3},
  pages        = {557-574},
  shortjournal = {Biometrika},
  title        = {On order determination by predictor augmentation},
  volume       = {108},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Rejoinder: “Estimating time-varying causal excursion
effects in mobile health with binary outcomes.” <em>BIOMET</em>,
<em>108</em>(3), 551–555. (<a
href="https://doi.org/10.1093/biomet/asab033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_BIOMET},
  author       = {Qian, Tianchen and Yoo, Hyesun and Klasnja, Predrag and Almirall, Daniel and Murphy, Susan A},
  doi          = {10.1093/biomet/asab033},
  journal      = {Biometrika},
  number       = {3},
  pages        = {551-555},
  shortjournal = {Biometrika},
  title        = {Rejoinder: ‘Estimating time-varying causal excursion effects in mobile health with binary outcomes’},
  volume       = {108},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Discussion of “estimating time-varying causal excursion
effects in mobile health with binary outcomes.” <em>BIOMET</em>,
<em>108</em>(3), 541–550. (<a
href="https://doi.org/10.1093/biomet/asab029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_BIOMET},
  author       = {Guo, F Richard and Richardson, Thomas S and Robins, James M},
  doi          = {10.1093/biomet/asab029},
  journal      = {Biometrika},
  number       = {3},
  pages        = {541-550},
  shortjournal = {Biometrika},
  title        = {Discussion of ‘Estimating time-varying causal excursion effects in mobile health with binary outcomes’},
  volume       = {108},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Discussion of “estimating time-varying causal excursion
effects in mobile health with binary outcomes.” <em>BIOMET</em>,
<em>108</em>(3), 535–539. (<a
href="https://doi.org/10.1093/biomet/asaa105">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_BIOMET},
  author       = {Zhang, Y and Laber, E B},
  doi          = {10.1093/biomet/asaa105},
  journal      = {Biometrika},
  number       = {3},
  pages        = {535-539},
  shortjournal = {Biometrika},
  title        = {Discussion of ‘Estimating time-varying causal excursion effects in mobile health with binary outcomes’},
  volume       = {108},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Discussion of “estimating time-varying causal excursion
effects in mobile health with binary outcomes.” <em>BIOMET</em>,
<em>108</em>(3), 529–533. (<a
href="https://doi.org/10.1093/biomet/asaa094">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this discussion, we examine the contributions of Qian et al. (2021) and potential applications of the newly developed estimator for the causal excursion effect in binary outcome data. Specifically, we consider extension of their method to count outcomes and observational data, propose an alternative use of their method for analysing excursion effect trajectories and discuss ways of improving estimator efficiency.},
  archive      = {J_BIOMET},
  author       = {Kim, S and Cho, H and Bang, D and De Marchi, D and El-Zaatari, H and Shah, K S and Valancius, M and Zikry, T M and Kosorok, M R},
  doi          = {10.1093/biomet/asaa094},
  journal      = {Biometrika},
  number       = {3},
  pages        = {529-533},
  shortjournal = {Biometrika},
  title        = {Discussion of ‘Estimating time-varying causal excursion effects in mobile health with binary outcomes’},
  volume       = {108},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Estimating time-varying causal excursion effects in mobile
health with binary outcomes. <em>BIOMET</em>, <em>108</em>(3), 507–527.
(<a href="https://doi.org/10.1093/biomet/asaa070">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Advances in digital technology and wearables have made it possible to deliver behavioural mobile health interventions to individuals in their everyday lives. Micro-randomized trials are increasingly used to provide data to inform the construction of these interventions. In a micro-randomized trial, each individual is repeatedly randomized among multiple intervention options, often hundreds or even thousands of times over the course of the trial. The work reported in this article is motivated by multiple micro-randomized trials that have been conducted or are currently in the field, in which the primary outcome is a longitudinal binary outcome. The primary aim of such micro-randomized trials is to examine whether a particular time-varying intervention has an effect on the longitudinal binary outcome, often marginally over all, but a small subset of the individual’s data. We propose the concept of causal excursion effect, which can be used in such a primary-aim analysis for micro-randomized trials with binary outcomes. Under rather restrictive assumptions one can derive, based on existing literature, a semiparametric, locally efficient estimator of the causal effect. Starting from this estimator, we develop an estimator that can be used as the basis of a primary-aim analysis under more plausible assumptions. Simulation studies are conducted to compare the estimators. We illustrate the proposed methods using data from the micro-randomized trial BariFit, the goal of which is to support weight maintenance for individuals who have undergone bariatric surgery.},
  archive      = {J_BIOMET},
  author       = {Qian, Tianchen and Yoo, Hyesun and Klasnja, Predrag and Almirall, Daniel and Murphy, Susan A},
  doi          = {10.1093/biomet/asaa070},
  journal      = {Biometrika},
  number       = {3},
  pages        = {507-527},
  shortjournal = {Biometrika},
  title        = {Estimating time-varying causal excursion effects in mobile health with binary outcomes},
  volume       = {108},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Nonsmooth backfitting for the excess risk additive
regression model with two survival time scales. <em>BIOMET</em>,
<em>108</em>(2), 491–506. (<a
href="https://doi.org/10.1093/biomet/asaa058">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider an extension of Aalen’s additive regression model that allows covariates to have effects that vary on two different time scales. The two time scales considered are equal up to a constant for each individual and vary across individuals, such as follow-up time and age in medical studies or calendar time and age in longitudinal studies. The model was introduced in Scheike (2001) , where it was solved using smoothing techniques. We present a new backfitting algorithm for estimating the structured model without having to use smoothing. Estimators of the cumulative regression functions on the two time scales are suggested by solving local estimating equations jointly on the two time scales. We provide large-sample properties and simultaneous confidence bands. The model is applied to data on myocardial infarction, providing a separation of the two effects stemming from time since diagnosis and age.},
  archive      = {J_BIOMET},
  author       = {Hiabu, M and Nielsen, J P and Scheike, T H},
  doi          = {10.1093/biomet/asaa058},
  journal      = {Biometrika},
  number       = {2},
  pages        = {491-506},
  shortjournal = {Biometrika},
  title        = {Nonsmooth backfitting for the excess risk additive regression model with two survival time scales},
  volume       = {108},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Finite-time analysis of vector autoregressive models under
linear restrictions. <em>BIOMET</em>, <em>108</em>(2), 469–489. (<a
href="https://doi.org/10.1093/biomet/asaa065">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper develops a unified finite-time theory for the ordinary least squares estimation of possibly unstable and even slightly explosive vector autoregressive models under linear restrictions, with the applicable region |$\rho(A)\leqslant 1+c/n$|⁠ , where |$\rho(A)$| is the spectral radius of the transition matrix |$A$| in the var (1) representation, |$n$| is the time horizon and |$c&gt;0$| is a universal constant. The linear restriction framework encompasses various existing models such as banded/network vector autoregressive models. We show that the restrictions reduce the error bounds via not only the reduced dimensionality, but also a scale factor resembling the asymptotic covariance matrix of the estimator in the fixed-dimensional set-up: as long as the model is correctly specified, this scale factor is decreasing in the number of restrictions. It is revealed that the phase transition from slow to fast error rate regimes is determined by the smallest singular value of |$A$|⁠ , a measure of the least excitable mode of the system. The minimax lower bounds are derived across different regimes. The developed non-asymptotic theory not only bridges the theoretical gap between stable and unstable regimes, but precisely characterizes the effect of restrictions and its interplay with model parameters. Simulations support our theoretical results.},
  archive      = {J_BIOMET},
  author       = {Zheng, Yao and Cheng, Guang},
  doi          = {10.1093/biomet/asaa065},
  journal      = {Biometrika},
  number       = {2},
  pages        = {469-489},
  shortjournal = {Biometrika},
  title        = {Finite-time analysis of vector autoregressive models under linear restrictions},
  volume       = {108},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Poisson reduced-rank models with an application to political
text data. <em>BIOMET</em>, <em>108</em>(2), 455–468. (<a
href="https://doi.org/10.1093/biomet/asaa063">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We discuss Poisson reduced-rank models for low-dimensional summaries of high-dimensional Poisson vectors that allow inference on the location of individuals in a low-dimensional space. We show that under weak dependence conditions, which allow for certain correlations between the Poisson random variables, the locations can be consistently estimated using Poisson maximum likelihood estimation. Moreover, we develop consistent rules for determining the dimension of the location from the discrete data. Our main motivation for studying Poisson reduced-rank models arises from applications to political text data, where word counts in a political document are modelled by Poisson random variables. We apply our method to party manifesto data taken from German political parties across seven federal elections following German reunification, to make statistical inferences on the multi-dimensional evolution of party positions.},
  archive      = {J_BIOMET},
  author       = {Jentsch, Carsten and Lee, Eun Ryung and Mammen, Enno},
  doi          = {10.1093/biomet/asaa063},
  journal      = {Biometrika},
  number       = {2},
  pages        = {455-468},
  shortjournal = {Biometrika},
  title        = {Poisson reduced-rank models with an application to political text data},
  volume       = {108},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Lattice-based designs with quasi-optimal separation distance
on all projections. <em>BIOMET</em>, <em>108</em>(2), 443–454. (<a
href="https://doi.org/10.1093/biomet/asaa057">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Experimental designs that spread points apart from each other on projections are important for computer experiments, when not necessarily all factors have a substantial influence on the response. We provide a theoretical framework for generating designs that have quasi-optimal separation distance on all the projections and quasi-optimal fill distance on univariate margins. The key is to use special techniques to rotate certain lattices. One such type of design is the class of densest packing-based maximum projection designs, which outperform existing types of space-filling designs in many scenarios.},
  archive      = {J_BIOMET},
  author       = {He, Xu},
  doi          = {10.1093/biomet/asaa057},
  journal      = {Biometrika},
  number       = {2},
  pages        = {443-454},
  shortjournal = {Biometrika},
  title        = {Lattice-based designs with quasi-optimal separation distance on all projections},
  volume       = {108},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Estimating differential latent variable graphical models
with applications to brain connectivity. <em>BIOMET</em>,
<em>108</em>(2), 425–442. (<a
href="https://doi.org/10.1093/biomet/asaa066">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Differential graphical models are designed to represent the difference between the conditional dependence structures of two groups, and thus are of particular interest for scientific investigations. Motivated by modern applications, this manuscript considers an extended setting where each group is generated by a latent variable Gaussian graphical model. Due to the existence of latent factors, the differential network is decomposed into sparse and low-rank components, both of which are symmetric indefinite matrices. We estimate these two components simultaneously using a two-stage procedure: (i) an initialization stage, which computes a simple, consistent estimator, and (ii) a convergence stage, implemented using a projected alternating gradient descent algorithm applied to a nonconvex objective, initialized using the output of the first stage. We prove that given the initialization, the estimator converges linearly with a nontrivial, minimax optimal statistical error. Experiments on synthetic and real data illustrate that the proposed nonconvex procedure outperforms existing methods.},
  archive      = {J_BIOMET},
  author       = {Na, S and Kolar, M and Koyejo, O},
  doi          = {10.1093/biomet/asaa066},
  journal      = {Biometrika},
  number       = {2},
  pages        = {425-442},
  shortjournal = {Biometrika},
  title        = {Estimating differential latent variable graphical models with applications to brain connectivity},
  volume       = {108},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). On quadratic forms in multivariate generalized hyperbolic
random vectors. <em>BIOMET</em>, <em>108</em>(2), 413–424. (<a
href="https://doi.org/10.1093/biomet/asaa067">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article presents exact and approximate expressions for tail probabilities and partial moments of quadratic forms in multivariate generalized hyperbolic random vectors. The derivations involve a generalization of the classic inversion formula for distribution functions ( Gil-Pelaez, 1951 ). Two numerical applications are considered: the distribution of the two-stage least squares estimator and the expected shortfall of a quadratic portfolio.},
  archive      = {J_BIOMET},
  author       = {Broda, Simon A and Zambrano, Juan Arismendi},
  doi          = {10.1093/biomet/asaa067},
  journal      = {Biometrika},
  number       = {2},
  pages        = {413-424},
  shortjournal = {Biometrika},
  title        = {On quadratic forms in multivariate generalized hyperbolic random vectors},
  volume       = {108},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An assumption-free exact test for fixed-design linear models
with exchangeable errors. <em>BIOMET</em>, <em>108</em>(2), 397–412. (<a
href="https://doi.org/10.1093/biomet/asaa079">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose the cyclic permutation test to test general linear hypotheses for linear models. The test is nonrandomized and valid in finite samples with exact Type I error |$\alpha$| for an arbitrary fixed design matrix and arbitrary exchangeable errors, whenever |$1 / \alpha$| is an integer and |$n / p \geqslant 1 / \alpha - 1$|⁠ , where |$n$| is the sample size and |$p$| is the number of parameters. The test involves applying the marginal rank test to |$1 / \alpha$| linear statistics of the outcome vector, where the coefficient vectors are determined by solving a linear system such that the joint distribution of the linear statistics is invariant with respect to a nonstandard cyclic permutation group under the null hypothesis. The power can be further enhanced by solving a secondary nonlinear travelling salesman problem, for which the genetic algorithm can find a reasonably good solution. Extensive simulation studies show that the cyclic permutation test has comparable power to existing tests. When testing for a single contrast of coefficients, an exact confidence interval can be obtained by inverting the test.},
  archive      = {J_BIOMET},
  author       = {Lei, Lihua and Bickel, Peter J},
  doi          = {10.1093/biomet/asaa079},
  journal      = {Biometrika},
  number       = {2},
  pages        = {397-412},
  shortjournal = {Biometrika},
  title        = {An assumption-free exact test for fixed-design linear models with exchangeable errors},
  volume       = {108},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The uniform general signed rank test and its design
sensitivity. <em>BIOMET</em>, <em>108</em>(2), 381–396. (<a
href="https://doi.org/10.1093/biomet/asaa072">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A sensitivity analysis in an observational study tests whether the qualitative conclusions of an analysis would change if we were to allow for the possibility of limited bias due to confounding. The design sensitivity of a hypothesis test quantifies the asymptotic performance of the test in a sensitivity analysis against a particular alternative. We propose a new, nonasymptotic, distribution-free test, the uniform general signed rank test, for observational studies with paired data, and examine its performance under Rosenbaum’s sensitivity analysis model. Our test can be viewed as adaptively choosing from among a large underlying family of signed rank tests, and we show that the uniform test achieves design sensitivity equal to the maximum design sensitivity over the underlying family of signed rank tests. Our test thus achieves superior design sensitivity, indicating it will perform well in sensitivity analyses on large samples. We support this conclusion with simulations and a data example, showing that the advantages of our test extend to moderate sample sizes as well.},
  archive      = {J_BIOMET},
  author       = {Howard, S R and Pimentel, S D},
  doi          = {10.1093/biomet/asaa072},
  journal      = {Biometrika},
  number       = {2},
  pages        = {381-396},
  shortjournal = {Biometrika},
  title        = {The uniform general signed rank test and its design sensitivity},
  volume       = {108},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Posterior contraction in sparse generalized linear models.
<em>BIOMET</em>, <em>108</em>(2), 367–379. (<a
href="https://doi.org/10.1093/biomet/asaa074">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study posterior contraction rates in sparse high-dimensional generalized linear models using priors incorporating sparsity. A mixture of a point mass at zero and a continuous distribution is used as the prior distribution on regression coefficients. In addition to the usual posterior, the fractional posterior, which is obtained by applying Bayes theorem with a fractional power of the likelihood, is also considered. The latter allows uniformity in posterior contraction over a larger subset of the parameter space. In our set-up, the link function of the generalized linear model need not be canonical. We show that Bayesian methods achieve convergence properties analogous to lasso-type procedures. Our results can be used to derive posterior contraction rates in many generalized linear models including logistic, Poisson regression and others.},
  archive      = {J_BIOMET},
  author       = {Jeong, Seonghyun and Ghosal, Subhashis},
  doi          = {10.1093/biomet/asaa074},
  journal      = {Biometrika},
  number       = {2},
  pages        = {367-379},
  shortjournal = {Biometrika},
  title        = {Posterior contraction in sparse generalized linear models},
  volume       = {108},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). On the use of a penalized quasilikelihood information
criterion for generalized linear mixed models. <em>BIOMET</em>,
<em>108</em>(2), 353–365. (<a
href="https://doi.org/10.1093/biomet/asaa069">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Information criteria are commonly used for joint fixed and random effects selection in mixed models. While information criteria are straightforward to implement, a major difficulty in applying them is that they are typically based on maximum likelihood estimates, but calculating such estimates for one candidate mixed model, let alone multiple models, presents a major computational challenge. To overcome this hurdle, we study penalized quasilikelihood estimation and use it as the basis for performing fast joint selection. Under a general framework, we show that penalized quasilikelihood estimation produces consistent estimates of the true parameters. We then propose a new penalized quasilikelihood information criterion whose distinguishing feature is the way it accounts for model complexity in the random effects, since penalized quasilikelihood estimation effectively treats the random effects as fixed. We demonstrate that the criterion asymptotically identifies the true set of important fixed and random effects. Simulations show that the quasilikelihood information criterion performs competitively with and sometimes better than common maximum likelihood information criteria for joint selection, while offering substantial reductions in computation time.},
  archive      = {J_BIOMET},
  author       = {Hui, Francis K C},
  doi          = {10.1093/biomet/asaa069},
  journal      = {Biometrika},
  number       = {2},
  pages        = {353-365},
  shortjournal = {Biometrika},
  title        = {On the use of a penalized quasilikelihood information criterion for generalized linear mixed models},
  volume       = {108},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Specification tests for covariance structures in
high-dimensional statistical models. <em>BIOMET</em>, <em>108</em>(2),
335–351. (<a href="https://doi.org/10.1093/biomet/asaa073">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider testing the covariance structure in statistical models. We focus on developing such tests when the random vectors of interest are not directly observable and have to be derived via estimated models. Additionally, the covariance specification may involve extra nuisance parameters which also need to be estimated. In a generic additive model setting, we develop and investigate test statistics based on the maximum discrepancy measure calculated from the residuals. To approximate the distributions of the test statistics under the null hypothesis, new multiplier bootstrap procedures with dedicated adjustments that incorporate the model and nuisance parameter estimation errors are proposed. Our theoretical development elucidates the impact due to the estimation errors with high-dimensional data and demonstrates the validity of our tests. Simulations and real data examples confirm our theory and demonstrate the performance of the proposed tests.},
  archive      = {J_BIOMET},
  author       = {Guo, X and Tang, C Y},
  doi          = {10.1093/biomet/asaa073},
  journal      = {Biometrika},
  number       = {2},
  pages        = {335-351},
  shortjournal = {Biometrika},
  title        = {Specification tests for covariance structures in high-dimensional statistical models},
  volume       = {108},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Inference for treatment effect parameters in potentially
misspecified high-dimensional models. <em>BIOMET</em>, <em>108</em>(2),
321–334. (<a href="https://doi.org/10.1093/biomet/asaa071">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Eliminating the effect of confounding in observational studies typically involves fitting a model for an outcome adjusted for covariates. When, as often, these covariates are high-dimensional, this necessitates the use of sparse estimators, such as the lasso, or other regularization approaches. Naïve use of such estimators yields confidence intervals for the conditional treatment effect parameter that are not uniformly valid. Moreover, as the number of covariates grows with the sample size, correctly specifying a model for the outcome is nontrivial. In this article we deal with both of these concerns simultaneously, obtaining confidence intervals for conditional treatment effects that are uniformly valid, regardless of whether the outcome model is correct. This is done by incorporating an additional model for the treatment selection mechanism. When both models are correctly specified, we can weaken the standard conditions on model sparsity. Our procedure extends to multivariate treatment effect parameters and complex longitudinal settings.},
  archive      = {J_BIOMET},
  author       = {Dukes, Oliver and Vansteelandt, Stijn},
  doi          = {10.1093/biomet/asaa071},
  journal      = {Biometrika},
  number       = {2},
  pages        = {321-334},
  shortjournal = {Biometrika},
  title        = {Inference for treatment effect parameters in potentially misspecified high-dimensional models},
  volume       = {108},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Quasi-oracle estimation of heterogeneous treatment effects.
<em>BIOMET</em>, <em>108</em>(2), 299–319. (<a
href="https://doi.org/10.1093/biomet/asaa076">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Flexible estimation of heterogeneous treatment effects lies at the heart of many statistical applications, such as personalized medicine and optimal resource allocation. In this article we develop a general class of two-step algorithms for heterogeneous treatment effect estimation in observational studies. First, we estimate marginal effects and treatment propensities to form an objective function that isolates the causal component of the signal. Then, we optimize this data-adaptive objective function. The proposed approach has several advantages over existing methods. From a practical perspective, our method is flexible and easy to use: in both steps, any loss-minimization method can be employed, such as penalized regression, deep neural networks, or boosting; moreover, these methods can be fine-tuned by cross-validation. Meanwhile, in the case of penalized kernel regression, we show that our method has a quasi-oracle property. Even when the pilot estimates for marginal effects and treatment propensities are not particularly accurate, we achieve the same error bounds as an oracle with prior knowledge of these two nuisance components. We implement variants of our approach based on penalized regression, kernel ridge regression, and boosting in a variety of simulation set-ups, and observe promising performance relative to existing baselines.},
  archive      = {J_BIOMET},
  author       = {Nie, X and Wager, S},
  doi          = {10.1093/biomet/asaa076},
  journal      = {Biometrika},
  number       = {2},
  pages        = {299-319},
  shortjournal = {Biometrika},
  title        = {Quasi-oracle estimation of heterogeneous treatment effects},
  volume       = {108},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Statistical properties of sketching algorithms.
<em>BIOMET</em>, <em>108</em>(2), 283–297. (<a
href="https://doi.org/10.1093/biomet/asaa062">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sketching is a probabilistic data compression technique that has been largely developed by the computer science community. Numerical operations on big datasets can be intolerably slow; sketching algorithms address this issue by generating a smaller surrogate dataset. Typically, inference proceeds on the compressed dataset. Sketching algorithms generally use random projections to compress the original dataset, and this stochastic generation process makes them amenable to statistical analysis. We argue that the sketched data can be modelled as a random sample, thus placing this family of data compression methods firmly within an inferential framework. In particular, we focus on the Gaussian, Hadamard and Clarkson–Woodruff sketches and their use in single-pass sketching algorithms for linear regression with huge samples. We explore the statistical properties of sketched regression algorithms and derive new distributional results for a large class of sketching estimators. A key result is a conditional central limit theorem for data-oblivious sketches. An important finding is that the best choice of sketching algorithm in terms of mean squared error is related to the signal-to-noise ratio in the source dataset. Finally, we demonstrate the theory and the limits of its applicability on two datasets.},
  archive      = {J_BIOMET},
  author       = {Ahfock, D C and Astle, W J and Richardson, S},
  doi          = {10.1093/biomet/asaa062},
  journal      = {Biometrika},
  number       = {2},
  pages        = {283-297},
  shortjournal = {Biometrika},
  title        = {Statistical properties of sketching algorithms},
  volume       = {108},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Approximating posteriors with high-dimensional nuisance
parameters via integrated rotated gaussian approximation.
<em>BIOMET</em>, <em>108</em>(2), 269–282. (<a
href="https://doi.org/10.1093/biomet/asaa068">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Posterior computation for high-dimensional data with many parameters can be challenging. This article focuses on a new method for approximating posterior distributions of a low- to moderate-dimensional parameter in the presence of a high-dimensional or otherwise computationally challenging nuisance parameter. The focus is on regression models and the key idea is to separate the likelihood into two components through a rotation. One component involves only the nuisance parameters, which can then be integrated out using a novel type of Gaussian approximation. We provide theory on approximation accuracy that holds for a broad class of forms of the nuisance component and priors. Applying our method to simulated and real datasets shows that it can outperform state-of-the-art posterior approximation approaches.},
  archive      = {J_BIOMET},
  author       = {van den Boom, W and Reeves, G and Dunson, D B},
  doi          = {10.1093/biomet/asaa068},
  journal      = {Biometrika},
  number       = {2},
  pages        = {269-282},
  shortjournal = {Biometrika},
  title        = {Approximating posteriors with high-dimensional nuisance parameters via integrated rotated gaussian approximation},
  volume       = {108},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A general interactive framework for false discovery rate
control under structural constraints. <em>BIOMET</em>, <em>108</em>(2),
253–267. (<a href="https://doi.org/10.1093/biomet/asaa064">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a general framework based on selectively traversed accumulation rules for interactive multiple testing with generic structural constraints on the rejection set. It combines accumulation tests from ordered multiple testing with data-carving ideas from post-selection inference, allowing highly flexible adaptation to generic structural information. Our procedure defines an interactive protocol for gradually pruning a candidate rejection set, beginning with the set of all hypotheses and shrinking the set with each step. By restricting the information at each step via a technique we call masking, our protocol enables interaction while controlling the false discovery rate in finite samples for any data-adaptive update rule that the analyst may choose. We suggest update rules for a variety of applications with complex structural constraints, demonstrate that selectively traversed accumulation rules perform well in problems ranging from convex region detection to false discovery rate control on directed acyclic graphs, and show how to extend the framework to regression problems where knockoff statistics are available in lieu of |$p$| -values.},
  archive      = {J_BIOMET},
  author       = {Lei, Lihua and Ramdas, Aaditya and Fithian, William},
  doi          = {10.1093/biomet/asaa064},
  journal      = {Biometrika},
  number       = {2},
  pages        = {253-267},
  shortjournal = {Biometrika},
  title        = {A general interactive framework for false discovery rate control under structural constraints},
  volume       = {108},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A likelihood analysis of quantile-matching transformations.
<em>BIOMET</em>, <em>108</em>(1), 247–251. (<a
href="https://doi.org/10.1093/biomet/asaa048">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quantile matching is a strictly monotone transformation that sends the observed response values to the quantiles of a given target distribution. A profile likelihood-based criterion is developed for comparing one target distribution with another in a linear-model setting.},
  archive      = {J_BIOMET},
  author       = {McCullagh, P and Tresoldi, M F},
  doi          = {10.1093/biomet/asaa048},
  journal      = {Biometrika},
  number       = {1},
  pages        = {247-251},
  shortjournal = {Biometrika},
  title        = {A likelihood analysis of quantile-matching transformations},
  volume       = {108},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Testing for measurement error in survey data analysis using
paradata. <em>BIOMET</em>, <em>108</em>(1), 239–246. (<a
href="https://doi.org/10.1093/biomet/asaa050">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Paradata refers to survey variables which are not of direct interest themselves, but are related to the quality of data on survey variables which are of interest. We focus on a categorical paradata variable, which reflects the presence of measurement error in a variable of interest. We propose a quasi-score test of the hypothesis of no measurement error bias in the estimation of regression coefficients under models for paradata. We also propose a regression-based test, analogous to a simple test proposed by Fuller for instrumental variables. The methods developed can take account of a complex sampling design. In an application with data from the British Household Panel Survey, all tests provide clear evidence of measurement bias in the estimated coefficient of gross pay. In a simulation study, all tests have rejection rates close to the nominal level under the null hypothesis; the quasi-score tests display more power than the regression-based test. The size of the quasi-score test is shown to be robust to some forms of misspecification of the paradata model, both by a theoretical argument and in findings of the simulation study.},
  archive      = {J_BIOMET},
  author       = {Da Silva, D N and Skinner, C J},
  doi          = {10.1093/biomet/asaa050},
  journal      = {Biometrika},
  number       = {1},
  pages        = {239-246},
  shortjournal = {Biometrika},
  title        = {Testing for measurement error in survey data analysis using paradata},
  volume       = {108},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Characterization of parameters with a mixed bias property.
<em>BIOMET</em>, <em>108</em>(1), 231–238. (<a
href="https://doi.org/10.1093/biomet/asaa054">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study a class of parameters with the so-called mixed bias property. For parameters with this property, the bias of the semiparametric efficient one-step estimator is equal to the mean of the product of the estimation errors of two nuisance functions. In nonparametric models, parameters with the mixed bias property admit so-called rate doubly robust estimators, i.e., estimators that are consistent and asymptotically normal when one succeeds in estimating both nuisance functions at sufficiently fast rates, with the possibility of trading off slower rates of convergence for the estimator of one of the nuisance functions against faster rates for the estimator of the other nuisance function. We show that the class of parameters with the mixed bias property strictly includes two recently studied classes of parameters which, in turn, include many parameters of interest in causal inference. We characterize the form of parameters with the mixed bias property and of their influence functions. Furthermore, we derive two functional loss functions, each being minimized at one of the two nuisance functions. These loss functions can be used to derive loss-based penalized estimators of the nuisance functions.},
  archive      = {J_BIOMET},
  author       = {Rotnitzky, A and Smucler, E and Robins, J M},
  doi          = {10.1093/biomet/asaa054},
  journal      = {Biometrika},
  number       = {1},
  pages        = {231-238},
  shortjournal = {Biometrika},
  title        = {Characterization of parameters with a mixed bias property},
  volume       = {108},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Event history analysis of dynamic networks. <em>BIOMET</em>,
<em>108</em>(1), 223–230. (<a
href="https://doi.org/10.1093/biomet/asaa045">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Statistical analysis on networks has received growing attention due to demand from various emerging applications. In dynamic networks, one of the key interests is to model the event history of time-stamped interactions among nodes. We model dynamic directed networks via multivariate counting processes. A pseudo partial likelihood approach is exploited to capture the network dependence structure. Asymptotic results are established. Numerical experiments are performed to demonstrate the effectiveness of our proposal.},
  archive      = {J_BIOMET},
  author       = {Sit, T and Ying, Z and Yu, Y},
  doi          = {10.1093/biomet/asaa045},
  journal      = {Biometrika},
  number       = {1},
  pages        = {223-230},
  shortjournal = {Biometrika},
  title        = {Event history analysis of dynamic networks},
  volume       = {108},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Jump or kink: On super-efficiency in segmented linear
regression breakpoint estimation. <em>BIOMET</em>, <em>108</em>(1),
215–222. (<a href="https://doi.org/10.1093/biomet/asaa049">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the problem of segmented linear regression with a single breakpoint, with the focus on estimating the location of the breakpoint. If |$n$| is the sample size, we show that the global minimax convergence rate for this problem in terms of the mean absolute error is |$O(n^{-1/3})$|⁠ . On the other hand, we demonstrate the construction of a super-efficient estimator that achieves the pointwise convergence rate of either |$O(n^{-1})$| or |$O(n^{-1/2})$| for every fixed parameter value, depending on whether the structural change is a jump or a kink. The implications of this example and a potential remedy are discussed.},
  archive      = {J_BIOMET},
  author       = {Chen, Yining},
  doi          = {10.1093/biomet/asaa049},
  journal      = {Biometrika},
  number       = {1},
  pages        = {215-222},
  shortjournal = {Biometrika},
  title        = {Jump or kink: On super-efficiency in segmented linear regression breakpoint estimation},
  volume       = {108},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Modelling temporal biomarkers with semiparametric nonlinear
dynamical systems. <em>BIOMET</em>, <em>108</em>(1), 199–214. (<a
href="https://doi.org/10.1093/biomet/asaa042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamical systems based on differential equations are useful for modelling the temporal evolution of biomarkers. Such systems can characterize the temporal patterns of biomarkers and inform the detection of interactions between biomarkers. Existing statistical methods for dynamical systems deal mostly with single time-course data based on a linear model or generalized additive model. Hence, they cannot adequately capture the complex interactions between biomarkers; nor can they take into account the heterogeneity between systems or subjects. In this article, we propose a semiparametric dynamical system based on multi-index models for multiple-subjects time-course data. Our model accounts for between-subject heterogeneity by incorporating system-level or subject-level covariates into the dynamical systems, and it allows for nonlinear relationships and interactions between the combined biomarkers and the temporal rate of each biomarker. For estimation and inference, we consider a two-step procedure based on integral equations from the proposed model. We propose an algorithm that iterates between estimation of the link function through splines and estimation of the index parameters, and which allows for regularization to achieve sparsity. We prove model identifiability and derive the asymptotic properties of the estimated model parameters. A benefit of our approach is the ability to pool information from multiple subjects to identify the interactions between biomarkers. We apply the method to analyse electroencephalogram data for patients affected by alcohol dependence. The results provide new insights into patients’ brain activities and demonstrate differential interaction patterns in patients compared to control subjects.},
  archive      = {J_BIOMET},
  author       = {Sun, Ming and Zeng, Donglin and Wang, Yuanjia},
  doi          = {10.1093/biomet/asaa042},
  journal      = {Biometrika},
  number       = {1},
  pages        = {199-214},
  shortjournal = {Biometrika},
  title        = {Modelling temporal biomarkers with semiparametric nonlinear dynamical systems},
  volume       = {108},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Heterogeneous individual risk modelling of recurrent events.
<em>BIOMET</em>, <em>108</em>(1), 183–198. (<a
href="https://doi.org/10.1093/biomet/asaa053">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Progression of chronic disease is often manifested by repeated occurrences of disease-related events over time. Delineating the heterogeneity in the risk of such recurrent events can provide valuable scientific insight for guiding customized disease management. We propose a new sensible measure of individual risk of recurrent events and present a dynamic modelling framework thereof, which accounts for both observed covariates and unobservable frailty. The proposed modelling requires no distributional specification of the unobservable frailty, while permitting exploration of the dynamic effects of the observed covariates. We develop estimation and inference procedures for the proposed model through a novel adaptation of the principle of conditional score. The asymptotic properties of the proposed estimator, including the uniform consistency and weak convergence, are established. Extensive simulation studies demonstrate satisfactory finite-sample performance of the proposed method. We illustrate the practical utility of the new method via an application to a diabetes clinical trial that explores the risk patterns of hypoglycemia in type 2 diabetes patients.},
  archive      = {J_BIOMET},
  author       = {Ma, Huijuan and Peng, Limin and Huang, Chiung-Yu and Fu, Haoda},
  doi          = {10.1093/biomet/asaa053},
  journal      = {Biometrika},
  number       = {1},
  pages        = {183-198},
  shortjournal = {Biometrika},
  title        = {Heterogeneous individual risk modelling of recurrent events},
  volume       = {108},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Functional regression on the manifold with contamination.
<em>BIOMET</em>, <em>108</em>(1), 167–181. (<a
href="https://doi.org/10.1093/biomet/asaa041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a new method for functional nonparametric regression with a predictor that resides on a finite-dimensional manifold, but is observable only in an infinite-dimensional space. Contamination of the predictor due to discrete or noisy measurements is also accounted for. By using functional local linear manifold smoothing, the proposed estimator enjoys a polynomial rate of convergence that adapts to the intrinsic manifold dimension and the contamination level. This is in contrast to the logarithmic convergence rate in the literature of functional nonparametric regression. We also observe a phase transition phenomenon related to the interplay between the manifold dimension and the contamination level. We demonstrate via simulated and real data examples that the proposed method has favourable numerical performance relative to existing commonly used methods.},
  archive      = {J_BIOMET},
  author       = {Lin, Zhenhua and Yao, Fang},
  doi          = {10.1093/biomet/asaa041},
  journal      = {Biometrika},
  number       = {1},
  pages        = {167-181},
  shortjournal = {Biometrika},
  title        = {Functional regression on the manifold with contamination},
  volume       = {108},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An asymptotic and empirical smoothing parameters selection
method for smoothing spline ANOVA models in large samples.
<em>BIOMET</em>, <em>108</em>(1), 149–166. (<a
href="https://doi.org/10.1093/biomet/asaa047">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large samples are generated routinely from various sources. Classic statistical models, such as smoothing spline ANOVA models, are not well equipped to analyse such large samples because of high computational costs. In particular, the daunting computational cost of selecting smoothing parameters renders smoothing spline ANOVA models impractical. In this article, we develop an asympirical, i.e., asymptotic and empirical, smoothing parameters selection method for smoothing spline ANOVA models in large samples. The idea of our approach is to use asymptotic analysis to show that the optimal smoothing parameter is a polynomial function of the sample size and an unknown constant. The unknown constant is then estimated through empirical subsample extrapolation. The proposed method significantly reduces the computational burden of selecting smoothing parameters in high-dimensional and large samples. We show that smoothing parameters chosen by the proposed method tend to the optimal smoothing parameters that minimize a specific risk function. In addition, the estimator based on the proposed smoothing parameters achieves the optimal convergence rate. Extensive simulation studies demonstrate the numerical advantage of the proposed method over competing methods in terms of relative efficacy and running time. In an application to molecular dynamics data containing nearly one million observations, the proposed method has the best prediction performance.},
  archive      = {J_BIOMET},
  author       = {Sun, Xiaoxiao and Zhong, Wenxuan and Ma, Ping},
  doi          = {10.1093/biomet/asaa047},
  journal      = {Biometrika},
  number       = {1},
  pages        = {149-166},
  shortjournal = {Biometrika},
  title        = {An asymptotic and empirical smoothing parameters selection method for smoothing spline ANOVA models in large samples},
  volume       = {108},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). High-dimensional empirical likelihood inference.
<em>BIOMET</em>, <em>108</em>(1), 127–147. (<a
href="https://doi.org/10.1093/biomet/asaa051">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High-dimensional statistical inference with general estimating equations is challenging and remains little explored. We study two problems in the area: confidence set estimation for multiple components of the model parameters, and model specifications tests. First, we propose to construct a new set of estimating equations such that the impact from estimating the high-dimensional nuisance parameters becomes asymptotically negligible. The new construction enables us to estimate a valid confidence region by empirical likelihood ratio. Second, we propose a test statistic as the maximum of the marginal empirical likelihood ratios to quantify data evidence against the model specification. Our theory establishes the validity of the proposed empirical likelihood approaches, accommodating over-identification and exponentially growing data dimensionality. Numerical studies demonstrate promising performance and potential practical benefits of the new methods.},
  archive      = {J_BIOMET},
  author       = {Chang, Jinyuan and Chen, Song Xi and Tang, Cheng Yong and Wu, Tong Tong},
  doi          = {10.1093/biomet/asaa051},
  journal      = {Biometrika},
  number       = {1},
  pages        = {127-147},
  shortjournal = {Biometrika},
  title        = {High-dimensional empirical likelihood inference},
  volume       = {108},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). High-quantile regression for tail-dependent time series.
<em>BIOMET</em>, <em>108</em>(1), 113–126. (<a
href="https://doi.org/10.1093/biomet/asaa046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quantile regression is a popular and powerful method for studying the effect of regressors on quantiles of a response distribution. However, existing results on quantile regression were mainly developed for cases in which the quantile level is fixed, and the data are often assumed to be independent. Motivated by recent applications, we consider the situation where (i) the quantile level is not fixed and can grow with the sample size to capture the tail phenomena, and (ii) the data are no longer independent, but collected as a time series that can exhibit serial dependence in both tail and non-tail regions. To study the asymptotic theory for high-quantile regression estimators in the time series setting, we introduce a tail adversarial stability condition, which had not previously been described, and show that it leads to an interpretable and convenient framework for obtaining limit theorems for time series that exhibit serial dependence in the tail region, but are not necessarily strongly mixing. Numerical experiments are conducted to illustrate the effect of tail dependence on high-quantile regression estimators, for which simply ignoring the tail dependence may yield misleading |$p$| -values.},
  archive      = {J_BIOMET},
  author       = {Zhang, Ting},
  doi          = {10.1093/biomet/asaa046},
  journal      = {Biometrika},
  number       = {1},
  pages        = {113-126},
  shortjournal = {Biometrika},
  title        = {High-quantile regression for tail-dependent time series},
  volume       = {108},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Optimal subsampling for quantile regression in big data.
<em>BIOMET</em>, <em>108</em>(1), 99–112. (<a
href="https://doi.org/10.1093/biomet/asaa043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We investigate optimal subsampling for quantile regression. We derive the asymptotic distribution of a general subsampling estimator and then derive two versions of optimal subsampling probabilities. One version minimizes the trace of the asymptotic variance-covariance matrix for a linearly transformed parameter estimator and the other minimizes that of the original parameter estimator. The former does not depend on the densities of the responses given covariates and is easy to implement. Algorithms based on optimal subsampling probabilities are proposed and asymptotic distributions, and the asymptotic optimality of the resulting estimators are established. Furthermore, we propose an iterative subsampling procedure based on the optimal subsampling probabilities in the linearly transformed parameter estimation which has great scalability to utilize available computational resources. In addition, this procedure yields standard errors for parameter estimators without estimating the densities of the responses given the covariates. We provide numerical examples based on both simulated and real data to illustrate the proposed method.},
  archive      = {J_BIOMET},
  author       = {Wang, Haiying and Ma, Yanyuan},
  doi          = {10.1093/biomet/asaa043},
  journal      = {Biometrika},
  number       = {1},
  pages        = {99-112},
  shortjournal = {Biometrika},
  title        = {Optimal subsampling for quantile regression in big data},
  volume       = {108},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Matrix-variate logistic regression with measurement error.
<em>BIOMET</em>, <em>108</em>(1), 83–97. (<a
href="https://doi.org/10.1093/biomet/asaa056">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Measurement error in covariates has been extensively studied in many conventional regression settings where covariate information is typically expressed in a vector form. However, there has been little work on error-prone matrix-variate data, which commonly arise from studies with imaging, spatial-temporal structures, etc. We consider analysis of error-contaminated matrix-variate data. We particularly focus on matrix-variate logistic measurement error models. We examine the biases induced from naive analysis which ignores measurement error in matrix-variate data. Two measurement error correction methods are developed to adjust for measurement error effects. The proposed methods are justified both theoretically and empirically. We analyse an electroencephalography dataset with the proposed methods.},
  archive      = {J_BIOMET},
  author       = {Fang, Junhan and Yi, Grace Y},
  doi          = {10.1093/biomet/asaa056},
  journal      = {Biometrika},
  number       = {1},
  pages        = {83-97},
  shortjournal = {Biometrika},
  title        = {Matrix-variate logistic regression with measurement error},
  volume       = {108},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Jeffreys-prior penalty, finiteness and shrinkage in
binomial-response generalized linear models. <em>BIOMET</em>,
<em>108</em>(1), 71–82. (<a
href="https://doi.org/10.1093/biomet/asaa052">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Penalization of the likelihood by Jeffreys’ invariant prior, or a positive power thereof, is shown to produce finite-valued maximum penalized likelihood estimates in a broad class of binomial generalized linear models. The class of models includes logistic regression, where the Jeffreys-prior penalty is known additionally to reduce the asymptotic bias of the maximum likelihood estimator, and models with other commonly used link functions, such as probit and log-log. Shrinkage towards equiprobability across observations, relative to the maximum likelihood estimator, is established theoretically and studied through illustrative examples. Some implications of finiteness and shrinkage for inference are discussed, particularly when inference is based on Wald-type procedures. A widely applicable procedure is developed for computation of maximum penalized likelihood estimates, by using repeated maximum likelihood fits with iteratively adjusted binomial responses and totals. These theoretical results and methods underpin the increasingly widespread use of reduced-bias and similarly penalized binomial regression models in many applied fields.},
  archive      = {J_BIOMET},
  author       = {Kosmidis, Ioannis and Firth, David},
  doi          = {10.1093/biomet/asaa052},
  journal      = {Biometrika},
  number       = {1},
  pages        = {71-82},
  shortjournal = {Biometrika},
  title        = {Jeffreys-prior penalty, finiteness and shrinkage in binomial-response generalized linear models},
  volume       = {108},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). In search of lost mixing time: Adaptive markov chain monte
carlo schemes for bayesian variable selection with very large
p. <em>BIOMET</em>, <em>108</em>(1), 53–69. (<a
href="https://doi.org/10.1093/biomet/asaa055">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The availability of datasets with large numbers of variables is rapidly increasing. The effective application of Bayesian variable selection methods for regression with these datasets has proved difficult since available Markov chain Monte Carlo methods do not perform well in typical problem sizes of interest. We propose new adaptive Markov chain Monte Carlo algorithms to address this shortcoming. The adaptive design of these algorithms exploits the observation that in large- |$p$|⁠ , small- |$n$| settings, the majority of the |$p$| variables will be approximately uncorrelated a posteriori. The algorithms adaptively build suitable nonlocal proposals that result in moves with squared jumping distance significantly larger than standard methods. Their performance is studied empirically in high-dimensional problems and speed-ups of up to four orders of magnitude are observed.},
  archive      = {J_BIOMET},
  author       = {Griffin, J E and Łatuszyński, K G and Steel, M F J},
  doi          = {10.1093/biomet/asaa055},
  journal      = {Biometrika},
  number       = {1},
  pages        = {53-69},
  shortjournal = {Biometrika},
  title        = {In search of lost mixing time: Adaptive markov chain monte carlo schemes for bayesian variable selection with very large p},
  volume       = {108},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Large-sample asymptotics of the pseudo-marginal method.
<em>BIOMET</em>, <em>108</em>(1), 37–51. (<a
href="https://doi.org/10.1093/biomet/asaa044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The pseudo-marginal algorithm is a variant of the Metropolis–Hastings algorithm which samples asymptotically from a probability distribution when it is only possible to estimate unbiasedly an unnormalized version of its density. Practically, one has to trade off the computational resources used to obtain this estimator against the asymptotic variances of the ergodic averages obtained by the pseudo-marginal algorithm. Recent works on optimizing this trade-off rely on some strong assumptions, which can cast doubts over their practical relevance. In particular, they all assume that the distribution of the difference between the log-density, and its estimate is independent of the parameter value at which it is evaluated. Under regularity conditions we show that as the number of data points tends to infinity, a space-rescaled version of the pseudo-marginal chain converges weakly to another pseudo-marginal chain for which this assumption indeed holds. A study of this limiting chain allows us to provide parameter dimension-dependent guidelines on how to optimally scale a normal random walk proposal, and the number of Monte Carlo samples for the pseudo-marginal method in the large-sample regime. These findings complement and validate currently available results.},
  archive      = {J_BIOMET},
  author       = {Schmon, S M and Deligiannidis, G and Doucet, A and Pitt, M K},
  doi          = {10.1093/biomet/asaa044},
  journal      = {Biometrika},
  number       = {1},
  pages        = {37-51},
  shortjournal = {Biometrika},
  title        = {Large-sample asymptotics of the pseudo-marginal method},
  volume       = {108},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Hypothesis testing for phylogenetic composition: A
minimum-cost flow perspective. <em>BIOMET</em>, <em>108</em>(1), 17–36.
(<a href="https://doi.org/10.1093/biomet/asaa061">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quantitative comparison of microbial composition from different populations is a fundamental task in various microbiome studies. We consider two-sample testing for microbial compositional data by leveraging phylogenetic information. Motivated by existing phylogenetic distances, we take a minimum-cost flow perspective to study such testing problems. We first show that multivariate analysis of variance with permutation using phylogenetic distances, one of the most commonly used methods in practice, is essentially a sum-of-squares type of test and has better power for dense alternatives. However, empirical evidence from real datasets suggests that the phylogenetic microbial composition difference between two populations is usually sparse. Motivated by this observation, we propose a new maximum type test, detector of active flow on a tree, and investigate its properties. We show that the proposed method is particularly powerful against sparse phylogenetic composition difference and enjoys certain optimality. The practical merit of the proposed method is demonstrated by simulation studies and an application to a human intestinal biopsy microbiome dataset on patients with ulcerative colitis.},
  archive      = {J_BIOMET},
  author       = {Wang, Shulei and Cai, T Tony and Li, Hongzhe},
  doi          = {10.1093/biomet/asaa061},
  journal      = {Biometrika},
  number       = {1},
  pages        = {17-36},
  shortjournal = {Biometrika},
  title        = {Hypothesis testing for phylogenetic composition: A minimum-cost flow perspective},
  volume       = {108},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The asymptotic distribution of modularity in weighted signed
networks. <em>BIOMET</em>, <em>108</em>(1), 1–16. (<a
href="https://doi.org/10.1093/biomet/asaa059">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modularity is a popular metric for quantifying the degree of community structure within a network. The distribution of the largest eigenvalue of a network’s edge weight or adjacency matrix is well studied and is frequently used as a substitute for modularity when performing statistical inference. However, we show that the largest eigenvalue and modularity are asymptotically uncorrelated, which suggests the need for inference directly on modularity itself when the network is large. To this end, we derive the asymptotic distribution of modularity in the case where the network’s edge weight matrix belongs to the Gaussian orthogonal ensemble, and study the statistical power of the corresponding test for community structure under some alternative models. We empirically explore universality extensions of the limiting distribution and demonstrate the accuracy of these asymptotic distributions through Type I error simulations. We also compare the empirical powers of the modularity-based tests and some existing methods. Our method is then used to test for the presence of community structure in two real data applications.},
  archive      = {J_BIOMET},
  author       = {Ma, Rong and Barnett, Ian},
  doi          = {10.1093/biomet/asaa059},
  journal      = {Biometrika},
  number       = {1},
  pages        = {1-16},
  shortjournal = {Biometrika},
  title        = {The asymptotic distribution of modularity in weighted signed networks},
  volume       = {108},
  year         = {2021},
}
</textarea>
</details></li>
</ul>

</body>
</html>
