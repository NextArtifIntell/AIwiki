<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>FROBT_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="frobt---411">FROBT - 411</h2>
<ul>
<li><details>
<summary>
(2021). Corrigendum: A socially adaptable framework for human-robot
interaction. <em>FROBT</em>, <em>8</em>, 812583. (<a
href="https://doi.org/10.3389/frobt.2021.812583">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Tanevska, Ana and Rea, Francesco and Sandini, Giulio and Cañamero, Lola and Sciutti, Alessandra},
  doi          = {10.3389/frobt.2021.812583},
  journal      = {Frontiers in Robotics and AI},
  month        = {12},
  pages        = {812583},
  shortjournal = {Front. Robot. AI},
  title        = {Corrigendum: A socially adaptable framework for human-robot interaction},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A multi-directional and agile academic knowledge transfer
strategy for healthcare technology. <em>FROBT</em>, <em>8</em>, 789827.
(<a href="https://doi.org/10.3389/frobt.2021.789827">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Technology, especially cognitive agents and robots, has significant potential to improve the healthcare system and patient care. However, innovation within academia seldomly finds its way into practice. At least in Germany, there is still a digitalization gap between academia and healthcare practice and little understanding of how healthcare facilities can successfully purchase, implement, and adopt new knowledge and technology. Therefore, the aim of this study is to develop a successful academic knowledge transfer strategy for healthcare technology. We conducted a qualitative study with academic staff working in higher education in Germany and professionals in their practice partner organizations. In 15 semi-structured interviews, we aimed to assess interviewees experiences with knowledge transfer, to identify perceived influencing factors, and to understand the key aspects of a successful knowledge transfer strategy. The Dynamic Knowledge Transfer Model by Wehn and Montalvo, 2018 was used for data analysis. Based on our findings, we suggest that a successful transfer strategy between academia and practice needs to be multi-directional and agile. Moreover, partners within the transfer need to be on equal terms about expected knowledge transfer project outcomes. Our proposed measures focus particularly on regular consultations and communication during and after the project proposal phase.},
  archive      = {J_FROBT},
  author       = {Klemme, Isabel and Richter, Birte and De Sabbata, Kevin and Wrede, Britta and Vollmer, Anna-Lisa},
  doi          = {10.3389/frobt.2021.789827},
  journal      = {Frontiers in Robotics and AI},
  month        = {12},
  pages        = {789827},
  shortjournal = {Front. Robot. AI},
  title        = {A multi-directional and agile academic knowledge transfer strategy for healthcare technology},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Robot as legal person: Electronic personhood in robotics and
artificial intelligence. <em>FROBT</em>, <em>8</em>, 789327. (<a
href="https://doi.org/10.3389/frobt.2021.789327">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper seeks to investigate the proposal to create a legal (electronic) personhood for robots with artificial intelligence based on the European Parliament resolution with recommendations on Civil Law and Robotics. To this end, we highlight the various risks and problems present in this type of initiative, especially in view of the current trend of expanding legal subjectivity in various jurisdictions. In addition to an anthropomorphic rhetoric, we can observe the prevalence of a pragmatic line that seeks to be guided, mainly, by the model of corporations, without taking into account, however, problems present in the process of embodiment of companies and the particular function of the term legal person in the grammar of Law.},
  archive      = {J_FROBT},
  author       = {Avila Negri, Sergio M. C.},
  doi          = {10.3389/frobt.2021.789327},
  journal      = {Frontiers in Robotics and AI},
  month        = {12},
  pages        = {789327},
  shortjournal = {Front. Robot. AI},
  title        = {Robot as legal person: Electronic personhood in robotics and artificial intelligence},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Rigid–soft interactive design of a lobster-inspired finger
surface for enhanced grasping underwater. <em>FROBT</em>, <em>8</em>,
787187. (<a href="https://doi.org/10.3389/frobt.2021.787187">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bio-inspirations from soft-bodied animals provide a rich design source for soft robots, yet limited literature explored the potential enhancement from rigid-bodied ones. This paper draws inspiration from the tooth profiles of the rigid claws of the Boston Lobster, aiming at an enhanced soft finger surface for underwater grasping using an iterative design process. The lobsters distinguish themselves from other marine animals with a pair of claws capable of dexterous object manipulation both on land and underwater. We proposed a 3-stage design iteration process that involves raw imitation, design parametric exploration, and bionic parametric exploitation on the original tooth profiles on the claws of the Boston Lobster. Eventually, 7 finger surface designs were generated and fabricated with soft silicone. We validated each design stage through many vision-based robotic grasping attempts against selected objects from the Evolved Grasping Analysis Dataset (EGAD). Over 14,000 grasp attempts were accumulated on land (71.4%) and underwater (28.6%), where we selected the optimal design through an on-land experiment and further tested its capability underwater. As a result, we observed an 18.2% improvement in grasping success rate at most from a resultant bionic finger surface design, compared with those without the surface, and a 10.4% improvement at most compared with the validation design from the previous literature. Results from this paper are relevant and consistent with the bioresearch earlier in 1911, showing the value of bionics. The results indicate the capability and competence of the optimal bionic finger surface design in an amphibious environment, which can contribute to future research in enhanced underwater grasping using soft robots.},
  archive      = {J_FROBT},
  author       = {Jiang , Haiyang and Han , Xudong and Jing, Yonglin and Guo , Ning and Wan , Fang and Song , Chaoyang},
  doi          = {10.3389/frobt.2021.787187},
  journal      = {Frontiers in Robotics and AI},
  month        = {12},
  pages        = {787187},
  shortjournal = {Front. Robot. AI},
  title        = {Rigid–Soft interactive design of a lobster-inspired finger surface for enhanced grasping underwater},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Editorial: Current trends in image processing and pattern
recognition. <em>FROBT</em>, <em>8</em>, 785075. (<a
href="https://doi.org/10.3389/frobt.2021.785075">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Santosh, KC},
  doi          = {10.3389/frobt.2021.785075},
  journal      = {Frontiers in Robotics and AI},
  month        = {12},
  pages        = {785075},
  shortjournal = {Front. Robot. AI},
  title        = {Editorial: Current trends in image processing and pattern recognition},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Local vs. Avatar robot: Performance and perceived workload
of service encounters in public space. <em>FROBT</em>, <em>8</em>,
778753. (<a href="https://doi.org/10.3389/frobt.2021.778753">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, the demand for remote services has increased with concerns regarding the spread of infectious diseases and employees’ quality of life. Many attempts have been made to enable store staff to provide various services remotely via avatars displayed to on-site customers. However, the workload required on the part of service staff by the emerging new work style of operating avatar robots remains a concern. No study has compared the performance and perceived workload of the same staff working locally versus remotely via an avatar. In this study, we conducted an experiment to identify differences between the performance of in-person services and remote work through an avatar robot in an actual public space. The results showed that there were significant differences in the partial performance between working via an avatar and working locally, and we could not find significant difference in the overall performance. On the other hand, the perceived workload was significantly lower when the avatar robot was used. We also found that customers reacted differently to the robots and to the in-person participants. In addition, the workload perceived by operators in the robotic task was correlated with their personality and experience. To the best of our knowledge, this study is the first investigation of both performance and workload in remote customer service through robotic avatars, and it has important implications for the implementation of avatar robots in service settings.},
  archive      = {J_FROBT},
  author       = {Baba, Jun and Song, Sichao and Nakanishi, Junya and Yoshikawa, Yuichiro and Ishiguro, Hiroshi},
  doi          = {10.3389/frobt.2021.778753},
  journal      = {Frontiers in Robotics and AI},
  month        = {12},
  pages        = {778753},
  shortjournal = {Front. Robot. AI},
  title        = {Local vs. avatar robot: Performance and perceived workload of service encounters in public space},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Detection of foreign bodies in soft foods employing tactile
image sensor. <em>FROBT</em>, <em>8</em>, 774080. (<a
href="https://doi.org/10.3389/frobt.2021.774080">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the inspection work involving foodstuffs in food factories, there are cases where people not only visually inspect foodstuffs, but must also physically touch foodstuffs with their hands to find foreign or undesirable objects mixed in the product. To contribute to the automation of the inspection process, this paper proposes a method for detecting foreign objects in food based on differences in hardness using a camera-based tactile image sensor. Because the foreign objects to be detected are often small, the tactile sensor requires a high spatial resolution. In addition, inspection work in food factories requires a sufficient inspection speed. The proposed cylindrical tactile image sensor meets these requirements because it can efficiently acquire high-resolution tactile images with a camera mounted inside while rolling the cylindrical sensor surface over the target object. By analyzing the images obtained from the tactile image sensor, we detected the presence of foreign objects and their locations. By using a reflective membrane-type sensor surface with high sensitivity, small and hard foreign bodies of sub-millimeter size mixed in with soft food were successfully detected. The effectiveness of the proposed method was confirmed through experiments to detect shell fragments left on the surface of raw shrimp and bones left in fish fillets.},
  archive      = {J_FROBT},
  author       = {Shimonomura, Kazuhiro and Chang, Tinghsuan and Murata, Tomomi},
  doi          = {10.3389/frobt.2021.774080},
  journal      = {Frontiers in Robotics and AI},
  month        = {12},
  pages        = {774080},
  shortjournal = {Front. Robot. AI},
  title        = {Detection of foreign bodies in soft foods employing tactile image sensor},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Control of thruster-assisted, bipedal legged locomotion of
the harpy robot. <em>FROBT</em>, <em>8</em>, 770514. (<a
href="https://doi.org/10.3389/frobt.2021.770514">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fast constraint satisfaction, frontal dynamics stabilization, and avoiding fallovers in dynamic, bipedal walkers can be pretty challenging. The challenges include underactuation, vulnerability to external perturbations, and high computational complexity that arise when accounting for the system full-dynamics and environmental interactions. In this work, we study the potential roles of thrusters in addressing some of these locomotion challenges in bipedal robotics. We will introduce a thruster-assisted bipedal robot called Harpy. We will capitalize on Harpy’s unique design to propose an optimization-free approach to satisfy gait feasibility conditions. In this thruster-assisted legged locomotion, the reference trajectories can be manipulated to fulfill constraints brought on by ground contact and those prescribed for states and inputs. Unintended changes to the trajectories, especially those optimized to produce periodic orbits, can adversely affect gait stability and hybrid invariance. We will show our approach can still guarantee stability and hybrid invariance of the gaits by employing the thrusters in Harpy. We will also show that the thrusters can be leveraged to robustify the gaits by dodging fallovers or jumping over large obstacles.},
  archive      = {J_FROBT},
  author       = {Dangol, Pravin and Sihite, Eric and Ramezani, Alireza},
  doi          = {10.3389/frobt.2021.770514},
  journal      = {Frontiers in Robotics and AI},
  month        = {12},
  pages        = {770514},
  shortjournal = {Front. Robot. AI},
  title        = {Control of thruster-assisted, bipedal legged locomotion of the harpy robot},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Speculating about robot moral standing: On the constitution
of social robots as objects of governance. <em>FROBT</em>, <em>8</em>,
769349. (<a href="https://doi.org/10.3389/frobt.2021.769349">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, the governance of robotic technologies has become an important topic in policy-making contexts. The many potential applications and roles of robots in combination with steady advances in their uptake within society are expected to cause various unprecedented issues, which in many cases will increase the demand for new policy measures. One of the major issues is the way in which societies will address potential changes in the moral and legal status of autonomous social robots. Robot standing is an important concept that aims to understand and elaborate on such changes in robots’ status. This paper explores the concept of robot standing as a useful idea that can assist in the anticipatory governance of social robots. However, at the same time, the concept necessarily involves forms of speculative thinking, as it is anticipating a future that has not yet fully arrived. This paper elaborates on how such speculative engagement with the potential of technology represents an important point of discussion in the critical study of technology more generally. The paper then situates social robotics in the context of anticipatory technology governance by emphasizing the idea that robots are currently in the process of becoming constituted as objects of governance. Subsequently, it explains how specifically a speculative concept like robot standing can be of value in this process.},
  archive      = {J_FROBT},
  author       = {De Pagter, Jesse},
  doi          = {10.3389/frobt.2021.769349},
  journal      = {Frontiers in Robotics and AI},
  month        = {12},
  pages        = {769349},
  shortjournal = {Front. Robot. AI},
  title        = {Speculating about robot moral standing: On the constitution of social robots as objects of governance},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A modular digital twinning framework for safety assurance of
collaborative robotics. <em>FROBT</em>, <em>8</em>, 758099. (<a
href="https://doi.org/10.3389/frobt.2021.758099">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Digital twins offer a unique opportunity to design, test, deploy, monitor, and control real-world robotic processes. In this paper we present a novel, modular digital twinning framework developed for the investigation of safety within collaborative robotic manufacturing processes. The modular architecture supports scalable representations of user-defined cyber-physical environments, and tools for safety analysis and control. This versatile research tool facilitates the creation of mixed environments of Digital Models, Digital Shadows, and Digital Twins, whilst standardising communication and physical system representation across different hardware platforms. The framework is demonstrated as applied to an industrial case-study focused on the safety assurance of a collaborative robotic manufacturing process. We describe the creation of a digital twin scenario, consisting of individual digital twins of entities in the manufacturing case study, and the application of a synthesised safety controller from our wider work. We show how the framework is able to provide adequate evidence to virtually assess safety claims made against the safety controller using a supporting validation module and testing strategy. The implementation, evidence and safety investigation is presented and discussed, raising exciting possibilities for the use of digital twins in robotic safety assurance.},
  archive      = {J_FROBT},
  author       = {Douthwaite, J.A. and Lesage, B. and Gleirscher, M. and Calinescu, R. and Aitken, J. M. and Alexander, R. and Law, J.},
  doi          = {10.3389/frobt.2021.758099},
  journal      = {Frontiers in Robotics and AI},
  month        = {12},
  pages        = {758099},
  shortjournal = {Front. Robot. AI},
  title        = {A modular digital twinning framework for safety assurance of collaborative robotics},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Teleoperation and visualization interfaces for remote
intervention in space. <em>FROBT</em>, <em>8</em>, 747917. (<a
href="https://doi.org/10.3389/frobt.2021.747917">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Approaches to robotic manufacturing, assembly, and servicing of in-space assets range from autonomous operation to direct teleoperation, with many forms of semi-autonomous teleoperation in between. Because most approaches require one or more human operators at some level, it is important to explore the control and visualization interfaces available to those operators, taking into account the challenges due to significant telemetry time delay. We consider one motivating application of remote teleoperation, which is ground-based control of a robot on-orbit for satellite servicing. This paper presents a model-based architecture that: 1) improves visualization and situation awareness, 2) enables more effective human/robot interaction and control, and 3) detects task failures based on anomalous sensor feedback. We illustrate elements of the architecture by drawing on 10 years of our research in this area. The paper further reports the results of several multi-user experiments to evaluate the model-based architecture, on ground-based test platforms, for satellite servicing tasks subject to round-trip communication latencies of several seconds. The most significant performance gains were obtained by enhancing the operators’ situation awareness via improved visualization and by enabling them to precisely specify intended motion. In contrast, changes to the control interface, including model-mediated control or an immersive 3D environment, often reduced the reported task load but did not significantly improve task performance. Considering the challenges of fully autonomous intervention, we expect that some form of teleoperation will continue to be necessary for robotic in-situ servicing, assembly, and manufacturing tasks for the foreseeable future. We propose that effective teleoperation can be enabled by modeling the remote environment, providing operators with a fused view of the real environment and virtual model, and incorporating interfaces and control strategies that enable interactive planning, precise operation, and prompt detection of errors.},
  archive      = {J_FROBT},
  author       = {Kazanzides, Peter and Vagvolgyi, Balazs P. and Pryor, Will and Deguet, Anton and Leonard, Simon and Whitcomb, Louis L.},
  doi          = {10.3389/frobt.2021.747917},
  journal      = {Frontiers in Robotics and AI},
  month        = {12},
  pages        = {747917},
  shortjournal = {Front. Robot. AI},
  title        = {Teleoperation and visualization interfaces for remote intervention in space},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Review on patient-cooperative control strategies for
upper-limb rehabilitation exoskeletons. <em>FROBT</em>, <em>8</em>,
745018. (<a href="https://doi.org/10.3389/frobt.2021.745018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Technology-supported rehabilitation therapy for neurological patients has gained increasing interest since the last decades. The literature agrees that the goal of robots should be to induce motor plasticity in subjects undergoing rehabilitation treatment by providing the patients with repetitive, intensive, and task-oriented treatment. As a key element, robot controllers should adapt to patients’ status and recovery stage. Thus, the design of effective training modalities and their hardware implementation play a crucial role in robot-assisted rehabilitation and strongly influence the treatment outcome. The objective of this paper is to provide a multi-disciplinary vision of patient-cooperative control strategies for upper-limb rehabilitation exoskeletons to help researchers bridge the gap between human motor control aspects, desired rehabilitation training modalities, and their hardware implementations. To this aim, we propose a three-level classification based on 1) “high-level” training modalities, 2) “low-level” control strategies, and 3) “hardware-level” implementation. Then, we provide examples of literature upper-limb exoskeletons to show how the three levels of implementation have been combined to obtain a given high-level behavior, which is specifically designed to promote motor relearning during the rehabilitation treatment. Finally, we emphasize the need for the development of compliant control strategies, based on the collaboration between the exoskeleton and the wearer, we report the key findings to promote the desired physical human-robot interaction for neurorehabilitation, and we provide insights and suggestions for future works.},
  archive      = {J_FROBT},
  author       = {Dalla Gasperina, Stefano and Roveda, Loris and Pedrocchi, Alessandra and Braghin, Francesco and Gandolla, Marta},
  doi          = {10.3389/frobt.2021.745018},
  journal      = {Frontiers in Robotics and AI},
  month        = {12},
  pages        = {745018},
  shortjournal = {Front. Robot. AI},
  title        = {Review on patient-cooperative control strategies for upper-limb rehabilitation exoskeletons},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Sensing deformation in vacuum driven foam-based actuator via
inductive method. <em>FROBT</em>, <em>8</em>, 742885. (<a
href="https://doi.org/10.3389/frobt.2021.742885">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Perception in soft robotics is crucial to allow a safe interaction to effectively explore the environment. Despite the inherent capabilities of soft materials, embedding reliable sensing in soft actuators or robots could introduce constraints in the overall design (e.g., loss of deformability, undesired trajectories, etc.) or reduce their compliant characteristics. Consequently, an adequate stiffness for both sensor and actuator becomes a crucial design parameter. In particular, for sensing the deformation related to actuation motion, sensing and actuating strategies must work in full mechanical synergy. In this view, an inductive sensing solution is presented, exploiting open-cell foam and a copper (Cu) wire in an Inductive Foam Sensor (IFS). Due to entangled air cells high deformability is enabled upon vacuum pressure, and proprioceptive information is provided. The IFS is then successfully integrated into the earlier developed Ultralight Hybrid Pneumatic Artificial Muscle (UH-PAM), which encases an elastomeric bellow skin and plastic rings. Such sensorized UH-PAM (SUH-PAM) is capable of a high contraction ratio (54% upon −80 kPa), while the inductive sensing shows a high sensitivity of 0.01031/1% and a hysteresis of 5.35%, with an average error of 1.85%, respectively. In order to implement a robust feedback control system, an adaptable proportional sliding mode control is presented. As a result, the SUH-PAM motion can be controlled to the mm-scale, with an RMSE of 0.925 mm, and high robustness against disturbances is demonstrated.},
  archive      = {J_FROBT},
  author       = {Joe, Seonggun and Wang, Hongbo and Totaro, Massimo and Beccai, Lucia},
  doi          = {10.3389/frobt.2021.742885},
  journal      = {Frontiers in Robotics and AI},
  month        = {12},
  pages        = {742885},
  shortjournal = {Front. Robot. AI},
  title        = {Sensing deformation in vacuum driven foam-based actuator via inductive method},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A human gesture mapping method to control a multi‐functional
hand for robot‐assisted laparoscopic surgery: The MUSHA case.
<em>FROBT</em>, <em>8</em>, 741807. (<a
href="https://doi.org/10.3389/frobt.2021.741807">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work presents a novel technique to control multi-functional hand for robot-assisted laparoscopic surgery. We tested the technique using the MUSHA multi-functional hand, a robot-aided minimally invasive surgery tool with more degrees of freedom than the standard commercial end-effector of the da Vinci robot. Extra degrees of freedom require the development of a proper control strategy to guarantee high performance and avoid an increasing complexity of control consoles. However, developing reliable control algorithms while reducing the control side’s mechanical complexity is still an open challenge. In the proposed solution, we present a control strategy that projects the human hand motions into the robot actuation space. The human hand motions are tracked by a LeapMotion camera and mapped into the actuation space of the virtualized end-effector. The effectiveness of the proposed method was evaluated in a twofold manner. Firstly, we verified the Lyapunov stability of the algorithm, then an user study with 10 subjects assessed the intuitiveness and usability of the system.},
  archive      = {J_FROBT},
  author       = {Ficuciello, Fanny and Villani, Alberto and Lisini Baldi, Tommaso and Prattichizzo, Domenico},
  doi          = {10.3389/frobt.2021.741807},
  journal      = {Frontiers in Robotics and AI},
  month        = {12},
  pages        = {741807},
  shortjournal = {Front. Robot. AI},
  title        = {A human gesture mapping method to control a Multi‐Functional hand for Robot‐Assisted laparoscopic surgery: The MUSHA case},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Virtual energy management for physical energy savings in a
legged robot hopping on granular media. <em>FROBT</em>, <em>8</em>,
740927. (<a href="https://doi.org/10.3389/frobt.2021.740927">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We discuss an active damping controller to reduce the energetic cost of a single step or jump of dynamic locomotion without changing the morphology of the robot. The active damping controller adds virtual damping to a virtual leg spring created by direct-drive motors through the robot’s leg linkage. The virtual damping added is proportional to the intrusion velocity of the robot’s foot, slowing the foot’s intrusion, and thus the rate at which energy is transferred to and dissipated by the ground. In this work, we use a combination of simulations and physical experiments in a controlled granular media bed with a single-leg robot to show that the active damping controller reduces the cost of transport compared with a naive compression-extension controller under various conditions.},
  archive      = {J_FROBT},
  author       = {Roberts , Sonia F. and Koditschek, Daniel E.},
  doi          = {10.3389/frobt.2021.740927},
  journal      = {Frontiers in Robotics and AI},
  month        = {12},
  pages        = {740927},
  shortjournal = {Front. Robot. AI},
  title        = {Virtual energy management for physical energy savings in a legged robot hopping on granular media},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Safe model-based reinforcement learning for systems with
parametric uncertainties. <em>FROBT</em>, <em>8</em>, 733104. (<a
href="https://doi.org/10.3389/frobt.2021.733104">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reinforcement learning has been established over the past decade as an effective tool to find optimal control policies for dynamical systems, with recent focus on approaches that guarantee safety during the learning and/or execution phases. In general, safety guarantees are critical in reinforcement learning when the system is safety-critical and/or task restarts are not practically feasible. In optimal control theory, safety requirements are often expressed in terms of state and/or control constraints. In recent years, reinforcement learning approaches that rely on persistent excitation have been combined with a barrier transformation to learn the optimal control policies under state constraints. To soften the excitation requirements, model-based reinforcement learning methods that rely on exact model knowledge have also been integrated with the barrier transformation framework. The objective of this paper is to develop safe reinforcement learning method for deterministic nonlinear systems, with parametric uncertainties in the model, to learn approximate constrained optimal policies without relying on stringent excitation conditions. To that end, a model-based reinforcement learning technique that utilizes a novel filtered concurrent learning method, along with a barrier transformation, is developed in this paper to realize simultaneous learning of unknown model parameters and approximate optimal state-constrained control policies for safety-critical systems.},
  archive      = {J_FROBT},
  author       = {Mahmud, S. M. Nahid and Nivison, Scott A. and Bell, Zachary I. and Kamalapurkar, Rushikesh},
  doi          = {10.3389/frobt.2021.733104},
  journal      = {Frontiers in Robotics and AI},
  month        = {12},
  pages        = {733104},
  shortjournal = {Front. Robot. AI},
  title        = {Safe model-based reinforcement learning for systems with parametric uncertainties},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multimodal representation learning for place recognition
using deep hebbian predictive coding. <em>FROBT</em>, <em>8</em>,
732023. (<a href="https://doi.org/10.3389/frobt.2021.732023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recognising familiar places is a competence required in many engineering applications that interact with the real world such as robot navigation. Combining information from different sensory sources promotes robustness and accuracy of place recognition. However, mismatch in data registration, dimensionality, and timing between modalities remain challenging problems in multisensory place recognition. Spurious data generated by sensor drop-out in multisensory environments is particularly problematic and often resolved through adhoc and brittle solutions. An effective approach to these problems is demonstrated by animals as they gracefully move through the world. Therefore, we take a neuro-ethological approach by adopting self-supervised representation learning based on a neuroscientific model of visual cortex known as predictive coding. We demonstrate how this parsimonious network algorithm which is trained using a local learning rule can be extended to combine visual and tactile sensory cues from a biomimetic robot as it naturally explores a visually aliased environment. The place recognition performance obtained using joint latent representations generated by the network is significantly better than contemporary representation learning techniques. Further, we see evidence of improved robustness at place recognition in face of unimodal sensor drop-out. The proposed multimodal deep predictive coding algorithm presented is also linearly extensible to accommodate more than two sensory modalities, thereby providing an intriguing example of the value of neuro-biologically plausible representation learning for multimodal navigation.},
  archive      = {J_FROBT},
  author       = {Pearson, Martin J. and Dora, Shirin and Struckmeier, Oliver and Knowles, Thomas C. and Mitchinson, Ben and Tiwari, Kshitij and Kyrki, Ville and Bohte, Sander and Pennartz, Cyriel M.A.},
  doi          = {10.3389/frobt.2021.732023},
  journal      = {Frontiers in Robotics and AI},
  month        = {12},
  pages        = {732023},
  shortjournal = {Front. Robot. AI},
  title        = {Multimodal representation learning for place recognition using deep hebbian predictive coding},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). BALLU2: A safe and affordable buoyancy assisted biped.
<em>FROBT</em>, <em>8</em>, 730323. (<a
href="https://doi.org/10.3389/frobt.2021.730323">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work presents the first full disclosure of BALLU, Buoyancy Assisted Lightweight Legged Unit, and describes the advantages and challenges of its concept, the hardware design of a new implementation (BALLU2), a motion analysis, and a data-driven walking controller. BALLU is a robot that never falls down due to the buoyancy provided by a set of helium balloons attached to the lightweight body, which solves many issues that hinder current robots from operating close to humans. The advantages gained also lead to the platform’s distinct difficulties caused by severe nonlinearities and external forces such as buoyancy and drag. The paper describes the nonconventional characteristics of BALLU as a legged robot and then gives an analysis of its unique behavior. Based on the analysis, a data-driven approach is proposed to achieve non-teleoperated walking: a statistical process using Spearman Correlation Coefficient is proposed to form low-dimensional state vectors from the simulation data, and an artificial neural network-based controller is trained on the same data. The controller is tested both on simulation and on real-world hardware. Its performance is assessed by observing the robot’s limit cycles and trajectories in the Cartesian coordinate. The controller generates periodic walking sequences in simulation as well as on the real-world robot even without additional transfer learning. It is also shown that the controller can deal with unseen conditions during the training phase. The resulting behavior not only shows the robustness of the controller but also implies that the proposed statistical process effectively extracts a state vector that is low-dimensional yet contains the essential information of the high-dimensional dynamics of BALLU’s walking.},
  archive      = {J_FROBT},
  author       = {Chae, Hosik and Ahn, Min Sung and Noh, Donghun and Nam, Hyunwoo and Hong, Dennis},
  doi          = {10.3389/frobt.2021.730323},
  journal      = {Frontiers in Robotics and AI},
  month        = {12},
  pages        = {730323},
  shortjournal = {Front. Robot. AI},
  title        = {BALLU2: A safe and affordable buoyancy assisted biped},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Rapidly learning generalizable and robot-agnostic tool-use
skills for a wide range of tasks. <em>FROBT</em>, <em>8</em>, 726463.
(<a href="https://doi.org/10.3389/frobt.2021.726463">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many real-world applications require robots to use tools. However, robots lack the skills necessary to learn and perform many essential tool-use tasks. To this end, we present the TRansferrIng Skilled Tool Use Acquired Rapidly (TRI-STAR) framework for task-general robot tool use. TRI-STAR has three primary components: 1) the ability to learn and apply tool-use skills to a wide variety of tasks from a minimal number of training demonstrations, 2) the ability to generalize learned skills to other tools and manipulated objects, and 3) the ability to transfer learned skills to other robots. These capabilities are enabled by TRI-STAR’s task-oriented approach, which identifies and leverages structural task knowledge through the use of our goal-based task taxonomy. We demonstrate this framework with seven tasks that impose distinct requirements on the usages of the tools, six of which were each performed on three physical robots with varying kinematic configurations. Our results demonstrate that TRI-STAR can learn effective tool-use skills from only 20 training demonstrations. In addition, our framework generalizes tool-use skills to morphologically distinct objects and transfers them to new platforms, with minor performance degradation.},
  archive      = {J_FROBT},
  author       = {Qin, Meiying and Brawer, Jake and Scassellati, Brian},
  doi          = {10.3389/frobt.2021.726463},
  journal      = {Frontiers in Robotics and AI},
  month        = {12},
  pages        = {726463},
  shortjournal = {Front. Robot. AI},
  title        = {Rapidly learning generalizable and robot-agnostic tool-use skills for a wide range of tasks},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Modeling a controlled-floating space robot for in-space
services: A beginner’s tutorial. <em>FROBT</em>, <em>8</em>, 725333. (<a
href="https://doi.org/10.3389/frobt.2021.725333">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ground-based applications of robotics and autonomous systems (RASs) are fast advancing, and there is a growing appetite for developing cost-effective RAS solutions for in situ servicing, debris removal, manufacturing, and assembly missions. An orbital space robot, that is, a spacecraft mounted with one or more robotic manipulators, is an inevitable system for a range of future in-orbit services. However, various practical challenges make controlling a space robot extremely difficult compared with its terrestrial counterpart. The state of the art of modeling the kinematics and dynamics of a space robot, operating in the free-flying and free-floating modes, has been well studied by researchers. However, these two modes of operation have various shortcomings, which can be overcome by operating the space robot in the controlled-floating mode. This tutorial article aims to address the knowledge gap in modeling complex space robots operating in the controlled-floating mode and under perturbed conditions. The novel research contribution of this article is the refined dynamic model of a chaser space robot, derived with respect to the moving target while accounting for the internal perturbations due to constantly changing the center of mass, the inertial matrix, Coriolis, and centrifugal terms of the coupled system; it also accounts for the external environmental disturbances. The nonlinear model presented accurately represents the multibody coupled dynamics of a space robot, which is pivotal for precise pose control. Simulation results presented demonstrate the accuracy of the model for closed-loop control. In addition to the theoretical contributions in mathematical modeling, this article also offers a commercially viable solution for a wide range of in-orbit missions.},
  archive      = {J_FROBT},
  author       = {Seddaoui, Asma and Saaj, Chakravarthini Mini and Nair, Manu Harikrishnan},
  doi          = {10.3389/frobt.2021.725333},
  journal      = {Frontiers in Robotics and AI},
  month        = {12},
  pages        = {725333},
  shortjournal = {Front. Robot. AI},
  title        = {Modeling a controlled-floating space robot for in-space services: A beginner’s tutorial},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Aerial flight paths for communication. <em>FROBT</em>,
<em>8</em>, 719154. (<a
href="https://doi.org/10.3389/frobt.2021.719154">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article presents an understanding of naive users’ perception of the communicative nature of unmanned aerial vehicle (UAV) motions refined through an iterative series of studies. This includes both what people believe the UAV is trying to communicate, and how they expect to respond through physical action or emotional response. Previous work in this area prioritized gestures from participants to the vehicle or augmenting the vehicle with additional communication modalities, rather than communicating without clear definitions of the states attempting to be conveyed. In an attempt to elicit more concrete states and better understand specific motion perception, this work includes multiple iterations of state creation, flight path refinement, and label assignment. The lessons learned in this work will be applicable broadly to those interested in defining flight paths, and within the human-robot interaction community as a whole, as it provides a base for those seeking to communicate using non-anthropomorphic robots. We found that the Negative Attitudes towards Robots Scale (NARS) can be an indicator of how a person is likely to react to a UAV, the emotional content they are likely to perceive from a message being conveyed, and it is an indicator for the personality characteristics they are likely to project upon the UAV. We also see that people commonly associate motions from other non-verbal communication situations onto UAVs. Flight specific recommendations are to use a dynamic retreating motion from a person to encourage following, use a perpendicular motion to their field of view for blocking, simple descending motion for landing, and to use either no motion or large altitude changes to encourage watching. Overall, this research explores the communication from the UAV to the bystander through its motion, to see how people respond physically and emotionally.},
  archive      = {J_FROBT},
  author       = {Bevins, Alisha and Duncan, Brittany A.},
  doi          = {10.3389/frobt.2021.719154},
  journal      = {Frontiers in Robotics and AI},
  month        = {12},
  pages        = {719154},
  shortjournal = {Front. Robot. AI},
  title        = {Aerial flight paths for communication},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). LEADOR: A method for end-to-end participatory design of
autonomous social robots. <em>FROBT</em>, <em>8</em>, 704119. (<a
href="https://doi.org/10.3389/frobt.2021.704119">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Participatory design (PD) has been used to good success in human-robot interaction (HRI) but typically remains limited to the early phases of development, with subsequent robot behaviours then being hardcoded by engineers or utilised in Wizard-of-Oz (WoZ) systems that rarely achieve autonomy. In this article, we present LEADOR (Led-by-Experts Automation and Design Of Robots), an end-to-end PD methodology for domain expert co-design, automation, and evaluation of social robot behaviour. This method starts with typical PD, working with the domain expert(s) to co-design the interaction specifications and state and action space of the robot. It then replaces the traditional offline programming or WoZ phase by an in situ and online teaching phase where the domain expert can live-program or teach the robot how to behave whilst being embedded in the interaction context. We point out that this live teaching phase can be best achieved by adding a learning component to a WoZ setup, which captures implicit knowledge of experts, as they intuitively respond to the dynamics of the situation. The robot then progressively learns an appropriate, expert-approved policy, ultimately leading to full autonomy, even in sensitive and/or ill-defined environments. However, LEADOR is agnostic to the exact technical approach used to facilitate this learning process. The extensive inclusion of the domain expert(s) in robot design represents established responsible innovation practice, lending credibility to the system both during the teaching phase and when operating autonomously. The combination of this expert inclusion with the focus on in situ development also means that LEADOR supports a mutual shaping approach to social robotics. We draw on two previously published, foundational works from which this (generalisable) methodology has been derived to demonstrate the feasibility and worth of this approach, provide concrete examples in its application, and identify limitations and opportunities when applying this framework in new environments.},
  archive      = {J_FROBT},
  author       = {Winkle, Katie and Senft, Emmanuel and Lemaignan, Séverin},
  doi          = {10.3389/frobt.2021.704119},
  journal      = {Frontiers in Robotics and AI},
  month        = {12},
  pages        = {704119},
  shortjournal = {Front. Robot. AI},
  title        = {LEADOR: A method for end-to-end participatory design of autonomous social robots},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Morphological computation in plant seeds for a new
generation of self-burial and flying soft robots. <em>FROBT</em>,
<em>8</em>, 797556. (<a
href="https://doi.org/10.3389/frobt.2021.797556">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Plants have evolved different mechanisms to disperse from parent plants and improve germination to sustain their survival. The study of seed dispersal mechanisms, with the related structural and functional characteristics, is an active research topic for ecology, plant diversity, climate change, as well as for its relevance for material science and engineering. The natural mechanisms of seed dispersal show a rich source of robust, highly adaptive, mass and energy efficient mechanisms for optimized passive flying, landing, crawling and drilling. The secret of seeds mobility is embodied in the structural features and anatomical characteristics of their tissues, which are designed to be selectively responsive to changes in the environmental conditions, and which make seeds one of the most fascinating examples of morphological computation in Nature. Particularly clever for their spatial mobility performance, are those seeds that use their morphology and structural characteristics to be carried by the wind and dispersed over great distances (i.e. “winged” and “parachute” seeds), and seeds able to move and penetrate in soil with a self-burial mechanism driven by their hygromorphic properties and morphological features. By looking at their motion mechanisms, new design principles can be extracted and used as inspiration for smart artificial systems endowed with embodied intelligence. This mini-review systematically collects, for the first time together, the morphological, structural, biomechanical and aerodynamic information from selected plant seeds relevant to take inspiration for engineering design of soft robots, and discusses potential future developments in the field across material science, plant biology, robotics and embodied intelligence.},
  archive      = {J_FROBT},
  author       = {Mazzolai, Barbara and Mariani, Stefano and Ronzan, Marilena and Cecchini, Luca and Fiorello, Isabella and Cikalleshi, Kliton and Margheri, Laura},
  doi          = {10.3389/frobt.2021.797556},
  journal      = {Frontiers in Robotics and AI},
  month        = {11},
  pages        = {797556},
  shortjournal = {Front. Robot. AI},
  title        = {Morphological computation in plant seeds for a new generation of self-burial and flying soft robots},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Editorial: Novel actuators, sensors and control systems for
endoscopic robots. <em>FROBT</em>, <em>8</em>, 797467. (<a
href="https://doi.org/10.3389/frobt.2021.797467">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Manfredi, Luigi and Mattos, Leonardo S. and Melzer, Andreas},
  doi          = {10.3389/frobt.2021.797467},
  journal      = {Frontiers in Robotics and AI},
  month        = {11},
  pages        = {797467},
  shortjournal = {Front. Robot. AI},
  title        = {Editorial: Novel actuators, sensors and control systems for endoscopic robots},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Editorial: On the planning, control, and perception of soft
robotic end-effectors. <em>FROBT</em>, <em>8</em>, 795863. (<a
href="https://doi.org/10.3389/frobt.2021.795863">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Averta, Giuseppe and Della Santina, Cosimo and Ficuciello, Fanny and Roa, Maximo A. and Bianchi, Matteo},
  doi          = {10.3389/frobt.2021.795863},
  journal      = {Frontiers in Robotics and AI},
  month        = {11},
  pages        = {795863},
  shortjournal = {Front. Robot. AI},
  title        = {Editorial: On the planning, control, and perception of soft robotic end-effectors},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Corrigendum: A review of possible EEG markers of
abstraction, attentiveness and memorisation in cyber-physical systems
for special education. <em>FROBT</em>, <em>8</em>, 795160. (<a
href="https://doi.org/10.3389/frobt.2021.795160">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Dimitrova, Maya and Wagatsuma, Hiroaki and Krastev, Aleksandar and Vrochidou, Eleni and Nunez-Gonzalez, J. David},
  doi          = {10.3389/frobt.2021.795160},
  journal      = {Frontiers in Robotics and AI},
  month        = {11},
  pages        = {795160},
  shortjournal = {Front. Robot. AI},
  title        = {Corrigendum: A review of possible EEG markers of abstraction, attentiveness and memorisation in cyber-physical systems for special education},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Protecting sentient artificial intelligence: A survey of lay
intuitions on standing, personhood, and general legal protection.
<em>FROBT</em>, <em>8</em>, 788355. (<a
href="https://doi.org/10.3389/frobt.2021.788355">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To what extent, if any, should the law protect sentient artificial intelligence (that is, AI that can feel pleasure or pain)? Here we surveyed United States adults (n = 1,061) on their views regarding granting 1) general legal protection, 2) legal personhood, and 3) standing to bring forth a lawsuit, with respect to sentient AI and eight other groups: humans in the jurisdiction, humans outside the jurisdiction, corporations, unions, non-human animals, the environment, humans living in the near future, and humans living in the far future. Roughly one-third of participants endorsed granting personhood and standing to sentient AI (assuming its existence) in at least some cases, the lowest of any group surveyed on, and rated the desired level of protection for sentient AI as lower than all groups other than corporations. We further investigated and observed political differences in responses; liberals were more likely to endorse legal protection and personhood for sentient AI than conservatives. Taken together, these results suggest that laypeople are not by-and-large in favor of granting legal protection to AI, and that the ordinary conception of legal status, similar to codified legal doctrine, is not based on a mere capacity to feel pleasure and pain. At the same time, the observed political differences suggest that previous literature regarding political differences in empathy and moral circle expansion apply to artificially intelligent systems and extend partially, though not entirely, to legal consideration, as well.},
  archive      = {J_FROBT},
  author       = {Martínez, Eric and Winter, Christoph},
  doi          = {10.3389/frobt.2021.788355},
  journal      = {Frontiers in Robotics and AI},
  month        = {11},
  pages        = {788355},
  shortjournal = {Front. Robot. AI},
  title        = {Protecting sentient artificial intelligence: A survey of lay intuitions on standing, personhood, and general legal protection},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Real time estimator to perform targeted biopsies with a
free-wrist robot despite large deformations of the insertion orifice.
<em>FROBT</em>, <em>8</em>, 780505. (<a
href="https://doi.org/10.3389/frobt.2021.780505">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the context of keyhole surgery, and more particularly of uterine biopsy, the fine automatic movements of a surgical instrument held by a robot with 3 active DOF’s require an exact knowledge of the point of rotation of the instrument. However, this center of rotation is not fixed and moves during an examination. This paper deals with a new method of detecting and updating the interaction matrix linking the movements of the robot with the surgical instrument. This is based on the method of updating the Jacobian matrix which is named the “Broyden method”. It is able to take into account body tissue deformations in real time in order to improve the pointing task for automatic movements of a surgical instrument in an unknown environment.},
  archive      = {J_FROBT},
  author       = {Chalard , Rémi and Fazel, Afshin and Vitrani, Marie-Aude},
  doi          = {10.3389/frobt.2021.780505},
  journal      = {Frontiers in Robotics and AI},
  month        = {11},
  pages        = {780505},
  shortjournal = {Front. Robot. AI},
  title        = {Real time estimator to perform targeted biopsies with a free-wrist robot despite large deformations of the insertion orifice},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Development of a modular tensegrity robot arm capable of
continuous bending. <em>FROBT</em>, <em>8</em>, 774253. (<a
href="https://doi.org/10.3389/frobt.2021.774253">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, we present a tensegrity robot arm that can reproduce the features of complex musculoskeletal structures, and can bend like a continuum manipulator. In particular, we propose a design method for an arm-type tensegrity robot that has a long shape in one direction, and can be deformed like a continuum manipulator. This method is based on the idea of utilizing simple and flexible strict tensegrity modules, and connecting them recursively so that they remain strict tensegrity even after being connected. The tensegrity obtained by this method strongly resists compressive forces in the longitudinal direction, but is flexible in the bending direction. Therefore, the changes in stiffness owing to internal forces, such as in musculoskeletal robots, appear more in the bending direction. First, this study describes this design method, then describes a developed pneumatically driven tensegrity robot arm with 20 actuators. Next, the range of motion and stiffness under various driving patterns are presented as evaluations of the robot performance.},
  archive      = {J_FROBT},
  author       = {Ikemoto , Shuhei and Tsukamoto , Kenta and Yoshimitsu , Yuhei},
  doi          = {10.3389/frobt.2021.774253},
  journal      = {Frontiers in Robotics and AI},
  month        = {11},
  pages        = {774253},
  shortjournal = {Front. Robot. AI},
  title        = {Development of a modular tensegrity robot arm capable of continuous bending},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A DIY fabrication approach of stretchable sensors using
carbon nano tube powder for wearable device. <em>FROBT</em>, <em>8</em>,
773056. (<a href="https://doi.org/10.3389/frobt.2021.773056">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Soft robotics and wearable devices are promising technologies due to their flexibility. As human-soft robot interaction technologies advance, the interest in stretchable sensor devices has increased. Currently, the main challenge in developing stretchable sensors is preparing high-quality sensors via a simple and cost-effective method. This study introduces the do-it-yourself (DIY)-approach to fabricate a carbon nanotube (CNT) powder-based stretchable sensor. The fabrication strategy utilizes an automatic brushing machine to pattern CNT powder on the elastomer. The elastomer ingredients are optimized to increase the elastomer compatibility with the brushing method. We found that polydimethylsiloxane-polyethyleneimine (PDMS-PEIE) is 50% more stretchable and 63% stickier than previously reported PDMS 30-1. With these improved elastomer characteristics, PDMS-PEIE/multiwalled CNT (PDMS-PEIE/MWCNT-1) strain sensor can realize a gauge factor of 6.2–8.2 and a responsivity up to 25 ms. To enhance the compatibility of the powder-based stretchable sensor for a wearable device, the sensor is laminated using a thin Ecoflex membrane. Additionally, system integration of the stretchable sensors are demonstrated by embedding it into a cotton-glove and a microcontroller to control a virtual hand. This cost-effective DIY-approach are expected to greatly contribute to the development of wearable devices since the technology is simple, economical, and reliable.},
  archive      = {J_FROBT},
  author       = {Wiranata, Ardi and Ohsugi, Yunosuke and Minaminosono, Ayato and Mao, Zebing and Kurata, Haruyuki and Hosoya, Naoki and Maeda, Shingo},
  doi          = {10.3389/frobt.2021.773056},
  journal      = {Frontiers in Robotics and AI},
  month        = {11},
  pages        = {773056},
  shortjournal = {Front. Robot. AI},
  title        = {A DIY fabrication approach of stretchable sensors using carbon nano tube powder for wearable device},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Influence of a socially assistive robot on physical
activity, social play behavior, and toy-use behaviors of children in a
free play environment: A within-subjects study. <em>FROBT</em>,
<em>8</em>, 768642. (<a
href="https://doi.org/10.3389/frobt.2021.768642">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Background: Play is critical for children’s physical, cognitive, and social development. Technology-based toys like robots are especially of interest to children. This pilot study explores the affordances of the play area provided by developmentally appropriate toys and a mobile socially assistive robot (SAR). The objective of this study is to assess the role of the SAR on physical activity, play behavior, and toy-use behavior of children during free play.Methods: Six children (5 females, Mage = 3.6 ± 1.9 years) participated in the majority of our pilot study’s seven 30-minute-long weekly play sessions (4 baseline and 3 intervention). During baseline sessions, the SAR was powered off. During intervention sessions, the SAR was teleoperated to move in the play area and offered rewards of lights, sounds, and bubbles to children. Thirty-minute videos of the play sessions were annotated using a momentary time sampling observation system. Mean percentage of time spent in behaviors of interest in baseline and intervention sessions were calculated. Paired-Wilcoxon signed rank tests were conducted to assess differences between baseline and intervention sessions.Results: There was a significant increase in children’s standing (∼15%; Z = −2.09; p = 0.037) and a tendency for less time sitting (∼19%; Z = −1.89; p = 0.059) in the intervention phase as compared to the baseline phase. There was also a significant decrease (∼4.5%, Z = −2.70; p = 0.007) in peer interaction play and a tendency for greater (∼4.5%, Z = −1.89; p = 0.059) interaction with adults in the intervention phase as compared to the baseline phase. There was a significant increase in children’s interaction with the robot (∼11.5%, Z = −2.52; p = 0.012) in the intervention phase as compared to the baseline phase.Conclusion: These results may indicate that a mobile SAR provides affordances through rewards that elicit children’s interaction with the SAR and more time standing in free play. This pilot study lays a foundation for exploring the role of SARs in inclusive play environments for children with and without mobility disabilities in real-world settings like day-care centers and preschools.},
  archive      = {J_FROBT},
  author       = {Raja Vora, Joseline and Helmi, Ameer and Zhan, Christine and Olivares, Eliora and Vu, Tina and Wilkey, Marie and Noregaard, Samantha and Fitter, Naomi T. and Logan, Samuel W.},
  doi          = {10.3389/frobt.2021.768642},
  journal      = {Frontiers in Robotics and AI},
  month        = {11},
  pages        = {768642},
  shortjournal = {Front. Robot. AI},
  title        = {Influence of a socially assistive robot on physical activity, social play behavior, and toy-use behaviors of children in a free play environment: A within-subjects study},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A soft pneumatic two-degree-of-freedom actuator for
endoscopy. <em>FROBT</em>, <em>8</em>, 768236. (<a
href="https://doi.org/10.3389/frobt.2021.768236">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rise of soft robotics opens new opportunities in endoscopy and minimally invasive surgery. Pneumatic catheters offer a promising alternative to conventional steerable catheters for safe navigation through the natural pathways without tissue injury. In this work, we present an optimized 6 mm diameter two-degree-of-freedom pneumatic actuator, able to bend in every direction and incorporating a 1 mm working channel. A versatile vacuum centrifugal overmolding method capable of producing small geometries with a variety of silicones is described, and meter-long actuators are extruded industrially. An improved method for fiber reinforcement is also presented. The actuator achieves bending more than 180° and curvatures of up to 0.1 mm−1. The exerted force remains below 100 mN, and with no rigid parts in the design, it limits the risks of damage on surrounding tissues. The response time of the actuator is below 300 ms and therefore not limited for medical applications. The working space and multi-channel actuation are also experimentally characterized. The focus is on the study of the influence of material stiffness on mechanical performances. As a rule, the softer the material, the better the energy conversion, and the stiffer the material, the larger the force developed at a given curvature. Based on the actuator, a 90 cm long steerable catheter demonstrator carrying an optical fiber is developed, and its potential for endoscopy is demonstrated in a bronchial tree phantom. In conclusion, this work contributes to the development of a toolbox of soft robotic solutions for MIS and endoscopic applications, by validating and characterizing a promising design, describing versatile and scalable fabrication methods, allowing for a better understanding of the influence of material stiffness on the actuator capabilities, and demonstrating the usability of the solution in a potential use-case.},
  archive      = {J_FROBT},
  author       = {Decroly, Gilles and Lambert, Pierre and Delchambre, Alain},
  doi          = {10.3389/frobt.2021.768236},
  journal      = {Frontiers in Robotics and AI},
  month        = {11},
  pages        = {768236},
  shortjournal = {Front. Robot. AI},
  title        = {A soft pneumatic two-degree-of-freedom actuator for endoscopy},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Robot responsibility and moral community. <em>FROBT</em>,
<em>8</em>, 768092. (<a
href="https://doi.org/10.3389/frobt.2021.768092">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is almost a foregone conclusion that robots cannot be morally responsible agents, both because they lack traditional features of moral agency like consciousness, intentionality, or empathy and because of the apparent senselessness of holding them accountable. Moreover, although some theorists include them in the moral community as moral patients, on the Strawsonian picture of moral community as requiring moral responsibility, robots are typically excluded from membership. By looking closely at our actual moral responsibility practices, however, I determine that the agency reflected and cultivated by them is limited to the kind of moral agency of which some robots are capable, not the philosophically demanding sort behind the traditional view. Hence, moral rule-abiding robots (if feasible) can be sufficiently morally responsible and thus moral community members, despite certain deficits. Alternative accountability structures could address these deficits, which I argue ought to be in place for those existing moral community members who share these deficits.},
  archive      = {J_FROBT},
  author       = {Gogoshin, Dane Leigh},
  doi          = {10.3389/frobt.2021.768092},
  journal      = {Frontiers in Robotics and AI},
  month        = {11},
  pages        = {768092},
  shortjournal = {Front. Robot. AI},
  title        = {Robot responsibility and moral community},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Quick setup of force-controlled industrial gluing tasks
using learning from demonstration. <em>FROBT</em>, <em>8</em>, 767878.
(<a href="https://doi.org/10.3389/frobt.2021.767878">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a framework for programming in-contact tasks using learning by demonstration. The framework is demonstrated on an industrial gluing task, showing that a high quality robot behavior can be programmed using a single demonstration. A unified controller structure is proposed for the demonstration and execution of in-contact tasks that eases the transition from admittance controller for demonstration to parallel force/position control for the execution. The proposed controller is adapted according to the geometry of the task constraints, which is estimated online during the demonstration. In addition, the controller gains are adapted to the human behavior during demonstration to improve the quality of the demonstration. The considered gluing task requires the robot to alternate between free motion and in-contact motion; hence, an approach for minimizing contact forces during the switching between the two situations is presented. We evaluate our proposed system in a series of experiments, where we show that we are able to estimate the geometry of a curved surface, that our adaptive controller for demonstration allows users to achieve higher accuracy in a shorter demonstration duration when compared to an off-the-shelf controller for teaching implemented on a collaborative robot, and that our execution controller is able to reduce impact forces and apply a constant process force while adapting to the surface geometry.},
  archive      = {J_FROBT},
  author       = {Iturrate, Iñigo and Kramberger, Aljaz and Sloth, Christoffer},
  doi          = {10.3389/frobt.2021.767878},
  journal      = {Frontiers in Robotics and AI},
  month        = {11},
  pages        = {767878},
  shortjournal = {Front. Robot. AI},
  title        = {Quick setup of force-controlled industrial gluing tasks using learning from demonstration},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Characterization of sustainable robotic materials and finite
element analysis of soft actuators under biodegradation. <em>FROBT</em>,
<em>8</em>, 760485. (<a
href="https://doi.org/10.3389/frobt.2021.760485">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Biodegradability is an important property for soft robots that makes them environmentally friendly. Many biodegradable materials have natural origins, and creating robots using these materials ensures sustainability. Hence, researchers have fabricated biodegradable soft actuators of various materials. During microbial degradation, the mechanical properties of biodegradable materials change; these cause changes in the behaviors of the actuators depending on the progression of degradation, where the outputs do not always remain the same against identical inputs. Therefore, to achieve appropriate operation with biodegradable soft actuators and robots, it is necessary to reflect the changes in the material properties in their design and control. However, there is a lack of insight on how biodegradable actuators change their actuation characteristics and how to identify them. In this study, we build and validate a framework that clarifies changes in the mechanical properties of biodegradable materials; further, it allows prediction of the actuation characteristics of degraded soft actuators through simulations incorporating the properties of the materials as functions of the degradation rates. As a biodegradable material, we use a mixture of gelatin and glycerol, which is fabricated in the form of a pneumatic soft actuator. The experimental results show that the actuation performance of the physical actuator reduces with the progression of biodegradation. The experimental data and simulations are in good agreement (R2 value up to 0.997), thus illustrating the applicability of our framework for designing and controlling biodegradable soft actuators and robots.},
  archive      = {J_FROBT},
  author       = {Nagai, Toshiaki and Kurita, Ashitaka and Shintake, Jun},
  doi          = {10.3389/frobt.2021.760485},
  journal      = {Frontiers in Robotics and AI},
  month        = {11},
  pages        = {760485},
  shortjournal = {Front. Robot. AI},
  title        = {Characterization of sustainable robotic materials and finite element analysis of soft actuators under biodegradation},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Shape reconstruction processes for interventional
application devices: State of the art, progress, and future directions.
<em>FROBT</em>, <em>8</em>, 758411. (<a
href="https://doi.org/10.3389/frobt.2021.758411">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Soft and continuum robots are transforming medical interventions thanks to their flexibility, miniaturization, and multidirectional movement abilities. Although flexibility enables reaching targets in unstructured and dynamic environments, it also creates challenges for control, especially due to interactions with the anatomy. Thus, in recent years lots of efforts have been devoted for the development of shape reconstruction methods, with the advancement of different kinematic models, sensors, and imaging techniques. These methods can increase the performance of the control action as well as provide the tip position of robotic manipulators relative to the anatomy. Each method, however, has its advantages and disadvantages and can be worthwhile in different situations. For example, electromagnetic (EM) and Fiber Bragg Grating (FBG) sensor-based shape reconstruction methods can be used in small-scale robots due to their advantages thanks to miniaturization, fast response, and high sensitivity. Yet, the problem of electromagnetic interference in the case of EM sensors, and poor response to high strains in the case of FBG sensors need to be considered. To help the reader make a suitable choice, this paper presents a review of recent progress on shape reconstruction methods, based on a systematic literature search, excluding pure kinematic models. Methods are classified into two categories. First, sensor-based techniques are presented that discuss the use of various sensors such as FBG, EM, and passive stretchable sensors for reconstructing the shape of the robots. Second, imaging-based methods are discussed that utilize images from different imaging systems such as fluoroscopy, endoscopy cameras, and ultrasound for the shape reconstruction process. The applicability, benefits, and limitations of each method are discussed. Finally, the paper draws some future promising directions for the enhancement of the shape reconstruction methods by discussing open questions and alternative methods.},
  archive      = {J_FROBT},
  author       = {Sahu, Sujit Kumar and Sozer, Canberk and Rosa, Benoit and Tamadon, Izadyar and Renaud, Pierre and Menciassi, Arianna},
  doi          = {10.3389/frobt.2021.758411},
  journal      = {Frontiers in Robotics and AI},
  month        = {11},
  pages        = {758411},
  shortjournal = {Front. Robot. AI},
  title        = {Shape reconstruction processes for interventional application devices: State of the art, progress, and future directions},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Communication apprehension and eye contact anxiety in video
conferences involving teleoperated robot avatars: A subjective
evaluation study. <em>FROBT</em>, <em>8</em>, 758177. (<a
href="https://doi.org/10.3389/frobt.2021.758177">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Communication apprehension (CA), defined as anxiety in oral communication, and anxiety in eye contact (AEC), defined as the discomfort felt in communication while being stared at by others, limit communication effectiveness. In this study, we examined whether using a teleoperated robot avatar in a video teleconference provides communication support to people with CA and AEC. We propose a robotic telecommunication system in which a user has two options to produce utterance for own responses in online interaction with interviewer i.e., either by a robot avatar that faces the interviewer, or by self. Two imagination-based experiments were conducted, in which a total of 400 participants were asked to watch videos for interview scenes with or without the proposed system; 200 participants for each experiment. The participants then evaluated their impressions by imagining that they were the interviewee. In the first experiment, a video conference with the proposed system was compared with an ordinary video conference, where the interviewer and interviewee faced each other. In the second experiment, it was compared with an ordinary video conference where the interviewer’s attentional focus was directed away from the interviewee. A significant decrease in the expected CA and AEC of participants with the proposed system was observed in both experiments, whereas a significant increase in the expected sense of being attended (SoBA) was observed in the second experiment. This study contributes to the literature in terms of examining the expected impact of using a teleoperated robot avatar for better video conferences, especially for supporting individuals with CA and AEC.},
  archive      = {J_FROBT},
  author       = {Mehmood, Faisal and Mahzoon, Hamed and Yoshikawa, Yuichiro and Ishiguro, Hiroshi},
  doi          = {10.3389/frobt.2021.758177},
  journal      = {Frontiers in Robotics and AI},
  month        = {11},
  pages        = {758177},
  shortjournal = {Front. Robot. AI},
  title        = {Communication apprehension and eye contact anxiety in video conferences involving teleoperated robot avatars: A subjective evaluation study},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Can the shape of a planar pathway be estimated using
proximal forces of inserting a flexible shaft? <em>FROBT</em>,
<em>8</em>, 757895. (<a
href="https://doi.org/10.3389/frobt.2021.757895">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The shape information of flexible endoscopes or other continuum structures, e.g., intro-vascular catheters, is needed for accurate navigation, motion compensation, and haptic feedback in robotic surgical systems. Existing methods rely on optical fiber sensors, electromagnetic sensors, or expensive medical imaging modalities such as X-ray fluoroscopy, magnetic resonance imaging, and ultrasound to obtain the shape information of these flexible medical devices. Here, we propose to estimate the shape/curvature of a continuum structure by measuring the force required to insert a flexible shaft into the internal channel/pathway of the continuum. We found that there is a consistent correlation between the measured insertion force and curvature of the planar continuum pathway. A testbed was built to insert a flexible shaft into a planar continuum pathway with adjustable shapes. The insertion forces, insertion displacement, and the shapes of the pathway were recorded. A neural network model was developed to model this correlation based on the training data collected on the testbed. The trained model, tested on the testing data, can accurately estimate the curvature magnitudes and the accumulated bending angles of the pathway simply based on the measured insertion force at the proximal end of the shaft. The approach may be used to estimate the curvature magnitudes and accumulated bending angles of flexible endoscopic surgical robots or catheters for accurate motion compensation, haptic force feedback, localization, or navigation. The advantage of this approach is that the employed proximal force can be easily obtained outside the pathway or continuum structure without any embedded sensor in the continuum structure. Future work is needed to further investigate the correlation between insertion forces and the pathway and enhance the capability of the model in estimating more complex shapes, e.g., spatial shapes with multiple bends.},
  archive      = {J_FROBT},
  author       = {Liu, Jiajun and Cao, Lin and Phee, Soo Jay},
  doi          = {10.3389/frobt.2021.757895},
  journal      = {Frontiers in Robotics and AI},
  month        = {11},
  pages        = {757895},
  shortjournal = {Front. Robot. AI},
  title        = {Can the shape of a planar pathway be estimated using proximal forces of inserting a flexible shaft?},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The conflict between people’s urge to punish AI and legal
systems. <em>FROBT</em>, <em>8</em>, 756242. (<a
href="https://doi.org/10.3389/frobt.2021.756242">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Regulating artificial intelligence (AI) has become necessary in light of its deployment in high-risk scenarios. This paper explores the proposal to extend legal personhood to AI and robots, which had not yet been examined through the lens of the general public. We present two studies (N = 3,559) to obtain people’s views of electronic legal personhood vis-à-vis existing liability models. Our study reveals people’s desire to punish automated agents even though these entities are not recognized any mental state. Furthermore, people did not believe automated agents’ punishment would fulfill deterrence nor retribution and were unwilling to grant them legal punishment preconditions, namely physical independence and assets. Collectively, these findings suggest a conflict between the desire to punish automated agents and its perceived impracticability. We conclude by discussing how future design and legal decisions may influence how the public reacts to automated agents’ wrongdoings.},
  archive      = {J_FROBT},
  author       = {Lima, Gabriel and Cha, Meeyoung and Jeon, Chihyung and Park, Kyung Sin},
  doi          = {10.3389/frobt.2021.756242},
  journal      = {Frontiers in Robotics and AI},
  month        = {11},
  pages        = {756242},
  shortjournal = {Front. Robot. AI},
  title        = {The conflict between people’s urge to punish AI and legal systems},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Gripe-needle: A sticky suction cup gripper equipped needle
for targeted therapeutics delivery. <em>FROBT</em>, <em>8</em>, 752290.
(<a href="https://doi.org/10.3389/frobt.2021.752290">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a multi-purpose gripping and incision tool-set to reduce the number of required manipulators for targeted therapeutics delivery in Minimally Invasive Surgery. We have recently proposed the use of multi-arm Concentric Tube Robots (CTR) consisting of an incision, a camera, and a gripper manipulator for deep orbital interventions, with a focus on Optic Nerve Sheath Fenestration (ONSF). The proposed prototype in this research, called Gripe-Needle, is a needle equipped with a sticky suction cup gripper capable of performing both gripping of target tissue and incision tasks in the optic nerve area by exploiting the multi-tube arrangement of a CTR for actuation of the different tool-set units. As a result, there will be no need for an independent gripper arm for an incision task. The CTR innermost tube is equipped with a needle, providing the pathway for drug delivery, and the immediate outer tube is attached to the suction cup, providing the suction pathway. Based on experiments on various materials, we observed that adding a sticky surface with bio-inspired grooves to a normal suction cup gripper has many advantages such as, 1) enhanced adhesion through material stickiness and by air-tightening the contact surface, 2) maintained adhesion despite internal pressure variations, e.g. due to the needle motion, and 3) sliding resistance. Simple Finite Element and theoretical modeling frameworks are proposed, based on which a miniature tool-set is designed to achieve the required gripping forces during ONSF. The final designs were successfully tested for accessing the optic nerve of a realistic eye phantom in a skull eye orbit, robust gripping and incision on units of a plastic bubble wrap sample, and manipulating different tissue types of porcine eye samples.},
  archive      = {J_FROBT},
  author       = {Joymungul, Kieran and Mitros, Zisos and da Cruz, Lyndon and Bergeles, Christos and Sadati, S.M.Hadi},
  doi          = {10.3389/frobt.2021.752290},
  journal      = {Frontiers in Robotics and AI},
  month        = {11},
  pages        = {752290},
  shortjournal = {Front. Robot. AI},
  title        = {Gripe-needle: A sticky suction cup gripper equipped needle for targeted therapeutics delivery},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Real-time 3D tracking of laparoscopy training instruments
for assessment and feedback. <em>FROBT</em>, <em>8</em>, 751741. (<a
href="https://doi.org/10.3389/frobt.2021.751741">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Assessment of minimally invasive surgical skills is a non-trivial task, usually requiring the presence and time of expert observers, including subjectivity and requiring special and expensive equipment and software. Although there are virtual simulators that provide self-assessment features, they are limited as the trainee loses the immediate feedback from realistic physical interaction. The physical training boxes, on the other hand, preserve the immediate physical feedback, but lack the automated self-assessment facilities. This study develops an algorithm for real-time tracking of laparoscopy instruments in the video cues of a standard physical laparoscopy training box with a single fisheye camera. The developed visual tracking algorithm recovers the 3D positions of the laparoscopic instrument tips, to which simple colored tapes (markers) are attached. With such system, the extracted instrument trajectories can be digitally processed, and automated self-assessment feedback can be provided. In this way, both the physical interaction feedback would be preserved and the need for the observance of an expert would be overcome. Real-time instrument tracking with a suitable assessment criterion would constitute a significant step towards provision of real-time (immediate) feedback to correct trainee actions and show them how the action should be performed. This study is a step towards achieving this with a low cost, automated, and widely applicable laparoscopy training and assessment system using a standard physical training box equipped with a fisheye camera.},
  archive      = {J_FROBT},
  author       = {Gautier, Benjamin and Tugal, Harun and Tang, Benjie and Nabi, Ghulam and Erden, Mustafa Suphi},
  doi          = {10.3389/frobt.2021.751741},
  journal      = {Frontiers in Robotics and AI},
  month        = {11},
  pages        = {751741},
  shortjournal = {Front. Robot. AI},
  title        = {Real-time 3D tracking of laparoscopy training instruments for assessment and feedback},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A semilinear parameter-varying observer method for
fabric-reinforced soft robots. <em>FROBT</em>, <em>8</em>, 749591. (<a
href="https://doi.org/10.3389/frobt.2021.749591">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents an observer architecture that can estimate a set of configuration space variables, their rates of change and contact forces of a fabric-reinforced inflatable soft robot. We discretized the continuum robot into a sequence of discs connected by inextensible threads; this allows great flexibility when describing the robot’s behavior. At first, the system dynamics is described by a linear parameter-varying (LPV) model that includes a set of subsystems, each of which corresponds to a particular range of chamber pressure. A real-world challenge we confront is that the physical robot prototype exhibits a hysteresis loop whose directions depend on whether the chamber is inflating or deflating. In this paper we transform the hysteresis model to a semilinear model to avoid backward-in-time definitions, making it suitable for observer and controller design. The final model describing the soft robot, including the discretized continuum and hysteresis behavior, is called the semilinear parameter-varying (SPV) model. The semilinear parameter-varying observer architecture includes a set of sub-observers corresponding to the subsystems for each chamber pressure range in the SPV model. The proposed observer is evaluated through simulations and experiments. Simulation results show that the observer can estimate the configuration space variables and their rate of change with no steady-state error. In addition, experimental results display fast convergence of generalized contact force estimates and good tracking of the robot’s configuration relative to ground-truth motion capture data.},
  archive      = {J_FROBT},
  author       = {Bui, Phuc D.H. and Schultz, Joshua A.},
  doi          = {10.3389/frobt.2021.749591},
  journal      = {Frontiers in Robotics and AI},
  month        = {11},
  pages        = {749591},
  shortjournal = {Front. Robot. AI},
  title        = {A semilinear parameter-varying observer method for fabric-reinforced soft robots},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Perceived service quality in HRI: Applying the SERVBOT
framework. <em>FROBT</em>, <em>8</em>, 746674. (<a
href="https://doi.org/10.3389/frobt.2021.746674">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Services are intangible in nature and as a result, it is often difficult to measure the quality of the service. In the service literature, the service is usually delivered by a human to a human customer and the quality of the service is often evaluated using the SERVQUAL dimensions. An extensive review of the literature shows there is a lack of an empirical model to assess the perceived service quality provided by a social robot. Furthermore, the social robot literature highlights key differences between human service and social robots. For example, scholars have highlighted the importance of entertainment value and engagement in the adoption of social robots in the service industry. However, it is unclear whether the SERVQUAL dimensions are appropriate to measure social robot’s service quality. The paper proposes the SERVBOT model to assess a social robot’s service quality. It identifies, reliability, responsiveness, assurance, empathy, and entertainment as the five dimensions of SERVBOT. Further, the research will investigate how these five factors influence emotional engagement and future intentions to use the social robot in a concierge service setting. The model was tested using student sampling, and a total of 94 responses were collected for the study. The findings indicate empathy and entertainment value as key predictors of emotional engagement. Further, emotional engagement is a strong predictor of future intention to use a social robot in a service setting. This study is the first to propose the SERVBOT model to measure social robot’s service quality. The model provides a theoretical underpinning on the key service quality dimensions of a social robot and gives scholars and managers a method to track the service quality of a social robot. The study also extends on the literature by exploring the key factors that influence the use of social robots (i.e. emotional engagement).},
  archive      = {J_FROBT},
  author       = {Kharub, Isha and Lwin, Michael and Khan, Aila and Mubin, Omar},
  doi          = {10.3389/frobt.2021.746674},
  journal      = {Frontiers in Robotics and AI},
  month        = {11},
  pages        = {746674},
  shortjournal = {Front. Robot. AI},
  title        = {Perceived service quality in HRI: Applying the SERVBOT framework},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Robot evolution: Ethical concerns. <em>FROBT</em>,
<em>8</em>, 744590. (<a
href="https://doi.org/10.3389/frobt.2021.744590">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rapid developments in evolutionary computation, robotics, 3D-printing, and material science are enabling advanced systems of robots that can autonomously reproduce and evolve. The emerging technology of robot evolution challenges existing AI ethics because the inherent adaptivity, stochasticity, and complexity of evolutionary systems severely weaken human control and induce new types of hazards. In this paper we address the question how robot evolution can be responsibly controlled to avoid safety risks. We discuss risks related to robot multiplication, maladaptation, and domination and suggest solutions for meaningful human control. Such concerns may seem far-fetched now, however, we posit that awareness must be created before the technology becomes mature.},
  archive      = {J_FROBT},
  author       = {Eiben, Ágoston E. and Ellers, Jacintha and Meynen, Gerben and Nyholm, Sven},
  doi          = {10.3389/frobt.2021.744590},
  journal      = {Frontiers in Robotics and AI},
  month        = {11},
  pages        = {744590},
  shortjournal = {Front. Robot. AI},
  title        = {Robot evolution: Ethical concerns},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). 10 years of human-NAO interaction research: A scoping
review. <em>FROBT</em>, <em>8</em>, 744526. (<a
href="https://doi.org/10.3389/frobt.2021.744526">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The evolving field of human-robot interaction (HRI) necessitates that we better understand how social robots operate and interact with humans. This scoping review provides an overview of about 300 research works focusing on the use of the NAO robot from 2010 to 2020. This study presents one of the most extensive and inclusive pieces of evidence on the deployment of the humanoid NAO robot and its global reach. Unlike most reviews, we provide both qualitative and quantitative results regarding how NAO is being used and what has been achieved so far. We analyzed a wide range of theoretical, empirical, and technical contributions that provide multidimensional insights, such as general trends in terms of application, the robot capabilities, its input and output modalities of communication, and the human-robot interaction experiments that featured NAO (e.g. number and roles of participants, design, and the length of interaction). Lastly, we derive from the review some research gaps in current state-of-the-art and provide suggestions for the design of the next generation of social robots.},
  archive      = {J_FROBT},
  author       = {Amirova, Aida and Rakhymbayeva, Nazerke and Yadollahi, Elmira and Sandygulova, Anara and Johal, Wafa},
  doi          = {10.3389/frobt.2021.744526},
  journal      = {Frontiers in Robotics and AI},
  month        = {11},
  pages        = {744526},
  shortjournal = {Front. Robot. AI},
  title        = {10 years of human-NAO interaction research: A scoping review},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Encouraging volitional pedaling in functional electrical
stimulation-assisted cycling using barrier functions. <em>FROBT</em>,
<em>8</em>, 742986. (<a
href="https://doi.org/10.3389/frobt.2021.742986">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stationary motorized cycling assisted by functional electrical stimulation (FES) is a popular therapy for people with movement impairments. Maximizing volitional contributions from the rider of the cycle can lead to long-term benefits like increased muscular strength and cardiovascular endurance. This paper develops a combined motor and FES control system that tasks the rider with maintaining their cadence near a target point using their own volition, while assistance or resistance is applied gradually as their cadence approaches the lower or upper boundary, respectively, of a user-defined safe range. Safety-ensuring barrier functions are used to guarantee that the rider’s cadence is constrained to the safe range, while minimal assistance is provided within the range to maximize effort by the rider. FES stimulation is applied before electric motor assistance to further increase power output from the rider. To account for uncertain dynamics, barrier function methods are combined with robust control tools from Lyapunov theory to develop controllers that guarantee safety in the worst-case. Because of the intermittent nature of FES stimulation, the closed-loop system is modeled as a hybrid system to certify that the set of states for which the cadence is in the safe range is asymptotically stable. The performance of the developed control method is demonstrated experimentally on five participants. The barrier function controller constrained the riders’ cadence in a range of 50 ± 5 RPM with an average cadence standard deviation of 1.4 RPM for a protocol where cadence with minimal variance was prioritized and used minimal assistance from the motor (4.1% of trial duration) in a separate protocol where power output from the rider was prioritized.},
  archive      = {J_FROBT},
  author       = {Isaly, Axton and Allen, Brendon C. and Sanfelice, Ricardo G. and Dixon, Warren E.},
  doi          = {10.3389/frobt.2021.742986},
  journal      = {Frontiers in Robotics and AI},
  month        = {11},
  pages        = {742986},
  shortjournal = {Front. Robot. AI},
  title        = {Encouraging volitional pedaling in functional electrical stimulation-assisted cycling using barrier functions},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Human-human hand interactions aid balance during walking by
haptic communication. <em>FROBT</em>, <em>8</em>, 735575. (<a
href="https://doi.org/10.3389/frobt.2021.735575">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Principles from human-human physical interaction may be necessary to design more intuitive and seamless robotic devices to aid human movement. Previous studies have shown that light touch can aid balance and that haptic communication can improve performance of physical tasks, but the effects of touch between two humans on walking balance has not been previously characterized. This study examines physical interaction between two persons when one person aids another in performing a beam-walking task. 12 pairs of healthy young adults held a force sensor with one hand while one person walked on a narrow balance beam (2 cm wide x 3.7 m long) and the other person walked overground by their side. We compare balance performance during partnered vs. solo beam-walking to examine the effects of haptic interaction, and we compare hand interaction mechanics during partnered beam-walking vs. overground walking to examine how the interaction aided balance. While holding the hand of a partner, participants were able to walk further on the beam without falling, reduce lateral sway, and decrease angular momentum in the frontal plane. We measured small hand force magnitudes (mean of 2.2 N laterally and 3.4 N vertically) that created opposing torque components about the beam axis and calculated the interaction torque, the overlapping opposing torque that does not contribute to motion of the beam-walker’s body. We found higher interaction torque magnitudes during partnered beam-walking vs. partnered overground walking, and correlation between interaction torque magnitude and reductions in lateral sway. To gain insight into feasible controller designs to emulate human-human physical interactions for aiding walking balance, we modeled the relationship between each torque component and motion of the beam-walker’s body as a mass-spring-damper system. Our model results show opposite types of mechanical elements (active vs. passive) for the two torque components. Our results demonstrate that hand interactions aid balance during partnered beam-walking by creating opposing torques that primarily serve haptic communication, and our model of the torques suggest control parameters for implementing human-human balance aid in human-robot interactions.},
  archive      = {J_FROBT},
  author       = {Wu, Mengnan and Drnach, Luke and Bong, Sistania M. and Song, Yun Seong and Ting, Lena H.},
  doi          = {10.3389/frobt.2021.735575},
  journal      = {Frontiers in Robotics and AI},
  month        = {11},
  pages        = {735575},
  shortjournal = {Front. Robot. AI},
  title        = {Human-human hand interactions aid balance during walking by haptic communication},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Embodied intelligence in soft robotics through hardware
multifunctionality. <em>FROBT</em>, <em>8</em>, 724056. (<a
href="https://doi.org/10.3389/frobt.2021.724056">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The soft robotics community is currently wondering what the future of soft robotics is. Therefore, it is very important to identify the directions in which the community should focus its efforts to consolidate its impact. The identification of convincing applications is a priority, especially to demonstrate that some achievements already represent an attractive alternative to current technological approaches in specific scenarios. However, most of the added value of soft robotics has been only theoretically grasped. Embodied Intelligence, being of these theoretical principles, represents an interesting approach to fully exploit soft robotic’s potential, but a pragmatic application of this theory still remains difficult and very limited. A different design approach could be beneficial, i.e., the integration of a certain degree of continuous adaptability in the hardware functionalities of the robot, namely, a “flexible” design enabled by hardware components able to fulfill multiple functionalities. In this paper this concept of flexible design is introduced along with its main technological and theoretical basic elements. The potential of the approach is demonstrated through a biological comparison and the feasibility is supported by practical examples with state-of-the-art technologies.},
  archive      = {J_FROBT},
  author       = {Cianchetti, Matteo},
  doi          = {10.3389/frobt.2021.724056},
  journal      = {Frontiers in Robotics and AI},
  month        = {11},
  pages        = {724056},
  shortjournal = {Front. Robot. AI},
  title        = {Embodied intelligence in soft robotics through hardware multifunctionality},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Autonomous obstacle crossing strategies for the hybrid
wheeled-legged robot centauro. <em>FROBT</em>, <em>8</em>, 721001. (<a
href="https://doi.org/10.3389/frobt.2021.721001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The development of autonomous legged/wheeled robots with the ability to navigate and execute tasks in unstructured environments is a well-known research challenge. In this work we introduce a methodology that permits a hybrid legged/wheeled platform to realize terrain traversing functionalities that are adaptable, extendable and can be autonomously selected and regulated based on the geometry of the perceived ground and associated obstacles. The proposed methodology makes use of a set of terrain traversing primitive behaviors that are used to perform driving, stepping on, down and over and can be adapted, based on the ground and obstacle geometry and dimensions. The terrain geometrical properties are first obtained by a perception module, which makes use of point cloud data coming from the LiDAR sensor to segment the terrain in front of the robot, identifying possible gaps or obstacles on the ground. Using these parameters the selection and adaption of the most appropriate traversing behavior is made in an autonomous manner. Traversing behaviors can be also serialized in a different order to synthesise more complex terrain crossing plans over paths of diverse geometry. Furthermore, the proposed methodology is easily extendable by incorporating additional primitive traversing behaviors into the robot mobility framework and in such a way more complex terrain negotiation capabilities can be eventually realized in an add-on fashion. The pipeline of the above methodology was initially implemented and validated on a Gazebo simulation environment. It was then ported and verified on the CENTAURO robot enabling the robot to successfully negotiate terrains of diverse geometry and size using the terrain traversing primitives.},
  archive      = {J_FROBT},
  author       = {De Luca, Alessio and Muratore, Luca and Raghavan, Vignesh Sushrutha and Antonucci, Davide and Tsagarakis, Nikolaos G.},
  doi          = {10.3389/frobt.2021.721001},
  journal      = {Frontiers in Robotics and AI},
  month        = {11},
  pages        = {721001},
  shortjournal = {Front. Robot. AI},
  title        = {Autonomous obstacle crossing strategies for the hybrid wheeled-legged robot centauro},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Monolithic stacked dielectric elastomer actuators.
<em>FROBT</em>, <em>8</em>, 714332. (<a
href="https://doi.org/10.3389/frobt.2021.714332">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dielectric elastomer actuators (DEAs) are a promising actuator technology for soft robotics. As a configuration of this technology, stacked DEAs afford a muscle-like contraction that is useful to build soft robotic systems. In stacked DEAs, dielectric and electrode layers are alternately stacked. Thus, often a dedicated setup with complicated processes or sometimes laborious manual stacking of the layers is required to fabricate stacked actuators. In this study, we propose a method to monolithically fabricate stacked DEAs without alternately stacking the dielectric and electrode layers. In this method, the actuators are fabricated mainly through two steps: 1) molding of an elastomeric matrix containing free-form microfluidic channels and 2) injection of a liquid conductive material that acts as an electrode. The feasibility of our method is investigated via the fabrication and characterization of simple monolithic DEAs with multiple electrodes (2, 4, and 10). The fabricated actuators are characterized in terms of actuation stroke, output force, and frequency response. In the actuators, polydimethylsiloxane (PDMS) and eutectic gallium–indium (EGaIn) are used for the elastomeric matrix and electrode material, respectively. Microfluidic channels are realized by dissolving a three-dimensional printed part suspended in the elastomeric structure. The experimental results show the successful implementation of the proposed method and the good agreement between the measured data and theoretical predication, validating the feasibility of the proposed method.},
  archive      = {J_FROBT},
  author       = {Shintake, Jun and Ichige, Daiki and Kanno, Ryo and Nagai, Toshiaki and Shimizu, Keita},
  doi          = {10.3389/frobt.2021.714332},
  journal      = {Frontiers in Robotics and AI},
  month        = {11},
  pages        = {714332},
  shortjournal = {Front. Robot. AI},
  title        = {Monolithic stacked dielectric elastomer actuators},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Educational robotics and tangible devices for promoting
computational thinking. <em>FROBT</em>, <em>8</em>, 713416. (<a
href="https://doi.org/10.3389/frobt.2021.713416">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, efforts have been made to add programming activities to the curriculum that promote computational thinking and foster 21st-century digital skills. One of the programming modalities is the use of Tangible Programming Languages (TPL), used in activities with 4+ year old children. In this review, we analyze solutions proposed for TPL in different contexts crossing them with non-TPL solutions, like Graphical Programming Languages (GPL). We start to characterize features of language interaction, their use, and what learning activities are associated with them. Then, in a diagram, we show a relation between the complexity of the languages with factors such as target age and output device types. We provide an analysis considering the type of input (e.g., TPL versus GPL) and output devices (e.g., physical robot versus graphical simulation) and evaluate their contribution to further insights about the general trends with respect to educational robotic systems. Finally, we discuss the opportunities to extend and improve TPLs based on the different solutions identified.},
  archive      = {J_FROBT},
  author       = {Funk, Matthias G. and Cascalho, Jose Manuel and Santos, Ana Isabel and Mendes, Armando B.},
  doi          = {10.3389/frobt.2021.713416},
  journal      = {Frontiers in Robotics and AI},
  month        = {11},
  pages        = {713416},
  shortjournal = {Front. Robot. AI},
  title        = {Educational robotics and tangible devices for promoting computational thinking},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Shared control of a powered exoskeleton and functional
electrical stimulation using iterative learning. <em>FROBT</em>,
<em>8</em>, 711388. (<a
href="https://doi.org/10.3389/frobt.2021.711388">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A hybrid exoskeleton comprising a powered exoskeleton and functional electrical stimulation (FES) is a promising technology for restoration of standing and walking functions after a neurological injury. Its shared control remains challenging due to the need to optimally distribute joint torques among FES and the powered exoskeleton while compensating for the FES-induced muscle fatigue and ensuring performance despite highly nonlinear and uncertain skeletal muscle behavior. This study develops a bi-level hierarchical control design for shared control of a powered exoskeleton and FES to overcome these challenges. A higher-level neural network–based iterative learning controller (NNILC) is derived to generate torques needed to drive the hybrid system. Then, a low-level model predictive control (MPC)-based allocation strategy optimally distributes the torque contributions between FES and the exoskeleton’s knee motors based on the muscle fatigue and recovery characteristics of a participant’s quadriceps muscles. A Lyapunov-like stability analysis proves global asymptotic tracking of state-dependent desired joint trajectories. The experimental results on four non-disabled participants validate the effectiveness of the proposed NNILC-MPC framework. The root mean square error (RMSE) of the knee joint and the hip joint was reduced by 71.96 and 74.57%, respectively, in the fourth iteration compared to the RMSE in the 1st sit-to-stand iteration.},
  archive      = {J_FROBT},
  author       = {Molazadeh , Vahidreza and Zhang , Qiang and Bao , Xuefeng and Dicianno , Brad E. and Sharma , Nitin},
  doi          = {10.3389/frobt.2021.711388},
  journal      = {Frontiers in Robotics and AI},
  month        = {11},
  pages        = {711388},
  shortjournal = {Front. Robot. AI},
  title        = {Shared control of a powered exoskeleton and functional electrical stimulation using iterative learning},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Planning fail-safe trajectories for space robotic arms.
<em>FROBT</em>, <em>8</em>, 710021. (<a
href="https://doi.org/10.3389/frobt.2021.710021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A frequent concern for robot manipulators deployed in dangerous and hazardous environments for humans is the reliability of task executions in the event of a joint failure. A redundant robotic manipulator can be used to mitigate the risk and guarantee a post-failure task completion, which is critical for instance for space applications. This paper describes methods to analyze potential risks due to a joint failure, and introduces tools for fault-tolerant task design and path planning for robotic manipulators. The presented methods are based on off-line precomputed workspace models. The methods are general enough to cope with robots with any type of joint (revolute or prismatic) and any number of degrees of freedom, and might include arbitrarily shaped obstacles in the process, without resorting to simplified models. Application examples illustrate the potential of the approach.},
  archive      = {J_FROBT},
  author       = {Porges, Oliver and Leidner, Daniel and Roa, Máximo A.},
  doi          = {10.3389/frobt.2021.710021},
  journal      = {Frontiers in Robotics and AI},
  month        = {11},
  pages        = {710021},
  shortjournal = {Front. Robot. AI},
  title        = {Planning fail-safe trajectories for space robotic arms},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Automating endoscope motion in robotic surgery: A usability
study on da vinci-assisted ex vivo neobladder reconstruction.
<em>FROBT</em>, <em>8</em>, 707704. (<a
href="https://doi.org/10.3389/frobt.2021.707704">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robots for minimally invasive surgery introduce many advantages, but still require the surgeon to alternatively control the surgical instruments and the endoscope. This work aims at providing autonomous navigation of the endoscope during a surgical procedure. The autonomous endoscope motion was based on kinematic tracking of the surgical instruments and integrated with the da Vinci Research Kit. A preclinical usability study was conducted by 10 urologists. They carried out an ex vivo orthotopic neobladder reconstruction twice, using both traditional and autonomous endoscope control. The usability of the system was tested by asking participants to fill standard system usability scales. Moreover, the effectiveness of the method was assessed by analyzing the total procedure time and the time spent with the instruments out of the field of view. The average system usability score overcame the threshold usually identified as the limit to assess good usability (average score = 73.25 &amp;gt; 68). The average total procedure time with the autonomous endoscope navigation was comparable with the classic control (p = 0.85 &amp;gt; 0.05), yet it significantly reduced the time out of the field of view (p = 0.022 &amp;lt; 0.05). Based on our findings, the autonomous endoscope improves the usability of the surgical system, and it has the potential to be an additional and customizable tool for the surgeon that can always take control of the endoscope or leave it to move autonomously.},
  archive      = {J_FROBT},
  author       = {Da Col, Tommaso and Caccianiga, Guido and Catellani, Michele and Mariani, Andrea and Ferro, Matteo and Cordima, Giovanni and De Momi, Elena and Ferrigno, Giancarlo and de Cobelli, Ottavio},
  doi          = {10.3389/frobt.2021.707704},
  journal      = {Frontiers in Robotics and AI},
  month        = {11},
  pages        = {707704},
  shortjournal = {Front. Robot. AI},
  title        = {Automating endoscope motion in robotic surgery: A usability study on da vinci-assisted ex vivo neobladder reconstruction},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Does the goal matter? Emotion recognition tasks can change
the social value of facial mimicry towards artificial agents.
<em>FROBT</em>, <em>8</em>, 699090. (<a
href="https://doi.org/10.3389/frobt.2021.699090">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we present a study aimed at understanding whether the embodiment and humanlikeness of an artificial agent can affect people’s spontaneous and instructed mimicry of its facial expressions. The study followed a mixed experimental design and revolved around an emotion recognition task. Participants were randomly assigned to one level of humanlikeness (between-subject variable: humanlike, characterlike, or morph facial texture of the artificial agents) and observed the facial expressions displayed by three artificial agents differing in embodiment (within-subject variable: video-recorded robot, physical robot, and virtual agent) and a human (control). To study both spontaneous and instructed facial mimicry, we divided the experimental sessions into two phases. In the first phase, we asked participants to observe and recognize the emotions displayed by the agents. In the second phase, we asked them to look at the agents’ facial expressions, replicate their dynamics as closely as possible, and then identify the observed emotions. In both cases, we assessed participants’ facial expressions with an automated Action Unit (AU) intensity detector. Contrary to our hypotheses, our results disclose that the agent that was perceived as the least uncanny, and most anthropomorphic, likable, and co-present, was the one spontaneously mimicked the least. Moreover, they show that instructed facial mimicry negatively predicts spontaneous facial mimicry. Further exploratory analyses revealed that spontaneous facial mimicry appeared when participants were less certain of the emotion they recognized. Hence, we postulate that an emotion recognition goal can flip the social value of facial mimicry as it transforms a likable artificial agent into a distractor. Further work is needed to corroborate this hypothesis. Nevertheless, our findings shed light on the functioning of human-agent and human-robot mimicry in emotion recognition tasks and help us to unravel the relationship between facial mimicry, liking, and rapport.},
  archive      = {J_FROBT},
  author       = {Perugia, Giulia and Paetzel-Prüsmann, Maike and Hupont, Isabelle and Varni, Giovanna and Chetouani, Mohamed and Peters, Christopher Edward and Castellano, Ginevra},
  doi          = {10.3389/frobt.2021.699090},
  journal      = {Frontiers in Robotics and AI},
  month        = {11},
  pages        = {699090},
  shortjournal = {Front. Robot. AI},
  title        = {Does the goal matter? emotion recognition tasks can change the social value of facial mimicry towards artificial agents},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Exploring behavioral creativity of a proactive robot.
<em>FROBT</em>, <em>8</em>, 694177. (<a
href="https://doi.org/10.3389/frobt.2021.694177">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Creativity, in one sense, can be seen as an effort or action to bring novelty. Following this, we explore how a robot can be creative by bringing novelty in a human–robot interaction (HRI) scenario. Studies suggest that proactivity is closely linked with creativity. Proactivity can be defined as acting or interacting by anticipating future needs or actions. This study aims to explore the effect of proactive behavior and the relation of such behaviors to the two aspects of creativity: 1) the perceived creativity observed by the user in the robot’s proactive behavior and 2) creativity of the user by assessing how creativity in HRI can be shaped or influenced by proactivity. We do so by conducting an experimental study, where the robot tries to support the user on the completion of the task regardless of the end result being novel or not and does so by exhibiting anticipatory proactive behaviors. In our study, the robot instantiates a set of verbal communications as proactive robot behavior. To our knowledge, the study is among the first to establish and investigate the relationship between creativity and proactivity in the HRI context, based on user studies. The initial results have indicated a relationship between observed proactivity, creativity, and task achievement. It also provides valuable pointers for further investigation in this domain.},
  archive      = {J_FROBT},
  author       = {Buyukgoz, Sera and Pandey, Amit Kumar and Chamoux, Marine and Chetouani, Mohamed},
  doi          = {10.3389/frobt.2021.694177},
  journal      = {Frontiers in Robotics and AI},
  month        = {11},
  pages        = {694177},
  shortjournal = {Front. Robot. AI},
  title        = {Exploring behavioral creativity of a proactive robot},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Active inference through energy minimization in multimodal
affective human–robot interaction. <em>FROBT</em>, <em>8</em>, 684401.
(<a href="https://doi.org/10.3389/frobt.2021.684401">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {During communication, humans express their emotional states using various modalities (e.g., facial expressions and gestures), and they estimate the emotional states of others by paying attention to multimodal signals. To ensure that a communication robot with limited resources can pay attention to such multimodal signals, the main challenge involves selecting the most effective modalities among those expressed. In this study, we propose an active perception method that involves selecting the most informative modalities using a criterion based on energy minimization. This energy-based model can learn the probability of the network state using energy values, whereby a lower energy value represents a higher probability of the state. A multimodal deep belief network, which is an energy-based model, was employed to represent the relationships between the emotional states and multimodal sensory signals. Compared to other active perception methods, the proposed approach demonstrated improved accuracy using limited information in several contexts associated with affective human–robot interaction. We present the differences and advantages of our method compared to other methods through mathematical formulations using, for example, information gain as a criterion. Further, we evaluate performance of our method, as pertains to active inference, which is based on the free energy principle. Consequently, we establish that our method demonstrated superior performance in tasks associated with mutually correlated multimodal information.},
  archive      = {J_FROBT},
  author       = {Horii, Takato and Nagai, Yukie},
  doi          = {10.3389/frobt.2021.684401},
  journal      = {Frontiers in Robotics and AI},
  month        = {11},
  pages        = {684401},
  shortjournal = {Front. Robot. AI},
  title        = {Active inference through energy minimization in multimodal affective Human–Robot interaction},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Modeling and learning constraints for creative tool use.
<em>FROBT</em>, <em>8</em>, 674292. (<a
href="https://doi.org/10.3389/frobt.2021.674292">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Improvisation is a hallmark of human creativity and serves a functional purpose in completing everyday tasks with novel resources. This is particularly exhibited in tool-using tasks: When the expected tool for a task is unavailable, humans often are able to replace the expected tool with an atypical one. As robots become more commonplace in human society, we will also expect them to become more skilled at using tools in order to accommodate unexpected variations of tool-using tasks. In order for robots to creatively adapt their use of tools to task variations in a manner similar to humans, they must identify tools that fulfill a set of task constraints that are essential to completing the task successfully yet are initially unknown to the robot. In this paper, we present a high-level process for tool improvisation (tool identification, evaluation, and adaptation), highlight the importance of tooltips in considering tool-task pairings, and describe a method of learning by correction in which the robot learns the constraints from feedback from a human teacher. We demonstrate the efficacy of the learning by correction method for both within-task and across-task transfer on a physical robot.},
  archive      = {J_FROBT},
  author       = {Fitzgerald , Tesca and Goel , Ashok and Thomaz , Andrea},
  doi          = {10.3389/frobt.2021.674292},
  journal      = {Frontiers in Robotics and AI},
  month        = {11},
  pages        = {674292},
  shortjournal = {Front. Robot. AI},
  title        = {Modeling and learning constraints for creative tool use},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Autonomous exploration of small bodies toward greater
autonomy for deep space missions. <em>FROBT</em>, <em>8</em>, 650885.
(<a href="https://doi.org/10.3389/frobt.2021.650885">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autonomy is becoming increasingly important for the robotic exploration of unpredictable environments. One such example is the approach, proximity operation, and surface exploration of small bodies. In this article, we present an overview of an estimation framework to approach and land on small bodies as a key functional capability for an autonomous small-body explorer. We use a multi-phase perception/estimation pipeline with interconnected and overlapping measurements and algorithms to characterize and reach the body, from millions of kilometers down to its surface. We consider a notional spacecraft design that operates across all phases from approach to landing and to maneuvering on the surface of the microgravity body. This SmallSat design makes accommodations to simplify autonomous surface operations. The estimation pipeline combines state-of-the-art techniques with new approaches to estimating the target’s unknown properties across all phases. Centroid and light-curve algorithms estimate the body–spacecraft relative trajectory and rotation, respectively, using a priori knowledge of the initial relative orbit. A new shape-from-silhouette algorithm estimates the pole (i.e., rotation axis) and the initial visual hull that seeds subsequent feature tracking as the body gets more resolved in the narrow field-of-view imager. Feature tracking refines the pole orientation and shape of the body for estimating initial gravity to enable safe close approach. A coarse-shape reconstruction algorithm is used to identify initial landable regions whose hazardous nature would subsequently be assessed by dense 3D reconstruction. Slope stability, thermal, occlusion, and terra-mechanical hazards would be assessed on densely reconstructed regions and continually refined prior to landing. We simulated a mission scenario for approaching a hypothetical small body whose motion and shape were unknown a priori, starting from thousands of kilometers down to 20 km. Results indicate the feasibility of recovering the relative body motion and shape solely relying on onboard measurements and estimates with their associated uncertainties and without human input. Current work continues to mature and characterize the algorithms for the last phases of the estimation framework to land on the surface.},
  archive      = {J_FROBT},
  author       = {Nesnas, Issa A. D. and Hockman, Benjamin J. and Bandopadhyay, Saptarshi and Morrell, Benjamin J. and Lubey, Daniel P. and Villa, Jacopo and Bayard, David S. and Osmundson, Alan and Jarvis, Benjamin and Bersani, Michele and Bhaskaran, Shyam},
  doi          = {10.3389/frobt.2021.650885},
  journal      = {Frontiers in Robotics and AI},
  month        = {11},
  pages        = {650885},
  shortjournal = {Front. Robot. AI},
  title        = {Autonomous exploration of small bodies toward greater autonomy for deep space missions},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Creative AI and musicking robots. <em>FROBT</em>,
<em>8</em>, 631752. (<a
href="https://doi.org/10.3389/frobt.2021.631752">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article discusses the creative and technical approaches in a performative robot project called “Embodied Musicking Robots” (2018–present). The core approach of this project is human-centered AI (HC-AI) which focuses on the design, development, and deployment of intelligent systems that cooperate with humans in real time in a “deep and meaningful way.”1 This project applies this goal as a central philosophy from which the concepts of creative AI and experiential learning are developed. At the center of this discussion is the articulation of a shift in thinking of what constitutes creative AI and new HC-AI forms of computational learning from inside the flow of the shared experience between robots and humans. The central case study (EMRv1) investigates the technical solutions and artistic potential of AI-driven robots co-creating with an improvising human musician (the author) in real time. This project is ongoing, currently at v4, with limited conclusions; other than this, the approach can be felt to be cooperative but requires further investigation.},
  archive      = {J_FROBT},
  author       = {Vear, Craig},
  doi          = {10.3389/frobt.2021.631752},
  journal      = {Frontiers in Robotics and AI},
  month        = {11},
  pages        = {631752},
  shortjournal = {Front. Robot. AI},
  title        = {Creative AI and musicking robots},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Fabrication of a soft robotic gripper with integrated strain
sensing elements using multi-material additive manufacturing.
<em>FROBT</em>, <em>8</em>, 615991. (<a
href="https://doi.org/10.3389/frobt.2021.615991">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the purpose of making soft robotic structures with embedded sensors, additive manufacturing techniques like fused deposition modeling (FDM) are popular. Thermoplastic polyurethane (TPU) filaments, with and without conductive fillers, are now commercially available. However, conventional FDM still has some limitations because of the marginal compatibility with soft materials. Material selection criteria for the available material options for FDM have not been established. In this study, an open-source soft robotic gripper design has been used to evaluate the FDM printing of TPU structures with integrated strain sensing elements in order to provide some guidelines for the material selection when an elastomer and a soft piezoresistive sensor are combined. Such soft grippers, with integrated strain sensing elements, were successfully printed using a multi-material FDM 3D printer. Characterization of the integrated piezoresistive sensor function, using dynamic tensile testing, revealed that the sensors exhibited good linearity up to 30% strain, which was sufficient for the deformation range of the selected gripper structure. Grippers produced using four different TPU materials were used to investigate the effect of the Shore hardness of the TPU on the piezoresistive sensor properties. The results indicated that the in situ printed strain sensing elements on the soft gripper were able to detect the deformation of the structure when the tentacles of the gripper were open or closed. The sensor signal could differentiate between the picking of small or big objects and when an obstacle prevented the tentacles from opening. Interestingly, the sensors embedded in the tentacles exhibited good reproducibility and linearity, and the sensitivity of the sensor response changed with the Shore hardness of the gripper. Correlation between TPU Shore hardness, used for the gripper body and sensitivity of the integrated in situ strain sensing elements, showed that material selection affects the sensor signal significantly.},
  archive      = {J_FROBT},
  author       = {Georgopoulou, Antonia and Vanderborght, Bram and Clemens, Frank},
  doi          = {10.3389/frobt.2021.615991},
  journal      = {Frontiers in Robotics and AI},
  month        = {11},
  pages        = {615991},
  shortjournal = {Front. Robot. AI},
  title        = {Fabrication of a soft robotic gripper with integrated strain sensing elements using multi-material additive manufacturing},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Implementation and evaluation of a grip behavior model to
express emotions for an android robot. <em>FROBT</em>, <em>8</em>,
755150. (<a href="https://doi.org/10.3389/frobt.2021.755150">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, we implemented a model with which a robot expressed such complex emotions as heartwarming (e.g., happy and sad) or horror (fear and surprise) by its touches and experimentally investigated the effectiveness of the modeled touch behaviors. Robots that can express emotions through touching behaviors increase their interaction capabilities with humans. Although past studies achieved ways to express emotions through a robot’s touch, such studies focused on expressing such basic emotions as happiness and sadness and downplayed these complex emotions. Such studies only proposed a model that expresses these emotions by touch behaviors without evaluations. Therefore, we conducted the experiment to evaluate the model with participants. In the experiment, they evaluated the perceived emotions and empathies from a robot’s touch while they watched a video stimulus with the robot. Our results showed that the touch timing before the climax received higher evaluations than touch timing after for both the scary and heartwarming videos.},
  archive      = {J_FROBT},
  author       = {Shiomi, Masahiro and Zheng, Xiqian and Minato, Takashi and Ishiguro, Hiroshi},
  doi          = {10.3389/frobt.2021.755150},
  journal      = {Frontiers in Robotics and AI},
  month        = {10},
  pages        = {755150},
  shortjournal = {Front. Robot. AI},
  title        = {Implementation and evaluation of a grip behavior model to express emotions for an android robot},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Tracking multiple vehicles constrained to a road network
from a UAV with sparse visual measurements. <em>FROBT</em>, <em>8</em>,
744185. (<a href="https://doi.org/10.3389/frobt.2021.744185">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multiple-target tracking algorithms generally operate in the local frame of the sensor and have difficulty with track reallocation when targets move in and out of the sensor field-of-view. This poses a problem when an unmanned aerial vehicle (UAV) is tracking multiple ground targets on a road network larger than its field-of-view. To address this problem, we propose a Rao-Blackwellized Particle Filter (RBPF) to maintain individual target tracks and to perform probabilistic data association when the targets are constrained to a road network. This is particularly useful when a target leaves and then re-enters the UAV’s field-of-view. The RBPF is structured as a particle filter of particle filters. The top level filter handles data association and each of its particles maintains a bank of particle filters to handle target tracking. The tracking particle filters incorporate both positive and negative information when a measurement is received. We implement two path planning controllers, receding horizon and deep reinforcement learning, and compare their ability to improve the certainty for multiple target location estimates. The controllers prioritize paths that reduce each target’s entropy. In addition, we develop an algorithm that computes the upper bound on the filter’s performance, thus facilitating an estimate of the number of UAVs needed to achieve a desired performance threshold.},
  archive      = {J_FROBT},
  author       = {Moore, Jared J. and Bidstrup, Craig C. and Peterson, Cameron K. and Beard, Randal W.},
  doi          = {10.3389/frobt.2021.744185},
  journal      = {Frontiers in Robotics and AI},
  month        = {10},
  pages        = {744185},
  shortjournal = {Front. Robot. AI},
  title        = {Tracking multiple vehicles constrained to a road network from a UAV with sparse visual measurements},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Persistent object search and surveillance control with
safety certificates for drone networks based on control barrier
functions. <em>FROBT</em>, <em>8</em>, 740460. (<a
href="https://doi.org/10.3389/frobt.2021.740460">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we address a persistent object search and surveillance mission for drone networks equipped with onboard cameras, and present a safe control strategy based on control barrier functions The mission for the object search and surveillance in this paper is defined with two subtasks, persistent search and object surveillance, which should be flexibly switched depending on the situation. Besides, to ensure actual persistency of the mission, we incorporate two additional specifications, safety (collision avoidance) and energy persistency (battery charging), into the mission. To rigorously describe the subtask of persistent search, we present a novel notion of γ-level persistent search and the performance certificate function as a candidate of a time-varying Control Barrier Function. We then design a constraint-based controller by combining the performance certificate function with other CBFs that individually reflect other specifications. In order to manage conflicts among the specifications, the present controller prioritizes individual specifications in the order of safety, energy persistency, and persistent search/object surveillance. The present controller is finally demonstrated through simulation and experiments on a testbed.},
  archive      = {J_FROBT},
  author       = {Dan, Hayato and Hatanaka, Takeshi and Yamauchi , Junya and Shimizu, Takumi and Fujita, Masayuki},
  doi          = {10.3389/frobt.2021.740460},
  journal      = {Frontiers in Robotics and AI},
  month        = {10},
  pages        = {740460},
  shortjournal = {Front. Robot. AI},
  title        = {Persistent object search and surveillance control with safety certificates for drone networks based on control barrier functions},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). General framework for the optimization of the human-robot
collaboration decision-making process through the ability to change
performance metrics. <em>FROBT</em>, <em>8</em>, 736644. (<a
href="https://doi.org/10.3389/frobt.2021.736644">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a new decision-making framework in the context of Human-Robot Collaboration (HRC). State-of-the-art techniques consider the HRC as an optimization problem in which the utility function, also called reward function, is defined to accomplish the task regardless of how well the interaction is performed. When the performance metrics are considered, they cannot be easily changed within the same framework. In contrast, our decision-making framework can easily handle the change of the performance metrics from one case scenario to another. Our method treats HRC as a constrained optimization problem where the utility function is split into two main parts. Firstly, a constraint defines how to accomplish the task. Secondly, a reward evaluates the performance of the collaboration, which is the only part that is modified when changing the performance metrics. It gives control over the way the interaction unfolds, and it also guarantees the adaptation of the robot actions to the human ones in real-time. In this paper, the decision-making process is based on Nash Equilibrium and perfect-information extensive form from game theory. It can deal with collaborative interactions considering different performance metrics such as optimizing the time to complete the task, considering the probability of human errors, etc. Simulations and a real experimental study on “an assembly task” -i.e., a game based on a construction kit-illustrate the effectiveness of the proposed framework.},
  archive      = {J_FROBT},
  author       = {Hani Daniel Zakaria, Mélodie and Lengagne, Sébastien and Corrales Ramón, Juan Antonio and Mezouar, Youcef},
  doi          = {10.3389/frobt.2021.736644},
  journal      = {Frontiers in Robotics and AI},
  month        = {10},
  pages        = {736644},
  shortjournal = {Front. Robot. AI},
  title        = {General framework for the optimization of the human-robot collaboration decision-making process through the ability to change performance metrics},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Coordinating shared tasks in human-robot collaboration by
commands. <em>FROBT</em>, <em>8</em>, 734548. (<a
href="https://doi.org/10.3389/frobt.2021.734548">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human-robot collaboration is gaining more and more interest in industrial settings, as collaborative robots are considered safe and robot actions can be programmed easily by, for example, physical interaction. Despite this, robot programming mostly focuses on automated robot motions and interactive tasks or coordination between human and robot still requires additional developments. For example, the selection of which tasks or actions a robot should do next might not be known beforehand or might change at the last moment. Within a human-robot collaborative setting, the coordination of complex shared tasks, is therefore more suited to a human, where a robot would act upon requested commands.In this work we explore the utilization of commands to coordinate a shared task between a human and a robot, in a shared work space. Based on a known set of higher-level actions (e.g., pick-and-placement, hand-over, kitting) and the commands that trigger them, both a speech-based and graphical command-based interface are developed to investigate its use. While speech-based interaction might be more intuitive for coordination, in industrial settings background sounds and noise might hinder its capabilities. The graphical command-based interface circumvents this, while still demonstrating the capabilities of coordination. The developed architecture follows a knowledge-based approach, where the actions available to the robot are checked at runtime whether they suit the task and the current state of the world. Experimental results on industrially relevant assembly, kitting and hand-over tasks in a laboratory setting demonstrate that graphical command-based and speech-based coordination with high-level commands is effective for collaboration between a human and a robot.},
  archive      = {J_FROBT},
  author       = {Angleraud , Alexandre and Mehman Sefat, Amir and Netzev, Metodi and Pieters, Roel},
  doi          = {10.3389/frobt.2021.734548},
  journal      = {Frontiers in Robotics and AI},
  month        = {10},
  pages        = {734548},
  shortjournal = {Front. Robot. AI},
  title        = {Coordinating shared tasks in human-robot collaboration by commands},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Real-time shape estimation for concentric tube continuum
robots with a single force/torque sensor. <em>FROBT</em>, <em>8</em>,
734033. (<a href="https://doi.org/10.3389/frobt.2021.734033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Shape-sensing in real-time is a key requirement for the development of advanced algorithms for concentric tube continuum robots when safe interaction with the environment is important e.g., for path planning, advanced control, and human-machine interaction. We propose a real-time shape-estimation algorithm for concentric tube continuum robots based on the force-torque information measured at the tubes’ basis. It extends a shape estimation algorithm for elastic rods based on discrete Kirchhoff rod theory. For simplicity and efficiency of calculation, we combine it with a model under piece-wise constant curvature assumption, in which we model a concentric tube continuum robot as a combination of segments of planar constant curvatures lying on different equilibrium planes. We evaluate our approach for a single and two combined additively manufactured tubes and achieve an estimation frequency of 333 Hz for two combined tubes with a mean deviation along the backbone of the tubes of 1.91–5.22 mm.},
  archive      = {J_FROBT},
  author       = {Donat, Heiko and Gu, Jiecong and Steil, Jochen J.},
  doi          = {10.3389/frobt.2021.734033},
  journal      = {Frontiers in Robotics and AI},
  month        = {10},
  pages        = {734033},
  shortjournal = {Front. Robot. AI},
  title        = {Real-time shape estimation for concentric tube continuum robots with a single Force/Torque sensor},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). On the mathematical modeling of slender biomedical continuum
robots. <em>FROBT</em>, <em>8</em>, 732643. (<a
href="https://doi.org/10.3389/frobt.2021.732643">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The passive, mechanical adaptation of slender, deformable robots to their environment, whether the robot be made of hard materials or soft ones, makes them desirable as tools for medical procedures. Their reduced physical compliance can provide a form of embodied intelligence that allows the natural dynamics of interaction between the robot and its environment to guide the evolution of the combined robot-environment system. To design these systems, the problems of analysis, design optimization, control, and motion planning remain of great importance because, in general, the advantages afforded by increased mechanical compliance must be balanced against penalties such as slower dynamics, increased difficulty in the design of control systems, and greater kinematic uncertainty. The models that form the basis of these problems should be reasonably accurate yet not prohibitively expensive to formulate and solve. In this article, the state-of-the-art modeling techniques for continuum robots are reviewed and cast in a common language. Classical theories of mechanics are used to outline formal guidelines for the selection of appropriate degrees of freedom in models of continuum robots, both in terms of number and of quality, for geometrically nonlinear models built from the general family of one-dimensional rod models of continuum mechanics. Consideration is also given to the variety of actuators found in existing designs, the types of interaction that occur between continuum robots and their biomedical environments, the imposition of constraints on degrees of freedom, and to the numerical solution of the family of models under study. Finally, some open problems of modeling are discussed and future challenges are identified.},
  archive      = {J_FROBT},
  author       = {Gilbert, Hunter B.},
  doi          = {10.3389/frobt.2021.732643},
  journal      = {Frontiers in Robotics and AI},
  month        = {10},
  pages        = {732643},
  shortjournal = {Front. Robot. AI},
  title        = {On the mathematical modeling of slender biomedical continuum robots},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Comparative analysis of model-based predictive shared
control for delayed operation in object reaching and recognition tasks
with tactile sensing. <em>FROBT</em>, <em>8</em>, 730946. (<a
href="https://doi.org/10.3389/frobt.2021.730946">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Communication delay represents a fundamental challenge in telerobotics: on one hand, it compromises the stability of teleoperated robots, on the other hand, it decreases the user’s awareness of the designated task. In scientific literature, such a problem has been addressed both with statistical models and neural networks (NN) to perform sensor prediction, while keeping the user in full control of the robot’s motion. We propose shared control as a tool to compensate and mitigate the effects of communication delay. Shared control has been proven to enhance precision and speed in reaching and manipulation tasks, especially in the medical and surgical fields. We analyse the effects of added delay and propose a unilateral teleoperated leader-follower architecture that both implements a predictive system and shared control, in a 1-dimensional reaching and recognition task with haptic sensing. We propose four different control modalities of increasing autonomy: non-predictive human control (HC), predictive human control (PHC), (shared) predictive human-robot control (PHRC), and predictive robot control (PRC). When analyzing how the added delay affects the subjects’ performance, the results show that the HC is very sensitive to the delay: users are not able to stop at the desired position and trajectories exhibit wide oscillations. The degree of autonomy introduced is shown to be effective in decreasing the total time requested to accomplish the task. Furthermore, we provide a deep analysis of environmental interaction forces and performed trajectories. Overall, the shared control modality, PHRC, represents a good trade-off, having peak performance in accuracy and task time, a good reaching speed, and a moderate contact with the object of interest.},
  archive      = {J_FROBT},
  author       = {Costi, Leone and Scimeca, Luca and Maiolino, Perla and Lalitharatne, Thilina Dulantha and Nanayakkara, Thrishantha and Hashem, Ryman and Iida, Fumiya},
  doi          = {10.3389/frobt.2021.730946},
  journal      = {Frontiers in Robotics and AI},
  month        = {10},
  pages        = {730946},
  shortjournal = {Front. Robot. AI},
  title        = {Comparative analysis of model-based predictive shared control for delayed operation in object reaching and recognition tasks with tactile sensing},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Together we can figure it out: Groups find hospitality
robots easier to use and interact with them more than individuals.
<em>FROBT</em>, <em>8</em>, 730399. (<a
href="https://doi.org/10.3389/frobt.2021.730399">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As robots are becoming more prevalent and entering hospitality settings, understanding how different configurations of individuals and groups interact with them becomes increasingly important for catering to various people. This is especially important because group dynamics can affect people’s perceptions of situations and behavior in them. We present research examining how individuals and groups interact with and accept a humanoid robot greeter at a real-world café (Study 1) and in an online study (Study 2). In each study, we separately examine interactions of individuals, groups that participants formed after they arrived at the café (new-formed groups), and groups that participants arrived with at the café (pre-formed groups). Results support prior findings that groups are more likely to interact with a public robot than individuals (Study 1). We also report novel findings that new-formed groups interacted more with the robot than pre-formed groups (Study 1). We link this with groups perceiving the robot as more positive and easier to use (Study 2). Future research should examine perceptions of the robot immediately after interaction and in different hospitality contexts.},
  archive      = {J_FROBT},
  author       = {Preusse, Harrison and Skulsky, Rebecca and Fraune, Marlena R. and Stringam, Betsy Bender},
  doi          = {10.3389/frobt.2021.730399},
  journal      = {Frontiers in Robotics and AI},
  month        = {10},
  pages        = {730399},
  shortjournal = {Front. Robot. AI},
  title        = {Together we can figure it out: Groups find hospitality robots easier to use and interact with them more than individuals},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A survey for machine learning-based control of continuum
robots. <em>FROBT</em>, <em>8</em>, 730330. (<a
href="https://doi.org/10.3389/frobt.2021.730330">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Soft continuum robots have been accepted as a promising category of biomedical robots, accredited to the robots’ inherent compliance that makes them safely interact with their surroundings. In its application of minimally invasive surgery, such a continuum concept shares the same view of robotization for conventional endoscopy/laparoscopy. Different from rigid-link robots with accurate analytical kinematics/dynamics, soft robots encounter modeling uncertainties due to intrinsic and extrinsic factors, which would deteriorate the model-based control performances. However, the trade-off between flexibility and controllability of soft manipulators may not be readily optimized but would be demanded for specific kinds of modeling approaches. To this end, data-driven modeling strategies making use of machine learning algorithms would be an encouraging way out for the control of soft continuum robots. In this article, we attempt to overview the current state of kinematic/dynamic model-free control schemes for continuum manipulators, particularly by learning-based means, and discuss their similarities and differences. Perspectives and trends in the development of new control methods are also investigated through the review of existing limitations and challenges.},
  archive      = {J_FROBT},
  author       = {Wang, Xiaomei and Li, Yingqi and Kwok, Ka-Wai},
  doi          = {10.3389/frobt.2021.730330},
  journal      = {Frontiers in Robotics and AI},
  month        = {10},
  pages        = {730330},
  shortjournal = {Front. Robot. AI},
  title        = {A survey for machine learning-based control of continuum robots},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A virtual sandbox approach to studying the effect of
augmented communication on human-robot collaboration. <em>FROBT</em>,
<em>8</em>, 728961. (<a
href="https://doi.org/10.3389/frobt.2021.728961">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human-Robot Collaboration (HRC) has the potential for a paradigm shift in industrial production by complementing the strengths of industrial robots with human staff. However, exploring these scenarios in physical experimental settings is costly and difficult, e.g., due to safety considerations. We present a virtual reality application that allows the exploration of HRC work arrangements with autonomous robots and their effect on human behavior. Prior experimental studies conducted using this application demonstrated the benefits of augmenting an autonomous robot arm with communication channels on subjective aspects such as perceived stress. Motivated by current safety regulations that hinder HRC to expand its full potential, we explored the effects of the augmented communication on objective measures (collision rate and produced goods) within a virtual sandbox application. Explored through a safe and replicable setup, the goal was to determine whether communication channels that provide guidance and explanation on the robot can help mitigate safety hazards without interfering with the production effectiveness of both parties. This is based on the theoretical foundation that communication channels enable the robot to explain its action, helps the human collaboration partner to comprehend the current state of the shared task better, and react accordingly. Focused on the optimization of production output, reduced collision rate, and increased perception of safety, a between-subjects experimental study with two conditions (augmented communication vs non-augmented) was conducted. The results revealed a statistically significant difference in terms of production quantity output and collisions with the robot, favoring the augmented conditions. Additional statistically significant differences regarding self-reported perceived safety were found. The results of this study provide an entry point for future research regarding the augmentation of industrial robots with communication channels for safety purposes.},
  archive      = {J_FROBT},
  author       = {Arntz, Alexander and Eimler, Sabrina C. and Hoppe, H. Ulrich},
  doi          = {10.3389/frobt.2021.728961},
  journal      = {Frontiers in Robotics and AI},
  month        = {10},
  pages        = {728961},
  shortjournal = {Front. Robot. AI},
  title        = {A virtual sandbox approach to studying the effect of augmented communication on human-robot collaboration},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Terrain-perception-free quadrupedal spinning locomotion on
versatile terrains: Modeling, analysis, and experimental validation.
<em>FROBT</em>, <em>8</em>, 724138. (<a
href="https://doi.org/10.3389/frobt.2021.724138">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic quadrupedal locomotion over rough terrains reveals remarkable progress over the last few decades. Small-scale quadruped robots are adequately flexible and adaptable to traverse uneven terrains along the sagittal direction, such as slopes and stairs. To accomplish autonomous locomotion navigation in complex environments, spinning is a fundamental yet indispensable functionality for legged robots. However, spinning behaviors of quadruped robots on uneven terrain often exhibit position drifts. Motivated by this problem, this study presents an algorithmic method to enable accurate spinning motions over uneven terrain and constrain the spinning radius of the center of mass (CoM) to be bounded within a small range to minimize the drift risks. A modified spherical foot kinematics representation is proposed to improve the foot kinematic model and rolling dynamics of the quadruped during locomotion. A CoM planner is proposed to generate a stable spinning motion based on projected stability margins. Accurate motion tracking is accomplished with linear quadratic regulator (LQR) to bind the position drift during the spinning movement. Experiments are conducted on a small-scale quadruped robot and the effectiveness of the proposed method is verified on versatile terrains including flat ground, stairs, and slopes.},
  archive      = {J_FROBT},
  author       = {Zhu, Hongwu and Wang, Dong and Boyd, Nathan and Zhou, Ziyi and Ruan, Lecheng and Zhang, Aidong and Ding, Ning and Zhao, Ye and Luo, Jianwen},
  doi          = {10.3389/frobt.2021.724138},
  journal      = {Frontiers in Robotics and AI},
  month        = {10},
  pages        = {724138},
  shortjournal = {Front. Robot. AI},
  title        = {Terrain-perception-free quadrupedal spinning locomotion on versatile terrains: Modeling, analysis, and experimental validation},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Hand-object interaction: From human demonstrations to robot
manipulation. <em>FROBT</em>, <em>8</em>, 714023. (<a
href="https://doi.org/10.3389/frobt.2021.714023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human-object interaction is of great relevance for robots to operate in human environments. However, state-of-the-art robotic hands are far from replicating humans skills. It is, therefore, essential to study how humans use their hands to develop similar robotic capabilities. This article presents a deep dive into hand-object interaction and human demonstrations, highlighting the main challenges in this research area and suggesting desirable future developments. To this extent, the article presents a general definition of the hand-object interaction problem together with a concise review for each of the main subproblems involved, namely: sensing, perception, and learning. Furthermore, the article discusses the interplay between these subproblems and describes how their interaction in learning from demonstration contributes to the success of robot manipulation. In this way, the article provides a broad overview of the interdisciplinary approaches necessary for a robotic system to learn new manipulation skills by observing human behavior in the real world.},
  archive      = {J_FROBT},
  author       = {Carfì, Alessandro and Patten, Timothy and Kuang, Yingyi and Hammoud, Ali and Alameh, Mohamad and Maiettini, Elisa and Weinberg, Abraham Itzhak and Faria, Diego and Mastrogiovanni, Fulvio and Alenyà, Guillem and Natale, Lorenzo and Perdereau, Véronique and Vincze, Markus and Billard, Aude},
  doi          = {10.3389/frobt.2021.714023},
  journal      = {Frontiers in Robotics and AI},
  month        = {10},
  pages        = {714023},
  shortjournal = {Front. Robot. AI},
  title        = {Hand-object interaction: From human demonstrations to robot manipulation},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Genetic algorithm for feature selection in lower limb
pattern recognition. <em>FROBT</em>, <em>8</em>, 710806. (<a
href="https://doi.org/10.3389/frobt.2021.710806">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Choosing the right features is important to optimize lower limb pattern recognition, such as in prosthetic control. EMG signals are noisy in nature, which makes it more challenging to extract useful information. Many features are used in the literature, which raises the question which features are most suited for use in lower limb myoelectric control. Therefore, it is important to find combinations of best performing features. One way to achieve this is by using a genetic algorithm, a meta-heuristic capable of searching vast feature spaces. The goal of this research is to demonstrate the capabilities of a genetic algorithm and come up with a feature set that has a better performance than the state-of-the-art feature set. In this study, we collected a dataset containing ten able-bodied subjects who performed various gait-related activities while measuring EMG and kinematics. The genetic algorithm selected features based on the performance on the training partition of this dataset. The selected feature sets were evaluated on the remaining test set and on the online benchmark dataset ENABL3S, against a state-of-the-art feature set. The results show that a feature set based on the selected features of a genetic algorithm outperforms the state-of-the-art set. The overall error decreased up to 0.54% and the transitional error by 2.44%, which represent a relative decrease in overall errors up to 11.6% and transitional errors up to 14.1%, although these results were not significant. This study showed that a genetic algorithm is capable of searching a large feature space and that systematic feature selection shows promising results for lower limb myoelectric control.},
  archive      = {J_FROBT},
  author       = {Schulte, Robert V. and Prinsen, Erik C. and Hermens, Hermie J. and Buurke, Jaap H.},
  doi          = {10.3389/frobt.2021.710806},
  journal      = {Frontiers in Robotics and AI},
  month        = {10},
  pages        = {710806},
  shortjournal = {Front. Robot. AI},
  title        = {Genetic algorithm for feature selection in lower limb pattern recognition},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Experimental evaluation of tactile sensors for compliant
robotic hands. <em>FROBT</em>, <em>8</em>, 704416. (<a
href="https://doi.org/10.3389/frobt.2021.704416">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The sense of touch is a key aspect in the human capability to robustly grasp and manipulate a wide variety of objects. Despite many years of development, there is still no preferred solution for tactile sensing in robotic hands: multiple technologies are available, each one with different benefits depending on the application. This study compares the performance of different tactile sensors mounted on the variable stiffness gripper CLASH 2F, including three commercial sensors: a single taxel sensor from the companies Tacterion and Kinfinity, the Robotic Finger Sensor v2 from Sparkfun, plus a self-built resistive 3 × 3 sensor array, and two self-built magnetic 3-DoF touch sensors, one with four taxels and one with one taxel. We verify the minimal force detectable by the sensors, test if slip detection is possible with the available taxels on each sensor, and use the sensors for edge detection to obtain the orientation of the grasped object. To evaluate the benefits obtained with each technology and to assess which sensor fits better the control loop in a variable stiffness hand, we use the CLASH gripper to grasp fruits and vegetables following a published benchmark for pick and place operations. To facilitate the repetition of tests, the CLASH hand is endowed with tactile buttons that ease human–robot interactions, including execution of a predefined program, resetting errors, or commanding the full robot to move in gravity compensation mode.},
  archive      = {J_FROBT},
  author       = {Friedl, Werner A. and Roa, Máximo A.},
  doi          = {10.3389/frobt.2021.704416},
  journal      = {Frontiers in Robotics and AI},
  month        = {10},
  pages        = {704416},
  shortjournal = {Front. Robot. AI},
  title        = {Experimental evaluation of tactile sensors for compliant robotic hands},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Personalizing HRI in musical instrument practicing: The
influence of robot roles (evaluative versus nonevaluative) on the
child’s motivation for children in different learning stages.
<em>FROBT</em>, <em>8</em>, 699524. (<a
href="https://doi.org/10.3389/frobt.2021.699524">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning to play a musical instrument involves skill learning and requires long-term practicing to reach expert levels. Research has already proven that the assistance of a robot can improve children’s motivation and performance during practice. In an earlier study, we showed that the specific role (evaluative role versus nonevaluative role) the robot plays can determine children’s motivation and performance. In the current study, we argue that the role of the robot has to be different for children in different learning stages (musical instrument expertise levels). Therefore, this study investigated whether children in different learning stages would have higher motivation when assisted by a robot in different supporting roles (i.e., evaluative role versus nonevaluative role). We conducted an empirical study in a real practice room of a music school with 31 children who were at different learning stages (i.e., beginners, developing players, and advanced players). In this study, every child practiced for three sessions: practicing alone, assisted by the evaluative robot, or assisted by the nonevaluative robot (in a random order). We measured motivation by using a questionnaire and analyzing video data. Results showed a significant interaction between condition (i.e., alone, evaluative robot, and nonevaluative robot) and learning stage groups indicating that children in different learning stage groups had different levels of motivation when practicing alone or with an evaluative or nonevaluative robot. More specifically, beginners had higher persistence when practicing with the nonevaluative robot, while advanced players expressed higher motivation after practicing with a robot than alone, but no difference was found between the two robot roles. Exploratory results also indicated that gender might have an interaction effect with the robot roles on child’s motivation in music practice with social robots. This study offers more insight into the child-robot interaction and robot role design in musical instrument learning. Specifically, our findings shed light on personalization in HRI, that is, from adapting the role of the robot to the characteristics and the development level of the user.},
  archive      = {J_FROBT},
  author       = {Song, Heqiu and Barakova, Emilia I. and Markopoulos, Panos and Ham, Jaap},
  doi          = {10.3389/frobt.2021.699524},
  journal      = {Frontiers in Robotics and AI},
  month        = {10},
  pages        = {699524},
  shortjournal = {Front. Robot. AI},
  title        = {Personalizing HRI in musical instrument practicing: The influence of robot roles (Evaluative versus nonevaluative) on the child’s motivation for children in different learning stages},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Kinematic-based classification of social gestures and
grasping by humans and machine learning techniques. <em>FROBT</em>,
<em>8</em>, 699505. (<a
href="https://doi.org/10.3389/frobt.2021.699505">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The affective motion of humans conveys messages that other humans perceive and understand without conventional linguistic processing. This ability to classify human movement into meaningful gestures or segments plays also a critical role in creating social interaction between humans and robots. In the research presented here, grasping and social gesture recognition by humans and four machine learning techniques (k-Nearest Neighbor, Locality-Sensitive Hashing Forest, Random Forest and Support Vector Machine) is assessed by using human classification data as a reference for evaluating the classification performance of machine learning techniques for thirty hand/arm gestures. The gestures are rated according to the extent of grasping motion on one task and the extent to which the same gestures are perceived as social according to another task. The results indicate that humans clearly rate differently according to the two different tasks. The machine learning techniques provide a similar classification of the actions according to grasping kinematics and social quality. Furthermore, there is a strong association between gesture kinematics and judgments of grasping and the social quality of the hand/arm gestures. Our results support previous research on intention-from-movement understanding that demonstrates the reliance on kinematic information for perceiving the social aspects and intentions in different grasping actions as well as communicative point-light actions.},
  archive      = {J_FROBT},
  author       = {Hemeren, Paul and Veto, Peter and Thill, Serge and Li, Cai and Sun, Jiong},
  doi          = {10.3389/frobt.2021.699505},
  journal      = {Frontiers in Robotics and AI},
  month        = {10},
  pages        = {699505},
  shortjournal = {Front. Robot. AI},
  title        = {Kinematic-based classification of social gestures and grasping by humans and machine learning techniques},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Solving the large-scale TSP problem in 1 h: Santa claus
challenge 2020. <em>FROBT</em>, <em>8</em>, 689908. (<a
href="https://doi.org/10.3389/frobt.2021.689908">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The scalability of traveling salesperson problem (TSP) algorithms for handling large-scale problem instances has been an open problem for a long time. We arranged a so-called Santa Claus challenge and invited people to submit their algorithms to solve a TSP problem instance that is larger than 1 M nodes given only 1 h of computing time. In this article, we analyze the results and show which design choices are decisive in providing the best solution to the problem with the given constraints. There were three valid submissions, all based on local search, including k-opt up to k = 5. The most important design choice turned out to be the localization of the operator using a neighborhood graph. The divide-and-merge strategy suffers a 2% loss of quality. However, via parallelization, the result can be obtained within less than 2 min, which can make a key difference in real-life applications.},
  archive      = {J_FROBT},
  author       = {Mariescu-Istodor, Radu and Fränti, Pasi},
  doi          = {10.3389/frobt.2021.689908},
  journal      = {Frontiers in Robotics and AI},
  month        = {10},
  pages        = {689908},
  shortjournal = {Front. Robot. AI},
  title        = {Solving the large-scale TSP problem in 1 h: Santa claus challenge 2020},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The sounds of softness. Designing sound for human-soft robot
interaction. <em>FROBT</em>, <em>8</em>, 674121. (<a
href="https://doi.org/10.3389/frobt.2021.674121">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we report on research and creative practice that explores the aesthetic interplay between movement and sound for soft robotics. Our inquiry seeks to interrogate what sound designs might be aesthetically engaging and appropriate for soft robotic movement in a social human-robot interaction setting. We present the design of a soft sound-producing robot, SONŌ, made of pliable and expandable silicone and three sound designs made for this robot. The article comprises an articulation of the underlying design process and results from two empirical interaction experiments (N = 66, N = 60) conducted to evaluate the sound designs. The sound designs did not have statistically significant effects on people’s perception of the social attributes of two different soft robots. Qualitative results, however, indicate that people’s interpretations of the sound designs depend on robot type.},
  archive      = {J_FROBT},
  author       = {Jørgensen, Jonas and Christiansen, Mads Bering},
  doi          = {10.3389/frobt.2021.674121},
  journal      = {Frontiers in Robotics and AI},
  month        = {10},
  pages        = {674121},
  shortjournal = {Front. Robot. AI},
  title        = {The sounds of softness. designing sound for human-soft robot interaction},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The intentional stance test-2: How to measure the tendency
to adopt intentional stance towards robots. <em>FROBT</em>, <em>8</em>,
666586. (<a href="https://doi.org/10.3389/frobt.2021.666586">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In human-robot interactions, people tend to attribute to robots mental states such as intentions or desires, in order to make sense of their behaviour. This cognitive strategy is termed “intentional stance”. Adopting the intentional stance influences how one will consider, engage and behave towards robots. However, people differ in their likelihood to adopt intentional stance towards robots. Therefore, it seems crucial to assess these interindividual differences. In two studies we developed and validated the structure of a task aiming at evaluating to what extent people adopt intentional stance towards robot actions, the Intentional Stance task (IST). The Intentional Stance Task consists in a task that probes participants’ stance by requiring them to choose the plausibility of a description (mentalistic vs. mechanistic) of behaviour of a robot depicted in a scenario composed of three photographs. Results showed a reliable psychometric structure of the IST. This paper therefore concludes with the proposal of using the IST as a proxy for assessing the degree of adoption of the intentional stance towards robots.},
  archive      = {J_FROBT},
  author       = {Spatola, Nicolas and Marchesi, Serena and Wykowska, Agnieszka},
  doi          = {10.3389/frobt.2021.666586},
  journal      = {Frontiers in Robotics and AI},
  month        = {10},
  pages        = {666586},
  shortjournal = {Front. Robot. AI},
  title        = {The intentional stance test-2: How to measure the tendency to adopt intentional stance towards robots},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Emergence of cooperative impression with self-estimation,
thinking time, and concordance of risk sensitivity in playing hanabi.
<em>FROBT</em>, <em>8</em>, 658348. (<a
href="https://doi.org/10.3389/frobt.2021.658348">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The authors evaluate the extent to which a user’s impression of an AI agent can be improved by giving the agent the ability of self-estimation, thinking time, and coordination of risk tendency. The authors modified the algorithm of an AI agent in the cooperative game Hanabi to have all of these traits, and investigated the change in the user’s impression by playing with the user. The authors used a self-estimation task to evaluate the effect that the ability to read the intention of a user had on an impression. The authors also show thinking time of an agent influences impression for an agent. The authors also investigated the relationship between the concordance of the risk-taking tendencies of players and agents, the player’s impression of agents, and the game experience. The results of the self-estimation task experiment showed that the more accurate the estimation of the agent’s self, the more likely it is that the partner will perceive humanity, affinity, intelligence, and communication skills in the agent. The authors also found that an agent that changes the length of thinking time according to the priority of action gives the impression that it is smarter than an agent with a normal thinking time when the player notices the difference in thinking time or an agent that randomly changes the thinking time. The result of the experiment regarding concordance of the risk-taking tendency shows that influence player’s impression toward agents. These results suggest that game agent designers can improve the player’s disposition toward an agent and the game experience by adjusting the agent’s self-estimation level, thinking time, and risk-taking tendency according to the player’s personality and inner state during the game.},
  archive      = {J_FROBT},
  author       = {Osawa, Hirotaka and Kawagoe, Atsushi and Sato, Eisuke and Kato, Takuya},
  doi          = {10.3389/frobt.2021.658348},
  journal      = {Frontiers in Robotics and AI},
  month        = {10},
  pages        = {658348},
  shortjournal = {Front. Robot. AI},
  title        = {Emergence of cooperative impression with self-estimation, thinking time, and concordance of risk sensitivity in playing hanabi},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The SMOOTH-robot: A modular, interactive service robot.
<em>FROBT</em>, <em>8</em>, 645639. (<a
href="https://doi.org/10.3389/frobt.2021.645639">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The SMOOTH-robot is a mobile robot that—due to its modularity—combines a relatively low price with the possibility to be used for a large variety of tasks in a wide range of domains. In this article, we demonstrate the potential of the SMOOTH-robot through three use cases, two of which were performed in elderly care homes. The robot is designed so that it can either make itself ready or be quickly changed by staff to perform different tasks. We carefully considered important design parameters such as the appearance, intended and unintended interactions with users, and the technical complexity, in order to achieve high acceptability and a sufficient degree of utilization of the robot. Three demonstrated use cases indicate that such a robot could contribute to an improved work environment, having the potential to free resources of care staff which could be allocated to actual care-giving tasks. Moreover, the SMOOTH-robot can be used in many other domains, as we will also exemplify in this article.},
  archive      = {J_FROBT},
  author       = {Krüger, Norbert and Fischer, Kerstin and Manoonpong, Poramate and Palinko, Oskar and Bodenhagen, Leon and Baumann, Timo and Kjærum, Jens and Rano, Ignacio and Naik, Lakshadeep and Juel, William Kristian and Haarslev, Frederik and Ignasov, Jevgeni and Marchetti, Emanuela and Langedijk, Rosalyn Melissa and Kollakidou, Avgi and Jeppesen, Kasper Camillus and Heidtmann, Conny and Dalgaard, Lars},
  doi          = {10.3389/frobt.2021.645639},
  journal      = {Frontiers in Robotics and AI},
  month        = {10},
  pages        = {645639},
  shortjournal = {Front. Robot. AI},
  title        = {The SMOOTH-robot: A modular, interactive service robot},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Assessing the role of gaze tracking in optimizing
humans-in-the-loop telerobotic operation using multimodal feedback.
<em>FROBT</em>, <em>8</em>, 578596. (<a
href="https://doi.org/10.3389/frobt.2021.578596">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A key challenge in achieving effective robot teleoperation is minimizing teleoperators’ cognitive workload and fatigue. We set out to investigate the extent to which gaze tracking data can reveal how teleoperators interact with a system. In this study, we present an analysis of gaze tracking, captured as participants completed a multi-stage task: grasping and emptying the contents of a jar into a container. The task was repeated with different combinations of visual, haptic, and verbal feedback. Our aim was to determine if teleoperation workload can be inferred by combining the gaze duration, fixation count, task completion time, and complexity of robot motion (measured as the sum of robot joint steps) at different stages of the task. Visual information of the robot workspace was captured using four cameras, positioned to capture the robot workspace from different angles. These camera views (aerial, right, eye-level, and left) were displayed through four quadrants (top-left, top-right, bottom-left, and bottom-right quadrants) of participants’ video feedback computer screen, respectively. We found that the gaze duration and the fixation count were highly dependent on the stage of the task and the feedback scenario utilized. The results revealed that combining feedback modalities reduced the cognitive workload (inferred by investigating the correlation between gaze duration, fixation count, task completion time, success or failure of task completion, and robot gripper trajectories), particularly in the task stages that require more precision. There was a significant positive correlation between gaze duration and complexity of robot joint movements. Participants’ gaze outside the areas of interest (distractions) was not influenced by feedback scenarios. A learning effect was observed in the use of the controller for all participants as they repeated the task with different feedback combination scenarios. To design a system for teleoperation, applicable in healthcare, we found that the analysis of teleoperators’ gaze can help understand how teleoperators interact with the system, hence making it possible to develop the system from the teleoperators’ stand point.},
  archive      = {J_FROBT},
  author       = {Bolarinwa, Joseph and Eimontaite, Iveta and Mitchell, Tom and Dogramadzi, Sanja and Caleb-Solly, Praminda},
  doi          = {10.3389/frobt.2021.578596},
  journal      = {Frontiers in Robotics and AI},
  month        = {10},
  pages        = {578596},
  shortjournal = {Front. Robot. AI},
  title        = {Assessing the role of gaze tracking in optimizing humans-in-the-loop telerobotic operation using multimodal feedback},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Microbial fuel cell based thermosensor for robotic
applications. <em>FROBT</em>, <em>8</em>, 558953. (<a
href="https://doi.org/10.3389/frobt.2021.558953">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {On the roadmap to building completely autonomous artificial bio-robots, all major aspects of robotic functions, namely, energy generation, processing, sensing, and actuation, need to be self-sustainable and function in the biological realm. Microbial Fuel Cells (MFCs) provide a platform technology for achieving this goal. In a series of experiments, we demonstrate that MFCs can be used as living, autonomous sensors in robotics. In this work, we focus on thermal sensing that is akin to thermoreceptors in mammalian entities. We therefore designed and tested an MFC-based thermosensor system for utilization within artificial bio-robots such as EcoBots. In open-loop sensor characterization, with a controlled load resistance and feed rate, the MFC thermoreceptor was able to detect stimuli of 1 min directed from a distance of 10 cm causing a temperature rise of ∼1°C at the thermoreceptor. The thermoreceptor responded to continuous stimuli with a minimum interval of 384 s. In a practical demonstration, a mobile robot was fitted with two artificial thermosensors, as environmental thermal detectors for thermotactic application, mimicking thermotaxis in biology. In closed-loop applications, continuous thermal stimuli were detected at a minimum time interval of 160 s, without the need for complete thermoreceptor recovery. This enabled the robot to detect thermal stimuli and steer away from a warmer thermal source within the rise of 1°C. We envision that the thermosensor can be used for future applications in robotics, including as a potential sensor mechanism for maintaining thermal homeostasis.},
  archive      = {J_FROBT},
  author       = {Greenman, John and Mendis, Arjuna and You, Jiseon and Gajda, Iwona and Horsfield, Ian and Ieropoulos, Ioannis},
  doi          = {10.3389/frobt.2021.558953},
  journal      = {Frontiers in Robotics and AI},
  month        = {10},
  pages        = {558953},
  shortjournal = {Front. Robot. AI},
  title        = {Microbial fuel cell based thermosensor for robotic applications},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Editorial: Robots that learn and reason: Towards learning
logic rules from noisy data. <em>FROBT</em>, <em>8</em>, 755933. (<a
href="https://doi.org/10.3389/frobt.2021.755933">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Moreno, Plinio and Bernardino, Alexandre and Santos-Victor, José and Ventura, Rodrigo and Kersting, Kristian},
  doi          = {10.3389/frobt.2021.755933},
  journal      = {Frontiers in Robotics and AI},
  month        = {9},
  pages        = {755933},
  shortjournal = {Front. Robot. AI},
  title        = {Editorial: robots that learn and reason: towards learning logic rules from noisy data},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Turning neural prosthetics into viable products.
<em>FROBT</em>, <em>8</em>, 754114. (<a
href="https://doi.org/10.3389/frobt.2021.754114">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Academic researchers concentrate on the scientific and technological feasibility of novel treatments. Investors and commercial partners, however, understand that success depends even more on strategies for regulatory approval, reimbursement, marketing, intellectual property protection and risk management. These considerations are critical for technologically complex and highly invasive treatments that entail substantial costs and risks in small and heterogeneous patient populations. Most implanted neural prosthetic devices for novel applications will be in FDA Device Class III, for which guidance documents have been issued recently. Less invasive devices may be eligible for the recently simplified “de novo” submission routes. We discuss typical timelines and strategies for integrating the regulatory path with approval for reimbursement, securing intellectual property and funding the enterprise, particularly as they might apply to implantable brain-computer interfaces for sensorimotor disabilities that do not yet have a track record of approved products.},
  archive      = {J_FROBT},
  author       = {Loeb, Gerald E. and Richmond, Frances J.},
  doi          = {10.3389/frobt.2021.754114},
  journal      = {Frontiers in Robotics and AI},
  month        = {9},
  pages        = {754114},
  shortjournal = {Front. Robot. AI},
  title        = {Turning neural prosthetics into viable products},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Pneumatic soft actuators with kirigami skins.
<em>FROBT</em>, <em>8</em>, 749051. (<a
href="https://doi.org/10.3389/frobt.2021.749051">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Soft pneumatic actuators have become indispensable for many robotic applications due to their reliability, safety, and design flexibility. However, the currently available actuator designs can be challenging to fabricate, requiring labor-intensive and time-consuming processes like reinforcing fiber wrapping and elastomer curing. To address this issue, we propose to use simple-to-fabricate kirigami skins—plastic sleeves with carefully arranged slit cuts—to construct pneumatic actuators with pre-programmable motion capabilities. Such kirigami skin, wrapped outside a cylindrical balloon, can transform the volumetric expansion from pneumatic pressure into anisotropic stretching and shearing, creating a combination of axial extension and twisting in the actuator. Moreover, the kirigami skin exhibits out-of-plane buckling near the slit cut, which enables high stretchability. To capture such complex deformations, we formulate and experimentally validates a new kinematics model to uncover the linkage between the kirigami cutting pattern design and the actuator’s motion characteristics. This model uses a virtual fold and rigid-facet assumption to simplify the motion analysis without sacrificing accuracy. Moreover, we tested the pressure-stroke performance and elastoplastic behaviors of the kirigami-skinned actuator to establish an operation protocol for repeatable performance. Analytical and experimental parametric analysis shows that one can effectively pre-program the actuator’s motion performance, with considerable freedom, simply by adjusting the angle and length of the slit cuts. The results of this study can establish the design and analysis framework for a new family of kirigami-skinned pneumatic actuators for many robotic applications.},
  archive      = {J_FROBT},
  author       = {Khosravi, Hesameddin and Iannucci, Steven M. and Li, Suyi},
  doi          = {10.3389/frobt.2021.749051},
  journal      = {Frontiers in Robotics and AI},
  month        = {9},
  pages        = {749051},
  shortjournal = {Front. Robot. AI},
  title        = {Pneumatic soft actuators with kirigami skins},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Tool-use model to reproduce the goal situations considering
relationship among tools, objects, actions and effects using multimodal
deep neural networks. <em>FROBT</em>, <em>8</em>, 748716. (<a
href="https://doi.org/10.3389/frobt.2021.748716">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a tool-use model that enables a robot to act toward a provided goal. It is important to consider features of the four factors; tools, objects actions, and effects at the same time because they are related to each other and one factor can influence the others. The tool-use model is constructed with deep neural networks (DNNs) using multimodal sensorimotor data; image, force, and joint angle information. To allow the robot to learn tool-use, we collect training data by controlling the robot to perform various object operations using several tools with multiple actions that leads different effects. Then the tool-use model is thereby trained and learns sensorimotor coordination and acquires relationships among tools, objects, actions and effects in its latent space. We can give the robot a task goal by providing an image showing the target placement and orientation of the object. Using the goal image with the tool-use model, the robot detects the features of tools and objects, and determines how to act to reproduce the target effects automatically. Then the robot generates actions adjusting to the real time situations even though the tools and objects are unknown and more complicated than trained ones.},
  archive      = {J_FROBT},
  author       = {Saito, Namiko and Ogata, Tetsuya and Mori, Hiroki and Murata, Shingo and Sugano, Shigeki},
  doi          = {10.3389/frobt.2021.748716},
  journal      = {Frontiers in Robotics and AI},
  month        = {9},
  pages        = {748716},
  shortjournal = {Front. Robot. AI},
  title        = {Tool-use model to reproduce the goal situations considering relationship among tools, objects, actions and effects using multimodal deep neural networks},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A systematic review of human and robot personality in health
care human-robot interaction. <em>FROBT</em>, <em>8</em>, 748246. (<a
href="https://doi.org/10.3389/frobt.2021.748246">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robots have become vital to the delivery of health care and their personalities are often important to understanding their effectiveness as health care providers. Despite this, there is a lack of a systematic overarching understanding of personality in health care human-robot interaction. This makes it difficult to understand what we know and do not know about the impact of personality in health care human-robot interaction (H-HRI). As a result, our understanding of personality in H-HRI has not kept pace with the deployment of robots in various health care environments. To address this, the authors conducted a literature review that identified 18 studies on personality in H-HRI. This paper expands, refines, and further explicates the systematic review done in a conference proceedings [see: Esterwood (Proceedings of the 8th International Conference on Human-Agent Interaction, 2020, 87–95)]. Review results: 1) highlight major thematic research areas, 2) derive and present major conclusions from the literature, 3) identify gaps in the literature, and 4) offer guidance for future H-HRI researchers. Overall, this paper represents a reflection on the existing literature and provides an important starting point for future research on personality in H-HRI.},
  archive      = {J_FROBT},
  author       = {Esterwood , Connor and Robert, Lionel P.},
  doi          = {10.3389/frobt.2021.748246},
  journal      = {Frontiers in Robotics and AI},
  month        = {9},
  pages        = {748246},
  shortjournal = {Front. Robot. AI},
  title        = {A systematic review of human and robot personality in health care human-robot interaction},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Atomization control to improve soft actuation through
vaporization. <em>FROBT</em>, <em>8</em>, 747440. (<a
href="https://doi.org/10.3389/frobt.2021.747440">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Soft actuation through droplet evaporation has significantly improved the actuation speed of methods that utilize liquid vaporization. Instead of boiling bulk liquid, this method implements atomization to disperse small droplets into a heater. Due to the large surface area of the droplets, the liquid evaporates much faster even at small temperature changes. However, further analysis is required to maximize the performance of this complex multi-physics method. This study was conducted to provide further insight into the atomizer and how it affects actuation. Numerical simulations were used to inspect the vibration modes and determine how frequency and voltage affect the atomization process. These results were used to experimentally control the atomizer, and the droplet growth on the heater surface was analyzed to study the evaporation process. A cuboid structure was inflated with the actuator to demonstrate its performance. The results show that simply maximizing the atomization rate creates large droplets on the surface of the heater, which slows down the vaporization process. Thus, an optimal atomization rate should be determined for ideal performance.},
  archive      = {J_FROBT},
  author       = {Lee, Han-Joo and Guerra-Bravo, Esteban and Baltazar, Arturo and Loh, Kenneth J.},
  doi          = {10.3389/frobt.2021.747440},
  journal      = {Frontiers in Robotics and AI},
  month        = {9},
  pages        = {747440},
  shortjournal = {Front. Robot. AI},
  title        = {Atomization control to improve soft actuation through vaporization},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Perception by palpation: Development and testing of a haptic
ferrogranular jamming surface. <em>FROBT</em>, <em>8</em>, 745234. (<a
href="https://doi.org/10.3389/frobt.2021.745234">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tactile hands-only training is particularly important for medical palpation. Generally, equipment for palpation training is expensive, static, or provides too few study cases to practice on. We have therefore developed a novel haptic surface concept for palpation training, using ferrogranular jamming. The concept’s design consists of a tactile field spanning 260 x 160 mm, and uses ferromagnetic granules to alter shape, position, and hardness of palpable irregularities. Granules are enclosed in a compliant vacuum-sealed chamber connected to a pneumatic system. A variety of geometric shapes (output) can be obtained by manipulating and arranging granules with permanent magnets. The tactile hardness of the palpable output can be controlled by adjusting the chamber’s vacuum level. A psychophysical experiment (N = 28) investigated how people interact with the palpable surface and evaluated the proposed concept. Untrained participants characterized irregularities with different position, form, and hardness through palpation, and their performance was evaluated. A baseline (no irregularity) was compared to three irregularity conditions: two circular shapes with different hardness (Hard Lump and Soft Lump), and an Annulus shape. 100% of participants correctly identified an irregularity in the three irregularity conditions, whereas 78.6% correctly identified baseline. Overall agreement between participants was high (κ= 0.723). The Intersection over Union (IoU) for participants sketched outline over the actual shape was IoU Mdn = 79.3% for Soft Lump, IoU Mdn = 68.8% for Annulus, and IoU Mdn = 76.7% for Hard Lump. The distance from actual to drawn center was Mdn = 6.4 mm (Soft Lump), Mdn = 5.3 mm (Annulus), and Mdn = 7.4 mm (Hard Lump), which are small distances compared to the size of the field. The participants subjectively evaluated Soft Lump to be significantly softer than Hard Lump and Annulus. Moreover, 71% of participants thought they improved their palpation skills throughout the experiment. Together, these results show that the concept can render irregularities with different position, form, and hardness, and that users are able to locate and characterize these through palpation. Participants experienced an improvement in palpation skills throughout the experiment, which indicates the concepts feasibility as a palpation training device.},
  archive      = {J_FROBT},
  author       = {Rørvik, Sigurd Bjarne and Auflem, Marius and Dybvik, Henrikke and Steinert, Martin},
  doi          = {10.3389/frobt.2021.745234},
  journal      = {Frontiers in Robotics and AI},
  month        = {9},
  pages        = {745234},
  shortjournal = {Front. Robot. AI},
  title        = {Perception by palpation: Development and testing of a haptic ferrogranular jamming surface},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Challenging the neo-anthropocentric relational approach to
robot rights. <em>FROBT</em>, <em>8</em>, 744426. (<a
href="https://doi.org/10.3389/frobt.2021.744426">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When will it make sense to consider robots candidates for moral standing? Major disagreements exist between those who find that question important and those who do not, and also between those united in their willingness to pursue the question. I narrow in on the approach to robot rights called relationalism, and ask: if we provide robots moral standing based on how humans relate to them, are we moving past human chauvinism, or are we merely putting a new dress on it? The background for the article is the clash between those who argue that robot rights are possible and those who see a fight for robot rights as ludicrous, unthinkable, or just outright harmful and disruptive for humans. The latter group are by some branded human chauvinists and anthropocentric, and they are criticized and portrayed as backward, unjust, and ignorant of history. Relationalism, in contrast, purportedly opens the door for considering robot rights and moving past anthropocentrism. However, I argue that relationalism is, quite to the contrary, a form of neo-anthropocentrism that recenters human beings and their unique ontological properties, perceptions, and values. I do so by raising three objections: 1) relationalism centers human values and perspectives, 2) it is indirectly a type of properties-based approach, and 3) edge cases reveal potentially absurd implications in practice.},
  archive      = {J_FROBT},
  author       = {Sætra, Henrik Skaug},
  doi          = {10.3389/frobt.2021.744426},
  journal      = {Frontiers in Robotics and AI},
  month        = {9},
  pages        = {744426},
  shortjournal = {Front. Robot. AI},
  title        = {Challenging the neo-anthropocentric relational approach to robot rights},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Robust ASV navigation through ground to water cross-domain
deep reinforcement learning. <em>FROBT</em>, <em>8</em>, 739023. (<a
href="https://doi.org/10.3389/frobt.2021.739023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a framework to alleviate the Deep Reinforcement Learning (DRL) training data sparsity problem that is present in challenging domains by creating a DRL agent training and vehicle integration methodology. The methodology leverages accessible domains to train an agent to solve navigational problems such as obstacle avoidance and allows the agent to generalize to challenging and inaccessible domains such as those present in marine environments with minimal further training. This is done by integrating a DRL agent at a high level of vehicle control and leveraging existing path planning and proven low-level control methodologies that are utilized in multiple domains. An autonomy package with a tertiary multilevel controller is developed to enable the DRL agent to interface at the prescribed high control level and thus be separated from vehicle dynamics and environmental constraints. An example Deep Q Network (DQN) employing this methodology for obstacle avoidance is trained in a simulated ground environment, and then its ability to generalize across domains is experimentally validated. Experimental validation utilized a simulated water surface environment and real-world deployment of ground and water robotic platforms. This methodology, when used, shows that it is possible to leverage accessible and data rich domains, such as ground, to effectively develop marine DRL agents for use on Autonomous Surface Vehicle (ASV) navigation. This will allow rapid and iterative agent development without the risk of ASV loss, the cost and logistic overhead of marine deployment, and allow landlocked institutions to develop agents for marine applications.},
  archive      = {J_FROBT},
  author       = {Lambert, Reeve and Li, Jianwen and Wu, Li-Fan and Mahmoudian, Nina},
  doi          = {10.3389/frobt.2021.739023},
  journal      = {Frontiers in Robotics and AI},
  month        = {9},
  pages        = {739023},
  shortjournal = {Front. Robot. AI},
  title        = {Robust ASV navigation through ground to water cross-domain deep reinforcement learning},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Autonomous collision avoidance at sea: A survey.
<em>FROBT</em>, <em>8</em>, 739013. (<a
href="https://doi.org/10.3389/frobt.2021.739013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this survey, results from an investigation on collision avoidance and path planning methods developed in recent research are provided. In particular, existing methods based on Artificial Intelligence, data-driven methods based on Machine Learning, and other Data Science approaches are investigated to provide a comprehensive overview of maritime collision avoidance techniques applicable to Maritime Autonomous Surface Ships. Relevant aspects of those methods and approaches are summarized and put into suitable perspectives. As autonomous systems are expected to operate alongside or in place of conventionally manned vessels, they must comply with the COLREGs for robust decision-support/-making. Thus, the survey specifically covers how COLREGs are addressed by the investigated methods and approaches. A conclusion regarding their utilization in industrial implementations is drawn.},
  archive      = {J_FROBT},
  author       = {Burmeister, Hans-Christoph and Constapel, Manfred},
  doi          = {10.3389/frobt.2021.739013},
  journal      = {Frontiers in Robotics and AI},
  month        = {9},
  pages        = {739013},
  shortjournal = {Front. Robot. AI},
  title        = {Autonomous collision avoidance at sea: A survey},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Comparing deep reinforcement learning algorithms’ ability to
safely navigate challenging waters. <em>FROBT</em>, <em>8</em>, 738113.
(<a href="https://doi.org/10.3389/frobt.2021.738113">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reinforcement Learning (RL) controllers have proved to effectively tackle the dual objectives of path following and collision avoidance. However, finding which RL algorithm setup optimally trades off these two tasks is not necessarily easy. This work proposes a methodology to explore this that leverages analyzing the performance and task-specific behavioral characteristics for a range of RL algorithms applied to path-following and collision-avoidance for underactuated surface vehicles in environments of increasing complexity. Compared to the introduced RL algorithms, the results show that the Proximal Policy Optimization (PPO) algorithm exhibits superior robustness to changes in the environment complexity, the reward function, and when generalized to environments with a considerable domain gap from the training environment. Whereas the proposed reward function significantly improves the competing algorithms’ ability to solve the training environment, an unexpected consequence of the dimensionality reduction in the sensor suite, combined with the domain gap, is identified as the source of their impaired generalization performance.},
  archive      = {J_FROBT},
  author       = {Larsen, Thomas Nakken and Teigen, Halvor Ødegård and Laache, Torkel and Varagnolo, Damiano and Rasheed, Adil},
  doi          = {10.3389/frobt.2021.738113},
  journal      = {Frontiers in Robotics and AI},
  month        = {9},
  pages        = {738113},
  shortjournal = {Front. Robot. AI},
  title        = {Comparing deep reinforcement learning algorithms’ ability to safely navigate challenging waters},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Highly sensitive flexible pressure sensors enabled by mixing
of silicone elastomer with ionic liquid-grafted silicone oil.
<em>FROBT</em>, <em>8</em>, 737500. (<a
href="https://doi.org/10.3389/frobt.2021.737500">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Developing highly sensitive flexible pressure sensors has become crucially urgent due to the increased societal demand for wearable electronic devices capable of monitoring various human motions. The sensitivity of such sensors has been shown to be significantly enhanced by increasing the relative dielectric permittivity of the dielectric layers used in device construction via compositing with immiscible ionic conductors. Unfortunately, however, the elastomers employed for this purpose possess inhomogeneous morphologies, and thus suffer from poor long-term durability and unstable electrical response. In this study, we developed a novel, flexible, and highly sensitive pressure sensor using an elastomeric dielectric layer with particularly high permittivity and homogeneity due to the addition of synthesized ionic liquid-grafted silicone oil (denoted LMS-EIL). LMS-EIL possesses both a very high relative dielectric permittivity (9.6 × 105 at 10−1 Hz) and excellent compatibility with silicone elastomers due to the covalently connected structure of conductive ionic liquid (IL) and chloropropyl silicone oil. A silicone elastomer with a relative permittivity of 22 at 10−1 Hz, Young’s modulus of 0.78 MPa, and excellent homogeneity was prepared by incorporating 10 phr (parts per hundreds rubber) of LMS-EIL into an elastomer matrix. The sensitivity of the pressure sensor produced using this optimized silicone elastomer was 0.51 kPa−1, which is 100 times higher than that of the pristine elastomer. In addition, a high durability illustrated by 100 loading–unloading cycles and a rapid response and recovery time of approximately 60 ms were achieved. The excellent performance of this novel pressure sensor suggests significant potential for use in human interfaces, soft robotics, and electronic skin applications.},
  archive      = {J_FROBT},
  author       = {Kang, Zhaoqing and Nie, Yi and Yu, Liyun and Zhang, Suojiang and Skov, Anne Ladegaard},
  doi          = {10.3389/frobt.2021.737500},
  journal      = {Frontiers in Robotics and AI},
  month        = {9},
  pages        = {737500},
  shortjournal = {Front. Robot. AI},
  title        = {Highly sensitive flexible pressure sensors enabled by mixing of silicone elastomer with ionic liquid-grafted silicone oil},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A digital twin approach for contextual assistance for
surgeons during surgical robotics training. <em>FROBT</em>, <em>8</em>,
735566. (<a href="https://doi.org/10.3389/frobt.2021.735566">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Minimally invasive robotic surgery copes with some disadvantages for the surgeon of minimally invasive surgery while preserving the advantages for the patient. Most commercially available robotic systems are telemanipulated with haptic input devices. The exploitation of the haptics channel, e.g., by means of Virtual Fixtures, would allow for an individualized enhancement of surgical performance with contextual assistance. However, it remains an open field of research as it is non-trivial to estimate the task context itself during a surgery. In contrast, surgical training allows to abstract away from a real operation and thus makes it possible to model the task accurately. The presented approach exploits this fact to parameterize Virtual Fixtures during surgical training, proposing a Shared Control Parametrization Engine that retrieves procedural context information from a Digital Twin. This approach accelerates a proficient use of the robotic system for novice surgeons by augmenting the surgeon’s performance through haptic assistance. With this our aim is to reduce the required skill level and cognitive load of a surgeon performing minimally invasive robotic surgery. A pilot study is performed on the DLR MiroSurge system to evaluate the presented approach. The participants are tasked with two benchmark scenarios of surgical training. The execution of the benchmark scenarios requires basic skills as pick, place and path following. The evaluation of the pilot study shows the promising trend that novel users profit from the haptic augmentation during training of certain tasks.},
  archive      = {J_FROBT},
  author       = {Hagmann, Katharina and Hellings-Kuß, Anja and Klodmann, Julian and Richter, Rebecca and Stulp, Freek and Leidner, Daniel},
  doi          = {10.3389/frobt.2021.735566},
  journal      = {Frontiers in Robotics and AI},
  month        = {9},
  pages        = {735566},
  shortjournal = {Front. Robot. AI},
  title        = {A digital twin approach for contextual assistance for surgeons during surgical robotics training},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Motion polytopes in virtual reality for shared control in
remote manipulation applications. <em>FROBT</em>, <em>8</em>, 730433.
(<a href="https://doi.org/10.3389/frobt.2021.730433">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In remote applications that mandate human supervision, shared control can prove vital by establishing a harmonious balance between the high-level cognition of a user and the low-level autonomy of a robot. Though in practice, achieving this balance is a challenging endeavor that largely depends on whether the operator effectively interprets the underlying shared control. Inspired by recent works on using immersive technologies to expose the internal shared control, we develop a virtual reality system to visually guide human-in-the-loop manipulation. Our implementation of shared control teleoperation employs end effector manipulability polytopes, which are geometrical constructs that embed joint limit and environmental constraints. These constructs capture a holistic view of the constrained manipulator’s motion and can thus be visually represented as feedback for users on their operable space of movement. To assess the efficacy of our proposed approach, we consider a teleoperation task where users manipulate a screwdriver attached to a robotic arm’s end effector. A pilot study with prospective operators is first conducted to discern which graphical cues and virtual reality setup are most preferable. Feedback from this study informs the final design of our virtual reality system, which is subsequently evaluated in the actual screwdriver teleoperation experiment. Our experimental findings support the utility of using polytopes for shared control teleoperation, but hint at the need for longer-term studies to garner their full benefits as virtual guides.},
  archive      = {J_FROBT},
  author       = {Zolotas , Mark and Wonsick , Murphy and Long , Philip and Padır , Taşkın},
  doi          = {10.3389/frobt.2021.730433},
  journal      = {Frontiers in Robotics and AI},
  month        = {9},
  pages        = {730433},
  shortjournal = {Front. Robot. AI},
  title        = {Motion polytopes in virtual reality for shared control in remote manipulation applications},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A 3D-printable robotic gripper based on thick panel origami.
<em>FROBT</em>, <em>8</em>, 730227. (<a
href="https://doi.org/10.3389/frobt.2021.730227">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Origami has been a source of inspiration for the design of robots because it can be easily produced using 2D materials and its motions can be well quantified. However, most applications to date have utilised origami patterns for thin sheet materials with a negligible thickness. If the thickness of the material cannot be neglected, commonly known as the thick panel origami, the creases need to be redesigned. One approach is to place creases either on top or bottom surfaces of a sheet of finite thickness. As a result, spherical linkages in the zero-thickness origami are replaced by spatial linkages in the thick panel one, leading to a reduction in the overall degrees of freedom (DOFs). For instance, a waterbomb pattern for a zero-thickness sheet shows multiple DOFs while its thick panel counterpart has only one DOF, which significantly reduces the complexity of motion control. In this article, we present a robotic gripper derived from a unit that is based on the thick panel six-crease waterbomb origami. Four such units complete the gripper. Kinematically, each unit is a plane-symmetric Bricard linkage, and the gripper can be modelled as an assembly of Bricard linkages, giving it single mobility. A gripper prototype was made using 3D printing technology, and its motion was controlled by a set of tendons tied to a single motor. Detailed kinematic modelling was done, and experiments were carried out to characterise the gripper’s behaviours. The positions of the tips on the gripper, the actuation force on tendons, and the grasping force generated on objects were analysed and measured. The experimental results matched well with the analytical ones, and the repeated tests demonstrate that the concept is viable. Furthermore, we observed that the gripper was also capable of grasping non-symmetrical objects, and such performance is discussed in detail in the paper.},
  archive      = {J_FROBT},
  author       = {Liu, Chenying and Maiolino, Perla and You, Zhong},
  doi          = {10.3389/frobt.2021.730227},
  journal      = {Frontiers in Robotics and AI},
  month        = {9},
  pages        = {730227},
  shortjournal = {Front. Robot. AI},
  title        = {A 3D-printable robotic gripper based on thick panel origami},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Automatic detection of gaze and body orientation in
elementary school classrooms. <em>FROBT</em>, <em>8</em>, 729832. (<a
href="https://doi.org/10.3389/frobt.2021.729832">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Detecting the direction of the gaze and orientation of the body of both teacher and students is essential to estimate who is paying attention to whom. It also provides vital clues for understanding their unconscious, non-verbal behavior. These are called “honest signals” since they are unconscious subtle patterns in our interaction with other people that help reveal the focus of our attention. Inside the classroom, they provide important clues about teaching practices and students&#39; responses to different conscious and unconscious teaching strategies. Scanning this non-verbal behavior in the classroom can provide important feedback to the teacher in order for them to improve their teaching practices. This type of analysis usually requires sophisticated eye-tracking equipment, motion sensors, or multiple cameras. However, for this to be a useful tool in the teacher&#39;s daily practice, an alternative must be found using only a smartphone. A smartphone is the only instrument that a teacher always has at their disposal and is nowadays considered truly ubiquitous. Our study looks at data from a group of first-grade classrooms. We show how video recordings on a teacher&#39;s smartphone can be used in order to estimate the direction of the teacher and students’ gaze, as well as their body orientation. Using the output from the OpenPose software, we run Machine Learning (ML) algorithms to train an estimator to recognize the direction of the students’ gaze and body orientation. We found that the level of accuracy achieved is comparable to that of human observers watching frames from the videos. The mean square errors (RMSE) of the predicted pitch and yaw angles for head and body directions are on average 11% lower than the RMSE between human annotators. However, our solution is much faster, avoids the tedium of doing it manually, and makes it possible to design solutions that give the teacher feedback as soon as they finish the class.},
  archive      = {J_FROBT},
  author       = {Araya, Roberto and Sossa-Rivera, Jorge},
  doi          = {10.3389/frobt.2021.729832},
  journal      = {Frontiers in Robotics and AI},
  month        = {9},
  pages        = {729832},
  shortjournal = {Front. Robot. AI},
  title        = {Automatic detection of gaze and body orientation in elementary school classrooms},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Augmented reality meets artificial intelligence in robotics:
A systematic review. <em>FROBT</em>, <em>8</em>, 724798. (<a
href="https://doi.org/10.3389/frobt.2021.724798">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, advancements in computational machinery have facilitated the integration of artificial intelligence (AI) to almost every field and industry. This fast-paced development in AI and sensing technologies have stirred an evolution in the realm of robotics. Concurrently, augmented reality (AR) applications are providing solutions to a myriad of robotics applications, such as demystifying robot motion intent and supporting intuitive control and feedback. In this paper, research papers combining the potentials of AI and AR in robotics over the last decade are presented and systematically reviewed. Four sources for data collection were utilized: Google Scholar, Scopus database, the International Conference on Robotics and Automation 2020 proceedings, and the references and citations of all identified papers. A total of 29 papers were analyzed from two perspectives: a theme-based perspective showcasing the relation between AR and AI, and an application-based analysis highlighting how the robotics application was affected. These two sections are further categorized based on the type of robotics platform and the type of robotics application, respectively. We analyze the work done and highlight some of the prevailing limitations hindering the field. Results also explain how AR and AI can be combined to solve the model-mismatch paradigm by creating a closed feedback loop between the user and the robot. This forms a solid base for increasing the efficiency of the robotic application and enhancing the user’s situational awareness, safety, and acceptance of AI robots. Our findings affirm the promising future for robust integration of AR and AI in numerous robotic applications.},
  archive      = {J_FROBT},
  author       = {Bassyouni, Zahraa and Elhajj, Imad H.},
  doi          = {10.3389/frobt.2021.724798},
  journal      = {Frontiers in Robotics and AI},
  month        = {9},
  pages        = {724798},
  shortjournal = {Front. Robot. AI},
  title        = {Augmented reality meets artificial intelligence in robotics: A systematic review},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Versatile dynamic motion generation framework: Demonstration
with a crutch-less exoskeleton on real-life obstacles at the cybathlon
2020 with a complete paraplegic person. <em>FROBT</em>, <em>8</em>,
723780. (<a href="https://doi.org/10.3389/frobt.2021.723780">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lower-limb exoskeletons are a promising option to increase the mobility of persons with leg impairments in a near future. However, it is still challenging for them to ensure the necessary stability and agility to face obstacles, particularly the variety that makes the urban environment. That is why most of the lower-limb exoskeletons must be used with crutches: the stability and agility features are deferred to the patient. Clinical experience shows that the use of crutches not only leads to shoulder pain and exhaustion, but also fully occupies the hands for daily tasks. In November 2020, Wandercraft presented Atalante Evolution, the first self-stabilized and crutch-less exoskeleton, to the powered exoskeleton race of the Cybathlon 2020 Global Edition. The Cybathlon aims at promoting research and development in the field of powered assistive technology to the public, contrary to the Paralympics where only participants with unpowered assistive technology are allowed. The race is designed to represent the challenges that a person could face every day in their environment: climbing stairs, walking through rough terrain, or descending ramps. Atalante Evolution is a 12 degree-of-freedom exoskeleton capable of moving dynamically with a complete paraplegic person. The challenge of this competition is to generate and execute new dynamic motions in a short time, to achieve different tasks. In this paper, an overview of Atalante Evolution system and of our framework for dynamic trajectory generation based on the direct collocation method will be presented. Next, the flexibility and efficiency of the dynamic motion generation framework are demonstrated by our tools developed for generating the important variety of stable motions required by the competition. A smartphone application has been developed to allow the pilot to choose between different modes and to control the motion direction according to the real situation to reach a destination. The advanced mechatronic design and the active cooperation of the pilot with the device will also be highlighted. As a result, Atalante Evolution allowed the pilot to complete four out of six obstacles, without crutches. Our developments lead to stable dynamic movements of the exoskeleton, hands-free walking, more natural stand-up and turning moves, and consequently a better physical condition of the pilot after the race compared to the challengers. The versatility and good results of these developments give hope that exoskeletons will soon be able to evolve in challenging everyday-life environments, allowing patients to live a normal life in complete autonomy.},
  archive      = {J_FROBT},
  author       = {Huynh, Vaiyee and Burger, Guillaume and Dang, Quoc Viet and Pelgé, Raphaël and Boéris, Guilhem and Grizzle, Jessy W. and Ames, Aaron D. and Masselin, Matthieu},
  doi          = {10.3389/frobt.2021.723780},
  journal      = {Frontiers in Robotics and AI},
  month        = {9},
  pages        = {723780},
  shortjournal = {Front. Robot. AI},
  title        = {Versatile dynamic motion generation framework: Demonstration with a crutch-less exoskeleton on real-life obstacles at the cybathlon 2020 with a complete paraplegic person},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Using probabilistic movement primitives in analyzing human
motion differences under transcranial current stimulation.
<em>FROBT</em>, <em>8</em>, 721890. (<a
href="https://doi.org/10.3389/frobt.2021.721890">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In medical tasks such as human motion analysis, computer-aided auxiliary systems have become the preferred choice for human experts for their high efficiency. However, conventional approaches are typically based on user-defined features such as movement onset times, peak velocities, motion vectors, or frequency domain analyses. Such approaches entail careful data post-processing or specific domain knowledge to achieve a meaningful feature extraction. Besides, they are prone to noise and the manual-defined features could hardly be re-used for other analyses. In this paper, we proposed probabilistic movement primitives (ProMPs), a widely-used approach in robot skill learning, to model human motions. The benefit of ProMPs is that the features are directly learned from the data and ProMPs can capture important features describing the trajectory shape, which can easily be extended to other tasks. Distinct from previous research, where classification tasks are mostly investigated, we applied ProMPs together with a variant of Kullback-Leibler (KL) divergence to quantify the effect of different transcranial current stimulation methods on human motions. We presented an initial result with 10 participants. The results validate ProMPs as a robust and effective feature extractor for human motions.},
  archive      = {J_FROBT},
  author       = {Xue, Honghu and Herzog, Rebecca and Berger, Till M. and Bäumer, Tobias and Weissbach, Anne and Rueckert, Elmar},
  doi          = {10.3389/frobt.2021.721890},
  journal      = {Frontiers in Robotics and AI},
  month        = {9},
  pages        = {721890},
  shortjournal = {Front. Robot. AI},
  title        = {Using probabilistic movement primitives in analyzing human motion differences under transcranial current stimulation},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Formulating and deploying strength amplification controllers
for lower-body walking exoskeletons. <em>FROBT</em>, <em>8</em>, 720231.
(<a href="https://doi.org/10.3389/frobt.2021.720231">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Augmenting the physical strength of a human operator during unpredictable human-directed (volitional) movements is a relevant capability for several proposed exoskeleton applications, including mobility augmentation, manual material handling, and tool operation. Unlike controllers and augmentation systems designed for repetitive tasks (e.g., walking), we approach physical strength augmentation by a task-agnostic method of force amplification—using force/torque sensors at the human–machine interface to estimate the human task force, and then amplifying it with the exoskeleton. We deploy an amplification controller that is integrated into a complete whole-body control framework for controlling exoskeletons that includes human-led foot transitions, inequality constraints, and a computationally efficient prioritization. A powered lower-body exoskeleton is used to demonstrate behavior of the control framework in a lab environment. This exoskeleton can assist the operator in lifting an unknown backpack payload while remaining fully backdrivable.},
  archive      = {J_FROBT},
  author       = {Thomas, Gray C. and Campbell, Orion and Nichols, Nick and Brissonneau, Nicolas and He, Binghan and James, Joshua and Paine, Nicholas and Sentis, Luis},
  doi          = {10.3389/frobt.2021.720231},
  journal      = {Frontiers in Robotics and AI},
  month        = {9},
  pages        = {720231},
  shortjournal = {Front. Robot. AI},
  title        = {Formulating and deploying strength amplification controllers for lower-body walking exoskeletons},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Personal narratives in technology design: The value of
sharing older adults’ stories in the design of social robots.
<em>FROBT</em>, <em>8</em>, 716581. (<a
href="https://doi.org/10.3389/frobt.2021.716581">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The storytelling lens in human-computer interaction has primarily focused on personas, design fiction, and other stories crafted by designers, yet informal personal narratives from everyday people have not been considered meaningful data, such as storytelling from older adults. Storytelling may provide a clear path to conceptualize how technologies such as social robots can support the lives of older or disabled individuals. To explore this, we engaged 28 older adults in a year-long co-design process, examining informal stories told by older adults as a means of generating and expressing technology ideas and needs. This paper presents an analysis of participants’ stories around their prior experience with technology, stories shaped by social context, and speculative scenarios for the future of social robots. From this analysis, we present suggestions for social robot design, considerations of older adults’ values around technology design, and promotion of participant stories as sources for design knowledge and shifting perspectives of older adults and technology.},
  archive      = {J_FROBT},
  author       = {Ostrowski, Anastasia K. and Harrington, Christina N. and Breazeal, Cynthia and Park , Hae Won},
  doi          = {10.3389/frobt.2021.716581},
  journal      = {Frontiers in Robotics and AI},
  month        = {9},
  pages        = {716581},
  shortjournal = {Front. Robot. AI},
  title        = {Personal narratives in technology design: The value of sharing older adults’ stories in the design of social robots},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An adaptive mechatronic exoskeleton for force-controlled
finger rehabilitation. <em>FROBT</em>, <em>8</em>, 716451. (<a
href="https://doi.org/10.3389/frobt.2021.716451">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a novel mechatronic exoskeleton architecture for finger rehabilitation. The system consists of an underactuated kinematic structure that enables the exoskeleton to act as an adaptive finger stimulator. The exoskeleton has sensors for motion detection and control. The proposed architecture offers three main advantages. First, the exoskeleton enables accurate quantification of subject-specific finger dynamics. The configuration of the exoskeleton can be fully reconstructed using measurements from three angular position sensors placed on the kinematic structure. In addition, the actuation force acting on the exoskeleton is recorded. Thus, the range of motion (ROM) and the force and torque trajectories of each finger joint can be determined. Second, the adaptive kinematic structure allows the patient to perform various functional tasks. The force control of the exoskeleton acts like a safeguard and limits the maximum possible joint torques during finger movement. Last, the system is compact, lightweight and does not require extensive peripherals. Due to its safety features, it is easy to use in the home. Applicability was tested in three healthy subjects.},
  archive      = {J_FROBT},
  author       = {Dickmann , Thomas and Wilhelm, Nikolas J. and Glowalla , Claudio and Haddadin , Sami and van der Smagt , Patrick and Burgkart , Rainer},
  doi          = {10.3389/frobt.2021.716451},
  journal      = {Frontiers in Robotics and AI},
  month        = {9},
  pages        = {716451},
  shortjournal = {Front. Robot. AI},
  title        = {An adaptive mechatronic exoskeleton for force-controlled finger rehabilitation},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The virtuous servant owner—a paradigm whose time has come
(again). <em>FROBT</em>, <em>8</em>, 715849. (<a
href="https://doi.org/10.3389/frobt.2021.715849">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Social Robots are coming. They are being designed to enter our lives and help in everything from childrearing to elderly care, from household chores to personal therapy, and the list goes on. There is great promise that these machines will further the progress that their predecessors achieved, enhancing our lives and alleviating us of the many tasks with which we would rather not be occupied. But there is a dilemma. On the one hand, these machines are just that, machines. Accordingly, some thinkers propose that we maintain this perspective and relate to Social Robots as “tools”. Yet, in treating them as such, it is argued, we deny our own natural empathy, ultimately inculcating vicious as opposed to virtuous dispositions. Many thinkers thus apply Kant’s approach to animals—“he who is cruel to animals becomes hard also in his dealings with men”—contending that we must not maltreat robots lest we maltreat humans. On the other hand, because we innately anthropomorphize entities that behave with autonomy and mobility (let alone entities that exhibit beliefs, desires and intentions), we become emotionally entangled with them. Some thinkers actually encourage such relationships. But there are problems here also. For starters, many maintain that it is imprudent to have “empty,” unidirectional relationships for we will then fail to appreciate authentic reciprocal relationships. Furthermore, such relationships can lead to our being manipulated, to our shunning of real human interactions as “messy,” to our incorrectly allocating resources away from humans, and more. In this article, I review the various positions on this issue and propose an approach that I believe sits in the middle ground between the one extreme of treating Social Robots as mere machines versus the other extreme of accepting Social Robots as having human-like status. I call the approach “The Virtuous Servant Owner” and base it on the virtue ethics of the medieval Jewish philosopher Maimonides.},
  archive      = {J_FROBT},
  author       = {Navon, Mois},
  doi          = {10.3389/frobt.2021.715849},
  journal      = {Frontiers in Robotics and AI},
  month        = {9},
  pages        = {715849},
  shortjournal = {Front. Robot. AI},
  title        = {The virtuous servant Owner—A paradigm whose time has come (Again)},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Practical design considerations for performance and
robustness in the face of uncertain flexible dynamics in space
manipulators. <em>FROBT</em>, <em>8</em>, 708388. (<a
href="https://doi.org/10.3389/frobt.2021.708388">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Low frequency dynamics introduced by structural flexibility can result in considerable performance degradation and even instability in on-orbit, robotic manipulators. Although there is a wealth of literature that addresses this problem, the author has found that many advanced solutions are often precluded by practical considerations. On the other hand, classical, robust control methods are tractable for these systems if the design problem is properly constrained. This paper investigates a pragmatic engineering approach that evaluates the system’s stability margins in the face of uncertain, flexible perturbation dynamics with frequencies that lie close to or within the bandwidth of the nominal closed-loop system. The robustness of classical control strategies is studied in the context of both collocated (joint rate) and non-collocated (force/torque and vision-based) feedback. It is shown that robust stability and performance depend on the open-loop control bandwidth of the nominal control law (as designed for a simplified, rigid plant). Namely, the designed bandwidth must be constrained to be lower than the minimum flexible mode frequency of the unmodeled dynamics by a given factor. This strategy gives credence to popular heuristic methods commonly used to reduce the effect of unmodeled dynamics in complex manipulator systems.},
  archive      = {J_FROBT},
  author       = {Holmes, Connor},
  doi          = {10.3389/frobt.2021.708388},
  journal      = {Frontiers in Robotics and AI},
  month        = {9},
  pages        = {708388},
  shortjournal = {Front. Robot. AI},
  title        = {Practical design considerations for performance and robustness in the face of uncertain flexible dynamics in space manipulators},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Task-level authoring for remote robot teleoperation.
<em>FROBT</em>, <em>8</em>, 707149. (<a
href="https://doi.org/10.3389/frobt.2021.707149">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Remote teleoperation of robots can broaden the reach of domain specialists across a wide range of industries such as home maintenance, health care, light manufacturing, and construction. However, current direct control methods are impractical, and existing tools for programming robot remotely have focused on users with significant robotic experience. Extending robot remote programming to end users, i.e., users who are experts in a domain but novices in robotics, requires tools that balance the rich features necessary for complex teleoperation tasks with ease of use. The primary challenge to usability is that novice users are unable to specify complete and robust task plans to allow a robot to perform duties autonomously, particularly in highly variable environments. Our solution is to allow operators to specify shorter sequences of high-level commands, which we call task-level authoring, to create periods of variable robot autonomy. This approach allows inexperienced users to create robot behaviors in uncertain environments by interleaving exploration, specification of behaviors, and execution as separate steps. End users are able to break down the specification of tasks and adapt to the current needs of the interaction and environments, combining the reactivity of direct control to asynchronous operation. In this paper, we describe a prototype system contextualized in light manufacturing and its empirical validation in a user study where 18 participants with some programming experience were able to perform a variety of complex telemanipulation tasks with little training. Our results show that our approach allowed users to create flexible periods of autonomy and solve rich manipulation tasks. Furthermore, participants significantly preferred our system over comparative more direct interfaces, demonstrating the potential of our approach for enabling end users to effectively perform remote robot programming.},
  archive      = {J_FROBT},
  author       = {Senft, Emmanuel and Hagenow, Michael and Welsh, Kevin and Radwin, Robert and Zinn, Michael and Gleicher, Michael and Mutlu, Bilge},
  doi          = {10.3389/frobt.2021.707149},
  journal      = {Frontiers in Robotics and AI},
  month        = {9},
  pages        = {707149},
  shortjournal = {Front. Robot. AI},
  title        = {Task-level authoring for remote robot teleoperation},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Physics-based modelling and simulation of multibeam
echosounder perception for autonomous underwater manipulation.
<em>FROBT</em>, <em>8</em>, 706646. (<a
href="https://doi.org/10.3389/frobt.2021.706646">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the key distinguishing aspects of underwater manipulation tasks is the perception challenges of the ocean environment, including turbidity, backscatter, and lighting effects. Consequently, underwater perception often relies on sonar-based measurements to estimate the vehicle’s state and surroundings, either standalone or in concert with other sensing modalities, to support the perception necessary to plan and control manipulation tasks. Simulation of the multibeam echosounder, while not a substitute for in-water testing, is a critical capability for developing manipulation strategies in the complex and variable ocean environment. Although several approaches exist in the literature to simulate synthetic sonar images, the methods in the robotics community typically use image processing and video rendering software to comply with real-time execution requirements. In addition to a lack of physics-based interaction model between sound and the scene of interest, several basic properties are absent in these rendered sonar images–notably the coherent imaging system and coherent speckle that cause distortion of the object geometry in the sonar image. To address this deficiency, we present a physics-based multibeam echosounder simulation method to capture these fundamental aspects of sonar perception. A point-based scattering model is implemented to calculate the acoustic interaction between the target and the environment. This is a simplified representation of target scattering but can produce realistic coherent image speckle and the correct point spread function. The results demonstrate that this multibeam echosounder simulator generates qualitatively realistic images with high efficiency to provide the sonar image and the physical time series signal data. This synthetic sonar data is a key enabler for developing, testing, and evaluating autonomous underwater manipulation strategies that use sonar as a component of perception.},
  archive      = {J_FROBT},
  author       = {Choi, Woen-Sug and Olson, Derek R. and Davis, Duane and Zhang, Mabel and Racson, Andy and Bingham, Brian and McCarrin, Michael and Vogt, Carson and Herman, Jessica},
  doi          = {10.3389/frobt.2021.706646},
  journal      = {Frontiers in Robotics and AI},
  month        = {9},
  pages        = {706646},
  shortjournal = {Front. Robot. AI},
  title        = {Physics-based modelling and simulation of multibeam echosounder perception for autonomous underwater manipulation},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Design of a wearable haptic device for hand palm cutaneous
feedback. <em>FROBT</em>, <em>8</em>, 706627. (<a
href="https://doi.org/10.3389/frobt.2021.706627">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study describes the main design and prototyping steps of a novel haptic device for cutaneous stimulus of a hand palm. This part of the hand is fundamental in several grasping and manipulation tasks, but is still less exploited in haptics applications than other parts of the hand, as for instance the fingertips. The proposed device has a parallel tendon-based mechanical structure and is actuated by three motors positioned on the hand’s back. The device is able to apply both normal and tangential forces and to render the contact with surfaces with different slopes. The end-effector can be easily changed to simulate the contact with different surface curvatures. The design is inspired by a smaller device previously developed for the fingertips; however, in the device presented in this study, there are significant differences due to the wider size, the different form-factor, and the structure of hand palm. The hand palm represents the support for the fingers and is connected to the arm through the wrist. The device has to be developed taking into account fingers’ and wrist’s motions, and this requirement constrains the number of actuators and the features of the transmission system. The larger size of the palm and the higher forces challenge the device from a structural point of view. Since tendons can apply only tensile forces, a spring-based support has been developed to keep the end-effector separated from the palm when the device is not actuated or when the force to be rendered is null. The study presents the main design guidelines and the main features of the proposed device. A prototype has been realized for the preliminary tests, and an application scenario with a VR environment is introduced.},
  archive      = {J_FROBT},
  author       = {Dragusanu, Mihai and Villani, Alberto and Prattichizzo, Domenico and Malvezzi, Monica},
  doi          = {10.3389/frobt.2021.706627},
  journal      = {Frontiers in Robotics and AI},
  month        = {9},
  pages        = {706627},
  shortjournal = {Front. Robot. AI},
  title        = {Design of a wearable haptic device for hand palm cutaneous feedback},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Bootstrapping virtual bipedal walkers with robotics
scaffolded learning. <em>FROBT</em>, <em>8</em>, 702599. (<a
href="https://doi.org/10.3389/frobt.2021.702599">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We reach walking optimality from a very early age by using natural supports, which can be the hands of our parents, chairs, and training wheels, and bootstrap a new knowledge from the recently acquired one. The idea behind bootstrapping is to use the previously acquired knowledge from simpler tasks to accelerate the learning of more complicated ones. In this paper, we propose a scaffolded learning method from an evolutionary perspective, where a biped creature achieves stable and independent bipedal walking while exploiting the natural scaffold of its changing morphology to create a third limb. The novelty of this work is speeding up the learning process with an artificially recreated scaffolded learning. We compare three conditions of scaffolded learning (free, time-constrained, and performance-based scaffolded learning) to reach bipedalism, and we prove that a performance-based scaffold, which is designed by the walking velocity obtained, is the most conducive to bootstrap the learning of bipedal walking. The scope of this work is not to study bipedal locomotion but to investigate the contribution from scaffolded learning to a faster learning process. Beyond a pedagogical experiment, this work presents a powerful tool to accelerate the learning of complex tasks in the Robotics field.},
  archive      = {J_FROBT},
  author       = {Zhu, Jiahui and Rong, Chunyan and Iida, Fumiya and Rosendo, Andre},
  doi          = {10.3389/frobt.2021.702599},
  journal      = {Frontiers in Robotics and AI},
  month        = {9},
  pages        = {702599},
  shortjournal = {Front. Robot. AI},
  title        = {Bootstrapping virtual bipedal walkers with robotics scaffolded learning},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). PAL: A framework for physically assisted learning through
design and exploration with a haptic robot buddy. <em>FROBT</em>,
<em>8</em>, 700465. (<a
href="https://doi.org/10.3389/frobt.2021.700465">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robots are an opportunity for interactive and engaging learning activities. In this paper we consider the premise that haptic force feedback delivered through a held robot can enrich learning of science-related concepts by building physical intuition as learners design experiments and physically explore them to solve problems they have posed. Further, we conjecture that combining this rich feedback with pen-and-paper interactions, e.g., to sketch experiments they want to try, could lead to fluid interactions and benefit focus. However, a number of technical barriers interfere with testing this approach, and making it accessible to learners and their teachers. In this paper, we propose a framework for Physically Assisted Learning based on stages of experiential learning which can guide designers in developing and evaluating effective technology, and which directs focus on how haptic feedback could assist with design and explore learning stages. To this end, we demonstrated a possible technical pathway to support the full experience of designing an experiment by drawing a physical system on paper, then interacting with it physically after the system recognizes the sketch, interprets as a model and renders it haptically. Our proposed framework is rooted in theoretical needs and current advances for experiential learning, pen-paper interaction and haptic technology. We further explain how to instantiate the PAL framework using available technologies and discuss a path forward to a larger vision of physically assisted learning.},
  archive      = {J_FROBT},
  author       = {Kianzad , Soheil and Chen , Guanxiong and MacLean , Karon E.},
  doi          = {10.3389/frobt.2021.700465},
  journal      = {Frontiers in Robotics and AI},
  month        = {9},
  pages        = {700465},
  shortjournal = {Front. Robot. AI},
  title        = {PAL: A framework for physically assisted learning through design and exploration with a haptic robot buddy},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Which one? Choosing favorite robot after different styles of
storytelling and robots’ conversation. <em>FROBT</em>, <em>8</em>,
700005. (<a href="https://doi.org/10.3389/frobt.2021.700005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The influence of human-care service robots in human–robot interaction is becoming of great importance, because of the roles that the robots are taking in today’s and future society. Thus, we need to identify how humans can interact, collaborate, and learn from social robots more efficiently. Additionally, it is important to determine the robots’ modalities that can increase the humans’ perceived likeness and knowledge acquisition and enhance human–robot collaboration. The present study aims to identify the optimal social service robots’ modalities that enhance the human learning process and level of enjoyment from the interaction and even attract the humans’ attention to choosing a robot to collaborate with it. Our target group was college students, pre-service teachers. For this purpose, we designed two experiments, each one split in two parts. Both the experiments were between groups, and human participants had the chance to watch the Nao robot performing a storytelling exercise about the history of robots in a museum-educational activity via video annotations. The robot’s modalities were manipulated on its body movements (expressive arm and head gestures) while performing the storytelling, friendly attitude expressions and storytelling, and personality traits. After the robot’s storytelling, participants filled out a knowledge acquisition questionnaire and a self-reported enjoyment level questionnaire. In the second part, we introduce the idea of participants witnessing a conversation between the robots with the different modalities, and they were asked to choose the robot with which they want to collaborate in a similar activity. Results indicated that participants prefer to collaborate with robots with a cheerful personality and expressive body movements. Especially when they were asked to choose between two robots that were cheerful and had expressive body movements, they preferred the one which originally told them the story. Moreover, participants did not prefer to collaborate with a robot with an extremely friendly attitude and storytelling style.},
  archive      = {J_FROBT},
  author       = {Velentza, Anna-Maria and Fachantidis, Nikolaos and Pliasa, Sofia},
  doi          = {10.3389/frobt.2021.700005},
  journal      = {Frontiers in Robotics and AI},
  month        = {9},
  pages        = {700005},
  shortjournal = {Front. Robot. AI},
  title        = {Which one? choosing favorite robot after different styles of storytelling and robots’ conversation},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Simulation evaluation for methods used to determine muscular
internal force based on joint stiffness using muscular internal force
feedforward controller for musculoskeletal system. <em>FROBT</em>,
<em>8</em>, 699792. (<a
href="https://doi.org/10.3389/frobt.2021.699792">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study proposes two novel methods for determining the muscular internal force (MIF) based on joint stiffness, using an MIF feedforward controller for the musculoskeletal system. The controller was developed in a previous study, where we found that it could be applied to achieve any desired end-point position without the use of sensors, by providing the MIF as a feedforward input to individual muscles. However, achieving motion with good response and low stiffness using the system, posed a challenge. Furthermore, the controller was subject to an ill-posed problem, where the input could not be uniquely determined. We propose two methods to improve the control performance of this controller. The first method involves determining a MIF that can independently control the response and stiffness at a desired position, and the second method involves the definition of an arbitrary vector that describes the stiffnesses at the initial and desired positions to uniquely determine the MIF balance at each position. The numerical simulation results reported in this study demonstrate the effectiveness of both proposed methods.},
  archive      = {J_FROBT},
  author       = {Matsutani, Yuki and Tahara, Kenji and Kino, Hitoshi},
  doi          = {10.3389/frobt.2021.699792},
  journal      = {Frontiers in Robotics and AI},
  month        = {9},
  pages        = {699792},
  shortjournal = {Front. Robot. AI},
  title        = {Simulation evaluation for methods used to determine muscular internal force based on joint stiffness using muscular internal force feedforward controller for musculoskeletal system},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Exploring effects of information filtering with a VR
interface for multi-robot supervision. <em>FROBT</em>, <em>8</em>,
692180. (<a href="https://doi.org/10.3389/frobt.2021.692180">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Supervising and controlling remote robot systems currently requires many specialised operators to have knowledge of the internal state of the system in addition to the environment. For applications such as remote maintenance of future nuclear fusion reactors, the number of robots (and hence supervisors) required to maintain or decommission a facility is too large to be financially feasible. To address this issue, this work explores the idea of intelligently filtering information so that a single user can supervise multiple robots safely. We gathered feedback from participants using five methods for teleoperating a semi-autonomous multi-robot system via Virtual Reality (VR). We present a novel 3D interaction method to filter the displayed information to allow the user to read information from the environment without being overwhelmed. The novelty of the interface design is the link between Semantic and Spatial filtering and the hierarchical information contained within the multi robot system. We conducted a user study including a cohort of expert robot teleoperators comparing these methods; highlighting the significant effects of 3D interface design on the performance and perceived workload of a user teleoperating many robot agents in complex environments. The results from this experiment and subjective user feedback will inform future investigations that build upon this initial work.},
  archive      = {J_FROBT},
  author       = {Butters, Daniel and Jonasson, Emil T. and Pawar, Vijay M.},
  doi          = {10.3389/frobt.2021.692180},
  journal      = {Frontiers in Robotics and AI},
  month        = {9},
  pages        = {692180},
  shortjournal = {Front. Robot. AI},
  title        = {Exploring effects of information filtering with a VR interface for multi-robot supervision},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Robots for foreign language learning: Speaking style
influences student performance. <em>FROBT</em>, <em>8</em>, 680509. (<a
href="https://doi.org/10.3389/frobt.2021.680509">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Much previous research suggests that teachers’ individual characteristics may affect students’ performance; however, which factors are particularly helpful is as yet unclear and methodologically very difficult to assess. In this paper, we study the effects of robots’ speaking styles when instructing students on a task. 40 participants saw a brief video in which a robot presented its instructions either in a charismatic or a not so charismatic speaking style. Participants’ task was then to produce foreign language sentences on the basis of visualizations of the prosodic properties of these sentences. A subsequent analysis of participants’ productions shows that language learners’ performance was significantly better when the robot had delivered its instructions in a charismatic voice. The results suggest not only that a charismatic speaking style may be crucial for teachers in general and hence one of the factors causing the interpersonal variation between teachers, but also that students can benefit from instructions by robots delivered in a charismatic speaking style.},
  archive      = {J_FROBT},
  author       = {Fischer, Kerstin and Niebuhr, Oliver and Alm, Maria},
  doi          = {10.3389/frobt.2021.680509},
  journal      = {Frontiers in Robotics and AI},
  month        = {9},
  pages        = {680509},
  shortjournal = {Front. Robot. AI},
  title        = {Robots for foreign language learning: Speaking style influences student performance},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The i-walk lightweight assistive rollator: First evaluation
study. <em>FROBT</em>, <em>8</em>, 677542. (<a
href="https://doi.org/10.3389/frobt.2021.677542">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robots can play a significant role as assistive devices for people with movement impairment and mild cognitive deficit. In this paper we present an overview of the lightweight i-Walk intelligent robotic rollator, which offers cognitive and mobility assistance to the elderly and to people with light to moderate mobility impairment. The utility, usability, safety and technical performance of the device is investigated through a clinical study, which took place at a rehabilitation center in Greece involving real patients with mild to moderate cognitive and mobility impairment. This first evaluation study comprised a set of scenarios in a number of pre-defined use cases, including physical rehabilitation exercises, as well as mobility and ambulation involved in typical daily living activities of the patients. The design and implementation of this study is discussed in detail, along with the obtained results, which include both an objective and a subjective evaluation of the system operation, based on a set of technical performance measures and a validated questionnaire for the analysis of qualitative data, respectively. The study shows that the technical modules performed satisfactory under real conditions, and that the users generally hold very positive views of the platform, considering it safe and reliable.},
  archive      = {J_FROBT},
  author       = {Moustris, George and Kardaris, Nikolaos and Tsiami, Antigoni and Chalvatzaki, Georgia and Koutras, Petros and Dometios, Athanasios and Oikonomou, Paris and Tzafestas, Costas and Maragos, Petros and Efthimiou, Eleni and Papageorgiou, Xanthi and Fotinea, Stavroula-Evita and Koumpouros, Yiannis and Vacalopoulou, Anna and Papageorgiou, Effie and Karavasili, Alexandra and Koureta, Foteini and Dimou, Dimitris and Nikolakakis, Alexandros and Karaiskos, Konstantinos and Mavridis, Panagiotis},
  doi          = {10.3389/frobt.2021.677542},
  journal      = {Frontiers in Robotics and AI},
  month        = {9},
  pages        = {677542},
  shortjournal = {Front. Robot. AI},
  title        = {The i-walk lightweight assistive rollator: First evaluation study},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Coffee with a hint of data: Towards using data-driven
approaches in personalised long-term interactions. <em>FROBT</em>,
<em>8</em>, 676814. (<a
href="https://doi.org/10.3389/frobt.2021.676814">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While earlier research in human-robot interaction pre-dominantly uses rule-based architectures for natural language interaction, these approaches are not flexible enough for long-term interactions in the real world due to the large variation in user utterances. In contrast, data-driven approaches map the user input to the agent output directly, hence, provide more flexibility with these variations without requiring any set of rules. However, data-driven approaches are generally applied to single dialogue exchanges with a user and do not build up a memory over long-term conversation with different users, whereas long-term interactions require remembering users and their preferences incrementally and continuously and recalling previous interactions with users to adapt and personalise the interactions, known as the lifelong learning problem. In addition, it is desirable to learn user preferences from a few samples of interactions (i.e., few-shot learning). These are known to be challenging problems in machine learning, while they are trivial for rule-based approaches, creating a trade-off between flexibility and robustness. Correspondingly, in this work, we present the text-based Barista Datasets generated to evaluate the potential of data-driven approaches in generic and personalised long-term human-robot interactions with simulated real-world problems, such as recognition errors, incorrect recalls and changes to the user preferences. Based on these datasets, we explore the performance and the underlying inaccuracies of the state-of-the-art data-driven dialogue models that are strong baselines in other domains of personalisation in single interactions, namely Supervised Embeddings, Sequence-to-Sequence, End-to-End Memory Network, Key-Value Memory Network, and Generative Profile Memory Network. The experiments show that while data-driven approaches are suitable for generic task-oriented dialogue and real-time interactions, no model performs sufficiently well to be deployed in personalised long-term interactions in the real world, because of their inability to learn and use new identities, and their poor performance in recalling user-related data.},
  archive      = {J_FROBT},
  author       = {Irfan, Bahar and Hellou , Mehdi and Belpaeme, Tony},
  doi          = {10.3389/frobt.2021.676814},
  journal      = {Frontiers in Robotics and AI},
  month        = {9},
  pages        = {676814},
  shortjournal = {Front. Robot. AI},
  title        = {Coffee with a hint of data: Towards using data-driven approaches in personalised long-term interactions},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Social robots as creativity eliciting agents.
<em>FROBT</em>, <em>8</em>, 673730. (<a
href="https://doi.org/10.3389/frobt.2021.673730">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Can robots help children be more creative? In this work, we posit social robots as creativity support tools for children in collaborative interactions. Children learn creative expressions and behaviors through social interactions with others during playful and collaborative tasks, and socially emulate their peers’ and teachers’ creativity. Social robots have a unique ability to engage in social and emotional interactions with children that can be leveraged to foster creative expression. We focus on two types of social interactions: creativity demonstration, where the robot exhibits creative behaviors, and creativity scaffolding, where the robot poses challenges, suggests ideas, provides positive reinforcement, and asks questions to scaffold children’s creativity. We situate our research in three playful and collaborative tasks - the Droodle Creativity game (that affords verbal creativity), the MagicDraw game (that affords figural creativity), and the WeDo construction task (that affords constructional creativity), that children play with Jibo, a social robot. To evaluate the efficacy of the robot’s social behaviors in enhancing creative behavior and expression in children, we ran three randomized controlled trials with 169 children in the 5–10 yr old age group. In the first two tasks, the robot exhibited creativity demonstration behaviors. We found that children who interacted with the robot exhibiting high verbal creativity in the Droodle game and high figural creativity in the MagicDraw game also exhibited significantly higher creativity than a control group of participants who interacted with a robot that did not express creativity (p &amp;lt; 0.05*). In the WeDo construction task, children who interacted with the robot that expressed creative scaffolding behaviors (asking reflective questions, generating ideas and challenges, and providing positive reinforcement) demonstrated higher creativity than participants in the control group by expressing a greater number of ideas, more original ideas, and more varied use of available materials (p &amp;lt; 0.05*). We found that both creativity demonstration and creativity scaffolding can be leveraged as social mechanisms for eliciting creativity in children using a social robot. From our findings, we suggest design guidelines for pedagogical tools and social agent interactions to better support children’s creativity.},
  archive      = {J_FROBT},
  author       = {Ali, Safinah and Devasia, Nisha and Park, Hae Won and Breazeal, Cynthia},
  doi          = {10.3389/frobt.2021.673730},
  journal      = {Frontiers in Robotics and AI},
  month        = {9},
  pages        = {673730},
  shortjournal = {Front. Robot. AI},
  title        = {Social robots as creativity eliciting agents},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). μRALP and beyond: Micro-technologies and systems for
robot-assisted endoscopic laser microsurgery. <em>FROBT</em>,
<em>8</em>, 664655. (<a
href="https://doi.org/10.3389/frobt.2021.664655">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Laser microsurgery is the current gold standard surgical technique for the treatment of selected diseases in delicate organs such as the larynx. However, the operations require large surgical expertise and dexterity, and face significant limitations imposed by available technology, such as the requirement for direct line of sight to the surgical field, restricted access, and direct manual control of the surgical instruments. To change this status quo, the European project μRALP pioneered research towards a complete redesign of current laser microsurgery systems, focusing on the development of robotic micro-technologies to enable endoscopic operations. This has fostered awareness and interest in this field, which presents a unique set of needs, requirements and constraints, leading to research and technological developments beyond μRALP and its research consortium. This paper reviews the achievements and key contributions of such research, providing an overview of the current state of the art in robot-assisted endoscopic laser microsurgery. The primary target application considered is phonomicrosurgery, which is a representative use case involving highly challenging microsurgical techniques for the treatment of glottic diseases. The paper starts by presenting the motivations and rationale for endoscopic laser microsurgery, which leads to the introduction of robotics as an enabling technology for improved surgical field accessibility, visualization and management. Then, research goals, achievements, and current state of different technologies that can build-up to an effective robotic system for endoscopic laser microsurgery are presented. This includes research in micro-robotic laser steering, flexible robotic endoscopes, augmented imaging, assistive surgeon-robot interfaces, and cognitive surgical systems. Innovations in each of these areas are shown to provide sizable progress towards more precise, safer and higher quality endoscopic laser microsurgeries. Yet, major impact is really expected from the full integration of such individual contributions into a complete clinical surgical robotic system, as illustrated in the end of this paper with a description of preliminary cadaver trials conducted with the integrated μRALP system. Overall, the contribution of this paper lays in outlining the current state of the art and open challenges in the area of robot-assisted endoscopic laser microsurgery, which has important clinical applications even beyond laryngology.},
  archive      = {J_FROBT},
  author       = {Mattos, Leonardo S. and Acemoglu, Alperen and Geraldes, André and Laborai, Andrea and Schoob, Andreas and Tamadazte, Brahim and Davies, Brian and Wacogne, Bruno and Pieralli, Christian and Barbalata, Corina and Caldwell, Darwin G. and Kundrat, Dennis and Pardo, Diego and Grant, Edward and Mora, Francesco and Barresi, Giacinto and Peretti, Giorgio and Ortiz, Jesùs and Rabenorosoa, Kanty and Tavernier, Laurent and Pazart, Lionel and Fichera, Loris and Guastini, Luca and Kahrs, Lüder A. and Rakotondrabe, Micky and Andreff, Nicolas and Deshpande, Nikhil and Gaiffe, Olivier and Renevier, Rupert and Moccia, Sara and Lescano, Sergio and Ortmaier, Tobias and Penza, Veronica},
  doi          = {10.3389/frobt.2021.664655},
  journal      = {Frontiers in Robotics and AI},
  month        = {9},
  pages        = {664655},
  shortjournal = {Front. Robot. AI},
  title        = {μRALP and beyond: Micro-technologies and systems for robot-assisted endoscopic laser microsurgery},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A robust observation, planning, and control pipeline for
autonomous rendezvous with tumbling targets. <em>FROBT</em>, <em>8</em>,
641338. (<a href="https://doi.org/10.3389/frobt.2021.641338">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accumulating space debris edges the space domain ever closer to cascading Kessler syndrome, a chain reaction of debris generation that could dramatically inhibit the practical use of space. Meanwhile, a growing number of retired satellites, particularly in higher orbits like geostationary orbit, remain nearly functional except for minor but critical malfunctions or fuel depletion. Servicing these ailing satellites and cleaning up “high-value” space debris remains a formidable challenge, but active interception of these targets with autonomous repair and deorbit spacecraft is inching closer toward reality as shown through a variety of rendezvous demonstration missions. However, some practical challenges are still unsolved and undemonstrated. Devoid of station-keeping ability, space debris and fuel-depleted satellites often enter uncontrolled tumbles on-orbit. In order to perform on-orbit servicing or active debris removal, docking spacecraft (the “Chaser”) must account for the tumbling motion of these targets (the “Target”), which is oftentimes not known a priori. Accounting for the tumbling dynamics of the Target, the Chaser spacecraft must have an algorithmic approach to identifying the state of the Target’s tumble, then use this information to produce useful motion planning and control. Furthermore, careful consideration of the inherent uncertainty of any maneuvers must be accounted for in order to provide guarantees on system performance. This study proposes the complete pipeline of rendezvous with such a Target, starting from a standoff estimation point to a mating point fixed in the rotating Target’s body frame. A novel visual estimation algorithm is applied using a 3D time-of-flight camera to perform remote standoff estimation of the Target’s rotational state and its principal axes of rotation. A novel motion planning algorithm is employed, making use of offline simulation of potential Target tumble types to produce a look-up table that is parsed on-orbit using the estimation data. This nonlinear programming-based algorithm accounts for known Target geometry and important practical constraints such as field of view requirements, producing a motion plan in the Target’s rotating body frame. Meanwhile, an uncertainty characterization method is demonstrated which propagates uncertainty in the Target’s tumble uncertainty to provide disturbance bounds on the motion plan’s reference trajectory in the inertial frame. Finally, this uncertainty bound is provided to a robust tube model predictive controller, which provides tube-based robustness guarantees on the system’s ability to follow the reference trajectory translationally. The combination and interfaces of these methods are shown, and some of the practical implications of their use on a planned demonstration on NASA’s Astrobee free-flyer are additionally discussed. Simulation results of each of the components individually and in a complete case study example of the full pipeline are presented as the study prepares to move toward demonstration on the International Space Station.},
  archive      = {J_FROBT},
  author       = {Albee, Keenan and Oestreich, Charles and Specht, Caroline and Terán Espinoza, Antonio and Todd, Jessica and Hokaj, Ian and Lampariello, Roberto and Linares, Richard},
  doi          = {10.3389/frobt.2021.641338},
  journal      = {Frontiers in Robotics and AI},
  month        = {9},
  pages        = {641338},
  shortjournal = {Front. Robot. AI},
  title        = {A robust observation, planning, and control pipeline for autonomous rendezvous with tumbling targets},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Bio-inspired knee joint: Trends in the hardware systems
development. <em>FROBT</em>, <em>8</em>, 613574. (<a
href="https://doi.org/10.3389/frobt.2021.613574">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The knee joint is a complex structure that plays a significant role in the human lower limb for locomotion activities in daily living. However, we are still not quite there yet where we can replicate the functions of the knee bones and the attached ligaments to a significant degree of success. This paper presents the current trend in the development of knee joints based on bio-inspiration concepts and modern bio-inspired knee joints in the research field of prostheses, power-assist suits and mobile robots. The paper also reviews the existing literature to describe major turning points during the development of hardware and control systems associated with bio-inspired knee joints. The anatomy and biomechanics of the knee joint are initially presented. Then the latest bio-inspired knee joints developed within the last 10 years are briefly reviewed based on bone structure, muscle and ligament structure and control strategies. A leg exoskeleton is then introduced for enhancing the functionality of the human lower limb that lacks muscle power. The design consideration, novelty of the design and the working principle of the proposed knee joint are summarized. Furthermore, the simulation results and experimental results are also presented and analyzed. Finally, the paper concludes with design difficulties, design considerations and future directions on bio-inspired knee joint design. The aim of this paper is to be a starting point for researchers keen on understanding the developments throughout the years in the field of bio-inspired knee joints.},
  archive      = {J_FROBT},
  author       = {Etoundi, Appolinaire C. and Semasinghe, Chathura L. and Agrawal, Subham and Dobner, Alexander and Jafari, Aghil},
  doi          = {10.3389/frobt.2021.613574},
  journal      = {Frontiers in Robotics and AI},
  month        = {9},
  pages        = {613574},
  shortjournal = {Front. Robot. AI},
  title        = {Bio-inspired knee joint: Trends in the hardware systems development},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Editorial: Robotics in extreme environments. <em>FROBT</em>,
<em>8</em>, 744092. (<a
href="https://doi.org/10.3389/frobt.2021.744092">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Takahashi, Chie and Giuliani, Manuel and Lennox, Barry and Hamel, William R. and Stolkin, Rustam and Semini, Claudio},
  doi          = {10.3389/frobt.2021.744092},
  journal      = {Frontiers in Robotics and AI},
  month        = {8},
  pages        = {744092},
  shortjournal = {Front. Robot. AI},
  title        = {Editorial: Robotics in extreme environments},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Yoshimura-origami based earthworm-like robot with
3-dimensional locomotion capability. <em>FROBT</em>, <em>8</em>, 738214.
(<a href="https://doi.org/10.3389/frobt.2021.738214">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Earthworm-like robots have received great attention due to their prominent locomotion abilities in various environments. In this research, by exploiting the extraordinary three-dimensional (3D) deformability of the Yoshimura-origami structure, the state of the art of earthworm-like robots is significantly advanced by enhancing the locomotion capability from 2D to 3D. Specifically, by introducing into the virtual creases, kinematics of the non-rigid-foldable Yoshimura-ori structure is systematically analyzed. In addition to exhibiting large axial deformation, the Yoshimura-ori structure could also bend toward different directions, which, therefore, significantly expands the reachable workspace and makes it possible for the robot to perform turning and rising motions. Based on prototypes made of PETE film, mechanical properties of the Yoshimura-ori structure are also evaluated experimentally, which provides useful guidelines for robot design. With the Yoshimura-ori structure as the skeleton of the robot, a hybrid actuation mechanism consisting of SMA springs, pneumatic balloons, and electromagnets is then proposed and embedded into the robot: the SMA springs are used to bend the origami segments for turning and rising motion, the pneumatic balloons are employed for extending and contracting the origami segments, and the electromagnets serve as anchoring devices. Learning from the earthworm’s locomotion mechanism--retrograde peristalsis wave, locomotion gaits are designed for controlling the robot. Experimental tests indicate that the robot could achieve effective rectilinear, turning, and rising locomotion, thus demonstrating the unique 3D locomotion capability.},
  archive      = {J_FROBT},
  author       = {Zhang, Qiwei and Fang, Hongbin and Xu, Jian},
  doi          = {10.3389/frobt.2021.738214},
  journal      = {Frontiers in Robotics and AI},
  month        = {8},
  pages        = {738214},
  shortjournal = {Front. Robot. AI},
  title        = {Yoshimura-origami based earthworm-like robot with 3-dimensional locomotion capability},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Hardware methods for onboard control of fluidically actuated
soft robots. <em>FROBT</em>, <em>8</em>, 720702. (<a
href="https://doi.org/10.3389/frobt.2021.720702">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Soft robots provide significant advantages over their rigid counterparts. These compliant, dexterous devices can navigate delicate environments with ease without damage to themselves or their surroundings. With many degrees of freedom, a single soft robotic actuator can achieve configurations that would be very challenging to obtain when using a rigid linkage. Because of these qualities, soft robots are well suited for human interaction. While there are many types of soft robot actuation, the most common type is fluidic actuation, where a pressurized fluid is used to inflate the device, causing bending or some other deformation. This affords advantages with regards to size, ease of manufacturing, and power delivery, but can pose issues when it comes to controlling the robot. Any device capable of complex tasks such as navigation requires multiple actuators working together. Traditionally, these have each required their own mechanism outside of the robot to control the pressure within. Beyond the limitations on autonomy that such a benchtop controller induces, the tether of tubing connecting the robot to its controller can increase stiffness, reduce reaction speed, and hinder miniaturization. Recently, a variety of techniques have been used to integrate control hardware into soft fluidic robots. These methods are varied and draw from disciplines including microfluidics, digital logic, and material science. In this review paper, we discuss the state of the art of onboard control hardware for soft fluidic robots with an emphasis on novel valve designs, including an overview of the prevailing techniques, how they differ, and how they compare to each other. We also define metrics to guide our comparison and discussion. Since the uses for soft robots can be so varied, the control system for one robot may very likely be inappropriate for use in another. We therefore wish to give an appreciation for the breadth of options available to soft roboticists today.},
  archive      = {J_FROBT},
  author       = {McDonald, Kevin and Ranzani, Tommaso},
  doi          = {10.3389/frobt.2021.720702},
  journal      = {Frontiers in Robotics and AI},
  month        = {8},
  pages        = {720702},
  shortjournal = {Front. Robot. AI},
  title        = {Hardware methods for onboard control of fluidically actuated soft robots},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Blower-powered soft inflatable joints for physical
human-robot interaction. <em>FROBT</em>, <em>8</em>, 720683. (<a
href="https://doi.org/10.3389/frobt.2021.720683">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inflatables are safe and lightweight structures even at the human scale. Inflatable robots are expected to be applied to physical human-robot interaction (pHRI). Although active joint mechanisms are essential for developing inflatable robots, the existing mechanisms are complex in structure and it is difficult to integrate actuators, which diminish the advantages of inflatables. This study proposes blower-powered soft inflatable joints that are easy to fabricate and contain enough space for an actuation inside. The joints are driven by tendon wires pulled by linear actuators. We derived a theoretical model for both unilateral and bilateral joints and demonstrated a hugging robot with multiple joints as an application of the proposed joint mechanism. The novelty of the proposed joint mechanism and the inflatable robot is that rigid parts have been thoroughly eliminated and the tendons for actuation have been successfully hidden inside. Moreover, the active control of the internal pressure makes inflatables resistant to punctures. We expect that the contact safety of inflatable robots will facilitate advancement of the pHRI field.},
  archive      = {J_FROBT},
  author       = {Niiyama, Ryuma and Seong, Young ah and Kawahara, Yoshihiro and Kuniyoshi, Yasuo},
  doi          = {10.3389/frobt.2021.720683},
  journal      = {Frontiers in Robotics and AI},
  month        = {8},
  pages        = {720683},
  shortjournal = {Front. Robot. AI},
  title        = {Blower-powered soft inflatable joints for physical human-robot interaction},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). On the social-relational moral standing of AI: An empirical
study using AI-generated art. <em>FROBT</em>, <em>8</em>, 719944. (<a
href="https://doi.org/10.3389/frobt.2021.719944">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The moral standing of robots and artificial intelligence (AI) systems has become a widely debated topic by normative research. This discussion, however, has primarily focused on those systems developed for social functions, e.g., social robots. Given the increasing interdependence of society with nonsocial machines, examining how existing normative claims could be extended to specific disrupted sectors, such as the art industry, has become imperative. Inspired by the proposals to ground machines’ moral status on social relations advanced by Gunkel and Coeckelbergh, this research presents online experiments (∑N = 448) that test whether and how interacting with AI-generated art affects the perceived moral standing of its creator, i.e., the AI-generative system. Our results indicate that assessing an AI system’s lack of mind could influence how people subsequently evaluate AI-generated art. We also find that the overvaluation of AI-generated images could negatively affect their creator’s perceived agency. Our experiments, however, did not suggest that interacting with AI-generated art has any significant effect on the perceived moral standing of the machine. These findings reveal that social-relational approaches to AI rights could be intertwined with property-based theses of moral standing. We shed light on how empirical studies can contribute to the AI and robot rights debate by revealing the public perception of this issue.},
  archive      = {J_FROBT},
  author       = {Lima , Gabriel and Zhunis, Assem and Manovich, Lev and Cha, Meeyoung},
  doi          = {10.3389/frobt.2021.719944},
  journal      = {Frontiers in Robotics and AI},
  month        = {8},
  pages        = {719944},
  shortjournal = {Front. Robot. AI},
  title        = {On the social-relational moral standing of AI: An empirical study using AI-generated art},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). AntAlate—a multi-agent autonomy framework. <em>FROBT</em>,
<em>8</em>, 719496. (<a
href="https://doi.org/10.3389/frobt.2021.719496">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {AntAlate is a software framework for Unmanned Aerial Vehicle (UAV) autonomy, designed to streamline and facilitate the work of application developers, particularly in deployment of Multi-Agent Robotic Systems (MARS). We created AntAlate in order to bring our research in the field of multi-agent systems from theoretical results to both advanced simulations and to real-life demonstrations. Creating a framework capable of catering to MARS applications requires support for distributed, decentralized, control using local sensing, performed autonomously by groups of identical anonymous agents. Though mainly interested in the emergent behavior of the system as a whole, we focused on the single agent and created a framework suitable for a system of systems approach, while minimizing the hardware requirements of the single agent. Global observers or even a centralized control can be added on top of AntAlate, but the framework does not require a global actor to finalize an application. The same applies to a human in the loop, and fully autonomous UAV applications can be written in as straightforward a way as can semi-autonomous applications. In this paper we describe the AntAlate framework and demonstrate its utility and versatility.},
  archive      = {J_FROBT},
  author       = {Dovrat, David and Bruckstein, Alfred M.},
  doi          = {10.3389/frobt.2021.719496},
  journal      = {Frontiers in Robotics and AI},
  month        = {8},
  pages        = {719496},
  shortjournal = {Front. Robot. AI},
  title        = {AntAlate—A multi-agent autonomy framework},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The impact of machine learning on 2D/3D registration for
image-guided interventions: A systematic review and perspective.
<em>FROBT</em>, <em>8</em>, 716007. (<a
href="https://doi.org/10.3389/frobt.2021.716007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image-based navigation is widely considered the next frontier of minimally invasive surgery. It is believed that image-based navigation will increase the access to reproducible, safe, and high-precision surgery as it may then be performed at acceptable costs and effort. This is because image-based techniques avoid the need of specialized equipment and seamlessly integrate with contemporary workflows. Furthermore, it is expected that image-based navigation techniques will play a major role in enabling mixed reality environments, as well as autonomous and robot-assisted workflows. A critical component of image guidance is 2D/3D registration, a technique to estimate the spatial relationships between 3D structures, e.g., preoperative volumetric imagery or models of surgical instruments, and 2D images thereof, such as intraoperative X-ray fluoroscopy or endoscopy. While image-based 2D/3D registration is a mature technique, its transition from the bench to the bedside has been restrained by well-known challenges, including brittleness with respect to optimization objective, hyperparameter selection, and initialization, difficulties in dealing with inconsistencies or multiple objects, and limited single-view performance. One reason these challenges persist today is that analytical solutions are likely inadequate considering the complexity, variability, and high-dimensionality of generic 2D/3D registration problems. The recent advent of machine learning-based approaches to imaging problems that, rather than specifying the desired functional mapping, approximate it using highly expressive parametric models holds promise for solving some of the notorious challenges in 2D/3D registration. In this manuscript, we review the impact of machine learning on 2D/3D registration to systematically summarize the recent advances made by introduction of this novel technology. Grounded in these insights, we then offer our perspective on the most pressing needs, significant open problems, and possible next steps.},
  archive      = {J_FROBT},
  author       = {Unberath, Mathias and Gao, Cong and Hu, Yicheng and Judish, Max and Taylor, Russell H and Armand, Mehran and Grupp, Robert},
  doi          = {10.3389/frobt.2021.716007},
  journal      = {Frontiers in Robotics and AI},
  month        = {8},
  pages        = {716007},
  shortjournal = {Front. Robot. AI},
  title        = {The impact of machine learning on 2D/3D registration for image-guided interventions: A systematic review and perspective},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). A review of possible EEG markers of abstraction,
attentiveness, and memorisation in cyber-physical systems for special
education. <em>FROBT</em>, <em>8</em>, 715962. (<a
href="https://doi.org/10.3389/frobt.2021.715962">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cyber-physical systems (CPSs) for special education rely on effective mental and brain processing during the lesson, performed with the assistance of humanoid robots. The improved diagnostic ability of the CPS is a prerogative of the system for efficient technological support of the pedagogical process. The article focuses on the available knowledge of possible EEG markers of abstraction, attentiveness, and memorisation (in some cases combined with eye tracking) related to predicting effective mental and brain processing during the lesson. The role of processing abstraction is emphasised as the learning mechanism, which is given priority over the other mechanisms by the cognitive system. The main markers in focus are P1, N170, Novelty P3, RewP, N400, and P600. The description of the effects is accompanied by the analysis of some implications for the design of novel educational scenarios in inclusive classes.},
  archive      = {J_FROBT},
  author       = {Dimitrova, Maya and Wagatsuma, Hiroaki and Krastev, Aleksandar and Vrochidou, Eleni and Nunez-Gonzalez, J. David},
  doi          = {10.3389/frobt.2021.715962},
  journal      = {Frontiers in Robotics and AI},
  month        = {8},
  pages        = {715962},
  shortjournal = {Front. Robot. AI},
  title        = {A review of possible EEG markers of abstraction, attentiveness, and memorisation in cyber-physical systems for special education},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). NSPG: An efficient posture generator based on null-space
alteration and kinetostatics constraints. <em>FROBT</em>, <em>8</em>,
715325. (<a href="https://doi.org/10.3389/frobt.2021.715325">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most of the locomotion and contact planners for multi-limbed robots rely on a reduction of the search space to improve the performance of their algorithm. Posture generation plays a fundamental role in these types of planners providing a collision-free, statically stable whole-body posture, projected onto the planned contacts. However, posture generation becomes particularly tedious for complex robots moving in cluttered environments, in which feasibility can be hard to accomplish. In this work, we take advantage of the kinematic structure of a multi-limbed robot to present a posture generator based on hierarchical inverse kinematics and contact force optimization, called the null-space posture generator (NSPG), able to efficiently satisfy the aforementioned requisites in short times. A new configuration of the robot is produced through conservatively altering a given nominal posture exploiting the null-space of the contact manifold, satisfying geometrical and kinetostatics constraints. This is achieved through an adaptive random velocity vector generator that lets the robot explore its workspace. To prove the validity and generality of the proposed method, simulations in multiple scenarios are reported employing different robots: a wheeled-legged quadruped and a biped. Specifically, it is shown that the NSPG is particularly suited in complex cluttered scenarios, in which linear collision avoidance and stability constraints may be inefficient due to the high computational cost. In particular, we show an improvement of performances being our method able to generate twice feasible configurations in the same period. A comparison with previous methods has been carried out collecting the obtained results which highlight the benefits of the NSPG. Finally, experiments with the CENTAURO platform, developed at Istituto Italiano di Tecnologia, are carried out showing the applicability of the proposed method to a real corridor scenario.},
  archive      = {J_FROBT},
  author       = {Rossini, Luca and Hoffman, Enrico Mingo and Laurenzi, Arturo and Tsagarakis, Nikos G.},
  doi          = {10.3389/frobt.2021.715325},
  journal      = {Frontiers in Robotics and AI},
  month        = {8},
  pages        = {715325},
  shortjournal = {Front. Robot. AI},
  title        = {NSPG: An efficient posture generator based on null-space alteration and kinetostatics constraints},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An open-source ROS-gazebo toolbox for simulating robots with
compliant actuators. <em>FROBT</em>, <em>8</em>, 713083. (<a
href="https://doi.org/10.3389/frobt.2021.713083">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To enable the design of planning and control strategies in simulated environments before their direct application to the real robot, exploiting the Sim2Real practice, powerful and realistic dynamic simulation tools have been proposed, e.g., the ROS-Gazebo framework. However, the majority of such simulators do not account for some of the properties of recently developed advanced systems, e.g., dynamic elastic behaviors shown by all those robots that purposely incorporate compliant elements into their actuators, the so-called Articulated Soft Robots ASRs. This paper presents an open-source ROS-Gazebo toolbox for simulating ASRs equipped with the aforementioned types of compliant actuators. To achieve this result, the toolbox consists of two ROS-Gazebo modules: a plugin that implements the custom compliant characteristics of a given actuator and simulates the internal motor dynamics, and a Robotic Operation System (ROS) manager node used to organize and simplify the overall toolbox usage. The toolbox can implement different compliant joint structures to perform realistic and representative simulations of ASRs, also when they interact with the environment. The simulated ASRs can be also used to retrieve information about the physical behavior of the real system from its simulation, and to develop control policies that can be transferred back to the real world, leveraging the Sim2Real practice. To assess the versatility of the proposed plugin, we report simulations of different compliant actuators. Then, to show the reliability of the simulated results, we present experiments executed on two ASRs and compare the performance of the real hardware with the simulations. Finally, to validate the toolbox effectiveness for Sim2Real control design, we learn a control policy in simulation, then feed it to the real system in feed-forward comparing the results.},
  archive      = {J_FROBT},
  author       = {Mengacci, Riccardo and Zambella, Grazia and Grioli, Giorgio and Caporale, Danilo and Catalano, Manuel G. and Bicchi, Antonio},
  doi          = {10.3389/frobt.2021.713083},
  journal      = {Frontiers in Robotics and AI},
  month        = {8},
  pages        = {713083},
  shortjournal = {Front. Robot. AI},
  title        = {An open-source ROS-gazebo toolbox for simulating robots with compliant actuators},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Versatile locomotion planning and control for humanoid
robots. <em>FROBT</em>, <em>8</em>, 712239. (<a
href="https://doi.org/10.3389/frobt.2021.712239">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a locomotion framework for bipedal robots consisting of a new motion planning method, dubbed trajectory optimization for walking robots plus (TOWR+), and a new whole-body control method, dubbed implicit hierarchical whole-body controller (IHWBC). For versatility, we consider the use of a composite rigid body (CRB) model to optimize the robot’s walking behavior. The proposed CRB model considers the floating base dynamics while accounting for the effects of the heavy distal mass of humanoids using a pre-trained centroidal inertia network. TOWR+ leverages the phase-based parameterization of its precursor, TOWR, and optimizes for base and end-effectors motions, feet contact wrenches, as well as contact timing and locations without the need to solve a complementary problem or integer program. The use of IHWBC enforces unilateral contact constraints (i.e., non-slip and non-penetration constraints) and a task hierarchy through the cost function, relaxing contact constraints and providing an implicit hierarchy between tasks. This controller provides additional flexibility and smooth task and contact transitions as applied to our 10 degree-of-freedom, line-feet biped robot DRACO. In addition, we introduce a new open-source and light-weight software architecture, dubbed planning and control (PnC), that implements and combines TOWR+ and IHWBC. PnC provides modularity, versatility, and scalability so that the provided modules can be interchanged with other motion planners and whole-body controllers and tested in an end-to-end manner. In the experimental section, we first analyze the performance of TOWR+ using various bipeds. We then demonstrate balancing behaviors on the DRACO hardware using the proposed IHWBC method. Finally, we integrate TOWR+ and IHWBC and demonstrate step-and-stop behaviors on the DRACO hardware.},
  archive      = {J_FROBT},
  author       = {Ahn, Junhyeok and Jorgensen, Steven Jens and Bang, Seung Hyeon and Sentis, Luis},
  doi          = {10.3389/frobt.2021.712239},
  journal      = {Frontiers in Robotics and AI},
  month        = {8},
  pages        = {712239},
  shortjournal = {Front. Robot. AI},
  title        = {Versatile locomotion planning and control for humanoid robots},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Neural networks trained via reinforcement learning stabilize
walking of a three-dimensional biped model with exoskeleton
applications. <em>FROBT</em>, <em>8</em>, 710999. (<a
href="https://doi.org/10.3389/frobt.2021.710999">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Our group is developing a cyber-physical walking system (CPWS) for people paralyzed by spinal cord injuries (SCI). The current CPWS consists of a functional neuromuscular stimulation (FNS) system and a powered lower-limb exoskeleton for walking with leg movements in the sagittal plane. We are developing neural control systems that learn to assist the user of this CPWS to walk with stability. In a previous publication (Liu et al., Biomimetics, 2019, 4, 28), we showed a neural controller that stabilized a simulated biped in the sagittal plane. We are considering adding degrees of freedom to the CPWS to allow more natural walking movements and improved stability. Thus, in this paper, we present a new neural network enhanced control system that stabilizes a three-dimensional simulated biped model of a human wearing an exoskeleton. Results show that it stabilizes human/exoskeleton models and is robust to impact disturbances. The simulated biped walks at a steady pace in a range of typical human ambulatory speeds from 0.7 to 1.3 m/s, follows waypoints at a precision of 0.3 m, remains stable, and continues walking forward despite impact disturbances and adapts its speed to compensate for persistent external disturbances. Furthermore, the neural network controller stabilizes human models of different statures from 1.4 to 2.2 m tall without any changes to the control parameters. Please see videos at the following link: 3D biped walking control.},
  archive      = {J_FROBT},
  author       = {Liu, Chujun and Audu, Musa L. and Triolo, Ronald J. and Quinn, Roger D.},
  doi          = {10.3389/frobt.2021.710999},
  journal      = {Frontiers in Robotics and AI},
  month        = {8},
  pages        = {710999},
  shortjournal = {Front. Robot. AI},
  title        = {Neural networks trained via reinforcement learning stabilize walking of a three-dimensional biped model with exoskeleton applications},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Gaze gesture recognition by graph convolutional networks.
<em>FROBT</em>, <em>8</em>, 709952. (<a
href="https://doi.org/10.3389/frobt.2021.709952">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gaze gestures are extensively used in the interactions with agents/computers/robots. Either remote eye tracking devices or head-mounted devices (HMDs) have the advantage of hands-free during the interaction. Previous studies have demonstrated the success of applying machine learning techniques for gaze gesture recognition. More recently, graph neural networks (GNNs) have shown great potential applications in several research areas such as image classification, action recognition, and text classification. However, GNNs are less applied in eye tracking researches. In this work, we propose a graph convolutional network (GCN)–based model for gaze gesture recognition. We train and evaluate the GCN model on the HideMyGaze! dataset. The results show that the accuracy, precision, and recall of the GCN model are 97.62%, 97.18%, and 98.46%, respectively, which are higher than the other compared conventional machine learning algorithms, the artificial neural network (ANN) and the convolutional neural network (CNN).},
  archive      = {J_FROBT},
  author       = {Shi, Lei and Copot, Cosmin and Vanlanduit, Steve},
  doi          = {10.3389/frobt.2021.709952},
  journal      = {Frontiers in Robotics and AI},
  month        = {8},
  pages        = {709952},
  shortjournal = {Front. Robot. AI},
  title        = {Gaze gesture recognition by graph convolutional networks},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Grasp stability prediction for a dexterous robotic hand
combining depth vision and haptic bayesian exploration. <em>FROBT</em>,
<em>8</em>, 703869. (<a
href="https://doi.org/10.3389/frobt.2021.703869">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Grasp stability prediction of unknown objects is crucial to enable autonomous robotic manipulation in an unstructured environment. Even if prior information about the object is available, real-time local exploration might be necessary to mitigate object modelling inaccuracies. This paper presents an approach to predict safe grasps of unknown objects using depth vision and a dexterous robot hand equipped with tactile feedback. Our approach does not assume any prior knowledge about the objects. First, an object pose estimation is obtained from RGB-D sensing; then, the object is explored haptically to maximise a given grasp metric. We compare two probabilistic methods (i.e. standard and unscented Bayesian Optimisation) against random exploration (i.e. uniform grid search). Our experimental results demonstrate that these probabilistic methods can provide confident predictions after a limited number of exploratory observations, and that unscented Bayesian Optimisation can find safer grasps, taking into account the uncertainty in robot sensing and grasp execution.},
  archive      = {J_FROBT},
  author       = {Siddiqui, Muhammad Sami and Coppola, Claudio and Solak, Gokhan and Jamone, Lorenzo},
  doi          = {10.3389/frobt.2021.703869},
  journal      = {Frontiers in Robotics and AI},
  month        = {8},
  pages        = {703869},
  shortjournal = {Front. Robot. AI},
  title        = {Grasp stability prediction for a dexterous robotic hand combining depth vision and haptic bayesian exploration},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Fast and slow adaptations of interlimb coordination via
reflex and learning during split-belt treadmill walking of a quadruped
robot. <em>FROBT</em>, <em>8</em>, 697612. (<a
href="https://doi.org/10.3389/frobt.2021.697612">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Interlimb coordination plays an important role in adaptive locomotion of humans and animals. This has been investigated using a split-belt treadmill, which imposes different speeds on the two sides of the body. Two types of adaptation have been identified, namely fast and slow adaptations. Fast adaptation induces asymmetric interlimb coordination soon after a change of the treadmill speed condition from same speed for both belts to different speeds. In contrast, slow adaptation slowly reduces the asymmetry after fast adaptation. It has been suggested that these adaptations are primarily achieved by the spinal reflex and cerebellar learning. However, these adaptation mechanisms remain unclear due to the complicated dynamics of locomotion. In our previous work, we developed a locomotion control system for a biped robot based on the spinal reflex and cerebellar learning. We reproduced the fast and slow adaptations observed in humans during split-belt treadmill walking of the biped robot and clarified the adaptation mechanisms from a dynamic viewpoint by focusing on the changes in the relative positions between the center of mass and foot stance induced by reflex and learning. In this study, we modified the control system for application to a quadruped robot. We demonstrate that even though the basic gait pattern of our robot is different from that of general quadrupeds (due to limitations of the robot experiment), fast and slow adaptations that are similar to those of quadrupeds appear during split-belt treadmill walking of the quadruped robot. Furthermore, we clarify these adaptation mechanisms from a dynamic viewpoint, as done in our previous work. These results will increase the understanding of how fast and slow adaptations are generated in quadrupedal locomotion on a split-belt treadmill through body dynamics and sensorimotor integration via the spinal reflex and cerebellar learning and help the development of control strategies for adaptive locomotion of quadruped robots.},
  archive      = {J_FROBT},
  author       = {Aoi, Shinya and Amano, Takashi and Fujiki, Soichiro and Senda, Kei and Tsuchiya, Kazuo},
  doi          = {10.3389/frobt.2021.697612},
  journal      = {Frontiers in Robotics and AI},
  month        = {8},
  pages        = {697612},
  shortjournal = {Front. Robot. AI},
  title        = {Fast and slow adaptations of interlimb coordination via reflex and learning during split-belt treadmill walking of a quadruped robot},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A multimodal hydrogel soft-robotic sensor for
multi-functional perception. <em>FROBT</em>, <em>8</em>, 692754. (<a
href="https://doi.org/10.3389/frobt.2021.692754">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Soft robots, with their unique and outstanding capabilities of environmental conformation, natural sealing against elements, as well as being insensitive to magnetic/electrical effects, are ideal candidates for extreme environment applications. However, sensing for soft robots in such harsh conditions would still be challenging, especially under large temperature change and complex, large deformations. Existing soft sensing approaches using liquid-metal medium compromise between large deformation and environmental robustness, limiting their real-world applicability. In this work, we propose a multimodal solid-state soft sensor using hydrogel and silicone. By exploiting the conductance and transparency of hydrogel, we could deploy both optical and resistive sensing in one sensing component. This novel combination enables us to benefit from the in-situ measurement discrepancies between the optical and electrical signal, to extract multifunctional measurements. Following this approach, prototype solid-state soft sensors were designed and fabricated, a dedicated neural network was built to extract the sensory information. Stretching and twisting were measured using the same sensor even at large deformations. In addition, exploiting the distinctive responses against temperature change, we could estimate environmental temperatures simultaneously. Results are promising for the proposed solid-state multimodal approach of soft sensors for multifunctional perception under extreme conditions.},
  archive      = {J_FROBT},
  author       = {Cheng, Yu and Zhang, Runzhi and Zhu, Wenpei and Zhong, Hua and Liu, Sicong and Yi, Juan and Shao, Liyang and Wang, Wenping and Lam, James and Wang, Zheng},
  doi          = {10.3389/frobt.2021.692754},
  journal      = {Frontiers in Robotics and AI},
  month        = {8},
  pages        = {692754},
  shortjournal = {Front. Robot. AI},
  title        = {A multimodal hydrogel soft-robotic sensor for multi-functional perception},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Pursuer assignment and control strategies in multi-agent
pursuit-evasion under uncertainties. <em>FROBT</em>, <em>8</em>, 691637.
(<a href="https://doi.org/10.3389/frobt.2021.691637">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a pursuit-evasion problem with a heterogeneous team of multiple pursuers and multiple evaders. Although both the pursuers and the evaders are aware of each others’ control and assignment strategies, they do not have exact information about the other type of agents’ location or action. Using only noisy on-board sensors the pursuers (or evaders) make probabilistic estimation of positions of the evaders (or pursuers). Each type of agent use Markov localization to update the probability distribution of the other type. A search-based control strategy is developed for the pursuers that intrinsically takes the probability distribution of the evaders into account. Pursuers are assigned using an assignment algorithm that takes redundancy (i.e., an excess in the number of pursuers than the number of evaders) into account, such that the total or maximum estimated time to capture the evaders is minimized. In this respect we assume the pursuers to have clear advantage over the evaders. However, the objective of this work is to use assignment strategies that minimize the capture time. This assignment strategy is based on a modified Hungarian algorithm as well as a novel algorithm for determining assignment of redundant pursuers. The evaders, in order to effectively avoid the pursuers, predict the assignment based on their probabilistic knowledge of the pursuers and use a control strategy to actively move away from those pursues. Our experimental evaluation shows that the redundant assignment algorithm performs better than an alternative nearest-neighbor based assignment algorithm1.},
  archive      = {J_FROBT},
  author       = {Zhang, Leiming and Prorok, Amanda and Bhattacharya, Subhrajit},
  doi          = {10.3389/frobt.2021.691637},
  journal      = {Frontiers in Robotics and AI},
  month        = {8},
  pages        = {691637},
  shortjournal = {Front. Robot. AI},
  title        = {Pursuer assignment and control strategies in multi-agent pursuit-evasion under uncertainties},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Underwater crawling robot with hydraulic soft actuators.
<em>FROBT</em>, <em>8</em>, 688697. (<a
href="https://doi.org/10.3389/frobt.2021.688697">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Benthic operation plays a vital role in underwater applications, where crawling robots have advantages compared with turbine-based underwater vehicles, in locomotion accuracy, actuation efficiency, current resistance, and in carrying more payloads. On the other hand, soft robots are quickly trending in underwater robotic design, with their naturally sealed body structure and intrinsic compliance both desirable for the highly unstructured and corrosive underwater environment. However, the limitations resulting directly from the inherent compliance, in structural rigidity, actuation precision, and limited force exertion capability, have also restricted soft robots in underwater applications. To date soft robots are adopted mainly as grippers and manipulators for atraumatic sampling, rather than as locomotion platforms. In this work, we present a soft-robotic approach to designing underwater crawling robots, with three main innovations: 1) using rigid structural components to strategically reinforce the otherwise omni-directionally flexible soft actuators, drastically increasing their loading capability and actuation precision; 2) proposing a rigid–soft hybrid multi-joint leg design, with quasi-linear motion range and force exertion, while maintaining excellent passive impact compliance by exploiting the inherent flexibility of soft actuators; 3) developing a novel valve-free hydraulic actuation system with peristaltic pumps, achieving a compact, lightweight, and untethered underwater crawling robot prototype with a 5:1 payload-to-weight ratio and multi-gait capability. The prototype was tested for design verification and showcasing the advantages of the proposed hybrid mechanism and actuation approach.},
  archive      = {J_FROBT},
  author       = {Tan, Qinlin and Chen, Yishan and Liu, Jianhui and Zou, Kehan and Yi, Juan and Liu, Sicong and Wang, Zheng},
  doi          = {10.3389/frobt.2021.688697},
  journal      = {Frontiers in Robotics and AI},
  month        = {8},
  pages        = {688697},
  shortjournal = {Front. Robot. AI},
  title        = {Underwater crawling robot with hydraulic soft actuators},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A theory of social agency for human-robot interaction.
<em>FROBT</em>, <em>8</em>, 687726. (<a
href="https://doi.org/10.3389/frobt.2021.687726">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Motivated by inconsistent, underspecified, or otherwise problematic theories and usages of social agency in the HRI literature, and leveraging philosophical work on moral agency, we present a theory of social agency wherein a social agent (a thing with social agency) is any agent capable of social action at some level of abstraction. Like previous theorists, we conceptualize agency as determined by the criteria of interactivity, autonomy, and adaptability. We use the concept of face from politeness theory to define social action as any action that threatens or affirms the face of a social patient. With these definitions in mind, we specify and examine the levels of abstraction most relevant to HRI research, compare notions of social agency and the surrounding concepts at each, and suggest new conventions for discussing social agency in our field.},
  archive      = {J_FROBT},
  author       = {Jackson, Ryan Blake and Williams, Tom},
  doi          = {10.3389/frobt.2021.687726},
  journal      = {Frontiers in Robotics and AI},
  month        = {8},
  pages        = {687726},
  shortjournal = {Front. Robot. AI},
  title        = {A theory of social agency for human-robot interaction},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A differentiable extended kalman filter for object tracking
under sliding regime. <em>FROBT</em>, <em>8</em>, 686447. (<a
href="https://doi.org/10.3389/frobt.2021.686447">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tactile sensing represents a valuable source of information in robotics for perception of the state of objects and their properties. Modern soft tactile sensors allow perceiving orthogonal forces and, in some cases, relative motions along the surface of the object. Detecting and measuring this kind of lateral motion is fundamental to react to possibly uncontrolled slipping and sliding of the object being manipulated. Object slip detection and prediction have been extensively studied in the robotic community leading to solutions with good accuracy and suitable for closed-loop grip stabilization. However, algorithms for object perception, such as in-hand object pose estimation and tracking algorithms, often assume no relative motion between the object and the hand and rarely consider the problem of tracking the pose of the object subjected to slipping and sliding motions. In this work, we propose a differentiable Extended Kalman filter that can be trained to track the position and the velocity of an object under translational sliding regime from tactile observations alone. Experiments with several objects, carried out on the iCub humanoid robot platform, show that the proposed approach allows achieving an average position tracking error in the order of 0.6 cm, and that the provided estimate of the object state can be used to take control decisions using tactile feedback alone. A video of the experiments is available as Supplementary Material.},
  archive      = {J_FROBT},
  author       = {Piga, Nicola A. and Pattacini, Ugo and Natale, Lorenzo},
  doi          = {10.3389/frobt.2021.686447},
  journal      = {Frontiers in Robotics and AI},
  month        = {8},
  pages        = {686447},
  shortjournal = {Front. Robot. AI},
  title        = {A differentiable extended kalman filter for object tracking under sliding regime},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). O2A: One-shot observational learning with action vectors.
<em>FROBT</em>, <em>8</em>, 686368. (<a
href="https://doi.org/10.3389/frobt.2021.686368">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present O2A, a novel method for learning to perform robotic manipulation tasks from a single (one-shot) third-person demonstration video. To our knowledge, it is the first time this has been done for a single demonstration. The key novelty lies in pre-training a feature extractor for creating a perceptual representation for actions that we call “action vectors”. The action vectors are extracted using a 3D-CNN model pre-trained as an action classifier on a generic action dataset. The distance between the action vectors from the observed third-person demonstration and trial robot executions is used as a reward for reinforcement learning of the demonstrated task. We report on experiments in simulation and on a real robot, with changes in viewpoint of observation, properties of the objects involved, scene background and morphology of the manipulator between the demonstration and the learning domains. O2A outperforms baseline approaches under different domain shifts and has comparable performance with an Oracle (that uses an ideal reward function). Videos of the results, including demonstrations, can be found in our: project-website.},
  archive      = {J_FROBT},
  author       = {Pauly, Leo and Agboh , Wisdom C. and Hogg , David C. and Fuentes , Raul},
  doi          = {10.3389/frobt.2021.686368},
  journal      = {Frontiers in Robotics and AI},
  month        = {8},
  pages        = {686368},
  shortjournal = {Front. Robot. AI},
  title        = {O2A: One-shot observational learning with action vectors},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Creativity in generative musical networks: Evidence from two
case studies. <em>FROBT</em>, <em>8</em>, 680586. (<a
href="https://doi.org/10.3389/frobt.2021.680586">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning, one of the fastest-growing branches of artificial intelligence, has become one of the most relevant research and development areas of the last years, especially since 2012, when a neural network surpassed the most advanced image classification techniques of the time. This spectacular development has not been alien to the world of the arts, as recent advances in generative networks have made possible the artificial creation of high-quality content such as images, movies or music. We believe that these novel generative models propose a great challenge to our current understanding of computational creativity. If a robot can now create music that an expert cannot distinguish from music composed by a human, or create novel musical entities that were not known at training time, or exhibit conceptual leaps, does it mean that the machine is then creative? We believe that the emergence of these generative models clearly signals that much more research needs to be done in this area. We would like to contribute to this debate with two case studies of our own: TimbreNet, a variational auto-encoder network trained to generate audio-based musical chords, and StyleGAN Pianorolls, a generative adversarial network capable of creating short musical excerpts, despite the fact that it was trained with images and not musical data. We discuss and assess these generative models in terms of their creativity and we show that they are in practice capable of learning musical concepts that are not obvious based on the training data, and we hypothesize that these deep models, based on our current understanding of creativity in robots and machines, can be considered, in fact, creative.},
  archive      = {J_FROBT},
  author       = {Cádiz, Rodrigo F. and Macaya, Agustín and Cartagena, Manuel and Parra, Denis},
  doi          = {10.3389/frobt.2021.680586},
  journal      = {Frontiers in Robotics and AI},
  month        = {8},
  pages        = {680586},
  shortjournal = {Front. Robot. AI},
  title        = {Creativity in generative musical networks: Evidence from two case studies},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Modelling and control of a 2-DOF robot arm with elastic
joints for safe human-robot interaction. <em>FROBT</em>, <em>8</em>,
679304. (<a href="https://doi.org/10.3389/frobt.2021.679304">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Collaborative robots (or cobots) are robots that can safely work together or interact with humans in a common space. They gradually become noticeable nowadays. Compliant actuators are very relevant for the design of cobots. This type of actuation scheme mitigates the damage caused by unexpected collision. Therefore, elastic joints are considered to outperform rigid joints when operating in a dynamic environment. However, most of the available elastic robots are relatively costly or difficult to construct. To give researchers a solution that is inexpensive, easily customisable, and fast to fabricate, a newly-designed low-cost, and open-source design of an elastic joint is presented in this work. Based on the newly design elastic joint, a highly-compliant multi-purpose 2-DOF robot arm for safe human-robot interaction is also introduced. The mechanical design of the robot and a position control algorithm are presented. The mechanical prototype is 3D-printed. The control algorithm is a two loops control scheme. In particular, the inner control loop is designed as a model reference adaptive controller (MRAC) to deal with uncertainties in the system parameters, while the outer control loop utilises a fuzzy proportional-integral controller to reduce the effect of external disturbances on the load. The control algorithm is first validated in simulation. Then the effectiveness of the controller is also proven by experiments on the mechanical prototype.},
  archive      = {J_FROBT},
  author       = {Tuan, Hua Minh and Sanfilippo, Filippo and Hao, Nguyen Vinh},
  doi          = {10.3389/frobt.2021.679304},
  journal      = {Frontiers in Robotics and AI},
  month        = {8},
  pages        = {679304},
  shortjournal = {Front. Robot. AI},
  title        = {Modelling and control of a 2-DOF robot arm with elastic joints for safe human-robot interaction},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Individual differences in children’s (language) learning
skills moderate effects of robot-assisted second language learning.
<em>FROBT</em>, <em>8</em>, 676248. (<a
href="https://doi.org/10.3389/frobt.2021.676248">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The current study investigated how individual differences among children affect the added value of social robots for teaching second language (L2) vocabulary to young children. Specifically, we investigated the moderating role of three individual child characteristics deemed relevant for language learning: first language (L1) vocabulary knowledge, phonological memory, and selective attention. We expected children low in these abilities to particularly benefit from being assisted by a robot in a vocabulary training. An L2 English vocabulary training intervention consisting of seven sessions was administered to 193 monolingual Dutch five-year-old children over a three- to four-week period. Children were randomly assigned to one of three experimental conditions: 1) a tablet only, 2) a tablet and a robot that used deictic (pointing) gestures (the no-iconic-gestures condition), or 3) a tablet and a robot that used both deictic and iconic gestures (i.e., gestures depicting the target word; the iconic-gestures condition). There also was a control condition in which children did not receive a vocabulary training, but played dancing games with the robot. L2 word knowledge was measured directly after the training and two to four weeks later. In these post-tests, children in the experimental conditions outperformed children in the control condition on word knowledge, but there were no differences between the three experimental conditions. Several moderation effects were found. The robot’s presence particularly benefited children with larger L1 vocabularies or poorer phonological memory, while children with smaller L1 vocabularies or better phonological memory performed better in the tablet-only condition. Children with larger L1 vocabularies and better phonological memory performed better in the no-iconic-gestures condition than in the iconic-gestures condition, while children with better selective attention performed better in the iconic-gestures condition than the no-iconic-gestures condition. Together, the results showed that the effects of the robot and its gestures differ across children, which should be taken into account when designing and evaluating robot-assisted L2 teaching interventions.},
  archive      = {J_FROBT},
  author       = {van den Berghe, Rianne and Oudgenoeg-Paz, Ora and Verhagen, Josje and Brouwer, Susanne and de Haas, Mirjam and de Wit, Jan and Willemsen, Bram and Vogt, Paul and Krahmer, Emiel and Leseman, Paul},
  doi          = {10.3389/frobt.2021.676248},
  journal      = {Frontiers in Robotics and AI},
  month        = {8},
  pages        = {676248},
  shortjournal = {Front. Robot. AI},
  title        = {Individual differences in children’s (Language) learning skills moderate effects of robot-assisted second language learning},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Dynamic input deep learning control of artificial avatars in
a multi-agent joint motor task. <em>FROBT</em>, <em>8</em>, 665301. (<a
href="https://doi.org/10.3389/frobt.2021.665301">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In many real-word scenarios, humans and robots are required to coordinate their movements in joint tasks to fulfil a common goal. While several examples regarding dyadic human robot interaction exist in the current literature, multi-agent scenarios in which one or more artificial agents need to interact with many humans are still seldom investigated. In this paper we address the problem of synthesizing an autonomous artificial agent to perform a paradigmatic oscillatory joint task in human ensembles while exhibiting some desired human kinematic features. We propose an architecture based on deep reinforcement learning which is flexible enough to make the artificial agent interact with human groups of different sizes. As a paradigmatic coordination task we consider a multi-agent version of the mirror game, an oscillatory motor task largely used in the literature to study human motor coordination.},
  archive      = {J_FROBT},
  author       = {Lombardi, Maria and Liuzza, Davide and di Bernardo, Mario},
  doi          = {10.3389/frobt.2021.665301},
  journal      = {Frontiers in Robotics and AI},
  month        = {8},
  pages        = {665301},
  shortjournal = {Front. Robot. AI},
  title        = {Dynamic input deep learning control of artificial avatars in a multi-agent joint motor task},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A supernumerary soft robotic limb for reducing hand-arm
vibration syndromes risks. <em>FROBT</em>, <em>8</em>, 650613. (<a
href="https://doi.org/10.3389/frobt.2021.650613">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The most common causes of the risk of work-related musculoskeletal disorders (WMSD) have been identified as joint overloading, bad postures, and vibrations. In the last two decades, various solutions ranging from human-robot collaborative systems to robotic exoskeletons have been proposed to mitigate them. More recently, a new approach has been proposed with a high potential in this direction: the supernumerary robotic limbs SRLs are additional robotic body parts (e.g., fingers, legs, and arms) that can be worn by the workers, augmenting their natural ability and reducing the risks of injuries. These systems are generally proposed in the literature for their potentiality of augmenting the user’s ability, but here we would like to explore this kind of technology as a new generation of (personal) protective equipment. A supernumerary robotic upper limb, for example, allows for indirectly interacting with hazardous objects like chemical products or vibrating tools. In particular, in this work, we present a supernumerary robotic limbs system to reduce the vibration transmitted along the arms and minimize the load on the upper limb joints. For this purpose, an off-the-shelf wearable gravity compensation system is integrated with a soft robotic hand and a custom damping wrist, designed starting from theoretical considerations on a mass-spring-damper model. The real efficacy of the system was experimentally tested within a simulated industrial work environment, where seven subjects performed a drilling task on two different materials. Experimental analysis was conducted according to the ISO-5349. Results showed a reduction from 40 to 60% of vibration transmission with respect to the traditional hand drilling using the presented SRL system without compromising the time performance.},
  archive      = {J_FROBT},
  author       = {Ciullo, Andrea S. and Catalano, Manuel G. and Bicchi, Antonio and Ajoudani, Arash},
  doi          = {10.3389/frobt.2021.650613},
  journal      = {Frontiers in Robotics and AI},
  month        = {8},
  pages        = {650613},
  shortjournal = {Front. Robot. AI},
  title        = {A supernumerary soft robotic limb for reducing hand-arm vibration syndromes risks},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Ethical design of a robot platform for disabled employees:
Some practical methodological considerations. <em>FROBT</em>,
<em>8</em>, 643160. (<a
href="https://doi.org/10.3389/frobt.2021.643160">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper explains the process of developing a scenario involving the use of a robotic platform to enhance the work experience of disabled employees. We outline the challenges involved in revealing the potential unintended consequences of introducing elements of Artificial Intelligence, automation, and robotics into a socially and ethically complex and potentially fragile scenario, and the practical challenges involved in giving a voice to vulnerable users throughout the design process. While an ideal case scenario would involve the disabled employees as much as possible directly in the design process, this can, realistically, be a challenge. In this paper, we detail a methodological and analytic approach that is centered around ethnography and design fictions. It is designed to provide a deeper understanding of all the stakeholders involved in the scenario while encouraging ethical reflection. Based on our findings, we argue that, while it is relatively easy to adopt an a priori ethical stance through notions such as inclusivity and accessibility, there are risks involved in making such a priori prescriptions with respect to the perspectives of different stakeholders in an applied research project. More specifically, we highlight the importance of understanding the broad organizational and bureaucratic characteristics of a business or workplace when devising HRI scenarios and tasks, and of considering elements such as business models, operating philosophy, and organizational hierarchies in the design process.},
  archive      = {J_FROBT},
  author       = {Colombino, Tommaso and Gallo, Danilo and Shreepriya, Shreepriya and Im, Yesook and Cha, Seijin},
  doi          = {10.3389/frobt.2021.643160},
  journal      = {Frontiers in Robotics and AI},
  month        = {8},
  pages        = {643160},
  shortjournal = {Front. Robot. AI},
  title        = {Ethical design of a robot platform for disabled employees: Some practical methodological considerations},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Performance metrics for fluidic soft robot rotational
actuators. <em>FROBT</em>, <em>8</em>, 632835. (<a
href="https://doi.org/10.3389/frobt.2021.632835">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The field of soft robotics is continuing to grow as more researchers see the potential for robots that can safely interact in unmodeled, unstructured, and uncertain environments. However, in order for the design, integration, and control of soft robotic actuators to develop into a full engineering methodology, a set of metrics and standards need to be established. This paper attempts to lay the groundwork for that process by proposing six soft robot actuator metrics that can be used to evaluate and compare characteristics and performance of soft robot actuators. Data from eight different soft robot rotational actuators (five distinct designs) were used to evaluate these soft robot actuator metrics and show their utility. Additionally we provide a simple case study as an example of how these metrics can be used to evaluate soft robot actuators for a designated task. While this paper does not claim to present a comprehensive list of all possible soft robot actuator metrics, the metrics presented can 1) be used to initiate the development and comparison of soft robot actuators in an engineering framework and 2) start a broader discussion of which metrics should be standardized in future soft robot actuator research.},
  archive      = {J_FROBT},
  author       = {Rupert, Levi and Saunders, Benjamin O. and Killpack, Marc D.},
  doi          = {10.3389/frobt.2021.632835},
  journal      = {Frontiers in Robotics and AI},
  month        = {8},
  pages        = {632835},
  shortjournal = {Front. Robot. AI},
  title        = {Performance metrics for fluidic soft robot rotational actuators},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Applications of haptic technology, virtual reality, and
artificial intelligence in medical training during the COVID-19
pandemic. <em>FROBT</em>, <em>8</em>, 612949. (<a
href="https://doi.org/10.3389/frobt.2021.612949">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper examines how haptic technology, virtual reality, and artificial intelligence help to reduce the physical contact in medical training during the COVID-19 Pandemic. Notably, any mistake made by the trainees during the education process might lead to undesired complications for the patient. Therefore, training of the medical skills to the trainees have always been a challenging issue for the expert surgeons, and this is even more challenging in pandemics. The current method of surgery training needs the novice surgeons to attend some courses, watch some procedure, and conduct their initial operations under the direct supervision of an expert surgeon. Owing to the requirement of physical contact in this method of medical training, the involved people including the novice and expert surgeons confront a potential risk of infection to the virus. This survey paper reviews recent technological breakthroughs along with new areas in which assistive technologies might provide a viable solution to reduce the physical contact in the medical institutes during the COVID-19 pandemic and similar crises.},
  archive      = {J_FROBT},
  author       = {Motaharifar, Mohammad and Norouzzadeh, Alireza and Abdi, Parisa and Iranfar, Arash and Lotfi, Faraz and Moshiri, Behzad and Lashay, Alireza and Mohammadi, Seyed Farzad and Taghirad, Hamid D.},
  doi          = {10.3389/frobt.2021.612949},
  journal      = {Frontiers in Robotics and AI},
  month        = {8},
  pages        = {612949},
  shortjournal = {Front. Robot. AI},
  title        = {Applications of haptic technology, virtual reality, and artificial intelligence in medical training during the COVID-19 pandemic},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Delivery of healthcare resources using autonomous ground
vehicle convoy systems: An overview. <em>FROBT</em>, <em>8</em>, 611978.
(<a href="https://doi.org/10.3389/frobt.2021.611978">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Utilizing military convoys in humanitarian missions allows for increased overall performance of healthcare logistical operations. To properly gauge performance of autonomous ground convoy systems in military humanitarian operations, a proper framework for comparative performance metrics needs to be established. Past efforts in this domain have had heavy focus on narrow and specialized areas of convoy performance such as human factors, trust metrics, or string stability analysis. This article reviews available Army doctrine for manned convoy requirements toward healthcare missions and establishes a framework to compare performance of autonomous convoys, using metrics such as spacing error, separation distance, and string stability. After developing a framework of comparison for the convoy systems, this article compares the performance of two autonomous convoys with unique convoy control strategies to demonstrate the application and utility of the framework.},
  archive      = {J_FROBT},
  author       = {Cheung, Calvin and Mohammadi, Alireza and Rawashdeh, Samir and Baek, Stanley},
  doi          = {10.3389/frobt.2021.611978},
  journal      = {Frontiers in Robotics and AI},
  month        = {8},
  pages        = {611978},
  shortjournal = {Front. Robot. AI},
  title        = {Delivery of healthcare resources using autonomous ground vehicle convoy systems: An overview},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). On the design of social robots using sheaf theory and smart
contracts. <em>FROBT</em>, <em>8</em>, 559380. (<a
href="https://doi.org/10.3389/frobt.2021.559380">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The incorporation of robots in the social fabric of our society has taken giant leaps, enabled by advances in artificial intelligence and big data. As these robots become increasingly adept at parsing through enormous datasets and making decisions where humans fall short, a significant challenge lies in the analysis of robot behavior. Capturing interactions between robots, humans and IoT devices in traditional structures such as graphs poses challenges in the storage and analysis of large data sets in dense graphs generated by frequent activities. This paper proposes a framework that uses the blockchain for the storage of robotic interactions, and the use of sheaf theory for analysis of these interactions. Applications of our framework for social robots and swarm robots incorporating imperfect information and irrationality on the blockchain sheaf are proposed. This work shows the application of such a framework for various blockchain applications on the spectrum of human-robot interaction, and identifies key challenges that arise as a result of using the blockchain for robotic applications.},
  archive      = {J_FROBT},
  author       = {Murimi, Renita},
  doi          = {10.3389/frobt.2021.559380},
  journal      = {Frontiers in Robotics and AI},
  month        = {8},
  pages        = {559380},
  shortjournal = {Front. Robot. AI},
  title        = {On the design of social robots using sheaf theory and smart contracts},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Robustness of bio-inspired visual systems for collision
prediction in critical robot traffic. <em>FROBT</em>, <em>8</em>,
529872. (<a href="https://doi.org/10.3389/frobt.2021.529872">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Collision prevention sets a major research and development obstacle for intelligent robots and vehicles. This paper investigates the robustness of two state-of-the-art neural network models inspired by the locust’s LGMD-1 and LGMD-2 visual pathways as fast and low-energy collision alert systems in critical scenarios. Although both the neural circuits have been studied and modelled intensively, their capability and robustness against real-time critical traffic scenarios where real-physical crashes will happen have never been systematically investigated due to difficulty and high price in replicating risky traffic with many crash occurrences. To close this gap, we apply a recently published robotic platform to test the LGMDs inspired visual systems in physical implementation of critical traffic scenarios at low cost and high flexibility. The proposed visual systems are applied as the only collision sensing modality in each micro-mobile robot to conduct avoidance by abrupt braking. The simulated traffic resembles on-road sections including the intersection and highway scenes wherein the roadmaps are rendered by coloured, artificial pheromones upon a wide LCD screen acting as the ground of an arena. The robots with light sensors at bottom can recognise the lanes and signals, tightly follow paths. The emphasis herein is laid on corroborating the robustness of LGMDs neural systems model in different dynamic robot scenes to timely alert potential crashes. This study well complements previous experimentation on such bio-inspired computations for collision prediction in more critical physical scenarios, and for the first time demonstrates the robustness of LGMDs inspired visual systems in critical traffic towards a reliable collision alert system under constrained computation power. This paper also exhibits a novel, tractable, and affordable robotic approach to evaluate online visual systems in dynamic scenes.},
  archive      = {J_FROBT},
  author       = {Fu, Qinbing and Sun, Xuelong and Liu, Tian and Hu, Cheng and Yue, Shigang},
  doi          = {10.3389/frobt.2021.529872},
  journal      = {Frontiers in Robotics and AI},
  month        = {8},
  pages        = {529872},
  shortjournal = {Front. Robot. AI},
  title        = {Robustness of bio-inspired visual systems for collision prediction in critical robot traffic},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Corrigendum: Design of an inkjet-printed rotary bellows
actuator and simulation of its time-dependent deformation behavior.
<em>FROBT</em>, <em>8</em>, 729549. (<a
href="https://doi.org/10.3389/frobt.2021.729549">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Dämmer, Gabriel and Lackner, Michael and Laicher, Sonja and Neumann, Rüdiger and Major, Zoltán},
  doi          = {10.3389/frobt.2021.729549},
  journal      = {Frontiers in Robotics and AI},
  month        = {7},
  pages        = {729549},
  shortjournal = {Front. Robot. AI},
  title        = {Corrigendum: Design of an inkjet-printed rotary bellows actuator and simulation of its time-dependent deformation behavior},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Editorial: Machine learning techniques for soft robots.
<em>FROBT</em>, <em>8</em>, 726774. (<a
href="https://doi.org/10.3389/frobt.2021.726774">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {George Thuruthel, Thomas and Falotico, Egidio and Beccai, Lucia and Iida, Fumiya},
  doi          = {10.3389/frobt.2021.726774},
  journal      = {Frontiers in Robotics and AI},
  month        = {7},
  pages        = {726774},
  shortjournal = {Front. Robot. AI},
  title        = {Editorial: Machine learning techniques for soft robots},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). FBG-based estimation of external forces along flexible
instrument bodies. <em>FROBT</em>, <em>8</em>, 718033. (<a
href="https://doi.org/10.3389/frobt.2021.718033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A variety of medical treatment and diagnostic procedures rely on flexible instruments such as catheters and endoscopes to navigate through tortuous and soft anatomies like the vasculature. Knowledge of the interaction forces between these flexible instruments and patient anatomy is extremely valuable. This can aid interventionalists in having improved awareness and decision-making abilities, efficient navigation, and increased procedural safety. In many applications, force interactions are inherently distributed. While knowledge of their locations and magnitudes is highly important, retrieving this information from instruments with conventional dimensions is far from trivial. Robust and reliable methods have not yet been found for this purpose. In this work, we present two new approaches to estimate the location, magnitude, and number of external point and distributed forces applied to flexible and elastic instrument bodies. Both methods employ the knowledge of the instrument’s curvature profile. The former is based on piecewise polynomial-based curvature segmentation, whereas the latter on model-based parameter estimation. The proposed methods make use of Cosserat rod theory to model the instrument and provide force estimates at rates over 30 Hz. Experiments on a Nitinol rod embedded with a multi-core fiber, inscribed with fiber Bragg gratings, illustrate the feasibility of the proposed methods with mean force error reaching 7.3% of the maximum applied force, for the point load case. Furthermore, simulations of a rod subjected to two distributed loads with varying magnitudes and locations show a mean force estimation error of 1.6% of the maximum applied force.},
  archive      = {J_FROBT},
  author       = {Al-Ahmad, Omar and Ourak, Mouloud and Vlekken, Johan and Vander Poorten, Emmanuel},
  doi          = {10.3389/frobt.2021.718033},
  journal      = {Frontiers in Robotics and AI},
  month        = {7},
  pages        = {718033},
  shortjournal = {Front. Robot. AI},
  title        = {FBG-based estimation of external forces along flexible instrument bodies},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Feasibility of fiber reinforcement within magnetically
actuated soft continuum robots. <em>FROBT</em>, <em>8</em>, 715662. (<a
href="https://doi.org/10.3389/frobt.2021.715662">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Soft continuum manipulators have the potential to replace traditional surgical catheters; offering greater dexterity with access to previously unfeasible locations for a wide range of interventions including neurological and cardiovascular. Magnetically actuated catheters are of particular interest due to their potential for miniaturization and remote control. Challenges around the operation of these catheters exist however, and one of these occurs when the angle between the actuating field and the local magnetization vector of the catheter exceeds 90°. In this arrangement, deformation generated by the resultant magnetic moment acts to increase magnetic torque, leading to potential instability. This phenomenon can cause unpredictable responses to actuation, particularly for soft, flexible materials. When coupled with the inherent challenges of sensing and localization inside living tissue, this behavior represents a barrier to progress. In this feasibility study we propose and investigate the use of helical fiber reinforcement within magnetically actuated soft continuum manipulators. Using numerical simulation to explore the design space, we optimize fiber parameters to enhance the ratio of torsional to bending stiffness. Through bespoke fabrication of an optimized helix design we validate a single, prototypical two-segment, 40 mm × 6 mm continuum manipulator demonstrating a reduction of 67% in unwanted twisting under actuation.},
  archive      = {J_FROBT},
  author       = {Lloyd, Peter and Koszowska, Zaneta and Di Lecce, Michele and Onaizah, Onaizah and Chandler, James H. and Valdastri, Pietro},
  doi          = {10.3389/frobt.2021.715662},
  journal      = {Frontiers in Robotics and AI},
  month        = {7},
  pages        = {715662},
  shortjournal = {Front. Robot. AI},
  title        = {Feasibility of fiber reinforcement within magnetically actuated soft continuum robots},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Editorial: Artificial intelligence and human movement in
industries and creation. <em>FROBT</em>, <em>8</em>, 712521. (<a
href="https://doi.org/10.3389/frobt.2021.712521">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Dimitropoulos, Kosmas and Daras, Petros and Manitsaris, Sotiris and Fol Leymarie, Frederic and Calinon, Sylvain},
  doi          = {10.3389/frobt.2021.712521},
  journal      = {Frontiers in Robotics and AI},
  month        = {7},
  pages        = {712521},
  shortjournal = {Front. Robot. AI},
  title        = {Editorial: Artificial intelligence and human movement in industries and creation},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Whether to save a robot or a human: On the ethical and legal
limits of protections for robots. <em>FROBT</em>, <em>8</em>, 712427.
(<a href="https://doi.org/10.3389/frobt.2021.712427">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Proponents of welcoming robots into the moral circle have presented various approaches to moral patiency under which determining the moral status of robots seems possible. However, even if we recognize robots as having moral standing, how should we situate them in the hierarchy of values? In particular, who should be sacrificed in a moral dilemma–a human or a robot? This paper answers this question with reference to the most popular approaches to moral patiency. However, the conclusions of a survey on moral patiency do not consider another important factor, namely the law. For now, the hierarchy of values is set by law, and we must take that law into consideration when making decisions. I demonstrate that current legal systems prioritize human beings and even force the active protection of humans. Recent studies have suggested that people would hesitate to sacrifice robots in order to save humans, yet doing so could be a crime. This hesitancy is associated with the anthropomorphization of robots, which are becoming more human-like. Robots’ increasing similarity to humans could therefore lead to the endangerment of humans and the criminal responsibility of others. I propose two recommendations in terms of robot design to ensure the supremacy of human life over that of humanoid robots.},
  archive      = {J_FROBT},
  author       = {Mamak, Kamil},
  doi          = {10.3389/frobt.2021.712427},
  journal      = {Frontiers in Robotics and AI},
  month        = {7},
  pages        = {712427},
  shortjournal = {Front. Robot. AI},
  title        = {Whether to save a robot or a human: On the ethical and legal limits of protections for robots},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Application of adaptive and switching control for contact
maintenance of a robotic vehicle-manipulator system for underwater asset
inspection. <em>FROBT</em>, <em>8</em>, 706558. (<a
href="https://doi.org/10.3389/frobt.2021.706558">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The aim of this study is to design an adaptive controller for the hard contact interaction problem of underwater vehicle-manipulator systems (UVMS) to realize asset inspection through physical interaction. The proposed approach consists of a force and position controller in the operational space of the end effector of the robot manipulator mounted on an underwater vehicle. The force tracking algorithm keeps the end effector perpendicular to the unknown surface of the asset and the position tracking algorithm makes it follow a desired trajectory on the surface. The challenging problem in such a system is to maintain the end effector of the manipulator in continuous and stable contact with the unknown surface in the presence of disturbances and reaction forces that constantly move the floating robot base in an unexpected manner. The main contribution of the proposed controller is the development of the adaptive force tracking control algorithm based on switching actions between contact and noncontact states. When the end effector loses contact with the surface, a velocity feed-forward augmented impedance controller is activated to rapidly regain contact interaction by generating a desired position profile whose speed is adjusted depending on the time and the point where the contact was lost. Once the contact interaction is reestablished, a dynamic adaptive damping-based admittance controller is operated for fast adaptation and continuous stable force tracking. To validate the proposed controller, we conducted experiments with a land robotic setup composed of a 6 degrees of freedom (DOF) Stewart Platform imitating an underwater vehicle and a 7 DOF KUKA IIWA robotic arm imitating the underwater robot manipulator attached to the vehicle. The proposed scheme significantly increases the contact time under realistic disturbances, in comparison to our former controllers without an adaptive control scheme. We have demonstrated the superior performance of the current controller with experiments and quantified measures.},
  archive      = {J_FROBT},
  author       = {Cetin, Kamil and Zapico, Carlos Suarez and Tugal, Harun and Petillot, Yvan and Dunnigan, Matthew and Erden, Mustafa Suphi},
  doi          = {10.3389/frobt.2021.706558},
  journal      = {Frontiers in Robotics and AI},
  month        = {7},
  pages        = {706558},
  shortjournal = {Front. Robot. AI},
  title        = {Application of adaptive and switching control for contact maintenance of a robotic vehicle-manipulator system for underwater asset inspection},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Micrometer positioning accuracy with a planar parallel
continuum robot. <em>FROBT</em>, <em>8</em>, 706070. (<a
href="https://doi.org/10.3389/frobt.2021.706070">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Parallel Continuum Robots (PCR) have several advantages over classical articulated robots, notably a large workspace, miniaturization capabilities and safe human-robot interactions. However, their low accuracy is still a serious drawback. Indeed, several conditions have to be met for PCR to reach a high accuracy, namely: a repeatable mechanical structure, a correct kinematic model, and a proper estimation of the model’s parameters. In this article, we propose a methodology that allows reaching a micrometer accuracy with a PCR. This approach emphasizes the importance of using a repeatable continuum mechanism, identifying the most influential parameters of an accurate kinematic model of the robot and precisely measuring them. The experimental results show that the proposed approach allows to reach an accuracy of 3.3 µm in position and 0.5 mrad in orientation over a 10 mm long circular path. These results push the current limits of PCR accuracy and make them good potential candidates for high accuracy automatic positioning tasks.},
  archive      = {J_FROBT},
  author       = {Mauzé, Benjamin and Laurent, Guillaume J. and Dahmouche, Redwan and Clévy, Cédric},
  doi          = {10.3389/frobt.2021.706070},
  journal      = {Frontiers in Robotics and AI},
  month        = {7},
  pages        = {706070},
  shortjournal = {Front. Robot. AI},
  title        = {Micrometer positioning accuracy with a planar parallel continuum robot},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Endorobots for colonoscopy: Design challenges and available
technologies. <em>FROBT</em>, <em>8</em>, 705454. (<a
href="https://doi.org/10.3389/frobt.2021.705454">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Colorectal cancer (CRC) is the second most common cause of cancer death worldwide, after lung cancer (Sung et al., 2021). Early stage detection is key to increase the survival rate. Colonoscopy remains to be the gold standard procedure due to its dual capability to optically inspect the entire colonic mucosa and to perform interventional procedures at the same time. However, this causes pain and discomfort, whereby it requires sedation or anaesthesia of the patient. It is a difficult procedure to perform that can cause damage to the colonic wall in some cases. Development of new technologies aims to overcome the current limitations on colonoscopy by using advancements in endorobotics research. The design of these advanced medical devices is challenging because of the limited space of the lumen, the contorted shape, and the long tract of the large bowel. The force applied to the colonic wall needs to be controlled to avoid collateral effects such as injuries to the colonic mucosa and pain during the procedure. This article discusses the current challenges in the colonoscopy procedure, the available locomotion technologies for endorobots used in colonoscopy at a prototype level and the commercial products available.},
  archive      = {J_FROBT},
  author       = {Manfredi, Luigi},
  doi          = {10.3389/frobt.2021.705454},
  journal      = {Frontiers in Robotics and AI},
  month        = {7},
  pages        = {705454},
  shortjournal = {Front. Robot. AI},
  title        = {Endorobots for colonoscopy: Design challenges and available technologies},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Reinforcement learning and control of a lower extremity
exoskeleton for squat assistance. <em>FROBT</em>, <em>8</em>, 702845.
(<a href="https://doi.org/10.3389/frobt.2021.702845">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A significant challenge for the control of a robotic lower extremity rehabilitation exoskeleton is to ensure stability and robustness during programmed tasks or motions, which is crucial for the safety of the mobility-impaired user. Due to various levels of the user’s disability, the human-exoskeleton interaction forces and external perturbations are unpredictable and could vary substantially and cause conventional motion controllers to behave unreliably or the robot to fall down. In this work, we propose a new, reinforcement learning-based, motion controller for a lower extremity rehabilitation exoskeleton, aiming to perform collaborative squatting exercises with efficiency, stability, and strong robustness. Unlike most existing rehabilitation exoskeletons, our exoskeleton has ankle actuation on both sagittal and front planes and is equipped with multiple foot force sensors to estimate center of pressure (CoP), an important indicator of system balance. This proposed motion controller takes advantage of the CoP information by incorporating it in the state input of the control policy network and adding it to the reward during the learning to maintain a well balanced system state during motions. In addition, we use dynamics randomization and adversary force perturbations including large human interaction forces during the training to further improve control robustness. To evaluate the effectiveness of the learning controller, we conduct numerical experiments with different settings to demonstrate its remarkable ability on controlling the exoskeleton to repetitively perform well balanced and robust squatting motions under strong perturbations and realistic human interaction forces.},
  archive      = {J_FROBT},
  author       = {Luo, Shuzhen and Androwis, Ghaith and Adamovich, Sergei and Su, Hao and Nunez, Erick and Zhou, Xianlian},
  doi          = {10.3389/frobt.2021.702845},
  journal      = {Frontiers in Robotics and AI},
  month        = {7},
  pages        = {702845},
  shortjournal = {Front. Robot. AI},
  title        = {Reinforcement learning and control of a lower extremity exoskeleton for squat assistance},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Soft capsule magnetic millirobots for region-specific drug
delivery in the central nervous system. <em>FROBT</em>, <em>8</em>,
702566. (<a href="https://doi.org/10.3389/frobt.2021.702566">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Small soft robotic systems are being explored for myriad applications in medicine. Specifically, magnetically actuated microrobots capable of remote manipulation hold significant potential for the targeted delivery of therapeutics and biologicals. Much of previous efforts on microrobotics have been dedicated to locomotion in aqueous environments and hard surfaces. However, our human bodies are made of dense biological tissues, requiring researchers to develop new microrobotics that can locomote atop tissue surfaces. Tumbling microrobots are a sub-category of these devices capable of walking on surfaces guided by rotating magnetic fields. Using microrobots to deliver payloads to specific regions of sensitive tissues is a primary goal of medical microrobots. Central nervous system (CNS) tissues are a prime candidate given their delicate structure and highly region-specific function. Here we demonstrate surface walking of soft alginate capsules capable of moving on top of a rat cortex and mouse spinal cord ex vivo, demonstrating multi-location small molecule delivery to up to six different locations on each type of tissue with high spatial specificity. The softness of alginate gel prevents injuries that may arise from friction with CNS tissues during millirobot locomotion. Development of this technology may be useful in clinical and preclinical applications such as drug delivery, neural stimulation, and diagnostic imaging.},
  archive      = {J_FROBT},
  author       = {Mair, Lamar O. and Adam, Georges and Chowdhury, Sagar and Davis, Aaron and Arifin, Dian R. and Vassoler, Fair M. and Engelhard, Herbert H. and Li, Jinxing and Tang, Xinyao and Weinberg, Irving N. and Evans, Benjamin A. and Bulte, Jeff W.M. and Cappelleri, David J.},
  doi          = {10.3389/frobt.2021.702566},
  journal      = {Frontiers in Robotics and AI},
  month        = {7},
  pages        = {702566},
  shortjournal = {Front. Robot. AI},
  title        = {Soft capsule magnetic millirobots for region-specific drug delivery in the central nervous system},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Robot-guided evacuation as a paradigm for human-robot
interaction research. <em>FROBT</em>, <em>8</em>, 701938. (<a
href="https://doi.org/10.3389/frobt.2021.701938">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper conceptualizes the problem of emergency evacuation as a paradigm for investigating human-robot interaction. We argue that emergency evacuation offers unique and important perspectives on human-robot interaction while also demanding close attention to the ethical ramifications of the technologies developed. We present a series of approaches for developing emergency evacuation robots and detail several essential design considerations. This paper concludes with a discussion of the ethical implications of emergency evacuation robots and a roadmap for their development, implementation, and evaluation.},
  archive      = {J_FROBT},
  author       = {Wagner, Alan R.},
  doi          = {10.3389/frobt.2021.701938},
  journal      = {Frontiers in Robotics and AI},
  month        = {7},
  pages        = {701938},
  shortjournal = {Front. Robot. AI},
  title        = {Robot-guided evacuation as a paradigm for human-robot interaction research},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). EMERGE modular robot: A tool for fast deployment of evolved
robots. <em>FROBT</em>, <em>8</em>, 699814. (<a
href="https://doi.org/10.3389/frobt.2021.699814">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work presents a platform for evolution of morphology in full cycle reconfigurable hardware: The EMERGE (Easy Modular Embodied Robot Generator) modular robot platform. Three parts necessary to implement a full cycle process, i.e., assembling the modules in morphologies, testing the morphologies, disassembling modules and repeating, are described as a previous step to testing a fully autonomous system: the mechanical design of the EMERGE module, extensive tests of the modules by first assembling them manually, and automatic assembly and disassembly tests. EMERGE modules are designed to be easy and fast to build, one module is built in half an hour and is constructed from off-the-shelf and 3D printed parts. Thanks to magnetic connectors, modules are quickly attached and detached to assemble and reconfigure robot morphologies. To test the performance of real EMERGE modules, 30 different morphologies are evolved in simulation, transferred to reality, and tested 10 times. Manual assembly of these morphologies is aided by a visual guiding tool that uses AprilTag markers to check the real modules positions in the morphology against their simulated counterparts and provides a color feedback. Assembly time takes under 5 min for robots with fewer than 10 modules and increases linearly with the number of modules in the morphology. Tests show that real EMERGE morphologies can reproduce the performance of their simulated counterparts, considering the reality gap. Results also show that magnetic connectors allow modules to disconnect in case of being subjected to high external torques that could damage them otherwise. Module tracking combined with their easy assembly and disassembly feature enable EMERGE modules to be also reconfigured using an external robotic manipulator. Experiments demonstrate that it is possible to attach and detach modules from a morphology, as well as release the module from the manipulator using a passive magnetic gripper. This shows that running a completely autonomous, evolution of morphology in full cycle reconfigurable hardware of different topologies for robots is possible and on the verge of being realized. We discuss EMERGE features and the trade-off between reusability and morphological variability among different approaches to physically implement evolved robots.},
  archive      = {J_FROBT},
  author       = {Moreno, Rodrigo and Faiña, Andres},
  doi          = {10.3389/frobt.2021.699814},
  journal      = {Frontiers in Robotics and AI},
  month        = {7},
  pages        = {699814},
  shortjournal = {Front. Robot. AI},
  title        = {EMERGE modular robot: A tool for fast deployment of evolved robots},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Aiding grasp synthesis for novel objects using
heuristic-based and data-driven active vision methods. <em>FROBT</em>,
<em>8</em>, 696587. (<a
href="https://doi.org/10.3389/frobt.2021.696587">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we present several heuristic-based and data-driven active vision strategies for viewpoint optimization of an arm-mounted depth camera to aid robotic grasping. These strategies aim to efficiently collect data to boost the performance of an underlying grasp synthesis algorithm. We created an open-source benchmarking platform in simulation (https://github.com/galenbr/2021ActiveVision), and provide an extensive study for assessing the performance of the proposed methods as well as comparing them against various baseline strategies. We also provide an experimental study with a real-world two finger parallel jaw gripper setup by utilizing an existing grasp planning benchmark in the literature. With these analyses, we were able to quantitatively demonstrate the versatility of heuristic methods that prioritize certain types of exploration, and qualitatively show their robustness to both novel objects and the transition from simulation to the real world. We identified scenarios in which our methods did not perform well and objectively difficult scenarios, and present a discussion on which avenues for future research show promise.},
  archive      = {J_FROBT},
  author       = {Natarajan, Sabhari and Brown, Galen and Calli, Berk},
  doi          = {10.3389/frobt.2021.696587},
  journal      = {Frontiers in Robotics and AI},
  month        = {7},
  pages        = {696587},
  shortjournal = {Front. Robot. AI},
  title        = {Aiding grasp synthesis for novel objects using heuristic-based and data-driven active vision methods},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Real-world robot evolution: Why would it (not) work?
<em>FROBT</em>, <em>8</em>, 696452. (<a
href="https://doi.org/10.3389/frobt.2021.696452">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper takes a critical look at the concept of real-world robot evolution discussing specific challenges for making it practicable. After a brief review of the state of the art several enablers are discussed in detail. It is noted that sample efficient evolution is one of the key prerequisites and there are various promising directions towards this in different stages of maturity, including learning as part of the evolutionary system, genotype filtering, and hybridizing real-world evolution with simulations in a new way. Furthermore, it is emphasized that an evolutionary system that works in the real world needs robots that work in the real world. Obvious as it may seem, to achieve this significant complexification of the robots and their tasks is needed compared to the current practice. Finally, the importance of not only building but also understanding evolving robot systems is emphasised, stating that in order to have the technology work we also need the science behind it.},
  archive      = {J_FROBT},
  author       = {Eiben, A.E.},
  doi          = {10.3389/frobt.2021.696452},
  journal      = {Frontiers in Robotics and AI},
  month        = {7},
  pages        = {696452},
  shortjournal = {Front. Robot. AI},
  title        = {Real-world robot evolution: Why would it (not) work?},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Becoming team members: Identifying interaction patterns of
mutual adaptation for human-robot co-learning. <em>FROBT</em>,
<em>8</em>, 692811. (<a
href="https://doi.org/10.3389/frobt.2021.692811">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Becoming a well-functioning team requires continuous collaborative learning by all team members. This is called co-learning, conceptualized in this paper as comprising two alternating iterative stages: partners adapting their behavior to the task and to each other (co-adaptation), and partners sustaining successful behavior through communication. This paper focuses on the first stage in human-robot teams, aiming at a method for the identification of recurring behaviors that indicate co-learning. Studying this requires a task context that allows for behavioral adaptation to emerge from the interactions between human and robot. We address the requirements for conducting research into co-adaptation by a human-robot team, and designed a simplified computer simulation of an urban search and rescue task accordingly. A human participant and a virtual robot were instructed to discover how to collaboratively free victims from the rubbles of an earthquake. The virtual robot was designed to be able to real-time learn which actions best contributed to good team performance. The interactions between human participants and robots were recorded. The observations revealed patterns of interaction used by human and robot in order to adapt their behavior to the task and to one another. Results therefore show that our task environment enables us to study co-learning, and suggest that more participant adaptation improved robot learning and thus team level learning. The identified interaction patterns can emerge in similar task contexts, forming a first description and analysis method for co-learning. Moreover, the identification of interaction patterns support awareness among team members, providing the foundation for human-robot communication about the co-adaptation (i.e., the second stage of co-learning). Future research will focus on these human-robot communication processes for co-learning.},
  archive      = {J_FROBT},
  author       = {van Zoelen, Emma M. and van den Bosch, Karel and Neerincx, Mark},
  doi          = {10.3389/frobt.2021.692811},
  journal      = {Frontiers in Robotics and AI},
  month        = {7},
  pages        = {692811},
  shortjournal = {Front. Robot. AI},
  title        = {Becoming team members: Identifying interaction patterns of mutual adaptation for human-robot co-learning},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Dynamically tunable friction via subsurface stiffness
modulation. <em>FROBT</em>, <em>8</em>, 691789. (<a
href="https://doi.org/10.3389/frobt.2021.691789">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Currently soft robots primarily rely on pneumatics and geometrical asymmetry to achieve locomotion, which limits their working range, versatility, and other untethered functionalities. In this paper, we introduce a novel approach to achieve locomotion for soft robots through dynamically tunable friction to address these challenges, which is achieved by subsurface stiffness modulation (SSM) of a stimuli-responsive component within composite structures. To demonstrate this, we design and fabricate an elastomeric pad made of polydimethylsiloxane (PDMS), which is embedded with a spiral channel filled with a low melting point alloy (LMPA). Once the LMPA strip is melted upon Joule heating, the compliance of the composite structure increases and the friction between the composite surface and the opposing surface increases. A series of experiments and finite element analysis (FEA) have been performed to characterize the frictional behavior of these composite pads and elucidate the underlying physics dominating the tunable friction. We also demonstrate that when these composite structures are properly integrated into soft crawling robots inspired by inchworms and earthworms, the differences in friction of the two ends of these robots through SSM can potentially be used to generate translational locomotion for untethered crawling robots.},
  archive      = {J_FROBT},
  author       = {Sharifi, Siavash and Rux, Caleb and Sparling, Nathaniel and Wan, Guangchao and Mohammadi Nasab, Amir and Siddaiah, Arpith and Menezes, Pradeep and Zhang, Teng and Shan, Wanliang},
  doi          = {10.3389/frobt.2021.691789},
  journal      = {Frontiers in Robotics and AI},
  month        = {7},
  pages        = {691789},
  shortjournal = {Front. Robot. AI},
  title        = {Dynamically tunable friction via subsurface stiffness modulation},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Compositional RL agents that follow language commands in
temporal logic. <em>FROBT</em>, <em>8</em>, 689550. (<a
href="https://doi.org/10.3389/frobt.2021.689550">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We demonstrate how a reinforcement learning agent can use compositional recurrent neural networks to learn to carry out commands specified in linear temporal logic (LTL). Our approach takes as input an LTL formula, structures a deep network according to the parse of the formula, and determines satisfying actions. This compositional structure of the network enables zero-shot generalization to significantly more complex unseen formulas. We demonstrate this ability in multiple problem domains with both discrete and continuous state-action spaces. In a symbolic domain, the agent finds a sequence of letters that satisfy a specification. In a Minecraft-like environment, the agent finds a sequence of actions that conform to a formula. In the Fetch environment, the robot finds a sequence of arm configurations that move blocks on a table to fulfill the commands. While most prior work can learn to execute one formula reliably, we develop a novel form of multi-task learning for RL agents that allows them to learn from a diverse set of tasks and generalize to a new set of diverse tasks without any additional training. The compositional structures presented here are not specific to LTL, thus opening the path to RL agents that perform zero-shot generalization in other compositional domains.},
  archive      = {J_FROBT},
  author       = {Kuo, Yen-Ling and Katz, Boris and Barbu, Andrei},
  doi          = {10.3389/frobt.2021.689550},
  journal      = {Frontiers in Robotics and AI},
  month        = {7},
  pages        = {689550},
  shortjournal = {Front. Robot. AI},
  title        = {Compositional RL agents that follow language commands in temporal logic},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Vision-guided MPC for robotic path following using learned
memory-augmented model. <em>FROBT</em>, <em>8</em>, 688275. (<a
href="https://doi.org/10.3389/frobt.2021.688275">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The control of the interaction between the robot and environment, following a predefined geometric surface path with high accuracy, is a fundamental problem for contact-rich tasks such as machining, polishing, or grinding. Flexible path-following control presents numerous applications in emerging industry fields such as disassembly and recycling, where the control system must adapt to a range of dissimilar object classes, where the properties of the environment are uncertain. We present an end-to-end framework for trajectory-independent robotic path following for contact-rich tasks in the presence of parametric uncertainties. We formulate a combination of model predictive control with image-based path planning and real-time visual feedback, based on a learned state-space dynamic model. For modeling the dynamics of the robot-environment system during contact, we introduce the application of the differentiable neural computer, a type of memory augmented neural network (MANN). Although MANNs have been as yet unexplored in a control context, we demonstrate a reduction in RMS error of &lt;mml:math id=&quot;m1&quot; xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mml:mo&gt;∼&lt;/mml:mo&gt;&lt;/mml:math&gt;21.0% compared with an equivalent Long Short-Term Memory (LSTM) architecture. Our framework was validated in simulation, demonstrating the ability to generalize to materials previously unseen in the training dataset.},
  archive      = {J_FROBT},
  author       = {Rastegarpanah, Alireza and Hathaway, Jamie and Stolkin, Rustam},
  doi          = {10.3389/frobt.2021.688275},
  journal      = {Frontiers in Robotics and AI},
  month        = {7},
  pages        = {688275},
  shortjournal = {Front. Robot. AI},
  title        = {Vision-guided MPC for robotic path following using learned memory-augmented model},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Robotic manipulation and capture in space: A survey.
<em>FROBT</em>, <em>8</em>, 686723. (<a
href="https://doi.org/10.3389/frobt.2021.686723">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Space exploration and exploitation depend on the development of on-orbit robotic capabilities for tasks such as servicing of satellites, removing of orbital debris, or construction and maintenance of orbital assets. Manipulation and capture of objects on-orbit are key enablers for these capabilities. This survey addresses fundamental aspects of manipulation and capture, such as the dynamics of space manipulator systems (SMS), i.e., satellites equipped with manipulators, the contact dynamics between manipulator grippers/payloads and targets, and the methods for identifying properties of SMSs and their targets. Also, it presents recent work of sensing pose and system states, of motion planning for capturing a target, and of feedback control methods for SMS during motion or interaction tasks. Finally, the paper reviews major ground testing testbeds for capture operations, and several notable missions and technologies developed for capture of targets on-orbit.},
  archive      = {J_FROBT},
  author       = {Papadopoulos, Evangelos and Aghili, Farhad and Ma, Ou and Lampariello, Roberto},
  doi          = {10.3389/frobt.2021.686723},
  journal      = {Frontiers in Robotics and AI},
  month        = {7},
  pages        = {686723},
  shortjournal = {Front. Robot. AI},
  title        = {Robotic manipulation and capture in space: A survey},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). On the efficiency of haptic based object identification:
Determining where to grasp to get the most distinguishing information.
<em>FROBT</em>, <em>8</em>, 686490. (<a
href="https://doi.org/10.3389/frobt.2021.686490">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Haptic perception is one of the key modalities in obtaining physical information of objects and in object identification. Most existing literature focused on improving the accuracy of identification algorithms with less attention paid to the efficiency. This work aims to investigate the efficiency of haptic object identification to reduce the number of grasps required to correctly identify an object out of a given object set. Thus, in a case where multiple grasps are required to characterise an object, the proposed algorithm seeks to determine where the next grasp should be on the object to obtain the most amount of distinguishing information. As such, the paper proposes the construction of the object description that preserves the association of the spatial information and the haptic information on the object. A clustering technique is employed both to construct the description of the object in a data set and for the identification process. An information gain (IG) based method is then employed to determine which pose would yield the most distinguishing information among the remaining possible candidates in the object set to improve the efficiency of the identification process. This proposed algorithm is validated experimentally. A Reflex TakkTile robotic hand with integrated joint displacement and tactile sensors is used to perform both the data collection for the dataset and the object identification procedure. The proposed IG approach was found to require a significantly lower number of grasps to identify the objects compared to a baseline approach where the decision was made by random choice of grasps.},
  archive      = {J_FROBT},
  author       = {Xia, Yu and Mohammadi, Alireza and Tan, Ying and Chen, Bernard and Choong, Peter and Oetomo, Denny},
  doi          = {10.3389/frobt.2021.686490},
  journal      = {Frontiers in Robotics and AI},
  month        = {7},
  pages        = {686490},
  shortjournal = {Front. Robot. AI},
  title        = {On the efficiency of haptic based object identification: Determining where to grasp to get the most distinguishing information},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Information distribution in multi-robot systems: Generic,
utility-aware optimization middleware. <em>FROBT</em>, <em>8</em>,
685105. (<a href="https://doi.org/10.3389/frobt.2021.685105">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work addresses the problem of what information is worth sending in a multi-robot system under generic constraints, e.g., limited throughput or energy. Our decision method is based on Monte Carlo Tree Search. It is designed as a transparent middleware that can be integrated into existing systems to optimize communication among robots. Furthermore, we introduce techniques to reduce the decision space of this problem to further improve the performance. We evaluate our approach using a simulation study and demonstrate its feasibility in a real-world environment by realizing a proof of concept in ROS 2 on mobile robots.},
  archive      = {J_FROBT},
  author       = {Barciś, Michał and Barciś, Agata and Tsiogkas, Nikolaos and Hellwagner, Hermann},
  doi          = {10.3389/frobt.2021.685105},
  journal      = {Frontiers in Robotics and AI},
  month        = {7},
  pages        = {685105},
  shortjournal = {Front. Robot. AI},
  title        = {Information distribution in multi-robot systems: Generic, utility-aware optimization middleware},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A review of SMA-based actuators for bidirectional rotational
motion: Application to origami robots. <em>FROBT</em>, <em>8</em>,
678486. (<a href="https://doi.org/10.3389/frobt.2021.678486">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Shape memory alloys (SMAs) are a group of metallic alloys capable of sustaining large inelastic strains that can be recovered when subjected to a specific process between two distinct phases. Regarding their unique and outstanding properties, SMAs have drawn considerable attention in various domains and recently became appropriate candidates for origami robots, that require bi-directional rotational motion actuation with limited operational space. However, longitudinal motion-driven actuators are frequently investigated and commonly mentioned, whereas studies in SMA-based rotational motion actuation is still very limited in the literature. This work provides a review of different research efforts related to SMA-based actuators for bi-directional rotational motion (BRM), thus provides a survey and classification of current approaches and design tools that can be applied to origami robots in order to achieve shape-changing. For this purpose, analytical tools for description of actuator behaviour are presented, followed by characterisation and performance prediction. Afterward, the actuators’ design methods, sensing, and controlling strategies are discussed. Finally, open challenges are discussed.},
  archive      = {J_FROBT},
  author       = {Hu, Kejun and Rabenorosoa, Kanty and Ouisse, Morvan},
  doi          = {10.3389/frobt.2021.678486},
  journal      = {Frontiers in Robotics and AI},
  month        = {7},
  pages        = {678486},
  shortjournal = {Front. Robot. AI},
  title        = {A review of SMA-based actuators for bidirectional rotational motion: Application to origami robots},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Optical-tactile sensor for lump detection using pneumatic
control. <em>FROBT</em>, <em>8</em>, 672315. (<a
href="https://doi.org/10.3389/frobt.2021.672315">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Soft tactile sensors are an attractive solution when robotic systems must interact with delicate objects in unstructured and obscured environments, such as most medical robotics applications. The soft nature of such a system increases both comfort and safety, while the addition of simultaneous soft active actuation provides additional features and can also improve the sensing range. This paper presents the development of a compact soft tactile sensor which is able to measure the profile of objects and, through an integrated pneumatic system, actuate and change the effective stiffness of its tactile contact surface. We report experimental results which demonstrate the sensor’s ability to detect lumps on the surface of objects or embedded within a silicone matrix. These results show the potential of this approach as a versatile method of tactile sensing with potential application in medical diagnosis.},
  archive      = {J_FROBT},
  author       = {Bewley, Jonathan and Jenkinson, George P. and Tzemanaki, Antonia},
  doi          = {10.3389/frobt.2021.672315},
  journal      = {Frontiers in Robotics and AI},
  month        = {7},
  pages        = {672315},
  shortjournal = {Front. Robot. AI},
  title        = {Optical-tactile sensor for lump detection using pneumatic control},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). You were always on my mind: Introducing chef’s hat and
COPPER for personalized reinforcement learning. <em>FROBT</em>,
<em>8</em>, 669990. (<a
href="https://doi.org/10.3389/frobt.2021.669990">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reinforcement learning simulation environments pose an important experimental test bed and facilitate data collection for developing AI-based robot applications. Most of them, however, focus on single-agent tasks, which limits their application to the development of social agents. This study proposes the Chef’s Hat simulation environment, which implements a multi-agent competitive card game that is a complete reproduction of the homonymous board game, designed to provoke competitive strategies in humans and emotional responses. The game was shown to be ideal for developing personalized reinforcement learning, in an online learning closed-loop scenario, as its state representation is extremely dynamic and directly related to each of the opponent’s actions. To adapt current reinforcement learning agents to this scenario, we also developed the COmPetitive Prioritized Experience Replay (COPPER) algorithm. With the help of COPPER and the Chef’s Hat simulation environment, we evaluated the following: (1) 12 experimental learning agents, trained via four different regimens (self-play, play against a naive baseline, PER, or COPPER) with three algorithms based on different state-of-the-art learning paradigms (PPO, DQN, and ACER), and two “dummy” baseline agents that take random actions, (2) the performance difference between COPPER and PER agents trained using the PPO algorithm and playing against different agents (PPO, DQN, and ACER) or all DQN agents, and (3) human performance when playing against two different collections of agents. Our experiments demonstrate that COPPER helps agents learn to adapt to different types of opponents, improving the performance when compared to off-line learning models. An additional contribution of the study is the formalization of the Chef’s Hat competitive game and the implementation of the Chef’s Hat Player Club, a collection of trained and assessed agents as an enabler for embedding human competitive strategies in social continual and competitive reinforcement learning.},
  archive      = {J_FROBT},
  author       = {Barros, Pablo and Bloem, Anne C. and Hootsmans, Inge M. and Opheij, Lena M. and Toebosch, Romain H. A. and Barakova, Emilia and Sciutti, Alessandra},
  doi          = {10.3389/frobt.2021.669990},
  journal      = {Frontiers in Robotics and AI},
  month        = {7},
  pages        = {669990},
  shortjournal = {Front. Robot. AI},
  title        = {You were always on my mind: Introducing chef’s hat and COPPER for personalized reinforcement learning},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Robot art, in the eye of the beholder?: Personalized
metaphors facilitate communication of emotions and creativity.
<em>FROBT</em>, <em>8</em>, 668986. (<a
href="https://doi.org/10.3389/frobt.2021.668986">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Socially assistive robots are being designed to support people’s well-being in contexts such as art therapy where human therapists are scarce, by making art together with people in an appropriate way. A challenge is that various complex and idiosyncratic concepts relating to art, like emotions and creativity, are not yet well understood. Guided by the principles of speculative design, the current article describes the use of a collaborative prototyping approach involving artists and engineers to explore this design space, especially in regard to general and personalized art-making strategies. This led to identifying a goal: to generate representational or abstract art that connects emotionally with people’s art and shows creativity. For this, an approach involving personalized “visual metaphors” was proposed, which balances the degree to which a robot’s art is influenced by interacting persons. The results of a small user study via a survey provided further insight into people’s perceptions: the general design was perceived as intended and appealed; as well, personalization via representational symbols appeared to lead to easier and clearer communication of emotions than via abstract symbols. In closing, the article describes a simplified demo, and discusses future challenges. Thus, the contribution of the current work lies in suggesting how a robot can seek to interact with people in an emotional and creative way through personalized art; thereby, the aim is to stimulate ideation in this promising area and facilitate acceptance of such robots in everyday human environments.},
  archive      = {J_FROBT},
  author       = {Cooney, Martin},
  doi          = {10.3389/frobt.2021.668986},
  journal      = {Frontiers in Robotics and AI},
  month        = {7},
  pages        = {668986},
  shortjournal = {Front. Robot. AI},
  title        = {Robot art, in the eye of the beholder?: Personalized metaphors facilitate communication of emotions and creativity},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). WoZ4U: An open-source wizard-of-oz interface for easy,
efficient and robust HRI experiments. <em>FROBT</em>, <em>8</em>,
668057. (<a href="https://doi.org/10.3389/frobt.2021.668057">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wizard-of-Oz experiments play a vital role in Human-Robot Interaction (HRI), as they allow for quick and simple hypothesis testing. Still, a publicly available general tool to conduct such experiments is currently not available in the research community, and researchers often develop and implement their own tools, customized for each individual experiment. Besides being inefficient in terms of programming efforts, this also makes it harder for non-technical researchers to conduct Wizard-of-Oz experiments. In this paper, we present a general and easy-to-use tool for the Pepper robot, one of the most commonly used robots in this context. While we provide the concrete interface for Pepper robots only, the system architecture is independent of the type of robot and can be adapted for other robots. A configuration file, which saves experiment-specific parameters, enables a quick setup for reproducible and repeatable Wizard-of-Oz experiments. A central server provides a graphical interface via a browser while handling the mapping of user input to actions on the robot. In our interface, keyboard shortcuts may be assigned to phrases, gestures, and composite behaviors to simplify and speed up control of the robot. The interface is lightweight and independent of the operating system. Our initial tests confirm that the system is functional, flexible, and easy to use. The interface, including source code, is made commonly available, and we hope that it will be useful for researchers with any background who want to conduct HRI experiments.},
  archive      = {J_FROBT},
  author       = {Rietz, Finn and Sutherland, Alexander and Bensch, Suna and Wermter, Stefan and Hellström, Thomas},
  doi          = {10.3389/frobt.2021.668057},
  journal      = {Frontiers in Robotics and AI},
  month        = {7},
  pages        = {668057},
  shortjournal = {Front. Robot. AI},
  title        = {WoZ4U: An open-source wizard-of-oz interface for easy, efficient and robust HRI experiments},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). IEEE p7001: A proposed standard on transparency.
<em>FROBT</em>, <em>8</em>, 665729. (<a
href="https://doi.org/10.3389/frobt.2021.665729">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper describes IEEE P7001, a new draft standard on transparency of autonomous systems1. In the paper, we outline the development and structure of the draft standard. We present the rationale for transparency as a measurable, testable property. We outline five stakeholder groups: users, the general public and bystanders, safety certification agencies, incident/accident investigators and lawyers/expert witnesses, and explain the thinking behind the normative definitions of “levels” of transparency for each stakeholder group in P7001. The paper illustrates the application of P7001 through worked examples of both specification and assessment of fictional autonomous systems.},
  archive      = {J_FROBT},
  author       = {Winfield, Alan F. T. and Booth, Serena and Dennis, Louise A. and Egawa, Takashi and Hastie, Helen and Jacobs, Naomi and Muttram, Roderick I. and Olszewska, Joanna I. and Rajabiyazdi, Fahimeh and Theodorou, Andreas and Underwood, Mark A. and Wortham, Robert H. and Watson, Eleanor},
  doi          = {10.3389/frobt.2021.665729},
  journal      = {Frontiers in Robotics and AI},
  month        = {7},
  pages        = {665729},
  shortjournal = {Front. Robot. AI},
  title        = {IEEE p7001: A proposed standard on transparency},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Online morphological adaptation for tactile sensing
augmentation. <em>FROBT</em>, <em>8</em>, 665030. (<a
href="https://doi.org/10.3389/frobt.2021.665030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sensor morphology and structure has the ability to significantly aid and improve tactile sensing capabilities, through mechanisms such as improved sensitivity or morphological computation. However, different tactile tasks require different morphologies posing a challenge as to how to best design sensors, and also how to enable sensor morphology to be varied. We introduce a jamming filter which, when placed over a tactile sensor, allows the filter to be shaped and molded online, thus varying the sensor structure. We demonstrate how this is beneficial for sensory tasks analyzing how the change in sensor structure varies the information that is gained using the sensor. Moreover, we show that appropriate morphology can significantly influence discrimination, and observe how the selection of an appropriate filter can increase the object classification accuracy when using standard classifiers by up to 28%.},
  archive      = {J_FROBT},
  author       = {Hughes, Josie and Scimeca, Luca and Maiolino, Perla and Iida, Fumiya},
  doi          = {10.3389/frobt.2021.665030},
  journal      = {Frontiers in Robotics and AI},
  month        = {7},
  pages        = {665030},
  shortjournal = {Front. Robot. AI},
  title        = {Online morphological adaptation for tactile sensing augmentation},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Robot-assisted image-guided interventions. <em>FROBT</em>,
<em>8</em>, 664622. (<a
href="https://doi.org/10.3389/frobt.2021.664622">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image guidance is a common methodology of minimally invasive procedures. Depending on the type of intervention, various imaging modalities are available. Common imaging modalities are computed tomography, magnetic resonance tomography, and ultrasound. Robotic systems have been developed to enable and improve the procedures using these imaging techniques. Spatial and technological constraints limit the development of versatile robotic systems. This paper offers a brief overview of the developments of robotic systems for image-guided interventions since 2015 and includes samples of our current research in this field.},
  archive      = {J_FROBT},
  author       = {Unger, Michael and Berger, Johann and Melzer, Andreas},
  doi          = {10.3389/frobt.2021.664622},
  journal      = {Frontiers in Robotics and AI},
  month        = {7},
  pages        = {664622},
  shortjournal = {Front. Robot. AI},
  title        = {Robot-assisted image-guided interventions},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The robot is present: Creative approaches for artistic
expression with robots. <em>FROBT</em>, <em>8</em>, 662249. (<a
href="https://doi.org/10.3389/frobt.2021.662249">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There is growing interest in developing creative applications for robots, specifically robots that provide entertainment, companionship, or motivation. Identifying the hallmarks of human creativity and discerning how these processes might be replicated or assisted by robots remain open questions. Transdisciplinary collaborations between artists and engineers can offer insights into how robots might foster creativity for human artists and open up new pathways for designing interactive systems. This paper presents an exploratory research project centered on drawing with robots. Using an arts-led, practice-based methodology, we developed custom hardware and software tools to support collaborative drawing with an industrial robot. A team of artists and engineers collaborated over a 6-month period to investigate the creative potential of collaborative drawing with a robot. The exploratory project focused on identifying creative and collaborative processes in the visual arts, and later on developing tools and features that would allow robots to participate meaningfully in these processes. The outcomes include a custom interface for controlling and programming robot motion (EMCAR) and custom tools for replicating experimental techniques used in visual art. We report on the artistic and technical outcomes and identify key features of process-led (as opposed to outcome-led) approaches for designing collaborative and creative systems. We also consider the value of embodied and tangible interaction for artists working collaboratively with computational systems. Transdisciplinary research can help researchers uncover new approaches for designing interfaces for interacting with machines.},
  archive      = {J_FROBT},
  author       = {Gomez Cubero, Carlos and Pekarik, Maros and Rizzo, Valeria and Jochum, Elizabeth},
  doi          = {10.3389/frobt.2021.662249},
  journal      = {Frontiers in Robotics and AI},
  month        = {7},
  pages        = {662249},
  shortjournal = {Front. Robot. AI},
  title        = {The robot is present: Creative approaches for artistic expression with robots},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Expect the unexpected: Leveraging the human-robot ecosystem
to handle unexpected robot failures. <em>FROBT</em>, <em>8</em>, 656385.
(<a href="https://doi.org/10.3389/frobt.2021.656385">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unexpected robot failures are inevitable. We propose to leverage socio-technical relations within the human-robot ecosystem to support adaptable strategies for handling unexpected failures. The Theory of Graceful Extensibility is used to understand how characteristics of the ecosystem can influence its ability to respond to unexpected events. By expanding our perspective from Human-Robot Interaction to the Human-Robot Ecosystem, adaptable failure-handling strategies are identified, alongside technical, social and organizational arrangements that are needed to support them. We argue that robotics and HRI communities should pursue more holistic approaches to failure-handling, recognizing the need to embrace the unexpected and consider socio-technical relations within the human robot ecosystem when designing failure-handling strategies.},
  archive      = {J_FROBT},
  author       = {Honig, Shanee and Oron-Gilad, Tal},
  doi          = {10.3389/frobt.2021.656385},
  journal      = {Frontiers in Robotics and AI},
  month        = {7},
  pages        = {656385},
  shortjournal = {Front. Robot. AI},
  title        = {Expect the unexpected: Leveraging the human-robot ecosystem to handle unexpected robot failures},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Hurry up, we need to find the key! How regulatory focus
design affects children’s trust in a social robot. <em>FROBT</em>,
<em>8</em>, 652035. (<a
href="https://doi.org/10.3389/frobt.2021.652035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In educational scenarios involving social robots, understanding the way robot behaviors affect children’s motivation to achieve their learning goals is of vital importance. It is crucial for the formation of a trust relationship between the child and the robot so that the robot can effectively fulfill its role as a learning companion. In this study, we investigate the effect of a regulatory focus design scenario on the way children interact with a social robot. Regulatory focus theory is a type of self-regulation that involves specific strategies in pursuit of goals. It provides insights into how a person achieves a particular goal, either through a strategy focused on “promotion” that aims to achieve positive outcomes or through one focused on “prevention” that aims to avoid negative outcomes. In a user study, 69 children (7–9 years old) played a regulatory focus design goal-oriented collaborative game with the EMYS robot. We assessed children’s perception of likability and competence and their trust in the robot, as well as their willingness to follow the robot’s suggestions when pursuing a goal. Results showed that children perceived the prevention-focused robot as being more likable than the promotion-focused robot. We observed that a regulatory focus design did not directly affect trust. However, the perception of likability and competence was positively correlated with children’s trust but negatively correlated with children’s acceptance of the robot’s suggestions.},
  archive      = {J_FROBT},
  author       = {Calvo-Barajas, Natalia and Elgarf, Maha and Perugia, Giulia and Paiva, Ana and Peters, Christopher and Castellano, Ginevra},
  doi          = {10.3389/frobt.2021.652035},
  journal      = {Frontiers in Robotics and AI},
  month        = {7},
  pages        = {652035},
  shortjournal = {Front. Robot. AI},
  title        = {Hurry up, we need to find the key! how regulatory focus design affects children’s trust in a social robot},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Exploring non-expert robot programming through
crowdsourcing. <em>FROBT</em>, <em>8</em>, 646002. (<a
href="https://doi.org/10.3389/frobt.2021.646002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A longstanding barrier to deploying robots in the real world is the ongoing need to author robot behavior. Remote data collection–particularly crowdsourcing—is increasingly receiving interest. In this paper, we make the argument to scale robot programming to the crowd and present an initial investigation of the feasibility of this proposed method. Using an off-the-shelf visual programming interface, non-experts created simple robot programs for two typical robot tasks (navigation and pick-and-place). Each needed four subtasks with an increasing number of programming statements (if statement, while loop, variables) for successful completion of the programs. Initial findings of an online study (N = 279) indicate that non-experts, after minimal instruction, were able to create simple programs using an off-the-shelf visual programming interface. We discuss our findings and identify future avenues for this line of research.},
  archive      = {J_FROBT},
  author       = {van Waveren, Sanne and Carter, Elizabeth J. and Örnberg, Oscar and Leite, Iolanda},
  doi          = {10.3389/frobt.2021.646002},
  journal      = {Frontiers in Robotics and AI},
  month        = {7},
  pages        = {646002},
  shortjournal = {Front. Robot. AI},
  title        = {Exploring non-expert robot programming through crowdsourcing},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Inferring trust from users’ behaviours; agents’
predictability positively affects trust, task performance and cognitive
load in human-agent real-time collaboration. <em>FROBT</em>, <em>8</em>,
642201. (<a href="https://doi.org/10.3389/frobt.2021.642201">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Collaborative virtual agents help human operators to perform tasks in real-time. For this collaboration to be effective, human operators must appropriately trust the agent(s) they are interacting with. Multiple factors influence trust, such as the context of interaction, prior experiences with automated systems and the quality of the help offered by agents in terms of its transparency and performance. Most of the literature on trust in automation identified the performance of the agent as a key factor influencing trust. However, other work has shown that the behavior of the agent, type of the agent’s errors, and predictability of the agent’s actions can influence the likelihood of the user’s reliance on the agent and efficiency of tasks completion. Our work focuses on how agents’ predictability affects cognitive load, performance and users’ trust in a real-time human-agent collaborative task. We used an interactive aiming task where participants had to collaborate with different agents that varied in terms of their predictability and performance. This setup uses behavioral information (such as task performance and reliance on the agent) as well as standardized survey instruments to estimate participants’ reported trust in the agent, cognitive load and perception of task difficulty. Thirty participants took part in our lab-based study. Our results showed that agents with more predictable behaviors have a more positive impact on task performance, reliance and trust while reducing cognitive workload. In addition, we investigated the human-agent trust relationship by creating models that could predict participants’ trust ratings using interaction data. We found that we could reliably estimate participants’ reported trust in the agents using information related to performance, task difficulty and reliance. This study provides insights on behavioral factors that are the most meaningful to anticipate complacent or distrusting attitudes toward automation. With this work, we seek to pave the way for the development of trust-aware agents capable of responding more appropriately to users by being able to monitor components of the human-agent relationships that are the most salient for trust calibration.},
  archive      = {J_FROBT},
  author       = {Daronnat, Sylvain and Azzopardi, Leif and Halvey, Martin and Dubiel, Mateusz},
  doi          = {10.3389/frobt.2021.642201},
  journal      = {Frontiers in Robotics and AI},
  month        = {7},
  pages        = {642201},
  shortjournal = {Front. Robot. AI},
  title        = {Inferring trust from users’ behaviours; agents’ predictability positively affects trust, task performance and cognitive load in human-agent real-time collaboration},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Beyond soft hands: Efficient grasping with
non-anthropomorphic soft grippers. <em>FROBT</em>, <em>8</em>, 632006.
(<a href="https://doi.org/10.3389/frobt.2021.632006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Grasping and manipulation are challenging tasks that are nonetheless critical for many robotic systems and applications. A century ago, robots were conceived as humanoid automata. While conceptual at the time, this viewpoint remains influential today. Many robotic grippers have been inspired by the dexterity and functionality of the prehensile human hand. However, multi-fingered grippers that emulate the hand often integrate many kinematic degrees-of-freedom, and thus complex mechanisms, which must be controlled in order to grasp and manipulate objects. Soft fingers can facilitate grasping through intrinsic compliance, enabling them to conform to diverse objects. However, as with conventional fingered grippers, grasping via soft fingers involves challenges in perception, computation, and control, because fingers must be placed so as to achieve force closure, which depends on the shape and pose of the object. Emerging soft robotics research on non-anthropomorphic grippers has yielded new techniques that can circumvent fundamental challenges associated with grasping via fingered grippers. Common to many non-anthropomorphic soft grippers are mechanisms for morphological deformation or adhesion that simplify the grasping of diverse objects in different poses, without detailed knowledge of the object geometry. These advantages may allow robots to be used in challenging applications, such as logistics or rapid manufacturing, with lower cost and complexity. In this perspective, we examine challenges associated with grasping via anthropomorphic grippers. We describe emerging soft, non-anthropomorphic grasping methods, and how they may reduce grasping complexities. We conclude by proposing several research directions that could expand the capabilities of robotic systems utilizing non-anthropomorphic grippers.},
  archive      = {J_FROBT},
  author       = {Hao, Yufei and Visell, Yon},
  doi          = {10.3389/frobt.2021.632006},
  journal      = {Frontiers in Robotics and AI},
  month        = {7},
  pages        = {632006},
  shortjournal = {Front. Robot. AI},
  title        = {Beyond soft hands: Efficient grasping with non-anthropomorphic soft grippers},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Bounded cost path planning for underwater vehicles assisted
by a time-invariant partitioned flow field model. <em>FROBT</em>,
<em>8</em>, 575267. (<a
href="https://doi.org/10.3389/frobt.2021.575267">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A bounded cost path planning method is developed for underwater vehicles assisted by a data-driven flow modeling method. The modeled flow field is partitioned as a set of cells of piece-wise constant flow speed. A flow partition algorithm and a parameter estimation algorithm are proposed to learn the flow field structure and parameters with justified convergence. A bounded cost path planning algorithm is developed taking advantage of the partitioned flow model. An extended potential search method is proposed to determine the sequence of partitions that the optimal path crosses. The optimal path within each partition is then determined by solving a constrained optimization problem. Theoretical justification is provided for the proposed extended potential search method generating the optimal solution. The path planned has the highest probability to satisfy the bounded cost constraint. The performance of the algorithms is demonstrated with experimental and simulation results, which show that the proposed method is more computationally efficient than some of the existing methods.},
  archive      = {J_FROBT},
  author       = {Hou, Mengxue and Cho, Sungjin and Zhou, Haomin and Edwards, Catherine R. and Zhang, Fumin},
  doi          = {10.3389/frobt.2021.575267},
  journal      = {Frontiers in Robotics and AI},
  month        = {7},
  pages        = {575267},
  shortjournal = {Front. Robot. AI},
  title        = {Bounded cost path planning for underwater vehicles assisted by a time-invariant partitioned flow field model},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Towards an engagement-aware attentive artificial listener
for multi-party interactions. <em>FROBT</em>, <em>8</em>, 555913. (<a
href="https://doi.org/10.3389/frobt.2021.555913">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Listening to one another is essential to human-human interaction. In fact, we humans spend a substantial part of our day listening to other people, in private as well as in work settings. Attentive listening serves the function to gather information for oneself, but at the same time, it also signals to the speaker that he/she is being heard. To deduce whether our interlocutor is listening to us, we are relying on reading his/her nonverbal cues, very much like how we also use non-verbal cues to signal our attention. Such signaling becomes more complex when we move from dyadic to multi-party interactions. Understanding how humans use nonverbal cues in a multi-party listening context not only increases our understanding of human-human communication but also aids the development of successful human-robot interactions. This paper aims to bring together previous analyses of listener behavior analyses in human-human multi-party interaction and provide novel insights into gaze patterns between the listeners in particular. We are investigating whether the gaze patterns and feedback behavior, as observed in the human-human dialogue, are also beneficial for the perception of a robot in multi-party human-robot interaction. To answer this question, we are implementing an attentive listening system that generates multi-modal listening behavior based on our human-human analysis. We are comparing our system to a baseline system that does not differentiate between different listener types in its behavior generation. We are evaluating it in terms of the participant’s perception of the robot, his behavior as well as the perception of third-party observers.},
  archive      = {J_FROBT},
  author       = {Oertel, Catharine and Jonell, Patrik and Kontogiorgos, Dimosthenis and Mora, Kenneth Funes and Odobez, Jean-Marc and Gustafson, Joakim},
  doi          = {10.3389/frobt.2021.555913},
  journal      = {Frontiers in Robotics and AI},
  month        = {7},
  pages        = {555913},
  shortjournal = {Front. Robot. AI},
  title        = {Towards an engagement-aware attentive artificial listener for multi-party interactions},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Editorial: Generation growbots: Materials, mechanisms, and
biomimetic design for growing robots. <em>FROBT</em>, <em>8</em>,
711942. (<a href="https://doi.org/10.3389/frobt.2021.711942">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Mazzolai, Barbara and Walker, Ian and Speck, Thomas},
  doi          = {10.3389/frobt.2021.711942},
  journal      = {Frontiers in Robotics and AI},
  month        = {6},
  pages        = {711942},
  shortjournal = {Front. Robot. AI},
  title        = {Editorial: generation growbots: materials, mechanisms, and biomimetic design for growing robots},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Corrigendum: [A comparative study of adaptive interlimb
coordination mechanisms for self-organized robot locomotion].
<em>FROBT</em>, <em>8</em>, 702167. (<a
href="https://doi.org/10.3389/frobt.2021.702167">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Sun, Tao and Xiong, Xiaofeng and Dai, Zhendong and Owaki, Dai and Manoonpong, Poramate},
  doi          = {10.3389/frobt.2021.702167},
  journal      = {Frontiers in Robotics and AI},
  month        = {6},
  pages        = {702167},
  shortjournal = {Front. Robot. AI},
  title        = {Corrigendum: [A comparative study of adaptive interlimb coordination mechanisms for self-organized robot locomotion]},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A pediatric knee exoskeleton with real-time adaptive control
for overground walking in ambulatory individuals with cerebral palsy.
<em>FROBT</em>, <em>8</em>, 702137. (<a
href="https://doi.org/10.3389/frobt.2021.702137">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gait training via a wearable device in children with cerebral palsy (CP) offers the potential to increase therapy dosage and intensity compared to current approaches. Here, we report the design and characterization of a pediatric knee exoskeleton (P.REX) with a microcontroller based multi-layered closed loop control system to provide individualized control capability. Exoskeleton performance was evaluated through benchtop and human subject testing. Step response tests show the averaged 90% rise was 26 ± 0.2 ms for 5 Nm, 22 ± 0.2 ms for 10 Nm, 32 ± 0.4 ms for 15 Nm. Torque bandwidth of P.REX was 12 Hz and output impedance was less than 1.8 Nm with control on (Zero mode). Three different control strategies can be deployed to apply assistance to knee extension: state-based assistance, impedance-based trajectory tracking, and real-time adaptive control. One participant with typical development (TD) and one participant with crouch gait from CP were recruited to evaluate P.REX in overground walking tests. Data from the participant with TD were used to validate control system performance. Kinematic and kinetic data were collected by motion capture and compared to exoskeleton on-board sensors to evaluate control system performance with results demonstrating that the control system functioned as intended. The data from the participant with CP are part of a larger ongoing study. Results for this participant compare walking with P.REX in two control modes: a state-based approach that provided constant knee extension assistance during early stance, mid-stance and late swing (Est+Mst+Lsw mode) and an Adaptive mode providing knee extension assistance proportional to estimated knee moment during stance. Both were well tolerated and significantly improved knee extension compared to walking without extension assistance (Zero mode). There was less reduction in gait speed during use of the adaptive controller, suggesting that it may be more intuitive than state-based constant assistance for this individual. Future work will investigate the effects of exoskeleton assistance during overground gait training in children with neurological disorders and will aim to identify the optimal individualized control strategy for exoskeleton prescription.},
  archive      = {J_FROBT},
  author       = {Chen, Ji and Hochstein, Jon and Kim, Christina and Tucker, Luke and Hammel, Lauren E. and Damiano, Diane L. and Bulea, Thomas C.},
  doi          = {10.3389/frobt.2021.702137},
  journal      = {Frontiers in Robotics and AI},
  month        = {6},
  pages        = {702137},
  shortjournal = {Front. Robot. AI},
  title        = {A pediatric knee exoskeleton with real-time adaptive control for overground walking in ambulatory individuals with cerebral palsy},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Fully polymeric domes as high-stroke biasing system for soft
dielectric elastomer actuators. <em>FROBT</em>, <em>8</em>, 695918. (<a
href="https://doi.org/10.3389/frobt.2021.695918">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The availability of compliant actuators is essential for the development of soft robotic systems. Dielectric elastomers (DEs) represent a class of smart actuators which has gained a significant popularity in soft robotics, due to their unique mix of large deformation (&amp;gt;100%), lightweight, fast response, and low cost. A DE consists of a thin elastomer membrane coated with flexible electrodes on both sides. When a high voltage is applied to the electrodes, the membrane undergoes a controllable mechanical deformation. In order to produce a significant actuation stroke, a DE membrane must be coupled with a mechanical biasing system. Commonly used spring-like bias elements, however, are generally made of rigid materials such as steel, and thus they do not meet the compliance requirements of soft robotic applications. To overcome this issue, in this paper we propose a novel type of compliant mechanism as biasing elements for DE actuators, namely a three-dimensional polymeric dome. When properly designed, such types of mechanisms exhibit a region of negative stiffness in their force-displacement behavior. This feature, in combination with the intrinsic softness of the polymeric material, ensures large actuation strokes as well as compliance compatibility with soft robots. After presenting the novel biasing concept, the overall soft actuator design, manufacturing, and assembly are discussed. Finally, experimental characterization is conducted, and the suitability for soft robotic applications is assessed.},
  archive      = {J_FROBT},
  author       = {Neu, Julian and Hubertus, Jonas and Croce, Sipontina and Schultes, Günter and Seelecke, Stefan and Rizzello, Gianluca},
  doi          = {10.3389/frobt.2021.695918},
  journal      = {Frontiers in Robotics and AI},
  month        = {6},
  pages        = {695918},
  shortjournal = {Front. Robot. AI},
  title        = {Fully polymeric domes as high-stroke biasing system for soft dielectric elastomer actuators},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Navigated, robot-driven laser craniotomy for SEEG
application using optical coherence tomography in an animal model.
<em>FROBT</em>, <em>8</em>, 695363. (<a
href="https://doi.org/10.3389/frobt.2021.695363">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Objectives: We recently introduced a navigated, robot-driven laser beam craniotomy for use with stereoelectroencephalography (SEEG) applications. This method was intended to substitute the hand-held electric power drill in an ex vivo study. The purpose of this in vivo non-recovery pilot study was to acquire data for the depth control unit of this laser device, to test the feasibility of cutting bone channels, and to assess dura perforation and possible cortex damage related to cold ablation.Methods: Multiple holes suitable for SEEG bone channels were planned for the superior portion of two pig craniums using surgical planning software and a frameless, navigated technique. The trajectories were planned to avoid cortical blood vessels using magnetic resonance angiography. Each trajectory was converted into a series of circular paths to cut bone channels. The cutting strategy for each hole involved two modes: a remaining bone thickness mode and a cut through mode (CTR). The remaining bone thickness mode is an automatic coarse approach where the cutting depth is measured in real time using optical coherence tomography (OCT). In this mode, a pre-set measurement, in mm, of the remaining bone is left over by automatically comparing the bone thickness from computed tomography with the OCT depth. In the CTR mode, the cut through at lower cutting energies is managed by observing the cutting site with real-time video.Results: Both anesthesia protocols did not show any irregularities. In total, 19 bone channels were cut in both specimens. All channels were executed according to the planned cutting strategy using the frameless navigation of the robot-driven laser device. The dura showed minor damage after one laser beam and severe damage after two and three laser beams. The cortex was not damaged. As soon as the cut through was obtained, we observed that moderate cerebrospinal fluid leakage impeded the cutting efficiency and interfered with the visualization for depth control. The coaxial camera showed a live video feed in which cut through of the bone could be identified in 84%.Conclusion: Inflowing cerebrospinal fluid disturbed OCT signals, and, therefore, the current CTR method could not be reliably applied. Video imaging is a candidate for observing a successful cut through. OCT and video imaging may be used for depth control to implement an updated SEEG bone channel cutting strategy in the future.},
  archive      = {J_FROBT},
  author       = {Winter, Fabian and Wilken, Tobias and Bammerlin, Martin and Shawarba, Julia and Dorfer, Christian and Roessler, Karl},
  doi          = {10.3389/frobt.2021.695363},
  journal      = {Frontiers in Robotics and AI},
  month        = {6},
  pages        = {695363},
  shortjournal = {Front. Robot. AI},
  title        = {Navigated, robot-driven laser craniotomy for SEEG application using optical coherence tomography in an animal model},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Machine teaching for human inverse reinforcement learning.
<em>FROBT</em>, <em>8</em>, 693050. (<a
href="https://doi.org/10.3389/frobt.2021.693050">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As robots continue to acquire useful skills, their ability to teach their expertise will provide humans the two-fold benefit of learning from robots and collaborating fluently with them. For example, robot tutors could teach handwriting to individual students and delivery robots could convey their navigation conventions to better coordinate with nearby human workers. Because humans naturally communicate their behaviors through selective demonstrations, and comprehend others’ through reasoning that resembles inverse reinforcement learning (IRL), we propose a method of teaching humans based on demonstrations that are informative for IRL. But unlike prior work that optimizes solely for IRL, this paper incorporates various human teaching strategies (e.g. scaffolding, simplicity, pattern discovery, and testing) to better accommodate human learners. We assess our method with user studies and find that our measure of test difficulty corresponds well with human performance and confidence, and also find that favoring simplicity and pattern discovery increases human performance on difficult tests. However, we did not find a strong effect for our method of scaffolding, revealing shortcomings that indicate clear directions for future work.},
  archive      = {J_FROBT},
  author       = {Lee, Michael S. and Admoni, Henny and Simmons, Reid},
  doi          = {10.3389/frobt.2021.693050},
  journal      = {Frontiers in Robotics and AI},
  month        = {6},
  pages        = {693050},
  shortjournal = {Front. Robot. AI},
  title        = {Machine teaching for human inverse reinforcement learning},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). A bayesian deep neural network for safe visual servoing in
human–robot interaction. <em>FROBT</em>, <em>8</em>, 687031. (<a
href="https://doi.org/10.3389/frobt.2021.687031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Safety is an important issue in human–robot interaction (HRI) applications. Various research works have focused on different levels of safety in HRI. If a human/obstacle is detected, a repulsive action can be taken to avoid the collision. Common repulsive actions include distance methods, potential field methods, and safety field methods. Approaches based on machine learning are less explored regarding the selection of the repulsive action. Few research works focus on the uncertainty of the data-based approaches and consider the efficiency of the executing task during collision avoidance. In this study, we describe a system that can avoid collision with human hands while the robot is executing an image-based visual servoing (IBVS) task. We use Monte Carlo dropout (MC dropout) to transform a deep neural network (DNN) to a Bayesian DNN, and learn the repulsive position for hand avoidance. The Bayesian DNN allows IBVS to converge faster than the opposite repulsive pose. Furthermore, it allows the robot to avoid undesired poses that the DNN cannot avoid. The experimental results show that Bayesian DNN has adequate accuracy and can generalize well on unseen data. The predictive interval coverage probability (PICP) of the predictions along x, y, and z directions are 0.84, 0.94, and 0.95, respectively. In the space which is unseen in the training data, the Bayesian DNN is also more robust than a DNN. We further implement the system on a UR10 robot, and test the robustness of the Bayesian DNN and the IBVS convergence speed. Results show that the Bayesian DNN can avoid the poses out of the reach range of the robot and it lets the IBVS task converge faster than the opposite repulsive pose.1},
  archive      = {J_FROBT},
  author       = {Shi, Lei and Copot, Cosmin and Vanlanduit, Steve},
  doi          = {10.3389/frobt.2021.687031},
  journal      = {Frontiers in Robotics and AI},
  month        = {6},
  pages        = {687031},
  shortjournal = {Front. Robot. AI},
  title        = {A bayesian deep neural network for safe visual servoing in Human–Robot interaction},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-level evolution for robotic design. <em>FROBT</em>,
<em>8</em>, 684304. (<a
href="https://doi.org/10.3389/frobt.2021.684304">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-level evolution (MLE) is a novel robotic design paradigm which decomposes the design problem into layered sub-tasks that involve concurrent search for appropriate materials, component geometry and overall morphology. This has a number of advantages, mainly in terms of quality and scalability. In this paper, we present a hierarchical approach to robotic design based on the MLE architecture. The design problem involves finding a robotic design which can be used to perform a specific locomotion task. At the materials layer, we put together a simple collection of materials which are represented by combinations of mechanical properties such as friction and restitution. At the components layer we combine these materials with geometric design to form robot limbs. Finally, at the robot layer we introduce these evolved limbs into robotic body-plans and learn control policies to form complete robots. Quality-diversity algorithms at each level allow for the discovery of a wide variety of reusable elements. The results strongly support the initial claims for the benefits of MLE, allowing for the discovery of designs that would otherwise be difficult to achieve with conventional design paradigms.},
  archive      = {J_FROBT},
  author       = {Chand, Shelvin and Howard, David},
  doi          = {10.3389/frobt.2021.684304},
  journal      = {Frontiers in Robotics and AI},
  month        = {6},
  pages        = {684304},
  shortjournal = {Front. Robot. AI},
  title        = {Multi-level evolution for robotic design},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Lifelong personalization via gaussian process modeling for
long-term HRI. <em>FROBT</em>, <em>8</em>, 683066. (<a
href="https://doi.org/10.3389/frobt.2021.683066">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Across a wide variety of domains, artificial agents that can adapt and personalize to users have potential to improve and transform how social services are provided. Because of the need for personalized interaction data to drive this process, long-term (or longitudinal) interactions between users and agents, which unfold over a series of distinct interaction sessions, have attracted substantial research interest. In recognition of the expanded scope and structure of a long-term interaction, researchers are also adjusting the personalization models and algorithms used, orienting toward “continual learning” methods, which do not assume a stationary modeling target and explicitly account for the temporal context of training data. In parallel, researchers have also studied the effect of “multitask personalization,” an approach in which an agent interacts with users over multiple different tasks contexts throughout the course of a long-term interaction and learns personalized models of a user that are transferrable across these tasks. In this paper, we unite these two paradigms under the framework of “Lifelong Personalization,” analyzing the effect of multitask personalization applied to dynamic, non-stationary targets. We extend the multi-task personalization approach to the more complex and realistic scenario of modeling dynamic learners over time, focusing in particular on interactive scenarios in which the modeling agent plays an active role in teaching the student whose knowledge the agent is simultaneously attempting to model. Inspired by the way in which agents use active learning to select new training data based on domain context, we augment a Gaussian Process-based multitask personalization model with a mechanism to actively and continually manage its own training data, allowing a modeling agent to remove or reduce the weight of observed data from its training set, based on interactive context cues. We evaluate this method in a series of simulation experiments comparing different approaches to continual and multitask learning on simulated student data. We expect this method to substantially improve learning in Gaussian Process models in dynamic domains, establishing Gaussian Processes as another flexible modeling tool for Long-term Human-Robot Interaction (HRI) Studies.},
  archive      = {J_FROBT},
  author       = {Spaulding, Samuel and Shen, Jocelyn and Park, Hae Won and Breazeal, Cynthia},
  doi          = {10.3389/frobt.2021.683066},
  journal      = {Frontiers in Robotics and AI},
  month        = {6},
  pages        = {683066},
  shortjournal = {Front. Robot. AI},
  title        = {Lifelong personalization via gaussian process modeling for long-term HRI},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). When even a robot tutor zooms: A study of embodiment,
attitudes, and impressions. <em>FROBT</em>, <em>8</em>, 679893. (<a
href="https://doi.org/10.3389/frobt.2021.679893">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study used an online second language (L2) vocabulary lesson to evaluate whether the physical body (i.e., embodiment) of a robot tutor has an impact on how the learner learns from the robot. In addition, we tested how individual differences in attitudes toward robots, first impressions of the robot, anxiety in learning L2, and personality traits may be related to L2 vocabulary learning. One hundred Turkish-speaking young adults were taught eight English words in a one-on-one Zoom session either with a NAO robot tutor (N = 50) or with a voice-only tutor (N = 50). The findings showed that participants learned the vocabulary equally well from the robot and voice tutors, indicating that the physical embodiment of the robot did not change learning gains in a short vocabulary lesson. Further, negative attitudes toward robots had negative effects on learning for participants in the robot tutor condition, but first impressions did not predict vocabulary learning in either of the two conditions. L2 anxiety, on the other hand, negatively predicted learning outcomes in both conditions. We also report that attitudes toward robots and the impressions of the robot tutor remained unchanged before and after the lesson. As one of the first to examine the effectiveness of robots as an online lecturer, this study presents an example of comparable learning outcomes regardless of physical embodiment.},
  archive      = {J_FROBT},
  author       = {Kanero, Junko and Tunalı, Elif Tutku and Oranç, Cansu and Göksun, Tilbe and Küntay, Aylin C.},
  doi          = {10.3389/frobt.2021.679893},
  journal      = {Frontiers in Robotics and AI},
  month        = {6},
  pages        = {679893},
  shortjournal = {Front. Robot. AI},
  title        = {When even a robot tutor zooms: A study of embodiment, attitudes, and impressions},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Electrically tunable lenses: A review. <em>FROBT</em>,
<em>8</em>, 678046. (<a
href="https://doi.org/10.3389/frobt.2021.678046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optical lenses with electrically controllable focal length are of growing interest, in order to reduce the complexity, size, weight, response time and power consumption of conventional focusing/zooming systems, based on glass lenses displaced by motors. They might become especially relevant for diverse robotic and machine vision-based devices, including cameras not only for portable consumer electronics (e.g. smart phones) and advanced optical instrumentation (e.g. microscopes, endoscopes, etc.), but also for emerging applications like small/micro-payload drones and wearable virtual/augmented-reality systems. This paper reviews the most widely studied strategies to obtain such varifocal “smart lenses”, which can electrically be tuned, either directly or via electro-mechanical or electro-thermal coupling. Only technologies that ensure controllable focusing of multi-chromatic light, with spatial continuity (i.e. continuous tunability) in wavefronts and focal lengths, as required for visible-range imaging, are considered. Both encapsulated fluid-based lenses and fully elastomeric lenses are reviewed, ranging from proof-of-concept prototypes to commercially available products. They are classified according to the focus-changing principles of operation, and they are described and compared in terms of advantages and drawbacks. This systematic overview should help to stimulate further developments in the field.},
  archive      = {J_FROBT},
  author       = {Chen, Leihao and Ghilardi, Michele and Busfield, James J. C. and Carpi, Federico},
  doi          = {10.3389/frobt.2021.678046},
  journal      = {Frontiers in Robotics and AI},
  month        = {6},
  pages        = {678046},
  shortjournal = {Front. Robot. AI},
  title        = {Electrically tunable lenses: A review},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Embodied computational evolution: Feedback between
development and evolution in simulated biorobots. <em>FROBT</em>,
<em>8</em>, 674823. (<a
href="https://doi.org/10.3389/frobt.2021.674823">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given that selection removes genetic variance from evolving populations, thereby reducing exploration opportunities, it is important to find mechanisms that create genetic variation without the disruption of adapted genes and genomes caused by random mutation. Just such an alternative is offered by random epigenetic error, a developmental process that acts on materials and parts expressed by the genome. In this system of embodied computational evolution, simulated within a physics engine, epigenetic error was instantiated in an explicit genotype-to-phenotype map as transcription error at the initiation of gene expression. The hypothesis was that transcription error would create genetic variance by shielding genes from the direct impact of selection, creating, in the process, masquerading genomes. To test this hypothesis, populations of simulated embodied biorobots and their developmental systems were evolved under steady directional selection as equivalent rates of random mutation and random transcriptional error were covaried systematically in an 11 × 11 fully factorial experimental design. In each of the 121 different experimental conditions (unique combinations of mutation and transcription error), the same set of 10 randomly created replicate populations of 60 individuals were evolved. Selection for the improved locomotor behavior of individuals led to increased mean fitness of populations over 100 generations at nearly all levels and combinations of mutation and transcription error. When the effects of both types of error were partitioned statistically, increasing transcription error was shown to increase the final genetic variance of populations, incurring a fitness cost but acting on variance independently and differently from genetic mutation. Thus, random epigenetic errors in development feed back through selection of individuals with masquerading genomes to the population’s genetic variance over generational time. Random developmental processes offer an additional mechanism for exploration by increasing genetic variation in the face of steady, directional selection.},
  archive      = {J_FROBT},
  author       = {Hawthorne-Madell, Joshua and Aaron, Eric and Livingston, Ken and Long, John H.},
  doi          = {10.3389/frobt.2021.674823},
  journal      = {Frontiers in Robotics and AI},
  month        = {6},
  pages        = {674823},
  shortjournal = {Front. Robot. AI},
  title        = {Embodied computational evolution: Feedback between development and evolution in simulated biorobots},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Criticality-driven evolution of adaptable morphologies of
voxel-based soft-robots. <em>FROBT</em>, <em>8</em>, 673156. (<a
href="https://doi.org/10.3389/frobt.2021.673156">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paradigm of voxel-based soft robots has allowed to shift the complexity from the control algorithm to the robot morphology itself. The bodies of voxel-based soft robots are extremely versatile and more adaptable than the one of traditional robots, since they consist of many simple components that can be freely assembled. Nonetheless, it is still not clear which are the factors responsible for the adaptability of the morphology, which we define as the ability to cope with tasks requiring different skills. In this work, we propose a task-agnostic approach for automatically designing adaptable soft robotic morphologies in simulation, based on the concept of criticality. Criticality is a property belonging to dynamical systems close to a phase transition between the ordered and the chaotic regime. Our hypotheses are that 1) morphologies can be optimized for exhibiting critical dynamics and 2) robots with those morphologies are not worse, on a set of different tasks, than robots with handcrafted morphologies. We introduce a measure of criticality in the context of voxel-based soft robots which is based on the concept of avalanche analysis, often used to assess criticality in biological and artificial neural networks. We let the robot morphologies evolve toward criticality by measuring how close is their avalanche distribution to a power law distribution. We then validate the impact of this approach on the actual adaptability by measuring the resulting robots performance on three different tasks designed to require different skills. The validation results confirm that criticality is indeed a good indicator for the adaptability of a soft robotic morphology, and therefore a promising approach for guiding the design of more adaptive voxel-based soft robots.},
  archive      = {J_FROBT},
  author       = {Talamini, Jacopo and Medvet, Eric and Nichele, Stefano},
  doi          = {10.3389/frobt.2021.673156},
  journal      = {Frontiers in Robotics and AI},
  month        = {6},
  pages        = {673156},
  shortjournal = {Front. Robot. AI},
  title        = {Criticality-driven evolution of adaptable morphologies of voxel-based soft-robots},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Constrained by design: Influence of genetic encodings on
evolved traits of robots. <em>FROBT</em>, <em>8</em>, 672379. (<a
href="https://doi.org/10.3389/frobt.2021.672379">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Genetic encodings and their particular properties are known to have a strong influence on the success of evolutionary systems. However, the literature has widely focused on studying the effects that encodings have on performance, i.e., fitness-oriented studies. Notably, this anchoring of the literature to performance is limiting, considering that performance provides bounded information about the behavior of a robot system. In this paper, we investigate how genetic encodings constrain the space of robot phenotypes and robot behavior. In summary, we demonstrate how two generative encodings of different nature lead to very different robots and discuss these differences. Our principal contributions are creating awareness about robot encoding biases, demonstrating how such biases affect evolved morphological, control, and behavioral traits, and finally scrutinizing the trade-offs among different biases.},
  archive      = {J_FROBT},
  author       = {Miras, Karine},
  doi          = {10.3389/frobt.2021.672379},
  journal      = {Frontiers in Robotics and AI},
  month        = {6},
  pages        = {672379},
  shortjournal = {Front. Robot. AI},
  title        = {Constrained by design: Influence of genetic encodings on evolved traits of robots},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A long-term engagement with a social robot for autism
therapy. <em>FROBT</em>, <em>8</em>, 669972. (<a
href="https://doi.org/10.3389/frobt.2021.669972">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Social robots are increasingly being used as a mediator between a therapist and a child in autism therapy studies. In this context, most behavioural interventions are typically short-term in nature. This paper describes a long-term study that was conducted with 11 children diagnosed with either Autism Spectrum Disorder (ASD) or ASD in co-occurrence with Attention Deficit Hyperactivity Disorder (ADHD). It uses a quantitative analysis based on behavioural measures, including engagement, valence, and eye gaze duration. Each child interacted with a robot on several occasions in which each therapy session was customized to a child’s reaction to robot behaviours. This paper presents a set of robot behaviours that were implemented with the goal to offer a variety of activities to be suitable for diverse forms of autism. Therefore, each child experienced an individualized robot-assisted therapy that was tailored according to the therapist’s knowledge and judgement. The statistical analyses showed that the proposed therapy managed to sustain children’s engagement. In addition, sessions containing familiar activities kept children more engaged compared to those sessions containing unfamiliar activities. The results of the interviews with parents and therapists are discussed in terms of therapy recommendations. The paper concludes with some reflections on the current study as well as suggestions for future studies.},
  archive      = {J_FROBT},
  author       = {Rakhymbayeva, Nazerke and Amirova, Aida and Sandygulova, Anara},
  doi          = {10.3389/frobt.2021.669972},
  journal      = {Frontiers in Robotics and AI},
  month        = {6},
  pages        = {669972},
  shortjournal = {Front. Robot. AI},
  title        = {A long-term engagement with a social robot for autism therapy},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Safety assessment review of a dressing assistance robot.
<em>FROBT</em>, <em>8</em>, 667316. (<a
href="https://doi.org/10.3389/frobt.2021.667316">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hazard analysis methods such as HAZOP and STPA have proven to be effective methods for assurance of system safety for years. However, the dimensionality and human factors uncertainty of many assistive robotic applications challenges the capability of these methods to provide comprehensive coverage of safety issues from interdisciplinary perspectives in a timely and cost-effective manner. Physically assistive tasks in which a range of dynamic contexts require continuous human–robot physical interaction such as e.g., robot-assisted dressing or sit-to-stand pose a new paradigm for safe design and safety analysis methodology. For these types of tasks, considerations have to be made for a range of dynamic contexts where the robot-assistance requires close and continuous physical contact with users. Current regulations mainly cover industrial collaborative robotics regarding physical human–robot interaction (pHRI) but largely neglects direct and continuous physical human contact. In this paper, we explore limitations of commonly used safety analysis techniques when applied to robot-assisted dressing scenarios. We provide a detailed analysis of the system requirements from the user perspective and consider user-bounded hazards that can compromise safety of this complex pHRI.},
  archive      = {J_FROBT},
  author       = {Delgado Bellamy, Daniel and Chance, Gregory and Caleb-Solly, Praminda and Dogramadzi, Sanja},
  doi          = {10.3389/frobt.2021.667316},
  journal      = {Frontiers in Robotics and AI},
  month        = {6},
  pages        = {667316},
  shortjournal = {Front. Robot. AI},
  title        = {Safety assessment review of a dressing assistance robot},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An integrated kinematic modeling and experimental approach
for an active endoscope. <em>FROBT</em>, <em>8</em>, 667205. (<a
href="https://doi.org/10.3389/frobt.2021.667205">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Continuum robots are a type of robotic device that are characterized by their flexibility and dexterity, thus making them ideal for an active endoscope. Instead of articulated joints they have flexible backbones that can be manipulated remotely, usually through tendons secured onto structures attached to the backbone. This structure makes them lightweight and ideal to be miniaturized for endoscopic applications. However, their flexibility poses technical challenges in the modeling and control of these devices, especially when closed-loop control is needed, as is the case in medical applications. There are two main approaches in the modeling of continuum robots, the first is to theoretically model the behavior of the backbone and the interaction with the tendons, while the second is to collect experimental observations and retrospectively apply a model that can approximate their apparent behavior. Both approaches are affected by the complexity of continuum robots through either model accuracy/computational time (theoretical method) or missing complex system interactions and lacking expandability (experimental method). In this work, theoretical and experimental descriptions of an endoscopic continuum robot are merged. A simplified yet representative mathematical model of a continuum robot is developed, in which the backbone model is based on Cosserat rod theory and is coupled to the tendon tensions. A robust numerical technique is formulated that has low computational costs. A bespoke experimental facility with precise automated motion of the backbone via the precise control of tendon tension, leads to a robust and detailed description of the system behavior provided through a contactless sensor. The resulting facility achieves a real-world mean positioning error of 3.95% of the backbone length for the examined range of tendon tensions which performs favourably to existing approaches. Moreover, it incorporates hysteresis behavior that could not be predicted by the theoretical modeling alone, reinforcing the benefits of the hybrid approach. The proposed workflow is theoretically grounded and experimentally validated allowing precise prediction of the continuum robot behavior, adhering to realistic observations. Based on this accurate estimation and the fact it is geometrically agnostic enables the proposed model to be scaled for various robotic endoscopes.},
  archive      = {J_FROBT},
  author       = {Isbister, Andrew and Bailey, Nicola Y. and Georgilas, Ioannis},
  doi          = {10.3389/frobt.2021.667205},
  journal      = {Frontiers in Robotics and AI},
  month        = {6},
  pages        = {667205},
  shortjournal = {Front. Robot. AI},
  title        = {An integrated kinematic modeling and experimental approach for an active endoscope},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Invariant set distributed explicit reference governors for
provably safe on-board control of nano-quadrotor swarms. <em>FROBT</em>,
<em>8</em>, 663809. (<a
href="https://doi.org/10.3389/frobt.2021.663809">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article provides a theory for provably safe and computationally efficient distributed constrained control, and describes an application to a swarm of nano-quadrotors with limited on-board hardware and subject to multiple state and input constraints. We provide a formal extension of the explicit reference governor framework to address the case of distributed systems. The efficacy, robustness, and scalability of the proposed theory is demonstrated by an extensive experimental validation campaign and a comparative simulation study on single and multiple nano-quadrotors. The control strategy is implemented in real-time on-board palm-sized unmanned erial vehicles, and achieves safe swarm coordination without relying on any offline trajectory computations.},
  archive      = {J_FROBT},
  author       = {Convens, Bryan and Merckaert, Kelly and Vanderborght, Bram and Nicotra, Marco M.},
  doi          = {10.3389/frobt.2021.663809},
  journal      = {Frontiers in Robotics and AI},
  month        = {6},
  pages        = {663809},
  shortjournal = {Front. Robot. AI},
  title        = {Invariant set distributed explicit reference governors for provably safe on-board control of nano-quadrotor swarms},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Design of an inkjet-printed rotary bellows actuator and
simulation of its time-dependent deformation behavior. <em>FROBT</em>,
<em>8</em>, 663158. (<a
href="https://doi.org/10.3389/frobt.2021.663158">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {State-of-the-art Additive Manufacturing processes such as three-dimensional (3D) inkjet printing are capable of producing geometrically complex multi-material components with integrated elastomeric features. Researchers and engineers seeking to exploit these capabilities must handle the complex mechanical behavior of inkjet-printed elastomers and expect a lack of suitable design examples. We address these obstacles using a pneumatic actuator as an application case. First, an inkjet-printable actuator design with elastomeric bellows structures is presented. While soft robotics research has brought forward several examples of inkjet-printed linear and bending bellows actuators, the rotary actuator described here advances into the still unexplored field of additively manufactured pneumatic lightweight robots with articulated joints. Second, we demonstrate that the complex structural behavior of the actuator’s elastomeric bellows structure can be predicted by Finite Element (FE) simulation. To this end, a suitable hyperviscoelastic material model was calibrated and compared to recently published models in a multiaxial-state-of-stress relaxation experiment. To verify the material model, Finite Element simulations of the actuator’s deformation behavior were conducted, and the results compared to those of corresponding experiments. The simulations presented here advance the materials science of inkjet-printed elastomers by demonstrating use of a hyperviscoelastic material model for estimating the deformation behavior of a prototypic robotic component. The results obtained contribute to the long-term goal of additively manufactured and pneumatically actuated lightweight robots.},
  archive      = {J_FROBT},
  author       = {Dämmer, Gabriel and Lackner, Michael and Laicher, Sonja and Neumann, Rüdiger and Major, Zoltán},
  doi          = {10.3389/frobt.2021.663158},
  journal      = {Frontiers in Robotics and AI},
  month        = {6},
  pages        = {663158},
  shortjournal = {Front. Robot. AI},
  title        = {Design of an inkjet-printed rotary bellows actuator and simulation of its time-dependent deformation behavior},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Embodiment in 18th century depictions of human-machine
co-creativity. <em>FROBT</em>, <em>8</em>, 662036. (<a
href="https://doi.org/10.3389/frobt.2021.662036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial intelligence has a rich history in literature; fiction has shaped how we view artificial agents and their capacities in the real world. This paper looks at embodied examples of human-machine co-creation from the literature of the Long 18th Century (1,650–1,850), examining how older depictions of creative machines could inform and inspire modern day research. The works are analyzed from the perspective of design fiction with special focus on the embodiment of the systems and the creativity exhibited by them. We find that the chosen examples highlight the importance of recognizing the environment as a major factor in human-machine co-creative processes and that some of the works seem to precede current examples of artificial systems reaching into our everyday lives. The examples present embodied interaction in a positive, creativity-oriented way, but also highlight ethical risks of human-machine co-creativity. Modern day perceptions of artificial systems and creativity can be limited to some extent by the technologies available; fictitious examples from centuries past allow us to examine such limitations using a Design Fiction approach. We conclude by deriving four guidelines for future research from our fictional examples: 1) explore unlikely embodiments; 2) think of situations, not systems; 3) be aware of the disjunction between action and appearance; and 4) consider the system as a situated moral agent.},
  archive      = {J_FROBT},
  author       = {Kantosalo, Anna and Falk, Michael and Jordanous, Anna},
  doi          = {10.3389/frobt.2021.662036},
  journal      = {Frontiers in Robotics and AI},
  month        = {6},
  pages        = {662036},
  shortjournal = {Front. Robot. AI},
  title        = {Embodiment in 18th century depictions of human-machine co-creativity},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Educational robotics and robot creativity: An
interdisciplinary dialogue. <em>FROBT</em>, <em>8</em>, 662030. (<a
href="https://doi.org/10.3389/frobt.2021.662030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There is a growing literature concerning robotics and creativity. Although some authors claim that robotics in classrooms may be a promising new tool to address the creativity crisis in school, we often face a lack of theoretical development of the concept of creativity and the mechanisms involved. In this article, we will first provide an overview of existing research using educational robotics to foster creativity. We show that in this line of work the exact mechanisms promoted by robotics activities are rarely discussed. We use a confluence model of creativity to account for the positive effect of designing and coding robots on students&#39; creative output. We focus on the cognitive components of the process of constructing and programming robots within the context of existing models of creative cognition. We address as well the question of the role of meta-reasoning and emergent strategies in the creative process. Then, in the second part of the article, we discuss how the notion of creativity applies to robots themselves in terms of the creative processes that can be embodied in these artificial agents. Ultimately, we argue that considering how robots and humans deal with novelty and solve open-ended tasks could help us to understand better some aspects of the essence of creativity.},
  archive      = {J_FROBT},
  author       = {Gubenko, Alla and Kirsch, Christiane and Smilek, Jan Nicola and Lubart, Todd and Houssemand, Claude},
  doi          = {10.3389/frobt.2021.662030},
  journal      = {Frontiers in Robotics and AI},
  month        = {6},
  pages        = {662030},
  shortjournal = {Front. Robot. AI},
  title        = {Educational robotics and robot creativity: An interdisciplinary dialogue},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Integration of a passive exoskeleton and a robotic
supernumerary finger for grasping compensation in chronic stroke
patients: The SoftPro wearable system. <em>FROBT</em>, <em>8</em>,
661354. (<a href="https://doi.org/10.3389/frobt.2021.661354">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Upper-limb impairments are all-pervasive in Activities of Daily Living (ADLs). As a consequence, people affected by a loss of arm function must endure severe limitations. To compensate for the lack of a functional arm and hand, we developed a wearable system that combines different assistive technologies including sensing, haptics, orthotics and robotics. The result is a device that helps lifting the forearm by means of a passive exoskeleton and improves the grasping ability of the impaired hand by employing a wearable robotic supernumerary finger. A pilot study involving 3 patients, which was conducted to test the capability of the device to assist in performing ADLs, confirmed its usefulness and serves as a first step in the investigation of novel paradigms for robotic assistance.},
  archive      = {J_FROBT},
  author       = {Salvietti, Gionata and Franco, Leonardo and Tschiersky, Martin and Wolterink, Gerjan and Bianchi, Matteo and Bicchi, Antonio and Barontini, Federica and Catalano, Manuel and Grioli, Giorgio and Poggiani, Mattia and Rossi, Simone and Prattichizzo, Domenico},
  doi          = {10.3389/frobt.2021.661354},
  journal      = {Frontiers in Robotics and AI},
  month        = {6},
  pages        = {661354},
  shortjournal = {Front. Robot. AI},
  title        = {Integration of a passive exoskeleton and a robotic supernumerary finger for grasping compensation in chronic stroke patients: The SoftPro wearable system},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Omnidirectional walking pattern generator combining virtual
constraints and preview control for humanoid robots. <em>FROBT</em>,
<em>8</em>, 660004. (<a
href="https://doi.org/10.3389/frobt.2021.660004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a novel omnidirectional walking pattern generator for bipedal locomotion combining two structurally different approaches based on the virtual constraints and the preview control theories to generate a flexible gait that can be modified on-line. The proposed strategy synchronizes the displacement of the robot along the two planes of walking: the zero moment point based preview control is responsible for the lateral component of the gait, while the sagittal motion is generated by a more dynamical approach based on virtual constraints. The resulting algorithm is characterized by a low computational complexity and high flexibility, requisite for a successful deployment to humanoid robots operating in real world scenarios. This solution is motivated by observations in biomechanics showing how during a nominal gait the dynamic motion of the human walk is mainly generated along the sagittal plane. We describe the implementation of the algorithm and we detail the strategy chosen to enable omnidirectionality and on-line gait tuning. Finally, we validate our strategy through simulation experiments using the COMAN + platform, an adult size humanoid robot developed at Istituto Italiano di Tecnologia. Finally, the hybrid walking pattern generator is implemented on real hardware, demonstrating promising results: the WPG trajectories results in open-loop stable walking in the absence of external disturbances.},
  archive      = {J_FROBT},
  author       = {Ruscelli, Francesco and Laurenzi, Arturo and Mingo Hoffman, Enrico and Tsagarakis, Nikos G.},
  doi          = {10.3389/frobt.2021.660004},
  journal      = {Frontiers in Robotics and AI},
  month        = {6},
  pages        = {660004},
  shortjournal = {Front. Robot. AI},
  title        = {Omnidirectional walking pattern generator combining virtual constraints and preview control for humanoid robots},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Brainstorming with a social robot facilitator: Better than
human facilitation due to reduced evaluation apprehension?
<em>FROBT</em>, <em>8</em>, 657291. (<a
href="https://doi.org/10.3389/frobt.2021.657291">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Brainstorming is a creative technique used to support productivity and creativity during the idea generation phase of an innovation process. In professional practice, a facilitator structures, regulates, and motivates those behaviors of participants that help maintain productivity and creativity during a brainstorm. Emerging technologies, such as social robots, are being developed to support or even automate the facilitator’s role. However, little is known about whether and how brainstorming with a social robot influences productivity. To take a first look, we conducted a between-subjects experiment (N = 54) that explored 1) whether brainstorming with a Wizard-of-Oz operated robot facilitator, compared to with a human facilitator, influences productivity; and 2) whether any effects on productivity might be explained by the robot’s negative effects on social anxiety and evaluation apprehension. The results showed no evidence for an effect of brainstorming with a teleoperated robot facilitator, compared to brainstorming directly with a human facilitator, on productivity. Although the results did suggest that overall, social anxiety caused evaluation apprehension, and evaluation apprehension negatively affected productivity, there was no effect of brainstorming with a robot facilitator on this relationship. Herewith, the present study contributes to an emerging body of work on the efficacy and mechanisms of the facilitation of creative work by social robots.},
  archive      = {J_FROBT},
  author       = {Geerts, Julia and de Wit, Jan and de Rooij, Alwin},
  doi          = {10.3389/frobt.2021.657291},
  journal      = {Frontiers in Robotics and AI},
  month        = {6},
  pages        = {657291},
  shortjournal = {Front. Robot. AI},
  title        = {Brainstorming with a social robot facilitator: Better than human facilitation due to reduced evaluation apprehension?},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Robot care ethics between autonomy and vulnerability:
Coupling principles and practices in autonomous systems for care.
<em>FROBT</em>, <em>8</em>, 654298. (<a
href="https://doi.org/10.3389/frobt.2021.654298">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Technological developments involving robotics and artificial intelligence devices are being employed evermore in elderly care and the healthcare sector more generally, raising ethical issues and practical questions warranting closer considerations of what we mean by “care” and, subsequently, how to design such software coherently with the chosen definition. This paper starts by critically examining the existing approaches to the ethical design of care robots provided by Aimee van Wynsberghe, who relies on the work on the ethics of care by Joan Tronto. In doing so, it suggests an alternative to their non-principled approach, an alternative suited to tackling some of the issues raised by Tronto and van Wynsberghe, while allowing for the inclusion of two orientative principles. Our proposal centres on the principles of autonomy and vulnerability, whose joint adoption we deem able to constitute an original revision of a bottom-up approach in care ethics. Conclusively, the ethical framework introduced here integrates more traditional approaches in care ethics in view of enhancing the debate regarding the ethical design of care robots under a new lens.},
  archive      = {J_FROBT},
  author       = {Pirni, Alberto and Balistreri, Maurizio and Capasso, Marianna and Umbrello, Steven and Merenda, Federica},
  doi          = {10.3389/frobt.2021.654298},
  journal      = {Frontiers in Robotics and AI},
  month        = {6},
  pages        = {654298},
  shortjournal = {Front. Robot. AI},
  title        = {Robot care ethics between autonomy and vulnerability: Coupling principles and practices in autonomous systems for care},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Assistive navigation using deep reinforcement learning
guiding robot with UWB/voice beacons and semantic feedbacks for blind
and visually impaired people. <em>FROBT</em>, <em>8</em>, 654132. (<a
href="https://doi.org/10.3389/frobt.2021.654132">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Facilitating navigation in pedestrian environments is critical for enabling people who are blind and visually impaired (BVI) to achieve independent mobility. A deep reinforcement learning (DRL)–based assistive guiding robot with ultrawide-bandwidth (UWB) beacons that can navigate through routes with designated waypoints was designed in this study. Typically, a simultaneous localization and mapping (SLAM) framework is used to estimate the robot pose and navigational goal; however, SLAM frameworks are vulnerable in certain dynamic environments. The proposed navigation method is a learning approach based on state-of-the-art DRL and can effectively avoid obstacles. When used with UWB beacons, the proposed strategy is suitable for environments with dynamic pedestrians. We also designed a handle device with an audio interface that enables BVI users to interact with the guiding robot through intuitive feedback. The UWB beacons were installed with an audio interface to obtain environmental information. The on-handle and on-beacon verbal feedback provides points of interests and turn-by-turn information to BVI users. BVI users were recruited in this study to conduct navigation tasks in different scenarios. A route was designed in a simulated ward to represent daily activities. In real-world situations, SLAM-based state estimation might be affected by dynamic obstacles, and the visual-based trail may suffer from occlusions from pedestrians or other obstacles. The proposed system successfully navigated through environments with dynamic pedestrians, in which systems based on existing SLAM algorithms have failed.},
  archive      = {J_FROBT},
  author       = {Lu, Chen-Lung and Liu, Zi-Yan and Huang, Jui-Te and Huang, Ching-I and Wang, Bo-Hui and Chen, Yi and Wu, Nien-Hsin and Wang, Hsueh-Cheng and Giarré, Laura and Kuo, Pei-Yi},
  doi          = {10.3389/frobt.2021.654132},
  journal      = {Frontiers in Robotics and AI},
  month        = {6},
  pages        = {654132},
  shortjournal = {Front. Robot. AI},
  title        = {Assistive navigation using deep reinforcement learning guiding robot with UWB/Voice beacons and semantic feedbacks for blind and visually impaired people},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). I am looking for your mind: Pupil dilation predicts
individual differences in sensitivity to hints of human-likeness in
robot behavior. <em>FROBT</em>, <em>8</em>, 653537. (<a
href="https://doi.org/10.3389/frobt.2021.653537">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The presence of artificial agents in our everyday lives is continuously increasing. Hence, the question of how human social cognition mechanisms are activated in interactions with artificial agents, such as humanoid robots, is frequently being asked. One interesting question is whether humans perceive humanoid robots as mere artifacts (interpreting their behavior with reference to their function, thereby adopting the design stance) or as intentional agents (interpreting their behavior with reference to mental states, thereby adopting the intentional stance). Due to their humanlike appearance, humanoid robots might be capable of evoking the intentional stance. On the other hand, the knowledge that humanoid robots are only artifacts should call for adopting the design stance. Thus, observing a humanoid robot might evoke a cognitive conflict between the natural tendency of adopting the intentional stance and the knowledge about the actual nature of robots, which should elicit the design stance. In the present study, we investigated the cognitive conflict hypothesis by measuring participants’ pupil dilation during the completion of the InStance Test. Prior to each pupillary recording, participants were instructed to observe the humanoid robot iCub behaving in two different ways (either machine-like or humanlike behavior). Results showed that pupil dilation and response time patterns were predictive of individual biases in the adoption of the intentional or design stance in the IST. These results may suggest individual differences in mental effort and cognitive flexibility in reading and interpreting the behavior of an artificial agent.},
  archive      = {J_FROBT},
  author       = {Marchesi, Serena and Bossi, Francesco and Ghiglino, Davide and De Tommaso, Davide and Wykowska, Agnieszka},
  doi          = {10.3389/frobt.2021.653537},
  journal      = {Frontiers in Robotics and AI},
  month        = {6},
  pages        = {653537},
  shortjournal = {Front. Robot. AI},
  title        = {I am looking for your mind: Pupil dilation predicts individual differences in sensitivity to hints of human-likeness in robot behavior},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). On-orbit robotic grasping of a spent rocket stage: Grasp
stability analysis and experimental results. <em>FROBT</em>, <em>8</em>,
652681. (<a href="https://doi.org/10.3389/frobt.2021.652681">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increased complexity of the tasks that on-orbit robots have to undertake has led to an increased need for manipulation dexterity. Space robots can become more dexterous by adopting grasping and manipulation methodologies and algorithms from terrestrial robots. In this paper, we present a novel methodology for evaluating the stability of a robotic grasp that captures a piece of space debris, a spent rocket stage. We calculate the Intrinsic Stiffness Matrix of a 2-fingered grasp on the surface of an Apogee Kick Motor nozzle and create a stability metric that is a function of the local contact curvature, material properties, applied force, and target mass. We evaluate the efficacy of the stability metric in a simulation and two real robot experiments. The subject of all experiments is a chasing robot that needs to capture a target AKM and pull it back towards the chaser body. In the V-REP simulator, we evaluate four grasping points on three AKM models, over three pulling profiles, using three physics engines. We also use a real robotic testbed with the capability of emulating an approaching robot and a weightless AKM target to evaluate our method over 11 grasps and three pulling profiles. Finally, we perform a sensitivity analysis to demonstrate how a variation on the grasping parameters affects grasp stability. The results of all experiments suggest that the grasp can be stable under slow pulling profiles, with successful pulling for all targets. The presented work offers an alternative way of capturing orbital targets and a novel example of how terrestrial robotic grasping methodologies could be extended to orbital activities.},
  archive      = {J_FROBT},
  author       = {Mavrakis, Nikos and Hao, Zhou and Gao, Yang},
  doi          = {10.3389/frobt.2021.652681},
  journal      = {Frontiers in Robotics and AI},
  month        = {6},
  pages        = {652681},
  shortjournal = {Front. Robot. AI},
  title        = {On-orbit robotic grasping of a spent rocket stage: Grasp stability analysis and experimental results},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Technical challenges for smooth interaction with seniors
with dementia: Lessons from humanitude™. <em>FROBT</em>, <em>8</em>,
650906. (<a href="https://doi.org/10.3389/frobt.2021.650906">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to cognitive and socio-emotional decline and mental diseases, senior citizens, especially people with dementia (PwD), struggle to interact smoothly with their caregivers. Therefore, various care techniques have been proposed to develop good relationships with seniors. Among them, Humanitude is one promising technique that provides caregivers with useful interaction skills to improve their relationships with PwD, from four perspectives: face-to-face interaction, verbal communication, touch interaction, and helping care receivers stand up (physical interaction). Regardless of advances in elderly care techniques, since current social robots interact with seniors in the same manner as they do with younger adults, they lack several important functions. For example, Humanitude emphasizes the importance of interaction at a relatively intimate distance to facilitate communication with seniors. Unfortunately, few studies have developed an interaction model for clinical care communication. In this paper, we discuss the current challenges to develop a social robot that can smoothly interact with PwDs and overview the interaction skills used in Humanitude as well as the existing technologies.},
  archive      = {J_FROBT},
  author       = {Sumioka, Hidenobu and Shiomi, Masahiro and Honda, Miwako and Nakazawa, Atsushi},
  doi          = {10.3389/frobt.2021.650906},
  journal      = {Frontiers in Robotics and AI},
  month        = {6},
  pages        = {650906},
  shortjournal = {Front. Robot. AI},
  title        = {Technical challenges for smooth interaction with seniors with dementia: Lessons from humanitude™},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A computational framework towards the tele-rehabilitation of
balance control skills. <em>FROBT</em>, <em>8</em>, 648485. (<a
href="https://doi.org/10.3389/frobt.2021.648485">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobility has been one of the most impacted aspects of human life due to the spread of the COVID-19 pandemic. Home confinement, the lack of access to physical rehabilitation, and prolonged immobilization of COVID-19-positive patients within hospitals are three major factors that affected the mobility of the general population world-wide. Balance is one key indicator to monitor the possible movement disorders that may arise both during the COVID-19 pandemic and in the coming future post-COVID-19. A systematic quantification of the balance performance in the general population is essential for preventing the appearance and progression of certain diseases (e.g., cardiovascular, neurodegenerative, and musculoskeletal), as well as for assessing the therapeutic outcomes of prescribed physical exercises for elderly and pathological patients. Current research on clinical exercises and associated outcome measures of balance is still far from reaching a consensus on a “golden standard” practice. Moreover, patients are often reluctant or unable to follow prescribed exercises, because of overcrowded facilities, lack of reliable and safe transportation, or stay-at-home orders due to the current pandemic. A novel balance assessment methodology, in combination with a home-care technology, can overcome these limitations. This paper presents a computational framework for the in-home quantitative assessment of balance control skills. Novel outcome measures of balance performance are implemented in the design of rehabilitation exercises with customized and quantifiable training goals. Using this framework in conjunction with a portable technology, physicians can treat and diagnose patients remotely, with reduced time and costs and a highly customized approach. The methodology proposed in this research can support the development of innovative technologies for smart and connected home-care solutions for physical therapy rehabilitation.},
  archive      = {J_FROBT},
  author       = {Akbas, Kubra and Mummolo, Carlotta},
  doi          = {10.3389/frobt.2021.648485},
  journal      = {Frontiers in Robotics and AI},
  month        = {6},
  pages        = {648485},
  shortjournal = {Front. Robot. AI},
  title        = {A computational framework towards the tele-rehabilitation of balance control skills},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Hybrid parallel compliance allows robots to operate with
sensorimotor delays and low control frequencies. <em>FROBT</em>,
<em>8</em>, 645748. (<a
href="https://doi.org/10.3389/frobt.2021.645748">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Animals locomote robustly and agile, albeit significant sensorimotor delays of their nervous system and the harsh loading conditions resulting from repeated, high-frequent impacts. The engineered sensorimotor control in legged robots is implemented with high control frequencies, often in the kilohertz range. Consequently, robot sensors and actuators can be polled within a few milliseconds. However, especially at harsh impacts with unknown touch-down timing, controllers of legged robots can become unstable, while animals are seemingly not affected. We examine this discrepancy and suggest and implement a hybrid system consisting of a parallel compliant leg joint with varying amounts of passive stiffness and a virtual leg length controller. We present systematic experiments both in computer simulation and robot hardware. Our system shows previously unseen robustness, in the presence of sensorimotor delays up to 60 ms, or control frequencies as low as 20 Hz, for a drop landing task from 1.3 leg lengths high and with a compliance ratio (fraction of physical stiffness of the sum of virtual and physical stiffness) of 0.7. In computer simulations, we report successful drop-landings from 3.8 leg lengths (1.2 m) for a 2 kg quadruped robot with 100 Hz control frequency and a sensorimotor delay of 35 ms.},
  archive      = {J_FROBT},
  author       = {Ashtiani, Milad Shafiee and Aghamaleki Sarvestani, Alborz and Badri-Spröwitz, Alexander},
  doi          = {10.3389/frobt.2021.645748},
  journal      = {Frontiers in Robotics and AI},
  month        = {6},
  pages        = {645748},
  shortjournal = {Front. Robot. AI},
  title        = {Hybrid parallel compliance allows robots to operate with sensorimotor delays and low control frequencies},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A dialogue-based system with photo and storytelling for
older adults: Toward daily cognitive training. <em>FROBT</em>,
<em>8</em>, 644964. (<a
href="https://doi.org/10.3389/frobt.2021.644964">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the elderly population grows worldwide, living a healthy and full life as an older adult is becoming a topic of great interest. One key factor and severe challenge to maintaining quality of life in older adults is cognitive decline. Assistive robots for helping older adults have been proposed to solve issues such as social isolation and dependent living. Only a few studies have reported the positive effects of dialogue robots on cognitive function but conversation is being discussed as a promising intervention that includes various cognitive tasks. Existing dialogue robot-related studies have reported on placing dialogue robots in elderly homes and allowing them to interact with residents. However, it is difficult to reproduce these experiments since the participants’ characteristics influence experimental conditions, especially at home. Besides, most dialogue systems are not designed to set experimental conditions without on-site support. This study proposes a novel design method that uses a dialogue-based robot system for cognitive training at home. We define challenges and requirements to meet them to realize cognitive function training through daily communication. Those requirements are designed to satisfy detailed conditions such as duration of dialogue, frequency, and starting time without on-site support. Our system displays photos and gives original stories to provide contexts for dialogue that help the robot maintain a conversation for each story. Then the system schedules dialogue sessions along with the participant’s plan. The robot moderates the user to ask a question and then responds to the question by changing its facial expression. This question-answering procedure continued for a specific duration (4 min). To verify our design method’s effectiveness and implementation, we conducted three user studies by recruiting 35 elderly participants. We performed prototype-, laboratory-, and home-based experiments. Through these experiments, we evaluated current datasets, user experience, and feasibility for home use. We report on and discuss the older adults’ attitudes toward the robot and the number of turns during dialogues. We also classify the types of utterances and identify user needs. Herein, we outline the findings of this study, outlining the system’s essential characteristics to experiment toward daily cognitive training and explain further feature requests.},
  archive      = {J_FROBT},
  author       = {Tokunaga, Seiki and Tamura, Kazuhiro and Otake-Matsuura, Mihoko},
  doi          = {10.3389/frobt.2021.644964},
  journal      = {Frontiers in Robotics and AI},
  month        = {6},
  pages        = {644964},
  shortjournal = {Front. Robot. AI},
  title        = {A dialogue-based system with photo and storytelling for older adults: Toward daily cognitive training},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Detachable robotic grippers for human-robot collaboration.
<em>FROBT</em>, <em>8</em>, 644532. (<a
href="https://doi.org/10.3389/frobt.2021.644532">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Collaborative robots promise to add flexibility to production cells thanks to the fact that they can work not only close to humans but also with humans. The possibility of a direct physical interaction between humans and robots allows to perform operations that were inconceivable with industrial robots. Collaborative soft grippers have been recently introduced to extend this possibility beyond the robot end-effector, making humans able to directly act on robotic hands. In this work, we propose to exploit collaborative grippers in a novel paradigm in which these devices can be easily attached and detached from the robot arm and used also independently from it. This is possible only with self-powered hands, that are still quite uncommon in the market. In the presented paradigm not only hands can be attached/detached to/from the robot end-effector as if they were simple tools, but they can also remain active and fully functional after detachment. This ensures all the advantages brought in by tool changers, that allow for quick and possibly automatic tool exchange at the robot end-effector, but also gives the possibility of using the hand capabilities and degrees of freedom without the need of an arm or of external power supplies. In this paper, the concept of detachable robotic grippers is introduced and demonstrated through two illustrative tasks conducted with a new tool changer designed for collaborative grippers. The novel tool changer embeds electromagnets that are used to add safety during attach/detach operations. The activation of the electromagnets is controlled through a wearable interface capable of providing tactile feedback. The usability of the system is confirmed by the evaluations of 12 users.},
  archive      = {J_FROBT},
  author       = {Iqbal, Zubair and Pozzi, Maria and Prattichizzo, Domenico and Salvietti, Gionata},
  doi          = {10.3389/frobt.2021.644532},
  journal      = {Frontiers in Robotics and AI},
  month        = {6},
  pages        = {644532},
  shortjournal = {Front. Robot. AI},
  title        = {Detachable robotic grippers for human-robot collaboration},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An immersive investment game to study human-robot trust.
<em>FROBT</em>, <em>8</em>, 644529. (<a
href="https://doi.org/10.3389/frobt.2021.644529">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As robots become more advanced and capable, developing trust is an important factor of human-robot interaction and cooperation. However, as multiple environmental and social factors can influence trust, it is important to develop more elaborate scenarios and methods to measure human-robot trust. A widely used measurement of trust in social science is the investment game. In this study, we propose a scaled-up, immersive, science fiction Human-Robot Interaction (HRI) scenario for intrinsic motivation on human-robot collaboration, built upon the investment game and aimed at adapting the investment game for human-robot trust. For this purpose, we utilize two Neuro-Inspired COmpanion (NICO) - robots and a projected scenery. We investigate the applicability of our space mission experiment design to measure trust and the impact of non-verbal communication. We observe a correlation of 0.43 (&lt;mml:math id=&quot;m1&quot; xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;p&lt;/mml:mi&gt;&lt;mml:mo&gt;=&lt;/mml:mo&gt;&lt;mml:mn&gt;0.02&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:math&gt;) between self-assessed trust and trust measured from the game, and a positive impact of non-verbal communication on trust (&lt;mml:math id=&quot;m2&quot; xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;p&lt;/mml:mi&gt;&lt;mml:mo&gt;=&lt;/mml:mo&gt;&lt;mml:mn&gt;0.0008&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:math&gt;) and robot perception for anthropomorphism (&lt;mml:math id=&quot;m3&quot; xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;p&lt;/mml:mi&gt;&lt;mml:mo&gt;=&lt;/mml:mo&gt;&lt;mml:mn&gt;0.007&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:math&gt;) and animacy (&lt;mml:math id=&quot;m4&quot; xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;p&lt;/mml:mi&gt;&lt;mml:mo&gt;=&lt;/mml:mo&gt;&lt;mml:mn&gt;0.00002&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:math&gt;). We conclude that our scenario is an appropriate method to measure trust in human-robot interaction and also to study how non-verbal communication influences a human’s trust in robots.},
  archive      = {J_FROBT},
  author       = {Zörner, Sebastian and Arts, Emy and Vasiljevic, Brenda and Srivastava, Ankit and Schmalzl, Florian and Mir, Glareh and Bhatia, Kavish and Strahl, Erik and Peters, Annika and Alpay, Tayfun and Wermter, Stefan},
  doi          = {10.3389/frobt.2021.644529},
  journal      = {Frontiers in Robotics and AI},
  month        = {6},
  pages        = {644529},
  shortjournal = {Front. Robot. AI},
  title        = {An immersive investment game to study human-robot trust},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Role-play as responsible robotics: The virtual witness
testimony role-play interview for investigating hazardous human-robot
interactions. <em>FROBT</em>, <em>8</em>, 644336. (<a
href="https://doi.org/10.3389/frobt.2021.644336">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The development of responsible robotics requires paying attention to responsibility within the research process in addition to responsibility as the outcome of research. This paper describes the preparation and application of a novel method to explore hazardous human-robot interactions. The Virtual Witness Testimony role-play interview is an approach that enables participants to engage with scenarios in which a human being comes to physical harm whilst a robot is present and may have had a malfunction. Participants decide what actions they would take in the scenario and are encouraged to provide their observations and speculations on what happened. Data collection takes place online, a format that provides convenience as well as a safe space for participants to role play a hazardous encounter with minimal risk of suffering discomfort or distress. We provide a detailed account of how our initial set of Virtual Witness Testimony role-play interviews were conducted and describe the ways in which it proved to be an efficient approach that generated useful findings, and upheld our project commitments to Responsible Research and Innovation. We argue that the Virtual Witness Testimony role-play interview is a flexible and fruitful method that can be adapted to benefit research in human robot interaction and advance responsibility in robotics.},
  archive      = {J_FROBT},
  author       = {Webb, Helena and Dumitru, Morgan and van Maris, Anouk and Winkle, Katie and Jirotka, Marina and Winfield, Alan},
  doi          = {10.3389/frobt.2021.644336},
  journal      = {Frontiers in Robotics and AI},
  month        = {6},
  pages        = {644336},
  shortjournal = {Front. Robot. AI},
  title        = {Role-play as responsible robotics: The virtual witness testimony role-play interview for investigating hazardous human-robot interactions},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Intelligent spacecraft visual GNC architecture with the
state-of-the-art AI components for on-orbit manipulation.
<em>FROBT</em>, <em>8</em>, 639327. (<a
href="https://doi.org/10.3389/frobt.2021.639327">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conventional spacecraft Guidance, Navigation, and Control (GNC) architectures have been designed to receive and execute commands from ground control with minimal automation and autonomy onboard spacecraft. In contrast, Artificial Intelligence (AI)-based systems can allow real-time decision-making by considering system information that is difficult to model and incorporate in the conventional decision-making process involving ground control or human operators. With growing interests in on-orbit services with manipulation, the conventional GNC faces numerous challenges in adapting to a wide range of possible scenarios, such as removing unknown debris, potentially addressed using emerging AI-enabled robotic technologies. However, a complete paradigm shift may need years&#39; efforts. As an intermediate solution, we introduce a novel visual GNC system with two state-of-the-art AI modules to replace the corresponding functions in the conventional GNC system for on-orbit manipulation. The AI components are as follows: (i) A Deep Learning (DL)-based pose estimation algorithm that can estimate a target&#39;s pose from two-dimensional images using a pre-trained neural network without requiring any prior information on the dynamics or state of the target. (ii) A technique for modeling and controlling space robot manipulator trajectories using probabilistic modeling and reproduction to previously unseen situations to avoid complex trajectory optimizations on board. This also minimizes the attitude disturbances of spacecraft induced on it due to the motion of the robot arm. This architecture uses a centralized camera network as the main sensor, and the trajectory learning module of the 7 degrees of freedom robotic arm is integrated into the GNC system. The intelligent visual GNC system is demonstrated by simulation of a conceptual mission—AISAT. The mission is a micro-satellite to carry out on-orbit manipulation around a non-cooperative CubeSat. The simulation shows how the GNC system works in discrete-time simulation with the control and trajectory planning are generated in Matlab/Simulink. The physics rendering engine, Eevee, renders the whole simulation to provide a graphic realism for the DL pose estimation. In the end, the testbeds developed to evaluate and demonstrate the GNC system are also introduced. The novel intelligent GNC system can be a stepping stone toward future fully autonomous orbital robot systems.},
  archive      = {J_FROBT},
  author       = {Hao, Zhou and Shyam, R. B. Ashith and Rathinam, Arunkumar and Gao, Yang},
  doi          = {10.3389/frobt.2021.639327},
  journal      = {Frontiers in Robotics and AI},
  month        = {6},
  pages        = {639327},
  shortjournal = {Front. Robot. AI},
  title        = {Intelligent spacecraft visual GNC architecture with the state-of-the-art AI components for on-orbit manipulation},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Onshoring through automation; perpetuating inequality?
<em>FROBT</em>, <em>8</em>, 634297. (<a
href="https://doi.org/10.3389/frobt.2021.634297">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many analyses of the ethical, legal and societal impacts of robotics are focussed on Europe and the United States. In this article I discuss the impacts of robotics on developing nations in a connected world, and make the case that international equity demands that we extend the scope of our discussions around these impacts. Offshoring has been instrumental in the economic development of a series of nations. As technology advances and wage share increases, less labour is required to achieve the same task, and more job functions move to new areas with lower labour costs. This cascade results in a ladder of economic betterment that is footed in a succession of countries, and has improved standards of living and human flourishing. The recent international crisis precipitated by COVID-19 has underlined the vulnerability of many industries to disruptions in global supply chains. As a response to this, “onshoring” of functions which had been moved to other nations decreases risk, but would increase labour costs if it were not for automation. Robotics, by facilitating onshoring, risks pulling up the ladder, and suppressing the drivers for economic development. The roots of the economic disparities that motivate these international shifts lie in many cases in colonialism and its effects on colonised societies. As we discuss the colonial legacy, and being mindful of the justifications and rationale for distributive justice, we should consider how robotics impacts international development.},
  archive      = {J_FROBT},
  author       = {Studley, Matthew},
  doi          = {10.3389/frobt.2021.634297},
  journal      = {Frontiers in Robotics and AI},
  month        = {6},
  pages        = {634297},
  shortjournal = {Front. Robot. AI},
  title        = {Onshoring through automation; perpetuating inequality?},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A minimal design of a human infant presence: A case study
toward interactive doll therapy for older adults with dementia.
<em>FROBT</em>, <em>8</em>, 633378. (<a
href="https://doi.org/10.3389/frobt.2021.633378">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce a minimal design approach to manufacture an infant-like robot for interactive doll therapy that provides emotional interactions for older people with dementia. Our approach stimulates their imaginations and then facilitates positive engagement with the robot by just expressing the most basic elements of humanlike features. Based on this approach, we developed HIRO, a baby-sized robot with an abstract body representation and no facial features. The recorded voice of a real human infant emitted by robots enhances the robot’s human-likeness and facilitates positive interaction between older adults and the robot. Although we did not find any significant difference between HIRO and an infant-like robot with a smiling face, a field study showed that HIRO was accepted by older adults with dementia and facilitated positive interaction by stimulating their imagination. We also discuss the importance of a minimal design approach in elderly care during post–COVID-19 world.},
  archive      = {J_FROBT},
  author       = {Sumioka, Hidenobu and Yamato, Nobuo and Shiomi, Masahiro and Ishiguro, Hiroshi},
  doi          = {10.3389/frobt.2021.633378},
  journal      = {Frontiers in Robotics and AI},
  month        = {6},
  pages        = {633378},
  shortjournal = {Front. Robot. AI},
  title        = {A minimal design of a human infant presence: A case study toward interactive doll therapy for older adults with dementia},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Improving autonomous robotic navigation using imitation
learning. <em>FROBT</em>, <em>8</em>, 627730. (<a
href="https://doi.org/10.3389/frobt.2021.627730">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autonomous navigation to a specified waypoint is traditionally accomplished with a layered stack of global path planning and local motion planning modules that generate feasible and obstacle-free trajectories. While these modules can be modified to meet task-specific constraints and user preferences, current modification procedures require substantial effort on the part of an expert roboticist with a great deal of technical training. In this paper, we simplify this process by inserting a Machine Learning module between the global path planning and local motion planning modules of an off-the shelf navigation stack. This model can be trained with human demonstrations of the preferred navigation behavior, using a training procedure based on Behavioral Cloning, allowing for an intuitive modification of the navigation policy by non-technical users to suit task-specific constraints. We find that our approach can successfully adapt a robot’s navigation behavior to become more like that of a demonstrator. Moreover, for a fixed amount of demonstration data, we find that the proposed technique compares favorably to recent baselines with respect to both navigation success rate and trajectory similarity to the demonstrator.},
  archive      = {J_FROBT},
  author       = {Cèsar-Tondreau, Brian and Warnell, Garrett and Stump, Ethan and Kochersberger, Kevin and Waytowich, Nicholas R.},
  doi          = {10.3389/frobt.2021.627730},
  journal      = {Frontiers in Robotics and AI},
  month        = {6},
  pages        = {627730},
  shortjournal = {Front. Robot. AI},
  title        = {Improving autonomous robotic navigation using imitation learning},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Fruit detection and pose estimation for grape
cluster–harvesting robot using binocular imagery based on deep neural
networks. <em>FROBT</em>, <em>8</em>, 626989. (<a
href="https://doi.org/10.3389/frobt.2021.626989">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reliable and robust fruit-detection algorithms in nonstructural environments are essential for the efficient use of harvesting robots. The pose of fruits is crucial to guide robots to approach target fruits for collision-free picking. To achieve accurate picking, this study investigates an approach to detect fruit and estimate its pose. First, the state-of-the-art mask region convolutional neural network (Mask R-CNN) is deployed to segment binocular images to output the mask image of the target fruit. Next, a grape point cloud extracted from the images was filtered and denoised to obtain an accurate grape point cloud. Finally, the accurate grape point cloud was used with the RANSAC algorithm for grape cylinder model fitting, and the axis of the cylinder model was used to estimate the pose of the grape. A dataset was acquired in a vineyard to evaluate the performance of the proposed approach in a nonstructural environment. The fruit detection results of 210 test images show that the average precision, recall, and intersection over union (IOU) are 89.53, 95.33, and 82.00%, respectively. The detection and point cloud segmentation for each grape took approximately 1.7 s. The demonstrated performance of the developed method indicates that it can be applied to grape-harvesting robots.},
  archive      = {J_FROBT},
  author       = {Yin, Wei and Wen, Hanjin and Ning, Zhengtong and Ye, Jian and Dong, Zhiqiang and Luo, Lufeng},
  doi          = {10.3389/frobt.2021.626989},
  journal      = {Frontiers in Robotics and AI},
  month        = {6},
  pages        = {626989},
  shortjournal = {Front. Robot. AI},
  title        = {Fruit detection and pose estimation for grape Cluster–Harvesting robot using binocular imagery based on deep neural networks},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Telerobotic operation of intensive care unit ventilators.
<em>FROBT</em>, <em>8</em>, 612964. (<a
href="https://doi.org/10.3389/frobt.2021.612964">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Since the first reports of a novel coronavirus (SARS-CoV-2) in December 2019, over 33 million people have been infected worldwide and approximately 1 million people worldwide have died from the disease caused by this virus, COVID-19. In the United States alone, there have been approximately 7 million cases and over 200,000 deaths. This outbreak has placed an enormous strain on healthcare systems and workers. Severe cases require hospital care, and 8.5% of patients require mechanical ventilation in an intensive care unit (ICU). One major challenge is the necessity for clinical care personnel to don and doff cumbersome personal protective equipment (PPE) in order to enter an ICU unit to make simple adjustments to ventilator settings. Although future ventilators and other ICU equipment may be controllable remotely through computer networks, the enormous installed base of existing ventilators do not have this capability. This paper reports the development of a simple, low cost telerobotic system that permits adjustment of ventilator settings from outside the ICU. The system consists of a small Cartesian robot capable of operating a ventilator touch screen with camera vision control via a wirelessly connected tablet master device located outside the room. Engineering system tests demonstrated that the open-loop mechanical repeatability of the device was 7.5 mm, and that the average positioning error of the robotic finger under visual servoing control was 5.94 mm. Successful usability tests in a simulated ICU environment were carried out and are reported. In addition to enabling a significant reduction in PPE consumption, the prototype system has been shown in a preliminary evaluation to significantly reduce the total time required for a respiratory therapist to perform typical setting adjustments on a commercial ventilator, including donning and doffing PPE, from 271 to 109 s.},
  archive      = {J_FROBT},
  author       = {Vagvolgyi, Balazs P. and Khrenov, Mikhail and Cope, Jonathan and Deguet, Anton and Kazanzides, Peter and Manzoor, Sajid and Taylor, Russell H. and Krieger, Axel},
  doi          = {10.3389/frobt.2021.612964},
  journal      = {Frontiers in Robotics and AI},
  month        = {6},
  pages        = {612964},
  shortjournal = {Front. Robot. AI},
  title        = {Telerobotic operation of intensive care unit ventilators},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Expectations and perceptions of healthcare professionals for
robot deployment in hospital environments during the COVID-19 pandemic.
<em>FROBT</em>, <em>8</em>, 612746. (<a
href="https://doi.org/10.3389/frobt.2021.612746">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Several challenges to guarantee medical care have been exposed during the current COVID-19 pandemic. Although the literature has shown some robotics applications to overcome the potential hazards and risks in hospital environments, the implementation of those developments is limited, and few studies measure the perception and the acceptance of clinicians. This work presents the design and implementation of several perception questionnaires to assess healthcare provider&#39;s level of acceptance and education toward robotics for COVID-19 control in clinic scenarios. Specifically, 41 healthcare professionals satisfactorily accomplished the surveys, exhibiting a low level of knowledge about robotics applications in this scenario. Likewise, the surveys revealed that the fear of being replaced by robots remains in the medical community. In the Colombian context, 82.9% of participants indicated a positive perception concerning the development and implementation of robotics in clinic environments. Finally, in general terms, the participants exhibited a positive attitude toward using robots and recommended them to be used in the current panorama.},
  archive      = {J_FROBT},
  author       = {Sierra Marín, Sergio D. and Gomez-Vargas, Daniel and Céspedes, Nathalia and Múnera, Marcela and Roberti, Flavio and Barria, Patricio and Ramamoorthy, Subramanian and Becker, Marcelo and Carelli, Ricardo and Cifuentes, Carlos A.},
  doi          = {10.3389/frobt.2021.612746},
  journal      = {Frontiers in Robotics and AI},
  month        = {6},
  pages        = {612746},
  shortjournal = {Front. Robot. AI},
  title        = {Expectations and perceptions of healthcare professionals for robot deployment in hospital environments during the COVID-19 pandemic},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Robotic home-based rehabilitation systems design: From a
literature review to a conceptual framework for community-based remote
therapy during COVID-19 pandemic. <em>FROBT</em>, <em>8</em>, 612331.
(<a href="https://doi.org/10.3389/frobt.2021.612331">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {During the COVID-19 pandemic, the higher susceptibility of post-stroke patients to infection calls for extra safety precautions. Despite the imposed restrictions, early neurorehabilitation cannot be postponed due to its paramount importance for improving motor and functional recovery chances. Utilizing accessible state-of-the-art technologies, home-based rehabilitation devices are proposed as a sustainable solution in the current crisis. In this paper, a comprehensive review on developed home-based rehabilitation technologies of the last 10 years (2011–2020), categorizing them into upper and lower limb devices and considering both commercialized and state-of-the-art realms. Mechatronic, control, and software aspects of the system are discussed to provide a classified roadmap for home-based systems development. Subsequently, a conceptual framework on the development of smart and intelligent community-based home rehabilitation systems based on novel mechatronic technologies is proposed. In this framework, each rehabilitation device acts as an agent in the network, using the internet of things (IoT) technologies, which facilitates learning from the recorded data of the other agents, as well as the tele-supervision of the treatment by an expert. The presented design paradigm based on the above-mentioned leading technologies could lead to the development of promising home rehabilitation systems, which encourage stroke survivors to engage in under-supervised or unsupervised therapeutic activities.},
  archive      = {J_FROBT},
  author       = {Akbari, Aylar and Haghverd, Faezeh and Behbahani, Saeed},
  doi          = {10.3389/frobt.2021.612331},
  journal      = {Frontiers in Robotics and AI},
  month        = {6},
  pages        = {612331},
  shortjournal = {Front. Robot. AI},
  title        = {Robotic home-based rehabilitation systems design: From a literature review to a conceptual framework for community-based remote therapy during COVID-19 pandemic},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Model-augmented haptic telemanipulation: Concept,
retrospective overview, and current use cases. <em>FROBT</em>,
<em>8</em>, 611251. (<a
href="https://doi.org/10.3389/frobt.2021.611251">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Certain telerobotic applications, including telerobotics in space, pose particularly demanding challenges to both technology and humans. Traditional bilateral telemanipulation approaches often cannot be used in such applications due to technical and physical limitations such as long and varying delays, packet loss, and limited bandwidth, as well as high reliability, precision, and task duration requirements. In order to close this gap, we research model-augmented haptic telemanipulation (MATM) that uses two kinds of models: a remote model that enables shared autonomous functionality of the teleoperated robot, and a local model that aims to generate assistive augmented haptic feedback for the human operator. Several technological methods that form the backbone of the MATM approach have already been successfully demonstrated in accomplished telerobotic space missions. On this basis, we have applied our approach in more recent research to applications in the fields of orbital robotics, telesurgery, caregiving, and telenavigation. In the course of this work, we have advanced specific aspects of the approach that were of particular importance for each respective application, especially shared autonomy, and haptic augmentation. This overview paper discusses the MATM approach in detail, presents the latest research results of the various technologies encompassed within this approach, provides a retrospective of DLR&#39;s telerobotic space missions, demonstrates the broad application potential of MATM based on the aforementioned use cases, and outlines lessons learned and open challenges.},
  archive      = {J_FROBT},
  author       = {Hulin, Thomas and Panzirsch, Michael and Singh, Harsimran and Coelho, Andre and Balachandran, Ribin and Pereira, Aaron and Weber, Bernhard M. and Bechtel, Nicolai and Riecke, Cornelia and Brunner, Bernhard and Lii, Neal Y. and Klodmann, Julian and Hellings, Anja and Hagmann, Katharina and Quere, Gabriel and Bauer, Adrian S. and Sierotowicz, Marek and Lampariello, Roberto and Vogel, Jörn and Dietrich, Alexander and Leidner, Daniel and Ott, Christian and Hirzinger, Gerd and Albu-Schäffer, Alin},
  doi          = {10.3389/frobt.2021.611251},
  journal      = {Frontiers in Robotics and AI},
  month        = {6},
  pages        = {611251},
  shortjournal = {Front. Robot. AI},
  title        = {Model-augmented haptic telemanipulation: Concept, retrospective overview, and current use cases},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Maize tassel detection from UAV imagery using deep learning.
<em>FROBT</em>, <em>8</em>, 600410. (<a
href="https://doi.org/10.3389/frobt.2021.600410">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The timing of flowering plays a critical role in determining the productivity of agricultural crops. If the crops flower too early, the crop would mature before the end of the growing season, losing the opportunity to capture and use large amounts of light energy. If the crops flower too late, the crop may be killed by the change of seasons before it is ready to harvest. Maize flowering is one of the most important periods where even small amounts of stress can significantly alter yield. In this work, we developed and compared two methods for automatic tassel detection based on the imagery collected from an unmanned aerial vehicle, using deep learning models. The first approach was a customized framework for tassel detection based on convolutional neural network (TD-CNN). The other method was a state-of-the-art object detection technique of the faster region-based CNN (Faster R-CNN), serving as baseline detection accuracy. The evaluation criteria for tassel detection were customized to correctly reflect the needs of tassel detection in an agricultural setting. Although detecting thin tassels in the aerial imagery is challenging, our results showed promising accuracy: the TD-CNN had an F1 score of 95.9% and the Faster R-CNN had 97.9% F1 score. More CNN-based model structures can be investigated in the future for improved accuracy, speed, and generalizability on aerial-based tassel detection.},
  archive      = {J_FROBT},
  author       = {Alzadjali, Aziza and Alali, Mohammed H. and Veeranampalayam Sivakumar, Arun Narenthiran and Deogun, Jitender S. and Scott, Stephen and Schnable, James C. and Shi, Yeyin},
  doi          = {10.3389/frobt.2021.600410},
  journal      = {Frontiers in Robotics and AI},
  month        = {6},
  pages        = {600410},
  shortjournal = {Front. Robot. AI},
  title        = {Maize tassel detection from UAV imagery using deep learning},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Reinforcement learning with human advice: A survey.
<em>FROBT</em>, <em>8</em>, 584075. (<a
href="https://doi.org/10.3389/frobt.2021.584075">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we provide an overview of the existing methods for integrating human advice into a reinforcement learning process. We first propose a taxonomy of the different forms of advice that can be provided to a learning agent. We then describe the methods that can be used for interpreting advice when its meaning is not determined beforehand. Finally, we review different approaches for integrating advice into the learning process.},
  archive      = {J_FROBT},
  author       = {Najar, Anis and Chetouani, Mohamed},
  doi          = {10.3389/frobt.2021.584075},
  journal      = {Frontiers in Robotics and AI},
  month        = {6},
  pages        = {584075},
  shortjournal = {Front. Robot. AI},
  title        = {Reinforcement learning with human advice: A survey},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Towards a blockchain-based multi-UAV surveillance system.
<em>FROBT</em>, <em>8</em>, 557692. (<a
href="https://doi.org/10.3389/frobt.2021.557692">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study describes a blockchain-based multi-unmanned aerial vehicle (multi-UAV) surveillance framework that enables UAV coordination and financial exchange between system users. The objective of the system is to allow a set of Points-Of-Interest (POI) to be surveyed by a set of autonomous UAVs that cooperate to minimize the time between successive visits while exhibiting unpredictable behavior to prevent external agents from learning their movements. The system can be seen as a marketplace where the UAVs are the service providers and the POIs are the service seekers. This concept is based on a blockchain embedded on the UAVs and on some nodes on the ground, which has two main functionalities. The first one is to plan the route of each UAV through an efficient and computationally cheap game-theoretic decision algorithm implemented into a smart contract. The second one is to allow financial transactions between the system and its users, where the POIs subscribe to surveillance services by buying tokens. Conversely, the system pays the UAVs in tokens for the provided services. The first benchmarking experiments show that the IOTA blockchain is a potential blockchain candidate to be integrated in the UAV embedded system and that the chosen decentralized decision-making coordination strategy is efficient enough to fill the mission requirements while being computationally light.},
  archive      = {J_FROBT},
  author       = {Santos De Campos, Mário Gabriel and Chanel, Caroline P. C. and Chauffaut, Corentin and Lacan, Jérôme},
  doi          = {10.3389/frobt.2021.557692},
  journal      = {Frontiers in Robotics and AI},
  month        = {6},
  pages        = {557692},
  shortjournal = {Front. Robot. AI},
  title        = {Towards a blockchain-based multi-UAV surveillance system},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A holistic approach to human-supervised humanoid robot
operations in extreme environments. <em>FROBT</em>, <em>8</em>, 550644.
(<a href="https://doi.org/10.3389/frobt.2021.550644">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nuclear energy will play a critical role in meeting clean energy targets worldwide. However, nuclear environments are dangerous for humans to operate in due to the presence of highly radioactive materials. Robots can help address this issue by allowing remote access to nuclear and other highly hazardous facilities under human supervision to perform inspection and maintenance tasks during normal operations, help with clean-up missions, and aid in decommissioning. This paper presents our research to help realize humanoid robots in supervisory roles in nuclear environments. Our research focuses on National Aeronautics and Space Administration (NASA’s) humanoid robot, Valkyrie, in the areas of constrained manipulation and motion planning, increasing stability using support contact, dynamic non-prehensile manipulation, locomotion on deformable terrains, and human-in-the-loop control interfaces.},
  archive      = {J_FROBT},
  author       = {Wonsick, Murphy and Long, Philip and Önol, Aykut Özgün and Wang, Maozhen and Padır, Taşkın},
  doi          = {10.3389/frobt.2021.550644},
  journal      = {Frontiers in Robotics and AI},
  month        = {6},
  pages        = {550644},
  shortjournal = {Front. Robot. AI},
  title        = {A holistic approach to human-supervised humanoid robot operations in extreme environments},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A mirror-based active vision system for underwater robots:
From the design to active object tracking application. <em>FROBT</em>,
<em>8</em>, 542717. (<a
href="https://doi.org/10.3389/frobt.2021.542717">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A mirror-based active system capable of changing the view’s direction of a pre-existing fixed camera is presented. The aim of this research work is to extend the perceptual tracking capabilities of an underwater robot without altering its structure. The ability to control the view’s direction allows the robot to explore its entire surroundings without any actual displacement, which can be useful for more effective motion planning and for different navigation strategies, such as object tracking and/or obstacle evasion, which are of great importance for natural preservation in environments as complex and fragile as coral reefs. Active vision systems based on mirrors had been used mainly in terrestrial platforms to capture the motion of fast projectiles using high-speed cameras of considerable size and weight, but they had not been used on underwater platforms. In this sense, our approach incorporates a lightweight design adapted to an underwater robot using affordable and easy-access technology (i.e., 3D printing). Our active system consists of two arranged mirrors, one of which remains static in front of the robot’s camera, while the orientation of the second mirror is controlled by two servomotors. Object tracking is performed by using only the pixels contained on the homography of a defined area in the active mirror. HSV color space is used to reduce lighting change effects. Since color and geometry information of the tracking object are previously known, a window filter is applied over the H-channel for color blobs detection, then, noise is filtered and the object’s centroid is estimated. If the object is lost, a Kalman filter is applied to predict its position. Finally, with this information, an image PD controller computes the servomotor articular values. We have carried out experiments in real environments, testing our active vision system in an object-tracking application where an artificial object is manually displaced on the periphery of the robot and the mirror system is automatically reconfigured to keep such object focused by the camera, having satisfactory results in real time for detecting objects of low complexity and in poor lighting conditions.},
  archive      = {J_FROBT},
  author       = {Cortés-Pérez, Noel and Torres-Méndez, Luz Abril},
  doi          = {10.3389/frobt.2021.542717},
  journal      = {Frontiers in Robotics and AI},
  month        = {6},
  pages        = {542717},
  shortjournal = {Front. Robot. AI},
  title        = {A mirror-based active vision system for underwater robots: From the design to active object tracking application},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Using tactile sensing to improve the sample efficiency and
performance of deep deterministic policy gradients for simulated in-hand
manipulation tasks. <em>FROBT</em>, <em>8</em>, 538773. (<a
href="https://doi.org/10.3389/frobt.2021.538773">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep Reinforcement Learning techniques demonstrate advances in the domain of robotics. One of the limiting factors is a large number of interaction samples usually required for training in simulated and real-world environments. In this work, we demonstrate for a set of simulated dexterous in-hand object manipulation tasks that tactile information can substantially increase sample efficiency for training (by up to more than threefold). We also observe an improvement in performance (up to 46%) after adding tactile information. To examine the role of tactile-sensor parameters in these improvements, we included experiments with varied sensor-measurement accuracy (ground truth continuous values, noisy continuous values, Boolean values), and varied spatial resolution of the tactile sensors (927 sensors, 92 sensors, and 16 pooled sensor areas in the hand). To facilitate further studies and comparisons, we make these touch-sensor extensions available as a part of the OpenAI Gym Shadow-Dexterous-Hand robotics environments.},
  archive      = {J_FROBT},
  author       = {Melnik, Andrew and Lach, Luca and Plappert, Matthias and Korthals, Timo and Haschke, Robert and Ritter, Helge},
  doi          = {10.3389/frobt.2021.538773},
  journal      = {Frontiers in Robotics and AI},
  month        = {6},
  pages        = {538773},
  shortjournal = {Front. Robot. AI},
  title        = {Using tactile sensing to improve the sample efficiency and performance of deep deterministic policy gradients for simulated in-hand manipulation tasks},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Editorial: Recent trends in morphological computation.
<em>FROBT</em>, <em>8</em>, 708206. (<a
href="https://doi.org/10.3389/frobt.2021.708206">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Ghazi-Zahedi, Keyan and Rieffel, John and Schmitt, Syn and Hauser, Helmut},
  doi          = {10.3389/frobt.2021.708206},
  journal      = {Frontiers in Robotics and AI},
  month        = {5},
  pages        = {708206},
  shortjournal = {Front. Robot. AI},
  title        = {Editorial: Recent trends in morphological computation},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Editorial: Advances in modeling and control of soft robots.
<em>FROBT</em>, <em>8</em>, 706514. (<a
href="https://doi.org/10.3389/frobt.2021.706514">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Monje Micharet, Concepción Alicia and Laschi, Cecilia},
  doi          = {10.3389/frobt.2021.706514},
  journal      = {Frontiers in Robotics and AI},
  month        = {5},
  pages        = {706514},
  shortjournal = {Front. Robot. AI},
  title        = {Editorial: Advances in modeling and control of soft robots},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Editorial: ViTac: Integrating vision and touch for
multimodal and cross-modal perception. <em>FROBT</em>, <em>8</em>,
697601. (<a href="https://doi.org/10.3389/frobt.2021.697601">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Luo, Shan and Lepora, Nathan F. and Martinez-Hernandez, Uriel and Bimbo, Joao and Liu, Huaping},
  doi          = {10.3389/frobt.2021.697601},
  journal      = {Frontiers in Robotics and AI},
  month        = {5},
  pages        = {697601},
  shortjournal = {Front. Robot. AI},
  title        = {Editorial: ViTac: integrating vision and touch for multimodal and cross-modal perception},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Corrigendum: Deep learning-based haptic guidance for
surgical skills transfer. <em>FROBT</em>, <em>8</em>, 691570. (<a
href="https://doi.org/10.3389/frobt.2021.691570">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Fekri, Pedram and Dargahi, Javad and Zadeh, Mehrdad},
  doi          = {10.3389/frobt.2021.691570},
  journal      = {Frontiers in Robotics and AI},
  month        = {5},
  pages        = {691570},
  shortjournal = {Front. Robot. AI},
  title        = {Corrigendum: Deep learning-based haptic guidance for surgical skills transfer},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Behavioral biometric data analysis for gender classification
using feature fusion and machine learning. <em>FROBT</em>, <em>8</em>,
685966. (<a href="https://doi.org/10.3389/frobt.2021.685966">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Biometric security applications have been employed for providing a higher security in several access control systems during the past few years. The handwritten signature is the most widely accepted behavioral biometric trait for authenticating the documents like letters, contracts, wills, MOU’s, etc. for validation in day to day life. In this paper, a novel algorithm to detect gender of individuals based on the image of their handwritten signatures is proposed. The proposed work is based on the fusion of textural and statistical features extracted from the signature images. The LBP and HOG features represent the texture. The writer’s gender classification is carried out using machine learning techniques. The proposed technique is evaluated on own dataset of 4,790 signatures and realized an encouraging accuracy of 96.17, 98.72 and 100% for k-NN, decision tree and Support Vector Machine classifiers, respectively. The proposed method is expected to be useful in design of efficient computer vision tools for authentication and forensic investigation of documents with handwritten signatures.},
  archive      = {J_FROBT},
  author       = {Gornale, Shivanand S. and Kumar, Sathish and Patil, Abhijit and Hiremath, Prakash S.},
  doi          = {10.3389/frobt.2021.685966},
  journal      = {Frontiers in Robotics and AI},
  month        = {5},
  pages        = {685966},
  shortjournal = {Front. Robot. AI},
  title        = {Behavioral biometric data analysis for gender classification using feature fusion and machine learning},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Light-driven crystal–polymer hybrid actuators.
<em>FROBT</em>, <em>8</em>, 684287. (<a
href="https://doi.org/10.3389/frobt.2021.684287">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, soft robots, which are made of soft and light organic materials, have attracted much attention because of improved safety for daily interactions with humans. Mechanically responsive materials that can move macroscopically by external stimuli, such as light and heat, have been studied extensively over the past two decades, and they are expected to be applicable to soft robots. Among them, mechanically responsive crystals are attractive in terms of a larger Young’s modulus and faster response speed compared with polymers and gels. However, it is impractical to use one piece of a single crystal as a crystal machine; it is difficult to control the size of crystals and obtain large crystals. Hybridization of crystals with polymers is one way to create actuators with more realistic movements. Herein, we report a hybrid crystal assembly in which plate-like salicylideneaniline crystals are aligned in polymer films by a “rubbing” technique, a new approach which is inexpensive, easy, and applicable to a wide range of crystals and polymers. The hybrid films bent reversibly upon alternate irradiation with ultraviolet and visible light. The hybrid films bent as fast as single crystals, even when larger than single-crystal size, showing great mechanical performance originating from the advantages of both molecular crystals (fast response time) and polymers (large size). This work enriches the development of light-driven hybrid actuators composed of molecular crystals and polymers.},
  archive      = {J_FROBT},
  author       = {Hasebe, Shodai and Matsuura, Daisuke and Mizukawa, Takaaki and Asahi, Toru and Koshima, Hideko},
  doi          = {10.3389/frobt.2021.684287},
  journal      = {Frontiers in Robotics and AI},
  month        = {5},
  pages        = {684287},
  shortjournal = {Front. Robot. AI},
  title        = {Light-driven Crystal–Polymer hybrid actuators},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Do shy preschoolers interact differently when learning
language with a social robot? An analysis of interactional behavior and
word learning. <em>FROBT</em>, <em>8</em>, 676123. (<a
href="https://doi.org/10.3389/frobt.2021.676123">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Temperamental traits can decisively influence how children enter into social interaction with their environment. Yet, in the field of child–robot interaction, little is known about how individual differences such as shyness impact on how children interact with social robots in educational settings. The present study systematically assessed the temperament of 28 preschool children aged 4–5 years in order to investigate the role of shyness within a dyadic child–robot interaction. Over the course of four consecutive sessions, we observed how shy compared to nonshy children interacted with a social robot during a word-learning educational setting and how shyness influenced children’s learning outcomes. Overall, results suggested that shy children not only interacted differently with a robot compared to nonshy children, but also changed their behavior over the course of the sessions. Critically, shy children interacted less expressively with the robot in general. With regard to children’s language learning outcomes, shy children scored lower on an initial posttest, but were able to close this gap on a later test, resulting in all children retrieving the learned words on a similar level. When intertest learning gain was considered, regression analyses even confirmed a positive predictive role of shyness on language learning gains. Findings are discussed with regard to the role of shyness in educational settings with social robots and the implications for future interaction design.},
  archive      = {J_FROBT},
  author       = {Tolksdorf, Nils F. and Viertel, Franziska E. and Rohlfing, Katharina J.},
  doi          = {10.3389/frobt.2021.676123},
  journal      = {Frontiers in Robotics and AI},
  month        = {5},
  pages        = {676123},
  shortjournal = {Front. Robot. AI},
  title        = {Do shy preschoolers interact differently when learning language with a social robot? an analysis of interactional behavior and word learning},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Soft adaptive mechanical metamaterials. <em>FROBT</em>,
<em>8</em>, 673478. (<a
href="https://doi.org/10.3389/frobt.2021.673478">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Soft materials are inherently flexible and make suitable candidates for soft robots intended for specific tasks that would otherwise not be achievable (e.g., smart grips capable of picking up objects without prior knowledge of their stiffness). Moreover, soft robots exploit the mechanics of their fundamental building blocks and aim to provide targeted functionality without the use of electronics or wiring. Despite recent progress, locomotion in soft robotics applications has remained a relatively young field with open challenges yet to overcome. Justly, harnessing structural instabilities and utilizing bistable actuators have gained importance as a solution. This report focuses on substrate-free reconfigurable structures composed of multistable unit cells with a nonconvex strain energy potential, which can exhibit structural transitions and produce strongly nonlinear transition waves. The energy released during the transition, if sufficient, balances the dissipation and kinetic energy of the system and forms a wave front that travels through the structure to effect its permanent or reversible reconfiguration. We exploit a triangular unit cell’s design space and provide general guidelines for unit cell selection. Using a continuum description, we predict and map the resulting structure’s behavior for various geometric and material properties. The structural motion created by these strongly nonlinear metamaterials has potential applications in propulsion in soft robotics, morphing surfaces, reconfigurable devices, mechanical logic, and controlled energy absorption.},
  archive      = {J_FROBT},
  author       = {Khajehtourian, Romik and Kochmann, Dennis M.},
  doi          = {10.3389/frobt.2021.673478},
  journal      = {Frontiers in Robotics and AI},
  month        = {5},
  pages        = {673478},
  shortjournal = {Front. Robot. AI},
  title        = {Soft adaptive mechanical metamaterials},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Handover control for human-robot and robot-robot
collaboration. <em>FROBT</em>, <em>8</em>, 672995. (<a
href="https://doi.org/10.3389/frobt.2021.672995">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modern scenarios in robotics involve human-robot collaboration or robot-robot cooperation in unstructured environments. In human-robot collaboration, the objective is to relieve humans from repetitive and wearing tasks. This is the case of a retail store, where the robot could help a clerk to refill a shelf or an elderly customer to pick an item from an uncomfortable location. In robot-robot cooperation, automated logistics scenarios, such as warehouses, distribution centers and supermarkets, often require repetitive and sequential pick and place tasks that can be executed more efficiently by exchanging objects between robots, provided that they are endowed with object handover ability. Use of a robot for passing objects is justified only if the handover operation is sufficiently intuitive for the involved humans, fluid and natural, with a speed comparable to that typical of a human-human object exchange. The approach proposed in this paper strongly relies on visual and haptic perception combined with suitable algorithms for controlling both robot motion, to allow the robot to adapt to human behavior, and grip force, to ensure a safe handover. The control strategy combines model-based reactive control methods with an event-driven state machine encoding a human-inspired behavior during a handover task, which involves both linear and torsional loads, without requiring explicit learning from human demonstration. Experiments in a supermarket-like environment with humans and robots communicating only through haptic cues demonstrate the relevance of force/tactile feedback in accomplishing handover operations in a collaborative task.},
  archive      = {J_FROBT},
  author       = {Costanzo, Marco and De Maria, Giuseppe and Natale, Ciro},
  doi          = {10.3389/frobt.2021.672995},
  journal      = {Frontiers in Robotics and AI},
  month        = {5},
  pages        = {672995},
  shortjournal = {Front. Robot. AI},
  title        = {Handover control for human-robot and robot-robot collaboration},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Optimization of phase-change material–elastomer composite
and integration in kirigami-inspired voxel-based actuators.
<em>FROBT</em>, <em>8</em>, 672934. (<a
href="https://doi.org/10.3389/frobt.2021.672934">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Phase-change material–elastomer composite (PCMEC) actuators are composed of a soft elastomer matrix embedding a phase-change fluid, typically ethanol, in microbubbles. When increasing the temperature, the phase change in each bubble induces a macroscopic expansion of the matrix. This class of actuators is promising for soft robotic applications because of their high energy density and actuation strain, and their low cost and easy manufacturing. However, several limitations must be addressed, such as the high actuation temperature and slow actuation speed. Moreover, the lack of a consistent design approach limits the possibility to build PCMEC-based soft robots able to achieve complex tasks. In this work, a new approach to manufacture PCMEC actuators with different fluid–elastomer combinations without altering the quality of the samples is proposed. The influence of the phase-change fluid and the elastomer on free elongation and bending is investigated. We demonstrate that choosing an appropriate fluid increases the actuation strain and speed, and decreases the actuation temperature compared with ethanol, allowing PCMECs to be used in close contact with the human body. Similarly, by using different elastomer materials, the actuator stiffness can be modified, and the experimental results showed that the curvature is roughly proportional to the inverse of Young’s modulus of the pure matrix. To demonstrate the potential of the optimized PCMECs, a kirigami-inspired voxel-based design approach is proposed. PCMEC cubes are molded and reinforced externally by paper. Cuts in the paper induce anisotropy into the structure. Elementary voxels deforming according to the basic kinematics (bending, torsion, elongation, compression and shear) are presented. The combination of these voxels into modular and reconfigurable structures could open new possibilities towards the design of flexible robots able to perform complex tasks.},
  archive      = {J_FROBT},
  author       = {Decroly, Gilles and Raffoul, Romain and Deslypere, Clara and Leroy, Paul and Van Hove, Louis and Delchambre, Alain and Lambert, Pierre},
  doi          = {10.3389/frobt.2021.672934},
  journal      = {Frontiers in Robotics and AI},
  month        = {5},
  pages        = {672934},
  shortjournal = {Front. Robot. AI},
  title        = {Optimization of phase-change Material–Elastomer composite and integration in kirigami-inspired voxel-based actuators},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). From warranty voids to uprising advocacy: Human action and
the perceived moral patiency of social robots. <em>FROBT</em>,
<em>8</em>, 670503. (<a
href="https://doi.org/10.3389/frobt.2021.670503">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Moral status can be understood along two dimensions: moral agency [capacities to be and do good (or bad)] and moral patiency (extents to which entities are objects of moral concern), where the latter especially has implications for how humans accept or reject machine agents into human social spheres. As there is currently limited understanding of how people innately understand and imagine the moral patiency of social robots, this study inductively explores key themes in how robots may be subject to humans’ (im)moral action across 12 valenced foundations in the moral matrix: care/harm, fairness/unfairness, loyalty/betrayal, authority/subversion, purity/degradation, liberty/oppression. Findings indicate that people can imagine clear dynamics by which anthropomorphic, zoomorphic, and mechanomorphic robots may benefit and suffer at the hands of humans (e.g., affirmations of personhood, compromising bodily integrity, veneration as gods, corruption by physical or information interventions). Patterns across the matrix are interpreted to suggest that moral patiency may be a function of whether people diminish or uphold the ontological boundary between humans and machines, though even moral upholdings bare notes of utilitarianism.},
  archive      = {J_FROBT},
  author       = {Banks, Jaime},
  doi          = {10.3389/frobt.2021.670503},
  journal      = {Frontiers in Robotics and AI},
  month        = {5},
  pages        = {670503},
  shortjournal = {Front. Robot. AI},
  title        = {From warranty voids to uprising advocacy: Human action and the perceived moral patiency of social robots},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Body-mounted robotic system for MRI-guided shoulder
arthrography: Cadaver and clinical workflow studies. <em>FROBT</em>,
<em>8</em>, 667121. (<a
href="https://doi.org/10.3389/frobt.2021.667121">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents an intraoperative MRI-guided, patient-mounted robotic system for shoulder arthrography procedures in pediatric patients. The robot is designed to be compact and lightweight and is constructed with nonmagnetic materials for MRI safety. Our goal is to transform the current two-step arthrography procedure (CT/x-ray-guided needle insertion followed by diagnostic MRI) into a streamlined single-step ionizing radiation-free procedure under MRI guidance. The MR-conditional robot was evaluated in a Thiel embalmed cadaver study and healthy volunteer studies. The robot was attached to the shoulder using straps and ten locations in the shoulder joint space were selected as targets. For the first target, contrast agent (saline) was injected to complete the clinical workflow. After each targeting attempt, a confirmation scan was acquired to analyze the needle placement accuracy. During the volunteer studies, a more comfortable and ergonomic shoulder brace was used, and the complete clinical workflow was followed to measure the total procedure time. In the cadaver study, the needle was successfully placed in the shoulder joint space in all the targeting attempts with translational and rotational accuracy of 2.07 ± 1.22 mm and 1.46 ± 1.06 degrees, respectively. The total time for the entire procedure was 94 min and the average time for each targeting attempt was 20 min in the cadaver study, while the average time for the entire workflow for the volunteer studies was 36 min. No image quality degradation due to the presence of the robot was detected. This Thiel-embalmed cadaver study along with the clinical workflow studies on human volunteers demonstrated the feasibility of using an MR-conditional, patient-mounted robotic system for MRI-guided shoulder arthrography procedure. Future work will be focused on moving the technology to clinical practice.},
  archive      = {J_FROBT},
  author       = {Patel, Niravkumar and Yan, Jiawen and Li, Gang and Monfaredi, Reza and Priba, Lukasz and Donald-Simpson, Helen and Joy, Joyce and Dennison, Andrew and Melzer, Andreas and Sharma, Karun and Iordachita, Iulian and Cleary, Kevin},
  doi          = {10.3389/frobt.2021.667121},
  journal      = {Frontiers in Robotics and AI},
  month        = {5},
  pages        = {667121},
  shortjournal = {Front. Robot. AI},
  title        = {Body-mounted robotic system for MRI-guided shoulder arthrography: Cadaver and clinical workflow studies},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An origami-based soft robotic actuator for upper
gastrointestinal endoscopic applications. <em>FROBT</em>, <em>8</em>,
664720. (<a href="https://doi.org/10.3389/frobt.2021.664720">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Soft pneumatic actuators have been explored for endoscopic applications, but challenges in fabricating complex geometry with desirable dimensions and compliance remain. The addition of an endoscopic camera or tool channel is generally not possible without significant change in the diameter of the actuator. Radial expansion and ballooning of actuator walls during bending is undesirable for endoscopic applications. The inclusion of strain limiting methods like, wound fibre, mesh, or multi-material molding have been explored, but the integration of these design approaches with endoscopic requirements drastically increases fabrication complexity, precluding reliable translation into functional endoscopes. For the first time in soft robotics, we present a multi-channel, single material elastomeric actuator with a fully corrugated design (inspired by origami); offering specific functionality for endoscopic applications. The features introduced in this design include i) fabrication of multi-channel monolithic structure of 8.5 mm diameter, ii) incorporation of the benefits of corrugated design in a single material (i.e., limited radial expansion and improved bending efficiency), iii) design scalability (length and diameter), and iv) incorporation of a central hollow channel for the inclusion of an endoscopic camera. Two variants of the actuator are fabricated which have different corrugated or origami length, i.e., 30 mm and 40 mm respectively). Each of the three actuator channels is evaluated under varying volumetric (0.5 mls-1 and 1.5 mls-1 feed rate) and pressurized control to achieve a similar bending profile with the maximum bending angle of 150°. With the intended use for single use upper gastrointestinal endoscopic application, it is desirable to have linear relationships between actuation and angular position in soft pneumatic actuators with high bending response at low pressures; this is where the origami actuator offers contribution. The soft pneumatic actuator has been demonstrated to achieve a maximum bending angle of 200° when integrated with manually driven endoscope. The simple 3-step fabrication technique produces a complex origami pattern in a soft robotic structure, which promotes low pressure bending through the opening of the corrugation while retaining a small diameter and a central lumen, required for successful endoscope integration.},
  archive      = {J_FROBT},
  author       = {Chauhan, Manish and Chandler, James H. and Jha, Animesh and Subramaniam, Venkataraman and Obstein, Keith L. and Valdastri, Pietro},
  doi          = {10.3389/frobt.2021.664720},
  journal      = {Frontiers in Robotics and AI},
  month        = {5},
  pages        = {664720},
  shortjournal = {Front. Robot. AI},
  title        = {An origami-based soft robotic actuator for upper gastrointestinal endoscopic applications},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Radar-to-lidar: Heterogeneous place recognition via joint
learning. <em>FROBT</em>, <em>8</em>, 661199. (<a
href="https://doi.org/10.3389/frobt.2021.661199">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Place recognition is critical for both offline mapping and online localization. However, current single-sensor based place recognition still remains challenging in adverse conditions. In this paper, a heterogeneous measurement based framework is proposed for long-term place recognition, which retrieves the query radar scans from the existing lidar (Light Detection and Ranging) maps. To achieve this, a deep neural network is built with joint training in the learning stage, and then in the testing stage, shared embeddings of radar and lidar are extracted for heterogeneous place recognition. To validate the effectiveness of the proposed method, we conducted tests and generalization experiments on the multi-session public datasets and compared them to other competitive methods. The experimental results indicate that our model is able to perform multiple place recognitions: lidar-to-lidar (L2L), radar-to-radar (R2R), and radar-to-lidar (R2L), while the learned model is trained only once. We also release the source code publicly: https://github.com/ZJUYH/radar-to-lidar-place-recognition.},
  archive      = {J_FROBT},
  author       = {Yin, Huan and Xu, Xuecheng and Wang, Yue and Xiong, Rong},
  doi          = {10.3389/frobt.2021.661199},
  journal      = {Frontiers in Robotics and AI},
  month        = {5},
  pages        = {661199},
  shortjournal = {Front. Robot. AI},
  title        = {Radar-to-lidar: Heterogeneous place recognition via joint learning},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Human–co-bot interaction and neuroergonomics: Co-botic
vs. Robotic systems. <em>FROBT</em>, <em>8</em>, 659319. (<a
href="https://doi.org/10.3389/frobt.2021.659319">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Cassioli, Federico and Fronda, Giulia and Balconi, Michela},
  doi          = {10.3389/frobt.2021.659319},
  journal      = {Frontiers in Robotics and AI},
  month        = {5},
  pages        = {659319},
  shortjournal = {Front. Robot. AI},
  title        = {Human–Co-bot interaction and neuroergonomics: Co-botic vs. robotic systems},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Using first principles for deep learning and model-based
control of soft robots. <em>FROBT</em>, <em>8</em>, 654398. (<a
href="https://doi.org/10.3389/frobt.2021.654398">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Model-based optimal control of soft robots may enable compliant, underdamped platforms to operate in a repeatable fashion and effectively accomplish tasks that are otherwise impossible for soft robots. Unfortunately, developing accurate analytical dynamic models for soft robots is time-consuming, difficult, and error-prone. Deep learning presents an alternative modeling approach that only requires a time history of system inputs and system states, which can be easily measured or estimated. However, fully relying on empirical or learned models involves collecting large amounts of representative data from a soft robot in order to model the complex state space–a task which may not be feasible in many situations. Furthermore, the exclusive use of empirical models for model-based control can be dangerous if the model does not generalize well. To address these challenges, we propose a hybrid modeling approach that combines machine learning methods with an existing first-principles model in order to improve overall performance for a sampling-based non-linear model predictive controller. We validate this approach on a soft robot platform and demonstrate that performance improves by 52% on average when employing the combined model.},
  archive      = {J_FROBT},
  author       = {Johnson, Curtis C. and Quackenbush, Tyler and Sorensen, Taylor and Wingate, David and Killpack, Marc D.},
  doi          = {10.3389/frobt.2021.654398},
  journal      = {Frontiers in Robotics and AI},
  month        = {5},
  pages        = {654398},
  shortjournal = {Front. Robot. AI},
  title        = {Using first principles for deep learning and model-based control of soft robots},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Adaptive cognitive mechanisms to maintain calibrated trust
and reliance in automation. <em>FROBT</em>, <em>8</em>, 652776. (<a
href="https://doi.org/10.3389/frobt.2021.652776">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Trust calibration for a human–machine team is the process by which a human adjusts their expectations of the automation’s reliability and trustworthiness; adaptive support for trust calibration is needed to engender appropriate reliance on automation. Herein, we leverage an instance-based learning ACT-R cognitive model of decisions to obtain and rely on an automated assistant for visual search in a UAV interface. This cognitive model matches well with the human predictive power statistics measuring reliance decisions; we obtain from the model an internal estimate of automation reliability that mirrors human subjective ratings. The model is able to predict the effect of various potential disruptions, such as environmental changes or particular classes of adversarial intrusions on human trust in automation. Finally, we consider the use of model predictions to improve automation transparency that account for human cognitive biases in order to optimize the bidirectional interaction between human and machine through supporting trust calibration. The implications of our findings for the design of reliable and trustworthy automation are discussed.},
  archive      = {J_FROBT},
  author       = {Lebiere, Christian and Blaha, Leslie M. and Fallon, Corey K. and Jefferson, Brett},
  doi          = {10.3389/frobt.2021.652776},
  journal      = {Frontiers in Robotics and AI},
  month        = {5},
  pages        = {652776},
  shortjournal = {Front. Robot. AI},
  title        = {Adaptive cognitive mechanisms to maintain calibrated trust and reliance in automation},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Modelling the impact of robotics on infectious spread among
healthcare workers. <em>FROBT</em>, <em>8</em>, 652685. (<a
href="https://doi.org/10.3389/frobt.2021.652685">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Coronavirus disease 2019 (Covid-19) pandemic has brought the world to a standstill. Healthcare systems are critical to maintain during pandemics, however, providing service to sick patients has posed a hazard to frontline healthcare workers (HCW) and particularly those caring for elderly patients. Various approaches are investigated to improve safety for HCW and patients. One promising avenue is the use of robots. Here, we model infectious spread based on real spatio-temporal precise personal interactions from a geriatric unit and test different scenarios of robotic integration. We find a significant mitigation of contamination rates when robots specifically replace a moderate fraction of high-risk healthcare workers, who have a high number of contacts with patients and other HCW. While the impact of robotic integration is significant across a range of reproductive number R0, the largest effect is seen when R0 is slightly above its critical value. Our analysis suggests that a moderate-sized robotic integration can represent an effective measure to significantly reduce the spread of pathogens with Covid-19 transmission characteristics in a small hospital unit.},
  archive      = {J_FROBT},
  author       = {Vicente, Raul and Mohamed, Youssef and Eguíluz, Victor M. and Zemmar, Emal and Bayer, Patrick and Neimat, Joseph S. and Hernesniemi, Juha and Nelson, Bradley J. and Zemmar, Ajmal},
  doi          = {10.3389/frobt.2021.652685},
  journal      = {Frontiers in Robotics and AI},
  month        = {5},
  pages        = {652685},
  shortjournal = {Front. Robot. AI},
  title        = {Modelling the impact of robotics on infectious spread among healthcare workers},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Symptom-based identification of g-4 chili leaf diseases
based on rotation invariant. <em>FROBT</em>, <em>8</em>, 650134. (<a
href="https://doi.org/10.3389/frobt.2021.650134">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Instinctive detection of infections by carefully inspecting the signs on the plant leaves is an easier and economic way to diagnose different plant leaf diseases. This defines a way in which symptoms of diseased plants are detected utilizing the concept of feature learning (Sulistyo et al., 2020). The physical method of detecting and analyzing diseases takes a lot of time and has chances of making many errors (Sulistyo et al., 2020). So a method has been developed to identify the symptoms by just acquiring the chili plant leaf image. The methodology used involves image database, extracting the region of interest, training and testing images, symptoms/features extraction of the plant image using moments, building of the symptom vector feature dataset, and finding the correlation and similarity between different symptoms of the plant (Sulistyo et al., 2020). This will detect different diseases of the plant.},
  archive      = {J_FROBT},
  author       = {Das Chagas Silva Araujo, Sufola and Malemath, V. S. and Sundaram, K. Meenakshi},
  doi          = {10.3389/frobt.2021.650134},
  journal      = {Frontiers in Robotics and AI},
  month        = {5},
  pages        = {650134},
  shortjournal = {Front. Robot. AI},
  title        = {Symptom-based identification of G-4 chili leaf diseases based on rotation invariant},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A benchmark environment for neuromorphic stereo vision.
<em>FROBT</em>, <em>8</em>, 647634. (<a
href="https://doi.org/10.3389/frobt.2021.647634">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Without neuromorphic hardware, artificial stereo vision suffers from high resource demands and processing times impeding real-time capability. This is mainly caused by high frame rates, a quality feature for conventional cameras, generating large amounts of redundant data. Neuromorphic visual sensors generate less redundant and more relevant data solving the issue of over- and undersampling at the same time. However, they require a rethinking of processing as established techniques in conventional stereo vision do not exploit the potential of their event-based operation principle. Many alternatives have been recently proposed which have yet to be evaluated on a common data basis. We propose a benchmark environment offering the methods and tools to compare different algorithms for depth reconstruction from two event-based sensors. To this end, an experimental setup consisting of two event-based and one depth sensor as well as a framework enabling synchronized, calibrated data recording is presented. Furthermore, we define metrics enabling a meaningful comparison of the examined algorithms, covering aspects such as performance, precision and applicability. To evaluate the benchmark, a stereo matching algorithm was implemented as a testing candidate and multiple experiments with different settings and camera parameters have been carried out. This work is a foundation for a robust and flexible evaluation of the multitude of new techniques for event-based stereo vision, allowing a meaningful comparison.},
  archive      = {J_FROBT},
  author       = {Steffen, L. and Elfgen, M. and Ulbrich, S. and Roennau, A. and Dillmann, R.},
  doi          = {10.3389/frobt.2021.647634},
  journal      = {Frontiers in Robotics and AI},
  month        = {5},
  pages        = {647634},
  shortjournal = {Front. Robot. AI},
  title        = {A benchmark environment for neuromorphic stereo vision},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Autonomous robotic point-of-care ultrasound imaging for
monitoring of COVID-19–induced pulmonary diseases. <em>FROBT</em>,
<em>8</em>, 645756. (<a
href="https://doi.org/10.3389/frobt.2021.645756">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The COVID-19 pandemic has emerged as a serious global health crisis, with the predominant morbidity and mortality linked to pulmonary involvement. Point-of-Care ultrasound (POCUS) scanning, becoming one of the primary determinative methods for its diagnosis and staging, requires, however, close contact of healthcare workers with patients, therefore increasing the risk of infection. This work thus proposes an autonomous robotic solution that enables POCUS scanning of COVID-19 patients’ lungs for diagnosis and staging. An algorithm was developed for approximating the optimal position of an ultrasound probe on a patient from prior CT scans to reach predefined lung infiltrates. In the absence of prior CT scans, a deep learning method was developed for predicting 3D landmark positions of a human ribcage given a torso surface model. The landmarks, combined with the surface model, are subsequently used for estimating optimal ultrasound probe position on the patient for imaging infiltrates. These algorithms, combined with a force–displacement profile collection methodology, enabled the system to successfully image all points of interest in a simulated experimental setup with an average accuracy of 20.6 ± 14.7 mm using prior CT scans, and 19.8 ± 16.9 mm using only ribcage landmark estimation. A study on a full torso ultrasound phantom showed that autonomously acquired ultrasound images were 100% interpretable when using force feedback with prior CT and 88% with landmark estimation, compared to 75 and 58% without force feedback, respectively. This demonstrates the preliminary feasibility of the system, and its potential for offering a solution to help mitigate the spread of COVID-19 in vulnerable environments.},
  archive      = {J_FROBT},
  author       = {Al-Zogbi, Lidia and Singh, Vivek and Teixeira, Brian and Ahuja, Avani and Bagherzadeh, Pooyan Sahbaee and Kapoor, Ankur and Saeidi, Hamed and Fleiter, Thorsten and Krieger, Axel},
  doi          = {10.3389/frobt.2021.645756},
  journal      = {Frontiers in Robotics and AI},
  month        = {5},
  pages        = {645756},
  shortjournal = {Front. Robot. AI},
  title        = {Autonomous robotic point-of-care ultrasound imaging for monitoring of COVID-19–Induced pulmonary diseases},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Activity, plan, and goal recognition: A review.
<em>FROBT</em>, <em>8</em>, 643010. (<a
href="https://doi.org/10.3389/frobt.2021.643010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recognizing the actions, plans, and goals of a person in an unconstrained environment is a key feature that future robotic systems will need in order to achieve a natural human-machine interaction. Indeed, we humans are constantly understanding and predicting the actions and goals of others, which allows us to interact in intuitive and safe ways. While action and plan recognition are tasks that humans perform naturally and with little effort, they are still an unresolved problem from the point of view of artificial intelligence. The immense variety of possible actions and plans that may be encountered in an unconstrained environment makes current approaches be far from human-like performance. In addition, while very different types of algorithms have been proposed to tackle the problem of activity, plan, and goal (intention) recognition, these tend to focus in only one part of the problem (e.g., action recognition), and techniques that address the problem as a whole have been not so thoroughly explored. This review is meant to provide a general view of the problem of activity, plan, and goal recognition as a whole. It presents a description of the problem, both from the human perspective and from the computational perspective, and proposes a classification of the main types of approaches that have been proposed to address it (logic-based, classical machine learning, deep learning, and brain-inspired), together with a description and comparison of the classes. This general view of the problem can help on the identification of research gaps, and may also provide inspiration for the development of new approaches that address the problem in a unified way.},
  archive      = {J_FROBT},
  author       = {Van-Horenbeke, Franz A. and Peer, Angelika},
  doi          = {10.3389/frobt.2021.643010},
  journal      = {Frontiers in Robotics and AI},
  month        = {5},
  pages        = {643010},
  shortjournal = {Front. Robot. AI},
  title        = {Activity, plan, and goal recognition: A review},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Mind the eyes: Artificial agents’ eye movements modulate
attentional engagement and anthropomorphic attribution. <em>FROBT</em>,
<em>8</em>, 642796. (<a
href="https://doi.org/10.3389/frobt.2021.642796">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial agents are on their way to interact with us daily. Thus, the design of embodied artificial agents that can easily cooperate with humans is crucial for their deployment in social scenarios. Endowing artificial agents with human-like behavior may boost individuals’ engagement during the interaction. We tested this hypothesis in two screen-based experiments. In the first one, we compared attentional engagement displayed by participants while they observed the same set of behaviors displayed by an avatar of a humanoid robot and a human. In the second experiment, we assessed the individuals’ tendency to attribute anthropomorphic traits towards the same agents displaying the same behaviors. The results of both experiments suggest that individuals need less effort to process and interpret an artificial agent’s behavior when it closely resembles one of a human being. Our results support the idea that including subtle hints of human-likeness in artificial agents’ behaviors would ease the communication between them and the human counterpart during interactive scenarios.},
  archive      = {J_FROBT},
  author       = {Ghiglino, Davide and Willemse, Cesco and De Tommaso, Davide and Wykowska, Agnieszka},
  doi          = {10.3389/frobt.2021.642796},
  journal      = {Frontiers in Robotics and AI},
  month        = {5},
  pages        = {642796},
  shortjournal = {Front. Robot. AI},
  title        = {Mind the eyes: Artificial agents’ eye movements modulate attentional engagement and anthropomorphic attribution},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Estimation of vibration characteristics of a space
manipulator from air bearing supported test data. <em>FROBT</em>,
<em>8</em>, 641165. (<a
href="https://doi.org/10.3389/frobt.2021.641165">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Space manipulators have attracted much attention due to their implications in on-orbit servicing in recent years. Air bearing based support equipment is widely used for ground test to offset the effect of gravity. However, an air bearing support introduces a new problem caused by additional inertial and mass properties. Additional mass and inertial load will influence the dynamics behavior, especially stiffness information and vibration response of the whole ground test system. In this paper, a set of procedures are presented to remove the influence of air bearings and identify the true equivalent joint stiffness and damping from the test data of a motor-braked space manipulator with an air bearing support. First, inertia parameters are identified. Then, the equivalent joint stiffness and damping are determined by using a genetic algorithm (GA) method. Finally, true vibration characteristics of the manipulator are estimated by removing the additional inertia caused by the air bearings. Moreover, simulations and experiments are carried out to validate the presented procedures.},
  archive      = {J_FROBT},
  author       = {Li, Haiquan and Wei, Qingqing and Liang, Jianxun and Ren, Weiyan and Tang, Zixin and Li, Delun},
  doi          = {10.3389/frobt.2021.641165},
  journal      = {Frontiers in Robotics and AI},
  month        = {5},
  pages        = {641165},
  shortjournal = {Front. Robot. AI},
  title        = {Estimation of vibration characteristics of a space manipulator from air bearing supported test data},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Moral decision making in human-agent teams: Human control
and the role of explanations. <em>FROBT</em>, <em>8</em>, 640647. (<a
href="https://doi.org/10.3389/frobt.2021.640647">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the progress of Artificial Intelligence, intelligent agents are increasingly being deployed in tasks for which ethical guidelines and moral values apply. As artificial agents do not have a legal position, humans should be held accountable if actions do not comply, implying humans need to exercise control. This is often labeled as Meaningful Human Control (MHC). In this paper, achieving MHC is addressed as a design problem, defining the collaboration between humans and agents. We propose three possible team designs (Team Design Patterns), varying in the level of autonomy on the agent’s part. The team designs include explanations given by the agent to clarify its reasoning and decision-making. The designs were implemented in a simulation of a medical triage task, to be executed by a domain expert and an artificial agent. The triage task simulates making decisions under time pressure, with too few resources available to comply with all medical guidelines all the time, hence involving moral choices. Domain experts (i.e., health care professionals) participated in the present study. One goal was to assess the ecological relevance of the simulation. Secondly, to explore the control that the human has over the agent to warrant moral compliant behavior in each proposed team design. Thirdly, to evaluate the role of agent explanations on the human’s understanding in the agent’s reasoning. Results showed that the experts overall found the task a believable simulation of what might occur in reality. Domain experts experienced control over the team’s moral compliance when consequences were quickly noticeable. When instead the consequences emerged much later, the experts experienced less control and felt less responsible. Possibly due to the experienced time pressure implemented in the task or over trust in the agent, the experts did not use explanations much during the task; when asked afterwards they however considered these to be useful. It is concluded that a team design should emphasize and support the human to develop a sense of responsibility for the agent’s behavior and for the team’s decisions. The design should include explanations that fit with the assigned team roles as well as the human cognitive state.},
  archive      = {J_FROBT},
  author       = {van der Waa, Jasper and Verdult, Sabine and van den Bosch, Karel and van Diggelen, Jurriaan and Haije, Tjalling and van der Stigchel, Birgit and Cocu, Ioana},
  doi          = {10.3389/frobt.2021.640647},
  journal      = {Frontiers in Robotics and AI},
  month        = {5},
  pages        = {640647},
  shortjournal = {Front. Robot. AI},
  title        = {Moral decision making in human-agent teams: Human control and the role of explanations},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Design optimization of a pneumatic soft robotic actuator
using model-based optimization and deep reinforcement learning.
<em>FROBT</em>, <em>8</em>, 639102. (<a
href="https://doi.org/10.3389/frobt.2021.639102">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present two frameworks for design optimization of a multi-chamber pneumatic-driven soft actuator to optimize its mechanical performance. The design goal is to achieve maximal horizontal motion of the top surface of the actuator with a minimum effect on its vertical motion. The parametric shape and layout of air chambers are optimized individually with the firefly algorithm and a deep reinforcement learning approach using both a model-based formulation and finite element analysis. The presented modeling approach extends the analytical formulations for tapered and thickened cantilever beams connected in a structure with virtual spring elements. The deep reinforcement learning-based approach is combined with both the model- and finite element-based environments to fully explore the design space and for comparison and cross-validation purposes. The two-chamber soft actuator was specifically designed to be integrated as a modular element into a soft robotic pad system used for pressure injury prevention, where local control of planar displacements can be advantageous to mitigate the risk of pressure injuries and blisters by minimizing shear forces at the skin-pad contact. A comparison of the results shows that designs achieved using the deep reinforcement based approach best decouples the horizontal and vertical motions, while producing the necessary displacement for the intended application. The results from optimizations were compared computationally and experimentally to the empirically obtained design in the existing literature to validate the optimized design and methodology.},
  archive      = {J_FROBT},
  author       = {Raeisinezhad, Mahsa and Pagliocca, Nicholas and Koohbor, Behrad and Trkov, Mitja},
  doi          = {10.3389/frobt.2021.639102},
  journal      = {Frontiers in Robotics and AI},
  month        = {5},
  pages        = {639102},
  shortjournal = {Front. Robot. AI},
  title        = {Design optimization of a pneumatic soft robotic actuator using model-based optimization and deep reinforcement learning},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Autonomous robots for space: Trajectory learning and
adaptation using imitation. <em>FROBT</em>, <em>8</em>, 638849. (<a
href="https://doi.org/10.3389/frobt.2021.638849">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper adds on to the on-going efforts to provide more autonomy to space robots and introduces the concept of programming by demonstration or imitation learning for trajectory planning of manipulators on free-floating spacecraft. A redundant 7-DoF robotic arm is mounted on small spacecraft dedicated for debris removal, on-orbit servicing and assembly, autonomous and rendezvous docking. The motion of robot (or manipulator) arm induces reaction forces on the spacecraft and hence its attitude changes prompting the Attitude Determination and Control System (ADCS) to take large corrective action. The method introduced here is capable of finding the trajectory that minimizes the attitudinal changes thereby reducing the load on ADCS. One of the critical elements in spacecraft trajectory planning and control is the power consumption. The approach introduced in this work carry out trajectory learning offline by collecting data from demonstrations and encoding it as a probabilistic distribution of trajectories. The learned trajectory distribution can be used for planning in previously unseen situations by conditioning the probabilistic distribution. Hence almost no power is required for computations after deployment. Sampling from a conditioned distribution provides several possible trajectories from the same start to goal state. To determine the trajectory that minimizes attitudinal changes, a cost term is defined and the trajectory which minimizes this cost is considered the optimal one.},
  archive      = {J_FROBT},
  author       = {Ashith Shyam, R. B. and Hao, Zhou and Montanaro, Umberto and Dixit, Shilp and Rathinam, Arunkumar and Gao, Yang and Neumann, Gerhard and Fallah, Saber},
  doi          = {10.3389/frobt.2021.638849},
  journal      = {Frontiers in Robotics and AI},
  month        = {5},
  pages        = {638849},
  shortjournal = {Front. Robot. AI},
  title        = {Autonomous robots for space: Trajectory learning and adaptation using imitation},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Combining task and motion planning: Challenges and
guidelines. <em>FROBT</em>, <em>8</em>, 637888. (<a
href="https://doi.org/10.3389/frobt.2021.637888">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Combined Task and Motion Planning (TAMP) is an area where no one-fits-all solution can exist. Many aspects of the domain, as well as operational requirements, have an effect on how algorithms and representations are designed. Frequently, trade-offs have to be made to build a system that is effective. We propose five research questions that we believe need to be answered to solve real-world problems that involve combined TAMP. We show which decisions and trade-offs should be made with respect to these research questions, and illustrate these on examples of existing application domains. By doing so, this article aims to provide a guideline for designing combined TAMP solutions that are adequate and effective in the target scenario.},
  archive      = {J_FROBT},
  author       = {Mansouri, Masoumeh and Pecora, Federico and Schüller, Peter},
  doi          = {10.3389/frobt.2021.637888},
  journal      = {Frontiers in Robotics and AI},
  month        = {5},
  pages        = {637888},
  shortjournal = {Front. Robot. AI},
  title        = {Combining task and motion planning: Challenges and guidelines},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Drivers of automation and consequences for jobs in
engineering services: An agent-based modelling approach. <em>FROBT</em>,
<em>8</em>, 637125. (<a
href="https://doi.org/10.3389/frobt.2021.637125">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {New technology is of little use if it is not adopted, and surveys show that less than 10% of firms use Artificial Intelligence. This paper studies the uptake of AI-driven automation and its impact on employment, using a dynamic agent-based model (ABM). It simulates the adoption of automation software as well as job destruction and job creation in its wake. There are two types of agents: manufacturing firms and engineering services firms. The agents choose between two business models: consulting or automated software. From the engineering firms’ point of view, the model exhibits static economies of scale in the software model and dynamic (learning by doing) economies of scale in the consultancy model. From the manufacturing firms’ point of view, switching to the software model requires restructuring of production and there are network effects in switching. The ABM matches engineering and manufacturing agents and derives employment of engineers and the tasks they perform, i.e. consultancy, software development, software maintenance, or employment in manufacturing. We find that the uptake of software is gradual; slow in the first few years and then accelerates. Software is fully adopted after about 18 years in the base line run. Employment of engineers shifts from consultancy to software development and to new jobs in manufacturing. Spells of unemployment may occur if skilled jobs creation in manufacturing is slow. Finally, the model generates boom and bust cycles in the software sector.},
  archive      = {J_FROBT},
  author       = {Kyvik Nordås, Hildegunn and Klügl, Franziska},
  doi          = {10.3389/frobt.2021.637125},
  journal      = {Frontiers in Robotics and AI},
  month        = {5},
  pages        = {637125},
  shortjournal = {Front. Robot. AI},
  title        = {Drivers of automation and consequences for jobs in engineering services: An agent-based modelling approach},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Adaptive and energy-efficient optimal control in CPGs
through tegotae-based feedback. <em>FROBT</em>, <em>8</em>, 632804. (<a
href="https://doi.org/10.3389/frobt.2021.632804">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To obtain biologically inspired robotic control, the architecture of central pattern generators (CPGs) has been extensively adopted to generate periodic patterns for locomotor control. This is attributed to the interesting properties of nonlinear oscillators. Although sensory feedback in CPGs is not necessary for the generation of patterns, it plays a central role in guaranteeing adaptivity to environmental conditions. Nonetheless, its inclusion significantly modifies the dynamics of the CPG architecture, which often leads to bifurcations. For instance, the force feedback can be exploited to derive information regarding the state of the system. In particular, the Tegotae approach can be adopted by coupling proprioceptive information with the state of the oscillation itself in the CPG model. This paper discusses this policy with respect to other types of feedback; it provides higher adaptivity and an optimal energy efficiency for reflex-like actuation. We believe this is the first attempt to analyse the optimal energy efficiency along with the adaptivity of the Tegotae approach.},
  archive      = {J_FROBT},
  author       = {Zamboni, Riccardo and Owaki, Dai and Hayashibe, Mitsuhiro},
  doi          = {10.3389/frobt.2021.632804},
  journal      = {Frontiers in Robotics and AI},
  month        = {5},
  pages        = {632804},
  shortjournal = {Front. Robot. AI},
  title        = {Adaptive and energy-efficient optimal control in CPGs through tegotae-based feedback},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A deeper look at autonomous vehicle ethics: An integrative
ethical decision-making framework to explain moral pluralism.
<em>FROBT</em>, <em>8</em>, 632394. (<a
href="https://doi.org/10.3389/frobt.2021.632394">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The autonomous vehicle (AV) is one of the first commercialized AI-embedded robots to make autonomous decisions. Despite technological advancements, unavoidable AV accidents that result in life-and-death consequences cannot be completely eliminated. The emerging social concern of how an AV should make ethical decisions during unavoidable accidents is referred to as the moral dilemma of AV, which has promoted heated discussions among various stakeholders. However, there are research gaps in explainable AV ethical decision-making processes that predict how AVs’ moral behaviors are made that are acceptable from the AV users’ perspectives. This study addresses the key question: What factors affect ethical behavioral intentions in the AV moral dilemma? To answer this question, this study draws theories from multidisciplinary research fields to propose the “Integrative ethical decision-making framework for the AV moral dilemma.” The framework includes four interdependent ethical decision-making stages: AV moral dilemma issue framing, intuitive moral reasoning, rational moral reasoning, and ethical behavioral intention making. Further, the framework includes variables (e.g., perceived moral intensity, individual factors, and personal moral philosophies) that influence the ethical decision-making process. For instance, the framework explains that AV users from Eastern cultures will tend to endorse a situationist ethics position (high idealism and high relativism), which views that ethical decisions are relative to context, compared to AV users from Western cultures. This proposition is derived from the link between individual factors and personal moral philosophy. Moreover, the framework proposes a dual-process theory, which explains that both intuitive and rational moral reasoning are integral processes of ethical decision-making during the AV moral dilemma. Further, this framework describes that ethical behavioral intentions that lead to decisions in the AV moral dilemma are not fixed, but are based on how an individual perceives the seriousness of the situation, which is shaped by their personal moral philosophy. This framework provides a step-by-step explanation of how pluralistic ethical decision-making occurs, reducing the abstractness of AV moral reasoning processes.},
  archive      = {J_FROBT},
  author       = {Rhim, Jimin and Lee, Ji-Hyun and Chen, Mo and Lim, Angelica},
  doi          = {10.3389/frobt.2021.632394},
  journal      = {Frontiers in Robotics and AI},
  month        = {5},
  pages        = {632394},
  shortjournal = {Front. Robot. AI},
  title        = {A deeper look at autonomous vehicle ethics: An integrative ethical decision-making framework to explain moral pluralism},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A deep learning method for vision based force prediction of
a soft fin ray gripper using simulation data. <em>FROBT</em>,
<em>8</em>, 631371. (<a
href="https://doi.org/10.3389/frobt.2021.631371">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Soft robotic grippers are increasingly desired in applications that involve grasping of complex and deformable objects. However, their flexible nature and non-linear dynamics makes the modelling and control difficult. Numerical techniques such as Finite Element Analysis (FEA) present an accurate way of modelling complex deformations. However, FEA approaches are computationally expensive and consequently challenging to employ for real-time control tasks. Existing analytical techniques simplify the modelling by approximating the deformed gripper geometry. Although this approach is less computationally demanding, it is limited in design scope and can lead to larger estimation errors. In this paper, we present a learning based framework that is able to predict contact forces as well as stress distribution from soft Fin Ray Effect (FRE) finger images in real-time. These images are used to learn internal representations for deformations using a deep neural encoder, which are further decoded to contact forces and stress maps using separate branches. The entire network is jointly learned in an end-to-end fashion. In order to address the challenge of having sufficient labelled data for training, we employ FEA to generate simulated images to supervise our framework. This leads to an accurate prediction, faster inference and availability of large and diverse data for better generalisability. Furthermore, our approach is able to predict a detailed stress distribution that can guide grasp planning, which would be particularly useful for delicate objects. Our proposed approach is validated by comparing the predicted contact forces to the computed ground-truth forces from FEA as well as real force sensor. We rigorously evaluate the performance of our approach under variations in contact point, object material, object shape, viewing angle, and level of occlusion.},
  archive      = {J_FROBT},
  author       = {De Barrie, Daniel and Pandya, Manjari and Pandya, Harit and Hanheide, Marc and Elgeneidy, Khaled},
  doi          = {10.3389/frobt.2021.631371},
  journal      = {Frontiers in Robotics and AI},
  month        = {5},
  pages        = {631371},
  shortjournal = {Front. Robot. AI},
  title        = {A deep learning method for vision based force prediction of a soft fin ray gripper using simulation data},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Body and tail coordination in the bluespot salamander
(ambystoma laterale) during limb regeneration. <em>FROBT</em>,
<em>8</em>, 629713. (<a
href="https://doi.org/10.3389/frobt.2021.629713">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Animals are incredibly good at adapting to changes in their environment, a trait envied by most roboticists. Many animals use different gaits to seamlessly transition between land and water and move through non-uniform terrains. In addition to adjusting to changes in their environment, animals can adjust their locomotion to deal with missing or regenerating limbs. Salamanders are an amphibious group of animals that can regenerate limbs, tails, and even parts of the spinal cord in some species. After the loss of a limb, the salamander successfully adjusts to constantly changing morphology as it regenerates the missing part. This quality is of particular interest to roboticists looking to design devices that can adapt to missing or malfunctioning components. While walking, an intact salamander uses its limbs, body, and tail to propel itself along the ground. Its body and tail are coordinated in a distinctive wave-like pattern. Understanding how their bending kinematics change as they regrow lost limbs would provide important information to roboticists designing amphibious machines meant to navigate through unpredictable and diverse terrain. We amputated both hindlimbs of blue-spotted salamanders (Ambystoma laterale) and measured their body and tail kinematics as the limbs regenerated. We quantified the change in the body wave over time and compared them to an amphibious fish species, Polypterus senegalus. We found that salamanders in the early stages of regeneration shift their kinematics, mostly around their pectoral girdle, where there is a local increase in undulation frequency. Amputated salamanders also show a reduced range of preferred walking speeds and an increase in the number of bending waves along the body. This work could assist roboticists working on terrestrial locomotion and water to land transitions.},
  archive      = {J_FROBT},
  author       = {Donatelli, Cassandra M. and Lutek, Keegan and Gupta, Keshav and Standen, Emily M.},
  doi          = {10.3389/frobt.2021.629713},
  journal      = {Frontiers in Robotics and AI},
  month        = {5},
  pages        = {629713},
  shortjournal = {Front. Robot. AI},
  title        = {Body and tail coordination in the bluespot salamander (Ambystoma laterale) during limb regeneration},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Unified approach to the motion design for a snake robot
negotiating complicated pipe structures. <em>FROBT</em>, <em>8</em>,
629368. (<a href="https://doi.org/10.3389/frobt.2021.629368">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A unified method for designing the motion of a snake robot negotiating complicated pipe structures is presented. Such robots moving inside pipes must deal with various “obstacles,” such as junctions, bends, diameter changes, shears, and blockages. To surmount these obstacles, we propose a method that enables the robot to adapt to multiple pipe structures in a unified way. This method also applies to motion that is necessary to pass between the inside and the outside of a pipe. We designed the target form of the snake robot using two helices connected by an arbitrary shape. This method can be applied to various obstacles by designing a part of the target form specifically for given obstacles. The robot negotiates obstacles under shift control by employing a rolling motion. Considering the slip between the robot and the pipe, the model expands the method to cover cases where two helices have different properties. We demonstrated the effectiveness of the proposed method in various experiments.},
  archive      = {J_FROBT},
  author       = {Inazawa, Mariko and Takemori, Tatsuya and Tanaka, Motoyasu and Matsuno, Fumitoshi},
  doi          = {10.3389/frobt.2021.629368},
  journal      = {Frontiers in Robotics and AI},
  month        = {5},
  pages        = {629368},
  shortjournal = {Front. Robot. AI},
  title        = {Unified approach to the motion design for a snake robot negotiating complicated pipe structures},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Framing effects on judgments of social robots’ (im)moral
behaviors. <em>FROBT</em>, <em>8</em>, 627233. (<a
href="https://doi.org/10.3389/frobt.2021.627233">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Frames—discursive structures that make dimensions of a situation more or less salient—are understood to influence how people understand novel technologies. As technological agents are increasingly integrated into society, it becomes important to discover how native understandings (i.e., individual frames) of social robots are associated with how they are characterized by media, technology developers, and even the agents themselves (i.e., produced frames). Moreover, these individual and produced frames may influence the ways in which people see social robots as legitimate and trustworthy agents—especially in the face of (im)moral behavior. This three-study investigation begins to address this knowledge gap by 1) identifying individually held frames for explaining an android’s (im)moral behavior, and experimentally testing how produced frames prime judgments about an android’s morally ambiguous behavior in 2) mediated representations and 3) face-to-face exposures. Results indicate that people rely on discernible ground rules to explain social robot behaviors; these frames induced only limited effects on responsibility judgments of that robot’s morally ambiguous behavior. Evidence also suggests that technophobia-induced reactance may move people to reject a produced frame in favor of a divergent individual frame.},
  archive      = {J_FROBT},
  author       = {Banks, Jaime and Koban, Kevin},
  doi          = {10.3389/frobt.2021.627233},
  journal      = {Frontiers in Robotics and AI},
  month        = {5},
  pages        = {627233},
  shortjournal = {Front. Robot. AI},
  title        = {Framing effects on judgments of social robots’ (Im)Moral behaviors},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Broad dataset and methods for counting and localization of
on-ear corn kernels. <em>FROBT</em>, <em>8</em>, 627009. (<a
href="https://doi.org/10.3389/frobt.2021.627009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Crop monitoring and yield prediction are central to management decisions for farmers. One key task is counting the number of kernels on an ear of corn to estimate yield in a field. As ears of corn can easily have 400–900 kernels, manual counting is unrealistic; traditionally, growers have approximated the number of kernels on an ear of corn through a mixture of counting and estimation. With the success of deep learning, these human estimates can now be replaced with more accurate machine learning models, many of which are efficient enough to run on a mobile device. Although a conceptually simple task, the counting and localization of hundreds of instances in an image is challenging for many image detection algorithms which struggle when objects are small in size and large in number. We compare different detection-based frameworks, Faster R-CNN, YOLO, and density-estimation approaches for on-ear corn kernel counting and localization. In addition to the YOLOv5 model which is accurate and edge-deployable, our density-estimation approach produces high-quality results, is lightweight enough for edge deployment, and maintains its computational efficiency independent of the number of kernels in the image. Additionally, we seek to standardize and broaden this line of work through the release of a challenging dataset with high-quality, multi-class segmentation masks. This dataset firstly enables quantitative comparison of approaches within the kernel counting application space and secondly promotes further research in transfer learning and domain adaptation, large count segmentation methods, and edge deployment methods.},
  archive      = {J_FROBT},
  author       = {Hobbs, Jennifer and Khachatryan, Vachik and Anandan, Barathwaj S. and Hovhannisyan, Harutyun and Wilson, David},
  doi          = {10.3389/frobt.2021.627009},
  journal      = {Frontiers in Robotics and AI},
  month        = {5},
  pages        = {627009},
  shortjournal = {Front. Robot. AI},
  title        = {Broad dataset and methods for counting and localization of on-ear corn kernels},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A COVID-19 emergency response for remote control of a
dialysis machine with mobile HRI. <em>FROBT</em>, <em>8</em>, 612855.
(<a href="https://doi.org/10.3389/frobt.2021.612855">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Healthcare workers face a high risk of contagion during a pandemic due to their close proximity to patients. The situation is further exacerbated in the case of a shortage of personal protective equipment that can increase the risk of exposure for the healthcare workers and even non-pandemic related patients, such as those on dialysis. In this study, we propose an emergency, non-invasive remote monitoring and control response system to retrofit dialysis machines with robotic manipulators for safely supporting the treatment of patients with acute kidney disease. Specifically, as a proof-of-concept, we mock-up the touchscreen instrument control panel of a dialysis machine and live-stream it to a remote user’s tablet computer device. Then, the user performs touch-based interactions on the tablet device to send commands to the robot to manipulate the instrument controls on the touchscreen of the dialysis machine. To evaluate the performance of the proposed system, we conduct an accuracy test. Moreover, we perform qualitative user studies using two modes of interaction with the designed system to measure the user task load and system usability and to obtain user feedback. The two modes of interaction included a touch-based interaction using a tablet device and a click-based interaction using a computer. The results indicate no statistically significant difference in the relatively low task load experienced by the users for both modes of interaction. Moreover, the system usability survey results reveal no statistically significant difference in the user experience for both modes of interaction except that users experienced a more consistent performance with the click-based interaction vs. the touch-based interaction. Based on the user feedback, we suggest an improvement to the proposed system and illustrate an implementation that corrects the distorted perception of the instrumentation control panel live-stream for a better and consistent user experience.},
  archive      = {J_FROBT},
  author       = {Wazir, Hassam Khan and Lourido, Christian and Chacko, Sonia Mary and Kapila, Vikram},
  doi          = {10.3389/frobt.2021.612855},
  journal      = {Frontiers in Robotics and AI},
  month        = {5},
  pages        = {612855},
  shortjournal = {Front. Robot. AI},
  title        = {A COVID-19 emergency response for remote control of a dialysis machine with mobile HRI},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Upper limb home-based robotic rehabilitation during COVID-19
outbreak. <em>FROBT</em>, <em>8</em>, 612834. (<a
href="https://doi.org/10.3389/frobt.2021.612834">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The coronavirus disease (COVID-19) outbreak requires rapid reshaping of rehabilitation services to include patients recovering from severe COVID-19 with post-intensive care syndromes, which results in physical deconditioning and cognitive impairments, patients with comorbid conditions, and other patients requiring physical therapy during the outbreak with no or limited access to hospital and rehabilitation centers. Considering the access barriers to quality rehabilitation settings and services imposed by social distancing and stay-at-home orders, these patients can be benefited from providing access to affordable and good quality care through home-based rehabilitation. The success of such treatment will depend highly on the intensity of the therapy and effort invested by the patient. Monitoring patients&#39; compliance and designing a home-based rehabilitation that can mentally engage them are the critical elements in home-based therapy&#39;s success. Hence, we study the state-of-the-art telerehabilitation frameworks and robotic devices, and comment about a hybrid model that can use existing telerehabilitation framework and home-based robotic devices for treatment and simultaneously assess patient&#39;s progress remotely. Second, we comment on the patients&#39; social support and engagement, which is critical for the success of telerehabilitation service. As the therapists are not physically present to guide the patients, we also discuss the adaptability requirement of home-based telerehabilitation. Finally, we suggest that the reformed rehabilitation services should consider both home-based solutions for enhancing the activities of daily living and an on-demand ambulatory rehabilitation unit for extensive training where we can monitor both cognitive and motor performance of the patients remotely.},
  archive      = {J_FROBT},
  author       = {Manjunatha, Hemanth and Pareek, Shrey and Jujjavarapu, Sri Sadhan and Ghobadi, Mostafa and Kesavadas, Thenkurussi and Esfahani, Ehsan T.},
  doi          = {10.3389/frobt.2021.612834},
  journal      = {Frontiers in Robotics and AI},
  month        = {5},
  pages        = {612834},
  shortjournal = {Front. Robot. AI},
  title        = {Upper limb home-based robotic rehabilitation during COVID-19 outbreak},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). RoboEthics in COVID-19: A case study in dentistry.
<em>FROBT</em>, <em>8</em>, 612740. (<a
href="https://doi.org/10.3389/frobt.2021.612740">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The COVID-19 pandemic has caused dramatic effects on the healthcare system, businesses, and education. In many countries, businesses were shut down, universities and schools had to cancel in-person classes, and many workers had to work remotely and socially distance in order to prevent the spread of the virus. These measures opened the door for technologies such as robotics and artificial intelligence to play an important role in minimizing the negative effects of such closures. There have been many efforts in the design and development of robotic systems for applications such as disinfection and eldercare. Healthcare education has seen a lot of potential in simulation robots, which offer valuable opportunities for remote learning during the pandemic. However, there are ethical considerations that need to be deliberated in the design and development of such systems. In this paper, we discuss the principles of roboethics and how these can be applied in the new era of COVID-19. We focus on identifying the most relevant ethical principles and apply them to a case study in dentistry education. DenTeach was developed as a portable device that uses sensors and computer simulation to make dental education more efficient. DenTeach makes remote instruction possible by allowing students to learn and practice dental procedures from home. We evaluate DenTeach on the principles of data, common good, and safety, and highlight the importance of roboethics in Canada. The principles identified in this paper can inform researchers and educational institutions considering implementing robots in their curriculum.},
  archive      = {J_FROBT},
  author       = {Maddahi, Yaser and Kalvandi, Maryam and Langman, Sofya and Capicotto, Nicole and Zareinia, Kourosh},
  doi          = {10.3389/frobt.2021.612740},
  journal      = {Frontiers in Robotics and AI},
  month        = {5},
  pages        = {612740},
  shortjournal = {Front. Robot. AI},
  title        = {RoboEthics in COVID-19: A case study in dentistry},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Neurorehabilitation from a distance: Can intelligent
technology support decentralized access to quality therapy?
<em>FROBT</em>, <em>8</em>, 612415. (<a
href="https://doi.org/10.3389/frobt.2021.612415">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Current neurorehabilitation models primarily rely on extended hospital stays and regular therapy sessions requiring close physical interactions between rehabilitation professionals and patients. The current COVID-19 pandemic has challenged this model, as strict physical distancing rules and a shift in the allocation of hospital resources resulted in many neurological patients not receiving essential therapy. Accordingly, a recent survey revealed that the majority of European healthcare professionals involved in stroke care are concerned that this lack of care will have a noticeable negative impact on functional outcomes. COVID-19 highlights an urgent need to rethink conventional neurorehabilitation and develop alternative approaches to provide high-quality therapy while minimizing hospital stays and visits. Technology-based solutions, such as, robotics bear high potential to enable such a paradigm shift. While robot-assisted therapy is already established in clinics, the future challenge is to enable physically assisted therapy and assessments in a minimally supervized and decentralized manner, ideally at the patient’s home. Key enablers are new rehabilitation devices that are portable, scalable and equipped with clinical intelligence, remote monitoring and coaching capabilities. In this perspective article, we discuss clinical and technological requirements for the development and deployment of minimally supervized, robot-assisted neurorehabilitation technologies in patient’s homes. We elaborate on key principles to ensure feasibility and acceptance, and on how artificial intelligence can be leveraged for embedding clinical knowledge for safe use and personalized therapy adaptation. Such new models are likely to impact neurorehabilitation beyond COVID-19, by providing broad access to sustained, high-quality and high-dose therapy maximizing long-term functional outcomes.},
  archive      = {J_FROBT},
  author       = {Lambercy, Olivier and Lehner, Rea and Chua, Karen and Wee, Seng Kwee and Rajeswaran, Deshan Kumar and Kuah, Christopher Wee Keong and Ang, Wei Tech and Liang, Phyllis and Campolo, Domenico and Hussain, Asif and Aguirre-Ollinger, Gabriel and Guan, Cuntai and Kanzler, Christoph M. and Wenderoth, Nicole and Gassert, Roger},
  doi          = {10.3389/frobt.2021.612415},
  journal      = {Frontiers in Robotics and AI},
  month        = {5},
  pages        = {612415},
  shortjournal = {Front. Robot. AI},
  title        = {Neurorehabilitation from a distance: Can intelligent technology support decentralized access to quality therapy?},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Design and modelling of a continuum robot for distal lung
sampling in mechanically ventilated patients in critical care.
<em>FROBT</em>, <em>8</em>, 611866. (<a
href="https://doi.org/10.3389/frobt.2021.611866">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we design and develop a novel robotic bronchoscope for sampling of the distal lung in mechanically-ventilated (MV) patients in critical care units. Despite the high cost and attributable morbidity and mortality of MV patients with pneumonia which approaches 40%, sampling of the distal lung in MV patients suffering from range of lung diseases such as Covid-19 is not standardised, lacks reproducibility and requires expert operators. We propose a robotic bronchoscope that enables repeatable sampling and guidance to distal lung pathologies by overcoming significant challenges that are encountered whilst performing bronchoscopy in MV patients, namely, limited dexterity, large size of the bronchoscope obstructing ventilation, and poor anatomical registration. We have developed a robotic bronchoscope with 7 Degrees of Freedom (DoFs), an outer diameter of 4.5 mm and inner working channel of 2 mm. The prototype is a push/pull actuated continuum robot capable of dexterous manipulation inside the lung and visualisation/sampling of the distal airways. A prototype of the robot is engineered and a mechanics-based model of the robotic bronchoscope is developed. Furthermore, we develop a novel numerical solver that improves the computational efficiency of the model and facilitates the deployment of the robot. Experiments are performed to verify the design and evaluate accuracy and computational cost of the model. Results demonstrate that the model can predict the shape of the robot in &amp;lt;0.011s with a mean error of 1.76 cm, enabling the future deployment of a robotic bronchoscope in MV patients.},
  archive      = {J_FROBT},
  author       = {Mitros, Zisos and Thamo, Balint and Bergeles, Christos and da Cruz, Lyndon and Dhaliwal, Kevin and Khadem, Mohsen},
  doi          = {10.3389/frobt.2021.611866},
  journal      = {Frontiers in Robotics and AI},
  month        = {5},
  pages        = {611866},
  shortjournal = {Front. Robot. AI},
  title        = {Design and modelling of a continuum robot for distal lung sampling in mechanically ventilated patients in critical care},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Deep learned quantization-based codec for 3D airborne LiDAR
point cloud images. <em>FROBT</em>, <em>8</em>, 606770. (<a
href="https://doi.org/10.3389/frobt.2021.606770">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a novel deep learned quantization-based coding for 3D Airborne LiDAR (Light detection and ranging) point cloud (pcd) image (DLQCPCD). The raw pcd signals are sampled and transformed by applying the Nyquist signal sampling and Min-max signal transformation techniques, respectively for improving the efficiency of the training process. Then, the transformed signals are feed into the deep learned quantization module for compressing the data. To the best of our knowledge, this proposed DLQCPCD is the first deep learning-based model for 3D airborne LiDAR pcd compression. The functions of Mean Squared Error and Stochastic Gradient Descent optimization function enhance the quality of the decompressed image by 67.01 percent on average, compared to other functions. The model’s efficiency has been validated with established well-known compression techniques such as the 7-Zip, WinRAR, and tensor tucker decomposition algorithm on the three inconsistent airborne datasets. The experimental results show that the proposed model compresses every pcd image into constant 16 Number of Neurons of data and decompresses the image with approximately 160 dB of PSNR value, 174.46 s execution time with 0.6 s execution speed per instruction, and proved that it outperforms the other existing algorithms regarding space and time.},
  archive      = {J_FROBT},
  author       = {Tamilmathi, A. Christoper and Chithra, P. L.},
  doi          = {10.3389/frobt.2021.606770},
  journal      = {Frontiers in Robotics and AI},
  month        = {5},
  pages        = {606770},
  shortjournal = {Front. Robot. AI},
  title        = {Deep learned quantization-based codec for 3D airborne LiDAR point cloud images},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A systematic review of robotic rehabilitation for cognitive
training. <em>FROBT</em>, <em>8</em>, 605715. (<a
href="https://doi.org/10.3389/frobt.2021.605715">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A large and increasing number of people around the world experience cognitive disability. Rehabilitation robotics has provided promising training and assistance approaches to mitigate cognitive deficits. In this article, we carried out a systematic review on recent developments in robot-assisted cognitive training. We included 99 articles in this work and described their applications, enabling technologies, experiments, and products. We also conducted a meta analysis on the articles that evaluated robot-assisted cognitive training protocol with primary end users (i.e., people with cognitive disability). We identified major limitations in current robotics rehabilitation for cognitive training, including the small sample size, non-standard measurement of training and uncontrollable factors. There are still multifaceted challenges in this field, including ethical issues, user-centered (or stakeholder-centered) design, the reliability, trust, and cost-effectiveness, personalization of the robot-assisted cognitive training system. Future research shall also take into consideration human-robot collaboration and social cognition to facilitate a natural human-robot interaction.},
  archive      = {J_FROBT},
  author       = {Yuan, Fengpei and Klavon, Elizabeth and Liu, Ziming and Lopez, Ruth Palan and Zhao, Xiaopeng},
  doi          = {10.3389/frobt.2021.605715},
  journal      = {Frontiers in Robotics and AI},
  month        = {5},
  pages        = {605715},
  shortjournal = {Front. Robot. AI},
  title        = {A systematic review of robotic rehabilitation for cognitive training},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Attention enhancement for exoskeleton-assisted hand
rehabilitation using fingertip haptic stimulation. <em>FROBT</em>,
<em>8</em>, 602091. (<a
href="https://doi.org/10.3389/frobt.2021.602091">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Active enrollment in rehabilitation training yields better treatment outcomes. This paper introduces an exoskeleton-assisted hand rehabilitation system. It is the first attempt to combine fingertip cutaneous haptic stimulation with exoskeleton-assisted hand rehabilitation for training participation enhancement. For the first time, soft material 3D printing techniques are adopted to make soft pneumatic fingertip haptic feedback actuators to achieve cheaper and faster iterations of prototype designs with consistent quality. The fingertip haptic stimulation is synchronized with the motion of our hand exoskeleton. The contact force of the fingertips resulted from a virtual interaction with a glass of water was based on data collected from normal hand motions to grasp a glass of water. System characterization experiments were conducted and exoskeleton-assisted hand motion with and without the fingertip cutaneous haptic stimulation were compared in an experiment involving healthy human subjects. Users’ attention levels were monitored in the motion control process using a Brainlink EEG-recording device and software. The results of characterization experiments show that our created haptic actuators are lightweight (6.8 ± 0.23 g each with a PLA fixture and Velcro) and their performance is consistent and stable with small hysteresis. The user study experimental results show that participants had significantly higher attention levels with additional haptic stimulations compared to when only the exoskeleton was deployed; heavier stimulated grasping weight (a 300 g glass) was associated with significantly higher attention levels of the participants compared to when lighter stimulated grasping weight (a 150 g glass) was applied. We conclude that haptic stimulations increase the involvement level of human subjects during exoskeleton-assisted hand exercises. Potentially, the proposed exoskeleton-assisted hand rehabilitation with fingertip stimulation may better attract user’s attention during treatment.},
  archive      = {J_FROBT},
  author       = {Li, Min and Chen, Jiazhou and He, Guoying and Cui, Lei and Chen, Chaoyang and Secco, Emanuele Lindo and Yao, Wei and Xie, Jun and Xu, Guanghua and Wurdemann, Helge},
  doi          = {10.3389/frobt.2021.602091},
  journal      = {Frontiers in Robotics and AI},
  month        = {5},
  pages        = {602091},
  shortjournal = {Front. Robot. AI},
  title        = {Attention enhancement for exoskeleton-assisted hand rehabilitation using fingertip haptic stimulation},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Smiles as a signal of prosocial behaviors toward the robot
in the therapeutic setting for children with autism spectrum disorder.
<em>FROBT</em>, <em>8</em>, 599755. (<a
href="https://doi.org/10.3389/frobt.2021.599755">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We explored how robot-assisted therapy based on smile analysis may facilitate the prosocial behaviors of children with autism spectrum disorder. Prosocial behaviors, which are actions for the benefit of others, are required to belong to society and increase the quality of life. As smiling is a candidate for predicting prosocial behaviors in robot-assisted therapy, we measured smiles by annotating behaviors that were recorded with video cameras and by classifying facial muscle activities recorded with a wearable device. While interacting with a robot, the participants experienced two situations where participants&#39; prosocial behaviors are expected, which were supporting the robot to walk and helping the robot from falling. We first explored the overall smiles at specific timings and prosocial behaviors. Then, we explored the smiles triggered by a robot and behavior changes before engaging in prosocial behaviors. The results show that the specific timing of smiles and prosocial behaviors increased in the second session of children with autism spectrum disorder. Additionally, a smile was followed by a series of behaviors before prosocial behavior. With a proposed Bayesian model, smiling, or heading predicted prosocial behaviors with higher accuracy compared to other variables. Particularly, voluntary prosocial behaviors were observed after smiling. The findings of this exploratory study imply that smiles might be a signal of prosocial behaviors. We also suggest a probabilistic model for predicting prosocial behaviors based on smile analysis, which could be applied to personalized robot-assisted therapy by controlling a robot&#39;s movements to arouse smiles and increase the probability that a child with autism spectrum disorder will engage in prosocial behaviors.},
  archive      = {J_FROBT},
  author       = {Kim, SunKyoung and Hirokawa, Masakazu and Matsuda, Soichiro and Funahashi, Atsushi and Suzuki, Kenji},
  doi          = {10.3389/frobt.2021.599755},
  journal      = {Frontiers in Robotics and AI},
  month        = {5},
  pages        = {599755},
  shortjournal = {Front. Robot. AI},
  title        = {Smiles as a signal of prosocial behaviors toward the robot in the therapeutic setting for children with autism spectrum disorder},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Cough recognition based on mel-spectrogram and convolutional
neural network. <em>FROBT</em>, <em>8</em>, 580080. (<a
href="https://doi.org/10.3389/frobt.2021.580080">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In daily life, there are a variety of complex sound sources. It is important to effectively detect certain sounds in some situations. With the outbreak of COVID-19, it is necessary to distinguish the sound of coughing, to estimate suspected patients in the population. In this paper, we propose a method for cough recognition based on a Mel-spectrogram and a Convolutional Neural Network called the Cough Recognition Network (CRN), which can effectively distinguish cough sounds.},
  archive      = {J_FROBT},
  author       = {Zhou, Quan and Shan, Jianhua and Ding, Wenlong and Wang, Chengyin and Yuan, Shi and Sun, Fuchun and Li, Haiyuan and Fang, Bin},
  doi          = {10.3389/frobt.2021.580080},
  journal      = {Frontiers in Robotics and AI},
  month        = {5},
  pages        = {580080},
  shortjournal = {Front. Robot. AI},
  title        = {Cough recognition based on mel-spectrogram and convolutional neural network},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Parental acceptance of children’s storytelling robots: A
projection of the uncanny valley of AI. <em>FROBT</em>, <em>8</em>,
579993. (<a href="https://doi.org/10.3389/frobt.2021.579993">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Parent–child story time is an important ritual of contemporary parenting. Recently, robots with artificial intelligence (AI) have become common. Parental acceptance of children’s storytelling robots, however, has received scant attention. To address this, we conducted a qualitative study with 18 parents using the research technique design fiction. Overall, parents held mixed, though generally positive, attitudes toward children’s storytelling robots. In their estimation, these robots would outperform screen-based technologies for children’s story time. However, the robots’ potential to adapt and to express emotion caused some parents to feel ambivalent about the robots, which might hinder their adoption. We found three predictors of parental acceptance of these robots: context of use, perceived agency, and perceived intelligence. Parents’ speculation revealed an uncanny valley of AI: a nonlinear relation between the human likeness of the artificial agent’s mind and affinity for the agent. Finally, we consider the implications of children’s storytelling robots, including how they could enhance equity in children’s access to education, and propose directions for research on their design to benefit family well-being.},
  archive      = {J_FROBT},
  author       = {Lin, Chaolan and Šabanović, Selma and Dombrowski, Lynn and Miller, Andrew D. and Brady, Erin and MacDorman, Karl F.},
  doi          = {10.3389/frobt.2021.579993},
  journal      = {Frontiers in Robotics and AI},
  month        = {5},
  pages        = {579993},
  shortjournal = {Front. Robot. AI},
  title        = {Parental acceptance of children’s storytelling robots: A projection of the uncanny valley of AI},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Exploring co-creative drawing workflows. <em>FROBT</em>,
<em>8</em>, 577770. (<a
href="https://doi.org/10.3389/frobt.2021.577770">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article presents the outcomes from a mixed-methods study of drawing practitioners (e.g., professional illustrators, fine artists, and art students) that was conducted in Autumn 2018 as a preliminary investigation for the development of a physical human-AI co-creative drawing system. The aim of the study was to discover possible roles that technology could play in observing, modeling, and possibly assisting an artist with their drawing. The study had three components: a paper survey of artists&#39; drawing practises, technology usage and attitudes, video recorded drawing exercises and a follow-up semi-structured interview which included a co-design discussion on how AI might contribute to their drawing workflow. Key themes identified from the interviews were (1) drawing with physical mediums is a traditional and primary way of creation; (2) artists&#39; views on AI varied, where co-creative AI is preferable to didactic AI; and (3) artists have a critical and skeptical view on the automation of creative work with AI. Participants&#39; input provided the basis for the design and technical specifications of a co-creative drawing prototype, for which details are presented in this article. In addition, lessons learned from conducting the user study are presented with a reflection on future studies with drawing practitioners.},
  archive      = {J_FROBT},
  author       = {Jansen, Chipp and Sklar, Elizabeth},
  doi          = {10.3389/frobt.2021.577770},
  journal      = {Frontiers in Robotics and AI},
  month        = {5},
  pages        = {577770},
  shortjournal = {Front. Robot. AI},
  title        = {Exploring co-creative drawing workflows},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-USV adaptive exploration using kernel information and
residual variance. <em>FROBT</em>, <em>8</em>, 572243. (<a
href="https://doi.org/10.3389/frobt.2021.572243">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Using a team of robots for estimating scalar environmental fields is an emerging approach. The aim of such an approach is to reduce the mission time for collecting informative data as compared to a single robot. However, increasing the number of robots requires coordination and efficient use of the mission time to provide a good approximation of the scalar field. We suggest an online multi-robot framework m-AdaPP to handle this coordination. We test our framework for estimating a scalar environmental field with no prior information and benchmark the performance via field experiments against conventional approaches such as lawn mower patterns. We demonstrated that our framework is capable of handling a team of robots for estimating a scalar field and outperforms conventional approaches used for approximating water quality parameters. The suggested framework can be used for estimating other scalar functions such as air temperature or vegetative index using land or aerial robots as well. Finally, we show an example use case of our adaptive algorithm in a scientific study for understanding micro-level interactions.},
  archive      = {J_FROBT},
  author       = {Mishra, Rajat and Koay, Teong Beng and Chitre, Mandar and Swarup, Sanjay},
  doi          = {10.3389/frobt.2021.572243},
  journal      = {Frontiers in Robotics and AI},
  month        = {5},
  pages        = {572243},
  shortjournal = {Front. Robot. AI},
  title        = {Multi-USV adaptive exploration using kernel information and residual variance},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Robot-as-a-service: From cloud to peering technologies.
<em>FROBT</em>, <em>8</em>, 560829. (<a
href="https://doi.org/10.3389/frobt.2021.560829">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article is devoted to the historical overview of the Robot-as-a-Service concept. Several major scientific publications on the development of Robot-as-a-Service systems based on a service-oriented paradigm are considered. Much attention is paid to the analysis of a centralized approach in the development using cloud computing services and the search for the limitations of this approach. As a result, general conclusions on the reviewed publications are given, as well as the authors&#39; own vision of Robot-as-a-Service systems based on the concept of robot economics.},
  archive      = {J_FROBT},
  author       = {Kapitonov, Aleksandr and Lonshakov, Sergey and Bulatov, Vitaly and Montazam, Babak Kia and White, James},
  doi          = {10.3389/frobt.2021.560829},
  journal      = {Frontiers in Robotics and AI},
  month        = {5},
  pages        = {560829},
  shortjournal = {Front. Robot. AI},
  title        = {Robot-as-a-service: From cloud to peering technologies},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). SIGVerse: A cloud-based VR platform for research on
multimodal human-robot interaction. <em>FROBT</em>, <em>8</em>, 549360.
(<a href="https://doi.org/10.3389/frobt.2021.549360">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Research on Human-Robot Interaction (HRI) requires the substantial consideration of an experimental design, as well as a significant amount of time to practice the subject experiment. Recent technology in virtual reality (VR) can potentially address these time and effort challenges. The significant advantages of VR systems for HRI are: 1) cost reduction, as experimental facilities are not required in a real environment; 2) provision of the same environmental and embodied interaction conditions to test subjects; 3) visualization of arbitrary information and situations that cannot occur in reality, such as playback of past experiences, and 4) ease of access to an immersive and natural interface for robot/avatar teleoperations. Although VR tools with their features have been applied and developed in previous HRI research, all-encompassing tools or frameworks remain unavailable. In particular, the benefits of integration with cloud computing have not been comprehensively considered. Hence, the purpose of this study is to propose a research platform that can comprehensively provide the elements required for HRI research by integrating VR and cloud technologies. To realize a flexible and reusable system, we developed a real-time bridging mechanism between the robot operating system (ROS) and Unity. To confirm the feasibility of the system in a practical HRI scenario, we applied the proposed system to three case studies, including a robot competition named RoboCup@Home. via these case studies, we validated the system’s usefulness and its potential for the development and evaluation of social intelligence via multimodal HRI.},
  archive      = {J_FROBT},
  author       = {Inamura, Tetsunari and Mizuchi, Yoshiaki},
  doi          = {10.3389/frobt.2021.549360},
  journal      = {Frontiers in Robotics and AI},
  month        = {5},
  pages        = {549360},
  shortjournal = {Front. Robot. AI},
  title        = {SIGVerse: A cloud-based VR platform for research on multimodal human-robot interaction},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). DeepFoG: An IMU-based detection of freezing of gait episodes
in parkinson’s disease patients via deep learning. <em>FROBT</em>,
<em>8</em>, 537384. (<a
href="https://doi.org/10.3389/frobt.2021.537384">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Freezing of Gait (FoG) is a movement disorder that mostly appears in the late stages of Parkinson’s Disease (PD). It causes incapability of walking, despite the PD patient’s intention, resulting in loss of coordination that increases the risk of falls and injuries and severely affects the PD patient’s quality of life. Stress, emotional stimulus, and multitasking have been encountered to be associated with the appearance of FoG episodes, while the patient’s functionality and self-confidence are constantly deteriorating. This study suggests a non-invasive method for detecting FoG episodes, by analyzing inertial measurement unit (IMU) data. Specifically, accelerometer and gyroscope data from 11 PD subjects, as captured from a single wrist-worn IMU sensor during continuous walking, are processed via Deep Learning for window-based detection of the FoG events. The proposed approach, namely DeepFoG, was evaluated in a Leave-One-Subject-Out (LOSO) cross-validation (CV) and 10-fold CV fashion schemes against its ability to correctly estimate the existence or not of a FoG episode at each data window. Experimental results have shown that DeepFoG performs satisfactorily, as it achieves 83%/88% and 86%/90% sensitivity/specificity, for LOSO CV and 10-fold CV schemes, respectively. The promising performance of the proposed DeepFoG reveals the potentiality of single-arm IMU-based real-time FoG detection that could guide effective interventions via stimuli, such as rhythmic auditory stimulation (RAS) and hand vibration. In this way, DeepFoG may scaffold the elimination of risk of falls in PD patients, sustaining their quality of life in everyday living activities.},
  archive      = {J_FROBT},
  author       = {Bikias, Thomas and Iakovakis, Dimitrios and Hadjidimitriou, Stelios and Charisis, Vasileios and Hadjileontiadis, Leontios J.},
  doi          = {10.3389/frobt.2021.537384},
  journal      = {Frontiers in Robotics and AI},
  month        = {5},
  pages        = {537384},
  shortjournal = {Front. Robot. AI},
  title        = {DeepFoG: An IMU-based detection of freezing of gait episodes in parkinson’s disease patients via deep learning},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Editorial: Soft robotics based on electroactive polymers.
<em>FROBT</em>, <em>8</em>, 676406. (<a
href="https://doi.org/10.3389/frobt.2021.676406">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Gu, Guoying and Shea, Herbert and Seelecke, Stefan and Alici, Gursel and Rizzello, Gianluca},
  doi          = {10.3389/frobt.2021.676406},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {676406},
  shortjournal = {Front. Robot. AI},
  title        = {Editorial: Soft robotics based on electroactive polymers},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Editorial: Language and robotics. <em>FROBT</em>,
<em>8</em>, 674832. (<a
href="https://doi.org/10.3389/frobt.2021.674832">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Taniguchi, Tadahiro and Horii, Takato and Hinaut, Xavier and Spranger, Michael and Mochihashi, Daichi and Nagai, Takayuki},
  doi          = {10.3389/frobt.2021.674832},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {674832},
  shortjournal = {Front. Robot. AI},
  title        = {Editorial: Language and robotics},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). 3D printing hydrogel-based soft and biohybrid actuators: A
mini-review on fabrication techniques, applications, and challenges.
<em>FROBT</em>, <em>8</em>, 673533. (<a
href="https://doi.org/10.3389/frobt.2021.673533">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stimuli-responsive hydrogels are candidate building blocks for soft robotic applications due to many of their unique properties, including tunable mechanical properties and biocompatibility. Over the past decade, there has been significant progress in developing soft and biohybrid actuators using naturally occurring and synthetic hydrogels to address the increasing demands for machines capable of interacting with fragile biological systems. Recent advancements in three-dimensional (3D) printing technology, either as a standalone manufacturing process or integrated with traditional fabrication techniques, have enabled the development of hydrogel-based actuators with on-demand geometry and actuation modalities. This mini-review surveys existing research efforts to inspire the development of novel fabrication techniques using hydrogel building blocks and identify potential future directions. In this article, existing 3D fabrication techniques for hydrogel actuators are first examined. Next, existing actuation mechanisms, including pneumatic, hydraulic, ionic, dehydration-rehydration, and cell-powered actuation, are reviewed with their benefits and limitations discussed. Subsequently, the applications of hydrogel-based actuators, including compliant handling of fragile items, micro-swimmers, wearable devices, and origami structures, are described. Finally, challenges in fabricating functional actuators using existing techniques are discussed.},
  archive      = {J_FROBT},
  author       = {Sun, Wenhuan and Schaffer, Saul and Dai, Kevin and Yao, Lining and Feinberg, Adam and Webster-Wood, Victoria},
  doi          = {10.3389/frobt.2021.673533},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {673533},
  shortjournal = {Front. Robot. AI},
  title        = {3D printing hydrogel-based soft and biohybrid actuators: A mini-review on fabrication techniques, applications, and challenges},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Toughening mechanism of unidirectional stretchable
composite. <em>FROBT</em>, <em>8</em>, 673307. (<a
href="https://doi.org/10.3389/frobt.2021.673307">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Composite materials have been long developed to improve the mechanical properties such as strength and toughness. Most composites are non-stretchable which hinders the applications in soft robotics. Recent papers have reported a new design of unidirectional soft composite with superior stretchability and toughness. This paper presents an analytical model to study the toughening mechanism of such composite. We use the Gent model to characterize the large deformation of the hard phase and soft phase of the composite. We analyze how the stress transfer between phases deconcentrates the stress at the crack tip and enhances the toughness. We identify two types of failure modes: rupture of hard phase and interfacial debonding. We calculate the average toughness of the composite with different physical and geometric parameters. The experimental results in literature agree with our theoretical predictions very well.},
  archive      = {J_FROBT},
  author       = {Jiang, Xiaochun and Wang, Zhengjin and Sun, Danqi and Lu, Tongqing and Wang, Tiejun},
  doi          = {10.3389/frobt.2021.673307},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {673307},
  shortjournal = {Front. Robot. AI},
  title        = {Toughening mechanism of unidirectional stretchable composite},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Investigation of the dynamic breakdown of a dielectric
elastomer actuator under cyclic voltage excitation. <em>FROBT</em>,
<em>8</em>, 672154. (<a
href="https://doi.org/10.3389/frobt.2021.672154">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The dielectric elastomer (DE) is a new kind of functional polymer that can be used as a smart actuator due to the large deformation induced by voltage excitation. Dielectric elastomer actuators (DEAs) are usually excited by dynamic voltages to generate alternating motions. DEAs are prone to premature breakdown failure during the dynamic excitation, while the research on the breakdown of DEAs under cyclic voltage excitation is still not fully revealed. In this paper, the dynamic breakdown behaviors of DEAs made from VHB4910 film were experimentally investigated. The factors affecting the breakdown behavior of DEAs under dynamic voltages were determined, and the relevant changing laws were summarized accordingly. The experimental results show that under dynamic voltage excitation, the critical breakdown voltage of DEAs were augmented slowly with voltage frequency and showed a substantial dispersion. In addition, the maximum cycle numbers before breakdown were significantly affected by voltage parameters (such as frequency, amplitude, waveform). Finally, the underlying mechanisms of breakdown under cyclic voltages were discussed qualitatively, a power-law equation was proposed to characterize the maximum cycle number for the dynamic breakdown of DEAs, and related parameters were fitted. This study provides a new path to predict the service life of DEAs under dynamic voltage.},
  archive      = {J_FROBT},
  author       = {Liu, Xuejing and Xing, Yu and Sun, Wenjie and Zhang, Zhouqiang and Guan, Shengqi and Li, Bo},
  doi          = {10.3389/frobt.2021.672154},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {672154},
  shortjournal = {Front. Robot. AI},
  title        = {Investigation of the dynamic breakdown of a dielectric elastomer actuator under cyclic voltage excitation},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Fatigue damage–resistant physical hydrogel adhesion.
<em>FROBT</em>, <em>8</em>, 666343. (<a
href="https://doi.org/10.3389/frobt.2021.666343">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Strong adhesion between hydrogels and various engineering surfaces has been achieved; yet, achieving fatigue-resistant hydrogel adhesion remains challenging. Here, we examine the fatigue of a specific type of hydrogel adhesion enabled by hydrogen bonds and wrinkling and show that the physical interactions–based hydrogel adhesion can resist fatigue damage. We synthesize polyacrylamide hydrogel as the adherend and poly(acrylic acid-co-acrylamide) hydrogel as the adhesive. The adherend and the adhesive interact via hydrogen bonds. We further introduce wrinkles at the interface by biaxially prestretching and then releasing the adherends and perform butt-joint tests to probe the adhesion performance. Experimental results reveal that the samples with a wrinkled interface resist fatigue damage, while the samples with a flat interface fail in ~9,000 cycles at stress levels of 70 and 63% peak stresses in static failure. The endurance limit of the wrinkled-interface samples is comparable to the peak stress of the flat-interface samples. Moreover, we find that the nearly perfectly elastic polyacrylamide hydrogel also suffers fatigue damage, which limits the fatigue life of the wrinkled-interface samples. When cohesive failure ensues, the evolutions of the elastic modulus of wrinkled-interface samples and hydrogel bulk, both in satisfactory agreements with the predictions of damage accumulation theory, are alike. We observe similar behaviors in different material systems with polyacrylamide hydrogels with different water contents. This work proves that physical interactions can be engaged in engineering fatigue-resistant adhesion between soft materials such as hydrogels.},
  archive      = {J_FROBT},
  author       = {Li, Qi and Wang, Luochang and Liu, Qihan and Hong, Wei and Yang, Canhui},
  doi          = {10.3389/frobt.2021.666343},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {666343},
  shortjournal = {Front. Robot. AI},
  title        = {Fatigue Damage–Resistant physical hydrogel adhesion},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Before, between, and after: Enriching robot communication
surrounding collaborative creative activities. <em>FROBT</em>,
<em>8</em>, 662355. (<a
href="https://doi.org/10.3389/frobt.2021.662355">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Research in creative robotics continues to expand across all creative domains, including art, music and language. Creative robots are primarily designed to be task specific, with limited research into the implications of their design outside their core task. In the case of a musical robot, this includes when a human sees and interacts with the robot before and after the performance, as well as in between pieces. These non-musical interaction tasks such as the presence of a robot during musical equipment set up, play a key role in the human perception of the robot however have received only limited attention. In this paper, we describe a new audio system using emotional musical prosody, designed to match the creative process of a musical robot for use before, between and after musical performances. Our generation system relies on the creation of a custom dataset for musical prosody. This system is designed foremost to operate in real time and allow rapid generation and dialogue exchange between human and robot. For this reason, the system combines symbolic deep learning through a Conditional Convolution Variational Auto-encoder, with an emotion-tagged audio sampler. We then compare this to a SOTA text-to-speech system in our robotic platform, Shimon the marimba player.We conducted a between-groups study with 100 participants watching a musician interact for 30 s with Shimon. We were able to increase user ratings for the key creativity metrics; novelty and coherence, while maintaining ratings for expressivity across each implementation. Our results also indicated that by communicating in a form that relates to the robot’s core functionality, we can raise likeability and perceived intelligence, while not altering animacy or anthropomorphism. These findings indicate the variation that can occur in the perception of a robot based on interactions surrounding a performance, such as initial meetings and spaces between pieces, in addition to the core creative algorithms.},
  archive      = {J_FROBT},
  author       = {Savery, Richard and Zahray, Lisa and Weinberg, Gil},
  doi          = {10.3389/frobt.2021.662355},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {662355},
  shortjournal = {Front. Robot. AI},
  title        = {Before, between, and after: Enriching robot communication surrounding collaborative creative activities},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Creative action at a distance: A conceptual framework for
embodied performance with robotic actors. <em>FROBT</em>, <em>8</em>,
662182. (<a href="https://doi.org/10.3389/frobt.2021.662182">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Acting, stand-up and dancing are creative, embodied performances that nonetheless follow a script. Unless experimental or improvised, the performers draw their movements from much the same stock of embodied schemas. A slavish following of the script leaves no room for creativity, but active interpretation of the script does. It is the choices one makes, of words and actions, that make a performance creative. In this theory and hypothesis article, we present a framework for performance and interpretation within robotic storytelling. The performance framework is built upon movement theory, and defines a taxonomy of basic schematic movements and the most important gesture types. For the interpretation framework, we hypothesise that emotionally-grounded choices can inform acts of metaphor and blending, to elevate a scripted performance into a creative one. Theory and hypothesis are each grounded in empirical research, and aim to provide resources for other robotic studies of the creative use of movement and gestures.},
  archive      = {J_FROBT},
  author       = {Wicke, Philipp and Veale, Tony},
  doi          = {10.3389/frobt.2021.662182},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {662182},
  shortjournal = {Front. Robot. AI},
  title        = {Creative action at a distance: A conceptual framework for embodied performance with robotic actors},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Editorial: Advanced control methods in marine robotics
applications. <em>FROBT</em>, <em>8</em>, 654581. (<a
href="https://doi.org/10.3389/frobt.2021.654581">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Bonsignorio, Fabio and Zereik, Enrica and Bibuli, Marco and Pettersen, Kristin Y. and Khatib, Oussama},
  doi          = {10.3389/frobt.2021.654581},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {654581},
  shortjournal = {Front. Robot. AI},
  title        = {Editorial: Advanced control methods in marine robotics applications},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Leveraging human perception in robot grasping and
manipulation through crowdsourcing and gamification. <em>FROBT</em>,
<em>8</em>, 652760. (<a
href="https://doi.org/10.3389/frobt.2021.652760">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robot grasping in unstructured and dynamic environments is heavily dependent on the object attributes. Although Deep Learning approaches have delivered exceptional performance in robot perception, human perception and reasoning are still superior in processing novel object classes. Furthermore, training such models requires large, difficult to obtain datasets. This work combines crowdsourcing and gamification to leverage human intelligence, enhancing the object recognition and attribute estimation processes of robot grasping. The framework employs an attribute matching system that encodes visual information into an online puzzle game, utilizing the collective intelligence of players to expand the attribute database and react to real-time perception conflicts. The framework is deployed and evaluated in two proof-of-concept applications: enhancing the control of a robotic exoskeleton glove and improving object identification for autonomous robot grasping. In addition, a model for estimating the framework response time is proposed. The obtained results demonstrate that the framework is capable of rapid adaptation to novel object classes, based purely on visual information and human experience.},
  archive      = {J_FROBT},
  author       = {Gorjup, Gal and Gerez, Lucas and Liarokapis, Minas},
  doi          = {10.3389/frobt.2021.652760},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {652760},
  shortjournal = {Front. Robot. AI},
  title        = {Leveraging human perception in robot grasping and manipulation through crowdsourcing and gamification},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Travelling santa problem: Optimization of a
million-households tour within one hour. <em>FROBT</em>, <em>8</em>,
652417. (<a href="https://doi.org/10.3389/frobt.2021.652417">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Finding the shortest tour visiting all given points at least ones belongs to the most famous optimization problems until today [travelling salesman problem (TSP)]. Optimal solutions exist for many problems up to several ten thousand points. The major difficulty in solving larger problems is the required computational complexity. This shifts the research from finding the optimum with no time limitation to approaches that find good but sub-optimal solutions in pre-defined limited time. This paper proposes a new approach for two-dimensional symmetric problems with more than a million coordinates that is able to create good initial tours within few minutes. It is based on a hierarchical clustering strategy and supports parallel processing. In addition, a method is proposed that can correct unfavorable paths with moderate computational complexity. The new approach is superior to state-of-the-art methods when applied to TSP instances with non-uniformly distributed coordinates.},
  archive      = {J_FROBT},
  author       = {Strutz, Tilo},
  doi          = {10.3389/frobt.2021.652417},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {652417},
  shortjournal = {Front. Robot. AI},
  title        = {Travelling santa problem: Optimization of a million-households tour within one hour},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). I can see it in your eyes: Gaze as an implicit cue of
uncanniness and task performance in repeated interactions with robots.
<em>FROBT</em>, <em>8</em>, 645956. (<a
href="https://doi.org/10.3389/frobt.2021.645956">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Over the past years, extensive research has been dedicated to developing robust platforms and data-driven dialog models to support long-term human-robot interactions. However, little is known about how people&#39;s perception of robots and engagement with them develop over time and how these can be accurately assessed through implicit and continuous measurement techniques. In this paper, we explore this by involving participants in three interaction sessions with multiple days of zero exposure in between. Each session consists of a joint task with a robot as well as two short social chats with it before and after the task. We measure participants&#39; gaze patterns with a wearable eye-tracker and gauge their perception of the robot and engagement with it and the joint task using questionnaires. Results disclose that aversion of gaze in a social chat is an indicator of a robot&#39;s uncanniness and that the more people gaze at the robot in a joint task, the worse they perform. In contrast with most HRI literature, our results show that gaze toward an object of shared attention, rather than gaze toward a robotic partner, is the most meaningful predictor of engagement in a joint task. Furthermore, the analyses of gaze patterns in repeated interactions disclose that people&#39;s mutual gaze in a social chat develops congruently with their perceptions of the robot over time. These are key findings for the HRI community as they entail that gaze behavior can be used as an implicit measure of people&#39;s perception of robots in a social chat and of their engagement and task performance in a joint task.},
  archive      = {J_FROBT},
  author       = {Perugia, Giulia and Paetzel-Prüsmann, Maike and Alanenpää, Madelene and Castellano, Ginevra},
  doi          = {10.3389/frobt.2021.645956},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {645956},
  shortjournal = {Front. Robot. AI},
  title        = {I can see it in your eyes: Gaze as an implicit cue of uncanniness and task performance in repeated interactions with robots},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Validating a termite-inspired construction coordination
mechanism using an autonomous robot. <em>FROBT</em>, <em>8</em>, 645728.
(<a href="https://doi.org/10.3389/frobt.2021.645728">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many species of termites build large, structurally complex mounds, and the mechanisms behind this coordinated construction have been a longstanding topic of investigation. Recent work has suggested that humidity may play a key role in the mound expansion of savannah-dwelling Macrotermes species: termites preferentially deposit soil on the mound surface at the boundary of the high-humidity region characteristic of the mound interior, implying a coordination mechanism through environmental feedback where addition of wet soil influences the humidity profile and vice versa. Here we test this potential mechanism physically using a robotic system. Local humidity measurements provide a cue for material deposition. As the analogue of the termite&#39;s deposition of wet soil and corresponding local increase in humidity, the robot drips water onto an absorbent substrate as it moves. Results show that the robot extends a semi-enclosed area outward when air is undisturbed, but closes it off when air is disturbed by an external fan, consistent with termite building activity in still vs. windy conditions. This result demonstrates an example of adaptive construction patterns arising from the proposed coordination mechanism, and supports the hypothesis that such a mechanism operates in termites.},
  archive      = {J_FROBT},
  author       = {Carey, Nicole E. and Bardunias, Paul and Nagpal, Radhika and Werfel, Justin},
  doi          = {10.3389/frobt.2021.645728},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {645728},
  shortjournal = {Front. Robot. AI},
  title        = {Validating a termite-inspired construction coordination mechanism using an autonomous robot},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A muscle-first, electromechanical hybrid gait restoration
system in people with spinal cord injury. <em>FROBT</em>, <em>8</em>,
645588. (<a href="https://doi.org/10.3389/frobt.2021.645588">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The development of a hybrid system for people with spinal cord injuries is described. The system includes implanted neural stimulation to activate the user&#39;s otherwise paralyzed muscles, an exoskeleton with electromechanical actuators at the hips and knees, and a sensory and control system that integrates both components. We are using a muscle-first approach: The person&#39;s muscles are the primary motivator for his/her joints and the motors provide power assistance. This design philosophy led to the development of high efficiency, low friction joint actuators, and feed-forward, burst-torque control. The system was tested with two participants with spinal cord injury (SCI) and unique implanted stimulation systems. Torque burst addition was found to increase gait speed. The system was found to satisfy the main design requirements as laid out at the outset.},
  archive      = {J_FROBT},
  author       = {Nandor, Mark and Kobetic, Rudi and Audu, Musa and Triolo, Ron and Quinn, Roger},
  doi          = {10.3389/frobt.2021.645588},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {645588},
  shortjournal = {Front. Robot. AI},
  title        = {A muscle-first, electromechanical hybrid gait restoration system in people with spinal cord injury},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Characterizing continuous manipulation families for
dexterous soft robot hands. <em>FROBT</em>, <em>8</em>, 645290. (<a
href="https://doi.org/10.3389/frobt.2021.645290">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There has been an explosion of ideas in soft robotics over the past decade, resulting in unprecedented opportunities for end effector design. Soft robot hands offer benefits of low-cost, compliance, and customized design, with the promise of dexterity and robustness. The space of opportunities is vast and exciting. However, new tools are needed to understand the capabilities of such manipulators and to facilitate manipulation planning with soft manipulators that exhibit free-form deformations. To address this challenge, we introduce a sampling based approach to discover and model continuous families of manipulations for soft robot hands. We give an overview of the soft foam robots in production in our lab and describe novel algorithms developed to characterize manipulation families for such robots. Our approach consists of sampling a space of manipulation actions, constructing Gaussian Mixture Model representations covering successful regions, and refining the results to create continuous successful regions representing the manipulation family. The space of manipulation actions is very high dimensional; we consider models with and without dimensionality reduction and provide a rigorous approach to compare models across different dimensions by comparing coverage of an unbiased test dataset in the full dimensional parameter space. Results show that some dimensionality reduction is typically useful in populating the models, but without our technique, the amount of dimensionality reduction to use is difficult to predict ahead of time and can depend on the hand and task. The models we produce can be used to plan and carry out successful, robust manipulation actions and to compare competing robot hand designs.},
  archive      = {J_FROBT},
  author       = {Sun, Jiatian and King, Jonathan P. and Pollard, Nancy S.},
  doi          = {10.3389/frobt.2021.645290},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {645290},
  shortjournal = {Front. Robot. AI},
  title        = {Characterizing continuous manipulation families for dexterous soft robot hands},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Aerial swarm defense by StringNet herding: Theory and
experiments. <em>FROBT</em>, <em>8</em>, 640446. (<a
href="https://doi.org/10.3389/frobt.2021.640446">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies a defense approach against one or more swarms of adversarial agents. In our earlier work, we employed a closed formation (“StringNet”) of defending agents (defenders) around a swarm of adversarial agents (attackers) to confine their motion within given bounds, and guide them to a safe area. The adversarial agents were assumed to remain close enough to each other, i.e., within a prescribed connectivity region. To handle situations when the attackers no longer stay within such a connectivity region, but rather split into smaller swarms (clusters) to maximize the chance or impact of attack, this paper proposes an approach to learn the attacking sub-swarms and reassign defenders toward the attackers. We use a “Density-based Spatial Clustering of Application with Noise (DBSCAN)” algorithm to identify the spatially distributed swarms of the attackers. Then, the defenders are assigned to each identified swarm of attackers by solving a constrained generalized assignment problem. We also provide conditions under which defenders can successfully herd all the attackers. The efficacy of the approach is demonstrated via computer simulations, as well as hardware experiments with a fleet of quadrotors.},
  archive      = {J_FROBT},
  author       = {Chipade, Vishnu S. and Marella, Venkata Sai Aditya and Panagou, Dimitra},
  doi          = {10.3389/frobt.2021.640446},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {640446},
  shortjournal = {Front. Robot. AI},
  title        = {Aerial swarm defense by StringNet herding: Theory and experiments},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Can robots earn our trust the same way humans do? A
systematic exploration of competence, warmth, and anthropomorphism as
determinants of trust development in HRI. <em>FROBT</em>, <em>8</em>,
640444. (<a href="https://doi.org/10.3389/frobt.2021.640444">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robots increasingly act as our social counterparts in domains such as healthcare and retail. For these human-robot interactions (HRI) to be effective, a question arises on whether we trust robots the same way we trust humans. We investigated whether the determinants competence and warmth, known to influence interpersonal trust development, influence trust development in HRI, and what role anthropomorphism plays in this interrelation. In two online studies with 2 × 2 between-subjects design, we investigated the role of robot competence (Study 1) and robot warmth (Study 2) in trust development in HRI. Each study explored the role of robot anthropomorphism in the respective interrelation. Videos showing an HRI were used for manipulations of robot competence (through varying gameplay competence) and robot anthropomorphism (through verbal and non-verbal design cues and the robot&#39;s presentation within the study introduction) in Study 1 (n = 155) as well as robot warmth (through varying compatibility of intentions with the human player) and robot anthropomorphism (same as Study 1) in Study 2 (n = 157). Results show a positive effect of robot competence (Study 1) and robot warmth (Study 2) on trust development in robots regarding anticipated trust and attributed trustworthiness. Subjective perceptions of competence (Study 1) and warmth (Study 2) mediated the interrelations in question. Considering applied manipulations, robot anthropomorphism neither moderated interrelations of robot competence and trust (Study 1) nor robot warmth and trust (Study 2). Considering subjective perceptions, perceived anthropomorphism moderated the effect of perceived competence (Study 1) and perceived warmth (Study 2) on trust on an attributional level. Overall results support the importance of robot competence and warmth for trust development in HRI and imply transferability regarding determinants of trust development in interpersonal interaction to HRI. Results indicate a possible role of perceived anthropomorphism in these interrelations and support a combined consideration of these variables in future studies. Insights deepen the understanding of key variables and their interaction in trust dynamics in HRI and suggest possibly relevant design factors to enable appropriate trust levels and a resulting desirable HRI. Methodological and conceptual limitations underline benefits of a rather robot-specific approach for future research.},
  archive      = {J_FROBT},
  author       = {Christoforakos, Lara and Gallucci, Alessio and Surmava-Große, Tinatini and Ullrich, Daniel and Diefenbach, Sarah},
  doi          = {10.3389/frobt.2021.640444},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {640444},
  shortjournal = {Front. Robot. AI},
  title        = {Can robots earn our trust the same way humans do? a systematic exploration of competence, warmth, and anthropomorphism as determinants of trust development in HRI},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Anti-sway and positioning adaptive control of a
double-pendulum effect crane system with neural network compensation.
<em>FROBT</em>, <em>8</em>, 639734. (<a
href="https://doi.org/10.3389/frobt.2021.639734">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cranes are widely used in the field of construction, logistics, and the manufacturing industry. Cranes that use wire ropes as the main lifting mechanism are deeply troubled by the swaying of heavy objects, which seriously restricts the working efficiency of the crane and even cause accidents. Compared with the single-pendulum crane, the double-pendulum effect crane model has stronger nonlinearity, and its controller design is challenging. In this paper, cranes with a double-pendulum effect are considered, and their nonlinear dynamical models are established. Then, a controller based on the radial basis function (RBF) neural network compensation adaptive method is designed, and a stability analysis is also presented. Finally, the hardware-in-the-loop experimental results show that the neural network compensation control can effectively improve the control performance of the controller in practice.},
  archive      = {J_FROBT},
  author       = {Qiang, Hai-yan and Sun, You-gang and Lyu, Jin-chao and Dong, Da-shan},
  doi          = {10.3389/frobt.2021.639734},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {639734},
  shortjournal = {Front. Robot. AI},
  title        = {Anti-sway and positioning adaptive control of a double-pendulum effect crane system with neural network compensation},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). MAP-elites enables powerful stepping stones and diversity
for modular robotics. <em>FROBT</em>, <em>8</em>, 639173. (<a
href="https://doi.org/10.3389/frobt.2021.639173">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In modular robotics modules can be reconfigured to change the morphology of the robot, making it able to adapt to specific tasks. However, optimizing both the body and control of such robots is a difficult challenge due to the intricate relationship between fine-tuning control and morphological changes that can invalidate such optimizations. These challenges can trap many optimization algorithms in local optima, halting progress towards better solutions. To solve this challenge we compare three different Evolutionary Algorithms on their capacity to optimize high performing and diverse morphologies and controllers in modular robotics. We compare two objective-based search algorithms, with and without a diversity promoting objective, with a Quality Diversity algorithm—MAP-Elites. The results show that MAP-Elites is capable of evolving the highest performing solutions in addition to generating the largest morphological diversity. Further, MAP-Elites is superior at regaining performance when transferring the population to new and more difficult environments. By analyzing genealogical ancestry we show that MAP-Elites produces more diverse and higher performing stepping stones than the two other objective-based search algorithms. The experiments transitioning the populations to new environments show the utility of morphological diversity, while the analysis of stepping stones show a strong correlation between diversity of ancestry and maximum performance on the locomotion task. Together, these results demonstrate the suitability of MAP-elites for the challenging task of morphology-control search for modular robots, and shed light on the algorithm’s capability of generating stepping stones for reaching high-performing solutions.},
  archive      = {J_FROBT},
  author       = {Nordmoen, Jørgen and Veenstra, Frank and Ellefsen, Kai Olav and Glette, Kyrre},
  doi          = {10.3389/frobt.2021.639173},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {639173},
  shortjournal = {Front. Robot. AI},
  title        = {MAP-elites enables powerful stepping stones and diversity for modular robotics},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). A comparative study of adaptive interlimb coordination
mechanisms for self-organized robot locomotion. <em>FROBT</em>,
<em>8</em>, 638684. (<a
href="https://doi.org/10.3389/frobt.2021.638684">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Walking animals demonstrate impressive self-organized locomotion and adaptation to body property changes by skillfully manipulating their complicated and redundant musculoskeletal systems. Adaptive interlimb coordination plays a crucial role in this achievement. It has been identified that interlimb coordination is generated through dynamical interactions between the neural system, musculoskeletal system, and environment. Based on this principle, two classical interlimb coordination mechanisms (continuous phase modulation and phase resetting) have been proposed independently. These mechanisms use decoupled central pattern generators (CPGs) with sensory feedback, such as ground reaction forces (GRFs), to generate robot locomotion autonomously without predefining it (i.e., self-organized locomotion). A comparative study was conducted on the two mechanisms under decoupled CPG-based control implemented on a quadruped robot in simulation. Their characteristics were compared by observing their CPG phase convergence processes at different control parameter values. Additionally, the mechanisms were investigated when the robot faced various unexpected situations, such as noisy feedback, leg motor damage, and carrying a load. The comparative study reveals that the phase modulation and resetting mechanisms demonstrate satisfactory performance when they are subjected to symmetric and asymmetric GRF distributions, respectively. This work also suggests a strategy for the appropriate selection of adaptive interlimb coordination mechanisms under different conditions and for the optimal setting of their control parameter values to enhance their control performance.},
  archive      = {J_FROBT},
  author       = {Sun, Tao and Xiong, Xiaofeng and Dai, Zhendong and Owaki, Dai and Manoonpong, Poramate},
  doi          = {10.3389/frobt.2021.638684},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {638684},
  shortjournal = {Front. Robot. AI},
  title        = {A comparative study of adaptive interlimb coordination mechanisms for self-organized robot locomotion},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Improved continuum joint configuration estimation using a
linear combination of length measurements and optimization of sensor
placement. <em>FROBT</em>, <em>8</em>, 637301. (<a
href="https://doi.org/10.3389/frobt.2021.637301">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents methods for placing length sensors on a soft continuum robot joint as well as a novel configuration estimation method that drastically minimizes configuration estimation error. The methods utilized for placing sensors along the length of the joint include a single joint length sensor, sensors lined end-to-end, sensors that overlap according to a heuristic, and sensors that are placed by an optimization that we describe in this paper. The methods of configuration estimation include directly relating sensor length to a segment of the joint&#39;s angle, using an equal weighting of overlapping sensors that cover a joint segment, and using a weighted linear combination of all sensors on the continuum joint. The weights for the linear combination method are determined using robust linear regression. Using a kinematic simulation we show that placing three or more overlapping sensors and estimating the configuration with a linear combination of sensors resulted in a median error of 0.026% of the max range of motion or less. This is over a 500 times improvement as compared to using a single sensor to estimate the joint configuration. This error was computed across 80 simulated robots of different lengths and ranges of motion. We also found that the fully optimized sensor placement performed only marginally better than the placement of sensors according to the heuristic. This suggests that the use of a linear combination of sensors, with weights found using linear regression is more important than the placement of the overlapping sensors. Further, using the heuristic significantly simplifies the application of these techniques when designing for hardware.},
  archive      = {J_FROBT},
  author       = {Rupert, Levi and Duggan, Timothy and Killpack, Marc D.},
  doi          = {10.3389/frobt.2021.637301},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {637301},
  shortjournal = {Front. Robot. AI},
  title        = {Improved continuum joint configuration estimation using a linear combination of length measurements and optimization of sensor placement},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Copresence with virtual humans in mixed reality: The impact
of contextual responsiveness on social perceptions. <em>FROBT</em>,
<em>8</em>, 634520. (<a
href="https://doi.org/10.3389/frobt.2021.634520">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Virtual humans (VHs)—automated, three-dimensional agents—can serve as realistic embodiments for social interactions with human users. Extant literature suggests that a user’s cognitive and affective responses toward a VH depend on the extent to which the interaction elicits a sense of copresence, or the subjective “sense of being together.” Furthermore, prior research has linked copresence to important social outcomes (e.g., likeability and trust), emphasizing the need to understand which factors contribute to this psychological state. Although there is some understanding of the determinants of copresence in virtual reality (VR) (cf. Oh et al., 2018), it is less known what determines copresence in mixed reality (MR), a modality wherein VHs have unique access to social cues in a “real-world” setting. In the current study, we examined the extent to which a VH’s responsiveness to events occurring in the user’s physical environment increased a sense of copresence and heightened affective connections to the VH. Participants (N = 65) engaged in two collaborative tasks with a (nonspeaking) VH using an MR headset. In the first task, no event in the participant’s physical environment would occur, which served as the control condition. In the second task, an event in the participants’ physical environment occurred, to which the VH either responded or ignored depending on the experimental condition. Copresence and interpersonal evaluations of the VHs were measured after each collaborative task via self-reported measures. Results show that when the VH responded to the physical event, participants experienced a significant stronger sense of copresence than when the VH did not respond. However, responsiveness did not elicit more positive evaluations toward the VH (likeability and emotional connectedness). This study is an integral first step in establishing how and when affective and cognitive components of evaluations during social interactions diverge. Importantly, the findings suggest that feeling copresence with VH in MR is partially determined by the VHs’ response to events in the actual physical environment shared by both interactants.},
  archive      = {J_FROBT},
  author       = {Pimentel, Daniel and Vinkers, Charlotte},
  doi          = {10.3389/frobt.2021.634520},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {634520},
  shortjournal = {Front. Robot. AI},
  title        = {Copresence with virtual humans in mixed reality: The impact of contextual responsiveness on social perceptions},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Cognitive intervention through photo-integrated conversation
moderated by robots (PICMOR) program: A randomized controlled trial.
<em>FROBT</em>, <em>8</em>, 633076. (<a
href="https://doi.org/10.3389/frobt.2021.633076">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Social interaction might prevent or delay dementia, but little is known about the specific effects of various social activity interventions on cognition. This study conducted a single-site randomized controlled trial (RCT) of Photo-Integrated Conversation Moderated by Robots (PICMOR), a group conversation intervention program for resilience against cognitive decline and dementia. In the RCT, PICMOR was compared to an unstructured group conversation condition. Sixty-five community-living older adults participated in this study. The intervention was provided once a week for 12 weeks. Primary outcome measures were the cognitive functions; process outcome measures included the linguistic characteristics of speech to estimate interaction quality. Baseline and post-intervention data were collected. PICMOR contains two key features: 1) photos taken by the participants are displayed and discussed sequentially; and 2) a robotic moderator manages turn-taking to make sure that participants are allocated the same amount of time. Among the primary outcome measures, one of the subcategories of cognitive functions, verbal fluency significantly improved in the intervention group. Among the process outcome measures, a part of the subcategories of linguistic characteristics of speech, the amount of speech and richness of words, proportion of providing topics, questions, and answers in total utterances were larger for the intervention group. This study demonstrated for the first time the positive effects of a robotic social activity intervention on cognitive function in healthy older adults via RCT. The group conversation generated by PICMOR may improve participants’ verbal fluency since participants have more opportunity to provide their own topics, asking and answering questions which results in exploring larger vocabularies. PICMOR is available and accessible to community-living older adults.Clinical Trial Registration:UMIN Clinical Trials Registry, identifier UMIN000036667.},
  archive      = {J_FROBT},
  author       = {Otake-Matsuura, Mihoko and Tokunaga, Seiki and Watanabe, Kumi and Abe, Masato S. and Sekiguchi, Takuya and Sugimoto, Hikaru and Kishimoto, Taishiro and Kudo, Takashi},
  doi          = {10.3389/frobt.2021.633076},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {633076},
  shortjournal = {Front. Robot. AI},
  title        = {Cognitive intervention through photo-integrated conversation moderated by robots (PICMOR) program: A randomized controlled trial},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). 3D facial pain expression for a care training assistant
robot in an elderly care education environment. <em>FROBT</em>,
<em>8</em>, 632015. (<a
href="https://doi.org/10.3389/frobt.2021.632015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the elderly population increases, the importance of the caregiver’s role in the quality of life of the elderly has increased. To achieve effective feedback in terms of care and nursing education, it is important to design a robot that can express emotions or feel pain like an actual human through visual-based feedback. This study proposes a care training assistant robot (CaTARo) system with 3D facial pain expression that simulates an elderly person for improving the skills of workers in elderly care. First, in order to develop an accurate and efficient system for elderly care training, this study introduces a fuzzy logic–based care training evaluation method that can calculate the pain level of a robot for giving the feedback. Elderly caregivers and trainees performed the range of motion exercise using the proposed CaTARo. We obtained quantitative data from CaTARo, and the pain level was calculated by combining four key parameters using the fuzzy logic method. Second, we developed a 3D facial avatar for use in CaTARo that is capable of expressing pain based on the UNBC-McMaster Pain Shoulder Archive, and we then generated four pain groups with respect to the pain level. To mimic the conditions for care training with actual humans, we designed the system to provide pain feedback based on the opinions of experts. The pain feedback was expressed in real time by using a projector and a 3D facial mask during care training. The results of the study confirmed the feasibility of utilizing a care training robot with pain expression for elderly care training, and it is concluded that the proposed approach may be used to improve caregiving and nursing skills upon further research.},
  archive      = {J_FROBT},
  author       = {Lee, Miran and Tran, Dinh Tuan and Lee, Joo-Ho},
  doi          = {10.3389/frobt.2021.632015},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {632015},
  shortjournal = {Front. Robot. AI},
  title        = {3D facial pain expression for a care training assistant robot in an elderly care education environment},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Brainless walking: Animal gaits emerge from an actuator
characteristic. <em>FROBT</em>, <em>8</em>, 629679. (<a
href="https://doi.org/10.3389/frobt.2021.629679">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, we discovered a phenomenon in which a quadruped robot without any sensors or microprocessor can autonomously generate the various gait patterns of animals using actuator characteristics and select the gaits according to the speed. The robot has one DC motor on each limb and a slider-crank mechanism connected to the motor shaft. Since each motor is directly connected to a power supply, the robot only moves its foot on an elliptical trajectory under a constant voltage. Although this robot does not have any computational equipment such as sensors or microprocessors, when we applied a voltage to the motor, each limb begins to adjust its gait autonomously and finally converged to a steady gait pattern. Furthermore, by raising the input voltage from the power supply, the gait changed from a pace to a half-bound, according to the speed, and also we observed various gait patterns, such as a bound or a rotary gallop. We investigated the convergence property of the gaits for several initial states and input voltages and have described detailed experimental results of each gait observed.},
  archive      = {J_FROBT},
  author       = {Masuda, Yoichi and Naniwa, Keisuke and Ishikawa, Masato and Osuka, Koichi},
  doi          = {10.3389/frobt.2021.629679},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {629679},
  shortjournal = {Front. Robot. AI},
  title        = {Brainless walking: Animal gaits emerge from an actuator characteristic},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Dynamic turning of a soft quadruped robot by changing phase
difference. <em>FROBT</em>, <em>8</em>, 629523. (<a
href="https://doi.org/10.3389/frobt.2021.629523">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic locomotion of a quadruped robot emerges from interaction between the robot body and the terrain. When the robot has a soft body, dynamic locomotion can be realized using a simple controller. This study investigates dynamic turning of a soft quadruped robot by changing the phase difference among the legs of the robot. We develop a soft quadruped robot driven by McKibben pneumatic artificial muscles. The phase difference between the hind and fore legs is fixed whereas that between the left and right legs is changed to enable the robot to turn dynamically. Since the robot legs are soft, the contact pattern between the legs and the terrain can be varied adaptively by simply changing the phase difference. Experimental results demonstrate that changes in the phase difference lead to changes in the contact time of the hind legs, and as a result, the soft robot can turn dynamically.},
  archive      = {J_FROBT},
  author       = {Tanaka, Hiroaki and Chen, Tsung-Yuan and Hosoda, Koh},
  doi          = {10.3389/frobt.2021.629523},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {629523},
  shortjournal = {Front. Robot. AI},
  title        = {Dynamic turning of a soft quadruped robot by changing phase difference},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Do privacy concerns about social robots affect use
intentions? Evidence from an experimental vignette study.
<em>FROBT</em>, <em>8</em>, 627958. (<a
href="https://doi.org/10.3389/frobt.2021.627958">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While the privacy implications of social robots have been increasingly discussed and privacy-sensitive robotics is becoming a research field within human–robot interaction, little empirical research has investigated privacy concerns about robots and the effect they have on behavioral intentions. To address this gap, we present the results of an experimental vignette study that includes antecedents from the privacy, robotics, technology adoption, and trust literature. Using linear regression analysis, with the privacy-invasiveness of a fictional but realistic robot as the key manipulation, we show that privacy concerns affect use intention significantly and negatively. Compared with earlier work done through a survey, where we found a robot privacy paradox, the experimental vignette approach allows for a more realistic and tangible assessment of respondents&#39; concerns and behavioral intentions, showing how potential robot users take into account privacy as consideration for future behavior. We contextualize our findings within broader debates on privacy and data protection with smart technologies.},
  archive      = {J_FROBT},
  author       = {Lutz, Christoph and Tamò-Larrieux, Aurelia},
  doi          = {10.3389/frobt.2021.627958},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {627958},
  shortjournal = {Front. Robot. AI},
  title        = {Do privacy concerns about social robots affect use intentions? evidence from an experimental vignette study},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Towards a machine vision-based yield monitor for the
counting and quality mapping of shallots. <em>FROBT</em>, <em>8</em>,
627067. (<a href="https://doi.org/10.3389/frobt.2021.627067">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In comparison to field crops such as cereals, cotton, hay and grain, specialty crops often require more resources, are usually more sensitive to sudden changes in growth conditions and are known to produce higher value products. Providing quality and quantity assessment of specialty crops during harvesting is crucial for securing higher returns and improving management practices. Technical advancements in computer and machine vision have improved the detection, quality assessment and yield estimation processes for various fruit crops, but similar methods capable of exporting a detailed yield map for vegetable crops have yet to be fully developed. A machine vision-based yield monitor was designed to perform size categorization and continuous counting of shallots in-situ during the harvesting process. Coupled with a software developed in Python, the system is composed of a video logger and a global navigation satellite system. Computer vision analysis is performed within the tractor while an RGB camera collects real-time video data of the crops under natural sunlight conditions. Vegetables are first segmented using Watershed segmentation, detected on the conveyor, and then classified by size. The system detected shallots in a subsample of the dataset with a precision of 76%. The software was also evaluated on its ability to classify the shallots into three size categories. The best performance was achieved in the large class (73%), followed by the small class (59%) and medium class (44%). Based on these results, the occasional occlusion of vegetables and inconsistent lighting conditions were the main factors that hindered performance. Although further enhancements are envisioned for the prototype system, its modular and novel design permits the mapping of a selection of other horticultural crops. Moreover, it has the potential to benefit many producers of small vegetable crops by providing them with useful harvest information in real-time.},
  archive      = {J_FROBT},
  author       = {Boatswain Jacques, Amanda A. and Adamchuk, Viacheslav I. and Park, Jaesung and Cloutier, Guillaume and Clark, James J. and Miller, Connor},
  doi          = {10.3389/frobt.2021.627067},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {627067},
  shortjournal = {Front. Robot. AI},
  title        = {Towards a machine vision-based yield monitor for the counting and quality mapping of shallots},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Off-policy evaluation of the performance of a robot swarm:
Importance sampling to assess potential modifications to the
finite-state machine that controls the robots. <em>FROBT</em>,
<em>8</em>, 625125. (<a
href="https://doi.org/10.3389/frobt.2021.625125">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the decentralized, loosely coupled nature of a swarm and to the lack of a general design methodology, the development of control software for robot swarms is typically an iterative process. Control software is generally modified and refined repeatedly, either manually or automatically, until satisfactory results are obtained. In this paper, we propose a technique based on off-policy evaluation to estimate how the performance of an instance of control software—implemented as a probabilistic finite-state machine—would be impacted by modifying the structure and the value of the parameters. The proposed technique is particularly appealing when coupled with automatic design methods belonging to the AutoMoDe family, as it can exploit the data generated during the design process. The technique can be used either to reduce the complexity of the control software generated, improving therefore its readability, or to evaluate perturbations of the parameters, which could help in prioritizing the exploration of the neighborhood of the current solution within an iterative improvement algorithm. To evaluate the technique, we apply it to control software generated with an AutoMoDe method, &lt;mml:math id=&quot;minf1&quot; xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi mathvariant=&quot;normal&quot;&gt;Chocolate&lt;/mml:mi&gt;&lt;mml:mo&gt;−&lt;/mml:mo&gt;&lt;mml:mn&gt;6&lt;/mml:mn&gt;&lt;mml:mi mathvariant=&quot;normal&quot;&gt;S&lt;/mml:mi&gt;&lt;mml:mtext&gt; &lt;/mml:mtext&gt;&lt;/mml:mrow&gt;&lt;/mml:math&gt;. In a first experiment, we use the proposed technique to estimate the impact of removing a state from a probabilistic finite-state machine. In a second experiment, we use it to predict the impact of changing the value of the parameters. The results show that the technique is promising and significantly better than a naive estimation. We discuss the limitations of the current implementation of the technique, and we sketch possible improvements, extensions, and generalizations.},
  archive      = {J_FROBT},
  author       = {Pagnozzi, Federico and Birattari, Mauro},
  doi          = {10.3389/frobt.2021.625125},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {625125},
  shortjournal = {Front. Robot. AI},
  title        = {Off-policy evaluation of the performance of a robot swarm: Importance sampling to assess potential modifications to the finite-state machine that controls the robots},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Motion smoothness metrics for cannulation skill assessment:
What factors matter? <em>FROBT</em>, <em>8</em>, 625003. (<a
href="https://doi.org/10.3389/frobt.2021.625003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Medical training simulators have the potential to provide remote and automated assessment of skill vital for medical training. Consequently, there is a need to develop “smart” training devices with robust metrics that can quantify clinical skills for effective training and self-assessment. Recently, metrics that quantify motion smoothness such as log dimensionless jerk (LDLJ) and spectral arc length (SPARC) are increasingly being applied in medical simulators. However, two key questions remain about the efficacy of such metrics: how do these metrics relate to clinical skill, and how to best compute these metrics from sensor data and relate them with similar metrics? This study addresses these questions in the context of hemodialysis cannulation by enrolling 52 clinicians who performed cannulation in a simulated arteriovenous (AV) fistula. For clinical skill, results demonstrate that the objective outcome metric flash ratio (FR), developed to measure the quality of task completion, outperformed traditional skill indicator metrics (years of experience and global rating sheet scores). For computing motion smoothness metrics for skill assessment, we observed that the lowest amount of smoothing could result in unreliable metrics. Furthermore, the relative efficacy of motion smoothness metrics when compared with other process metrics in correlating with skill was similar for FR, the most accurate measure of skill. These results provide guidance for the computation and use of motion-based metrics for clinical skill assessment, including utilizing objective outcome metrics as ideal measures for quantifying skill.},
  archive      = {J_FROBT},
  author       = {Singh, Simar and Bible, Joe and Liu, Zhanhe and Zhang, Ziyang and Singapogu, Ravikiran},
  doi          = {10.3389/frobt.2021.625003},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {625003},
  shortjournal = {Front. Robot. AI},
  title        = {Motion smoothness metrics for cannulation skill assessment: What factors matter?},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Automation inner speech as an anthropomorphic feature
affecting human trust: Current issues and future directions.
<em>FROBT</em>, <em>8</em>, 620026. (<a
href="https://doi.org/10.3389/frobt.2021.620026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper aims to discuss the possible role of inner speech in influencing trust in human–automation interaction. Inner speech is an everyday covert inner monolog or dialog with oneself, which is essential for human psychological life and functioning as it is linked to self-regulation and self-awareness. Recently, in the field of machine consciousness, computational models using different forms of robot speech have been developed that make it possible to implement inner speech in robots. As is discussed, robot inner speech could be a new feature affecting human trust by increasing robot transparency and anthropomorphism.},
  archive      = {J_FROBT},
  author       = {Geraci, Alessandro and D&#39;Amico, Antonella and Pipitone, Arianna and Seidita, Valeria and Chella, Antonio},
  doi          = {10.3389/frobt.2021.620026},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {620026},
  shortjournal = {Front. Robot. AI},
  title        = {Automation inner speech as an anthropomorphic feature affecting human trust: Current issues and future directions},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Fault-tolerant six-DoF pose estimation for tendon-driven
continuum mechanisms. <em>FROBT</em>, <em>8</em>, 619238. (<a
href="https://doi.org/10.3389/frobt.2021.619238">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a fault-tolerant estimation technique for the six-DoF pose of a tendon-driven continuum mechanisms using machine learning. In contrast to previous estimation techniques, no deformation model is required, and the pose prediction is rather performed with polynomial regression. As only a few datapoints are required for the regression, several estimators are trained with structured occlusions of the available sensor information, and clustered into ensembles based on the available sensors. By computing the variance of one ensemble, the uncertainty in the prediction is monitored and, if the variance is above a threshold, sensor loss is detected and handled. Experiments on the humanoid neck of the DLR robot DAVID, demonstrate that the accuracy of the predicted pose is significantly improved, and a reliable prediction can still be performed using only 3 out of 8 sensors.},
  archive      = {J_FROBT},
  author       = {Raffin, Antonin and Deutschmann, Bastian and Stulp, Freek},
  doi          = {10.3389/frobt.2021.619238},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {619238},
  shortjournal = {Front. Robot. AI},
  title        = {Fault-tolerant six-DoF pose estimation for tendon-driven continuum mechanisms},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Signal-based self-organization of a chain of UAVs for
subterranean exploration. <em>FROBT</em>, <em>8</em>, 614206. (<a
href="https://doi.org/10.3389/frobt.2021.614206">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Miniature multi-rotors are promising robots for navigating subterranean networks, but maintaining a radio connection underground is challenging. In this paper, we introduce a distributed algorithm, called U-Chain (for Underground-chain), that coordinates a chain of flying robots between an exploration drone and an operator. Our algorithm only uses the measurement of the signal quality between two successive robots and an estimate of the ground speed based on an optic flow sensor. It leverages a distributed policy for each UAV and a Kalman filter to get reliable estimates of the signal quality. We evaluate our approach formally and in simulation, and we describe experimental results with a chain of 3 real miniature quadrotors (12 by 12 cm) and a base station.},
  archive      = {J_FROBT},
  author       = {Laclau, Pierre and Tempez, Vladislav and Ruffier, Franck and Natalizio, Enrico and Mouret, Jean-Baptiste},
  doi          = {10.3389/frobt.2021.614206},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {614206},
  shortjournal = {Front. Robot. AI},
  title        = {Signal-based self-organization of a chain of UAVs for subterranean exploration},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Speech interaction to control a hands-free delivery robot
for high-risk health care scenarios. <em>FROBT</em>, <em>8</em>, 612750.
(<a href="https://doi.org/10.3389/frobt.2021.612750">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Covid-19 pandemic has had a widespread effect across the globe. The major effect on health-care workers and the vulnerable populations they serve has been of particular concern. Near-complete lockdown has been a common strategy to reduce the spread of the pandemic in environments such as live-in care facilities. Robotics is a promising area of research that can assist in reducing the spread of covid-19, while also preventing the need for complete physical isolation. The research presented in this paper demonstrates a speech-controlled, self-sanitizing robot that enables the delivery of items from a visitor to a resident of a care facility. The system is automated to reduce the burden on facility staff, and it is controlled entirely through hands-free audio interaction in order to reduce transmission of the virus. We demonstrate an end-to-end delivery test, and an in-depth evaluation of the speech interface. We also recorded a speech dataset with two conditions: the talker wearing a face mask and the talker not wearing a face mask. We then used this dataset to evaluate the speech recognition system. This enabled us to test the effect of face masks on speech recognition interfaces in the context of autonomous systems.},
  archive      = {J_FROBT},
  author       = {Grasse, Lukas and Boutros, Sylvain J. and Tata, Matthew S.},
  doi          = {10.3389/frobt.2021.612750},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {612750},
  shortjournal = {Front. Robot. AI},
  title        = {Speech interaction to control a hands-free delivery robot for high-risk health care scenarios},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). FaceGuard: A wearable system to avoid face touching.
<em>FROBT</em>, <em>8</em>, 612392. (<a
href="https://doi.org/10.3389/frobt.2021.612392">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most people touch their faces unconsciously, for instance to scratch an itch or to rest one’s chin in their hands. To reduce the spread of the novel coronavirus (COVID-19), public health officials recommend against touching one’s face, as the virus is transmitted through mucous membranes in the mouth, nose and eyes. Students, office workers, medical personnel and people on trains were found to touch their faces between 9 and 23 times per hour. This paper introduces FaceGuard, a system that utilizes deep learning to predict hand movements that result in touching the face, and provides sensory feedback to stop the user from touching the face. The system utilizes an inertial measurement unit (IMU) to obtain features that characterize hand movement involving face touching. Time-series data can be efficiently classified using 1D-Convolutional Neural Network (CNN) with minimal feature engineering; 1D-CNN filters automatically extract temporal features in IMU data. Thus, a 1D-CNN based prediction model is developed and trained with data from 4,800 trials recorded from 40 participants. Training data are collected for hand movements involving face touching during various everyday activities such as sitting, standing, or walking. Results showed that while the average time needed to touch the face is 1,200 ms, a prediction accuracy of more than 92% is achieved with less than 550 ms of IMU data. As for the sensory response, the paper presents a psychophysical experiment to compare the response time for three sensory feedback modalities, namely visual, auditory, and vibrotactile. Results demonstrate that the response time is significantly smaller for vibrotactile feedback (427.3 ms) compared to visual (561.70 ms) and auditory (520.97 ms). Furthermore, the success rate (to avoid face touching) is also statistically higher for vibrotactile and auditory feedback compared to visual feedback. These results demonstrate the feasibility of predicting a hand movement and providing timely sensory feedback within less than a second in order to avoid face touching.},
  archive      = {J_FROBT},
  author       = {Michelin, Allan Michael and Korres, Georgios and Ba’ara, Sara and Assadi, Hadi and Alsuradi, Haneen and Sayegh, Rony R. and Argyros, Antonis and Eid, Mohamad},
  doi          = {10.3389/frobt.2021.612392},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {612392},
  shortjournal = {Front. Robot. AI},
  title        = {FaceGuard: A wearable system to avoid face touching},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A flexible transoral robot towards COVID-19 swab sampling.
<em>FROBT</em>, <em>8</em>, 612167. (<a
href="https://doi.org/10.3389/frobt.2021.612167">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There are high risks of infection for surgeons during the face-to-face COVID-19 swab sampling due to the novel coronavirus’s infectivity. To address this issue, we propose a flexible transoral robot with a teleoperated configuration for swab sampling. The robot comprises a flexible manipulator, an endoscope with a monitor, and a master device. A 3-prismatic-universal (3-PU) flexible parallel mechanism with 3 degrees of freedom (DOF) is used to realize the manipulator’s movements. The flexibility of the manipulator improves the safety of testees. Besides, the master device is similar to the manipulator in structure. It is easy to use for operators. Under the guidance of the vision from the endoscope, the surgeon can operate the master device to control the swab’s motion attached to the manipulator for sampling. In this paper, the robotic system, the workspace, and the operation procedure are described in detail. The tongue depressor, which is used to prevent the tongue’s interference during the sampling, is also tested. The accuracy of the manipulator under visual guidance is validated intuitively. Finally, the experiment on a human phantom is conducted to demonstrate the feasibility of the robot preliminarily.},
  archive      = {J_FROBT},
  author       = {Li, Changsheng and Gu, Xiaoyi and Xiao, Xiao and Lim, Chwee Ming and Duan, Xingguang and Ren, Hongliang},
  doi          = {10.3389/frobt.2021.612167},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {612167},
  shortjournal = {Front. Robot. AI},
  title        = {A flexible transoral robot towards COVID-19 swab sampling},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Robotics and AI for teleoperation, tele-assessment, and
tele-training for surgery in the era of COVID-19: Existing challenges,
and future vision. <em>FROBT</em>, <em>8</em>, 610677. (<a
href="https://doi.org/10.3389/frobt.2021.610677">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The unprecedented shock caused by the COVID-19 pandemic has severely influenced the delivery of regular healthcare services. Most non-urgent medical activities, including elective surgeries, have been paused to mitigate the risk of infection and to dedicate medical resources to managing the pandemic. In this regard, not only surgeries are substantially influenced, but also pre- and post-operative assessment of patients and training for surgical procedures have been significantly impacted due to the pandemic. Many countries are planning a phased reopening, which includes the resumption of some surgical procedures. However, it is not clear how the reopening safe-practice guidelines will impact the quality of healthcare delivery. This perspective article evaluates the use of robotics and AI in 1) robotics-assisted surgery, 2) tele-examination of patients for pre- and post-surgery, and 3) tele-training for surgical procedures. Surgeons interact with a large number of staff and patients on a daily basis. Thus, the risk of infection transmission between them raises concerns. In addition, pre- and post-operative assessment also raises concerns about increasing the risk of disease transmission, in particular, since many patients may have other underlying conditions, which can increase their chances of mortality due to the virus. The pandemic has also limited the time and access that trainee surgeons have for training in the OR and/or in the presence of an expert. In this article, we describe existing challenges and possible solutions and suggest future research directions that may be relevant for robotics and AI in addressing the three tasks mentioned above.},
  archive      = {J_FROBT},
  author       = {Feizi, Navid and Tavakoli, Mahdi and Patel, Rajni V. and Atashzar, S. Farokh},
  doi          = {10.3389/frobt.2021.610677},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {610677},
  shortjournal = {Front. Robot. AI},
  title        = {Robotics and AI for teleoperation, tele-assessment, and tele-training for surgery in the era of COVID-19: Existing challenges, and future vision},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Perspective: Wearable internet of medical things for remote
tracking of symptoms, prediction of health anomalies, implementation of
preventative measures, and control of virus spread during the era of
COVID-19. <em>FROBT</em>, <em>8</em>, 610653. (<a
href="https://doi.org/10.3389/frobt.2021.610653">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The COVID-19 pandemic has highly impacted the communities globally by reprioritizing the means through which various societal sectors operate. Among these sectors, healthcare providers and medical workers have been impacted prominently due to the massive increase in demand for medical services under unprecedented circumstances. Hence, any tool that can help the compliance with social guidelines for COVID-19 spread prevention will have a positive impact on managing and controlling the virus outbreak and reducing the excessive burden on the healthcare system. This perspective article disseminates the perspectives of the authors regarding the use of novel biosensors and intelligent algorithms embodied in wearable IoMT frameworks for tackling this issue. We discuss how with the use of smart IoMT wearables certain biomarkers can be tracked for detection of COVID-19 in exposed individuals. We enumerate several machine learning algorithms which can be used to process a wide range of collected biomarkers for detecting (a) multiple symptoms of SARS-CoV-2 infection and (b) the dynamical likelihood of contracting the virus through interpersonal interaction. Eventually, we enunciate how a systematic use of smart wearable IoMT devices in various social sectors can intelligently help controlling the spread of COVID-19 in communities as they enter the reopening phase. We explain how this framework can benefit individuals and their medical correspondents by introducing Systems for Symptom Decoding (SSD), and how the use of this technology can be generalized on a societal level for the control of spread by introducing Systems for Spread Tracing (SST).},
  archive      = {J_FROBT},
  author       = {Mehrdad, Sarmad and Wang, Yao and Atashzar, S. Farokh},
  doi          = {10.3389/frobt.2021.610653},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {610653},
  shortjournal = {Front. Robot. AI},
  title        = {Perspective: Wearable internet of medical things for remote tracking of symptoms, prediction of health anomalies, implementation of preventative measures, and control of virus spread during the era of COVID-19},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Review: How can intelligent robots and smart mechatronic
modules facilitate remote assessment, assistance, and rehabilitation for
isolated adults with neuro-musculoskeletal conditions? <em>FROBT</em>,
<em>8</em>, 610529. (<a
href="https://doi.org/10.3389/frobt.2021.610529">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Worldwide, at the time this article was written, there are over 127 million cases of patients with a confirmed link to COVID-19 and about 2.78 million deaths reported. With limited access to vaccine or strong antiviral treatment for the novel coronavirus, actions in terms of prevention and containment of the virus transmission rely mostly on social distancing among susceptible and high-risk populations. Aside from the direct challenges posed by the novel coronavirus pandemic, there are serious and growing secondary consequences caused by the physical distancing and isolation guidelines, among vulnerable populations. Moreover, the healthcare system’s resources and capacity have been focused on addressing the COVID-19 pandemic, causing less urgent care, such as physical neurorehabilitation and assessment, to be paused, canceled, or delayed. Overall, this has left elderly adults, in particular those with neuromusculoskeletal (NMSK) conditions, without the required service support. However, in many cases, such as stroke, the available time window of recovery through rehabilitation is limited since neural plasticity decays quickly with time. Given that future waves of the outbreak are expected in the coming months worldwide, it is important to discuss the possibility of using available technologies to address this issue, as societies have a duty to protect the most vulnerable populations. In this perspective review article, we argue that intelligent robotics and wearable technologies can help with remote delivery of assessment, assistance, and rehabilitation services while physical distancing and isolation measures are in place to curtail the spread of the virus. By supporting patients and medical professionals during this pandemic, robots, and smart digital mechatronic systems can reduce the non-COVID-19 burden on healthcare systems. Digital health and cloud telehealth solutions that can complement remote delivery of assessment and physical rehabilitation services will be the subject of discussion in this article due to their potential in enabling more effective and safer NMSDK rehabilitation, assistance, and assessment service delivery. This article will hopefully lead to an interdisciplinary dialogue between the medical and engineering sectors, stake holders, and policy makers for a better delivery of care for those with NMSK conditions during a global health crisis including future pandemics.},
  archive      = {J_FROBT},
  author       = {Atashzar, S. Farokh and Carriere, Jay and Tavakoli, Mahdi},
  doi          = {10.3389/frobt.2021.610529},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {610529},
  shortjournal = {Front. Robot. AI},
  title        = {Review: How can intelligent robots and smart mechatronic modules facilitate remote assessment, assistance, and rehabilitation for isolated adults with neuro-musculoskeletal conditions?},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). 3D scanning of the forearm for orthosis and HMI
applications. <em>FROBT</em>, <em>8</em>, 576783. (<a
href="https://doi.org/10.3389/frobt.2021.576783">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rise of rehabilitation robotics has ignited a global investigation into the human machine interface (HMI) between device and user. Previous research on wearable robotics has primarily focused on robotic kinematics and controls but rarely on the actual design of the physical HMI (pHMI). This paper presents a data-driven statistical forearm surface model for designing a forearm orthosis in exoskeleton applications. The forearms of 6 subjects were 3D scanned in a custom-built jig to capture data in extreme pronation and supination poses, creating 3D point clouds of the forearm surface. Resulting data was characterized into a series of ellipses from 20 to 100% of the forearm length. Key ellipse parameters in the model include: normalized major and minor axis length, normalized center point location, tilt angle, and circularity ratio. Single-subject (SS) ellipse parameters were normalized with respect to forearm radiale-stylion (RS) length and circumference and then averaged over the 6 subjects. Averaged parameter profiles were fit with 3rd-order polynomials to create combined-subjects (CS) elliptical models of the forearm. CS models were created in the jig as-is (CS1) and after alignment to ellipse centers at 20 and 100% of the forearm length (CS2). Normalized curve fits of ellipse major and minor axes in model CS2 achieve R2 values ranging from 0.898 to 0.980 indicating a high degree of correlation between cross-sectional size and position along the forearm. Most other parameters showed poor correlation with forearm position (0.005 &amp;lt; R2 &amp;lt; 0.391) with the exception of tilt angle in pronation (0.877) and circularity in supination (0.657). Normalized RMSE of the CS2 ellipse-fit model ranged from 0.21 to 0.64% of forearm circumference and 0.22 to 0.46% of forearm length. The average and peak surface deviation between the scaled CS2 model and individual scans along the forearm varied from 0.56 to 2.86 mm (subject averages) and 3.86 to 7.16 (subject maximums), with the peak deviation occurring between 45 and 50% RS length. The developed equations allow reconstruction of a scalable 3D model that can be sized based on two user measures, RS length and forearm circumference, or based on generic arm measurements taken from existing anthropometric databases.},
  archive      = {J_FROBT},
  author       = {Perry, Joel C. and Brower, Jacob R. and Carne, Robert H. R. and Bogert, Melissa A.},
  doi          = {10.3389/frobt.2021.576783},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {576783},
  shortjournal = {Front. Robot. AI},
  title        = {3D scanning of the forearm for orthosis and HMI applications},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). AQuRo: A cat-like adaptive quadruped robot with novel
bio-inspired capabilities. <em>FROBT</em>, <em>8</em>, 562524. (<a
href="https://doi.org/10.3389/frobt.2021.562524">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There are currently many quadruped robots suited to a wide range of applications, but traversing some terrains, such as vertical ladders, remains an open challenge. There is still a need to develop adaptive robots that can walk and climb efficiently. This paper presents an adaptive quadruped robot that, by mimicking feline structure, supports several novel capabilities. We design a novel paw structure and several point-cloud-based sensory structures incorporating a quad-composite time-of-flight sensor and a dual-laser range finder. The proposed robot is equipped with physical and cognitive capabilities which include: 1) a dynamic-density topological map building with attention model, 2) affordance perception using the topological map, and 3) a neural-based locomotion model. The novel capabilities show strong integration between locomotion and internal–external sensory information, enabling short-term adaptations in response to environmental changes. The robot performed well in several situations: walking on natural terrain, walking with a leg malfunction, avoiding a sudden obstacle, climbing a vertical ladder. Further, we consider current problems and future development.},
  archive      = {J_FROBT},
  author       = {Saputra, Azhar Aulia and Takesue, Naoyuki and Wada, Kazuyoshi and Ijspeert, Auke Jan and Kubota, Naoyuki},
  doi          = {10.3389/frobt.2021.562524},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {562524},
  shortjournal = {Front. Robot. AI},
  title        = {AQuRo: A cat-like adaptive quadruped robot with novel bio-inspired capabilities},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The development of overtrust: An empirical simulation and
psychological analysis in the context of human–robot interaction.
<em>FROBT</em>, <em>8</em>, 554578. (<a
href="https://doi.org/10.3389/frobt.2021.554578">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With impressive developments in human–robot interaction it may seem that technology can do anything. Especially in the domain of social robots which suggest to be much more than programmed machines because of their anthropomorphic shape, people may overtrust the robot&#39;s actual capabilities and its reliability. This presents a serious problem, especially when personal well-being might be at stake. Hence, insights about the development and influencing factors of overtrust in robots may form an important basis for countermeasures and sensible design decisions. An empirical study [N = 110] explored the development of overtrust using the example of a pet feeding robot. A 2 × 2 experimental design and repeated measurements contrasted the effect of one&#39;s own experience, skill demonstration, and reputation through experience reports of others. The experiment was realized in a video environment where the participants had to imagine they were going on a four-week safari trip and leaving their beloved cat at home, making use of a pet feeding robot. Every day, the participants had to make a choice: go to a day safari without calling options (risk and reward) or make a boring car trip to another village to check if the feeding was successful and activate an emergency call if not (safe and no reward). In parallel to cases of overtrust in other domains (e.g., autopilot), the feeding robot performed flawlessly most of the time until in the fourth week; it performed faultily on three consecutive days, resulting in the cat&#39;s death if the participants had decided to go for the day safari on these days. As expected, with repeated positive experience about the robot&#39;s reliability on feeding the cat, trust levels rapidly increased and the number of control calls decreased. Compared to one&#39;s own experience, skill demonstration and reputation were largely neglected or only had a temporary effect. We integrate these findings in a conceptual model of (over)trust over time and connect these to related psychological concepts such as positivism, instant rewards, inappropriate generalization, wishful thinking, dissonance theory, and social concepts from human–human interaction. Limitations of the present study as well as implications for robot design and future research are discussed.},
  archive      = {J_FROBT},
  author       = {Ullrich, Daniel and Butz, Andreas and Diefenbach, Sarah},
  doi          = {10.3389/frobt.2021.554578},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {554578},
  shortjournal = {Front. Robot. AI},
  title        = {The development of overtrust: An empirical simulation and psychological analysis in the context of Human–Robot interaction},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Root systems research for bioinspired resilient design: A
concept framework for foundation and coastal engineering.
<em>FROBT</em>, <em>8</em>, 548444. (<a
href="https://doi.org/10.3389/frobt.2021.548444">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The continuous increase in population and human migration to urban and coastal areas leads to the expansion of built environments over natural habitats. Current infrastructure suffers from environmental changes and their impact on ecosystem services. Foundations are static anchoring structures dependent on soil compaction, which reduces water infiltration and increases flooding. Coastal infrastructure reduces wave action and landward erosion but alters natural habitat and sediment transport. On the other hand, root systems are multifunctional, resilient, biological structures that offer promising strategies for the design of civil and coastal infrastructure, such as adaptivity, multifunctionality, self-healing, mechanical and chemical soil attachment. Therefore, the biomimetic methodology is employed to abstract root strategies of interest for the design of building foundations and coastal infrastructures that prevent soil erosion, anchor structures, penetrate soils, and provide natural habitat. The strategies are described in a literature review on root biology, then these principles are abstracted from their biological context to show their potential for engineering transfer. After a review of current and developing technologies in both application fields, the abstracted strategies are translated into conceptual designs for foundation and coastal engineering. In addition to presenting the potential of root-inspired designs for both fields, this paper also showcases the main steps of the biomimetic methodology from the study of a biological system to the development of conceptual technical designs. In this way the paper also contributes to the development of a more strategic intersection between biology and engineering and provides a framework for further research and development projects.},
  archive      = {J_FROBT},
  author       = {Stachew, Elena and Houette, Thibaut and Gruber, Petra},
  doi          = {10.3389/frobt.2021.548444},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {548444},
  shortjournal = {Front. Robot. AI},
  title        = {Root systems research for bioinspired resilient design: A concept framework for foundation and coastal engineering},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Embodiment and its influence on informational costs of
decision density—atomic actions vs. Scripted sequences. <em>FROBT</em>,
<em>8</em>, 535158. (<a
href="https://doi.org/10.3389/frobt.2021.535158">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The importance of embodiment for effective robot performance has been postulated for a long time. Despite this, only relatively recently concrete quantitative models were put forward to characterize the advantages provided by a well-chosen embodiment. We here use one of these models, based on the concept of relevant information, to identify in a minimalistic scenario how and when embodiment affects the decision density. Concretely, we study how embodiment affects information costs when, instead of atomic actions, scripts are introduced, that is, predefined action sequences. Their inclusion can be treated as a straightforward extension of the basic action space. We will demonstrate the effect on informational decision cost of utilizing scripts vs. basic actions using a simple navigation task. Importantly, we will also employ a world with “mislabeled” actions, which we will call a “twisted” world. This is a model which had been used in an earlier study of the influence of embodiment on decision costs. It will turn out that twisted scenarios, as opposed to well-labeled (“embodied”) ones, are significantly more costly in terms of relevant information. This cost is further worsened when the agent is forced to lower the decision density by employing scripts (once a script is triggered, no decisions are taken until the script has run to its end). This adds to our understanding why well-embodied (interpreted in our model as well-labeled) agents should be preferable, in a quantifiable, objective sense.},
  archive      = {J_FROBT},
  author       = {Riegler, Bente and Polani, Daniel and Steuber, Volker},
  doi          = {10.3389/frobt.2021.535158},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {535158},
  shortjournal = {Front. Robot. AI},
  title        = {Embodiment and its influence on informational costs of decision Density—Atomic actions vs. scripted sequences},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). From multi-modal property dataset to robot-centric
conceptual knowledge about household objects. <em>FROBT</em>,
<em>8</em>, 476084. (<a
href="https://doi.org/10.3389/frobt.2021.476084">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conceptual knowledge about objects is essential for humans, as well as for animals, to interact with their environment. On this basis, the objects can be understood as tools, a selection process can be implemented and their usage can be planned in order to achieve a specific goal. The conceptual knowledge, in this case, is primarily concerned about the physical properties and functional properties observed in the objects. Similarly tool-use applications in robotics require such conceptual knowledge about objects for substitute selection among other purposes. State-of-the-art methods employ a top-down approach where hand-crafted symbolic knowledge, which is defined from a human perspective, is grounded into sensory data afterwards. However, due to different sensing and acting capabilities of robots, a robot&#39;s conceptual understanding of objects (e.g., light/heavy) will vary and therefore should be generated from the robot&#39;s perspective entirely, which entails robot-centric conceptual knowledge about objects. A similar bottom-up argument has been put forth in cognitive science that humans and animals alike develop conceptual understanding of objects based on their own perceptual experiences with objects. With this goal in mind, we propose an extensible property estimation framework which consists of estimations methods to obtain the quantitative measurements of physical properties (rigidity, weight, etc.) and functional properties (containment, support, etc.) from household objects. This property estimation forms the basis for our second contribution: Generation of robot-centric conceptual knowledge. Our approach employs unsupervised clustering methods to transform numerical property data into symbols, and Bivariate Joint Frequency Distributions and Sample Proportion to generate conceptual knowledge about objects using the robot-centric symbols. A preliminary implementation of the proposed framework is employed to acquire a dataset comprising six physical and four functional properties of 110 household objects. This Robot-Centric dataSet (RoCS) is used to evaluate the framework regarding the property estimation methods and the semantics of the considered properties within the dataset. Furthermore, the dataset includes the derived robot-centric conceptual knowledge using the proposed framework. The application of the conceptual knowledge about objects is then evaluated by examining its usefulness in a tool substitution scenario.},
  archive      = {J_FROBT},
  author       = {Thosar, Madhura and Mueller, Christian A. and Jäger, Georg and Schleiss, Johannes and Pulugu, Narender and Mallikarjun Chennaboina, Ravi and Rao Jeevangekar, Sai Vivek and Birk, Andreas and Pfingsthorn, Max and Zug, Sebastian},
  doi          = {10.3389/frobt.2021.476084},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {476084},
  shortjournal = {Front. Robot. AI},
  title        = {From multi-modal property dataset to robot-centric conceptual knowledge about household objects},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Editorial: Complexity and self-organization. <em>FROBT</em>,
<em>8</em>, 668305. (<a
href="https://doi.org/10.3389/frobt.2021.668305">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Gershenson, Carlos and Polani, Daniel and Martius, Georg},
  doi          = {10.3389/frobt.2021.668305},
  journal      = {Frontiers in Robotics and AI},
  month        = {3},
  pages        = {668305},
  shortjournal = {Front. Robot. AI},
  title        = {Editorial: Complexity and self-organization},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Editorial: Advances in the integration of brain-machine
interfaces and robotic devices. <em>FROBT</em>, <em>8</em>, 653615. (<a
href="https://doi.org/10.3389/frobt.2021.653615">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Tonin, Luca and Menegatti, Emanuele and Coyle, Damien},
  doi          = {10.3389/frobt.2021.653615},
  journal      = {Frontiers in Robotics and AI},
  month        = {3},
  pages        = {653615},
  shortjournal = {Front. Robot. AI},
  title        = {Editorial: Advances in the integration of brain-machine interfaces and robotic devices},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). From learning to relearning: A framework for diminishing
bias in social robot navigation. <em>FROBT</em>, <em>8</em>, 650325. (<a
href="https://doi.org/10.3389/frobt.2021.650325">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The exponentially increasing advances in robotics and machine learning are facilitating the transition of robots from being confined to controlled industrial spaces to performing novel everyday tasks in domestic and urban environments. In order to make the presence of robots safe as well as comfortable for humans, and to facilitate their acceptance in public environments, they are often equipped with social abilities for navigation and interaction. Socially compliant robot navigation is increasingly being learned from human observations or demonstrations. We argue that these techniques that typically aim to mimic human behavior do not guarantee fair behavior. As a consequence, social navigation models can replicate, promote, and amplify societal unfairness, such as discrimination and segregation. In this work, we investigate a framework for diminishing bias in social robot navigation models so that robots are equipped with the capability to plan as well as adapt their paths based on both physical and social demands. Our proposed framework consists of two components: learning which incorporates social context into the learning process to account for safety and comfort, and relearning to detect and correct potentially harmful outcomes before the onset. We provide both technological and societal analysis using three diverse case studies in different social scenarios of interaction. Moreover, we present ethical implications of deploying robots in social environments and propose potential solutions. Through this study, we highlight the importance and advocate for fairness in human-robot interactions in order to promote more equitable social relationships, roles, and dynamics and consequently positively influence our society.},
  archive      = {J_FROBT},
  author       = {Hurtado, Juana Valeria and Londoño, Laura and Valada, Abhinav},
  doi          = {10.3389/frobt.2021.650325},
  journal      = {Frontiers in Robotics and AI},
  month        = {3},
  pages        = {650325},
  shortjournal = {Front. Robot. AI},
  title        = {From learning to relearning: A framework for diminishing bias in social robot navigation},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Investigating tissue mechanics in vitro using untethered
soft robotic microdevices. <em>FROBT</em>, <em>8</em>, 649765. (<a
href="https://doi.org/10.3389/frobt.2021.649765">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents the design, fabrication, and operation of a soft robotic compression device that is remotely powered by laser illumination. We combined the rapid and wireless response of hybrid nanomaterials with state-of-the-art microengineering techniques to develop machinery that can apply physiologically relevant mechanical loading. The passive hydrogel structures that constitute the compliant skeleton of the machines were fabricated using single-step in situ polymerization process and directly incorporated around the actuators without further assembly steps. Experimentally validated computational models guided the design of the compression mechanism. We incorporated a cantilever beam to the prototype for life-time monitoring of mechanical properties of cell clusters on optical microscopes. The mechanical and biochemical compatibility of the chosen materials with living cells together with the on-site manufacturing process enable seamless interfacing of soft robotic devices with biological specimen.},
  archive      = {J_FROBT},
  author       = {Parreira, Raquel and Özelçi, Ece and Sakar, Mahmut Selman},
  doi          = {10.3389/frobt.2021.649765},
  journal      = {Frontiers in Robotics and AI},
  month        = {3},
  pages        = {649765},
  shortjournal = {Front. Robot. AI},
  title        = {Investigating tissue mechanics in vitro using untethered soft robotic microdevices},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Locating creativity in differing approaches to musical
robotics. <em>FROBT</em>, <em>8</em>, 647028. (<a
href="https://doi.org/10.3389/frobt.2021.647028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The field of musical robotics presents an interesting case study of the intersection between creativity and robotics. While the potential for machines to express creativity represents an important issue in the field of robotics and AI, this subject is especially relevant in the case of machines that replicate human activities that are traditionally associated with creativity, such as music making. There are several different approaches that fall under the broad category of musical robotics, and creativity is expressed differently based on the design and goals of each approach. By exploring elements of anthropomorphic form, capacity for sonic nuance, control, and musical output, this article evaluates the locus of creativity in six of the most prominent approaches to musical robots, including: 1) nonspecialized anthropomorphic robots that can play musical instruments, 2) specialized anthropomorphic robots that model the physical actions of human musicians, 3) semi-anthropomorphic robotic musicians, 4) non-anthropomorphic robotic instruments, 5) cooperative musical robots, and 6) individual actuators used for their own sound production capabilities.},
  archive      = {J_FROBT},
  author       = {Kemper, Steven},
  doi          = {10.3389/frobt.2021.647028},
  journal      = {Frontiers in Robotics and AI},
  month        = {3},
  pages        = {647028},
  shortjournal = {Front. Robot. AI},
  title        = {Locating creativity in differing approaches to musical robotics},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Robotic ultrasound scanning with real-time image-based force
adjustment: Quick response for enabling physical distancing during the
COVID-19 pandemic. <em>FROBT</em>, <em>8</em>, 645424. (<a
href="https://doi.org/10.3389/frobt.2021.645424">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {During an ultrasound (US) scan, the sonographer is in close contact with the patient, which puts them at risk of COVID-19 transmission. In this paper, we propose a robot-assisted system that automatically scans tissue, increasing sonographer/patient distance and decreasing contact duration between them. This method is developed as a quick response to the COVID-19 pandemic. It considers the preferences of the sonographers in terms of how US scanning is done and can be trained quickly for different applications. Our proposed system automatically scans the tissue using a dexterous robot arm that holds US probe. The system assesses the quality of the acquired US images in real-time. This US image feedback will be used to automatically adjust the US probe contact force based on the quality of the image frame. The quality assessment algorithm is based on three US image features: correlation, compression and noise characteristics. These US image features are input to the SVM classifier, and the robot arm will adjust the US scanning force based on the SVM output. The proposed system enables the sonographer to maintain a distance from the patient because the sonographer does not have to be holding the probe and pressing against the patient&#39;s body for any prolonged time. The SVM was trained using bovine and porcine biological tissue, the system was then tested experimentally on plastisol phantom tissue. The result of the experiments shows us that our proposed quality assessment algorithm successfully maintains US image quality and is fast enough for use in a robotic control loop.},
  archive      = {J_FROBT},
  author       = {Akbari, Mojtaba and Carriere, Jay and Meyer, Tyler and Sloboda, Ron and Husain, Siraj and Usmani, Nawaid and Tavakoli, Mahdi},
  doi          = {10.3389/frobt.2021.645424},
  journal      = {Frontiers in Robotics and AI},
  month        = {3},
  pages        = {645424},
  shortjournal = {Front. Robot. AI},
  title        = {Robotic ultrasound scanning with real-time image-based force adjustment: Quick response for enabling physical distancing during the COVID-19 pandemic},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A scooping-binding robotic gripper for handling various food
products. <em>FROBT</em>, <em>8</em>, 640805. (<a
href="https://doi.org/10.3389/frobt.2021.640805">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Food products are usually difficult to handle for robots because of their large variations in shape, size, softness, and surface conditions. It is ideal to use one robotic gripper to handle as many food products as possible. In this study, a scooping-binding robotic gripper is proposed to achieve this goal. The gripper was constructed using a pneumatic parallel actuator and two identical scooping-binding mechanisms. The mechanism consists of a thin scooping plate and multiple rubber strings for binding. When grasping an object, the mechanisms actively makes contact with the environment for scooping, and the object weight is mainly supported by the scooping plate. The binding strings are responsible for stabilizing the grasping by wrapping around the object. Therefore, the gripper can perform high-speed pick-and-place operations. Contact analysis was conducted using a simple beam model and a finite element model that were experimentally validated. Tension property of the binding string was characterized and an analytical model was established to predict binding force based on object geometry and binding displacement. Finally, handling tests on 20 food items, including products with thin profiles and slippery surfaces, were performed. The scooping-binding gripper succeeded in handling all items with a takt time of approximately 4 s. The gripper showed potential for actual applications in the food industry.},
  archive      = {J_FROBT},
  author       = {Wang, Zhongkui and Furuta, Haruki and Hirai, Shinichi and Kawamura, Sadao},
  doi          = {10.3389/frobt.2021.640805},
  journal      = {Frontiers in Robotics and AI},
  month        = {3},
  pages        = {640805},
  shortjournal = {Front. Robot. AI},
  title        = {A scooping-binding robotic gripper for handling various food products},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Neural networks predicting microbial fuel cells output for
soft robotics applications. <em>FROBT</em>, <em>8</em>, 633414. (<a
href="https://doi.org/10.3389/frobt.2021.633414">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The development of biodegradable soft robotics requires an appropriate eco-friendly source of energy. The use of Microbial Fuel Cells (MFCs) is suggested as they can be designed completely from soft materials with little or no negative effects to the environment. Nonetheless, their responsiveness and functionality is not strictly defined as in other conventional technologies, i.e. lithium batteries. Consequently, the use of artificial intelligence methods in their control techniques is highly recommended. The use of neural networks, namely a nonlinear autoregressive network with exogenous inputs was employed to predict the electrical output of an MFC, given its previous outputs and feeding volumes. Thus, predicting MFC outputs as a time series, enables accurate determination of feeding intervals and quantities required for sustenance that can be incorporated in the behavioural repertoire of a soft robot.},
  archive      = {J_FROBT},
  author       = {Tsompanas, Michail-Antisthenis and You, Jiseon and Philamore, Hemma and Rossiter, Jonathan and Ieropoulos, Ioannis},
  doi          = {10.3389/frobt.2021.633414},
  journal      = {Frontiers in Robotics and AI},
  month        = {3},
  pages        = {633414},
  shortjournal = {Front. Robot. AI},
  title        = {Neural networks predicting microbial fuel cells output for soft robotics applications},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The effects of physically embodied multiple conversation
robots on the elderly. <em>FROBT</em>, <em>8</em>, 633045. (<a
href="https://doi.org/10.3389/frobt.2021.633045">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, communication robots aiming to offer mental support to the elderly have attracted increasing attention. Dialogue systems consisting of two robots could provide the elderly with opportunities to hold longer conversations in care homes. In this study, we conducted an experiment to compare two types of scenario-based dialogue systems with different types of bodies—physical and virtual robots—to investigate the effects of embodying such dialogue systems. Forty elderly people aged from 65 to 84 interacted with either an embodied desktop-sized humanoid robot or computer graphic agent displayed on a monitor. The elderly participants were divided into groups depending on the success of the interactions. The results revealed that (i) in the group where the robots responded more successfully with the expected conversation flow, the elderly are more engaged in the conversation with the physical robots than the virtual robots, and (ii) the elderly in the group in which robots responded successfully are more engaged in the conversation with the physical robots than those in the group in which the robots responded with ambiguous responses owing to unexpected utterances from the elderly. These results suggest that having a physical body is advantageous in promoting high engagement, and the potential advantage appears depending on whether the system can handle the conversation flow. These findings provide new insight into the development of dialogue systems assisting elderly in maintaining a better mental health.},
  archive      = {J_FROBT},
  author       = {Nishio, Toshiaki and Yoshikawa, Yuichiro and Sakai, Kazuki and Iio, Takamasa and Chiba, Mariko and Asami, Taichi and Isoda, Yoshinori and Ishiguro, Hiroshi},
  doi          = {10.3389/frobt.2021.633045},
  journal      = {Frontiers in Robotics and AI},
  month        = {3},
  pages        = {633045},
  shortjournal = {Front. Robot. AI},
  title        = {The effects of physically embodied multiple conversation robots on the elderly},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A recurrent neural-network-based real-time dynamic model for
soft continuum manipulators. <em>FROBT</em>, <em>8</em>, 631303. (<a
href="https://doi.org/10.3389/frobt.2021.631303">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces and validates a real-time dynamic predictive model based on a neural network approach for soft continuum manipulators. The presented model provides a real-time prediction framework using neural-network-based strategies and continuum mechanics principles. A time-space integration scheme is employed to discretize the continuous dynamics and decouple the dynamic equations for translation and rotation for each node of a soft continuum manipulator. Then the resulting architecture is used to develop distributed prediction algorithms using recurrent neural networks. The proposed RNN-based parallel predictive scheme does not rely on computationally intensive algorithms; therefore, it is useful in real-time applications. Furthermore, simulations are shown to illustrate the approach performance on soft continuum elastica, and the approach is also validated through an experiment on a magnetically-actuated soft continuum manipulator. The results demonstrate that the presented model can outperform classical modeling approaches such as the Cosserat rod model while also shows possibilities for being used in practice.},
  archive      = {J_FROBT},
  author       = {Tariverdi, Abbas and Venkiteswaran, Venkatasubramanian Kalpathy and Richter, Michiel and Elle, Ole J. and Tørresen, Jim and Mathiassen, Kim and Misra, Sarthak and Martinsen, Ørjan G.},
  doi          = {10.3389/frobt.2021.631303},
  journal      = {Frontiers in Robotics and AI},
  month        = {3},
  pages        = {631303},
  shortjournal = {Front. Robot. AI},
  title        = {A recurrent neural-network-based real-time dynamic model for soft continuum manipulators},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Generic and flexible unmanned sailboat for innovative
education and world robotic sailing championship. <em>FROBT</em>,
<em>8</em>, 630081. (<a
href="https://doi.org/10.3389/frobt.2021.630081">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Over the past two decades, scholars developed various unmanned sailboat platforms, but most of them have specialized designs and controllers. Whereas these robotic sailboats have good performance with open-source designs, it is actually hard for interested researchers or fans to follow and make their own sailboats with these open-source designs. Thus, in this paper, a generic and flexible unmanned sailboat platform with easy access to the hardware and software architectures is designed and tested. The commonly used 1-m class RC racing sailboat was employed to install Pixhawk V2.4.8, Arduino Mega 2,560, GPS module M8N, custom-designed wind direction sensor, and wireless 433 Mhz telegram. The widely used open-source hardware modules were selected to keep reliable and low-cost hardware setup to emphasize the generality and feasibility of the unmanned sailboat platform. In software architecture, the Pixhawk V2.4.8 provided reliable states’ feedback. The Arduino Mega 2,560 received estimated states from Pixhawk V2.4.8 and the wind vane sensor, and then controlled servo actuators of rudder and sail using simplified algorithms. Due to the complexity of introducing robot operating system and its packages, we designed a generic but real-time software architecture just using Arduino Mega 2,560. A suitable line-of-sight guidance strategy and PID-based controllers were used to let the autonomous sailboat sail at user-defined waypoints. Field tests validated the sailing performance in facing WRSC challenges. Results of fleet race, station keeping, and area scanning proved that our design and algorithms could control the 1-m class RC sailboat with acceptable accuracy. The proposed design and algorithms contributed to developing educational, low-cost, micro class autonomous sailboats with accessible, generic, and flexible hardware and software. Besides, our sailboat platform also facilitates readers to develop similar sailboats with more focus on their missions.},
  archive      = {J_FROBT},
  author       = {Yang, Shaolong and Liu, Chuan and Liu, Ya and An, Jinxin and Xiang, Xianbo},
  doi          = {10.3389/frobt.2021.630081},
  journal      = {Frontiers in Robotics and AI},
  month        = {3},
  pages        = {630081},
  shortjournal = {Front. Robot. AI},
  title        = {Generic and flexible unmanned sailboat for innovative education and world robotic sailing championship},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Descending and ascending signals that maintain rhythmic
walking pattern in crickets. <em>FROBT</em>, <em>8</em>, 625094. (<a
href="https://doi.org/10.3389/frobt.2021.625094">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The cricket is one of the model animals used to investigate the neuronal mechanisms underlying adaptive locomotion. An intact cricket walks mostly with a tripod gait, similar to other insects. The motor control center of the leg movements is located in the thoracic ganglia. In this study, we investigated the walking gait patterns of the crickets whose ventral nerve cords were surgically cut to gain an understanding of how the descending signals from the head ganglia and ascending signals from the abdominal nervous system into the thoracic ganglia mediate the initiation and coordination of the walking gait pattern. Crickets whose paired connectives between the brain and subesophageal ganglion (SEG) (circumesophageal connectives) were cut exhibited a tripod gait pattern. However, when one side of the circumesophageal connectives was cut, the crickets continued to turn in the opposite direction to the connective cut. Crickets whose paired connectives between the SEG and prothoracic ganglion were cut did not walk, whereas the crickets exhibited an ordinal tripod gait pattern when one side of the connectives was intact. Crickets whose paired connectives between the metathoracic ganglion and abdominal ganglia were cut initiated walking, although the gait was not a coordinated tripod pattern, whereas the crickets exhibited a tripod gait when one side of the connectives was intact. These results suggest that the brain plays an inhibitory role in initiating leg movements and that both the descending signals from the head ganglia and the ascending signals from the abdominal nervous system are important in initiating and coordinating insect walking gait patterns.},
  archive      = {J_FROBT},
  author       = {Naniwa, Keisuke and Aonuma, Hitoshi},
  doi          = {10.3389/frobt.2021.625094},
  journal      = {Frontiers in Robotics and AI},
  month        = {3},
  pages        = {625094},
  shortjournal = {Front. Robot. AI},
  title        = {Descending and ascending signals that maintain rhythmic walking pattern in crickets},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Efficient coverage path planning for mobile disinfecting
robots using graph-based representation of environment. <em>FROBT</em>,
<em>8</em>, 624333. (<a
href="https://doi.org/10.3389/frobt.2021.624333">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The effective disinfection of hospitals is paramount in lowering the COVID-19 transmission risk to both patients and medical personnel. Autonomous mobile robots can perform the surface disinfection task in a timely and cost-effective manner, while preventing the direct contact of disinfecting agents with humans. This paper proposes an end-to-end coverage path planning technique that generates a continuous and uninterrupted collision-free path for a mobile robot to cover an area of interest. The aim of this work is to decrease the disinfection task completion time and cost by finding an optimal coverage path using a new graph-based representation of the environment. The results are compared with other existing state-of-the-art coverage path planning approaches. It is shown that the proposed approach generates a path with shorter total travelled distance (fewer number of overlaps) and smaller number of turns.},
  archive      = {J_FROBT},
  author       = {Nasirian, B. and Mehrandezh, M. and Janabi-Sharifi, F.},
  doi          = {10.3389/frobt.2021.624333},
  journal      = {Frontiers in Robotics and AI},
  month        = {3},
  pages        = {624333},
  shortjournal = {Front. Robot. AI},
  title        = {Efficient coverage path planning for mobile disinfecting robots using graph-based representation of environment},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Towards energy-aware feedback planning for long-range
autonomous underwater vehicles. <em>FROBT</em>, <em>8</em>, 621820. (<a
href="https://doi.org/10.3389/frobt.2021.621820">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ocean ecosystems have spatiotemporal variability and dynamic complexity that require a long-term deployment of an autonomous underwater vehicle for data collection. A new generation of long-range autonomous underwater vehicles (LRAUVs), such as the Slocum glider and Tethys-class AUV, has emerged with high endurance, long-range, and energy-aware capabilities. These new vehicles provide an effective solution to study different oceanic phenomena across multiple spatial and temporal scales. For these vehicles, the ocean environment has forces and moments from changing water currents which are generally on the order of magnitude of the operational vehicle velocity. Therefore, it is not practical to generate a simple trajectory from an initial location to a goal location in an uncertain ocean, as the vehicle can deviate significantly from the prescribed trajectory due to disturbances resulted from water currents. Since state estimation remains challenging in underwater conditions, feedback planning must incorporate state uncertainty that can be framed into a stochastic energy-aware path planning problem. This article presents an energy-aware feedback planning method for an LRAUV utilizing its kinematic model in an underwater environment under motion and sensor uncertainties. Our method uses ocean dynamics from a predictive ocean model to understand the water flow pattern and introduces a goal-constrained belief space to make the feedback plan synthesis computationally tractable. Energy-aware feedback plans for different water current layers are synthesized through sampling and ocean dynamics. The synthesized feedback plans provide strategies for the vehicle that drive it from an environment’s initial location toward the goal location. We validate our method through extensive simulations involving the Tethys vehicle’s kinematic model and incorporating actual ocean model prediction data.},
  archive      = {J_FROBT},
  author       = {Alam, Tauhidul and Al Redwan Newaz, Abdullah and Bobadilla, Leonardo and Alsabban, Wesam H. and Smith, Ryan N. and Karimoddini, Ali},
  doi          = {10.3389/frobt.2021.621820},
  journal      = {Frontiers in Robotics and AI},
  month        = {3},
  pages        = {621820},
  shortjournal = {Front. Robot. AI},
  title        = {Towards energy-aware feedback planning for long-range autonomous underwater vehicles},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Underwater docking approach and homing to enable persistent
operation. <em>FROBT</em>, <em>8</em>, 621755. (<a
href="https://doi.org/10.3389/frobt.2021.621755">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the main limiting factors in deployment of marine robots is the issue of energy sustainability. This is particularly challenging for traditional propeller-driven autonomous underwater vehicles which operate using energy intensive thrusters. One emerging technology to enable persistent performance is the use of autonomous recharging and retasking through underwater docking stations. This paper presents an integrated navigational algorithm to facilitate reliable underwater docking of autonomous underwater vehicles. Specifically, the algorithm dynamically re-plans Dubins paths to create an efficient trajectory from the current vehicle position through approach into terminal homing. The path is followed using integral line of sight control until handoff to the terminal homing method. A light tracking algorithm drives the vehicle from the handoff location into the dock. In experimental testing using an Oceanserver Iver3 and Bluefin SandShark, the approach phase reached the target handoff within 2 m in 48 of 48 tests. The terminal homing phase was capable of handling up to 5 m offsets with approximately 70% accuracy (12 of 17 tests). In the event of failed docking, a Dubins path is generated to efficiently drive the vehicle to re-attempt docking. The vehicle should be able to successfully dock in the majority of foreseeable scenarios when re-attempts are considered. This method, when combined with recent work on docking station design, intelligent cooperative path planning, underwater communication, and underwater power transfer, will enable true persistent undersea operation in the extremely dynamic ocean environment.},
  archive      = {J_FROBT},
  author       = {Page, Brian R. and Lambert, Reeve and Chavez‐Galaviz, Jalil and Mahmoudian, Nina},
  doi          = {10.3389/frobt.2021.621755},
  journal      = {Frontiers in Robotics and AI},
  month        = {3},
  pages        = {621755},
  shortjournal = {Front. Robot. AI},
  title        = {Underwater docking approach and homing to enable persistent operation},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Development and grasp stability estimation of sensorized
soft robotic hand. <em>FROBT</em>, <em>8</em>, 619390. (<a
href="https://doi.org/10.3389/frobt.2021.619390">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces the development of an anthropomorphic soft robotic hand integrated with multiple flexible force sensors in the fingers. By leveraging on the integrated force sensing mechanism, grip state estimation networks have been developed. The robotic hand was tasked to hold the given object on the table for 1.5 s and lift it up within 1 s. The object manipulation experiment of grasping and lifting the given objects were conducted with various pneumatic pressure (50, 80, and 120 kPa). Learning networks were developed to estimate occurrence of object instability and slippage due to acceleration of the robot or insufficient grasp strength. Hence the grip state estimation network can potentially feedback object stability status to the pneumatic control system. This would allow the pneumatic system to use suitable pneumatic pressure to efficiently handle different objects, i.e., lower pneumatic pressure (50 kPa) for lightweight objects which do not require high grasping strength. The learning process of the soft hand is made challenging by curating a diverse selection of daily objects, some of which displays dynamic change in shape upon grasping. To address the cost of collecting extensive training datasets, we adopted one-shot learning (OSL) technique with a long short-term memory (LSTM) recurrent neural network. OSL aims to allow the networks to learn based on limited training data. It also promotes the scalability of the network to accommodate more grasping objects in the future. Three types of LSTM-based networks have been developed and their performance has been evaluated in this study. Among the three LSTM networks, triplet network achieved overall stability estimation accuracy at 89.96%, followed by LSTM network with 88.00% and Siamese LSTM network with 85.16%.},
  archive      = {J_FROBT},
  author       = {Khin, P. M. and Low, Jin H. and Ang, Marcelo H. and Yeow, Chen H.},
  doi          = {10.3389/frobt.2021.619390},
  journal      = {Frontiers in Robotics and AI},
  month        = {3},
  pages        = {619390},
  shortjournal = {Front. Robot. AI},
  title        = {Development and grasp stability estimation of sensorized soft robotic hand},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Robotic telemedicine for mental health: A multimodal
approach to improve human-robot engagement. <em>FROBT</em>, <em>8</em>,
618866. (<a href="https://doi.org/10.3389/frobt.2021.618866">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {COVID-19 has severely impacted mental health in vulnerable demographics, in particular older adults, who face unprecedented isolation. Consequences, while globally severe, are acutely pronounced in low- and middle-income countries (LMICs) confronting pronounced gaps in resources and clinician accessibility. Social robots are well-recognized for their potential to support mental health, yet user compliance (i.e., trust) demands seamless affective human-robot interactions; natural ‘human-like’ conversations are required in simple, inexpensive, deployable platforms. We present the design, development, and pilot testing of a multimodal robotic framework fusing verbal (contextual speech) and nonverbal (facial expressions) social cues, aimed to improve engagement in human-robot interaction and ultimately facilitate mental health telemedicine during and beyond the COVID-19 pandemic. We report the design optimization of a hybrid face robot, which combines digital facial expressions based on mathematical affect space mapping with static 3D facial features. We further introduce a contextual virtual assistant with integrated cloud-based AI coupled to the robot’s facial representation of emotions, such that the robot adapts its emotional response to users’ speech in real-time. Experiments with healthy participants demonstrate emotion recognition exceeding 90% for happy, tired, sad, angry, surprised and stern/disgusted robotic emotions. When separated, stern and disgusted are occasionally transposed (70%+ accuracy overall) but are easily distinguishable from other emotions. A qualitative user experience analysis indicates overall enthusiastic and engaging reception to human-robot multimodal interaction with the new framework. The robot has been modified to enable clinical telemedicine for cognitive engagement with older adults and people with dementia (PwD) in LMICs. The mechanically simple and low-cost social robot has been deployed in pilot tests to support older individuals and PwD at the Schizophrenia Research Foundation (SCARF) in Chennai, India. A procedure for deployment addressing challenges in cultural acceptance, end-user acclimatization and resource allocation is further introduced. Results indicate strong promise to stimulate human-robot psychosocial interaction through the hybrid-face robotic system. Future work is targeting deployment for telemedicine to mitigate the mental health impact of COVID-19 on older adults and PwD in both LMICs and higher income regions.},
  archive      = {J_FROBT},
  author       = {Lima, Maria R. and Wairagkar, Maitreyee and Natarajan, Nirupama and Vaitheswaran, Sridhar and Vaidyanathan, Ravi},
  doi          = {10.3389/frobt.2021.618866},
  journal      = {Frontiers in Robotics and AI},
  month        = {3},
  pages        = {618866},
  shortjournal = {Front. Robot. AI},
  title        = {Robotic telemedicine for mental health: A multimodal approach to improve human-robot engagement},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A smart tendon hammer system for remote neurological
examination. <em>FROBT</em>, <em>8</em>, 618656. (<a
href="https://doi.org/10.3389/frobt.2021.618656">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The deep tendon reflex exam is an important part of neurological assessment of patients consisting of two components, reflex elicitation and reflex grading. While this exam has traditionally been performed in person, with trained clinicians both eliciting and grading the reflex, this work seeks to enable the exam by novices. The COVID-19 pandemic has motivated greater utilization of telemedicine and other remote healthcare delivery tools. A smart tendon hammer capable of streaming acceleration measurements wirelessly allows differentiation of correct and incorrect tapping locations with 91.5% accuracy to provide feedback to users about the appropriateness of stimulation, enabling reflex elicitation by laypeople, while survey results demonstrate that novices are reasonably able to grade reflex responses. Novice reflex grading demonstrates adequate performance with a mean error of 0.2 points on a five point scale. This work shows that by assisting in the reflex elicitation component of the reflex exam via a smart hammer and feedback application, novices should be able to complete the reflex exam remotely, filling a critical gap in neurological care during the COVID-19 pandemic.},
  archive      = {J_FROBT},
  author       = {Meinhold, Waiman and Yamakawa, Yoshinori and Honda, Hiroshi and Mori, Takayuki and Izumi, Shin-ichi and Ueda, Jun},
  doi          = {10.3389/frobt.2021.618656},
  journal      = {Frontiers in Robotics and AI},
  month        = {3},
  pages        = {618656},
  shortjournal = {Front. Robot. AI},
  title        = {A smart tendon hammer system for remote neurological examination},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Swarm SLAM: Challenges and perspectives. <em>FROBT</em>,
<em>8</em>, 618268. (<a
href="https://doi.org/10.3389/frobt.2021.618268">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A robot swarm is a decentralized system characterized by locality of sensing and communication, self-organization, and redundancy. These characteristics allow robot swarms to achieve scalability, flexibility and fault tolerance, properties that are especially valuable in the context of simultaneous localization and mapping (SLAM), specifically in unknown environments that evolve over time. So far, research in SLAM has mainly focused on single- and centralized multi-robot systems—i.e., non-swarm systems. While these systems can produce accurate maps, they are typically not scalable, cannot easily adapt to unexpected changes in the environment, and are prone to failure in hostile environments. Swarm SLAM is a promising approach to SLAM as it could leverage the decentralized nature of a robot swarm and achieve scalable, flexible and fault-tolerant exploration and mapping. However, at the moment of writing, swarm SLAM is a rather novel idea and the field lacks definitions, frameworks, and results. In this work, we present the concept of swarm SLAM and its constraints, both from a technical and an economical point of view. In particular, we highlight the main challenges of swarm SLAM for gathering, sharing, and retrieving information. We also discuss the strengths and weaknesses of this approach against traditional multi-robot SLAM. We believe that swarm SLAM will be particularly useful to produce abstract maps such as topological or simple semantic maps and to operate under time or cost constraints.},
  archive      = {J_FROBT},
  author       = {Kegeleirs, Miquel and Grisetti, Giorgio and Birattari, Mauro},
  doi          = {10.3389/frobt.2021.618268},
  journal      = {Frontiers in Robotics and AI},
  month        = {3},
  pages        = {618268},
  shortjournal = {Front. Robot. AI},
  title        = {Swarm SLAM: Challenges and perspectives},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Risk-aware model-based control. <em>FROBT</em>, <em>8</em>,
617839. (<a href="https://doi.org/10.3389/frobt.2021.617839">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Model-Based Reinforcement Learning (MBRL) algorithms have been shown to have an advantage on data-efficiency, but often overshadowed by state-of-the-art model-free methods in performance, especially when facing high-dimensional and complex problems. In this work, a novel MBRL method is proposed, called Risk-Aware Model-Based Control (RAMCO). It combines uncertainty-aware deep dynamics models and the risk assessment technique Conditional Value at Risk (CVaR). This mechanism is appropriate for real-world application since it takes epistemic risk into consideration. In addition, we use a model-free solver to produce warm-up training data, and this setting improves the performance in low-dimensional environments and covers the shortage of MBRL’s nature in the high-dimensional scenarios. In comparison with other state-of-the-art reinforcement learning algorithms, we show that it produces superior results on a walking robot model. We also evaluate the method with an Eidos environment, which is a novel experimental method with multi-dimensional randomly initialized deep neural networks to measure the performance of any reinforcement learning algorithm, and the advantages of RAMCO are highlighted.},
  archive      = {J_FROBT},
  author       = {Yu, Chen and Rosendo, Andre},
  doi          = {10.3389/frobt.2021.617839},
  journal      = {Frontiers in Robotics and AI},
  month        = {3},
  pages        = {617839},
  shortjournal = {Front. Robot. AI},
  title        = {Risk-aware model-based control},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Covid, AI, and robotics—a neurologist’s perspective.
<em>FROBT</em>, <em>8</em>, 617426. (<a
href="https://doi.org/10.3389/frobt.2021.617426">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Two of the major revolutions of this century are the Artificial Intelligence and Robotics. These technologies are penetrating through all disciplines and faculties at a very rapid pace. The application of these technologies in medicine, specifically in the context of Covid 19 is paramount. This article briefly reviews the commonly applied protocols in the Health Care System and provides a perspective in improving the efficiency and effectiveness of the current system. This article is not meant to provide a literature review of the current technology but rather provides a personal perspective of the author regarding what could happen in the ideal situation.},
  archive      = {J_FROBT},
  author       = {Ahmed, Syed Nizamuddin},
  doi          = {10.3389/frobt.2021.617426},
  journal      = {Frontiers in Robotics and AI},
  month        = {3},
  pages        = {617426},
  shortjournal = {Front. Robot. AI},
  title        = {Covid, AI, and Robotics—A neurologist&#39;s perspective},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A compact soft robotic wrist brace with origami actuators.
<em>FROBT</em>, <em>8</em>, 614623. (<a
href="https://doi.org/10.3389/frobt.2021.614623">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wrist disability caused by a series of diseases or injuries hinders the patient’s capability to perform activities of daily living (ADL). Rehabilitation devices for the wrist motor function have gained popularity among clinics and researchers due to the convenience of self-rehabilitation. The inherent compliance of soft robots enabled safe human-robot interaction and light-weight characteristics, providing new possibilities to develop wearable devices. Compared with the conventional apparatus, soft robotic wearable rehabilitation devices showed advantages in flexibility, cost, and comfort. In this work, a compact and low-profile soft robotic wrist brace was proposed by directly integrating eight soft origami-patterned actuators on the commercially available wrist brace. The linear motion of the actuators was defined by their origami pattern. The extensions of the actuators were constrained by the brace fabrics, deriving the motions of the wrist joint, i.e., extension/flexion, ulnar/radial deviation. The soft actuators were made of ethylene-vinyl acetate by blow molding, achieving mass-production capability, low cost, and high repeatability. The design and fabrication of the soft robotic wrist brace are presented in this work. The experiments on the range of motion, output force, wearing position adaptivity, and performance under disturbance have been carried out with results analyzed. The modular soft actuator approach of design and fabrication of the soft robotic wrist brace has a wide application potential in wearable devices.},
  archive      = {J_FROBT},
  author       = {Liu, Sicong and Fang, Zhonggui and Liu, Jianhui and Tang, Kailuan and Luo, Jianwen and Yi, Juan and Hu, Xinyao and Wang, Zheng},
  doi          = {10.3389/frobt.2021.614623},
  journal      = {Frontiers in Robotics and AI},
  month        = {3},
  pages        = {614623},
  shortjournal = {Front. Robot. AI},
  title        = {A compact soft robotic wrist brace with origami actuators},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A configurable architecture for two degree-of-freedom
variable stiffness actuators to match the compliant behavior of human
joints. <em>FROBT</em>, <em>8</em>, 614145. (<a
href="https://doi.org/10.3389/frobt.2021.614145">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Living beings modulate the impedance of their joints to interact proficiently, robustly, and safely with the environment. These observations inspired the design of soft articulated robots with the development of Variable Impedance and Variable Stiffness Actuators. However, designing them remains a challenging task due to their mechanical complexity, encumbrance, and weight, but also due to the different specifications that the wide range of applications requires. For instance, as prostheses or parts of humanoid systems, there is currently a need for multi-degree-of-freedom joints that have abilities similar to those of human articulations. Toward this goal, we propose a new compact and configurable design for a two-degree-of-freedom variable stiffness joint that can match the passive behavior of a human wrist and ankle. Using only three motors, this joint can control its equilibrium orientation around two perpendicular axes and its overall stiffness as a one-dimensional parameter, like the co-contraction of human muscles. The kinematic architecture builds upon a state-of-the-art rigid parallel mechanism with the addition of nonlinear elastic elements to allow the control of the stiffness. The mechanical parameters of the proposed system can be optimized to match desired passive compliant behaviors and to fit various applications (e.g., prosthetic wrists or ankles, artificial wrists, etc.). After describing the joint structure, we detail the kinetostatic analysis to derive the compliant behavior as a function of the design parameters and to prove the variable stiffness ability of the system. Besides, we provide sets of design parameters to match the passive compliance of either a human wrist or ankle. Moreover, to show the versatility of the proposed joint architecture and as guidelines for the future designer, we describe the influence of the main design parameters on the system stiffness characteristic and show the potential of the design for more complex applications.},
  archive      = {J_FROBT},
  author       = {Lemerle, Simon and Catalano, Manuel G. and Bicchi, Antonio and Grioli, Giorgio},
  doi          = {10.3389/frobt.2021.614145},
  journal      = {Frontiers in Robotics and AI},
  month        = {3},
  pages        = {614145},
  shortjournal = {Front. Robot. AI},
  title        = {A configurable architecture for two degree-of-freedom variable stiffness actuators to match the compliant behavior of human joints},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Deployable telescopic tubular mechanisms with a steerable
tongue depressor towards self-administered oral swab. <em>FROBT</em>,
<em>8</em>, 612959. (<a
href="https://doi.org/10.3389/frobt.2021.612959">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Swabbing tests have proved to be an effective method of diagnosis for a wide range of diseases. Potential occupational health hazards and reliance on healthcare workers during traditional swabbing procedures can be mitigated by self-administered swabs. Hence, we report possible methods to apply closed kinematic chain theory to develop a self-administered viral swab to collect respiratory specimens. The proposed sensorized swab models utilizing hollow polypropylene tubes possess mechanical compliance, simple construction, and inexpensive components. In detail, the adaptation of the slider-crank mechanism combined with concepts of a deployable telescopic tubular mechanical system is explored through four different oral swab designs. A closed kinematic chain on suitable material to create a developable surface allows the translation of simple two-dimensional motion into more complex multi-dimensional motion. These foldable telescopic straws with multiple kirigami cuts minimize components involved in the system as the characteristics are built directly into the material. Further, it offers a possibility to include soft stretchable sensors for realtime performance monitoring. A variety of features were constructed and tested using the concepts above, including 1) tongue depressor and cough/gag reflex deflector; 2) changing the position and orientation of the oral swab when sample collection is in the process; 3) protective cover for the swabbing bud; 4) a combination of the features mentioned above.},
  archive      = {J_FROBT},
  author       = {Kumar, Kirthika Senthil and Nguyen, Tuan Dung and Kalairaj, Manivannan Sivaperuman and Hema, Vishnu Mani and Cai, Catherine Jiayi and Huang, Hui and Lim, Chwee Ming and Ren, Hongliang},
  doi          = {10.3389/frobt.2021.612959},
  journal      = {Frontiers in Robotics and AI},
  month        = {3},
  pages        = {612959},
  shortjournal = {Front. Robot. AI},
  title        = {Deployable telescopic tubular mechanisms with a steerable tongue depressor towards self-administered oral swab},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Editorial: Autonomous health monitoring and assistance
systems with IoT. <em>FROBT</em>, <em>8</em>, 611352. (<a
href="https://doi.org/10.3389/frobt.2021.611352">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Azzopardi, George and Karastoyanova, Dimka and Aiello, Marco and Schizas, Christos N.},
  doi          = {10.3389/frobt.2021.611352},
  journal      = {Frontiers in Robotics and AI},
  month        = {3},
  pages        = {611352},
  shortjournal = {Front. Robot. AI},
  title        = {Editorial: Autonomous health monitoring and assistance systems with IoT},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A modular geometrical framework for modelling the
force-contraction profile of vacuum-powered soft actuators.
<em>FROBT</em>, <em>8</em>, 606938. (<a
href="https://doi.org/10.3389/frobt.2021.606938">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we present a generalized modeling tool for predicting the output force profile of vacuum-powered soft actuators using a simplified geometrical approach and the principle of virtual work. Previous work has derived analytical formulas to model the force-contraction profile of specific actuators. To enhance the versatility and the efficiency of the modelling process we propose a generalized numerical algorithm based purely on geometrical inputs, which can be tailored to the desired actuator, to estimate its force-contraction profile quickly and for any combination of varying geometrical parameters. We identify a class of linearly contracting vacuum actuators that consists of a polymeric skin guided by a rigid skeleton and apply our model to two such actuators-vacuum bellows and Fluid-driven Origami-inspired Artificial Muscles-to demonstrate the versatility of our model. We perform experiments to validate that our model can predict the force profile of the actuators using its geometric principles, modularly combined with design-specific external adjustment factors. Our framework can be used as a versatile design tool that allows users to perform parametric studies and rapidly and efficiently tune actuator dimensions to produce a force-contraction profile to meet their needs, and as a pre-screening tool to obviate the need for multiple rounds of time-intensive actuator fabrication and testing.},
  archive      = {J_FROBT},
  author       = {Gollob, Samuel Dutra and Park, Clara and Koo, Bon Ho Brandon and Roche, Ellen T.},
  doi          = {10.3389/frobt.2021.606938},
  journal      = {Frontiers in Robotics and AI},
  month        = {3},
  pages        = {606938},
  shortjournal = {Front. Robot. AI},
  title        = {A modular geometrical framework for modelling the force-contraction profile of vacuum-powered soft actuators},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Safety assessment of rehabilitation robots: A review
identifying safety skills and current knowledge gaps. <em>FROBT</em>,
<em>8</em>, 602878. (<a
href="https://doi.org/10.3389/frobt.2021.602878">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The assessment of rehabilitation robot safety is a vital aspect of the development process, which is often experienced as difficult. There are gaps in best practices and knowledge to ensure safe usage of rehabilitation robots. Currently, safety is commonly assessed by monitoring adverse events occurrence. The aim of this article is to explore how safety of rehabilitation robots can be assessed early in the development phase, before they are used with patients. We are suggesting a uniform approach for safety validation of robots closely interacting with humans, based on safety skills and validation protocols. Safety skills are an abstract representation of the ability of a robot to reduce a specific risk or deal with a specific hazard. They can be implemented in various ways, depending on the application requirements, which enables the use of a single safety skill across a wide range of applications and domains. Safety validation protocols have been developed that correspond to these skills and consider domain-specific conditions. This gives robot users and developers concise testing procedures to prove the mechanical safety of their robotic system, even when the applications are in domains with a lack of standards and best practices such as the healthcare domain. Based on knowledge about adverse events occurring in rehabilitation robot use, we identified multi-directional excessive forces on the soft tissue level and musculoskeletal level as most relevant hazards for rehabilitation robots and related them to four safety skills, providing a concrete starting point for safety assessment of rehabilitation robots. We further identified a number of gaps which need to be addressed in the future to pave the way for more comprehensive guidelines for rehabilitation robot safety assessments. Predominantly, besides new developments of safety by design features, there is a strong need for reliable measurement methods as well as acceptable limit values for human-robot interaction forces both on skin and joint level.},
  archive      = {J_FROBT},
  author       = {Bessler, Jule and Prange-Lasonder, Gerdienke B. and Schaake, Leendert and Saenz, José F. and Bidard, Catherine and Fassi, Irene and Valori, Marcello and Lassen, Aske Bach and Buurke, Jaap H.},
  doi          = {10.3389/frobt.2021.602878},
  journal      = {Frontiers in Robotics and AI},
  month        = {3},
  pages        = {602878},
  shortjournal = {Front. Robot. AI},
  title        = {Safety assessment of rehabilitation robots: A review identifying safety skills and current knowledge gaps},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Shape memory alloy (SMA) actuator with embedded liquid metal
curvature sensor for closed-loop control. <em>FROBT</em>, <em>8</em>,
599650. (<a href="https://doi.org/10.3389/frobt.2021.599650">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce a soft robot actuator composed of a pre-stressed elastomer film embedded with shape memory alloy (SMA) and a liquid metal (LM) curvature sensor. SMA-based actuators are commonly used as electrically-powered limbs to enable walking, crawling, and swimming of soft robots. However, they are susceptible to overheating and long-term degradation if they are electrically stimulated before they have time to mechanically recover from their previous activation cycle. Here, we address this by embedding the soft actuator with a capacitive LM sensor capable of measuring bending curvature. The soft sensor is thin and elastic and can track curvature changes without significantly altering the natural mechanical properties of the soft actuator. We show that the sensor can be incorporated into a closed-loop “bang-bang” controller to ensure that the actuator fully relaxes to its natural curvature before the next activation cycle. In this way, the activation frequency of the actuator can be dynamically adapted for continuous, cyclic actuation. Moreover, in the special case of slower, low power actuation, we can use the embedded curvature sensor as feedback for achieving partial actuation and limiting the amount of curvature change.},
  archive      = {J_FROBT},
  author       = {Ren, Zhijian and Zarepoor, Masoud and Huang, Xiaonan and Sabelhaus, Andrew P. and Majidi, Carmel},
  doi          = {10.3389/frobt.2021.599650},
  journal      = {Frontiers in Robotics and AI},
  month        = {3},
  pages        = {599650},
  shortjournal = {Front. Robot. AI},
  title        = {Shape memory alloy (SMA) actuator with embedded liquid metal curvature sensor for closed-loop control},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). MaskUKF: An instance segmentation aided unscented kalman
filter for 6D object pose and velocity tracking. <em>FROBT</em>,
<em>8</em>, 594583. (<a
href="https://doi.org/10.3389/frobt.2021.594583">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tracking the 6D pose and velocity of objects represents a fundamental requirement for modern robotics manipulation tasks. This paper proposes a 6D object pose tracking algorithm, called MaskUKF, that combines deep object segmentation networks and depth information with a serial Unscented Kalman Filter to track the pose and the velocity of an object in real-time. MaskUKF achieves and in most cases surpasses state-of-the-art performance on the YCB-Video pose estimation benchmark without the need for expensive ground truth pose annotations at training time. Closed loop control experiments on the iCub humanoid platform in simulation show that joint pose and velocity tracking helps achieving higher precision and reliability than with one-shot deep pose estimation networks. A video of the experiments is available as Supplementary Material.},
  archive      = {J_FROBT},
  author       = {Piga, Nicola A. and Bottarel, Fabrizio and Fantacci, Claudio and Vezzani, Giulia and Pattacini, Ugo and Natale, Lorenzo},
  doi          = {10.3389/frobt.2021.594583},
  journal      = {Frontiers in Robotics and AI},
  month        = {3},
  pages        = {594583},
  shortjournal = {Front. Robot. AI},
  title        = {MaskUKF: An instance segmentation aided unscented kalman filter for 6D object pose and velocity tracking},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Art, design and communication theory in creating the
communicative social robot “haru.” <em>FROBT</em>, <em>8</em>, 577107.
(<a href="https://doi.org/10.3389/frobt.2021.577107">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Haru is a social, affective robot designed to support a wide range of research into human–robot communication. This article analyses the design process for Haru beta, identifying how both visual and performing arts were an essential part of that process, contributing to ideas of Haru’s communication as a science and as an art. Initially, the article examines how a modified form of Design Thinking shaped the work of the interdisciplinary development team—including animators, performers and sketch artists working alongside roboticists—to frame Haru’s interaction style in line with sociopsychological and cybernetic–semiotic communication theory. From these perspectives on communication, the focus is on creating a robot that is persuasive and able to transmit precise information clearly. The article moves on to highlight two alternative perspectives on communication, based on phenomenological and sociocultural theories, from which such a robot can be further developed as a more flexible and dynamic communicative agent. The various theoretical perspectives introduced are brought together by considering communication across three elements: encounter, story and dance. Finally, the article explores the potential of Haru as a research platform for human–robot communication across various scenarios designed to investigate how to support long-term interactions between humans and robots in different contexts. In particular, it gives an overview of plans for humanities-based, qualitative research with Haru.},
  archive      = {J_FROBT},
  author       = {Sandry, Eleanor and Gomez, Randy and Nakamura, Keisuke},
  doi          = {10.3389/frobt.2021.577107},
  journal      = {Frontiers in Robotics and AI},
  month        = {3},
  pages        = {577107},
  shortjournal = {Front. Robot. AI},
  title        = {Art, design and communication theory in creating the communicative social robot ‘Haru’},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Babyface: Performance and installation art exploring the
feminine ideal in gendered machines. <em>FROBT</em>, <em>8</em>, 576664.
(<a href="https://doi.org/10.3389/frobt.2021.576664">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Representations of gender in new technologies like the Siri, Pepper, and Sophia robotic assistants, as well as the commodification of features associated with gender on platforms like Instagram, inspire questions about how and whether robotic tools can have gender and what it means to people if they do. One possible response to this is through artistic creation of dance performance. This paper reports on one such project where, along the route to this inquiry, creation of machine augmentation – of both the performer and audience member – was necessary to communicate the artistic ideas grappled with therein. Thus, this article describes the presentation of Babyface, a machine-augmented, participatory contemporary dance performance. This work is a reaction to feminized tropes in popular media and modern technology, and establishes a parallel between the ways that women and machines are talked about, treated, and – in the case of machines – designed to look and behave. This paper extends prior reports on the creation of this piece and its accompanying devices to describe extensions with audience member participation, and reflect on the responses of these audience members. These fabricated elements alongside the actions of the performer and a soundscape that quotes statements made by real “female” robots create an otherwordly, sad cyborg character that causes viewers to question their assumptions about and pressures on the feminine ideal.},
  archive      = {J_FROBT},
  author       = {Ladenheim, Kate and LaViers, Amy},
  doi          = {10.3389/frobt.2021.576664},
  journal      = {Frontiers in Robotics and AI},
  month        = {3},
  pages        = {576664},
  shortjournal = {Front. Robot. AI},
  title        = {Babyface: Performance and installation art exploring the feminine ideal in gendered machines},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Modeling and reconstruction of state variables for low-level
control of soft pneumatic actuators. <em>FROBT</em>, <em>8</em>, 557830.
(<a href="https://doi.org/10.3389/frobt.2021.557830">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To further advance closed-loop control for soft robotics, suitable sensor and modeling strategies have to be investigated. Although there are many flexible and soft sensors available, the integration into the actuator and the use in a control loop is still challenging. Therefore, a state-space model for closed-loop low-level control of a fiber-reinforced actuator using pressure and orientation measurement is investigated. To do so, the integration of an inertial measurement unit and geometric modeling of actuator is presented. The piecewise constant curvature approach is used to describe the actuator’s shape and deformation variables. For low-level control, the chamber’s lengths are reconstructed from bending angles with a geometrical model and the identified material characteristics. For parameter identification and model validation, data from a camera tracking system is analyzed. Then, a closed-loop control of pressure and chambers’ length of the actuator is investigated. It will be shown, that the reconstruction model is suitable for estimating the state variables of the actuator. In addition, the use of the inertial measurement unit will demonstrate a cost-effective and compact sensor for soft pneumatic actuators.},
  archive      = {J_FROBT},
  author       = {Ibrahim, Serhat and Krause, Jan Christoph and Olbrich, Alexander and Raatz, Annika},
  doi          = {10.3389/frobt.2021.557830},
  journal      = {Frontiers in Robotics and AI},
  month        = {3},
  pages        = {557830},
  shortjournal = {Front. Robot. AI},
  title        = {Modeling and reconstruction of state variables for low-level control of soft pneumatic actuators},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Comparison between the facial flow lines of androids and
humans. <em>FROBT</em>, <em>8</em>, 540193. (<a
href="https://doi.org/10.3389/frobt.2021.540193">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The behavior of an android robot face is difficult to predict because of the complicated interactions between many and various attributes (size, weight, and shape) of system components. Therefore, the system behavior should be analyzed after these components are assembled to improve their performance. In this study, the three-dimensional displacement distributions for the facial surfaces of two android robots were measured for the analysis. The faces of three adult males were also analyzed for comparison. The visualized displacement distributions indicated that the androids lacked two main deformation features observed in the human upper face: curved flow lines and surface undulation, where the upstream areas of the flow lines elevate. These features potentially characterize the human-likeness. These findings suggest that innovative composite motion mechanisms to control both the flow lines and surface undulations are required to develop advanced androids capable of exhibiting more realistic facial expressions. Our comparative approach between androids and humans will improve androids’ impressions in future real-life application scenes, e.g., receptionists in hotels and banks, and clerks in shops.},
  archive      = {J_FROBT},
  author       = {Ishihara, Hisashi and Iwanaga, Saneyuki and Asada, Minoru},
  doi          = {10.3389/frobt.2021.540193},
  journal      = {Frontiers in Robotics and AI},
  month        = {3},
  pages        = {540193},
  shortjournal = {Front. Robot. AI},
  title        = {Comparison between the facial flow lines of androids and humans},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Can you activate me? From robots to human brain.
<em>FROBT</em>, <em>8</em>, 633514. (<a
href="https://doi.org/10.3389/frobt.2021.633514">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Manzi, F. and Di Dio, C. and Di Lernia, D. and Rossignoli, D. and Maggioni, M. A. and Massaro, D. and Marchetti, A. and Riva, G.},
  doi          = {10.3389/frobt.2021.633514},
  journal      = {Frontiers in Robotics and AI},
  month        = {2},
  pages        = {633514},
  shortjournal = {Front. Robot. AI},
  title        = {Can you activate me? from robots to human brain},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Sensor-less and control-less underactuated grippers with
pull-in mechanisms for grasping various objects. <em>FROBT</em>,
<em>8</em>, 631242. (<a
href="https://doi.org/10.3389/frobt.2021.631242">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes an underactuated grippers mechanism that grasps and pulls in different types of objects. These two movements are generated by only a single actuator while two independent actuators are used in conventional grippers. To demonstrate this principle, we have developed two kinds of gripper by different driving systems: one is driven by a DC motor with planetary gear reducers and another is driven by pneumatic actuators with branch tubes as a differential. Each pulling-in mechanism in the former one and the latter one is achieved by a belt-driven finger surface and a linear slider with an air cylinder, respectively. The motor-driven gripper with planetary gear reducers can pull-up the object after grasping. However, the object tends to fall when placing because it opens the finger before pushing out the object during the reversed movement. In addition, the closing speed and the picking-up speed of the fingers are slow due to the high reduction gear. To solve these drawbacks, a new pneumatic gripper by combining three valves, a speed control valve, a relief valve, and non-return valves, is proposed. The proposed pneumatic gripper is superior in the sense that it can perform pulling-up after grasping the object and opening the fingers after pushing-out the object. In the present paper, a design methodology of the different underactuated grippers that can not only grasp but also pull up objects is discussed. Then, to examine the performance of the grippers, experiments were conducted using various objects with different rigidity, shapes, size, and mass, which may be potentially available in real applications.},
  archive      = {J_FROBT},
  author       = {Kakogawa, Atsushi and Kaizu, Yuki and Ma, Shugen},
  doi          = {10.3389/frobt.2021.631242},
  journal      = {Frontiers in Robotics and AI},
  month        = {2},
  pages        = {631242},
  shortjournal = {Front. Robot. AI},
  title        = {Sensor-less and control-less underactuated grippers with pull-in mechanisms for grasping various objects},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A vision-based sensing approach for a spherical soft robotic
arm. <em>FROBT</em>, <em>8</em>, 630935. (<a
href="https://doi.org/10.3389/frobt.2021.630935">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sensory feedback is essential for the control of soft robotic systems and to enable deployment in a variety of different tasks. Proprioception refers to sensing the robot’s own state and is of crucial importance in order to deploy soft robotic systems outside of laboratory environments, i.e. where no external sensing, such as motion capture systems, is available. A vision-based sensing approach for a soft robotic arm made from fabric is presented, leveraging the high-resolution sensory feedback provided by cameras. No mechanical interaction between the sensor and the soft structure is required and consequently the compliance of the soft system is preserved. The integration of a camera into an inflatable, fabric-based bellow actuator is discussed. Three actuators, each featuring an integrated camera, are used to control the spherical robotic arm and simultaneously provide sensory feedback of the two rotational degrees of freedom. A convolutional neural network architecture predicts the two angles describing the robot’s orientation from the camera images. Ground truth data is provided by a motion capture system during the training phase of the supervised learning approach and its evaluation thereafter. The camera-based sensing approach is able to provide estimates of the orientation in real-time with an accuracy of about one degree. The reliability of the sensing approach is demonstrated by using the sensory feedback to control the orientation of the robotic arm in closed-loop.},
  archive      = {J_FROBT},
  author       = {Hofer, Matthias and Sferrazza, Carmelo and D’Andrea, Raffaello},
  doi          = {10.3389/frobt.2021.630935},
  journal      = {Frontiers in Robotics and AI},
  month        = {2},
  pages        = {630935},
  shortjournal = {Front. Robot. AI},
  title        = {A vision-based sensing approach for a spherical soft robotic arm},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Leveraging geometry to enable high-strength continuum
robots. <em>FROBT</em>, <em>8</em>, 629871. (<a
href="https://doi.org/10.3389/frobt.2021.629871">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Developing high-strength continuum robots can be challenging without compromising on the overall size of the robot, the complexity of design and the range of motion. In this work, we explore how the load capacity of continuum robots can drastically be improved through a combination of backbone design and convergent actuation path routing. We propose a rhombus-patterned backbone structure composed of thin walled-plates that can be easily fabricated via 3D printing and exhibits high shear and torsional stiffness while allowing bending. We then explore the effect of combined parallel and converging actuation path routing and its influence on continuum robot strength. Experimentally determined compliance matrices are generated for straight, translation and bending configurations for analysis and discussion. A robotic actuation platform is constructed to demonstrate the applicability of these design choices.},
  archive      = {J_FROBT},
  author       = {Childs, Jake A. and Rucker, Caleb},
  doi          = {10.3389/frobt.2021.629871},
  journal      = {Frontiers in Robotics and AI},
  month        = {2},
  pages        = {629871},
  shortjournal = {Front. Robot. AI},
  title        = {Leveraging geometry to enable high-strength continuum robots},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Opinion: Opportunities and limitations of machine vision for
yield mapping. <em>FROBT</em>, <em>8</em>, 627280. (<a
href="https://doi.org/10.3389/frobt.2021.627280">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Schueller, John K.},
  doi          = {10.3389/frobt.2021.627280},
  journal      = {Frontiers in Robotics and AI},
  month        = {2},
  pages        = {627280},
  shortjournal = {Front. Robot. AI},
  title        = {Opinion: Opportunities and limitations of machine vision for yield mapping},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). UAV-UGV-UMV multi-swarms for cooperative surveillance.
<em>FROBT</em>, <em>8</em>, 616950. (<a
href="https://doi.org/10.3389/frobt.2021.616950">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we present a surveillance system for early detection of escapers from a restricted area based on a new swarming mobility model called CROMM-MS (Chaotic Rössler Mobility Model for Multi-Swarms). CROMM-MS is designed for controlling the trajectories of heterogeneous multi-swarms of aerial, ground and marine unmanned vehicles with important features such as prioritising early detections and success rate. A new Competitive Coevolutionary Genetic Algorithm (CompCGA) is proposed to optimise the vehicles’ parameters and escapers’ evasion ability using a predator-prey approach. Our results show that CROMM-MS is not only viable for surveillance tasks but also that its results are competitive in regard to the state-of-the-art approaches.},
  archive      = {J_FROBT},
  author       = {Stolfi, Daniel H. and Brust, Matthias R. and Danoy, Grégoire and Bouvry, Pascal},
  doi          = {10.3389/frobt.2021.616950},
  journal      = {Frontiers in Robotics and AI},
  month        = {2},
  pages        = {616950},
  shortjournal = {Front. Robot. AI},
  title        = {UAV-UGV-UMV multi-swarms for cooperative surveillance},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Approaches for efficiently detecting frontier cells in
robotics exploration. <em>FROBT</em>, <em>8</em>, 616470. (<a
href="https://doi.org/10.3389/frobt.2021.616470">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many robot exploration algorithms that are used to explore office, home, or outdoor environments, rely on the concept of frontier cells. Frontier cells define the border between known and unknown space. Frontier-based exploration is the process of repeatedly detecting frontiers and moving towards them, until there are no more frontiers and therefore no more unknown regions. The faster frontier cells can be detected, the more efficient exploration becomes. This paper proposes several algorithms for detecting frontiers. The first is called Naïve Active Area (NaïveAA) frontier detection and achieves frontier detection in constant time by only evaluating the cells in the active area defined by scans taken. The second algorithm is called Expanding-Wavefront Frontier Detection (EWFD) and uses frontiers from the previous timestep as a starting point for searching for frontiers in newly discovered space. The third approach is called Frontier-Tracing Frontier Detection (FTFD) and also uses the frontiers from the previous timestep as well as the endpoints of the scan, to determine the frontiers at the current timestep. Algorithms are compared to state-of-the-art algorithms such as Naïve, WFD, and WFD-INC. NaïveAA is shown to operate in constant time and therefore is suitable as a basic benchmark for frontier detection algorithms. EWFD and FTFD are found to be significantly faster than other algorithms.},
  archive      = {J_FROBT},
  author       = {Quin, Phillip and Nguyen, Dac Dang Khoa and Vu, Thanh Long and Alempijevic, Alen and Paul, Gavin},
  doi          = {10.3389/frobt.2021.616470},
  journal      = {Frontiers in Robotics and AI},
  month        = {2},
  pages        = {616470},
  shortjournal = {Front. Robot. AI},
  title        = {Approaches for efficiently detecting frontier cells in robotics exploration},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). State-space characterization of balance capabilities in
biped systems with segmented feet. <em>FROBT</em>, <em>8</em>, 613038.
(<a href="https://doi.org/10.3389/frobt.2021.613038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The human ability of keeping balance during various locomotion tasks is attributed to our capability of withstanding complex interactions with the environment and coordinating whole-body movements. Despite this, several stability analysis methods are limited by the use of overly simplified biped and foot structures and corresponding contact models. As a result, existing stability criteria tend to be overly restrictive and do not represent the full balance capabilities of complex biped systems. The proposed methodology allows for the characterization of the balance capabilities of general biped models (ranging from reduced-order to whole-body) with segmented feet. Limits of dynamic balance are evaluated by the Boundary of Balance (BoB) and the associated novel balance indicators, both formulated in the Center of Mass (COM) state space. Intermittent heel, flat, and toe contacts are enabled by a contact model that maps discrete contact modes into corresponding center of pressure constraints. For demonstration purposes, the BoB and balance indicators are evaluated for a whole-body biped model with segmented feet representative of the human-like standing posture in the sagittal plane. The BoB is numerically constructed as the set of maximum allowable COM perturbations that the biped can sustain along a prescribed direction. For each point of the BoB, a constrained trajectory optimization algorithm generates the biped’s whole-body trajectory as it recovers from extreme COM velocity perturbations in the anterior–posterior direction. Balance capabilities for the cases of flat and segmented feet are compared, demonstrating the functional role the foot model plays in the limits of postural balance. The state-space evaluation of the BoB and balance indicators allows for a direct comparison between the proposed balance benchmark and existing stability criteria based on reduced-order models [e.g., Linear Inverted Pendulum (LIP)] and their associated stability metrics [e.g., Margin of Stability (MOS)]. The proposed characterization of balance capabilities provides an important benchmarking framework for the stability of general biped/foot systems.},
  archive      = {J_FROBT},
  author       = {Mummolo, Carlotta and Akbas, Kubra and Carbone, Giuseppe},
  doi          = {10.3389/frobt.2021.613038},
  journal      = {Frontiers in Robotics and AI},
  month        = {2},
  pages        = {613038},
  shortjournal = {Front. Robot. AI},
  title        = {State-space characterization of balance capabilities in biped systems with segmented feet},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Guidelines for robotic flexible endoscopy at the time of
COVID-19. <em>FROBT</em>, <em>8</em>, 612852. (<a
href="https://doi.org/10.3389/frobt.2021.612852">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Flexible endoscopy involves the insertion of a long narrow flexible tube into the body for diagnostic and therapeutic procedures. In the gastrointestinal (GI) tract, flexible endoscopy plays a major role in cancer screening, surveillance, and treatment programs. As a result of gas insufflation during the procedure, both upper and lower GI endoscopy procedures have been classified as aerosol generating by the guidelines issued by the respective societies during the COVID-19 pandemic—although no quantifiable data on aerosol generation currently exists. Due to the risk of COVID-19 transmission to healthcare workers, most societies halted non-emergency and diagnostic procedures during the lockdown. The long-term implications of stoppage in cancer diagnoses and treatment is predicted to lead to a large increase in preventable deaths. Robotics may play a major role in this field by allowing healthcare operators to control the flexible endoscope from a safe distance and pave a path for protecting healthcare workers through minimizing the risk of virus transmission without reducing diagnostic and therapeutic capacities. This review focuses on the needs and challenges associated with the design of robotic flexible endoscopes for use during a pandemic. The authors propose that a few minor changes to existing platforms or considerations for platforms in development could lead to significant benefits for use during infection control scenarios.},
  archive      = {J_FROBT},
  author       = {Onaizah, Onaizah and Koszowska, Zaneta and Winters, Conchubhair and Subramanian, Venkatamaran and Jayne, David and Arezzo, Alberto and Obstein, Keith L. and Valdastri, Pietro},
  doi          = {10.3389/frobt.2021.612852},
  journal      = {Frontiers in Robotics and AI},
  month        = {2},
  pages        = {612852},
  shortjournal = {Front. Robot. AI},
  title        = {Guidelines for robotic flexible endoscopy at the time of COVID-19},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). “Hit the robot on the head with this mallet” – making a case
for including more open questions in HRI research. <em>FROBT</em>,
<em>8</em>, 603510. (<a
href="https://doi.org/10.3389/frobt.2021.603510">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Researchers continue to devise creative ways to explore the extent to which people perceive robots as social agents, as opposed to objects. One such approach involves asking participants to inflict ‘harm’ on a robot. Researchers are interested in the length of time between the experimenter issuing the instruction and the participant complying, and propose that relatively long periods of hesitation might reflect empathy for the robot, and perhaps even attribution of human-like qualities, such as agency and sentience. In a recent experiment, we adapted the so-called ‘hesitance to hit’ paradigm, in which participants were instructed to hit a humanoid robot on the head with a mallet. After standing up to do so (signaling intent to hit the robot), participants were stopped, and then took part in a semi-structured interview to probe their thoughts and feelings during the period of hesitation. Thematic analysis of the responses indicate that hesitation not only reflects perceived socialness, but also other factors including (but not limited to) concerns about cost, mallet disbelief, processing of the task instruction, and the influence of authority. The open-ended, free responses participants provided also offer rich insights into individual differences with regards to anthropomorphism, perceived power imbalances, and feelings of connection toward the robot. In addition to aiding understanding of this measurement technique and related topics regarding socialness attribution to robots, we argue that greater use of open questions can lead to exciting new research questions and interdisciplinary collaborations in the domain of social robotics.},
  archive      = {J_FROBT},
  author       = {Riddoch, Katie A. and Cross, Emily. S.},
  doi          = {10.3389/frobt.2021.603510},
  journal      = {Frontiers in Robotics and AI},
  month        = {2},
  pages        = {603510},
  shortjournal = {Front. Robot. AI},
  title        = {“Hit the robot on the head with this mallet” – making a case for including more open questions in HRI research},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Optimizing the rigid or compliant behavior of a novel
parallel-actuated architecture for exoskeleton robot applications.
<em>FROBT</em>, <em>8</em>, 596958. (<a
href="https://doi.org/10.3389/frobt.2021.596958">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The purpose of this work is to optimize the rigid or compliant behavior of a new type of parallel-actuated robot architecture developed for exoskeleton robot applications. This is done in an effort to provide those that utilize the architecture with the means to maximize, minimize, or simply adjust its stiffness property so as to optimize it for particular tasks, such as augmented lifting or impact absorption. This research even provides the means to produce non-homogeneous stiffness properties for applications that may require non-homogeneous dynamic behavior. In this work, the new architecture is demonstrated in the form of a shoulder exoskeleton. An analytical stiffness model for the shoulder exoskeleton is created and validated experimentally. The model is then used, along with a method of bounded nonlinear multi-objective optimization to configure the parallel substructures for desired rigidity, compliance or nonhomogeneous stiffness behavior. The stiffness model and its optimization can be applied beyond the shoulder to any embodiment of the new parallel architecture, including hip, wrist and ankle robot applications. In order to exemplify this, we present the rigidity optimization for a theoretical hip exoskeleton.},
  archive      = {J_FROBT},
  author       = {Hunt, Justin and Lee, Hyunglae},
  doi          = {10.3389/frobt.2021.596958},
  journal      = {Frontiers in Robotics and AI},
  month        = {2},
  pages        = {596958},
  shortjournal = {Front. Robot. AI},
  title        = {Optimizing the rigid or compliant behavior of a novel parallel-actuated architecture for exoskeleton robot applications},
  volume       = {8},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A concise and geometrically exact planar beam model for
arbitrarily large elastic deformation dynamics. <em>FROBT</em>,
<em>7</em>, 609478. (<a
href="https://doi.org/10.3389/frobt.2020.609478">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The potential of large elastic deformations in control applications, e.g., robotic manipulation, is not yet fully exploited, especially in dynamic contexts. Mainly because essential geometrically exact continuum models are necessary to express these arbitrarily large deformation dynamics, they typically result in a set of nonlinear, coupled, partial differential equations that are unsuited for control applications. Due to this lack of appropriate models, current approaches that try to exploit elastic properties are limited to either small deflection assumptions or quasistatic considerations only. To promote further exploration of this exciting research field of large elastic deflection control, we propose a geometrically exact, but yet concise a beam model for a planar, shear-, and torsion-free case without elongation. The model is derived by reducing the general geometrically exact the 3D Simo–Reissner beam model to this special case, where the assumption of inextensibility allows expressing the couple of planar Cartesian parameters in terms of the curve tangent angle of the beam center line alone. We further elaborate on how the necessary coupling between position-related boundary conditions (i.e., clamped and hinged ends) and the tangent angle parametrization of the beam model can be incorporated in a finite element method formulation and verify all derived expressions by comparison to analytic initial value solutions and an energy analysis of a dynamic simulation result. The presented beam model opens the possibility of designing online feedback control structures for accessing the full potential that elasticity in planar beam dynamics has to offer.},
  archive      = {J_FROBT},
  author       = {Huber, Gerold and Wollherr, Dirk and Buss, Martin},
  doi          = {10.3389/frobt.2020.609478},
  journal      = {Frontiers in Robotics and AI},
  month        = {5},
  pages        = {609478},
  shortjournal = {Front. Robot. AI},
  title        = {A concise and geometrically exact planar beam model for arbitrarily large elastic deformation dynamics},
  volume       = {7},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). OUTPUT: Choreographed and reconfigured human and industrial
robot bodies across artistic modalities. <em>FROBT</em>, <em>7</em>,
576790. (<a href="https://doi.org/10.3389/frobt.2020.576790">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Millions of industrial robots are used across manufacturing and research applications worldwide. Handfuls of these robots have been used in dance, installation, and theatrical art works as tools and performers. OUTPUT, a collaborative artwork presented here, employs an industrial robot as choreographic source material and dancing body in order to reframe these robots as performers and bring them into closer proximity with the general public. This OUTPUT work has existed as a performance, installation, and augmented reality application. All three formats of the work include improvisational components, where a human can dance with a representation of themselves alongside an industrial robot, facilitating an embodied and creative experience next to these sequestered machines.},
  archive      = {J_FROBT},
  author       = {Cuan, Catie},
  doi          = {10.3389/frobt.2020.576790},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {576790},
  shortjournal = {Front. Robot. AI},
  title        = {OUTPUT: Choreographed and reconfigured human and industrial robot bodies across artistic modalities},
  volume       = {7},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Soft origami optical-sensing actuator for underwater
manipulation. <em>FROBT</em>, <em>7</em>, 616128. (<a
href="https://doi.org/10.3389/frobt.2020.616128">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Soft robots are ideal for underwater manipulation in sampling and other servicing applications. Their unique features of compliance, adaptability, and being naturally waterproof enable robotic designs to be compact and lightweight, while achieving uncompromized dexterity and flexibility. However, the inherent flexibility and high nonlinearity of soft materials also results in combined complex motions, which creates both soft actuator and sensor challenges for force output, modeling, and sensory feedback, especially under highly dynamic underwater environments. To tackle these limitations, a novel Soft Origami Optical-Sensing Actuator (SOSA) with actuation and sensing integration is proposed in this paper. Inspired by origami art, the proposed sensorized actuator enables a large force output, contraction/elongation/passive bending actuation by fluid, and hybrid motion sensing with optical waveguides. The SOSA design brings two major novelties over current designs. First, it involves a new actuation-sensing mode which enables a superior large payload output and a robust and accurate sensing performance by introducing the origami design, significantly facilitating the integration of sensing and actuating technology for wider applications. Secondly, it simplifies the fabrication process for harsh environment application by investigating the boundary features between optical waveguides and ambient water, meaning the external cladding layer of traditional sensors is unnecessary. With these merits, the proposed actuator could be applied to harsh environments for complex interaction/operation tasks. To showcase the performance of the proposed SOSA actuator, a hybrid underwater 3-DOFs manipulator has been developed. The entire workflow on concept design, fabrication, modeling, experimental validation, and application are presented in detail as reference for wider effective robot-environment applications.},
  archive      = {J_FROBT},
  author       = {Shen, Zhong and Zhao, Yafei and Zhong, Hua and Tang, Kailuan and Chen, Yishan and Xiao, Yin and Yi, Juan and Liu, Sicong and Wang, Zheng},
  doi          = {10.3389/frobt.2020.616128},
  journal      = {Frontiers in Robotics and AI},
  month        = {3},
  pages        = {616128},
  shortjournal = {Front. Robot. AI},
  title        = {Soft origami optical-sensing actuator for underwater manipulation},
  volume       = {7},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The aesthetics of encounter: A relational-performative
design approach to human-robot interaction. <em>FROBT</em>, <em>7</em>,
577900. (<a href="https://doi.org/10.3389/frobt.2020.577900">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article lays out the framework for relational-performative aesthetics in human-robot interaction, comprising a theoretical lens and design approach for critical practice-based inquiries into embodied meaning-making in human-robot interaction. I explore the centrality of aesthetics as a practice of embodied meaning-making by drawing on my arts-led, performance-based approach to human-robot encounters, as well as other artistic practices. Understanding social agency and meaning as being enacted through the situated dynamics of the interaction, I bring into focus a process of bodying-thinging; entangling and transforming subjects and objects in the encounter and rendering elastic boundaries in-between. Rather than serving to make the strange look more familiar, aesthetics here is about rendering the differences between humans and robots more relational. My notion of a relational-performative design approach—designing with bodying-thinging—proposes that we engage with human-robot encounters from the earliest stages of the robot design. This is where we begin to manifest boundaries that shape meaning-making and the potential for emergence, transformation, and connections arising from intra-bodily resonances (bodying-thinging). I argue that this relational-performative approach opens up new possibilities for how we design robots and how they socially participate in the encounter.},
  archive      = {J_FROBT},
  author       = {Gemeinboeck, Petra},
  doi          = {10.3389/frobt.2020.577900},
  journal      = {Frontiers in Robotics and AI},
  month        = {3},
  pages        = {577900},
  shortjournal = {Front. Robot. AI},
  title        = {The aesthetics of encounter: A relational-performative design approach to human-robot interaction},
  volume       = {7},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). How to model tendon-driven continuum robots and benchmark
modelling performance. <em>FROBT</em>, <em>7</em>, 630245. (<a
href="https://doi.org/10.3389/frobt.2020.630245">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tendon actuation is one of the most prominent actuation principles for continuum robots. To date, a wide variety of modelling approaches has been derived to describe the deformations of tendon-driven continuum robots. Motivated by the need for a comprehensive overview of existing methodologies, this work summarizes and outlines state-of-the-art modelling approaches. In particular, the most relevant models are classified based on backbone representations and kinematic as well as static assumptions. Numerical case studies are conducted to compare the performance of representative modelling approaches from the current state-of-the-art, considering varying robot parameters and scenarios. The approaches show different performances in terms of accuracy and computation time. Guidelines for the selection of the most suitable approach for given designs of tendon-driven continuum robots and applications are deduced from these results.},
  archive      = {J_FROBT},
  author       = {Rao, Priyanka and Peyron, Quentin and Lilge, Sven and Burgner-Kahrs, Jessica},
  doi          = {10.3389/frobt.2020.630245},
  journal      = {Frontiers in Robotics and AI},
  month        = {2},
  pages        = {630245},
  shortjournal = {Front. Robot. AI},
  title        = {How to model tendon-driven continuum robots and benchmark modelling performance},
  volume       = {7},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Robotic-assisted surgery for cadaveric skull opening: A new
method of autopsy procedure. <em>FROBT</em>, <em>7</em>, 622083. (<a
href="https://doi.org/10.3389/frobt.2020.622083">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Background: Sawing of bone is an essential part of an autopsy procedure. An oscillating saw always generates noise, fine infectious dust particles, and the possibility of traumatic injuries, all of which can induce occupational hazard risks to autopsy workers, especially during the COVID-19 pandemic.Objectives: The first goal of this study was to explore the production of noise and bone dust emission, comparing an oscillating saw and a robotic autopsy saw during an autopsy. The second goal was to evaluate the performance of a new robotic autopsy method, used during skull opening. The third goal was to encourage mortuary workers to use robotic technology during the autopsy procedure to protect us away from occupational injuries as well as airborne infections.Materials and Methods: The experiments involved a comparison of noise levels and aerosol production during skull cutting between the oscillating saw and the robotic autopsy saw.Results: The results confirmed that noise production from the robotic autopsy saw was lower than the oscillating saw. However, the bone dust levels, produced by the robotic autopsy saw, were greater than the oscillating saw, but were not greater than the dust concentrations which were present before opening the skull.Conclusions: The use of a new robotic system might be an alternative choice for protecting against occupational damage among the healthcare workers. Further research might attempt to consider other healthcare problems which occur in the autopsy workplace and apply the robotic-assisted technology in autopsy surgery.},
  archive      = {J_FROBT},
  author       = {Jumlongkul, Arnon and Chutivongse, Panuwat},
  doi          = {10.3389/frobt.2020.622083},
  journal      = {Frontiers in Robotics and AI},
  month        = {2},
  pages        = {622083},
  shortjournal = {Front. Robot. AI},
  title        = {Robotic-assisted surgery for cadaveric skull opening: A new method of autopsy procedure},
  volume       = {7},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Applying deep reinforcement learning to cable driven
parallel robots for balancing unstable loads: A ball case study.
<em>FROBT</em>, <em>7</em>, 611203. (<a
href="https://doi.org/10.3389/frobt.2020.611203">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The current pandemic has highlighted the need for rapid construction of structures to treat patients and ensure manufacturing of health care products such as vaccines. In order to achieve this, rapid transportation of construction materials from staging area to deposition is needed. In the future, this could be achieved through automated construction sites that make use of robots. Toward this, in this paper a cable driven parallel manipulator (CDPM) is designed and built to balance a highly unstable load, a ball plate system. The system consists of eight cables attached to the end effector plate that can be extended or retracted to actuate movement of the plate. The hardware for the system was designed and built utilizing modern manufacturing processes. A camera system was designed using image recognition to identify the ball pose on the plate. The hardware was used to inform the development of a control system consisting of a reinforcement-learning trained neural network controller that outputs the desired platform response. A nested PID controller for each motor attached to each cable was used to realize the desired response. For the neural network controller, three different model structures were compared to assess the impact of varying model complexity. It was seen that less complex structures resulted in a slower response that was less flexible and more complex structures output a high frequency oscillation of the actuation signal resulting in an unresponsive system. It was concluded that the system showed promise for future development with the potential to improve on the state of the art.},
  archive      = {J_FROBT},
  author       = {Grimshaw, Alex and Oyekan, John},
  doi          = {10.3389/frobt.2020.611203},
  journal      = {Frontiers in Robotics and AI},
  month        = {2},
  pages        = {611203},
  shortjournal = {Front. Robot. AI},
  title        = {Applying deep reinforcement learning to cable driven parallel robots for balancing unstable loads: A ball case study},
  volume       = {7},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Hierarchical, dense and dynamic 3D reconstruction based on
VDB data structure for robotic manipulation tasks. <em>FROBT</em>,
<em>7</em>, 600387. (<a
href="https://doi.org/10.3389/frobt.2020.600387">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a novel approach to implement hierarchical, dense and dynamic reconstruction of 3D objects based on the VDB (Variational Dynamic B + Trees) data structure for robotic applications. The scene reconstruction is done by the integration of depth-images using the Truncated Signed Distance Field (TSDF). The proposed reconstruction method is based on dynamic trees in order to provide similar reconstruction results to the current state-of-the-art methods (i.e., complete volumes, hashing voxels and hierarchical volumes) in terms of execution time but with a direct multi-level representation that remains real-time. This representation provides two major advantages: it is a hierarchical and unbounded space representation. The proposed method is optimally implemented to be used on a GPU architecture, exploiting the parallelism skills of this hardware. A series of experiments will be presented to prove the performance of this approach in a robot arm platform.},
  archive      = {J_FROBT},
  author       = {Mateo, Carlos M. and Corrales, Juan A. and Mezouar, Youcef},
  doi          = {10.3389/frobt.2020.600387},
  journal      = {Frontiers in Robotics and AI},
  month        = {2},
  pages        = {600387},
  shortjournal = {Front. Robot. AI},
  title        = {Hierarchical, dense and dynamic 3D reconstruction based on VDB data structure for robotic manipulation tasks},
  volume       = {7},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Learning optimal fin-ray finger design for soft grasping.
<em>FROBT</em>, <em>7</em>, 590076. (<a
href="https://doi.org/10.3389/frobt.2020.590076">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The development of soft hands is an important progress to empower robotic grasping with passive compliance while greatly decreasing the complexity of control. Despite the advances during the past decades, it is still not clear how to design optimal hands or fingers given the task requirements. In this paper, we propose a framework to learn the optimal design parameter for a fin-ray finger in order to achieve stable grasping. First, the pseudo-kinematics of the soft finger is learned in simulation. Second, the task constraints are encoded as a combination of desired grasping force and the empirical grasping quality function in terms of winding number. Finally, the effectiveness of the proposed approach is validated with experiments in simulation and using real-world examples as well.},
  archive      = {J_FROBT},
  author       = {Deng, Zhifeng and Li, Miao},
  doi          = {10.3389/frobt.2020.590076},
  journal      = {Frontiers in Robotics and AI},
  month        = {2},
  pages        = {590076},
  shortjournal = {Front. Robot. AI},
  title        = {Learning optimal fin-ray finger design for soft grasping},
  volume       = {7},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Lessons from joint improvisation workshops for musicians and
robotics engineers. <em>FROBT</em>, <em>7</em>, 576702. (<a
href="https://doi.org/10.3389/frobt.2020.576702">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We report on a series of workshops with musicians and robotics engineers aimed to study how human and machine improvisation can be explored through interdisciplinary design research. In the first workshop, we posed two leading questions to participants. First, what can AI and robotics learn by how improvisers think about time, space, actions, and decisions? Second, how can improvisation and musical instruments be enhanced by AI and robotics? The workshop included sessions led by the musicians, which provided an overview of the theory and practice of musical improvisation. In other sessions, AI and robotics researchers introduced AI principles to the musicians. Two smaller follow-up workshops comprised of only engineering and information science students provided an opportunity to elaborate on the principles covered in the first workshop. The workshops revealed parallels and discrepancies in the conceptualization of improvisation between musicians and engineers. These thematic differences could inform considerations for future designers of improvising robots.},
  archive      = {J_FROBT},
  author       = {Carter, Anthonia and Papalexandri-Alexandri, Marianthi and Hoffman, Guy},
  doi          = {10.3389/frobt.2020.576702},
  journal      = {Frontiers in Robotics and AI},
  month        = {2},
  pages        = {576702},
  shortjournal = {Front. Robot. AI},
  title        = {Lessons from joint improvisation workshops for musicians and robotics engineers},
  volume       = {7},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Automated AMBU ventilator with negative pressure headbox and
transporting capsule for COVID-19 patient transfer. <em>FROBT</em>,
<em>7</em>, 621580. (<a
href="https://doi.org/10.3389/frobt.2020.621580">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Purpose: It is now clear that the COVID-19 viruses can be transferred via airborne transmission. The objective of this study was to attempt the design and fabrication of an AMBU ventilator with a negative pressure headbox linked to a negative pressure transporting capsule, which could provide a low-cost construction, flexible usage unit, and also airborne prevention that could be manufactured without a high level of technology.Method: The machine consists of an automated AMBU bag ventilator, a negative pressure headbox, and a transporting capsule. The function and working duration of each component were tested.Results: The two main settings of the ventilator include an active mode that can be set at the time range of 0 s–9 h 59 min 59 s and a resting mode, which could work continuously for 24 h. The blower motor and battery system, which were used to power the ventilator, create negative air pressure within the headbox, and the transporting capsule, could run for at least 2 h without being recharged. The transporting capsule was able to create an air change rate of 21.76 ACH with-10 Pa internal pressure.Conclusion: This automated AMBU ventilator allowed flow rate, rhythm, and volume of oxygen to be set. The hazardous expired air was treated by a HEPA filter. The patient’s transporting capsule is of a compact size and incorporates the air treatment systems. Further development of this machine should focus on how to link seamlessly with imaging technology, to verify standardization, to test using human subjects, and then to be the commercialized.},
  archive      = {J_FROBT},
  author       = {Jumlongkul, Arnon},
  doi          = {10.3389/frobt.2020.621580},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {621580},
  shortjournal = {Front. Robot. AI},
  title        = {Automated AMBU ventilator with negative pressure headbox and transporting capsule for COVID-19 patient transfer},
  volume       = {7},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Application of DenTeach in remote dentistry teaching and
learning during the COVID-19 pandemic: A case study. <em>FROBT</em>,
<em>7</em>, 611424. (<a
href="https://doi.org/10.3389/frobt.2020.611424">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In December 2019, an outbreak of novel coronavirus pneumonia occurred, and subsequently attracted worldwide attention when it bloomed into the COVID-19 pandemic. To limit the spread and transmission of the novel coronavirus, governments, regulatory bodies, and health authorities across the globe strongly enforced shut down of educational institutions including medical and dental schools. The adverse effects of COVID-19 on dental education have been tremendous, including difficulties in the delivery of practical courses such as restorative dentistry. As a solution to help dental schools adapt to the pandemic, we have developed a compact and portable teaching-learning platform called DenTeach. This platform is intended for remote teaching and learning pertaining to dental schools at these unprecedented times. This device can facilitate fully remote and physical-distancing-aware teaching and learning in dentistry. DenTeach platform consists of an instructor workstation (DT-Performer), a student workstation (DT-Student), advanced wireless networking technology, and cloud-based data storage and retrieval. The platform procedurally synchronizes the instructor and the student with real-time video, audio, feel, and posture (VAFP). To provide quantitative feedback to instructors and students, the DT-Student workstation quantifies key performance indices (KPIs) related to a given task to assess and improve various aspects of the dental skills of the students. DenTeach has been developed for use in teaching, shadowing, and practice modes. In the teaching mode, the device provides each student with tactile feedback by processing the data measured and/or obtained from the instructor&#39;s workstation, which helps the student enhance their dental skills while inherently learning from the instructor. In the shadowing mode, the student can download the augmented videos and start watching, feeling, and repeating the tasks before entering the practice mode. In the practice mode, students use the system to perform dental tasks and have their dental performance skills automatically evaluated in terms of KPIs such that both the student and the instructor are able to monitor student’s work. Most importantly, as DenTeach is packaged in a small portable suitcase, it can be used anywhere by connecting to the cloud-based data storage network to retrieve procedures and performance metrics. This paper also discusses the feasibility of the DenTeach device in the form of a case study. It is demonstrated that a combination of the KPIs, video views, and graphical reports in both teaching and shadowing modes effectively help the student understand which aspects of their work needs further improvement. Moreover, the results of the practice mode over 10 trials have shown significant improvement in terms of tool handling, smoothness of motion, and steadiness of the operation.},
  archive      = {J_FROBT},
  author       = {Cheng, Lingbo and Kalvandi, Maryam and McKinstry, Sheri and Maddahi, Ali and Chaudhary, Ambika and Maddahi, Yaser and Tavakoli, Mahdi},
  doi          = {10.3389/frobt.2020.611424},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {611424},
  shortjournal = {Front. Robot. AI},
  title        = {Application of DenTeach in remote dentistry teaching and learning during the COVID-19 pandemic: A case study},
  volume       = {7},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Comparison of human social brain activity during eye-contact
with another human and a humanoid robot. <em>FROBT</em>, <em>7</em>,
599581. (<a href="https://doi.org/10.3389/frobt.2020.599581">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robot design to simulate interpersonal social interaction is an active area of research with applications in therapy and companionship. Neural responses to eye-to-eye contact in humans have recently been employed to determine the neural systems that are active during social interactions. Whether eye-contact with a social robot engages the same neural system remains to be seen. Here, we employ a similar approach to compare human-human and human-robot social interactions. We assume that if human-human and human-robot eye-contact elicit similar neural activity in the human, then the perceptual and cognitive processing is also the same for human and robot. That is, the robot is processed similar to the human. However, if neural effects are different, then perceptual and cognitive processing is assumed to be different. In this study neural activity was compared for human-to-human and human-to-robot conditions using near infrared spectroscopy for neural imaging, and a robot (Maki) with eyes that blink and move right and left. Eye-contact was confirmed by eye-tracking for both conditions. Increased neural activity was observed in human social systems including the right temporal parietal junction and the dorsolateral prefrontal cortex during human-human eye contact but not human-robot eye-contact. This suggests that the type of human-robot eye-contact used here is not sufficient to engage the right temporoparietal junction in the human. This study establishes a foundation for future research into human-robot eye-contact to determine how elements of robot design and behavior impact human social processing within this type of interaction and may offer a method for capturing difficult to quantify components of human-robot interaction, such as social engagement.},
  archive      = {J_FROBT},
  author       = {Kelley, Megan S. and Noah, J. Adam and Zhang, Xian and Scassellati, Brian and Hirsch, Joy},
  doi          = {10.3389/frobt.2020.599581},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {599581},
  shortjournal = {Front. Robot. AI},
  title        = {Comparison of human social brain activity during eye-contact with another human and a humanoid robot},
  volume       = {7},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Remote actuation systems for fully wearable assistive
devices: Requirements, selection, and optimization for out-of-the-lab
application of a hand exoskeleton. <em>FROBT</em>, <em>7</em>, 596185.
(<a href="https://doi.org/10.3389/frobt.2020.596185">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wearable robots assist individuals with sensorimotor impairment in daily life, or support industrial workers in physically demanding tasks. In such scenarios, low mass and compact design are crucial factors for device acceptance. Remote actuation systems (RAS) have emerged as a popular approach in wearable robots to reduce perceived weight and increase usability. Different RAS have been presented in the literature to accommodate for a wide range of applications and related design requirements. The push toward use of wearable robotics in out-of-the-lab applications in clinics, home environments, or industry created a shift in requirements for RAS. In this context, high durability, ergonomics, and simple maintenance gain in importance. However, these are only rarely considered and evaluated in research publications, despite being drivers for device abandonment by end-users. In this paper, we summarize existing approaches of RAS for wearable assistive technology in a literature review and compare advantages and disadvantages, focusing on specific evaluation criteria for out-of-the-lab applications to provide guidelines for the selection of RAS. Based on the gained insights, we present the development, optimization, and evaluation of a cable-based RAS for out-of-the-lab applications in a wearable assistive soft hand exoskeleton. The presented RAS features full wearability, high durability, high efficiency, and appealing design while fulfilling ergonomic criteria such as low mass and high wearing comfort. This work aims to support the transfer of RAS for wearable robotics from controlled lab environments to out-of-the-lab applications.},
  archive      = {J_FROBT},
  author       = {Dittli, Jan and Hofmann, Urs A. T. and Bützer, Tobias and Smit, Gerwin and Lambercy, Olivier and Gassert, Roger},
  doi          = {10.3389/frobt.2020.596185},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {596185},
  shortjournal = {Front. Robot. AI},
  title        = {Remote actuation systems for fully wearable assistive devices: Requirements, selection, and optimization for out-of-the-lab application of a hand exoskeleton},
  volume       = {7},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An assistive soft wrist exosuit for flexion movements with
an ergonomic reinforced glove. <em>FROBT</em>, <em>7</em>, 595862. (<a
href="https://doi.org/10.3389/frobt.2020.595862">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Soft exosuits are a promising solution for the assistance and augmentation of human motor abilities in the industrial field, where the use of more symbiotic wearable robots can avoid excessive worker fatigue and improve the quality of the work. One of the challenges in the design of soft exosuits is the choice of the right amount of softness to balance load transfer, ergonomics, and weight. This article presents a cable-driven based soft wrist exosuit for flexion assistance with the use of an ergonomic reinforced glove. The flexible and highly compliant three-dimensional (3D)-printed plastic structure that is sewn on the glove allows an optimal force transfer from the remotely located motor to the wrist articulation and to preserve a high level of comfort for the user during assistance. The device is shown to reduce fatigue and the muscular effort required for holding and lifting loads in healthy subjects for weights up to 3 kg.},
  archive      = {J_FROBT},
  author       = {Chiaradia, Domenico and Tiseni, Luca and Xiloyannis, Michele and Solazzi, Massimiliano and Masia, Lorenzo and Frisoli, Antonio},
  doi          = {10.3389/frobt.2020.595862},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {595862},
  shortjournal = {Front. Robot. AI},
  title        = {An assistive soft wrist exosuit for flexion movements with an ergonomic reinforced glove},
  volume       = {7},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Suitability of the openly accessible 3D printed prosthetic
hands for war-wounded children. <em>FROBT</em>, <em>7</em>, 594196. (<a
href="https://doi.org/10.3389/frobt.2020.594196">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The field of rehabilitation and assistive devices is being disrupted by innovations in desktop 3D printers and open-source designs. For upper limb prosthetics, those technologies have demonstrated a strong potential to aid those with missing hands. However, there are basic interfacing issues that need to be addressed for long term usage. The functionality, durability, and the price need to be considered especially for those in difficult living conditions. We evaluated the most popular designs of body-powered, 3D printed prosthetic hands. We selected a representative sample and evaluated its suitability for its grasping postures, durability, and cost. The prosthetic hand can perform three grasping postures out of the 33 grasps that a human hand can do. This corresponds to grasping objects similar to a coin, a golf ball, and a credit card. Results showed that the material used in the hand and the cables can withstand a 22 N normal grasping force, which is acceptable based on standards for accessibility design. The cost model showed that a 3D printed hand could be produced for as low as $19. For the benefit of children with congenital missing limbs and for the war-wounded, the results can serve as a baseline study to advance the development of prosthetic hands that are functional yet low-cost.},
  archive      = {J_FROBT},
  author       = {Cabibihan, John-John and Alkhatib, Farah and Mudassir, Mohammed and Lambert, Laurent A. and Al-Kwifi, Osama S. and Diab, Khaled and Mahdi, Elsadig},
  doi          = {10.3389/frobt.2020.594196},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {594196},
  shortjournal = {Front. Robot. AI},
  title        = {Suitability of the openly accessible 3D printed prosthetic hands for war-wounded children},
  volume       = {7},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Development and testing of psychological conflict resolution
strategies for assertive robots to resolve human–robot goal conflict.
<em>FROBT</em>, <em>7</em>, 591448. (<a
href="https://doi.org/10.3389/frobt.2020.591448">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As service robots become increasingly autonomous and follow their own task-related goals, human-robot conflicts seem inevitable, especially in shared spaces. Goal conflicts can arise from simple trajectory planning to complex task prioritization. For successful human-robot goal-conflict resolution, humans and robots need to negotiate their goals and priorities. For this, the robot might be equipped with effective conflict resolution strategies to be assertive and effective but similarly accepted by the user. In this paper, conflict resolution strategies for service robots (public cleaning robot, home assistant robot) are developed by transferring psychological concepts (e.g., negotiation, cooperation) to HRI. Altogether, fifteen strategies were grouped by the expected affective outcome (positive, neutral, negative). In two online experiments, the acceptability of and compliance with these conflict resolution strategies were tested with humanoid and mechanic robots in two application contexts (public: n1 = 61; private: n2 = 93). To obtain a comparative value, the strategies were also applied by a human. As additional outcomes trust, fear, arousal, and valence, as well as perceived politeness of the agent were assessed. The positive/neutral strategies were found to be more acceptable and effective than negative strategies. Some negative strategies (i.e., threat, command) even led to reactance and fear. Some strategies were only positively evaluated and effective for certain agents (human or robot) or only acceptable in one of the two application contexts (i.e., approach, empathy). Influences on strategy acceptance and compliance in the public context could be found: acceptance was predicted by politeness and trust. Compliance was predicted by interpersonal power. Taken together, psychological conflict resolution strategies can be applied in HRI to enhance robot task effectiveness. If applied robot-specifically and context-sensitively they are accepted by the user. The contribution of this paper is twofold: conflict resolution strategies based on Human Factors and Social Psychology are introduced and empirically evaluated in two online studies for two application contexts. Influencing factors and requirements for the acceptance and effectiveness of robot assertiveness are discussed.},
  archive      = {J_FROBT},
  author       = {Babel, Franziska and Kraus, Johannes M. and Baumann, Martin},
  doi          = {10.3389/frobt.2020.591448},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {591448},
  shortjournal = {Front. Robot. AI},
  title        = {Development and testing of psychological conflict resolution strategies for assertive robots to resolve Human–Robot goal conflict},
  volume       = {7},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Exploring the applicability of robot-assisted UV
disinfection in radiology. <em>FROBT</em>, <em>7</em>, 590306. (<a
href="https://doi.org/10.3389/frobt.2020.590306">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The importance of infection control procedures in hospital radiology departments has become increasingly apparent in recent months as the impact of COVID-19 has spread across the world. Existing disinfectant procedures that rely on the manual application of chemical-based disinfectants are time consuming, resource intensive and prone to high degrees of human error. Alternative non-touch disinfection methods, such as Ultraviolet Germicidal Irradiation (UVGI), have the potential to overcome many of the limitations of existing approaches while significantly improving workflow and equipment utilization. The aim of this research was to investigate the germicidal effectiveness and the practical feasibility of using a robotic UVGI device for disinfecting surfaces in a radiology setting. We present the design of a robotic UVGI platform that can be deployed alongside human workers and can operate autonomously within cramped rooms, thereby addressing two important requirements necessary for integrating the technology within radiology settings. In one hospital, we conducted experiments in a CT and X-ray room. In a second hospital, we investigated the germicidal performance of the robot when deployed to disinfect a CT room in &amp;lt;15 minutes, a period which is estimated to be 2–4 times faster than current practice for disinfecting rooms after infectious (or potentially infectious) patients. Findings from both test sites show that UVGI successfully inactivated all of measurable microbial load on 22 out of 24 surfaces. On the remaining two surfaces, UVGI reduced the microbial load by 84 and 95%, respectively. The study also exposes some of the challenges of manually disinfecting radiology suites, revealing high concentrations of microbial load in hard-to-reach places. Our findings provide compelling evidence that UVGI can effectively inactivate microbes on commonly touched surfaces in radiology suites, even if they were only exposed to relatively short bursts of irradiation. Despite the short irradiation period, we demonstrated the ability to inactivate microbes with more complex cell structures and requiring higher UV inactivation energies than SARS-CoV-2, thus indicating high likelihood of effectiveness against coronavirus.},
  archive      = {J_FROBT},
  author       = {McGinn, Conor and Scott, Robert and Donnelly, Niamh and Roberts, Kim L. and Bogue, Marina and Kiernan, Christine and Beckett, Michael},
  doi          = {10.3389/frobt.2020.590306},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {590306},
  shortjournal = {Front. Robot. AI},
  title        = {Exploring the applicability of robot-assisted UV disinfection in radiology},
  volume       = {7},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Deep learning-based haptic guidance for surgical skills
transfer. <em>FROBT</em>, <em>7</em>, 586707. (<a
href="https://doi.org/10.3389/frobt.2020.586707">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Having a trusted and useful system that helps to diminish the risk of medical errors and facilitate the improvement of quality in the medical education is indispensable. Thousands of surgical errors are occurred annually with high adverse event rate, despite inordinate number of devised patients safety initiatives. Inadvertently or otherwise, surgeons play a critical role in the aforementioned errors. Training surgeons is one of the most crucial and delicate parts of medical education and needs more attention due to its practical intrinsic. In contrast to engineering, dealing with mortal alive creatures provides a minuscule chance of trial and error for trainees. Training in operative rooms, on the other hand, is extremely expensive in terms of not only equipment but also hiring professional trainers. In addition, the COVID-19 pandemic has caused to establish initiatives such as social distancing in order to mitigate the rate of outbreak. This leads surgeons to postpone some non-urgent surgeries or operate with restrictions in terms of safety. Subsequently, educational systems are affected by the limitations due to the pandemic. Skill transfer systems in cooperation with a virtual training environment is thought as a solution to address aforesaid issues. This enables not only novice surgeons to enrich their proficiency but also helps expert surgeons to be supervised during the operation. This paper focuses on devising a solution based on deep leaning algorithms to model the behavior of experts during the operation. In other words, the proposed solution is a skill transfer method that learns professional demonstrations using different effective factors from the body of experts. The trained model then provides a real-time haptic guidance signal for either instructing trainees or supervising expert surgeons. A simulation is utilized to emulate an operating room for femur drilling surgery, which is a common invasive treatment for osteoporosis. This helps us with both collecting the essential data and assessing the obtained models. Experimental results show that the proposed method is capable of emitting guidance force haptic signal with an acceptable error rate.},
  archive      = {J_FROBT},
  author       = {Fekri, Pedram and Dargahi, Javad and Zadeh, Mehrdad},
  doi          = {10.3389/frobt.2020.586707},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {586707},
  shortjournal = {Front. Robot. AI},
  title        = {Deep learning-based haptic guidance for surgical skills transfer},
  volume       = {7},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Model-based control and external load estimation of an
extensible soft robotic arm. <em>FROBT</em>, <em>7</em>, 586490. (<a
href="https://doi.org/10.3389/frobt.2020.586490">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Soft robotics has widely been known for its compliant characteristics when dealing with contraction or manipulation. These soft behavior patterns provide safe and adaptive interactions, greatly relieving the complexity of active control policies. However, another promising aspect of soft robotics, which is to achieve useful information from compliant behavior, is not widely studied. This characteristic could help to reduce the dependence of sensors, gain a better knowledge of the environment, and enrich high-level control strategies. In this paper, we have developed a state-change model of a soft robotic arm, and we demonstrate how compliant behavior could be used to estimate external load based on this model. Moreover, we propose an improved version of the estimation procedure, further reducing the estimation error by compensating the influcence of pressure deadzone. Experiments of both methods are compared, displaying the potential effectiveness of applying these methods.},
  archive      = {J_FROBT},
  author       = {Chen, Xiaojiao and Duanmu, Dehao and Wang, Zheng},
  doi          = {10.3389/frobt.2020.586490},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {586490},
  shortjournal = {Front. Robot. AI},
  title        = {Model-based control and external load estimation of an extensible soft robotic arm},
  volume       = {7},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Monitoring re-growth of invasive plants using an autonomous
surface vessel. <em>FROBT</em>, <em>7</em>, 583416. (<a
href="https://doi.org/10.3389/frobt.2020.583416">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Invasive aquatic plant species, and in particular Eurasian Water-Milfoil (EWM), pose a major threat to domestic flora and fauna and can in turn negatively impact local economies. Numerous strategies have been developed to harvest and remove these plant species from the environment. However it is still an open question as to which method is best suited to removing a particular invasive species and the impact of different lake conditions on the choice. One problem common to all harvesting methods is the need to assess the location and degree of infestation on an ongoing manner. This is a difficult and error prone problem given that the plants grow underwater and significant infestation at depth may not be visible at the surface. Here we detail efforts to monitor EWM infestation and evaluate harvesting methods using an autonomous surface vessel (ASV). This novel ASV is based around a mono-hull design with two outriggers. Powered by a differential pair of underwater thrusters, the ASV is outfitted with RTK GPS for position estimation and a set of submerged environmental sensors that are used to capture imagery and depth information including the presence of material suspended in the water column. The ASV is capable of both autonomous and tele-operation.},
  archive      = {J_FROBT},
  author       = {Codd-Downey, Robert and Jenkin, Michael and Dey, Bir Bikram and Zacher, James and Blainey, Eva and Andrews, Peter},
  doi          = {10.3389/frobt.2020.583416},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {583416},
  shortjournal = {Front. Robot. AI},
  title        = {Monitoring re-growth of invasive plants using an autonomous surface vessel},
  volume       = {7},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Improving resource management for unattended observation of
the marginal ice zone using autonomous underwater gliders.
<em>FROBT</em>, <em>7</em>, 579256. (<a
href="https://doi.org/10.3389/frobt.2020.579256">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present control policies for use with a modified autonomous underwater glider that are intended to enable remote launch/recovery and long-range unattended survey of the Arctic&#39;s marginal ice zone (MIZ). This region of the Arctic is poorly characterized but critical to the dynamics of ice advance and retreat. Due to the high cost of operating support vessels in the Arctic, the proposed glider architecture minimizes external infrastructure requirements for navigation and mission updates to brief and infrequent satellite updates on the order of once per day. This is possible through intelligent power management in combination with hybrid propulsion, adaptive velocity control, and dynamic depth band selection based on real-time environmental state estimation. We examine the energy savings, range improvements, decreased communication requirements, and temporal consistency that can be attained with the proposed glider architecture and control policies based on preliminary field data, and we discuss a future MIZ survey mission concept in the Arctic. Although the sensing and control policies presented here focus on under ice missions with an unattended underwater glider, they are hardware independent and are transferable to other robotic vehicle classes, including in aerial and space domains.},
  archive      = {J_FROBT},
  author       = {Duguid, Zachary and Camilli, Richard},
  doi          = {10.3389/frobt.2020.579256},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {579256},
  shortjournal = {Front. Robot. AI},
  title        = {Improving resource management for unattended observation of the marginal ice zone using autonomous underwater gliders},
  volume       = {7},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Risk of injury in moral dilemmas with autonomous vehicles.
<em>FROBT</em>, <em>7</em>, 572529. (<a
href="https://doi.org/10.3389/frobt.2020.572529">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As autonomous machines, such as automated vehicles (AVs) and robots, become pervasive in society, they will inevitably face moral dilemmas where they must make decisions that risk injuring humans. However, prior research has framed these dilemmas in starkly simple terms, i.e., framing decisions as life and death and neglecting the influence of risk of injury to the involved parties on the outcome. Here, we focus on this gap and present experimental work that systematically studies the effect of risk of injury on the decisions people make in these dilemmas. In four experiments, participants were asked to program their AVs to either save five pedestrians, which we refer to as the utilitarian choice, or save the driver, which we refer to as the nonutilitarian choice. The results indicate that most participants made the utilitarian choice but that this choice was moderated in important ways by perceived risk to the driver and risk to the pedestrians. As a second contribution, we demonstrate the value of formulating AV moral dilemmas in a game-theoretic framework that considers the possible influence of others’ behavior. In the fourth experiment, we show that participants were more (less) likely to make the utilitarian choice, the more utilitarian (nonutilitarian) other drivers behaved; furthermore, unlike the game-theoretic prediction that decision-makers inevitably converge to nonutilitarianism, we found significant evidence of utilitarianism. We discuss theoretical implications for our understanding of human decision-making in moral dilemmas and practical guidelines for the design of autonomous machines that solve these dilemmas while, at the same time, being likely to be adopted in practice.},
  archive      = {J_FROBT},
  author       = {de Melo, Celso M. and Marsella, Stacy and Gratch, Jonathan},
  doi          = {10.3389/frobt.2020.572529},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {572529},
  shortjournal = {Front. Robot. AI},
  title        = {Risk of injury in moral dilemmas with autonomous vehicles},
  volume       = {7},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Deep reinforcement learning controller for 3D path following
and collision avoidance by autonomous underwater vehicles.
<em>FROBT</em>, <em>7</em>, 566037. (<a
href="https://doi.org/10.3389/frobt.2020.566037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Control theory provides engineers with a multitude of tools to design controllers that manipulate the closed-loop behavior and stability of dynamical systems. These methods rely heavily on insights into the mathematical model governing the physical system. However, in complex systems, such as autonomous underwater vehicles performing the dual objective of path following and collision avoidance, decision making becomes nontrivial. We propose a solution using state-of-the-art Deep Reinforcement Learning (DRL) techniques to develop autonomous agents capable of achieving this hybrid objective without having a priori knowledge about the goal or the environment. Our results demonstrate the viability of DRL in path following and avoiding collisions towards achieving human-level decision making in autonomous vehicle systems within extreme obstacle configurations.},
  archive      = {J_FROBT},
  author       = {Havenstrøm, Simen Theie and Rasheed, Adil and San, Omer},
  doi          = {10.3389/frobt.2020.566037},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {566037},
  shortjournal = {Front. Robot. AI},
  title        = {Deep reinforcement learning controller for 3D path following and collision avoidance by autonomous underwater vehicles},
  volume       = {7},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Acceptance of industrial collaborative robots by people with
disabilities in sheltered workshops. <em>FROBT</em>, <em>7</em>, 541741.
(<a href="https://doi.org/10.3389/frobt.2020.541741">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The integration of people with disabilities into the working world is an important, yet challenging field of research. While different inclusion efforts exist, people with disabilities are still under-represented in the open labor market. This paper investigates the approach of using a collaborative robot arm to support people with disabilities with their reintegration into the workplace. However, there is currently little literature about the acceptance of an industrial robot by people with disabilities and in cases where a robot leads to stress, fear, or any other form of discomfort, this approach is not feasible. For this reason, a first user study was performed in a sheltered workshop to investigate the acceptance of a robot arm by workers with disabilities. As a first step in this underdeveloped field, two main aspects were covered. Firstly, the reaction and familiarization to the robot arm within a study situation was closely examined in order to separate any effects that were not caused by the moving robot. Secondly, the reaction toward the robot arm during collaboration was investigated. In doing so, five different distances between the robot arm and the participants were considered to make collaboration in the workplace as pleasant as possible. The results revealed that it took the participants about 20 min to get used to the situation, while the robot was immediately accepted very well and did not cause fear or discomfort at any time. Surprisingly, in some cases, short distances were accepted even better than the larger distances. For these reasons, the presented approach showed to promise for future investigations.},
  archive      = {J_FROBT},
  author       = {Drolshagen, Sandra and Pfingsthorn, Max and Gliesche, Pascal and Hein, Andreas},
  doi          = {10.3389/frobt.2020.541741},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {541741},
  shortjournal = {Front. Robot. AI},
  title        = {Acceptance of industrial collaborative robots by people with disabilities in sheltered workshops},
  volume       = {7},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Personogenesis through imitating human behavior in a
humanoid robot “Alter3.” <em>FROBT</em>, <em>7</em>, 532375. (<a
href="https://doi.org/10.3389/frobt.2020.532375">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, we report the investigations conducted on the mimetic behavior of a new humanoid robot called Alter3. Alter3 autonomously imitates the motions of a person in front of it and stores the motion sequences in its memory. Alter3 also uses a self-simulator to simulate its own motions before executing them and generates a self-image. If the visual perception (of a person&#39;s motion being imitated) and the imitating self-image differ significantly, Alter3 retrieves a motion sequence closer to the target motion from its memory and executes it. We investigate how this mimetic behavior develops interacting with human, by analyzing memory dynamics and information flow between Alter3 and a interacting person. One important observation from this study is that when Alter3 fails to imitate a person&#39;s motion, the person tend to imitate Alter3 instead. This tendency is quantified by the alternation of the direction of information flow. This spontaneous role-switching behavior between a human and Alter3 is a way to initiate personality formation (i.e., personogenesis) in Alter3.},
  archive      = {J_FROBT},
  author       = {Masumori, Atsushi and Maruyama, Norihiro and Ikegami, Takashi},
  doi          = {10.3389/frobt.2020.532375},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {532375},
  shortjournal = {Front. Robot. AI},
  title        = {Personogenesis through imitating human behavior in a humanoid robot “Alter3”},
  volume       = {7},
  year         = {2021},
}
</textarea>
</details></li>
</ul>

</body>
</html>
