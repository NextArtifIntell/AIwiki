<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>FRAI_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="frai---205">FRAI - 205</h2>
<ul>
<li><details>
<summary>
(2021). Automatic speech recognition in noise for parkinson’s
disease: A pilot study. <em>FRAI</em>, <em>4</em>, 809321. (<a
href="https://doi.org/10.3389/frai.2021.809321">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The sophistication of artificial intelligence (AI) technologies has significantly advanced in the past decade. However, the observed unpredictability and variability of AI behavior in noisy signals is still underexplored and represents a challenge when trying to generalize AI behavior to real-life environments, especially for people with a speech disorder, who already experience reduced speech intelligibility. In the context of developing assistive technology for people with Parkinson&#39;s disease using automatic speech recognition (ASR), this pilot study reports on the performance of Google Cloud speech-to-text technology with dysarthric and healthy speech in the presence of multi-talker babble noise at different intensity levels. Despite sensitivities and shortcomings, it is possible to control the performance of these systems with current tools in order to measure speech intelligibility in real-life conditions.},
  archive      = {J_FRAI},
  author       = {Goudarzi, Alireza and Moya-Galé, Gemma},
  doi          = {10.3389/frai.2021.809321},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {12},
  pages        = {809321},
  shortjournal = {Front. Artif. Intell.},
  title        = {Automatic speech recognition in noise for parkinson&#39;s disease: A pilot study},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Accelerating hyperparameter tuning in machine learning for
alzheimer’s disease with high performance computing. <em>FRAI</em>,
<em>4</em>, 798962. (<a
href="https://doi.org/10.3389/frai.2021.798962">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Driven by massive datasets that comprise biomarkers from both blood and magnetic resonance imaging (MRI), the need for advanced learning algorithms and accelerator architectures, such as GPUs and FPGAs has increased. Machine learning (ML) methods have delivered remarkable prediction for the early diagnosis of Alzheimer’s disease (AD). Although ML has improved accuracy of AD prediction, the requirement for the complexity of algorithms in ML increases, for example, hyperparameters tuning, which in turn, increases its computational complexity. Thus, accelerating high performance ML for AD is an important research challenge facing these fields. This work reports a multicore high performance support vector machine (SVM) hyperparameter tuning workflow with 100 times repeated 5-fold cross-validation for speeding up ML for AD. For demonstration and evaluation purposes, the high performance hyperparameter tuning model was applied to public MRI data for AD and included demographic factors such as age, sex and education. Results showed that computational efficiency increased by 96%, which helped to shed light on future diagnostic AD biomarker applications. The high performance hyperparameter tuning model can also be applied to other ML algorithms such as random forest, logistic regression, xgboost, etc.},
  archive      = {J_FRAI},
  author       = {Zhang, Fan and Petersen, Melissa and Johnson, Leigh and Hall, James and O’Bryant, Sid E.},
  doi          = {10.3389/frai.2021.798962},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {12},
  pages        = {798962},
  shortjournal = {Front. Artif. Intell.},
  title        = {Accelerating hyperparameter tuning in machine learning for alzheimer’s disease with high performance computing},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Towards effective patient simulators. <em>FRAI</em>,
<em>4</em>, 798659. (<a
href="https://doi.org/10.3389/frai.2021.798659">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we give an overview of the field of patient simulators and provide qualitative and quantitative comparison of different modeling and simulation approaches. Simulators can be used to train human caregivers but also to develop and optimize algorithms for clinical decision support applications and test and validate interventions. In this paper we introduce three novel patient simulators with different levels of representational accuracy: HeartPole, a simplistic transparent rule-based system, GraphSim, a graph-based model trained on intensive care data, and Auto-ALS—an adjusted version of an educational software package used for training junior healthcare professionals. We provide a qualitative and quantitative comparison of the previously existing as well as proposed simulators.},
  archive      = {J_FRAI},
  author       = {Liventsev, Vadim and Härmä, Aki and Petković, Milan},
  doi          = {10.3389/frai.2021.798659},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {12},
  pages        = {798659},
  shortjournal = {Front. Artif. Intell.},
  title        = {Towards effective patient simulators},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Audience-dependent explanations for AI-based risk management
tools: A survey. <em>FRAI</em>, <em>4</em>, 794996. (<a
href="https://doi.org/10.3389/frai.2021.794996">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial Intelligence (AI) is one of the most sought-after innovations in the financial industry. However, with its growing popularity, there also is the call for AI-based models to be understandable and transparent. However, understandably explaining the inner mechanism of the algorithms and their interpretation is entirely audience-dependent. The established literature fails to match the increasing number of explainable AI (XAI) methods with the different stakeholders’ explainability needs. This study addresses this gap by exploring how various stakeholders within the Swiss financial industry view explainability in their respective contexts. Based on a series of interviews with practitioners within the financial industry, we provide an in-depth review and discussion of their view on the potential and limitation of current XAI techniques needed to address the different requirements for explanations.},
  archive      = {J_FRAI},
  author       = {Hadji Misheva, Branka and Jaggi, David and Posth, Jan-Alexander and Gramespacher, Thomas and Osterrieder, Joerg},
  doi          = {10.3389/frai.2021.794996},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {12},
  pages        = {794996},
  shortjournal = {Front. Artif. Intell.},
  title        = {Audience-dependent explanations for AI-based risk management tools: A survey},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Physics-informed tensor-train ConvLSTM for volumetric
velocity forecasting of the loop current. <em>FRAI</em>, <em>4</em>,
780271. (<a href="https://doi.org/10.3389/frai.2021.780271">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {According to the National Academies, a week long forecast of velocity, vertical structure, and duration of the Loop Current (LC) and its eddies at a given location is a critical step toward understanding their effects on the gulf ecosystems as well as toward anticipating and mitigating the outcomes of anthropogenic and natural disasters in the Gulf of Mexico (GoM). However, creating such a forecast has remained a challenging problem since LC behavior is dominated by dynamic processes across multiple time and spatial scales not resolved at once by conventional numerical models. In this paper, building on the foundation of spatiotemporal predictive learning in video prediction, we develop a physics informed deep learning based prediction model called—Physics-informed Tensor-train ConvLSTM (PITT-ConvLSTM)—for forecasting 3D geo-spatiotemporal sequences. Specifically, we propose (1) a novel 4D higher-order recurrent neural network with empirical orthogonal function analysis to capture the hidden uncorrelated patterns of each hierarchy, (2) a convolutional tensor-train decomposition to capture higher-order space-time correlations, and (3) a mechanism that incorporates prior physics from domain experts by informing the learning in latent space. The advantage of our proposed approach is clear: constrained by the law of physics, the prediction model simultaneously learns good representations for frame dependencies (both short-term and long-term high-level dependency) and inter-hierarchical relations within each time frame. Experiments on geo-spatiotemporal data collected from the GoM demonstrate that the PITT-ConvLSTM model can successfully forecast the volumetric velocity of the LC and its eddies for a period greater than 1 week.},
  archive      = {J_FRAI},
  author       = {Huang, Yu and Tang, Yufei and Zhuang, Hanqi and VanZwieten, James and Cherubin, Laurent},
  doi          = {10.3389/frai.2021.780271},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {12},
  pages        = {780271},
  shortjournal = {Front. Artif. Intell.},
  title        = {Physics-informed tensor-train ConvLSTM for volumetric velocity forecasting of the loop current},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Benefits of adaptive learning transfer from typing-based
learning to speech-based learning. <em>FRAI</em>, <em>4</em>, 780131.
(<a href="https://doi.org/10.3389/frai.2021.780131">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Memorising vocabulary is an important aspect of formal foreign-language learning. Advances in cognitive psychology have led to the development of adaptive learning systems that make vocabulary learning more efficient. One way these computer-based systems optimize learning is by measuring learning performance in real time to create optimal repetition schedules for individual learners. While such adaptive learning systems have been successfully applied to word learning using keyboard-based input, they have thus far seen little application in word learning where spoken instead of typed input is used. Here we present a framework for speech-based word learning using an adaptive model that was developed for and tested with typing-based word learning. We show that typing- and speech-based learning result in similar behavioral patterns that can be used to reliably estimate individual memory processes. We extend earlier findings demonstrating that a response-time based adaptive learning approach outperforms an accuracy-based, Leitner flashcard approach in learning efficiency (demonstrated by higher average accuracy and lower response times after a learning session). In short, we show that adaptive learning benefits transfer from typing-based learning, to speech based learning. Our work provides a basis for the development of language learning applications that use real-time pronunciation assessment software to score the accuracy of the learner’s pronunciations. We discuss the implications for our approach for the development of educationally relevant, adaptive speech-based learning applications.},
  archive      = {J_FRAI},
  author       = {Wilschut, Thomas and Sense, Florian and van der Velde, Maarten and Fountas, Zafeirios and Maaß, Sarah C. and van Rijn, Hedderik},
  doi          = {10.3389/frai.2021.780131},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {12},
  pages        = {780131},
  shortjournal = {Front. Artif. Intell.},
  title        = {Benefits of adaptive learning transfer from typing-based learning to speech-based learning},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Visual features and their own optical flow. <em>FRAI</em>,
<em>4</em>, 768516. (<a
href="https://doi.org/10.3389/frai.2021.768516">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Symmetries, invariances and conservation equations have always been an invaluable guide in Science to model natural phenomena through simple yet effective relations. For instance, in computer vision, translation equivariance is typically a built-in property of neural architectures that are used to solve visual tasks; networks with computational layers implementing such a property are known as Convolutional Neural Networks (CNNs). This kind of mathematical symmetry, as well as many others that have been recently studied, are typically generated by some underlying group of transformations (translations in the case of CNNs, rotations, etc.) and are particularly suitable to process highly structured data such as molecules or chemical compounds which are known to possess those specific symmetries. When dealing with video streams, common built-in equivariances are able to handle only a small fraction of the broad spectrum of transformations encoded in the visual stimulus and, therefore, the corresponding neural architectures have to resort to a huge amount of supervision in order to achieve good generalization capabilities. In the paper we formulate a theory on the development of visual features that is based on the idea that movement itself provides trajectories on which to impose consistency. We introduce the principle of Material Point Invariance which states that each visual feature is invariant with respect to the associated optical flow, so that features and corresponding velocities are an indissoluble pair. Then, we discuss the interaction of features and velocities and show that certain motion invariance traits could be regarded as a generalization of the classical concept of affordance. These analyses of feature-velocity interactions and their invariance properties leads to a visual field theory which expresses the dynamical constraints of motion coherence and might lead to discover the joint evolution of the visual features along with the associated optical flows.},
  archive      = {J_FRAI},
  author       = {Betti, Alessandro and Boccignone, Giuseppe and Faggi, Lapo and Gori, Marco and Melacci, Stefano},
  doi          = {10.3389/frai.2021.768516},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {12},
  pages        = {768516},
  shortjournal = {Front. Artif. Intell.},
  title        = {Visual features and their own optical flow},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). What does a language-and-vision transformer see: The impact
of semantic information on visual representations. <em>FRAI</em>,
<em>4</em>, 767971. (<a
href="https://doi.org/10.3389/frai.2021.767971">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural networks have proven to be very successful in automatically capturing the composition of language and different structures across a range of multi-modal tasks. Thus, an important question to investigate is how neural networks learn and organise such structures. Numerous studies have examined the knowledge captured by language models (LSTMs, transformers) and vision architectures (CNNs, vision transformers) for respective uni-modal tasks. However, very few have explored what structures are acquired by multi-modal transformers where linguistic and visual features are combined. It is critical to understand the representations learned by each modality, their respective interplay, and the task’s effect on these representations in large-scale architectures. In this paper, we take a multi-modal transformer trained for image captioning and examine the structure of the self-attention patterns extracted from the visual stream. Our results indicate that the information about different relations between objects in the visual stream is hierarchical and varies from local to a global object-level understanding of the image. In particular, while visual representations in the first layers encode the knowledge of relations between semantically similar object detections, often constituting neighbouring objects, deeper layers expand their attention across more distant objects and learn global relations between them. We also show that globally attended objects in deeper layers can be linked with entities described in image descriptions, indicating a critical finding - the indirect effect of language on visual representations. In addition, we highlight how object-based input representations affect the structure of learned visual knowledge and guide the model towards more accurate image descriptions. A parallel question that we investigate is whether the insights from cognitive science echo the structure of representations that the current neural architecture learns. The proposed analysis of the inner workings of multi-modal transformers can be used to better understand and improve on such problems as pre-training of large-scale multi-modal architectures, multi-modal information fusion and probing of attention weights. In general, we contribute to the explainable multi-modal natural language processing and currently shallow understanding of how the input representations and the structure of the multi-modal transformer affect visual representations.},
  archive      = {J_FRAI},
  author       = {Ilinykh, Nikolai and Dobnik, Simon},
  doi          = {10.3389/frai.2021.767971},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {12},
  pages        = {767971},
  shortjournal = {Front. Artif. Intell.},
  title        = {What does a language-and-vision transformer see: The impact of semantic information on visual representations},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Self-organising map based framework for investigating
accounts suspected of money laundering. <em>FRAI</em>, <em>4</em>,
761925. (<a href="https://doi.org/10.3389/frai.2021.761925">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There has been an emerging interest by financial institutions to develop advanced systems that can help enhance their anti-money laundering (AML) programmes. In this study, we present a self-organising map (SOM) based approach to predict which bank accounts are possibly involved in money laundering cases, given their financial transaction histories. Our method takes advantage of the competitive and adaptive properties of SOM to represent the accounts in a lower-dimensional space. Subsequently, categorising the SOM and the accounts into money laundering risk levels and proposing investigative strategies enables us to measure the classification performance. Our results indicate that our framework is well capable of identifying suspicious accounts already investigated by our partner bank, using both proposed investigation strategies. We further validate our model by analysing the performance when modifying different parameters in our dataset.},
  archive      = {J_FRAI},
  author       = {Alshantti, Abdallah and Rasheed, Adil},
  doi          = {10.3389/frai.2021.761925},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {12},
  pages        = {761925},
  shortjournal = {Front. Artif. Intell.},
  title        = {Self-organising map based framework for investigating accounts suspected of money laundering},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Monitoring weeder robots and anticipating their functioning
by using advanced topological data analysis. <em>FRAI</em>, <em>4</em>,
761123. (<a href="https://doi.org/10.3389/frai.2021.761123">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The present paper aims at analyzing the topological content of the complex trajectories that weeder-autonomous robots follow in operation. We will prove that the topological descriptors of these trajectories are affected by the robot environment as well as by the robot state, with respect to maintenance operations. Most of existing methodologies enabling efficient diagnosis are based on the data analysis, and in particular on some statistical quantities derived from the data. The present work explores the use of an original approach that instead of analyzing quantities derived from the data, analyzes the “shape” of the data, that is, the time series topology based on the homology persistence. We will prove that this procedure is able to extract valuable patterns able to discriminate the trajectories that the robot follows depending on the particular patch in which it operates, as well as to differentiate the robot behavior before and after undergoing a maintenance operation. Even if it is a preliminary work, and it does not pretend to compare its performances with respect to other existing technologies, this work opens new perspectives in considering quite natural and simple descriptors based on the intrinsic information that data contains, with the aim of performing efficient diagnosis and prognosis.},
  archive      = {J_FRAI},
  author       = {Frahi , Tarek and Sancarlos , Abel and Galle , Mathieu and Beaulieu, Xavier and Chambard, Anne and Falco, Antonio and Cueto, Elias and Chinesta, Francisco},
  doi          = {10.3389/frai.2021.761123},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {12},
  pages        = {761123},
  shortjournal = {Front. Artif. Intell.},
  title        = {Monitoring weeder robots and anticipating their functioning by using advanced topological data analysis},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Persuasive apps for sustainable waste management: A
comparative systematic evaluation of behavior change strategies and
state-of-the-art. <em>FRAI</em>, <em>4</em>, 748454. (<a
href="https://doi.org/10.3389/frai.2021.748454">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the proliferation of ubiquitous computing and mobile technologies, mobile apps are tailored to support users to perform target behaviors in various domains, including a sustainable future. This article provides a systematic evaluation of mobile apps for sustainable waste management to deconstruct and compare the persuasive strategies employed and their implementations. Specifically, it targeted apps that support various sustainable waste management activities such as personal tracking, recycling, conference management, data collection, food waste management, do-it-yourself (DIY) projects, games, etc. The authors who are persuasive technology researchers retrieved a total of 244 apps from App Store and Google Play, out of which 148 apps were evaluated. Two researchers independently analyzed and coded the apps and a third researcher was involved to resolve any disagreement. They coded the apps based on the persuasive strategies of the persuasive system design framework. Overall, the findings uncover that out of the 148 sustainable waste management apps evaluated, primary task support was the most employed category by 89% (n = 131) apps, followed by system credibility support implemented by 76% (n = 112) apps. The dialogue support was implemented by 71% (n = 105) apps and social support was the least utilized strategy by 34% (n = 51) apps. Specifically, Reduction (n = 97), personalization (n = 90), real-world feel (n = 83), surface credibility (n = 83), reminder (n = 73), and self-monitoring (n = 50) were the most commonly employed persuasive strategies. The findings established that there is a significant association between the number of persuasive strategies employed and the apps’ effectiveness as indicated by user ratings of the apps. How the apps are implemented differs depending on the kind of sustainable waste management activities it was developed for. Based on the findings, this paper offers design implications for personalizing sustainable waste management apps to improve their persuasiveness and effectiveness.},
  archive      = {J_FRAI},
  author       = {Nkwo, Makuochi and Suruliraj, Banuchitra and Orji, Rita},
  doi          = {10.3389/frai.2021.748454},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {12},
  pages        = {748454},
  shortjournal = {Front. Artif. Intell.},
  title        = {Persuasive apps for sustainable waste management: A comparative systematic evaluation of behavior change strategies and state-of-the-art},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Predictive modelling of susceptibility to substance abuse,
mortality and drug-drug interactions in opioid patients. <em>FRAI</em>,
<em>4</em>, 742723. (<a
href="https://doi.org/10.3389/frai.2021.742723">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Objective: Opioids are a class of drugs that are known for their use as pain relievers. They bind to opioid receptors on nerve cells in the brain and the nervous system to mitigate pain. Addiction is one of the chronic and primary adverse events of prolonged usage of opioids. They may also cause psychological disorders, muscle pain, depression, anxiety attacks etc. In this study, we present a collection of predictive models to identify patients at risk of opioid abuse and mortality by using their prescription histories. Also, we discover particularly threatening drug-drug interactions in the context of opioid usage.Methods and Materials: Using a publicly available dataset from MIMIC-III, two models were trained, Logistic Regression with L2 regularization (baseline) and Extreme Gradient Boosting (enhanced model), to classify the patients of interest into two categories based on their susceptibility to opioid abuse. We’ve also used K-Means clustering, an unsupervised algorithm, to explore drug-drug interactions that might be of concern.Results: The baseline model for classifying patients susceptible to opioid abuse has an F1 score of 76.64% (accuracy 77.16%) while the enhanced model has an F1 score of 94.45% (accuracy 94.35%). These models can be used as a preliminary step towards inferring the causal effect of opioid usage and can help monitor the prescription practices to minimize the opioid abuse.Discussion and Conclusion: Results suggest that the enhanced model provides a promising approach in preemptive identification of patients at risk for opioid abuse. By discovering and correlating the patterns contributing to opioid overdose or abuse among a variety of patients, machine learning models can be used as an efficient tool to help uncover the existing gaps and/or fraudulent practices in prescription writing. To quote an example of one such incidental finding, our study discovered that insulin might possibly be interacting with opioids in an unfavourable way leading to complications in diabetic patients. This indicates that diabetic patients under long term opioid usage might need to take increased amounts of insulin to make it more effective. This observation backs up prior research studies done on a similar aspect. To increase the translational value of our work, the predictive models and the associated software code are made available under the MIT License.},
  archive      = {J_FRAI},
  author       = {Vunikili, Ramya and Glicksberg, Benjamin S. and Johnson, Kipp W. and Dudley, Joel T. and Subramanian, Lakshminarayanan and Shameer, Khader},
  doi          = {10.3389/frai.2021.742723},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {12},
  pages        = {742723},
  shortjournal = {Front. Artif. Intell.},
  title        = {Predictive modelling of susceptibility to substance abuse, mortality and drug-drug interactions in opioid patients},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Application of laser-induced breakdown spectroscopy coupled
with spectral matrix and convolutional neural network for identifying
geographical origins of gentiana rigescens franch. <em>FRAI</em>,
<em>4</em>, 735533. (<a
href="https://doi.org/10.3389/frai.2021.735533">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate geographical origin identification is of great significance to ensure the quality of traditional Chinese medicine (TCM). Laser-induced breakdown spectroscopy (LIBS) was applied to achieve the fast geographical origin identification of wild Gentiana rigescens Franch (G. rigescens Franch). However, LIBS spectra with too many variables could increase the training time of models and reduce the discrimination accuracy. In order to solve the problems, we proposed two methods. One was reducing the number of variables through two consecutive variable selections. The other was transforming the spectrum into spectral matrix by spectrum segmentation and recombination. Combined with convolutional neural network (CNN), both methods could improve the accuracy of discrimination. For the underground parts of G. rigescens Franch, the optimal accuracy in the prediction set for the two methods was 92.19 and 94.01%, respectively. For the aerial parts, the two corresponding accuracies were the same with the value of 94.01%. Saliency map was used to explain the rationality of discriminant analysis by CNN combined with spectral matrix. The first method could provide some support for LIBS portable instrument development. The second method could offer some reference for the discriminant analysis of LIBS spectra with too many variables by the end-to-end learning of CNN. The present results demonstrated that LIBS combined with CNN was an effective tool to quickly identify the geographical origin of G. rigescens Franch.},
  archive      = {J_FRAI},
  author       = {Li, Xiaolong and Kong, Wenwen and Liu, Xiaoli and Zhang, Xi and Wang, Wei and Chen, Rongqin and Sun, Yongqi and Liu, Fei},
  doi          = {10.3389/frai.2021.735533},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {12},
  pages        = {735533},
  shortjournal = {Front. Artif. Intell.},
  title        = {Application of laser-induced breakdown spectroscopy coupled with spectral matrix and convolutional neural network for identifying geographical origins of gentiana rigescens franch},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Acronyms and opportunities for improving deep nets.
<em>FRAI</em>, <em>4</em>, 732381. (<a
href="https://doi.org/10.3389/frai.2021.732381">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, several studies have reported promising results with BERT-like methods on acronym tasks. In this study, we find an older rule-based program, Ab3P, not only performs better, but error analysis suggests why. There is a well-known spelling convention in acronyms where each letter in the short form (SF) refers to “salient” letters in the long form (LF). The error analysis uses decision trees and logistic regression to show that there is an opportunity for many pre-trained models (BERT, T5, BioBert, BART, ERNIE) to take advantage of this spelling convention.},
  archive      = {J_FRAI},
  author       = {Church, Kenneth and Liu, Boxiang},
  doi          = {10.3389/frai.2021.732381},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {12},
  pages        = {732381},
  shortjournal = {Front. Artif. Intell.},
  title        = {Acronyms and opportunities for improving deep nets},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). BERT-based natural language processing of drug labeling
documents: A case study for classifying drug-induced liver injury risk.
<em>FRAI</em>, <em>4</em>, 729834. (<a
href="https://doi.org/10.3389/frai.2021.729834">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Background &amp;amp; Aims: The United States Food and Drug Administration (FDA) regulates a broad range of consumer products, which account for about 25% of the United States market. The FDA regulatory activities often involve producing and reading of a large number of documents, which is time consuming and labor intensive. To support regulatory science at FDA, we evaluated artificial intelligence (AI)-based natural language processing (NLP) of regulatory documents for text classification and compared deep learning-based models with a conventional keywords-based model.Methods: FDA drug labeling documents were used as a representative regulatory data source to classify drug-induced liver injury (DILI) risk by employing the state-of-the-art language model BERT. The resulting NLP-DILI classification model was statistically validated with both internal and external validation procedures and applied to the labeling data from the European Medicines Agency (EMA) for cross-agency application.Results: The NLP-DILI model developed using FDA labeling documents and evaluated by cross-validations in this study showed remarkable performance in DILI classification with a recall of 1 and a precision of 0.78. When cross-agency data were used to validate the model, the performance remained comparable, demonstrating that the model was portable across agencies. Results also suggested that the model was able to capture the semantic meanings of sentences in drug labeling.Conclusion: Deep learning-based NLP models performed well in DILI classification of drug labeling documents and learned the meanings of complex text in drug labeling. This proof-of-concept work demonstrated that using AI technologies to assist regulatory activities is a promising approach to modernize and advance regulatory science.},
  archive      = {J_FRAI},
  author       = {Wu, Yue and Liu, Zhichao and Wu, Leihong and Chen, Minjun and Tong, Weida},
  doi          = {10.3389/frai.2021.729834},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {12},
  pages        = {729834},
  shortjournal = {Front. Artif. Intell.},
  title        = {BERT-based natural language processing of drug labeling documents: A case study for classifying drug-induced liver injury risk},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). MagNet: Detecting digital presentation attacks on face
recognition. <em>FRAI</em>, <em>4</em>, 643424. (<a
href="https://doi.org/10.3389/frai.2021.643424">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Presentation attacks on face recognition systems are classified into two categories: physical and digital. While much research has focused on physical attacks such as photo, replay, and mask attacks, digital attacks such as morphing have received limited attention. With the advancements in deep learning and computer vision algorithms, several easy-to-use applications are available where with few taps/clicks, an image can be easily and seamlessly altered. Moreover, generation of synthetic images or modifying images/videos (e.g. creating deepfakes) is relatively easy and highly effective due to the tremendous improvement in generative machine learning models. Many of these techniques can be used to attack the face recognition systems. To address this potential security risk, in this research, we present a novel algorithm for digital presentation attack detection, termed as MagNet, using a “Weighted Local Magnitude Pattern” (WLMP) feature descriptor. We also present a database, termed as IDAgender, which consists of three different subsets of swapping/morphing and neural face transformation. In contrast to existing research, which utilizes sophisticated machine learning networks for attack generation, the databases in this research are prepared using social media platforms that are readily available to everyone with and without any malicious intent. Experiments on the proposed database, FaceForensic database, GAN generated images, and real-world images/videos show the stimulating performance of the proposed algorithm. Through the extensive experiments, it is observed that the proposed algorithm not only yields lower error rates, but also provides computational efficiency.},
  archive      = {J_FRAI},
  author       = {Agarwal, Akshay and Singh, Richa and Vatsa, Mayank and Noore, Afzel},
  doi          = {10.3389/frai.2021.643424},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {12},
  pages        = {643424},
  shortjournal = {Front. Artif. Intell.},
  title        = {MagNet: Detecting digital presentation attacks on face recognition},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Studying the evolution of neural activation patterns during
training of feed-forward ReLU networks. <em>FRAI</em>, <em>4</em>,
642374. (<a href="https://doi.org/10.3389/frai.2021.642374">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The ability of deep neural networks to form powerful emergent representations of complex statistical patterns in data is as remarkable as imperfectly understood. For deep ReLU networks, these are encoded in the mixed discrete–continuous structure of linear weight matrices and non-linear binary activations. Our article develops a new technique for instrumenting such networks to efficiently record activation statistics, such as information content (entropy) and similarity of patterns, in real-world training runs. We then study the evolution of activation patterns during training for networks of different architecture using different training and initialization strategies. As a result, we see characteristic- and general-related as well as architecture-related behavioral patterns: in particular, most architectures form bottom-up structure, with the exception of highly tuned state-of-the-art architectures and methods (PyramidNet and FixUp), where layers appear to converge more simultaneously. We also observe intermediate dips in entropy in conventional CNNs that are not visible in residual networks. A reference implementation is provided under a free license1.},
  archive      = {J_FRAI},
  author       = {Hartmann, David and Franzen, Daniel and Brodehl, Sebastian},
  doi          = {10.3389/frai.2021.642374},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {12},
  pages        = {642374},
  shortjournal = {Front. Artif. Intell.},
  title        = {Studying the evolution of neural activation patterns during training of feed-forward ReLU networks},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Editorial: Respecting human autonomy through human-centered
AI. <em>FRAI</em>, <em>4</em>, 807566. (<a
href="https://doi.org/10.3389/frai.2021.807566">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Väänänen, Kaisa and Sankaran, Supraja and Lopez, Marisela Gutierrez and Zhang, Chao},
  doi          = {10.3389/frai.2021.807566},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {11},
  pages        = {807566},
  shortjournal = {Front. Artif. Intell.},
  title        = {Editorial: Respecting human autonomy through human-centered AI},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The ReIMAGINE multimodal warehouse: Using artificial
intelligence for accurate risk stratification of prostate cancer.
<em>FRAI</em>, <em>4</em>, 769582. (<a
href="https://doi.org/10.3389/frai.2021.769582">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Introduction. Prostate cancer (PCa) is the most frequent cancer diagnosis in men worldwide. Our ability to identify those men whose cancer will decrease their lifespan and/or quality of life remains poor. The ReIMAGINE Consortium has been established to improve PCa diagnosis.Materials and methods. MRI will likely become the future cornerstone of the risk-stratification process for men at risk of early prostate cancer. We will, for the first time, be able to combine the underlying molecular changes in PCa with the state-of-the-art imaging. ReIMAGINE Screening invites men for MRI and PSA evaluation. ReIMAGINE Risk includes men at risk of prostate cancer based on MRI, and includes biomarker testing.Results. Baseline clinical information, genomics, blood, urine, fresh prostate tissue samples, digital pathology and radiomics data will be analysed. Data will be de-identified, stored with correlated mpMRI disease endotypes and linked with long term follow-up outcomes in an instance of the Philips Clinical Data Lake, consisting of cloud-based software. The ReIMAGINE platform includes application programming interfaces and a user interface that allows users to browse data, select cohorts, manage users and access rights, query data, and more. Connection to analytics tools such as Python allows statistical and stratification method pipelines to run profiling regression analyses. Discussion. The ReIMAGINE Multimodal Warehouse comprises a unique data source for PCa research, to improve risk stratification for PCa and inform clinical practice. The de-identified dataset characterized by clinical, imaging, genomics and digital pathology PCa patient phenotypes will be a valuable resource for the scientific and medical community.},
  archive      = {J_FRAI},
  author       = {Santaolalla, Aida and Hulsen, Tim and Davis, Jenson and Ahmed, Hashim U. and Moore, Caroline M. and Punwani, Shonit and Attard, Gert and McCartan, Neil and Emberton, Mark and Coolen, Anthony and Van Hemelrijck, Mieke},
  doi          = {10.3389/frai.2021.769582},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {11},
  pages        = {769582},
  shortjournal = {Front. Artif. Intell.},
  title        = {The ReIMAGINE multimodal warehouse: Using artificial intelligence for accurate risk stratification of prostate cancer},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Quantum prisoner’s dilemma and high frequency trading on the
quantum cloud. <em>FRAI</em>, <em>4</em>, 769392. (<a
href="https://doi.org/10.3389/frai.2021.769392">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High-frequency trading (HFT) offers an excellent use case and a potential killer application of the commercially available, first generation quasi-quantum computers. To this end, we offer here a simple game-theoretic model of HFT as the famous two player game, Prisoner’s Dilemma. We explore the implementation of HFT as an instance of Prisoner’s Dilemma on the (quasi) quantum cloud using the Eisert, Wilkens, and Lewenstein quantum mediated communication protocol, and how this implementation can not only increase transaction speed but also improve the lot of the players in HFT. Using cooperative game-theoretic reasoning, we also note that in the near future when the internet is properly quantum, players will be able to achieve Pareto-optimality in HFT as an instance of reinforced machine learning.},
  archive      = {J_FRAI},
  author       = {Khan, Faisal Shah and Bao, Ning},
  doi          = {10.3389/frai.2021.769392},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {11},
  pages        = {769392},
  shortjournal = {Front. Artif. Intell.},
  title        = {Quantum prisoner’s dilemma and high frequency trading on the quantum cloud},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). CycleStyleGAN-based knowledge transfer for a machining
digital twin. <em>FRAI</em>, <em>4</em>, 767451. (<a
href="https://doi.org/10.3389/frai.2021.767451">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Digitalisation of manufacturing is a crucial component of the Industry 4.0 transformation. The digital twin is an important tool for enabling real-time digital access to precise information about physical systems and for supporting process optimisation via the translation of the associated big data into actionable insights. Although a variety of frameworks and conceptual models addressing the requirements and advantages of digital twins has been suggested in the academic literature, their implementation has received less attention. The work presented in this paper aims to make a proposition that considers the novel challenges introduced for data analysis in the presence of heterogeneous and dynamic cyber-physical systems in Industry 4.0. The proposed approach defines a digital twin simulation tool that captures the dynamics of a machining vibration signal from a source model and adapts them to a given target environment. This constitutes a flexible approach to knowledge extraction from the existing manufacturing simulation models, as information from both physics-based and data-driven solutions can be elicited this way. Therefore, an opportunity to reuse the costly established systems is made available to the manufacturing businesses, and the paper presents a process optimisation framework for such use case. The proposed approach is implemented as a domain adaptation algorithm based on the generative adversarial network model. The novel CycleStyleGAN architecture extends the CycleGAN model with a style-based signal encoding. The implemented model is validated in an experimental scenario that aims to replicate a real-world manufacturing knowledge transfer problem. The experiment shows that the transferred information enables the reduction of the required target domain data by one order of magnitude.},
  archive      = {J_FRAI},
  author       = {Zotov, Evgeny and Kadirkamanathan, Visakan},
  doi          = {10.3389/frai.2021.767451},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {11},
  pages        = {767451},
  shortjournal = {Front. Artif. Intell.},
  title        = {CycleStyleGAN-based knowledge transfer for a machining digital twin},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Fibrosis-net: A tailored deep convolutional neural network
design for prediction of pulmonary fibrosis progression from chest CT
images. <em>FRAI</em>, <em>4</em>, 764047. (<a
href="https://doi.org/10.3389/frai.2021.764047">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pulmonary fibrosis is a devastating chronic lung disease that causes irreparable lung tissue scarring and damage, resulting in progressive loss in lung capacity and has no known cure. A critical step in the treatment and management of pulmonary fibrosis is the assessment of lung function decline, with computed tomography (CT) imaging being a particularly effective method for determining the extent of lung damage caused by pulmonary fibrosis. Motivated by this, we introduce Fibrosis-Net, a deep convolutional neural network design tailored for the prediction of pulmonary fibrosis progression from chest CT images. More specifically, machine-driven design exploration was leveraged to determine a strong architectural design for CT lung analysis, upon which we build a customized network design tailored for predicting forced vital capacity (FVC) based on a patient’s CT scan, initial spirometry measurement, and clinical metadata. Finally, we leverage an explainability-driven performance validation strategy to study the decision-making behavior of Fibrosis-Net as to verify that predictions are based on relevant visual indicators in CT images. Experiments using a patient cohort from the OSIC Pulmonary Fibrosis Progression Challenge showed that the proposed Fibrosis-Net is able to achieve a significantly higher modified Laplace Log Likelihood score than the winning solutions on the challenge. Furthermore, explainability-driven performance validation demonstrated that the proposed Fibrosis-Net exhibits correct decision-making behavior by leveraging clinically-relevant visual indicators in CT images when making predictions on pulmonary fibrosis progress. Fibrosis-Net is able to achieve a significantly higher modified Laplace Log Likelihood score than the winning solutions on the OSIC Pulmonary Fibrosis Progression Challenge, and has been shown to exhibit correct decision-making behavior when making predictions. Fibrosis-Net is available to the general public in an open-source and open access manner as part of the OpenMedAI initiative. While Fibrosis-Net is not yet a production-ready clinical assessment solution, we hope that its release will encourage researchers, clinicians, and citizen data scientists alike to leverage and build upon it.},
  archive      = {J_FRAI},
  author       = {Wong, Alexander and Lu, Jack and Dorfman, Adam and McInnis, Paul and Famouri, Mahmoud and Manary, Daniel and Lee, James Ren Hou and Lynch, Michael},
  doi          = {10.3389/frai.2021.764047},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {11},
  pages        = {764047},
  shortjournal = {Front. Artif. Intell.},
  title        = {Fibrosis-net: A tailored deep convolutional neural network design for prediction of pulmonary fibrosis progression from chest CT images},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). DeepCarc: Deep learning-powered carcinogenicity prediction
using model-level representation. <em>FRAI</em>, <em>4</em>, 757780. (<a
href="https://doi.org/10.3389/frai.2021.757780">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Carcinogenicity testing plays an essential role in identifying carcinogens in environmental chemistry and drug development. However, it is a time-consuming and label-intensive process to evaluate the carcinogenic potency with conventional 2-years rodent animal studies. Thus, there is an urgent need for alternative approaches to providing reliable and robust assessments on carcinogenicity. In this study, we proposed a DeepCarc model to predict carcinogenicity for small molecules using deep learning-based model-level representations. The DeepCarc Model was developed using a data set of 692 compounds and evaluated on a test set containing 171 compounds in the National Center for Toxicological Research liver cancer database (NCTRlcdb). As a result, the proposed DeepCarc model yielded a Matthews correlation coefficient (MCC) of 0.432 for the test set, outperforming four advanced deep learning (DL) powered quantitative structure-activity relationship (QSAR) models with an average improvement rate of 37%. Furthermore, the DeepCarc model was also employed to screen the carcinogenicity potential of the compounds from both DrugBank and Tox21. Altogether, the proposed DeepCarc model could serve as an early detection tool (https://github.com/TingLi2016/DeepCarc) for carcinogenicity assessment.},
  archive      = {J_FRAI},
  author       = {Li, Ting and Tong, Weida and Roberts, Ruth and Liu, Zhichao and Thakkar, Shraddha},
  doi          = {10.3389/frai.2021.757780},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {11},
  pages        = {757780},
  shortjournal = {Front. Artif. Intell.},
  title        = {DeepCarc: Deep learning-powered carcinogenicity prediction using model-level representation},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). NC 4.0, a novel approach to nonconformities management:
Prioritizing events with risk management tools. <em>FRAI</em>,
<em>4</em>, 752520. (<a
href="https://doi.org/10.3389/frai.2021.752520">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quality 4.0, the correspondent quality practice fit to address the Industry 4.0 mindset, is expected to provide models and processes endorsed by continuous improvement and data-driven proofs, especially given the exponential growth in available data. The research consolidates the reality of big data availability (part of Quality 4.0) with a generic aspect of quality—managing nonconformities. Its purpose is to suggest a model to improve the initiation step for dealing with nonconformity by prioritizing these events. The new concept in the model suggested is incorporating the risk management method of prioritizing into the nonconformity’s management. These tools are designed to transform qualitative data into quantitative ones and enable easier decision-making, in this case, choosing which issue to deal with first. The research approach is developing and testing the suggested model as a pilot in a real production environment to establish its impact and define key guidelines for utilizing it in various processes and, in addition, to conduct a survey among quality experts from different organizations for reference. Two main outcomes were achieved during the research: The quality experts’ survey welcomed the model concept as a structured tool based on the solid risk management methodology. Implementing the model on actual production lines resulted in a significant reduction of NC financial impact as the events were solved as per their impact.},
  archive      = {J_FRAI},
  author       = {Ravoy, Dvir and Parmet, Yisrael},
  doi          = {10.3389/frai.2021.752520},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {11},
  pages        = {752520},
  shortjournal = {Front. Artif. Intell.},
  title        = {NC 4.0, a novel approach to nonconformities management: Prioritizing events with risk management tools},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Adaptive initialization method for k-means algorithm.
<em>FRAI</em>, <em>4</em>, 740817. (<a
href="https://doi.org/10.3389/frai.2021.740817">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The K-means algorithm is a widely used clustering algorithm that offers simplicity and efficiency. However, the traditional K-means algorithm uses a random method to determine the initial cluster centers, which make clustering results prone to local optima and then result in worse clustering performance. In this research, we propose an adaptive initialization method for the K-means algorithm (AIMK) which can adapt to the various characteristics in different datasets and obtain better clustering performance with stable results. For larger or higher-dimensional datasets, we even leverage random sampling in AIMK (name as AIMK-RS) to reduce the time complexity. 22 real-world datasets were applied for performance comparisons. The experimental results show AIMK and AIMK-RS outperform the current initialization methods and several well-known clustering algorithms. Specifically, AIMK-RS can significantly reduce the time complexity to O (n). Moreover, we exploit AIMK to initialize K-medoids and spectral clustering, and better performance is also explored. The above results demonstrate superior performance and good scalability by AIMK or AIMK-RS. In the future, we would like to apply AIMK to more partition-based clustering algorithms to solve real-life practical problems.},
  archive      = {J_FRAI},
  author       = {Yang, Jie and Wang, Yu-Kai and Yao, Xin and Lin, Chin-Teng},
  doi          = {10.3389/frai.2021.740817},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {11},
  pages        = {740817},
  shortjournal = {Front. Artif. Intell.},
  title        = {Adaptive initialization method for K-means algorithm},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). What makes artificial intelligence exceptional in health
technology assessment? <em>FRAI</em>, <em>4</em>, 736697. (<a
href="https://doi.org/10.3389/frai.2021.736697">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The application of artificial intelligence (AI) may revolutionize the healthcare system, leading to enhance efficiency by automatizing routine tasks and decreasing health-related costs, broadening access to healthcare delivery, targeting more precisely patient needs, and assisting clinicians in their decision-making. For these benefits to materialize, governments and health authorities must regulate AI, and conduct appropriate health technology assessment (HTA). Many authors have highlighted that AI health technologies (AIHT) challenge traditional evaluation and regulatory processes. To inform and support HTA organizations and regulators in adapting their processes to AIHTs, we conducted a systematic review of the literature on the challenges posed by AIHTs in HTA and health regulation. Our research question was: What makes artificial intelligence exceptional in HTA? The current body of literature appears to portray AIHTs as being exceptional to HTA. This exceptionalism is expressed along 5 dimensions: 1) AIHT’s distinctive features; 2) their systemic impacts on health care and the health sector; 3) the increased expectations towards AI in health; 4) the new ethical, social and legal challenges that arise from deploying AI in the health sector; and 5) the new evaluative constraints that AI poses to HTA. Thus, AIHTs are perceived as exceptional because of their technological characteristics and potential impacts on society at large. As AI implementation by governments and health organizations carries risks of generating new, and amplifying existing, challenges, there are strong arguments for taking into consideration the exceptional aspects of AIHTs, especially as their impacts on the healthcare system will be far greater than that of drugs and medical devices. As AIHTs begin to be increasingly introduced into the health care sector, there is a window of opportunity for HTA agencies and scholars to consider AIHTs’ exceptionalism and to work towards only deploying clinically, economically, socially acceptable AIHTs in the health care system.},
  archive      = {J_FRAI},
  author       = {Bélisle-Pipon, Jean-Christophe and Couture, Vincent and Roy, Marie-Christine and Ganache, Isabelle and Goetghebeur, Mireille and Cohen, I. Glenn},
  doi          = {10.3389/frai.2021.736697},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {11},
  pages        = {736697},
  shortjournal = {Front. Artif. Intell.},
  title        = {What makes artificial intelligence exceptional in health technology assessment?},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Extended goal recognition: Lessons from magic.
<em>FRAI</em>, <em>4</em>, 730990. (<a
href="https://doi.org/10.3389/frai.2021.730990">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The “science of magic” has lately emerged as a new field of study, providing valuable insights into the nature of human perception and cognition. While most of us think of magic as being all about deception and perceptual “tricks”, the craft—as documented by psychologists and professional magicians—provides a rare practical demonstration and understanding of goal recognition. For the purposes of human-aware planning, goal recognition involves predicting what a human observer is most likely to understand from a sequence of actions. Magicians perform sequences of actions with keen awareness of what an audience will understand from them and—in order to subvert it—the ability to predict precisely what an observer’s expectation is most likely to be. Magicians can do this without needing to know any personal details about their audience and without making any significant modification to their routine from one performance to the next. That is, the actions they perform are reliably interpreted by any human observer in such a way that particular (albeit erroneous) goals are predicted every time. This is achievable because people’s perception, cognition and sense-making are predictably fallible. Moreover, in the context of magic, the principles underlying human fallibility are not only well-articulated but empirically proven. In recent work we demonstrated how aspects of human cognition could be incorporated into a standard model of goal recognition, showing that—even though phenomena may be “fully observable” in that nothing prevents them from being observed—not all are noticed, not all are encoded or remembered, and few are remembered indefinitely. In the current article, we revisit those findings from a different angle. We first explore established principles from the science of magic, then recontextualise and build on our model of extended goal recognition in the context of those principles. While our extensions relate primarily to observations, this work extends and explains the definitions, showing how incidental (and apparently incidental) behaviours may significantly influence human memory and belief. We conclude by discussing additional ways in which magic can inform models of goal recognition and the light that this sheds on the persistence of conspiracy theories in the face of compelling contradictory evidence.},
  archive      = {J_FRAI},
  author       = {Masters, Peta and Smith, Wally and Kirley, Michael},
  doi          = {10.3389/frai.2021.730990},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {11},
  pages        = {730990},
  shortjournal = {Front. Artif. Intell.},
  title        = {Extended goal recognition: Lessons from magic},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). “I don’t think these devices are very culturally
sensitive.”—impact of automated speech recognition errors on african
americans. <em>FRAI</em>, <em>4</em>, 725911. (<a
href="https://doi.org/10.3389/frai.2021.725911">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automated speech recognition (ASR) converts language into text and is used across a variety of applications to assist us in everyday life, from powering virtual assistants, natural language conversations, to enabling dictation services. While recent work suggests that there are racial disparities in the performance of ASR systems for speakers of African American Vernacular English, little is known about the psychological and experiential effects of these failures paper provides a detailed examination of the behavioral and psychological consequences of ASR voice errors and the difficulty African American users have with getting their intents recognized. The results demonstrate that ASR failures have a negative, detrimental impact on African American users. Specifically, African Americans feel othered when using technology powered by ASR—errors surface thoughts about identity, namely about race and geographic location—leaving them feeling that the technology was not made for them. As a result, African Americans accommodate their speech to have better success with the technology. We incorporate the insights and lessons learned from sociolinguistics in our suggestions for linguistically responsive ways to build more inclusive voice systems that consider African American users’ needs, attitudes, and speech patterns. Our findings suggest that the use of a diary study can enable researchers to best understand the experiences and needs of communities who are often misunderstood by ASR. We argue this methodological framework could enable researchers who are concerned with fairness in AI to better capture the needs of all speakers who are traditionally misheard by voice-activated, artificially intelligent (voice-AI) digital systems.},
  archive      = {J_FRAI},
  author       = {Mengesha, Zion and Heldreth, Courtney and Lahav, Michal and Sublewski, Juliana and Tuennerman, Elyse},
  doi          = {10.3389/frai.2021.725911},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {11},
  pages        = {725911},
  shortjournal = {Front. Artif. Intell.},
  title        = {“I don’t think these devices are very culturally Sensitive.”—Impact of automated speech recognition errors on african americans},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Explainable AI for data-driven feedback and intelligent
action recommendations to support students self-regulation.
<em>FRAI</em>, <em>4</em>, 723447. (<a
href="https://doi.org/10.3389/frai.2021.723447">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Formative feedback has long been recognised as an effective tool for student learning, and researchers have investigated the subject for decades. However, the actual implementation of formative feedback practices is associated with significant challenges because it is highly time-consuming for teachers to analyse students’ behaviours and to formulate and deliver effective feedback and action recommendations to support students’ regulation of learning. This paper proposes a novel approach that employs learning analytics techniques combined with explainable machine learning to provide automatic and intelligent feedback and action recommendations that support student’s self-regulation in a data-driven manner, aiming to improve their performance in courses. Prior studies within the field of learning analytics have predicted students’ performance and have used the prediction status as feedback without explaining the reasons behind the prediction. Our proposed method, which has been developed based on LMS data from a university course, extends this approach by explaining the root causes of the predictions and by automatically providing data-driven intelligent recommendations for action. Based on the proposed explainable machine learning-based approach, a dashboard that provides data-driven feedback and intelligent course action recommendations to students is developed, tested and evaluated. Based on such an evaluation, we identify and discuss the utility and limitations of the developed dashboard. According to the findings of the conducted evaluation, the dashboard improved students’ learning outcomes, assisted them in self-regulation and had a positive effect on their motivation.},
  archive      = {J_FRAI},
  author       = {Afzaal, Muhammad and Nouri, Jalal and Zia, Aayesha and Papapetrou, Panagiotis and Fors, Uno and Wu, Yongchao and Li, Xiu and Weegar, Rebecka},
  doi          = {10.3389/frai.2021.723447},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {11},
  pages        = {723447},
  shortjournal = {Front. Artif. Intell.},
  title        = {Explainable AI for data-driven feedback and intelligent action recommendations to support students self-regulation},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A quantitative evaluation of global, rule-based explanations
of post-hoc, model agnostic methods. <em>FRAI</em>, <em>4</em>, 717899.
(<a href="https://doi.org/10.3389/frai.2021.717899">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Understanding the inferences of data-driven, machine-learned models can be seen as a process that discloses the relationships between their input and output. These relationships consist and can be represented as a set of inference rules. However, the models usually do not explicit these rules to their end-users who, subsequently, perceive them as black-boxes and might not trust their predictions. Therefore, scholars have proposed several methods for extracting rules from data-driven machine-learned models to explain their logic. However, limited work exists on the evaluation and comparison of these methods. This study proposes a novel comparative approach to evaluate and compare the rulesets produced by five model-agnostic, post-hoc rule extractors by employing eight quantitative metrics. Eventually, the Friedman test was employed to check whether a method consistently performed better than the others, in terms of the selected metrics, and could be considered superior. Findings demonstrate that these metrics do not provide sufficient evidence to identify superior methods over the others. However, when used together, these metrics form a tool, applicable to every rule-extraction method and machine-learned models, that is, suitable to highlight the strengths and weaknesses of the rule-extractors in various applications in an objective and straightforward manner, without any human interventions. Thus, they are capable of successfully modelling distinctively aspects of explainability, providing to researchers and practitioners vital insights on what a model has learned during its training process and how it makes its predictions.},
  archive      = {J_FRAI},
  author       = {Vilone, Giulia and Longo, Luca},
  doi          = {10.3389/frai.2021.717899},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {11},
  pages        = {717899},
  shortjournal = {Front. Artif. Intell.},
  title        = {A quantitative evaluation of global, rule-based explanations of post-hoc, model agnostic methods},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Data-driven discovery of mathematical and physical relations
in oncology data using human-understandable machine learning.
<em>FRAI</em>, <em>4</em>, 713690. (<a
href="https://doi.org/10.3389/frai.2021.713690">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For decades, researchers have used the concepts of rate of change and differential equations to model and forecast neoplastic processes. This expressive mathematical apparatus brought significant insights in oncology by describing the unregulated proliferation and host interactions of cancer cells, as well as their response to treatments. Now, these theories have been given a new life and found new applications. With the advent of routine cancer genome sequencing and the resulting abundance of data, oncology now builds an “arsenal” of new modeling and analysis tools. Models describing the governing physical laws of tumor–host–drug interactions can be now challenged with biological data to make predictions about cancer progression. Our study joins the efforts of the mathematical and computational oncology community by introducing a novel machine learning system for data-driven discovery of mathematical and physical relations in oncology. The system utilizes computational mechanisms such as competition, cooperation, and adaptation in neural networks to simultaneously learn the statistics and the governing relations between multiple clinical data covariates. Targeting an easy adoption in clinical oncology, the solutions of our system reveal human-understandable properties and features hidden in the data. As our experiments demonstrate, our system can describe nonlinear conservation laws in cancer kinetics and growth curves, symmetries in tumor’s phenotypic staging transitions, the preoperative spatial tumor distribution, and up to the nonlinear intracellular and extracellular pharmacokinetics of neoadjuvant therapies. The primary goal of our work is to enhance or improve the mechanistic understanding of cancer dynamics by exploiting heterogeneous clinical data. We demonstrate through multiple instantiations that our system is extracting an accurate human-understandable representation of the underlying dynamics of physical interactions central to typical oncology problems. Our results and evaluation demonstrate that, using simple—yet powerful—computational mechanisms, such a machine learning system can support clinical decision-making. To this end, our system is a representative tool of the field of mathematical and computational oncology and offers a bridge between the data, the modeler, the data scientist, and the practicing clinician.},
  archive      = {J_FRAI},
  author       = {Kurz, Daria and Sánchez, Carlos Salort and Axenie, Cristian},
  doi          = {10.3389/frai.2021.713690},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {11},
  pages        = {713690},
  shortjournal = {Front. Artif. Intell.},
  title        = {Data-driven discovery of mathematical and physical relations in oncology data using human-understandable machine learning},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Social networks of lexical innovation. Investigating the
social dynamics of diffusion of neologisms on twitter. <em>FRAI</em>,
<em>4</em>, 648583. (<a
href="https://doi.org/10.3389/frai.2021.648583">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Societies continually evolve and speakers use new words to talk about innovative products and practices. While most lexical innovations soon fall into disuse, others spread successfully and become part of the lexicon. In this paper, I conduct a longitudinal study of the spread of 99 English neologisms on Twitter to study their degrees and pathways of diffusion. Previous work on lexical innovation has almost exclusively relied on usage frequency for investigating the spread of new words. To get a more differentiated picture of diffusion, I use frequency-based measures to study temporal aspects of diffusion and I use network analyses for a more detailed and accurate investigation of the sociolinguistic dynamics of diffusion. The results show that frequency measures manage to capture diffusion with varying success. Frequency counts can serve as an approximate indicator for overall degrees of diffusion, yet they miss important information about the temporal usage profiles of lexical innovations. The results indicate that neologisms with similar total frequency can exhibit significantly different degrees of diffusion. Analysing differences in their temporal dynamics of use with regard to their age, trends in usage intensity, and volatility contributes to a more accurate account of their diffusion. The results obtained from the social network analysis reveal substantial differences in the social pathways of diffusion. Social diffusion significantly correlates with the frequency and temporal usage profiles of neologisms. However, the network visualisations and metrics identify neologisms whose degrees of social diffusion are more limited than suggested by their overall frequency of use. These include, among others, highly volatile neologisms (e.g., poppygate) and political terms (e.g., alt-left), whose use almost exclusively goes back to single communities of closely-connected, like-minded individuals. I argue that the inclusion of temporal and social information is of particular importance for the study of lexical innovation since neologisms exhibit high degrees of temporal volatility and social indexicality. More generally, the present approach demonstrates the potential of social network analysis for sociolinguistic research on linguistic innovation, variation, and change.},
  archive      = {J_FRAI},
  author       = {Würschinger, Quirin},
  doi          = {10.3389/frai.2021.648583},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {11},
  pages        = {648583},
  shortjournal = {Front. Artif. Intell.},
  title        = {Social networks of lexical innovation. investigating the social dynamics of diffusion of neologisms on twitter},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Developing a conversational agent’s capability to identify
structural wrongness in arguments based on toulmin’s model of arguments.
<em>FRAI</em>, <em>4</em>, 645516. (<a
href="https://doi.org/10.3389/frai.2021.645516">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article discusses the usefulness of Toulmin’s model of arguments as structuring an assessment of different types of wrongness in an argument. We discuss the usability of the model within a conversational agent that aims to support users to develop a good argument. Within the article, we present a study and the development of classifiers that identify the existence of structural components in a good argument, namely a claim, a warrant (underlying understanding), and evidence. Based on a dataset (three sub-datasets with 100, 1,026, 211 responses in each) in which users argue about the intelligence or non-intelligence of entities, we have developed classifiers for these components: The existence and direction (positive/negative) of claims can be detected a weighted average F1 score over all classes (positive/negative/unknown) of 0.91. The existence of a warrant (with warrant/without warrant) can be detected with a weighted F1 score over all classes of 0.88. The existence of evidence (with evidence/without evidence) can be detected with a weighted average F1 score of 0.80. We argue that these scores are high enough to be of use within a conditional dialogue structure based on Bloom’s taxonomy of learning; and show by argument an example conditional dialogue structure that allows us to conduct coherent learning conversations. While in our described experiments, we show how Toulmin’s model of arguments can be used to identify structural problems with argumentation, we also discuss how Toulmin’s model of arguments could be used in conjunction with content-wise assessment of the correctness especially of the evidence component to identify more complex types of wrongness in arguments, where argument components are not well aligned. Owing to having progress in argument mining and conversational agents, the next challenges could be the developing agents that support learning argumentation. These agents could identify more complex type of wrongness in arguments that result from wrong connections between argumentation components.},
  archive      = {J_FRAI},
  author       = {Mirzababaei, Behzad and Pammer-Schindler, Viktoria},
  doi          = {10.3389/frai.2021.645516},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {11},
  pages        = {645516},
  shortjournal = {Front. Artif. Intell.},
  title        = {Developing a conversational agent’s capability to identify structural wrongness in arguments based on toulmin’s model of arguments},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A modified AUC for training convolutional neural networks:
Taking confidence into account. <em>FRAI</em>, <em>4</em>, 582928. (<a
href="https://doi.org/10.3389/frai.2021.582928">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Receiver operating characteristic (ROC) curve is an informative tool in binary classification and Area Under ROC Curve (AUC) is a popular metric for reporting performance of binary classifiers. In this paper, first we present a comprehensive review of ROC curve and AUC metric. Next, we propose a modified version of AUC that takes confidence of the model into account and at the same time, incorporates AUC into Binary Cross Entropy (BCE) loss used for training a Convolutional neural Network for classification tasks. We demonstrate this on three datasets: MNIST, prostate MRI, and brain MRI. Furthermore, we have published GenuineAI, a new python library, which provides the functions for conventional AUC and the proposed modified AUC along with metrics including sensitivity, specificity, recall, precision, and F1 for each point of the ROC curve.},
  archive      = {J_FRAI},
  author       = {Namdar, Khashayar and Haider, Masoom A. and Khalvati, Farzad},
  doi          = {10.3389/frai.2021.582928},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {11},
  pages        = {582928},
  shortjournal = {Front. Artif. Intell.},
  title        = {A modified AUC for training convolutional neural networks: Taking confidence into account},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Challenges of developing robust AI for intrapartum fetal
heart rate monitoring. <em>FRAI</em>, <em>4</em>, 765210. (<a
href="https://doi.org/10.3389/frai.2021.765210">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Background: CTG remains the only non-invasive tool available to the maternity team for continuous monitoring of fetal well-being during labour. Despite widespread use and investment in staff training, difficulty with CTG interpretation continues to be identified as a problem in cases of fetal hypoxia, which often results in permanent brain injury. Given the recent advances in AI, it is hoped that its application to CTG will offer a better, less subjective and more reliable method of CTG interpretation.Objectives: This mini-review examines the literature and discusses the impediments to the success of AI application to CTG thus far. Prior randomised control trials (RCTs) of CTG decision support systems are reviewed from technical and clinical perspectives. A selection of novel engineering approaches, not yet validated in RCTs, are also reviewed. The review presents the key challenges that need to be addressed in order to develop a robust AI tool to identify fetal distress in a timely manner so that appropriate intervention can be made.Results: The decision support systems used in three RCTs were reviewed, summarising the algorithms, the outcomes of the trials and the limitations. Preliminary work suggests that the inclusion of clinical data can improve the performance of AI-assisted CTG. Combined with newer approaches to the classification of traces, this offers promise for rewarding future development.},
  archive      = {J_FRAI},
  author       = {O’Sullivan, M. E. and Considine, E. C. and O&#39;Riordan, M. and Marnane, W. P. and Rennie, J. M. and Boylan, G. B.},
  doi          = {10.3389/frai.2021.765210},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {765210},
  shortjournal = {Front. Artif. Intell.},
  title        = {Challenges of developing robust AI for intrapartum fetal heart rate monitoring},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Corrigendum: Trust dynamics and verbal assurances in human
robot physical collaboration. <em>FRAI</em>, <em>4</em>, 761184. (<a
href="https://doi.org/10.3389/frai.2021.761184">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Alhaji, Basel and Prilla, Michael and Rausch, Andreas},
  doi          = {10.3389/frai.2021.761184},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {761184},
  shortjournal = {Front. Artif. Intell.},
  title        = {Corrigendum: Trust dynamics and verbal assurances in human robot physical collaboration},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). GDP forecasting: Machine learning, linear or autoregression?
<em>FRAI</em>, <em>4</em>, 757864. (<a
href="https://doi.org/10.3389/frai.2021.757864">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper compares the predictive power of different models to forecast the real U.S. GDP. Using quarterly data from 1976 to 2020, we find that the machine learning K-Nearest Neighbour (KNN) model captures the self-predictive ability of the U.S. GDP and performs better than traditional time series analysis. We explore the inclusion of predictors such as the yield curve, its latent factors, and a set of macroeconomic variables in order to increase the level of forecasting accuracy. The predictions result to be improved only when considering long forecast horizons. The use of machine learning algorithm provides additional guidance for data-driven decision making.},
  archive      = {J_FRAI},
  author       = {Maccarrone, Giovanni and Morelli, Giacomo and Spadaccini, Sara},
  doi          = {10.3389/frai.2021.757864},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {757864},
  shortjournal = {Front. Artif. Intell.},
  title        = {GDP forecasting: Machine learning, linear or autoregression?},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). QF-TraderNet: Intraday trading via deep reinforcement with
quantum price levels based profit-and-loss control. <em>FRAI</em>,
<em>4</em>, 749878. (<a
href="https://doi.org/10.3389/frai.2021.749878">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reinforcement Learning (RL) based machine trading attracts a rich profusion of interest. However, in the existing research, RL in the day-trade task suffers from the noisy financial movement in the short time scale, difficulty in order settlement, and expensive action search in a continuous-value space. This paper introduced an end-to-end RL intraday trading agent, namely QF-TraderNet, based on the quantum finance theory (QFT) and deep reinforcement learning. We proposed a novel design for the intraday RL trader’s action space, inspired by the Quantum Price Levels (QPLs). Our action space design also brings the model a learnable profit-and-loss control strategy. QF-TraderNet composes two neural networks: 1) A long short term memory networks for the feature learning of financial time series; 2) a policy generator network (PGN) for generating the distribution of actions. The profitability and robustness of QF-TraderNet have been verified in multi-type financial datasets, including FOREX, metals, crude oil, and financial indices. The experimental results demonstrate that QF-TraderNet outperforms other baselines in terms of cumulative price returns and Sharpe Ratio, and the robustness in the acceidential market shift.},
  archive      = {J_FRAI},
  author       = {Qiu, Yifu and Qiu, Yitao and Yuan, Yicong and Chen, Zheng and Lee, Raymond},
  doi          = {10.3389/frai.2021.749878},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {749878},
  shortjournal = {Front. Artif. Intell.},
  title        = {QF-TraderNet: Intraday trading via deep reinforcement with quantum price levels based profit-and-loss control},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). In the pursuit of privacy: The promises and predicaments of
federated learning in healthcare. <em>FRAI</em>, <em>4</em>, 746497. (<a
href="https://doi.org/10.3389/frai.2021.746497">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial Intelligence and its subdomain, Machine Learning (ML), have shown the potential to make an unprecedented impact in healthcare. Federated Learning (FL) has been introduced to alleviate some of the limitations of ML, particularly the capability to train on larger datasets for improved performance, which is usually cumbersome for an inter-institutional collaboration due to existing patient protection laws and regulations. Moreover, FL may also play a crucial role in circumventing ML’s exigent bias problem by accessing underrepresented groups’ data spanning geographically distributed locations. In this paper, we have discussed three FL challenges, namely: privacy of the model exchange, ethical perspectives, and legal considerations. Lastly, we have proposed a model that could aide in assessing data contributions of a FL implementation. In light of the expediency and adaptability of using the Sørensen–Dice Coefficient over the more limited (e.g., horizontal FL) and computationally expensive Shapley Values, we sought to demonstrate a new paradigm that we hope, will become invaluable for sharing any profit and responsibilities that may accompany a FL endeavor.},
  archive      = {J_FRAI},
  author       = {Topaloglu, Mustafa Y. and Morrell, Elisabeth M. and Rajendran, Suraj and Topaloglu, Umit},
  doi          = {10.3389/frai.2021.746497},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {746497},
  shortjournal = {Front. Artif. Intell.},
  title        = {In the pursuit of privacy: The promises and predicaments of federated learning in healthcare},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Identification of scams in initial coin offerings with
machine learning. <em>FRAI</em>, <em>4</em>, 718450. (<a
href="https://doi.org/10.3389/frai.2021.718450">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Following the emergence of cryptocurrencies, the field of digital assets experienced a sudden explosion of interest among institutional investors. However, regarding ICOs, there were a lot of scams involving the disappearance of firms after they had collected significant amounts of funds. We study how well one can predict if an offering will turn out to be a scam, doing so based on the characteristics known ex-ante. We therefore examine which of these characteristics are the most important predictors of a scam, and how they influence the probability of a scam. We use detailed data with 160 features from about 300 ICOs that took place before March 2018 and succeeded in raising most of their required capital. Various machine learning algorithms are applied together with novel XAI tools in order to identify the most important predictors of an offering’s failure and understand the shape of relationships. It turns out that based on the features known ex-ante, one can predict a scam with an accuracy of about 65–70%, and that nonlinear machine learning models perform better than traditional logistic regression and its regularized extensions.},
  archive      = {J_FRAI},
  author       = {Karimov, Bedil and Wójcik, Piotr},
  doi          = {10.3389/frai.2021.718450},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {718450},
  shortjournal = {Front. Artif. Intell.},
  title        = {Identification of scams in initial coin offerings with machine learning},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Behaviour recognition with kinodynamic planning over
continuous domains. <em>FRAI</em>, <em>4</em>, 717003. (<a
href="https://doi.org/10.3389/frai.2021.717003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We investigate the application of state-of-the-art goal recognition techniques for behaviour recognition over complex continuous domains using model predictive control (MPC) for trajectory generation. We formally define the problem of kinodynamic behaviour recognition and establish a set of baseline behaviours and performance measures in the complex domain of unmanned aerial maneuvers. We evaluate how well our approach performs over a range of standard aerial maneuvers and representative initial configurations of varying complexity. The work also highlights future research directions in compound model-based behaviour recognition and team behaviour recognition where multiple agents may be acting simultaneously.},
  archive      = {J_FRAI},
  author       = {Fitzpatrick, Grady and Lipovetzky, Nir and Papasimeon, Michael and Ramirez, Miquel and Vered, Mor},
  doi          = {10.3389/frai.2021.717003},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {717003},
  shortjournal = {Front. Artif. Intell.},
  title        = {Behaviour recognition with kinodynamic planning over continuous domains},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Machine learning detects anti-DENV signatures in antibody
repertoire sequences. <em>FRAI</em>, <em>4</em>, 715462. (<a
href="https://doi.org/10.3389/frai.2021.715462">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dengue infection is a global threat. As of today, there is no universal dengue fever treatment or vaccines unreservedly recommended by the World Health Organization. The investigation of the specific immune response to dengue virus would support antibody discovery as therapeutics for passive immunization and vaccine design. High-throughput sequencing enables the identification of the multitude of antibodies elicited in response to dengue infection at the sequence level. Artificial intelligence can mine the complex data generated and has the potential to uncover patterns in entire antibody repertoires and detect signatures distinctive of single virus-binding antibodies. However, these machine learning have not been harnessed to determine the immune response to dengue virus. In order to enable the application of machine learning, we have benchmarked existing methods for encoding biological and chemical knowledge as inputs and have investigated novel encoding techniques. We have applied different machine learning methods such as neural networks, random forests, and support vector machines and have investigated the parameter space to determine best performing algorithms for the detection and prediction of antibody patterns at the repertoire and antibody sequence levels in dengue-infected individuals. Our results show that immune response signatures to dengue are detectable both at the antibody repertoire and at the antibody sequence levels. By combining machine learning with phylogenies and network analysis, we generated novel sequences that present dengue-binding specific signatures. These results might aid further antibody discovery and support vaccine design.},
  archive      = {J_FRAI},
  author       = {Horst, Alexander and Smakaj, Erand and Natali, Eriberto Noel and Tosoni, Deniz and Babrak, Lmar Marie and Meier, Patrick and Miho, Enkelejda},
  doi          = {10.3389/frai.2021.715462},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {715462},
  shortjournal = {Front. Artif. Intell.},
  title        = {Machine learning detects anti-DENV signatures in antibody repertoire sequences},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). AI systems and respect for human autonomy. <em>FRAI</em>,
<em>4</em>, 705164. (<a
href="https://doi.org/10.3389/frai.2021.705164">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study concerns the sociotechnical bases of human autonomy. Drawing on recent literature on AI ethics, philosophical literature on dimensions of autonomy, and on independent philosophical scrutiny, we first propose a multi-dimensional model of human autonomy and then discuss how AI systems can support or hinder human autonomy. What emerges is a philosophically motivated picture of autonomy and of the normative requirements personal autonomy poses in the context of algorithmic systems. Ranging from consent to data collection and processing, to computational tasks and interface design, to institutional and societal considerations, various aspects related to sociotechnical systems must be accounted for in order to get the full picture of potential effects of AI systems on human autonomy. It is clear how human agents can, for example, via coercion or manipulation, hinder each other’s autonomy, or how they can respect each other’s autonomy. AI systems can promote or hinder human autonomy, but can they literally respect or disrespect a person’s autonomy? We argue for a philosophical view according to which AI systems—while not moral agents or bearers of duties, and unable to literally respect or disrespect—are governed by so-called “ought-to-be norms.” This explains the normativity at stake with AI systems. The responsible people (designers, users, etc.) have duties and ought-to-do norms, which correspond to these ought-to-be norms.},
  archive      = {J_FRAI},
  author       = {Laitinen, Arto and Sahlgren, Otto},
  doi          = {10.3389/frai.2021.705164},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {705164},
  shortjournal = {Front. Artif. Intell.},
  title        = {AI systems and respect for human autonomy},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Early classification of intent for maritime domains using
multinomial hidden markov models. <em>FRAI</em>, <em>4</em>, 702153. (<a
href="https://doi.org/10.3389/frai.2021.702153">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The need for increased maritime security has prompted research focus on intent recognition solutions for the naval domain. We consider the problem of early classification of the hostile behavior of agents in a dynamic maritime domain and propose our solution using multinomial hidden Markov models (HMMs). Our contribution stems from a novel encoding of observable symbols as the rate of change (instead of static values) for parameters relevant to the task, which enables the early classification of hostile behaviors, well before the behavior has been finalized. We discuss our implementation of a one-versus-all intent classifier using multinomial HMMs and present the performance of our system for three types of hostile behaviors (ram, herd, block) and a benign behavior.},
  archive      = {J_FRAI},
  author       = {Carlson, Logan and Navalta, Dalton and Nicolescu, Monica and Nicolescu, Mircea and Woodward, Gail},
  doi          = {10.3389/frai.2021.702153},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {702153},
  shortjournal = {Front. Artif. Intell.},
  title        = {Early classification of intent for maritime domains using multinomial hidden markov models},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Matrix profile-based interpretable time series classifier.
<em>FRAI</em>, <em>4</em>, 699448. (<a
href="https://doi.org/10.3389/frai.2021.699448">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time series classification (TSC) is a pervasive and transversal problem in various fields ranging from disease diagnosis to anomaly detection in finance. Unfortunately, the most effective models used by Artificial Intelligence (AI) systems for TSC are not interpretable and hide the logic of the decision process, making them unusable in sensitive domains. Recent research is focusing on explanation methods to pair with the obscure classifier to recover this weakness. However, a TSC approach that is transparent by design and is simultaneously efficient and effective is even more preferable. To this aim, we propose an interpretable TSC method based on the patterns, which is possible to extract from the Matrix Profile (MP) of the time series in the training set. A smart design of the classification procedure allows obtaining an efficient and effective transparent classifier modeled as a decision tree that expresses the reasons for the classification as the presence of discriminative subsequences. Quantitative and qualitative experimentation shows that the proposed method overcomes the state-of-the-art interpretable approaches.},
  archive      = {J_FRAI},
  author       = {Guidotti, Riccardo and D’Onofrio, Matteo},
  doi          = {10.3389/frai.2021.699448},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {699448},
  shortjournal = {Front. Artif. Intell.},
  title        = {Matrix profile-based interpretable time series classifier},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). ROA: A rapid learning scheme for in-situ memristor networks.
<em>FRAI</em>, <em>4</em>, 692065. (<a
href="https://doi.org/10.3389/frai.2021.692065">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Memristors show great promise in neuromorphic computing owing to their high-density integration, fast computing and low-energy consumption. However, the non-ideal update of synaptic weight in memristor devices, including nonlinearity, asymmetry and device variation, still poses challenges to the in-situ learning of memristors, thereby limiting their broad applications. Although the existing offline learning schemes can avoid this problem by transferring the weight optimization process into cloud, it is difficult to adapt to unseen tasks and uncertain environments. Here, we propose a bi-level meta-learning scheme that can alleviate the non-ideal update problem, and achieve fast adaptation and high accuracy, named Rapid One-step Adaption (ROA). By introducing a special regularization constraint and a dynamic learning rate strategy for in-situ learning, the ROA method effectively combines offline pre-training and online rapid one-step adaption. Furthermore, we implemented it on memristor-based neural networks to solve few-shot learning tasks, proving its superiority over the pure offline and online schemes under noisy conditions. This method can solve in-situ learning in non-ideal memristor networks, providing potential applications of on-chip neuromorphic learning and edge computing.},
  archive      = {J_FRAI},
  author       = {Zhang, Wenli and Wang, Yaoyuan and Ji, Xinglong and Wu, Yujie and Zhao, Rong},
  doi          = {10.3389/frai.2021.692065},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {692065},
  shortjournal = {Front. Artif. Intell.},
  title        = {ROA: A rapid learning scheme for in-situ memristor networks},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An empirical investigation into deep and shallow rule
learning. <em>FRAI</em>, <em>4</em>, 689398. (<a
href="https://doi.org/10.3389/frai.2021.689398">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inductive rule learning is arguably among the most traditional paradigms in machine learning. Although we have seen considerable progress over the years in learning rule-based theories, all state-of-the-art learners still learn descriptions that directly relate the input features to the target concept. In the simplest case, concept learning, this is a disjunctive normal form (DNF) description of the positive class. While it is clear that this is sufficient from a logical point of view because every logical expression can be reduced to an equivalent DNF expression, it could nevertheless be the case that more structured representations, which form deep theories by forming intermediate concepts, could be easier to learn, in very much the same way as deep neural networks are able to outperform shallow networks, even though the latter are also universal function approximators. However, there are several non-trivial obstacles that need to be overcome before a sufficiently powerful deep rule learning algorithm could be developed and be compared to the state-of-the-art in inductive rule learning. In this paper, we therefore take a different approach: we empirically compare deep and shallow rule sets that have been optimized with a uniform general mini-batch based optimization algorithm. In our experiments on both artificial and real-world benchmark data, deep rule networks outperformed their shallow counterparts, which we take as an indication that it is worth-while to devote more efforts to learning deep rule structures from data.},
  archive      = {J_FRAI},
  author       = {Beck, Florian and Fürnkranz, Johannes},
  doi          = {10.3389/frai.2021.689398},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {689398},
  shortjournal = {Front. Artif. Intell.},
  title        = {An empirical investigation into deep and shallow rule learning},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Facing the challenges of developing fair risk scoring
models. <em>FRAI</em>, <em>4</em>, 681915. (<a
href="https://doi.org/10.3389/frai.2021.681915">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Algorithmic scoring methods are widely used in the finance industry for several decades in order to prevent risk and to automate and optimize decisions. Regulatory requirements as given by the Basel Committee on Banking Supervision (BCBS) or the EU data protection regulations have led to an increasing interest and research activity on understanding black box machine learning models by means of explainable machine learning. Even though this is a step into a right direction, such methods are not able to guarantee for a fair scoring as machine learning models are not necessarily unbiased and may discriminate with respect to certain subpopulations such as a particular race, gender, or sexual orientation—even if the variable itself is not used for modeling. This is also true for white box methods like logistic regression. In this study, a framework is presented that allows analyzing and developing models with regard to fairness. The proposed methodology is based on techniques of causal inference and some of the methods can be linked to methods from explainable machine learning. A definition of counterfactual fairness is given together with an algorithm that results in a fair scoring model. The concepts are illustrated by means of a transparent simulation and a popular real-world example, the German Credit data using traditional scorecard models based on logistic regression and weight of evidence variable pre-transform. In contrast to previous studies in the field for our study, a corrected version of the data is presented and used. With the help of the simulation, the trade-off between fairness and predictive accuracy is analyzed. The results indicate that it is possible to remove unfairness without a strong performance decrease unless the correlation of the discriminative attributes on the other predictor variables in the model is not too strong. In addition, the challenge in explaining the resulting scoring model and the associated fairness implications to users is discussed.},
  archive      = {J_FRAI},
  author       = {Szepannek, Gero and Lübke, Karsten},
  doi          = {10.3389/frai.2021.681915},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {681915},
  shortjournal = {Front. Artif. Intell.},
  title        = {Facing the challenges of developing fair risk scoring models},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Minimal cycle representatives in persistent homology using
linear programming: An empirical study with user’s guide. <em>FRAI</em>,
<em>4</em>, 681117. (<a
href="https://doi.org/10.3389/frai.2021.681117">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cycle representatives of persistent homology classes can be used to provide descriptions of topological features in data. However, the non-uniqueness of these representatives creates ambiguity and can lead to many different interpretations of the same set of classes. One approach to solving this problem is to optimize the choice of representative against some measure that is meaningful in the context of the data. In this work, we provide a study of the effectiveness and computational cost of several &lt;mml:math id=&quot;m1&quot; xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mml:mrow&gt;&lt;mml:msub&gt;&lt;mml:mi&gt;ℓ&lt;/mml:mi&gt;&lt;mml:mn&gt;1&lt;/mml:mn&gt;&lt;/mml:msub&gt;&lt;/mml:mrow&gt;&lt;/mml:math&gt; minimization optimization procedures for constructing homological cycle bases for persistent homology with rational coefficients in dimension one, including uniform-weighted and length-weighted edge-loss algorithms as well as uniform-weighted and area-weighted triangle-loss algorithms. We conduct these optimizations via standard linear programming methods, applying general-purpose solvers to optimize over column bases of simplicial boundary matrices. Our key findings are: 1) optimization is effective in reducing the size of cycle representatives, though the extent of the reduction varies according to the dimension and distribution of the underlying data, 2) the computational cost of optimizing a basis of cycle representatives exceeds the cost of computing such a basis, in most data sets we consider, 3) the choice of linear solvers matters a lot to the computation time of optimizing cycles, 4) the computation time of solving an integer program is not significantly longer than the computation time of solving a linear program for most of the cycle representatives, using the Gurobi linear solver, 5) strikingly, whether requiring integer solutions or not, we almost always obtain a solution with the same cost and almost all solutions found have entries in &lt;mml:math id=&quot;m2&quot; xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mo&gt;{&lt;/mml:mo&gt;&lt;mml:mrow&gt;&lt;mml:mo&gt;‐&lt;/mml:mo&gt;&lt;mml:mn&gt;1,0,1&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;}&lt;/mml:mo&gt;&lt;/mml:mrow&gt;&lt;/mml:mrow&gt;&lt;/mml:math&gt; and therefore, are also solutions to a restricted &lt;mml:math id=&quot;m3&quot; xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mml:mrow&gt;&lt;mml:msub&gt;&lt;mml:mi&gt;ℓ&lt;/mml:mi&gt;&lt;mml:mn&gt;0&lt;/mml:mn&gt;&lt;/mml:msub&gt;&lt;/mml:mrow&gt;&lt;/mml:math&gt; optimization problem, and 6) we obtain qualitatively different results for generators in Erdős-Rényi random clique complexes than in real-world and synthetic point cloud data.},
  archive      = {J_FRAI},
  author       = {Li, Lu and Thompson, Connor and Henselman-Petrusek, Gregory and Giusti, Chad and Ziegelmeier, Lori},
  doi          = {10.3389/frai.2021.681117},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {681117},
  shortjournal = {Front. Artif. Intell.},
  title        = {Minimal cycle representatives in persistent homology using linear programming: An empirical study with user’s guide},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Assessing open-ended human-computer collaboration systems:
Applying a hallmarks approach. <em>FRAI</em>, <em>4</em>, 670009. (<a
href="https://doi.org/10.3389/frai.2021.670009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There is a growing desire to create computer systems that can collaborate with humans on complex, open-ended activities. These activities typically have no set completion criteria and frequently involve multimodal communication, extensive world knowledge, creativity, and building structures or compositions through multiple steps. Because these systems differ from question and answer (Q&amp;amp;A) systems, chatbots, and simple task-oriented assistants, new methods for evaluating such collaborative computer systems are needed. Here, we present a set of criteria for evaluating these systems, called Hallmarks of Human-Machine Collaboration. The Hallmarks build on the success of heuristic evaluation used by the user interface community and past evaluation techniques used in the spoken language and chatbot communities. They consist of observable characteristics indicative of successful collaborative communication, grouped into eight high-level properties: robustness; habitability; mutual contribution of meaningful content; context-awareness; consistent human engagement; provision of rationale; use of elementary concepts to teach and learn new concepts; and successful collaboration. We present examples of how we used these Hallmarks in the DARPA Communicating with Computers (CwC) program to evaluate diverse activities, including story and music generation, interactive building with blocks, and exploration of molecular mechanisms in cancer. We used the Hallmarks as guides for developers and as diagnostics, assessing systems with the Hallmarks to identify strengths and opportunities for improvement using logs from user studies, surveying the human partner, third-party review of creative products, and direct tests. Informal feedback from CwC technology developers indicates that the use of the Hallmarks for program evaluation helped guide development. The Hallmarks also made it possible to identify areas of progress and major gaps in developing systems where the machine is an equal, creative partner.},
  archive      = {J_FRAI},
  author       = {Kozierok, Robyn and Aberdeen, John and Clark, Cheryl and Garay, Christopher and Goodman, Bradley and Korves, Tonia and Hirschman, Lynette and McDermott, Patricia L. and Peterson, Matthew W.},
  doi          = {10.3389/frai.2021.670009},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {670009},
  shortjournal = {Front. Artif. Intell.},
  title        = {Assessing open-ended human-computer collaboration systems: Applying a hallmarks approach},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Artificial intelligence to analyze the cortical thickness
through age. <em>FRAI</em>, <em>4</em>, 549255. (<a
href="https://doi.org/10.3389/frai.2021.549255">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, Artificial Intelligence was used to analyze a dataset containing the cortical thickness from 1,100 healthy individuals. This dataset had the cortical thickness from 31 regions in the left hemisphere of the brain as well as from 31 regions in the right hemisphere. Then, 62 artificial neural networks were trained and validated to estimate the number of neurons in the hidden layer. These neural networks were used to create a model for the cortical thickness through age for each region in the brain. Using the artificial neural networks and kernels with seven points, numerical differentiation was used to compute the derivative of the cortical thickness with respect to age. The derivative was computed to estimate the cortical thickness speed. Finally, color bands were created for each region in the brain to identify a positive derivative, that is, a part of life with an increase in cortical thickness. Likewise, the color bands were used to identify a negative derivative, that is, a lifetime period with a cortical thickness reduction. Regions of the brain with similar derivatives were organized and displayed in clusters. Computer simulations showed that some regions exhibit abrupt changes in cortical thickness at specific periods of life. The simulations also illustrated that some regions in the left hemisphere do not follow the pattern of the same region in the right hemisphere. Finally, it was concluded that each region in the brain must be dynamically modeled. One advantage of using artificial neural networks is that they can learn and model non-linear and complex relationships. Also, artificial neural networks are immune to noise in the samples and can handle unseen data. That is, the models based on artificial neural networks can predict the behavior of samples that were not used for training. Furthermore, several studies have shown that artificial neural networks are capable of deriving information from imprecise data. Because of these advantages, the results obtained in this study by the artificial neural networks provide valuable information to analyze and model the cortical thickness.},
  archive      = {J_FRAI},
  author       = {Ledesma, Sergio and Ibarra-Manzano, Mario-Alberto and Almanza-Ojeda, Dora-Luz and Fallavollita, Pascal and Steffener, Jason},
  doi          = {10.3389/frai.2021.549255},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {549255},
  shortjournal = {Front. Artif. Intell.},
  title        = {Artificial intelligence to analyze the cortical thickness through age},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Corrigendum: Insights into co-morbidity and other risk
factors related to COVID-19 within ontario, canada. <em>FRAI</em>,
<em>4</em>, 759022. (<a
href="https://doi.org/10.3389/frai.2021.759022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Snider, Brett and Patel, Bhumi and McBean, Edward},
  doi          = {10.3389/frai.2021.759022},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {9},
  pages        = {759022},
  shortjournal = {Front. Artif. Intell.},
  title        = {Corrigendum: Insights into co-morbidity and other risk factors related to COVID-19 within ontario, canada},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Deep learning of histopathology images at the single cell
level. <em>FRAI</em>, <em>4</em>, 754641. (<a
href="https://doi.org/10.3389/frai.2021.754641">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The tumor immune microenvironment (TIME) encompasses many heterogeneous cell types that engage in extensive crosstalk among the cancer, immune, and stromal components. The spatial organization of these different cell types in TIME could be used as biomarkers for predicting drug responses, prognosis and metastasis. Recently, deep learning approaches have been widely used for digital histopathology images for cancer diagnoses and prognoses. Furthermore, some recent approaches have attempted to integrate spatial and molecular omics data to better characterize the TIME. In this review we focus on machine learning-based digital histopathology image analysis methods for characterizing tumor ecosystem. In this review, we will consider three different scales of histopathological analyses that machine learning can operate within: whole slide image (WSI)-level, region of interest (ROI)-level, and cell-level. We will systematically review the various machine learning methods in these three scales with a focus on cell-level analysis. We will provide a perspective of workflow on generating cell-level training data sets using immunohistochemistry markers to “weakly-label” the cell types. We will describe some common steps in the workflow of preparing the data, as well as some limitations of this approach. Finally, we will discuss future opportunities of integrating molecular omics data with digital histopathology images for characterizing tumor ecosystem.},
  archive      = {J_FRAI},
  author       = {Lee, Kyubum and Lockhart, John H. and Xie, Mengyu and Chaudhary, Ritu and Slebos, Robbert J. C. and Flores, Elsa R. and Chung, Christine H. and Tan, Aik Choon},
  doi          = {10.3389/frai.2021.754641},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {9},
  pages        = {754641},
  shortjournal = {Front. Artif. Intell.},
  title        = {Deep learning of histopathology images at the single cell level},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). SHAP and LIME: An evaluation of discriminative power in
credit risk. <em>FRAI</em>, <em>4</em>, 752558. (<a
href="https://doi.org/10.3389/frai.2021.752558">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In credit risk estimation, the most important element is obtaining a probability of default as close as possible to the effective risk. This effort quickly prompted new, powerful algorithms that reach a far higher accuracy, but at the cost of losing intelligibility, such as Gradient Boosting or ensemble methods. These models are usually referred to as “black-boxes”, implying that you know the inputs and the output, but there is little way to understand what is going on under the hood. As a response to that, we have seen several different Explainable AI models flourish in recent years, with the aim of letting the user see why the black-box gave a certain output. In this context, we evaluate two very popular eXplainable AI (XAI) models in their ability to discriminate observations into groups, through the application of both unsupervised and predictive modeling to the weights these XAI models assign to features locally. The evaluation is carried out on real Small and Medium Enterprises data, obtained from official italian repositories, and may form the basis for the employment of such XAI models for post-processing features extraction.},
  archive      = {J_FRAI},
  author       = {Gramegna, Alex and Giudici, Paolo},
  doi          = {10.3389/frai.2021.752558},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {9},
  pages        = {752558},
  shortjournal = {Front. Artif. Intell.},
  title        = {SHAP and LIME: An evaluation of discriminative power in credit risk},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Applications of learning analytics in high schools: A
systematic literature review. <em>FRAI</em>, <em>4</em>, 737891. (<a
href="https://doi.org/10.3389/frai.2021.737891">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning analytics aims to analyze data from students and learning environments to support learning at different levels. Although learning analytics is a recent field, it reached a high level of maturity, especially in its applications for higher education. However, little of the research in learning analytics targets other educational levels, such as high school. This paper reports the results of a systematic literature review (SLR) focused on the adoption of learning analytics in high schools. More specifically, the SLR followed four steps: the search, selection of relevant studies, critical assessment, and the extraction of the relevant field, which included the main goals, approaches, techniques, and challenges of adopting learning analytics in high school. The results show that, in this context, learning analytics applications are focused on small-scale initiatives rather than institutional adoption. Based on the findings of this study, in combination with the literature, this paper proposes future directions of research and development in order to scale up learning analytics applications in high schools.},
  archive      = {J_FRAI},
  author       = {Sousa, Erverson B. G. de and Alexandre, Bruno and Ferreira Mello, Rafael and Pontual Falcão, Taciana and Vesin, Boban and Gašević, Dragan},
  doi          = {10.3389/frai.2021.737891},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {9},
  pages        = {737891},
  shortjournal = {Front. Artif. Intell.},
  title        = {Applications of learning analytics in high schools: A systematic literature review},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Let me take over: Variable autonomy for meaningful human
control. <em>FRAI</em>, <em>4</em>, 737072. (<a
href="https://doi.org/10.3389/frai.2021.737072">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As Artificial Intelligence (AI) continues to expand its reach, the demand for human control and the development of AI systems that adhere to our legal, ethical, and social values also grows. Many (international and national) institutions have taken steps in this direction and published guidelines for the development and deployment of responsible AI systems. These guidelines, however, rely heavily on high-level statements that provide no clear criteria for system assessment, making the effective control over systems a challenge. “Human oversight” is one of the requirements being put forward as a means to support human autonomy and agency. In this paper, we argue that human presence alone does not meet this requirement and that such a misconception may limit the use of automation where it can otherwise provide so much benefit across industries. We therefore propose the development of systems with variable autonomy—dynamically adjustable levels of autonomy—as a means of ensuring meaningful human control over an artefact by satisfying all three core values commonly advocated in ethical guidelines: accountability, responsibility, and transparency.},
  archive      = {J_FRAI},
  author       = {Methnani, Leila and Aler Tubella, Andrea and Dignum, Virginia and Theodorou, Andreas},
  doi          = {10.3389/frai.2021.737072},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {9},
  pages        = {737072},
  shortjournal = {Front. Artif. Intell.},
  title        = {Let me take over: Variable autonomy for meaningful human control},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Balancing performance and human autonomy with implicit
guidance agent. <em>FRAI</em>, <em>4</em>, 736321. (<a
href="https://doi.org/10.3389/frai.2021.736321">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The human-agent team, which is a problem in which humans and autonomous agents collaborate to achieve one task, is typical in human-AI collaboration. For effective collaboration, humans want to have an effective plan, but in realistic situations, they might have difficulty calculating the best plan due to cognitive limitations. In this case, guidance from an agent that has many computational resources may be useful. However, if an agent guides the human behavior explicitly, the human may feel that they have lost autonomy and are being controlled by the agent. We therefore investigated implicit guidance offered by means of an agent’s behavior. With this type of guidance, the agent acts in a way that makes it easy for the human to find an effective plan for a collaborative task, and the human can then improve the plan. Since the human improves their plan voluntarily, he or she maintains autonomy. We modeled a collaborative agent with implicit guidance by integrating the Bayesian Theory of Mind into existing collaborative-planning algorithms and demonstrated through a behavioral experiment that implicit guidance is effective for enabling humans to maintain a balance between improving their plans and retaining autonomy.},
  archive      = {J_FRAI},
  author       = {Nakahashi, Ryo and Yamada, Seiji},
  doi          = {10.3389/frai.2021.736321},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {9},
  pages        = {736321},
  shortjournal = {Front. Artif. Intell.},
  title        = {Balancing performance and human autonomy with implicit guidance agent},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Sentiment analysis of students’ feedback in MOOCs: A
systematic literature review. <em>FRAI</em>, <em>4</em>, 728708. (<a
href="https://doi.org/10.3389/frai.2021.728708">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, sentiment analysis (SA) has gained popularity among researchers in various domains, including the education domain. Particularly, sentiment analysis can be applied to review the course comments in massive open online courses (MOOCs), which could enable instructors to easily evaluate their courses. This article is a systematic literature review on the use of sentiment analysis for evaluating students’ feedback in MOOCs, exploring works published between January 1, 2015, and March 4, 2021. To the best of our knowledge, this systematic review is the first of its kind. We have applied a stepwise PRISMA framework to guide our search process, by searching for studies in six electronic research databases (ACM, IEEE, ScienceDirect, Springer, Scopus, and Web of Science). Our review identified 40 relevant articles out of 440 that were initially found at the first stage. From the reviewed literature, we found that the research has revolved around six areas: MOOC content evaluation, feedback contradiction detection, SA effectiveness, SA through social network posts, understanding course performance and dropouts, and MOOC design model evaluation. In the end, some recommendations are provided and areas for future research directions are identified.},
  archive      = {J_FRAI},
  author       = {Dalipi, Fisnik and Zdravkova, Katerina and Ahlgren, Fredrik},
  doi          = {10.3389/frai.2021.728708},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {9},
  pages        = {728708},
  shortjournal = {Front. Artif. Intell.},
  title        = {Sentiment analysis of students’ feedback in MOOCs: A systematic literature review},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Design implications for explanations: A case study on
supporting reflective assessment of potentially misleading videos.
<em>FRAI</em>, <em>4</em>, 712072. (<a
href="https://doi.org/10.3389/frai.2021.712072">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Online videos have become a prevalent means for people to acquire information. Videos, however, are often polarized, misleading, or contain topics on which people have different, contradictory views. In this work, we introduce natural language explanations to stimulate more deliberate reasoning about videos and raise users’ awareness of potentially deceiving or biased information. With these explanations, we aim to support users in actively deciding and reflecting on the usefulness of the videos. We generate the explanations through an end-to-end pipeline that extracts reflection triggers so users receive additional information to the video based on its source, covered topics, communicated emotions, and sentiment. In a between-subjects user study, we examine the effect of showing the explanations for videos on three controversial topics. Besides, we assess the users’ alignment with the video’s message and how strong their belief is about the topic. Our results indicate that respondents’ alignment with the video’s message is critical to evaluate the video’s usefulness. Overall, the explanations were found to be useful and of high quality. While the explanations do not influence the perceived usefulness of the videos compared to only seeing the video, people with an extreme negative alignment with a video’s message perceived it as less useful (with or without explanations) and felt more confident in their assessment. We relate our findings to cognitive dissonance since users seem to be less receptive to explanations when the video’s message strongly challenges their beliefs. Given these findings, we provide a set of design implications for explanations grounded in theories on reducing cognitive dissonance in light of raising awareness about online deception.},
  archive      = {J_FRAI},
  author       = {Inel, Oana and Duricic, Tomislav and Kaur, Harmanpreet and Lex, Elisabeth and Tintarev, Nava},
  doi          = {10.3389/frai.2021.712072},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {9},
  pages        = {712072},
  shortjournal = {Front. Artif. Intell.},
  title        = {Design implications for explanations: A case study on supporting reflective assessment of potentially misleading videos},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Agent-supported peer collaboration in MOOCs. <em>FRAI</em>,
<em>4</em>, 710856. (<a
href="https://doi.org/10.3389/frai.2021.710856">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While massive open online courses (MOOCs) can be effective in scaling education, orchestrating collaborative learning activities for large audiences remains a non-trivial task that introduces a series of practical challenges, such as the lack of adequate human support. Even when collaboration takes place, there is uncertainty whether meaningful interactions will occur among learners. This work presents the architecture of a prototype system called PeerTalk. The system was created to enable instructors to easily incorporate real-time collaborative learning activities into their online courses. Furthermore, PeerTalk employs a conversational agent service that aims to scaffold students’ online collaboration and provide valuable guidance, which can be configured by the course instructor. In order to investigate the user-acceptance of the system, two evaluation studies took place. The first one involved a group of experts, i.e., MOOC instructors who are expected to use such a system in their course, whereas the second study featured 44 postgraduate students. The study findings were encouraging in terms of the system efficiency and usability levels, laying the foundation for a conversational agent service, which can effectively scale the support of the teaching staff and be easily integrated in MOOC platforms, creating further opportunities for valuable social interaction among learners.},
  archive      = {J_FRAI},
  author       = {Tegos, Stergios and Mavridis, Apostolos and Demetriadis, Stavros},
  doi          = {10.3389/frai.2021.710856},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {9},
  pages        = {710856},
  shortjournal = {Front. Artif. Intell.},
  title        = {Agent-supported peer collaboration in MOOCs},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Enabling training of neural networks on noisy hardware.
<em>FRAI</em>, <em>4</em>, 699148. (<a
href="https://doi.org/10.3389/frai.2021.699148">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neural networks (DNNs) are typically trained using the conventional stochastic gradient descent (SGD) algorithm. However, SGD performs poorly when applied to train networks on non-ideal analog hardware composed of resistive device arrays with non-symmetric conductance modulation characteristics. Recently we proposed a new algorithm, the Tiki-Taka algorithm, that overcomes this stringent symmetry requirement. Here we build on top of Tiki-Taka and describe a more robust algorithm that further relaxes other stringent hardware requirements. This more robust second version of the Tiki-Taka algorithm (referred to as TTv2) 1. decreases the number of device conductance states requirement from 1000s of states to only 10s of states, 2. increases the noise tolerance to the device conductance modulations by about 100x, and 3. increases the noise tolerance to the matrix-vector multiplication performed by the analog arrays by about 10x. Empirical simulation results show that TTv2 can train various neural networks close to their ideal accuracy even at extremely noisy hardware settings. TTv2 achieves these capabilities by complementing the original Tiki-Taka algorithm with lightweight and low computational complexity digital filtering operations performed outside the analog arrays. Therefore, the implementation cost of TTv2 compared to SGD and Tiki-Taka is minimal, and it maintains the usual power and speed benefits of using analog hardware for training workloads. Here we also show how to extract the neural network from the analog hardware once the training is complete for further model deployment. Similar to Bayesian model averaging, we form analog hardware compatible averages over the neural network weights derived from TTv2 iterates. This model average then can be transferred to another analog or digital hardware with notable improvements in test accuracy, transcending the trained model itself. In short, we describe an end-to-end training and model extraction technique for extremely noisy crossbar-based analog hardware that can be used to accelerate DNN training workloads and match the performance of full-precision SGD.},
  archive      = {J_FRAI},
  author       = {Gokmen, Tayfun},
  doi          = {10.3389/frai.2021.699148},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {9},
  pages        = {699148},
  shortjournal = {Front. Artif. Intell.},
  title        = {Enabling training of neural networks on noisy hardware},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Insights into co-morbidity and other risk factors related
to COVID-19 within ontario, canada. <em>FRAI</em>, <em>4</em>, 684609.
(<a href="https://doi.org/10.3389/frai.2021.684609">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The worldwide rapid spread of the severe acute respiratory syndrome coronavirus 2 has affected millions of individuals and caused unprecedented medical challenges by putting healthcare services under high pressure. Given the global increase in number of cases and mortalities due to the current COVID-19 pandemic, it is critical to identify predictive features that assist identification of individuals most at-risk of COVID-19 mortality and thus, enable planning for effective usage of medical resources. The impact of individual variables in an XGBoost artificial intelligence model, applied to a dataset containing 57,390 individual COVID-19 cases and 2,822 patient deaths in Ontario, is explored with the use of SHapley Additive exPlanations values. The most important variables were found to be: age, date of the positive test, sex, income, dementia plus many more that were considered. The utility of SHapley Additive exPlanations dependency graphs is used to provide greater interpretation of the black-box XGBoost mortality prediction model, allowing focus on the non-linear relationships to improve insights. A “Test-date Dependency” plot indicates mortality risk dropped substantially over time, as likely a result of the improved treatment being developed within the medical system. As well, the findings indicate that people of lower income and people from more ethnically diverse communities, face an increased mortality risk due to COVID-19 within Ontario. These findings will help guide clinical decision-making for patients with COVID-19.},
  archive      = {J_FRAI},
  author       = {Snider, Brett and Patel, Bhumi and McBean, Edward},
  doi          = {10.3389/frai.2021.684609},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {9},
  pages        = {684609},
  shortjournal = {Front. Artif. Intell.},
  title        = {Insights into co-morbidity and other risk factors related to COVID-19 within ontario, canada},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The singleton fallacy: Why current critiques of language
models miss the point. <em>FRAI</em>, <em>4</em>, 682578. (<a
href="https://doi.org/10.3389/frai.2021.682578">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper discusses the current critique against neural network-based Natural Language Understanding solutions known as language models. We argue that much of the current debate revolves around an argumentation error that we refer to as the singleton fallacy: the assumption that a concept (in this case, language, meaning, and understanding) refers to a single and uniform phenomenon, which in the current debate is assumed to be unobtainable by (current) language models. By contrast, we argue that positing some form of (mental) “unobtanium” as definiens for understanding inevitably leads to a dualistic position, and that such a position is precisely the original motivation for developing distributional methods in computational linguistics. As such, we argue that language models present a theoretically (and practically) sound approach that is our current best bet for computers to achieve language understanding. This understanding must however be understood as a computational means to an end.},
  archive      = {J_FRAI},
  author       = {Sahlgren, Magnus and Carlsson, Fredrik},
  doi          = {10.3389/frai.2021.682578},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {9},
  pages        = {682578},
  shortjournal = {Front. Artif. Intell.},
  title        = {The singleton fallacy: Why current critiques of language models miss the point},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Data-driven prediction of fatigue in parkinson’s disease
patients. <em>FRAI</em>, <em>4</em>, 678678. (<a
href="https://doi.org/10.3389/frai.2021.678678">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Introduction: Numerous non-motor symptoms are associated with Parkinson’s disease (PD) including fatigue. The challenge in the clinic is to detect relevant non-motor symptoms while keeping patient-burden of questionnaires low and to take potential subgroups such as sex differences into account. The Fatigue Severity Scale (FSS) effectively detects clinically significant fatigue in PD patients. Machine learning techniques can determine which FSS items best predict clinically significant fatigue yet the choice of technique is crucial as it determines the stability of results.Methods: 182 records of PD patients were analyzed with two machine learning algorithms: random forest (RF) and Boruta. RF and Boruta calculated feature importance scores, which measured how much impact an FSS item had in predicting clinically significant fatigue. Items with the highest feature importance scores were the best predictors. Principal components analysis (PCA) grouped highly related FSS items together.Results: RF, Boruta and PCA demonstrated that items 8 (“Fatigue is among my three most disabling symptoms”) and 9 (“Fatigue interferes with my work, family or social life”) were the most important predictors. Item 5 (“Fatigue causes frequent problems for me”) was an important predictor for females, and item 6 (“My fatigue prevents sustained physical functioning”) was important for males. Feature importance scores’ standard deviations were large for RF (14–66%) but small for Boruta (0–5%).Conclusion: The clinically most informative questions may be how disabling fatigue is compared to other symptoms and interference with work, family and friends. There may be some sex-related differences with frequency of fatigue-related complaints in females and endurance-related complaints in males yielding significant information. Boruta but not RF yielded stable results and might be a better tool to determine the most relevant components of abbreviated questionnaires. Further research in this area would be beneficial in order to replicate these findings with other machine learning algorithms, and using a more representative sample of PD patients.},
  archive      = {J_FRAI},
  author       = {Lee, Dong Goo and Lindsay, Adrian and Yu, Adam and Neilson, Samantha and Sundvick, Kristen and Golz, Ella and Foulger, Liam and Mirian, Maryam and Appel-Cresswell, Silke},
  doi          = {10.3389/frai.2021.678678},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {9},
  pages        = {678678},
  shortjournal = {Front. Artif. Intell.},
  title        = {Data-driven prediction of fatigue in parkinson’s disease patients},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Reliable and interpretable mortality prediction with strong
foresight in COVID-19 patients: An international study from china and
germany. <em>FRAI</em>, <em>4</em>, 672050. (<a
href="https://doi.org/10.3389/frai.2021.672050">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cohort-independent robust mortality prediction model in patients with COVID-19 infection is not yet established. To build up a reliable, interpretable mortality prediction model with strong foresight, we have performed an international, bi-institutional study from China (Wuhan cohort, collected from January to March) and Germany (Würzburg cohort, collected from March to September). A Random Forest-based machine learning approach was applied to 1,352 patients from the Wuhan cohort, generating a mortality prediction model based on their clinical features. The results showed that five clinical features at admission, including lymphocyte (%), neutrophil count, C-reactive protein, lactate dehydrogenase, and α-hydroxybutyrate dehydrogenase, could be used for mortality prediction of COVID-19 patients with more than 91% accuracy and 99% AUC. Additionally, the time-series analysis revealed that the predictive model based on these clinical features is very robust over time when patients are in the hospital, indicating the strong association of these five clinical features with the progression of treatment as well. Moreover, for different preexisting diseases, this model also demonstrated high predictive power. Finally, the mortality prediction model has been applied to the independent Würzburg cohort, resulting in high prediction accuracy (with above 90% accuracy and 85% AUC) as well, indicating the robustness of the model in different cohorts. In summary, this study has established the mortality prediction model that allowed early classification of COVID-19 patients, not only at admission but also along the treatment timeline, not only cohort-independent but also highly interpretable. This model represents a valuable tool for triaging and optimizing the resources in COVID-19 patients.},
  archive      = {J_FRAI},
  author       = {Bai, Tao and Zhu, Xue and Zhou, Xiang and Grathwohl, Denise and Yang, Pengshuo and Zha, Yuguo and Jin, Yu and Chong, Hui and Yu, Qingyang and Isberner, Nora and Wang, Dongke and Zhang, Lei and Kortüm, K. Martin and Song, Jun and Rasche, Leo and Einsele, Hermann and Ning, Kang and Hou, Xiaohua},
  doi          = {10.3389/frai.2021.672050},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {9},
  pages        = {672050},
  shortjournal = {Front. Artif. Intell.},
  title        = {Reliable and interpretable mortality prediction with strong foresight in COVID-19 patients: An international study from china and germany},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Application of video-to-video translation networks to
computational fluid dynamics. <em>FRAI</em>, <em>4</em>, 670208. (<a
href="https://doi.org/10.3389/frai.2021.670208">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, the evolution of artificial intelligence, especially deep learning, has been remarkable, and its application to various fields has been growing rapidly. In this paper, I report the results of the application of generative adversarial networks (GANs), specifically video-to-video translation networks, to computational fluid dynamics (CFD) simulations. The purpose of this research is to reduce the computational cost of CFD simulations with GANs. The architecture of GANs in this research is a combination of the image-to-image translation networks (the so-called “pix2pix”) and Long Short-Term Memory (LSTM). It is shown that the results of high-cost and high-accuracy simulations (with high-resolution computational grids) can be estimated from those of low-cost and low-accuracy simulations (with low-resolution grids). In particular, the time evolution of density distributions in the cases of a high-resolution grid is reproduced from that in the cases of a low-resolution grid through GANs, and the density inhomogeneity estimated from the image generated by GANs recovers the ground truth with good accuracy. Qualitative and quantitative comparisons of the results of the proposed method with those of several super-resolution algorithms are also presented.},
  archive      = {J_FRAI},
  author       = {Kigure, Hiromitsu},
  doi          = {10.3389/frai.2021.670208},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {9},
  pages        = {670208},
  shortjournal = {Front. Artif. Intell.},
  title        = {Application of video-to-video translation networks to computational fluid dynamics},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An introduction to topological data analysis: Fundamental
and practical aspects for data scientists. <em>FRAI</em>, <em>4</em>,
667963. (<a href="https://doi.org/10.3389/frai.2021.667963">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the recent explosion in the amount, the variety, and the dimensionality of available data, identifying, extracting, and exploiting their underlying structure has become a problem of fundamental importance for data analysis and statistical learning. Topological data analysis (tda) is a recent and fast-growing field providing a set of new topological and geometric tools to infer relevant features for possibly complex data. It proposes new well-founded mathematical theories and computational tools that can be used independently or in combination with other data analysis and statistical learning techniques. This article is a brief introduction, through a few selected topics, to basic fundamental and practical aspects of tda for nonexperts.},
  archive      = {J_FRAI},
  author       = {Chazal, Frédéric and Michel, Bertrand},
  doi          = {10.3389/frai.2021.667963},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {9},
  pages        = {667963},
  shortjournal = {Front. Artif. Intell.},
  title        = {An introduction to topological data analysis: Fundamental and practical aspects for data scientists},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Advances in completely automated vowel analysis for
sociophonetics: Using end-to-end speech recognition systems with DARLA.
<em>FRAI</em>, <em>4</em>, 662097. (<a
href="https://doi.org/10.3389/frai.2021.662097">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent decades, computational approaches to sociophonetic vowel analysis have been steadily increasing, and sociolinguists now frequently use semi-automated systems for phonetic alignment and vowel formant extraction, including FAVE (Forced Alignment and Vowel Extraction, Rosenfelder et al., 2011; Evanini et al., Proceedings of Interspeech, 2009), Penn Aligner (Yuan and Liberman, J. Acoust. Soc. America, 2008, 123, 3878), and DARLA (Dartmouth Linguistic Automation), (Reddy and Stanford, DARLA Dartmouth Linguistic Automation: Online Tools for Linguistic Research, 2015a). Yet these systems still have a major bottleneck: manual transcription. For most modern sociolinguistic vowel alignment and formant extraction, researchers must first create manual transcriptions. This human step is painstaking, time-consuming, and resource intensive. If this manual step could be replaced with completely automated methods, sociolinguists could potentially tap into vast datasets that have previously been unexplored, including legacy recordings that are underutilized due to lack of transcriptions. Moreover, if sociolinguists could quickly and accurately extract phonetic information from the millions of hours of new audio content posted on the Internet every day, a virtual ocean of speech from newly created podcasts, videos, live-streams, and other audio content would now inform research. How close are the current technological tools to achieving such groundbreaking changes for sociolinguistics? Prior work (Reddy et al., Proceedings of the North American Association for Computational Linguistics 2015 Conference, 2015b, 71–75) showed that an HMM-based Automated Speech Recognition system, trained with CMU Sphinx (Lamere et al., 2003), was accurate enough for DARLA to uncover evidence of the US Southern Vowel Shift without any human transcription. Even so, because that automatic speech recognition (ASR) system relied on a small training set, it produced numerous transcription errors. Six years have passed since that study, and since that time numerous end-to-end automatic speech recognition (ASR) algorithms have shown considerable improvement in transcription quality. One example of such a system is the RNN/CTC-based DeepSpeech from Mozilla (Hannun et al., 2014). (RNN stands for recurrent neural networks, the learning mechanism for DeepSpeech. CTC stands for connectionist temporal classification, the mechanism to merge phones into words). The present paper combines DeepSpeech with DARLA to push the technological envelope and determine how well contemporary ASR systems can perform in completely automated vowel analyses with sociolinguistic goals. Specifically, we used these techniques on audio recordings from 352 North American English speakers in the International Dialects of English Archive (IDEA1), extracting 88,500 tokens of vowels in stressed position from spontaneous, free speech passages. With this large dataset we conducted acoustic sociophonetic analyses of the Southern Vowel Shift and the Northern Cities Chain Shift in the North American IDEA speakers. We compared the results using three different sources of transcriptions: 1) IDEA’s manual transcriptions as the baseline “ground truth”, 2) the ASR built on CMU Sphinx used by Reddy et al. (Proceedings of the North American Association for Computational Linguistics 2015 Conference, 2015b, 71–75), and 3) the latest publicly available Mozilla DeepSpeech system. We input these three different transcriptions to DARLA, which automatically aligned and extracted the vowel formants from the 352 IDEA speakers. Our quantitative results show that newer ASR systems like DeepSpeech show considerable promise for sociolinguistic applications like DARLA. We found that DeepSpeech’s automated transcriptions had significantly fewer character error rates than those from the prior Sphinx system (from 46 to 35%). When we performed the sociolinguistic analysis of the extracted vowel formants from DARLA, we found that the automated transcriptions from DeepSpeech matched the results from the ground truth for the Southern Vowel Shift (SVS): five vowels showed a shift in both transcriptions, and two vowels didn’t show a shift in either transcription. The Northern Cities Shift (NCS) was more difficult to detect, but ground truth and DeepSpeech matched for four vowels: One of the vowels showed a clear shift, and three showed no shift in either transcription. Our study therefore shows how technology has made progress toward greater automation in vowel sociophonetics, while also showing what remains to be done. Our statistical modeling provides a quantified view of both the abilities and the limitations of a completely “hands-free” analysis of vowel shifts in a large dataset. Naturally, when comparing a completely automated system against a semi-automated system involving human manual work, there will always be a tradeoff between accuracy on the one hand versus speed and replicability on the other hand [Kendall and Joseph, Towards best practices in sociophonetics (with Marianna DiPaolo), 2014]. The amount of “noise” that can be tolerated for a given study will depend on the particular research goals and researchers’ preferences. Nonetheless, our study shows that, for certain large-scale applications and research goals, a completely automated approach using publicly available ASR can produce meaningful sociolinguistic results across large datasets, and these results can be generated quickly, efficiently, and with full replicability.},
  archive      = {J_FRAI},
  author       = {Coto-Solano, Rolando and Stanford, James N. and Reddy, Sravana K.},
  doi          = {10.3389/frai.2021.662097},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {9},
  pages        = {662097},
  shortjournal = {Front. Artif. Intell.},
  title        = {Advances in completely automated vowel analysis for sociophonetics: Using end-to-end speech recognition systems with DARLA},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Teaching multiple inverse reinforcement learners.
<em>FRAI</em>, <em>4</em>, 625183. (<a
href="https://doi.org/10.3389/frai.2021.625183">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose the first machine teaching algorithm for multiple inverse reinforcement learners. As our initial contribution, we formalize the problem of optimally teaching a sequential task to a heterogeneous class of learners. We then contribute a theoretical analysis of such problem, identifying conditions under which it is possible to conduct such teaching using the same demonstration for all learners. Our analysis shows that, contrary to other teaching problems, teaching a sequential task to a heterogeneous class of learners with a single demonstration may not be possible, as the differences between individual agents increase. We then contribute two algorithms that address the main difficulties identified by our theoretical analysis. The first algorithm, which we dub SplitTeach, starts by teaching the class as a whole until all students have learned all that they can learn as a group; it then teaches each student individually, ensuring that all students are able to perfectly acquire the target task. The second approach, which we dub JointTeach, selects a single demonstration to be provided to the whole class so that all students learn the target task as well as a single demonstration allows. While SplitTeach ensures optimal teaching at the cost of a bigger teaching effort, JointTeach ensures minimal effort, although the learners are not guaranteed to perfectly recover the target task. We conclude by illustrating our methods in several simulation domains. The simulation results agree with our theoretical findings, showcasing that indeed class teaching is not possible in the presence of heterogeneous students. At the same time, they also illustrate the main properties of our proposed algorithms: in all domains, SplitTeach guarantees perfect teaching and, in terms of teaching effort, is always at least as good as individualized teaching (often better); on the other hand, JointTeach attains minimal teaching effort in all domains, even if sometimes it compromises the teaching performance.},
  archive      = {J_FRAI},
  author       = {Melo, Francisco S. and Lopes, Manuel},
  doi          = {10.3389/frai.2021.625183},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {9},
  pages        = {625183},
  shortjournal = {Front. Artif. Intell.},
  title        = {Teaching multiple inverse reinforcement learners},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). On consensus-optimality trade-offs in collaborative deep
learning. <em>FRAI</em>, <em>4</em>, 573731. (<a
href="https://doi.org/10.3389/frai.2021.573731">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In distributed machine learning, where agents collaboratively learn from diverse private data sets, there is a fundamental tension between consensus and optimality. In this paper, we build on recent algorithmic progresses in distributed deep learning to explore various consensus-optimality trade-offs over a fixed communication topology. First, we propose the incremental consensus-based distributed stochastic gradient descent (i-CDSGD) algorithm, which involves multiple consensus steps (where each agent communicates information with its neighbors) within each SGD iteration. Second, we propose the generalized consensus-based distributed SGD (g-CDSGD) algorithm that enables us to navigate the full spectrum from complete consensus (all agents agree) to complete disagreement (each agent converges to individual model parameters). We analytically establish convergence of the proposed algorithms for strongly convex and nonconvex objective functions; we also analyze the momentum variants of the algorithms for the strongly convex case. We support our algorithms via numerical experiments, and demonstrate significant improvements over existing methods for collaborative deep learning.},
  archive      = {J_FRAI},
  author       = {Jiang, Zhanhong and Balu, Aditya and Hegde, Chinmay and Sarkar, Soumik},
  doi          = {10.3389/frai.2021.573731},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {9},
  pages        = {573731},
  shortjournal = {Front. Artif. Intell.},
  title        = {On consensus-optimality trade-offs in collaborative deep learning},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Biologically-inspired pulse signal processing for
intelligence at the edge. <em>FRAI</em>, <em>4</em>, 568384. (<a
href="https://doi.org/10.3389/frai.2021.568384">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There is an ever-growing mismatch between the proliferation of data-intensive, power-hungry deep learning solutions in the machine learning (ML) community and the need for agile, portable solutions in resource-constrained devices, particularly for intelligence at the edge. In this paper, we present a fundamentally novel approach that leverages data-driven intelligence with biologically-inspired efficiency. The proposed Sparse Embodiment Neural-Statistical Architecture (SENSA) decomposes the learning task into two distinct phases: a training phase and a hardware embedment phase where prototypes are extracted from the trained network and used to construct fast, sparse embodiment for hardware deployment at the edge. Specifically, we propose the Sparse Pulse Automata via Reproducing Kernel (SPARK) method, which first constructs a learning machine in the form of a dynamical system using energy-efficient spike or pulse trains, commonly used in neuroscience and neuromorphic engineering, then extracts a rule-based solution in the form of automata or lookup tables for rapid deployment in edge computing platforms. We propose to use the theoretically-grounded unifying framework of the Reproducing Kernel Hilbert Space (RKHS) to provide interpretable, nonlinear, and nonparametric solutions, compared to the typical neural network approach. In kernel methods, the explicit representation of the data is of secondary nature, allowing the same algorithm to be used for different data types without altering the learning rules. To showcase SPARK’s capabilities, we carried out the first proof-of-concept demonstration on the task of isolated-word automatic speech recognition (ASR) or keyword spotting, benchmarked on the TI-46 digit corpus. Together, these energy-efficient and resource-conscious techniques will bring advanced machine learning solutions closer to the edge.},
  archive      = {J_FRAI},
  author       = {Li, Kan and Príncipe, José C.},
  doi          = {10.3389/frai.2021.568384},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {9},
  pages        = {568384},
  shortjournal = {Front. Artif. Intell.},
  title        = {Biologically-inspired pulse signal processing for intelligence at the edge},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Interlocutors’ age impacts teenagers’ online writing style:
Accommodation in intra- and intergenerational online conversations.
<em>FRAI</em>, <em>4</em>, 738278. (<a
href="https://doi.org/10.3389/frai.2021.738278">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The present study examines how teenagers adapt their language use to that of their conversation partner (i.e., the linguistic phenomenon of accommodation) in interactions with peers (intragenerational communication) and with older interlocutors (intergenerational communication). We analyze a large corpus of Flemish teenagers’ conversations on Facebook Messenger and WhatsApp, which appear to be highly peer-oriented. With Poisson models, we examine whether the teenage participants adjust their writing style to older interlocutors. The same trend emerges for three sets of prototypical markers of the informal online genre: teenagers insert significantly fewer of these markers when interacting with older interlocutors, thus matching their interlocutors’ style and increasing linguistic similarity. Finally, the analyses reveal subtle differences in accommodation patterns for the distinct linguistic variables with respect to the impact of the teenagers’ sociodemographic profiles and their interlocutors’ age.},
  archive      = {J_FRAI},
  author       = {Hilte, Lisa and Daelemans, Walter and Vandekerckhove, Reinhild},
  doi          = {10.3389/frai.2021.738278},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {8},
  pages        = {738278},
  shortjournal = {Front. Artif. Intell.},
  title        = {Interlocutors’ age impacts teenagers’ online writing style: Accommodation in intra- and intergenerational online conversations},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Implementation of a commitment machine for an adaptive and
robust expected shortfall estimation. <em>FRAI</em>, <em>4</em>, 732805.
(<a href="https://doi.org/10.3389/frai.2021.732805">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study proposes a metaheuristic for the selection of models among different Expected Shortfall (ES) estimation methods. The proposed approach, denominated “Commitment Machine” (CM), has a strong focus on assets cross-correlation and allows to measure adaptively the ES, dynamically evaluating which is the most performing method through the minimization of a loss function. The CM algorithm compares four different ES estimation techniques which all take into account the interaction effects among assets: a Bayesian Vector autoregressive model, Stochastic Differential Equation (SDE) numerical schemes with Exponential Weighted Moving Average (EWMA), a Generalized AutoRegressive Conditional Heteroskedasticity (GARCH) volatility model and a hybrid method that integrates Dynamic Recurrent Neural Networks together with a Monte Carlo approach. The integration of traditional Monte Carlo approaches with Machine Learning technologies and the heterogeneity of dynamically selected methodologies lead to an improved estimation of the ES. The study describes the techniques adopted by the CM and the logic behind model selection; moreover, it provides a market application case of the proposed metaheuristic, by simulating an equally weighted multi-asset portfolio.},
  archive      = {J_FRAI},
  author       = {Bagnato, Marco and Bottasso, Anna and Giribone, Pier Giuseppe},
  doi          = {10.3389/frai.2021.732805},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {8},
  pages        = {732805},
  shortjournal = {Front. Artif. Intell.},
  title        = {Implementation of a commitment machine for an adaptive and robust expected shortfall estimation},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). DICE: A drug indication classification and encyclopedia for
AI-based indication extraction. <em>FRAI</em>, <em>4</em>, 711467. (<a
href="https://doi.org/10.3389/frai.2021.711467">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Drug labeling contains an ‘INDICATIONS AND USAGE’ that provides vital information to support clinical decision making and regulatory management. Effective extraction of drug indication information from free-text based resources could facilitate drug repositioning projects and help collect real-world evidence in support of secondary use of approved medicines. To enable AI-powered language models for the extraction of drug indication information, we used manual reading and curation to develop a Drug Indication Classification and Encyclopedia (DICE) based on FDA approved human prescription drug labeling. A DICE scheme with 7,231 sentences categorized into five classes (indications, contradictions, side effects, usage instructions, and clinical observations) was developed. To further elucidate the utility of the DICE, we developed nine different AI-based classifiers for the prediction of indications based on the developed DICE to comprehensively assess their performance. We found that the transformer-based language models yielded an average MCC of 0.887, outperforming the word embedding-based Bidirectional long short-term memory (BiLSTM) models (0.862) with a 2.82% improvement on the test set. The best classifiers were also used to extract drug indication information in DrugBank and achieved a high enrichment rate (&amp;gt;0.930) for this task. We found that domain-specific training could provide more explainable models without performance sacrifices and better generalization for external validation datasets. Altogether, the proposed DICE could be a standard resource for the development and evaluation of task-specific AI-powered, natural language processing (NLP) models.},
  archive      = {J_FRAI},
  author       = {Bhatt, Arjun and Roberts, Ruth and Chen, Xi and Li, Ting and Connor, Skylar and Hatim, Qais and Mikailov, Mike and Tong, Weida and Liu, Zhichao},
  doi          = {10.3389/frai.2021.711467},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {8},
  pages        = {711467},
  shortjournal = {Front. Artif. Intell.},
  title        = {DICE: A drug indication classification and encyclopedia for AI-based indication extraction},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Semantics in high-dimensional space. <em>FRAI</em>,
<em>4</em>, 698809. (<a
href="https://doi.org/10.3389/frai.2021.698809">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Geometric models are used for modelling meaning in various semantic-space models. They are seductive in their simplicity and their imaginative qualities, and for that reason, their metaphorical power risks leading our intuitions astray: human intuition works well in a three-dimensional world but is overwhelmed by higher dimensionalities. This note is intended to warn about some practical pitfalls of using high-dimensional geometric representation as a knowledge representation and a memory model—challenges that can be met by informed design of the representation and its application.},
  archive      = {J_FRAI},
  author       = {Karlgren, Jussi and Kanerva, Pentti},
  doi          = {10.3389/frai.2021.698809},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {8},
  pages        = {698809},
  shortjournal = {Front. Artif. Intell.},
  title        = {Semantics in high-dimensional space},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Text-graph enhanced knowledge graph representation learning.
<em>FRAI</em>, <em>4</em>, 697856. (<a
href="https://doi.org/10.3389/frai.2021.697856">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge Graphs (KGs) such as Freebase and YAGO have been widely adopted in a variety of NLP tasks. Representation learning of Knowledge Graphs (KGs) aims to map entities and relationships into a continuous low-dimensional vector space. Conventional KG embedding methods (such as TransE and ConvE) utilize only KG triplets and thus suffer from structure sparsity. Some recent works address this issue by incorporating auxiliary texts of entities, typically entity descriptions. However, these methods usually focus only on local consecutive word sequences, but seldom explicitly use global word co-occurrence information in a corpus. In this paper, we propose to model the whole auxiliary text corpus with a graph and present an end-to-end text-graph enhanced KG embedding model, named Teger. Specifically, we model the auxiliary texts with a heterogeneous entity-word graph (called text-graph), which entails both local and global semantic relationships among entities and words. We then apply graph convolutional networks to learn informative entity embeddings that aggregate high-order neighborhood information. These embeddings are further integrated with the KG triplet embeddings via a gating mechanism, thus enriching the KG representations and alleviating the inherent structure sparsity. Experiments on benchmark datasets show that our method significantly outperforms several state-of-the-art methods.},
  archive      = {J_FRAI},
  author       = {Hu, Linmei and Zhang, Mengmei and Li, Shaohua and Shi, Jinghan and Shi, Chuan and Yang, Cheng and Liu, Zhiyuan},
  doi          = {10.3389/frai.2021.697856},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {8},
  pages        = {697856},
  shortjournal = {Front. Artif. Intell.},
  title        = {Text-graph enhanced knowledge graph representation learning},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Image completion in embedded space using multistage tensor
ring decomposition. <em>FRAI</em>, <em>4</em>, 687176. (<a
href="https://doi.org/10.3389/frai.2021.687176">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tensor Completion is an important problem in big data processing. Usually, data acquired from different aspects of a multimodal phenomenon or different sensors are incomplete due to different reasons such as noise, low sampling rate or human mistake. In this situation, recovering the missing or uncertain elements of the incomplete dataset is an important step for efficient data processing. In this paper, a new completion approach using Tensor Ring (TR) decomposition in the embedded space has been proposed. In the proposed approach, the incomplete data tensor is first transformed into a higher order tensor using the block Hankelization method. Then the higher order tensor is completed using TR decomposition with rank incremental and multistage strategy. Simulation results show the effectiveness of the proposed approach compared to the state of the art completion algorithms, especially for very high missing ratios and noisy cases.},
  archive      = {J_FRAI},
  author       = {Sedighin, Farnaz and Cichocki, Andrzej},
  doi          = {10.3389/frai.2021.687176},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {8},
  pages        = {687176},
  shortjournal = {Front. Artif. Intell.},
  title        = {Image completion in embedded space using multistage tensor ring decomposition},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Sysrev: A FAIR platform for data curation and systematic
evidence review. <em>FRAI</em>, <em>4</em>, 685298. (<a
href="https://doi.org/10.3389/frai.2021.685298">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Well-curated datasets are essential to evidence based decision making and to the integration of artificial intelligence with human reasoning across disciplines. However, many sources of data remain siloed, unstructured, and/or unavailable for complementary and secondary research. Sysrev was developed to address these issues. First, Sysrev was built to aid in systematic evidence reviews (SER), where digital documents are evaluated according to a well defined process, and where Sysrev provides an easy to access, publicly available and free platform for collaborating in SER projects. Secondly, Sysrev addresses the issue of unstructured, siloed, and inaccessible data in the context of generalized data extraction, where human and machine learning algorithms are combined to extract insights and evidence for better decision making across disciplines. Sysrev uses FAIR - Findability, Accessibility, Interoperability, and Reuse of digital assets - as primary principles in design. Sysrev was developed primarily because of an observed need to reduce redundancy, reduce inefficient use of human time and increase the impact of evidence based decision making. This publication is an introduction to Sysrev as a novel technology, with an overview of the features, motivations and use cases of the tool.Methods: Sysrev. com is a FAIR motivated web platform for data curation and SER. Sysrev allows users to create data curation projects called “sysrevs” wherein users upload documents, define review tasks, recruit reviewers, perform review tasks, and automate review tasks.Conclusion: Sysrev is a web application designed to facilitate data curation and SERs. Thousands of publicly accessible Sysrev projects have been created, accommodating research in a wide variety of disciplines. Described use cases include data curation, managed reviews, and SERs.},
  archive      = {J_FRAI},
  author       = {Bozada, Thomas and Borden, James and Workman, Jeffrey and Del Cid, Mardo and Malinowski, Jennifer and Luechtefeld, Thomas},
  doi          = {10.3389/frai.2021.685298},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {8},
  pages        = {685298},
  shortjournal = {Front. Artif. Intell.},
  title        = {Sysrev: A FAIR platform for data curation and systematic evidence review},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Topological data analysis highlights novel geographical
signatures of the human gut microbiome. <em>FRAI</em>, <em>4</em>,
680564. (<a href="https://doi.org/10.3389/frai.2021.680564">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Background: There is growing interest in the connection between the gut microbiome and human health and disease. Conventional approaches to analyse microbiome data typically entail dimensionality reduction and assume linearity of the observed relationships, however, the microbiome is a highly complex ecosystem marked by non-linear relationships. In this study, we use topological data analysis (TDA) to explore differences and similarities between the gut microbiome across several countries.Methods: We used curated adult microbiome data at the genus level from the GMrepo database. The dataset contains OTU and demographical data of over 4,400 samples from 19 studies, spanning 12 countries. We analysed the data with tmap, an integrative framework for TDA specifically designed for stratification and enrichment analysis of population-based gut microbiome datasets.Results: We find associations between specific microbial genera and groups of countries. Specifically, both the USA and UK were significantly co-enriched with the proinflammatory genera Lachnoclostridium and Ruminiclostridium, while France and New Zealand were co-enriched with other, butyrate-producing, taxa of the order Clostridiales.Conclusion: The TDA approach demonstrates the overlap and distinctions of microbiome composition between and within countries. This yields unique insights into complex associations in the dataset, a finding not possible with conventional approaches. It highlights the potential utility of TDA as a complementary tool in microbiome research, particularly for large population-scale datasets, and suggests further analysis on the effects of diet and other regionally varying factors.},
  archive      = {J_FRAI},
  author       = {Lymberopoulos, Eva and Gentili, Giorgia Isabella and Alomari, Muhannad and Sharma, Nikhil},
  doi          = {10.3389/frai.2021.680564},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {8},
  pages        = {680564},
  shortjournal = {Front. Artif. Intell.},
  title        = {Topological data analysis highlights novel geographical signatures of the human gut microbiome},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Estimation and discriminability of doppler ultrasound fetal
heart rate variability measures. <em>FRAI</em>, <em>4</em>, 674238. (<a
href="https://doi.org/10.3389/frai.2021.674238">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Continuous electronic fetal monitoring and the access to databases of fetal heart rate (FHR) data have sparked the application of machine learning classifiers to identify fetal pathologies. However, most fetal heart rate data are acquired using Doppler ultrasound (DUS). DUS signals use autocorrelation (AC) to estimate the average heartbeat period within a window. In consequence, DUS FHR signals loses high frequency information to an extent that depends on the length of the AC window. We examined the effect of this on the estimation bias and discriminability of frequency domain features: low frequency power (LF: 0.03–0.15 Hz), movement frequency power (MF: 0.15–0.5 Hz), high frequency power (HF: 0.5–1 Hz), the LF/(MF + HF) ratio, and the nonlinear approximate entropy (ApEn) as a function of AC window length and signal to noise ratio. We found that the average discriminability loss across all evaluated AC window lengths and SNRs was 10.99% for LF 14.23% for MF, 13.33% for the HF, 10.39% for the LF/(MF + HF) ratio, and 24.17% for ApEn. This indicates that the frequency domain features are more robust to the AC method and additive noise than the ApEn. This is likely because additive noise increases the irregularity of the signals, which results in an overestimation of ApEn. In conclusion, our study found that the LF features are the most robust to the effects of the AC method and noise. Future studies should investigate the effect of other variables such as signal drop, gestational age, and the length of the analysis window on the estimation of fHRV features and their discriminability.},
  archive      = {J_FRAI},
  author       = {Vargas-Calixto, Johann and Warrick, Philip and Kearney, Robert},
  doi          = {10.3389/frai.2021.674238},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {8},
  pages        = {674238},
  shortjournal = {Front. Artif. Intell.},
  title        = {Estimation and discriminability of doppler ultrasound fetal heart rate variability measures},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Solution of the fokker–planck equation by cross
approximation method in the tensor train format. <em>FRAI</em>,
<em>4</em>, 668215. (<a
href="https://doi.org/10.3389/frai.2021.668215">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose the novel numerical scheme for solution of the multidimensional Fokker–Planck equation, which is based on the Chebyshev interpolation and the spectral differentiation techniques as well as low rank tensor approximations, namely, the tensor train decomposition and the multidimensional cross approximation method, which in combination makes it possible to drastically reduce the number of degrees of freedom required to maintain accuracy as dimensionality increases. We demonstrate the effectiveness of the proposed approach on a number of multidimensional problems, including Ornstein-Uhlenbeck process and the dumbbell model. The developed computationally efficient solver can be used in a wide range of practically significant problems, including density estimation in machine learning applications.},
  archive      = {J_FRAI},
  author       = {Chertkov, Andrei and Oseledets, Ivan},
  doi          = {10.3389/frai.2021.668215},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {8},
  pages        = {668215},
  shortjournal = {Front. Artif. Intell.},
  title        = {Solution of the Fokker–Planck equation by cross approximation method in the tensor train format},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). On topological analysis of fs-LIMS data. Implications for in
situ planetary mass spectrometry. <em>FRAI</em>, <em>4</em>, 668163. (<a
href="https://doi.org/10.3389/frai.2021.668163">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this contribution, we present results of non-linear dimensionality reduction and classification of the fs laser ablation ionization mass spectrometry (LIMS) imaging dataset acquired from the Precambrian Gunflint chert (1.88 Ga) using a miniature time-of-flight mass spectrometer developed for in situ space applications. We discuss the data generation, processing, and analysis pipeline for the classification of the recorded fs-LIMS mass spectra. Further, we define topological biosignatures identified for Precambrian Gunflint microfossils by projecting the recorded fs-LIMS intensity space into low dimensions. Two distinct subtypes of microfossil-related spectra, a layer of organic contamination and inorganic quartz matrix were identified using the fs-LIMS data. The topological analysis applied to the fs-LIMS data allows to gain additional knowledge from large datasets, formulate hypotheses and quickly generate insights from spectral data. Our contribution illustrates the utility of applying spatially resolved mass spectrometry in combination with topology-based analytics in detecting signatures of early (primitive) life. Our results indicate that fs-LIMS, in combination with topological methods, provides a powerful analytical framework and could be applied to the study of other complex mineralogical samples.},
  archive      = {J_FRAI},
  author       = {Lukmanov, Rustam A. and Riedo, Andreas and Wacey, David and Ligterink, Niels F. W. and Grimaudo, Valentine and Tulej, Marek and de Koning, Coenraad and Neubeck, Anna and Wurz, Peter},
  doi          = {10.3389/frai.2021.668163},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {8},
  pages        = {668163},
  shortjournal = {Front. Artif. Intell.},
  title        = {On topological analysis of fs-LIMS data. implications for in situ planetary mass spectrometry},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Cosmic ray background removal with deep neural networks in
SBND. <em>FRAI</em>, <em>4</em>, 649917. (<a
href="https://doi.org/10.3389/frai.2021.649917">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In liquid argon time projection chambers exposed to neutrino beams and running on or near surface levels, cosmic muons, and other cosmic particles are incident on the detectors while a single neutrino-induced event is being recorded. In practice, this means that data from surface liquid argon time projection chambers will be dominated by cosmic particles, both as a source of event triggers and as the majority of the particle count in true neutrino-triggered events. In this work, we demonstrate a novel application of deep learning techniques to remove these background particles by applying deep learning on full detector images from the SBND detector, the near detector in the Fermilab Short-Baseline Neutrino Program. We use this technique to identify, on a pixel-by-pixel level, whether recorded activity originated from cosmic particles or neutrino interactions.},
  archive      = {J_FRAI},
  author       = {Acciarri, R. and Adams, C. and Andreopoulos, C. and Asaadi, J. and Babicz, M. and Backhouse, C. and Badgett, W. and Bagby, L. and Barker, D. and Basque, V. and Bazetto, M. C. Q. and Betancourt, M. and Bhanderi, A. and Bhat, A. and Bonifazi, C. and Brailsford, D. and Brandt, A. G. and Brooks, T. and Carneiro, M. F. and Chen, Y. and Chen, H. and Chisnall, G. and Crespo-Anadón, J. I. and Cristaldo, E. and Cuesta, C. and de Icaza Astiz, I. L. and De Roeck, A. and de Sá Pereira, G. and Del Tutto, M. and Di Benedetto, V. and Ereditato, A. and Evans, J. J. and Ezeribe, A. C. and Fitzpatrick, R. S. and Fleming, B. T. and Foreman, W. and Franco, D. and Furic, I. and Furmanski, A. P. and Gao, S. and Garcia-Gamez, D. and Frandini, H. and Ge, G. and Gil-Botella, I. and Gollapinni, S. and Goodwin, O. and Green, P. and Griffith, W. C. and Guenette, R. and Guzowski, P. and Ham, T. and Henzerling, J. and Holin, A. and Howard, B. and Jones, R. S. and Kalra, D. and Karagiorgi, G. and Kashur, L. and Ketchum, W. and Kim, M. J. and Kudryavtsev, V. A. and Larkin, J. and Lay, H. and Lepetic, I. and Littlejohn, B. R. and Louis, W. C. and Machado, A. A. and Malek, M. and Mardsen, D. and Mariani, C. and Marinho, F. and Mastbaum, A. and Mavrokoridis, K. and McConkey, N. and Meddage, V. and Méndez, D. P. and Mettler, T. and Mistry, K. and Mogan, A. and Molina, J. and Mooney, M. and Mora, L. and Moura, C. A. and Mousseau, J. and Navrer-Agasson, A. and Nicolas-Arnaldos, F. J. and Nowak, J. A. and Palamara, O. and Pandey, V. and Pater, J. and Paulucci, L. and Pimentel, V. L. and Psihas, F. and Putnam, G. and Qian, X. and Raguzin, E. and Ray, H. and Reggiani-Guzzo, M. and Rivera, D. and Roda, M. and Ross-Lonergan, M. and Scanavini, G. and Scarff, A. and Schmitz, D. W. and Schukraft, A. and Segreto, E. and Soares Nunes, M. and Soderberg, M. and Söldner-Rembold, S. and Spitz, J. and Spooner, N. J. C. and Stancari, M. and Stenico, G. V. and Szelc, A. and Tang, W. and Tena Vidal, J. and Torretta, D. and Toups, M. and Touramanis, C. and Tripathi, M. and Tufanli, S. and Tyley, E. and Valdiviesso, G. A. and Worcester, E. and Worcester, M. and Yarbrough, G. and Yu, J. and Zamorano, B. and Zennamo, J. and Zglam, A.},
  doi          = {10.3389/frai.2021.649917},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {8},
  pages        = {649917},
  shortjournal = {Front. Artif. Intell.},
  title        = {Cosmic ray background removal with deep neural networks in SBND},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Ordinal SuStaIn: Subtype and stage inference for clinical
scores, visual ratings, and other ordinal data. <em>FRAI</em>,
<em>4</em>, 613261. (<a
href="https://doi.org/10.3389/frai.2021.613261">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Subtype and Stage Inference (SuStaIn) is an unsupervised learning algorithm that uniquely enables the identification of subgroups of individuals with distinct pseudo-temporal disease progression patterns from cross-sectional datasets. SuStaIn has been used to identify data-driven subgroups and perform patient stratification in neurodegenerative diseases and in lung diseases from continuous biomarker measurements predominantly obtained from imaging. However, the SuStaIn algorithm is not currently applicable to discrete ordinal data, such as visual ratings of images, neuropathological ratings, and clinical and neuropsychological test scores, restricting the applicability of SuStaIn to a narrower range of settings. Here we propose ‘Ordinal SuStaIn’, an ordinal version of the SuStaIn algorithm that uses a scored events model of disease progression to enable the application of SuStaIn to ordinal data. We demonstrate the validity of Ordinal SuStaIn by benchmarking the performance of the algorithm on simulated data. We further demonstrate that Ordinal SuStaIn out-performs the existing continuous version of SuStaIn (Z-score SuStaIn) on discrete scored data, providing much more accurate subtype progression patterns, better subtyping and staging of individuals, and accurate uncertainty estimates. We then apply Ordinal SuStaIn to six different sub-scales of the Clinical Dementia Rating scale (CDR) using data from the Alzheimer’s disease Neuroimaging Initiative (ADNI) study to identify individuals with distinct patterns of functional decline. Using data from 819 ADNI1 participants we identified three distinct CDR subtype progression patterns, which were independently verified using data from 790 ADNI2 participants. Our results provide insight into patterns of decline in daily activities in Alzheimer’s disease and a mechanism for stratifying individuals into groups with difficulties in different domains. Ordinal SuStaIn is broadly applicable across different types of ratings data, including visual ratings from imaging, neuropathological ratings and clinical or behavioural ratings data.},
  archive      = {J_FRAI},
  author       = {Young, Alexandra L. and Vogel, Jacob W. and Aksman, Leon M. and Wijeratne, Peter A. and Eshaghi, Arman and Oxtoby, Neil P. and Williams, Steven C. R. and Alexander, Daniel C. and , for the Alzheimer’s Disease Neuroimaging Initiative},
  doi          = {10.3389/frai.2021.613261},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {8},
  pages        = {613261},
  shortjournal = {Front. Artif. Intell.},
  title        = {Ordinal SuStaIn: Subtype and stage inference for clinical scores, visual ratings, and other ordinal data},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Predicting the disease outcome in COVID-19 positive patients
through machine learning: A retrospective cohort study with brazilian
data. <em>FRAI</em>, <em>4</em>, 579931. (<a
href="https://doi.org/10.3389/frai.2021.579931">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The first officially registered case of COVID-19 in Brazil was on February 26, 2020. Since then, the situation has worsened with more than 672, 000 confirmed cases and at least 36, 000 reported deaths by June 2020. Accurate diagnosis of patients with COVID-19 is extremely important to offer adequate treatment, and avoid overloading the healthcare system. Characteristics of patients such as age, comorbidities and varied clinical symptoms can help in classifying the level of infection severity, predict the disease outcome and the need for hospitalization. Here, we present a study to predict a poor prognosis in positive COVID-19 patients and possible outcomes using machine learning. The study dataset comprises information of 8, 443 patients concerning closed cases due to cure or death. Our experimental results show the disease outcome can be predicted with a Receiver Operating Characteristic AUC of 0.92, Sensitivity of 0.88 and Specificity of 0.82 for the best prediction model. This is a preliminary retrospective study which can be improved with the inclusion of further data. Conclusion: Machine learning techniques fed with demographic and clinical data along with comorbidities of the patients can assist in the prognostic prediction and physician decision-making, allowing a faster response and contributing to the non-overload of healthcare systems.},
  archive      = {J_FRAI},
  author       = {De Souza , Fernanda Sumika Hojo and Hojo-Souza , Natália Satchiko and Dos Santos , Edimilson Batista and Da Silva , Cristiano Maciel and Guidoni , Daniel Ludovico},
  doi          = {10.3389/frai.2021.579931},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {8},
  pages        = {579931},
  shortjournal = {Front. Artif. Intell.},
  title        = {Predicting the disease outcome in COVID-19 positive patients through machine learning: A retrospective cohort study with brazilian data},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The perils of misspecified priors and optional stopping in
multi-armed bandits. <em>FRAI</em>, <em>4</em>, 715690. (<a
href="https://doi.org/10.3389/frai.2021.715690">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The connection between optimal stopping times of American Options and multi-armed bandits is the subject of active research. This article investigates the effects of optional stopping in a particular class of multi-armed bandit experiments, which randomly allocates observations to arms proportional to the Bayesian posterior probability that each arm is optimal (Thompson sampling). The interplay between optional stopping and prior mismatch is examined. We propose a novel partitioning of regret into peri/post testing. We further show a strong dependence of the parameters of interest on the assumed prior probability density.},
  archive      = {J_FRAI},
  author       = {Loecher, Markus},
  doi          = {10.3389/frai.2021.715690},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {7},
  pages        = {715690},
  shortjournal = {Front. Artif. Intell.},
  title        = {The perils of misspecified priors and optional stopping in multi-armed bandits},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Diagnostic accuracy of machine learning models to identify
congenital heart disease: A meta-analysis. <em>FRAI</em>, <em>4</em>,
708365. (<a href="https://doi.org/10.3389/frai.2021.708365">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Background: With the dearth of trained care providers to diagnose congenital heart disease (CHD) and a surge in machine learning (ML) models, this review aims to estimate the diagnostic accuracy of such models for detecting CHD.Methods: A comprehensive literature search in the PubMed, CINAHL, Wiley Cochrane Library, and Web of Science databases was performed. Studies that reported the diagnostic ability of ML for the detection of CHD compared to the reference standard were included. Risk of bias assessment was performed using Quality Assessment for Diagnostic Accuracy Studies-2 tool. The sensitivity and specificity results from the studies were used to generate the hierarchical Summary ROC (HSROC) curve.Results: We included 16 studies (1217 participants) that used ML algorithm to diagnose CHD. Neural networks were used in seven studies with overall sensitivity of 90.9% (95% CI 85.2–94.5%) and specificity was 92.7% (95% CI 86.4–96.2%). Other ML models included ensemble methods, deep learning and clustering techniques but did not have sufficient number of studies for a meta-analysis. Majority (n=11, 69%) of studies had a high risk of patient selection bias, unclear bias on index test (n=9, 56%) and flow and timing (n=12, 75%) while low risk of bias was reported for the reference standard (n=10, 62%).Conclusion: ML models such as neural networks have the potential to diagnose CHD accurately without the need for trained personnel. The heterogeneity of the diagnostic modalities used to train these models and the heterogeneity of the CHD diagnoses included between the studies is a major limitation.},
  archive      = {J_FRAI},
  author       = {Hoodbhoy, Zahra and Jiwani, Uswa and Sattar, Saima and Salam, Rehana and Hasan, Babar and Das, Jai K.},
  doi          = {10.3389/frai.2021.708365},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {7},
  pages        = {708365},
  shortjournal = {Front. Artif. Intell.},
  title        = {Diagnostic accuracy of machine learning models to identify congenital heart disease: A meta-analysis},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Learning systems versus future everyday domestic life: A
designer’s interpretation of social practice imaginaries. <em>FRAI</em>,
<em>4</em>, 707562. (<a
href="https://doi.org/10.3389/frai.2021.707562">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Smart home technologies with the ability to learn over time promise to adjust their actions to inhabitants’ unique preferences and circumstances. For example, by learning to anticipate their routines. However, these promises show frictions with the reality of everyday life, which is characterized by its complexity and unpredictability. These systems and their design can thus benefit from meaningful ways of eliciting reflections on potential challenges for integrating learning systems into everyday domestic contexts, both for the inhabitants of the home as for the technologies and their designers. For example, is there a risk that inhabitants’ everyday lives will reshape to accommodate the learning system’s preference for predictability and measurability? To this end, in this paper we build a designer’s interpretation on the Social Practice Imaginaries method as developed by Strengers et al. to create a set of diverse, plausible imaginaries for the year 2030. As a basis for these imaginaries, we have selected three social practices in a domestic context: waking up, doing groceries, and heating/cooling the home. For each practice, we create one imaginary in which the inhabitants’ routine is flawlessly supported by the learning system and one that features everyday crises of that routine. The resulting social practice imaginaries are then viewed through the perspective of the inhabitant, the learning system, and the designer. In doing so, we aim to enable designers and design researchers to uncover a diverse and dynamic set of implications the integration of these systems in everyday life pose.},
  archive      = {J_FRAI},
  author       = {Viaene, Emilia and Kuijer, Lenneke and Funk, Mathias},
  doi          = {10.3389/frai.2021.707562},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {7},
  pages        = {707562},
  shortjournal = {Front. Artif. Intell.},
  title        = {Learning systems versus future everyday domestic life: A designer’s interpretation of social practice imaginaries},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Human autonomy in future drone traffic: Joint human–AI
control in temporal cognitive work. <em>FRAI</em>, <em>4</em>, 704082.
(<a href="https://doi.org/10.3389/frai.2021.704082">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The roles of human operators are changing due to increased intelligence and autonomy of computer systems. Humans will interact with systems at a more overarching level or only in specific situations. This involves learning new practices and changing habitual ways of thinking and acting, including reconsidering human autonomy in relation to autonomous systems. This paper describes a design case of a future autonomous management system for drone traffic in cities in a key scenario we call The Computer in Brussels. Our approach to designing for human collaboration with autonomous systems builds on scenario-based design and cognitive work analysis facilitated by computer simulations. We use a temporal method, called the Joint Control Framework to describe human and automated work in an abstraction hierarchy labeled Levels of Autonomy in Cognitive Control. We use the Score notation to analyze patterns of temporal developments that span levels of the abstraction hierarchy and discuss implications for human-automation communication in traffic management. We discuss how autonomy at a lower level can prevent autonomy on higher levels, and vice versa. We also discuss the temporal nature of autonomy in minute-to-minute operative work. Our conclusion is that human autonomy in relation to autonomous systems is based on fundamental trade-offs between technological opportunities to automate and values of what human actors find meaningful.},
  archive      = {J_FRAI},
  author       = {Lundberg, Jonas and Arvola, Mattias and Palmerius, Karljohan Lundin},
  doi          = {10.3389/frai.2021.704082},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {7},
  pages        = {704082},
  shortjournal = {Front. Artif. Intell.},
  title        = {Human autonomy in future drone traffic: Joint Human–AI control in temporal cognitive work},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Trust dynamics and verbal assurances in human robot
physical collaboration. <em>FRAI</em>, <em>4</em>, 703504. (<a
href="https://doi.org/10.3389/frai.2021.703504">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Trust is the foundation of successful human collaboration. This has also been found to be true for human-robot collaboration, where trust has also influence on over- and under-reliance issues. Correspondingly, the study of trust in robots is usually concerned with the detection of the current level of the human collaborator trust, aiming at keeping it within certain limits to avoid undesired consequences, which is known as trust calibration. However, while there is intensive research on human-robot trust, there is a lack of knowledge about the factors that affect it in synchronous and co-located teamwork. Particularly, there is hardly any knowledge about how these factors impact the dynamics of trust during the collaboration. These factors along with trust evolvement characteristics are prerequisites for a computational model that allows robots to adapt their behavior dynamically based on the current human trust level, which in turn is needed to enable a dynamic and spontaneous cooperation. To address this, we conducted a two-phase lab experiment in a mixed-reality environment, in which thirty-two participants collaborated with a virtual CoBot on disassembling traction batteries in a recycling context. In the first phase, we explored the (dynamics of) relevant trust factors during physical human-robot collaboration. In the second phase, we investigated the impact of robot’s reliability and feedback on human trust in robots. Results manifest stronger trust dynamics while dissipating than while accumulating and highlight different relevant factors as more interactions occur. Besides, the factors that show relevance as trust accumulates differ from those appear as trust dissipates. We detected four factors while trust accumulates (perceived reliability, perceived dependability, perceived predictability, and faith) which do not appear while it dissipates. This points to an interesting conclusion that depending on the stage of the collaboration and the direction of trust evolvement, different factors might shape trust. Further, the robot’s feedback accuracy has a conditional effect on trust depending on the robot’s reliability level. It preserves human trust when a failure is expected but does not affect it when the robot works reliably. This provides a hint to designers on when assurances are necessary and when they are redundant.},
  archive      = {J_FRAI},
  author       = {Alhaji, Basel and Prilla, Michael and Rausch, Andreas},
  doi          = {10.3389/frai.2021.703504},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {7},
  pages        = {703504},
  shortjournal = {Front. Artif. Intell.},
  title        = {Trust dynamics and verbal assurances in human robot physical collaboration},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Lung cancer segmentation with transfer learning: Usefulness
of a pretrained model constructed from an artificial dataset generated
using a generative adversarial network. <em>FRAI</em>, <em>4</em>,
694815. (<a href="https://doi.org/10.3389/frai.2021.694815">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Purpose: The purpose of this study was to develop and evaluate lung cancer segmentation with a pretrained model and transfer learning. The pretrained model was constructed from an artificial dataset generated using a generative adversarial network (GAN).Materials and Methods: Three public datasets containing images of lung nodules/lung cancers were used: LUNA16 dataset, Decathlon lung dataset, and NSCLC radiogenomics. The LUNA16 dataset was used to generate an artificial dataset for lung cancer segmentation with the help of the GAN and 3D graph cut. Pretrained models were then constructed from the artificial dataset. Subsequently, the main segmentation model was constructed from the pretrained models and the Decathlon lung dataset. Finally, the NSCLC radiogenomics dataset was used to evaluate the main segmentation model. The Dice similarity coefficient (DSC) was used as a metric to evaluate the segmentation performance.Results: The mean DSC for the NSCLC radiogenomics dataset improved overall when using the pretrained models. At maximum, the mean DSC was 0.09 higher with the pretrained model than that without it.Conclusion: The proposed method comprising an artificial dataset and a pretrained model can improve lung cancer segmentation as confirmed in terms of the DSC metric. Moreover, the construction of the artificial dataset for the segmentation using the GAN and 3D graph cut was found to be feasible.},
  archive      = {J_FRAI},
  author       = {Nishio, Mizuho and Fujimoto, Koji and Matsuo, Hidetoshi and Muramatsu, Chisako and Sakamoto, Ryo and Fujita, Hiroshi},
  doi          = {10.3389/frai.2021.694815},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {7},
  pages        = {694815},
  shortjournal = {Front. Artif. Intell.},
  title        = {Lung cancer segmentation with transfer learning: Usefulness of a pretrained model constructed from an artificial dataset generated using a generative adversarial network},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Governing AI in electricity systems: Reflections on the EU
artificial intelligence bill. <em>FRAI</em>, <em>4</em>, 690237. (<a
href="https://doi.org/10.3389/frai.2021.690237">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Proposal for an Artificial Intelligence Act, published by the European Commission in April 2021, marks a major step in the governance of artificial intelligence (AI). This paper examines the significance of this Act for the electricity sector, specifically investigating to what extent the current European Union Bill addresses the societal and governance challenges posed by the use of AI that affects the tasks of system operators. For this we identify various options for the use of AI by system operators, as well as associated risks. AI has the potential to facilitate grid management, flexibility asset management and electricity market activities. Associated risks include lack of transparency, decline of human autonomy, cybersecurity, market dominance, and price manipulation on the electricity market. We determine to what extent the current bill pays attention to these identified risks and how the European Union intends to govern these risks. The proposed AI Act addresses well the issue of transparency and clarifying responsibilities, but pays too little attention to risks related to human autonomy, cybersecurity, market dominance and price manipulation. We make some governance suggestions to address those gaps.},
  archive      = {J_FRAI},
  author       = {Niet, Irene and van Est, Rinie and Veraart, Frank},
  doi          = {10.3389/frai.2021.690237},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {7},
  pages        = {690237},
  shortjournal = {Front. Artif. Intell.},
  title        = {Governing AI in electricity systems: Reflections on the EU artificial intelligence bill},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A comparative study of machine learning methods for
persistence diagrams. <em>FRAI</em>, <em>4</em>, 681174. (<a
href="https://doi.org/10.3389/frai.2021.681174">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many and varied methods currently exist for featurization, which is the process of mapping persistence diagrams to Euclidean space, with the goal of maximally preserving structure. However, and to our knowledge, there are presently no methodical comparisons of existing approaches, nor a standardized collection of test data sets. This paper provides a comparative study of several such methods. In particular, we review, evaluate, and compare the stable multi-scale kernel, persistence landscapes, persistence images, the ring of algebraic functions, template functions, and adaptive template systems. Using these approaches for feature extraction, we apply and compare popular machine learning methods on five data sets: MNIST, Shape retrieval of non-rigid 3D Human Models (SHREC14), extracts from the Protein Classification Benchmark Collection (Protein), MPEG7 shape matching, and HAM10000 skin lesion data set. These data sets are commonly used in the above methods for featurization, and we use them to evaluate predictive utility in real-world applications.},
  archive      = {J_FRAI},
  author       = {Barnes, Danielle and Polanco, Luis and Perea, Jose A.},
  doi          = {10.3389/frai.2021.681174},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {7},
  pages        = {681174},
  shortjournal = {Front. Artif. Intell.},
  title        = {A comparative study of machine learning methods for persistence diagrams},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Users’ responsiveness to persuasive techniques in
recommender systems. <em>FRAI</em>, <em>4</em>, 679459. (<a
href="https://doi.org/10.3389/frai.2021.679459">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Understanding user’s behavior and their interactions with artificial-intelligent-based systems is as important as analyzing the performance of the algorithms used in these systems. For instance, in the Recommender Systems domain, the accuracy of the recommendation algorithm was the ultimate goal for most systems designers. However, researchers and practitioners have realized that providing accurate recommendations is insufficient to enhance users’ acceptance. A recommender system needs to focus on other factors that enhance its interactions with the users. Recent researches suggest augmenting these systems with persuasive capabilities. Persuasive features lead to increasing users’ acceptance of the recommendations, which, in turn, enhances users’ experience with these systems. Nonetheless, the literature still lacks a comprehensive view of the actual effect of persuasive principles on recommender users. To fill this gap, this study diagnoses how users of different characteristics get influenced by various persuasive principles that a recommender system uses. The study considers four users’ aspects: age, gender, culture (continent), and personality traits. The paper also investigates the impact of the context (or application domain) on the influence of the persuasive principles. Two application domains (namely eCommerce and Movie recommendations) are considered. A within-subject user study was conducted. The analysis of (279) responses revealed that persuasive principles have the potential to enhance users’ experience with recommender systems. The study also shows that, among the considered factors, culture, personality traits, and the domain of recommendations have a higher impact on the influence of persuasive principles than other factors. Based on the analysis of the results, the study provides insights and guidelines for recommender systems designers. These guidelines can be used as a reference for designing recommender systems with users’ experience in mind. We suggest that considering the results presented in this paper could help to improve recommender-users interaction.},
  archive      = {J_FRAI},
  author       = {Alslaity, Alaa and Tran, Thomas},
  doi          = {10.3389/frai.2021.679459},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {7},
  pages        = {679459},
  shortjournal = {Front. Artif. Intell.},
  title        = {Users’ responsiveness to persuasive techniques in recommender systems},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Ps and qs: Quantization-aware pruning for efficient low
latency neural network inference. <em>FRAI</em>, <em>4</em>, 676564. (<a
href="https://doi.org/10.3389/frai.2021.676564">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Efficient machine learning implementations optimized for inference in hardware have wide-ranging benefits, depending on the application, from lower inference latency to higher data throughput and reduced energy consumption. Two popular techniques for reducing computation in neural networks are pruning, removing insignificant synapses, and quantization, reducing the precision of the calculations. In this work, we explore the interplay between pruning and quantization during the training of neural networks for ultra low latency applications targeting high energy physics use cases. Techniques developed for this study have potential applications across many other domains. We study various configurations of pruning during quantization-aware training, which we term quantization-aware pruning, and the effect of techniques like regularization, batch normalization, and different pruning schemes on performance, computational complexity, and information content metrics. We find that quantization-aware pruning yields more computationally efficient models than either pruning or quantization alone for our task. Further, quantization-aware pruning typically performs similar to or better in terms of computational efficiency compared to other neural architecture search techniques like Bayesian optimization. Surprisingly, while networks with different training configurations can have similar performance for the benchmark application, the information content in the network can vary significantly, affecting its generalizability.},
  archive      = {J_FRAI},
  author       = {Hawks, Benjamin and Duarte, Javier and Fraser, Nicholas J. and Pappalardo, Alessandro and Tran, Nhan and Umuroglu, Yaman},
  doi          = {10.3389/frai.2021.676564},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {7},
  pages        = {676564},
  shortjournal = {Front. Artif. Intell.},
  title        = {Ps and qs: Quantization-aware pruning for efficient low latency neural network inference},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Kernelized heterogeneity-aware cross-view face recognition.
<em>FRAI</em>, <em>4</em>, 670538. (<a
href="https://doi.org/10.3389/frai.2021.670538">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cross-view or heterogeneous face matching involves comparing two different views of the face modality such as two different spectrums or resolutions. In this research, we present two heterogeneity-aware subspace techniques, heterogeneous discriminant analysis (HDA) and its kernel version (KHDA) that encode heterogeneity in the objective function and yield a suitable projection space for improved performance. They can be applied on any feature to make it heterogeneity invariant. We next propose a face recognition framework that uses existing facial features along with HDA/KHDA for matching. The effectiveness of HDA and KHDA is demonstrated using both handcrafted and learned representations on three challenging heterogeneous cross-view face recognition scenarios: (i) visible to near-infrared matching, (ii) cross-resolution matching, and (iii) digital photo to composite sketch matching. It is observed that, consistently in all the case studies, HDA and KHDA help to reduce the heterogeneity variance, clearly evidenced in the improved results. Comparison with recent heterogeneous matching algorithms shows that HDA- and KHDA-based matching yields state-of-the-art or comparable results on all three case studies. The proposed algorithms yield the best rank-1 accuracy of 99.4% on the CASIA NIR-VIS 2.0 database, up to 100% on the CMU Multi-PIE for different resolutions, and 95.2% rank-10 accuracies on the e-PRIP database for digital to composite sketch matching.},
  archive      = {J_FRAI},
  author       = {Dhamecha, Tejas I. and Ghosh, Soumyadeep and Vatsa, Mayank and Singh, Richa},
  doi          = {10.3389/frai.2021.670538},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {7},
  pages        = {670538},
  shortjournal = {Front. Artif. Intell.},
  title        = {Kernelized heterogeneity-aware cross-view face recognition},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Are we there yet? - a systematic literature review on
chatbots in education. <em>FRAI</em>, <em>4</em>, 654924. (<a
href="https://doi.org/10.3389/frai.2021.654924">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Chatbots are a promising technology with the potential to enhance workplaces and everyday life. In terms of scalability and accessibility, they also offer unique possibilities as communication and information tools for digital learning. In this paper, we present a systematic literature review investigating the areas of education where chatbots have already been applied, explore the pedagogical roles of chatbots, the use of chatbots for mentoring purposes, and their potential to personalize education. We conducted a preliminary analysis of 2,678 publications to perform this literature review, which allowed us to identify 74 relevant publications for chatbots’ application in education. Through this, we address five research questions that, together, allow us to explore the current state-of-the-art of this educational technology. We conclude our systematic review by pointing to three main research challenges: 1) Aligning chatbot evaluations with implementation objectives, 2) Exploring the potential of chatbots for mentoring students, and 3) Exploring and leveraging adaptation capabilities of chatbots. For all three challenges, we discuss opportunities for future research.},
  archive      = {J_FRAI},
  author       = {Wollny, Sebastian and Schneider, Jan and Di Mitri, Daniele and Weidlich, Joshua and Rittberger, Marc and Drachsler, Hendrik},
  doi          = {10.3389/frai.2021.654924},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {7},
  pages        = {654924},
  shortjournal = {Front. Artif. Intell.},
  title        = {Are we there yet? - a systematic literature review on chatbots in education},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Perception in black and white: Effects of intonational
variables and filtering conditions on sociolinguistic judgments with
implications for ASR. <em>FRAI</em>, <em>4</em>, 642783. (<a
href="https://doi.org/10.3389/frai.2021.642783">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study tests the effects of intonational contours and filtering conditions on listener judgments of ethnicity to arrive at a more comprehensive understanding on how prosody influences these judgments, with implications for austomatic speech recognition systems as well as speech synthesis. In a perceptual experiment, 40 American English listeners heard phrase-long clips which were controlled for pitch accent type and focus marking. Each clip contained either two H* (high) or two L+H* (low high) pitch accents and a L-L% (falling) boundary tone, and had also previously been labelled for broad or narrow focus. Listeners rated clips in two tasks, one with unmodified stimuli and one with stimuli lowpass filtered at 400 Hz, and were asked to judge whether the speaker was “Black” or “White”. In the filtered condition, tokens with the L+H* pitch accent were more likely to be rated as “Black”, with an interaction such that broad focus enhanced this pattern, supporting earlier findings that listeners may perceive African American Language as having more variation in possible pitch accent meanings. In the unfiltered condition, tokens with the L+H* pitch accent were less likely to be rated as Black, with no effect of focus, likely due to the fact that listeners relied more heavily on available segmental information in this condition. These results enhance our understanding of cues listeners rely on in making social judgments about speakers, especially in ethnic identification and linguistic profiling, by highlighting perceptual differences due to listening environment as well as predicted meaning of specific intonational contours. They also contribute to our understanding of the role of how human listeners interpret meaning within a holistic context, which has implications for the construction of computational systems designed to replicate the properties of natural language. In particular, they have important applicability to speech synthesis and speech recognition programs, which are often limited in their capacities due to the fact that they do not make such holistic sociolinguistic considerations of the meanings of input or output speech.},
  archive      = {J_FRAI},
  author       = {Holliday, Nicole R.},
  doi          = {10.3389/frai.2021.642783},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {7},
  pages        = {642783},
  shortjournal = {Front. Artif. Intell.},
  title        = {Perception in black and white: Effects of intonational variables and filtering conditions on sociolinguistic judgments with implications for ASR},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Rule extraction from binary neural networks with
convolutional rules for model validation. <em>FRAI</em>, <em>4</em>,
642263. (<a href="https://doi.org/10.3389/frai.2021.642263">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Classification approaches that allow to extract logical rules such as decision trees are often considered to be more interpretable than neural networks. Also, logical rules are comparatively easy to verify with any possible input. This is an important part in systems that aim to ensure correct operation of a given model. However, for high-dimensional input data such as images, the individual symbols, i.e. pixels, are not easily interpretable. Therefore, rule-based approaches are not typically used for this kind of high-dimensional data. We introduce the concept of first-order convolutional rules, which are logical rules that can be extracted using a convolutional neural network (CNN), and whose complexity depends on the size of the convolutional filter and not on the dimensionality of the input. Our approach is based on rule extraction from binary neural networks with stochastic local search. We show how to extract rules that are not necessarily short, but characteristic of the input, and easy to visualize. Our experiments show that the proposed approach is able to model the functionality of the neural network while at the same time producing interpretable logical rules. Thus, we demonstrate the potential of rule-based approaches for images which allows to combine advantages of neural networks and rule learning.},
  archive      = {J_FRAI},
  author       = {Burkhardt, Sophie and Brugger, Jannis and Wagner, Nicolas and Ahmadi, Zahra and Kersting, Kristian and Kramer, Stefan},
  doi          = {10.3389/frai.2021.642263},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {7},
  pages        = {642263},
  shortjournal = {Front. Artif. Intell.},
  title        = {Rule extraction from binary neural networks with convolutional rules for model validation},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Corrigendum: A frequency-domain machine learning method for
dual-calibrated fMRI mapping of oxygen extraction fraction (OEF) and
cerebral metabolic rate of oxygen consumption (CMRO2). <em>FRAI</em>,
<em>4</em>, 614245. (<a
href="https://doi.org/10.3389/frai.2021.614245">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Germuska, Michael and Chandler, Hannah Louise and Okell, Thomas and Fasano, Fabrizio and Tomassini, Valentina and Murphy, Kevin and Wise, Richard G.},
  doi          = {10.3389/frai.2021.614245},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {7},
  pages        = {614245},
  shortjournal = {Front. Artif. Intell.},
  title        = {Corrigendum: A frequency-domain machine learning method for dual-calibrated fMRI mapping of oxygen extraction fraction (OEF) and cerebral metabolic rate of oxygen consumption (CMRO2)},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). AI-empowered computational examination of chest imaging for
COVID-19 treatment: A review. <em>FRAI</em>, <em>4</em>, 612914. (<a
href="https://doi.org/10.3389/frai.2021.612914">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Since the first case of coronavirus disease 2019 (COVID-19) was discovered in December 2019, COVID-19 swiftly spread over the world. By the end of March 2021, more than 136 million patients have been infected. Since the second and third waves of the COVID-19 outbreak are in full swing, investigating effective and timely solutions for patients’ check-ups and treatment is important. Although the SARS-CoV-2 virus-specific reverse transcription polymerase chain reaction test is recommended for the diagnosis of COVID-19, the test results are prone to be false negative in the early course of COVID-19 infection. To enhance the screening efficiency and accessibility, chest images captured via X-ray or computed tomography (CT) provide valuable information when evaluating patients with suspected COVID-19 infection. With advanced artificial intelligence (AI) techniques, AI-driven models training with lung scans emerge as quick diagnostic and screening tools for detecting COVID-19 infection in patients. In this article, we provide a comprehensive review of state-of-the-art AI-empowered methods for computational examination of COVID-19 patients with lung scans. In this regard, we searched for papers and preprints on bioRxiv, medRxiv, and arXiv published for the period from January 1, 2020, to March 31, 2021, using the keywords of COVID, lung scans, and AI. After the quality screening, 96 studies are included in this review. The reviewed studies were grouped into three categories based on their target application scenarios: automatic detection of coronavirus disease, infection segmentation, and severity assessment and prognosis prediction. The latest AI solutions to process and analyze chest images for COVID-19 treatment and their advantages and limitations are presented. In addition to reviewing the rapidly developing techniques, we also summarize publicly accessible lung scan image sets. The article ends with discussions of the challenges in current research and potential directions in designing effective computational solutions to fight against the COVID-19 pandemic in the future.},
  archive      = {J_FRAI},
  author       = {Deng, Hanqiu and Li, Xingyu},
  doi          = {10.3389/frai.2021.612914},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {7},
  pages        = {612914},
  shortjournal = {Front. Artif. Intell.},
  title        = {AI-empowered computational examination of chest imaging for COVID-19 treatment: A review},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Radical knowledge management: Using lessons learned from
artists to create sustainable workplaces. <em>FRAI</em>, <em>4</em>,
598807. (<a href="https://doi.org/10.3389/frai.2021.598807">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study weaves together research that has been published over the last 20 years and creates a narrative about how we can change our organisations so that they are fit-for-purpose in the 21st century. Using knowledge management as the starting point, the question “How do we move forward in a sustainable, holistic way to create organisations that are healthy and balanced among social, environmental, and financial performance (triple bottom line)?” needs to be answered. This brand new form of knowledge management is called radical knowledge management (radical KM).},
  archive      = {J_FRAI},
  author       = {Barnes, Stephanie},
  doi          = {10.3389/frai.2021.598807},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {7},
  pages        = {598807},
  shortjournal = {Front. Artif. Intell.},
  title        = {Radical knowledge management: Using lessons learned from artists to create sustainable workplaces},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). AI-assisted CT as a clinical and research tool for COVID-19.
<em>FRAI</em>, <em>4</em>, 590189. (<a
href="https://doi.org/10.3389/frai.2021.590189">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There is compelling support for widening the role of computed tomography (CT) for COVID-19 in clinical and research scenarios. Reverse transcription polymerase chain reaction (RT-PCR) testing, the gold standard for COVID-19 diagnosis, has two potential weaknesses: the delay in obtaining results and the possibility of RT-PCR test kits running out when demand spikes or being unavailable altogether. This perspective article discusses the potential use of CT in conjunction with RT-PCR in hospitals lacking sufficient access to RT-PCR test kits. The precedent for this approach is discussed based on the use of CT for COVID-19 diagnosis and screening in the United Kingdom and China. The hurdles and challenges are presented, which need addressing prior to realization of the potential roles for CT artificial intelligence (AI). The potential roles include a more accurate clinical classification, characterization for research roles and mechanisms, and informing clinical trial response criteria as a surrogate for clinical outcomes.},
  archive      = {J_FRAI},
  author       = {Tse, Zion Tsz Ho and Hovet, Sierra and Ren, Hongliang and Barrett, Tristan and Xu, Sheng and Turkbey, Baris and Wood, Bradford J.},
  doi          = {10.3389/frai.2021.590189},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {7},
  pages        = {590189},
  shortjournal = {Front. Artif. Intell.},
  title        = {AI-assisted CT as a clinical and research tool for COVID-19},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Editorial: Probabilistic perspectives on brain
(dys)function. <em>FRAI</em>, <em>4</em>, 710179. (<a
href="https://doi.org/10.3389/frai.2021.710179">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Parr, Thomas and Marković, Dimitrije and Ramstead, Maxwell James D. and Smith, Ryan and Hesp, Casper and Friston, Karl},
  doi          = {10.3389/frai.2021.710179},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {6},
  pages        = {710179},
  shortjournal = {Front. Artif. Intell.},
  title        = {Editorial: Probabilistic perspectives on brain (Dys)function},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A united states fair lending perspective on machine
learning. <em>FRAI</em>, <em>4</em>, 695301. (<a
href="https://doi.org/10.3389/frai.2021.695301">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The use of machine learning (ML) has become more widespread in many areas of consumer financial services, including credit underwriting and pricing of loans. ML’s ability to automatically learn nonlinearities and interactions in training data is perceived to facilitate faster and more accurate credit decisions, and ML is now a viable challenger to traditional credit modeling methodologies. In this mini review, we further the discussion of ML in consumer finance by proposing uniform definitions of key ML and legal concepts related to discrimination and interpretability. We use the United States legal and regulatory environment as a foundation to add critical context to the broader discussion of relevant, substantial, and novel ML methodologies in credit underwriting, and we review numerous strategies to mitigate the many potential adverse implications of ML in consumer finance.},
  archive      = {J_FRAI},
  author       = {Hall, Patrick and Cox, Benjamin and Dickerson, Steven and Ravi Kannan, Arjun and Kulkarni, Raghu and Schmidt, Nicholas},
  doi          = {10.3389/frai.2021.695301},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {6},
  pages        = {695301},
  shortjournal = {Front. Artif. Intell.},
  title        = {A united states fair lending perspective on machine learning},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Deep learning–based COVID-19 pneumonia classification using
chest CT images: Model generalizability. <em>FRAI</em>, <em>4</em>,
694875. (<a href="https://doi.org/10.3389/frai.2021.694875">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Since the outbreak of the COVID-19 pandemic, worldwide research efforts have focused on using artificial intelligence (AI) technologies on various medical data of COVID-19–positive patients in order to identify or classify various aspects of the disease, with promising reported results. However, concerns have been raised over their generalizability, given the heterogeneous factors in training datasets. This study aims to examine the severity of this problem by evaluating deep learning (DL) classification models trained to identify COVID-19–positive patients on 3D computed tomography (CT) datasets from different countries. We collected one dataset at UT Southwestern (UTSW) and three external datasets from different countries: CC-CCII Dataset (China), COVID-CTset (Iran), and MosMedData (Russia). We divided the data into two classes: COVID-19–positive and COVID-19–negative patients. We trained nine identical DL-based classification models by using combinations of datasets with a 72% train, 8% validation, and 20% test data split. The models trained on a single dataset achieved accuracy/area under the receiver operating characteristic curve (AUC) values of 0.87/0.826 (UTSW), 0.97/0.988 (CC-CCCI), and 0.86/0.873 (COVID-CTset) when evaluated on their own dataset. The models trained on multiple datasets and evaluated on a test set from one of the datasets used for training performed better. However, the performance dropped close to an AUC of 0.5 (random guess) for all models when evaluated on a different dataset outside of its training datasets. Including MosMedData, which only contained positive labels, into the training datasets did not necessarily help the performance of other datasets. Multiple factors likely contributed to these results, such as patient demographics and differences in image acquisition or reconstruction, causing a data shift among different study cohorts.},
  archive      = {J_FRAI},
  author       = {Nguyen, Dan and Kay, Fernando and Tan, Jun and Yan, Yulong and Ng, Yee Seng and Iyengar, Puneeth and Peshock, Ron and Jiang, Steve},
  doi          = {10.3389/frai.2021.694875},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {6},
  pages        = {694875},
  shortjournal = {Front. Artif. Intell.},
  title        = {Deep Learning–Based COVID-19 pneumonia classification using chest CT images: Model generalizability},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Employing explainable AI to optimize the return target
function of a loan portfolio. <em>FRAI</em>, <em>4</em>, 693022. (<a
href="https://doi.org/10.3389/frai.2021.693022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the recent years, data science methods have been developed considerably and have consequently found their way into many business processes in banking and finance. One example is the review and approval process of credit applications where they are employed with the aim to reduce rare but costly credit defaults in portfolios of loans. But there are challenges. Since defaults are rare events, it is—even with machine learning (ML) techniques—difficult to improve prediction accuracy and improvements are often marginal. Furthermore, while from an event prediction point of view, a non-default is the same as a default, from an economic point of view much more relevant to the end user it is not due to the high asymmetry in cost. Last, there are regulatory constraints when it comes to the adoption of advanced ML, hence the call for explainable artificial intelligence (XAI) issued by regulatory bodies like FINMA and BaFin. In our study, we will address these challenges. In particular, based on an exemplary use case, we show how ML methods can be adapted to the specific needs of credit assessment and how, in the case of strongly asymmetric costs of wrong forecasts, it makes sense to optimize not for accuracy but for an economic target function. We showcase this for two simple and ad hoc explainable ML algorithms, finding that in the case of credit approval, surprisingly high rejection rates contribute to maximizing profit.},
  archive      = {J_FRAI},
  author       = {Gramespacher, Thomas and Posth, Jan-Alexander},
  doi          = {10.3389/frai.2021.693022},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {6},
  pages        = {693022},
  shortjournal = {Front. Artif. Intell.},
  title        = {Employing explainable AI to optimize the return target function of a loan portfolio},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Digital slide assessment for programmed death-ligand 1
combined positive score in head and neck squamous carcinoma: Focus on
validation and vision. <em>FRAI</em>, <em>4</em>, 684034. (<a
href="https://doi.org/10.3389/frai.2021.684034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Eccher, Albino and Girolami, Ilaria and Troncone, Giancarlo and Pantanowitz, Liron},
  doi          = {10.3389/frai.2021.684034},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {6},
  pages        = {684034},
  shortjournal = {Front. Artif. Intell.},
  title        = {Digital slide assessment for programmed death-ligand 1 combined positive score in head and neck squamous carcinoma: Focus on validation and vision},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Symptom prediction and mortality risk calculation for
COVID-19 using machine learning. <em>FRAI</em>, <em>4</em>, 673527. (<a
href="https://doi.org/10.3389/frai.2021.673527">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Background: Early prediction of symptoms and mortality risks for COVID-19 patients would improve healthcare outcomes, allow for the appropriate distribution of healthcare resources, reduce healthcare costs, aid in vaccine prioritization and self-isolation strategies, and thus reduce the prevalence of the disease. Such publicly accessible prediction models are lacking, however.Methods: Based on a comprehensive evaluation of existing machine learning (ML) methods, we created two models based solely on the age, gender, and medical histories of 23,749 hospital-confirmed COVID-19 patients from February to September 2020: a symptom prediction model (SPM) and a mortality prediction model (MPM). The SPM predicts 12 symptom groups for each patient: respiratory distress, consciousness disorders, chest pain, paresis or paralysis, cough, fever or chill, gastrointestinal symptoms, sore throat, headache, vertigo, loss of smell or taste, and muscular pain or fatigue. The MPM predicts the death of COVID-19-positive individuals.Results: The SPM yielded ROC-AUCs of 0.53–0.78 for symptoms. The most accurate prediction was for consciousness disorders at a sensitivity of 74% and a specificity of 70%. 2,440 deaths were observed in the study population. MPM had a ROC-AUC of 0.79 and could predict mortality with a sensitivity of 75% and a specificity of 70%. About 90% of deaths occurred in the top 21 percentile of risk groups. To allow patients and clinicians to use these models easily, we created a freely accessible online interface at www.aicovid.net.Conclusion: The ML models predict COVID-19-related symptoms and mortality using information that is readily available to patients as well as clinicians. Thus, both can rapidly estimate the severity of the disease, allowing shared and better healthcare decisions with regard to hospitalization, self-isolation strategy, and COVID-19 vaccine prioritization in the coming months.},
  archive      = {J_FRAI},
  author       = {Jamshidi, Elham and Asgary, Amirhossein and Tavakoli, Nader and Zali, Alireza and Dastan, Farzaneh and Daaee, Amir and Badakhshan, Mohammadtaghi and Esmaily, Hadi and Jamaldini, Seyed Hamid and Safari, Saeid and Bastanhagh, Ehsan and Maher, Ali and Babajani, Amirhesam and Mehrazi, Maryam and Sendani Kashi, Mohammad Ali and Jamshidi, Masoud and Sendani, Mohammad Hassan and Rahi, Sahand Jamal and Mansouri, Nahal},
  doi          = {10.3389/frai.2021.673527},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {6},
  pages        = {673527},
  shortjournal = {Front. Artif. Intell.},
  title        = {Symptom prediction and mortality risk calculation for COVID-19 using machine learning},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Emulation of cosmological mass maps with conditional
generative adversarial networks. <em>FRAI</em>, <em>4</em>, 673062. (<a
href="https://doi.org/10.3389/frai.2021.673062">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Weak gravitational lensing mass maps play a crucial role in understanding the evolution of structures in the Universe and our ability to constrain cosmological models. The prediction of these mass maps is based on expensive N-body simulations, which can create a computational bottleneck for cosmological analyses. Simulation-based emulators of map summary statistics, such as the matter power spectrum and its covariance, are starting to play increasingly important role, as the analytical predictions are expected to reach their precision limits for upcoming experiments. Creating an emulator of the cosmological mass maps themselves, rather than their summary statistics, is a more challenging task. Modern deep generative models, such as Generative Adversarial Networks (GAN), have demonstrated their potential to achieve this goal. Most existing GAN approaches produce simulations for a fixed value of the cosmological parameters, which limits their practical applicability. We propose a novel conditional GAN model that is able to generate mass maps for any pair of matter density Ωm and matter clustering strength σ8, parameters which have the largest impact on the evolution of structures in the Universe, for a given source galaxy redshift distribution n(z). Our results show that our conditional GAN can interpolate efficiently within the space of simulated cosmologies, and generate maps anywhere inside this space with good visual quality high statistical accuracy. We perform an extensive quantitative comparison of the N-body and GAN -generated maps using a range of metrics: the pixel histograms, peak counts, power spectra, bispectra, Minkowski functionals, correlation matrices of the power spectra, the Multi-Scale Structural Similarity Index (MS-SSIM) and our equivalent of the Fréchet Inception Distance. We find a very good agreement on these metrics, with typical differences are &amp;lt;5% at the center of the simulation grid, and slightly worse for cosmologies at the grid edges. The agreement for the bispectrum is slightly worse, on the &amp;lt;20% level. This contribution is a step toward building emulators of mass maps directly, capturing both the cosmological signal and its variability. We make the code1 and the data2 publicly available.},
  archive      = {J_FRAI},
  author       = {Perraudin, Nathanaël and Marcon, Sandro and Lucchi, Aurelien and Kacprzak, Tomasz},
  doi          = {10.3389/frai.2021.673062},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {6},
  pages        = {673062},
  shortjournal = {Front. Artif. Intell.},
  title        = {Emulation of cosmological mass maps with conditional generative adversarial networks},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Topological data analysis of c. Elegans locomotion and
behavior. <em>FRAI</em>, <em>4</em>, 668395. (<a
href="https://doi.org/10.3389/frai.2021.668395">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We apply topological data analysis to the behavior of C. elegans, a widely studied model organism in biology. In particular, we use topology to produce a quantitative summary of complex behavior which may be applied to high-throughput data. Our methods allow us to distinguish and classify videos from various environmental conditions and we analyze the trade-off between accuracy and interpretability. Furthermore, we present a novel technique for visualizing the outputs of our analysis in terms of the input. Specifically, we use representative cycles of persistent homology to produce synthetic videos of stereotypical behaviors.},
  archive      = {J_FRAI},
  author       = {Thomas, Ashleigh and Bates, Kathleen and Elchesen, Alex and Hartsock, Iryna and Lu, Hang and Bubenik, Peter},
  doi          = {10.3389/frai.2021.668395},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {6},
  pages        = {668395},
  shortjournal = {Front. Artif. Intell.},
  title        = {Topological data analysis of c. elegans locomotion and behavior},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Linking linguistic and geographic distance in four semantic
domains: Computational geo-analyses of internal and external factors in
a dialect continuum. <em>FRAI</em>, <em>4</em>, 668035. (<a
href="https://doi.org/10.3389/frai.2021.668035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dialectometry studies patterns of linguistic variation through correlations between geographic and aggregate measures of linguistic distance. However, aggregating smooths out the role of semantic characteristics, which have been shown to affect the distribution of lexical variants across dialects. Furthermore, although dialectologists have always been well-aware of other variables like population size, isolation and socio-demographic features, these characteristics are generally only included in dialectometric analyses afterwards for further interpretation of the results rather than as explanatory variables. This study showcases linear mixed-effects modelling as a method that is able to incorporate both language-external and language-internal factors as explanatory variables of linguistic variation in the Limburgish dialect continuum in Belgium and the Netherlands. Covering four semantic domains that vary in their degree of basic vs. cultural vocabulary and their degree of standardization, the study models linguistic distances using a combination of external (e.g., geographic distance, separation by water, population size) and internal (semantic density, salience) sources of variation. The results show that both external and internal factors contribute to variation, but that the exact role of each individual factor differs across semantic domains. These findings highlight the need to incorporate language-internal factors in studies on variation, as well as a need for more comprehensive analysis tools to help better understand its patterns.},
  archive      = {J_FRAI},
  author       = {Huisman, John L. A. and Franco, Karlien and van Hout, Roeland},
  doi          = {10.3389/frai.2021.668035},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {6},
  pages        = {668035},
  shortjournal = {Front. Artif. Intell.},
  title        = {Linking linguistic and geographic distance in four semantic domains: Computational geo-analyses of internal and external factors in a dialect continuum},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Gender bias in the news: A scalable topic modelling and
visualization framework. <em>FRAI</em>, <em>4</em>, 664737. (<a
href="https://doi.org/10.3389/frai.2021.664737">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a topic modelling and data visualization methodology to examine gender-based disparities in news articles by topic. Existing research in topic modelling is largely focused on the text mining of closed corpora, i.e., those that include a fixed collection of composite texts. We showcase a methodology to discover topics via Latent Dirichlet Allocation, which can reliably produce human-interpretable topics over an open news corpus that continually grows with time. Our system generates topics, or distributions of keywords, for news articles on a monthly basis, to consistently detect key events and trends aligned with events in the real world. Findings from 2 years worth of news articles in mainstream English-language Canadian media indicate that certain topics feature either women or men more prominently and exhibit different types of language. Perhaps unsurprisingly, topics such as lifestyle, entertainment, and healthcare tend to be prominent in articles that quote more women than men. Topics such as sports, politics, and business are characteristic of articles that quote more men than women. The data shows a self-reinforcing gendered division of duties and representation in society. Quoting female sources more frequently in a caregiving role and quoting male sources more frequently in political and business roles enshrines women’s status as caregivers and men’s status as leaders and breadwinners. Our results can help journalists and policy makers better understand the unequal gender representation of those quoted in the news and facilitate news organizations’ efforts to achieve gender parity in their sources. The proposed methodology is robust, reproducible, and scalable to very large corpora, and can be used for similar studies involving unsupervised topic modelling and language analyses.},
  archive      = {J_FRAI},
  author       = {Rao, Prashanth and Taboada, Maite},
  doi          = {10.3389/frai.2021.664737},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {6},
  pages        = {664737},
  shortjournal = {Front. Artif. Intell.},
  title        = {Gender bias in the news: A scalable topic modelling and visualization framework},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). NeuroSim simulator for compute-in-memory hardware
accelerator: Validation and benchmark. <em>FRAI</em>, <em>4</em>,
659060. (<a href="https://doi.org/10.3389/frai.2021.659060">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Compute-in-memory (CIM) is an attractive solution to process the extensive workloads of multiply-and-accumulate (MAC) operations in deep neural network (DNN) hardware accelerators. A simulator with options of various mainstream and emerging memory technologies, architectures, and networks can be a great convenience for fast early-stage design space exploration of CIM hardware accelerators. DNN+NeuroSim is an integrated benchmark framework supporting flexible and hierarchical CIM array design options from a device level, to a circuit level and up to an algorithm level. In this study, we validate and calibrate the prediction of NeuroSim against a 40-nm RRAM-based CIM macro post-layout simulations. First, the parameters of a memory device and CMOS transistor are extracted from the foundry’s process design kit (PDK) and employed in the NeuroSim settings; the peripheral modules and operating dataflow are also configured to be the same as the actual chip implementation. Next, the area, critical path, and energy consumption values from the SPICE simulations at the module level are compared with those from NeuroSim. Some adjustment factors are introduced to account for transistor sizing and wiring area in the layout, gate switching activity, post-layout performance drop, etc. We show that the prediction from NeuroSim is precise with chip-level error under 1% after the calibration. Finally, the system-level performance benchmark is conducted with various device technologies and compared with the results before the validation. The general conclusions stay the same after the validation, but the performance degrades slightly due to the post-layout calibration.},
  archive      = {J_FRAI},
  author       = {Lu, Anni and Peng, Xiaochen and Li, Wantong and Jiang, Hongwu and Yu, Shimeng},
  doi          = {10.3389/frai.2021.659060},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {6},
  pages        = {659060},
  shortjournal = {Front. Artif. Intell.},
  title        = {NeuroSim simulator for compute-in-memory hardware accelerator: Validation and benchmark},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). “Part man, part machine, all cop”: Automation in policing.
<em>FRAI</em>, <em>4</em>, 655486. (<a
href="https://doi.org/10.3389/frai.2021.655486">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Digitisation, automation, and datafication permeate policing and justice more and more each year—from predictive policing methods through recidivism prediction to automated biometric identification at the border. The sociotechnical issues surrounding the use of such systems raise questions and reveal problems, both old and new. Our article reviews contemporary issues surrounding automation in policing and the legal system, finds common issues and themes in various different examples, introduces the distinction between human “retail bias” and algorithmic “wholesale bias”, and argues for shifting the viewpoint on the debate to focus on both workers&#39; rights and organisational responsibility as well as fundamental rights and the right to an effective remedy.},
  archive      = {J_FRAI},
  author       = {Adensamer, Angelika and Klausner, Lukas Daniel},
  doi          = {10.3389/frai.2021.655486},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {6},
  pages        = {655486},
  shortjournal = {Front. Artif. Intell.},
  title        = {“Part man, part machine, all cop”: Automation in policing},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Dissemination dynamics of receding words: A diachronic case
study of whom. <em>FRAI</em>, <em>4</em>, 654154. (<a
href="https://doi.org/10.3389/frai.2021.654154">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We explore the relationship between word dissemination and frequency change for a rapidly receding feature, the relativizer whom. The success of newly emerging words has been shown to correlate with high dissemination scores. However, the reverse—a correlation of lower dissemination scores with receding features—has not been investigated. Based on two established and two newly developed measures of word dissemination—across texts, linguistic environments, registers, and topics—we show that a general correlation between dissemination and frequency does not obtain in the case of whom. Different dissemination measures diverge from each other and show internally variable developments. These can, however, be explained with reference to the specific sociolinguistic history of whom over the past 300 years. Our findings suggest that the relationship between dissemination and word success is not static, but needs to be contextualized against different stages in individual words’ life-cycles. Our study demonstrates the applicability of large-scale, quantitative measures to qualitatively informed sociolinguistic research.},
  archive      = {J_FRAI},
  author       = {Bohmann, Axel and Bohmann, Martin and Hinrichs, Lars},
  doi          = {10.3389/frai.2021.654154},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {6},
  pages        = {654154},
  shortjournal = {Front. Artif. Intell.},
  title        = {Dissemination dynamics of receding words: A diachronic case study of whom},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Characterising online news comments: A multi-dimensional
cruise through online registers. <em>FRAI</em>, <em>4</em>, 643770. (<a
href="https://doi.org/10.3389/frai.2021.643770">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {News organisations often allow public comments at the bottom of their news stories. These comments constitute a fruitful source of data to investigate linguistic variation online; their characteristics, however, are rather understudied. This paper thus contributes to the description of online news comments and online language in English. In this spirit, we apply multi-dimensional analysis to a large dataset of online news comments and compare them to a corpus of online registers, thus placing online comments in the space of register variation online. We find that online news comments are involved-evaluative and informational at the same time, but mostly argumentative in nature, with such argumentation taking an informal shape. Our analyses lead us to conclude that online registers are a different mode of communication, neither spoken nor written, with individual variation across different types of online registers.},
  archive      = {J_FRAI},
  author       = {Ehret, Katharina and Taboada, Maite},
  doi          = {10.3389/frai.2021.643770},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {6},
  pages        = {643770},
  shortjournal = {Front. Artif. Intell.},
  title        = {Characterising online news comments: A multi-dimensional cruise through online registers},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Evaluation of MRI denoising methods using unsupervised
learning. <em>FRAI</em>, <em>4</em>, 642731. (<a
href="https://doi.org/10.3389/frai.2021.642731">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we evaluate two unsupervised approaches to denoise Magnetic Resonance Images (MRI) in the complex image space using the raw information that k-space holds. The first method is based on Stein’s Unbiased Risk Estimator, while the second approach is based on a blindspot network, which limits the network’s receptive field. Both methods are tested on two different datasets, one containing real knee MRI and the other consists of synthetic brain MRI. These datasets contain information about the complex image space which will be used for denoising purposes. Both networks are compared against a state-of-the-art algorithm, Non-Local Means (NLM) using quantitative and qualitative measures. For most given metrics and qualitative measures, both networks outperformed NLM, and they prove to be reliable denoising methods.},
  archive      = {J_FRAI},
  author       = {Moreno López, Marc and Frederick, Joshua M. and Ventura, Jonathan},
  doi          = {10.3389/frai.2021.642731},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {6},
  pages        = {642731},
  shortjournal = {Front. Artif. Intell.},
  title        = {Evaluation of MRI denoising methods using unsupervised learning},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Learning medical materials from radiography images.
<em>FRAI</em>, <em>4</em>, 638299. (<a
href="https://doi.org/10.3389/frai.2021.638299">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning models have been shown to be effective for material analysis, a subfield of computer vision, on natural images. In medicine, deep learning systems have been shown to more accurately analyze radiography images than algorithmic approaches and even experts. However, one major roadblock to applying deep learning-based material analysis on radiography images is a lack of material annotations accompanying image sets. To solve this, we first introduce an automated procedure to augment annotated radiography images into a set of material samples. Next, using a novel Siamese neural network that compares material sample pairs, called D-CNN, we demonstrate how to learn a perceptual distance metric between material categories. This system replicates the actions of human annotators by discovering attributes that encode traits that distinguish materials in radiography images. Finally, we update and apply MAC-CNN, a material recognition neural network, to demonstrate this system on a dataset of knee X-rays and brain MRIs with tumors. Experiments show that this system has strong predictive power on these radiography images, achieving 92.8% accuracy at predicting the material present in a local region of an image. Our system also draws interesting parallels between human perception of natural materials and materials in radiography images.},
  archive      = {J_FRAI},
  author       = {Molder, Carson and Lowe, Benjamin and Zhan, Justin},
  doi          = {10.3389/frai.2021.638299},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {6},
  pages        = {638299},
  shortjournal = {Front. Artif. Intell.},
  title        = {Learning medical materials from radiography images},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Predicting cervical cancer outcomes: Statistics, images, and
machine learning. <em>FRAI</em>, <em>4</em>, 627369. (<a
href="https://doi.org/10.3389/frai.2021.627369">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cervical cancer is a very common and severe disease in women worldwide. Accurate prediction of its clinical outcomes will help adjust or optimize the treatment of cervical cancer and benefit the patients. Statistical models, various types of medical images, and machine learning have been used for outcome prediction and obtained promising results. Compared to conventional statistical models, machine learning has demonstrated advantages in dealing with the complexity in large-scale data and discovering prognostic factors. It has great potential in clinical application and improving cervical cancer management. However, the limitations of prediction studies and prediction models including simplification, insufficient data, overfitting and lack of interpretability, indicate that more work is needed to make clinical outcome prediction more accurate, more reliable, and more practical for clinical use.},
  archive      = {J_FRAI},
  author       = {Luo, Wei},
  doi          = {10.3389/frai.2021.627369},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {6},
  pages        = {627369},
  shortjournal = {Front. Artif. Intell.},
  title        = {Predicting cervical cancer outcomes: Statistics, images, and machine learning},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Registerial adaptation vs. Innovation across situational
contexts: 18th century women in transition. <em>FRAI</em>, <em>4</em>,
609970. (<a href="https://doi.org/10.3389/frai.2021.609970">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Endeavors to computationally model language variation and change are ever increasing. While analyses of recent diachronic trends are frequently conducted, long-term trends accounting for sociolinguistic variation are less well-studied. Our work sheds light on the temporal dynamics of language use of British 18th century women as a group in transition across two situational contexts. Our findings reveal that in formal contexts women adapt to register conventions, while in informal contexts they act as innovators of change in language use influencing others. While adopted from other disciplines, our methods inform (historical) sociolinguistic work in novel ways. These methods include diachronic periodization by Kullback-Leibler divergence to determine periods of change and relevant features of variation, and event cascades as influencer models.},
  archive      = {J_FRAI},
  author       = {Degaetano-Ortlieb, Stefania and Säily, Tanja and Bizzoni, Yuri},
  doi          = {10.3389/frai.2021.609970},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {6},
  pages        = {609970},
  shortjournal = {Front. Artif. Intell.},
  title        = {Registerial adaptation vs. innovation across situational contexts: 18th century women in transition},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Ensuring the robustness and reliability of data-driven
knowledge discovery models in production and manufacturing.
<em>FRAI</em>, <em>4</em>, 576892. (<a
href="https://doi.org/10.3389/frai.2021.576892">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Cross-Industry Standard Process for Data Mining (CRISP-DM) is a widely accepted framework in production and manufacturing. This data-driven knowledge discovery framework provides an orderly partition of the often complex data mining processes to ensure a practical implementation of data analytics and machine learning models. However, the practical application of robust industry-specific data-driven knowledge discovery models faces multiple data- and model development-related issues. These issues need to be carefully addressed by allowing a flexible, customized and industry-specific knowledge discovery framework. For this reason, extensions of CRISP-DM are needed. In this paper, we provide a detailed review of CRISP-DM and summarize extensions of this model into a novel framework we call Generalized Cross-Industry Standard Process for Data Science (GCRISP-DS). This framework is designed to allow dynamic interactions between different phases to adequately address data- and model-related issues for achieving robustness. Furthermore, it emphasizes also the need for a detailed business understanding and the interdependencies with the developed models and data quality for fulfilling higher business objectives. Overall, such a customizable GCRISP-DS framework provides an enhancement for model improvements and reusability by minimizing robustness-issues.},
  archive      = {J_FRAI},
  author       = {Tripathi, Shailesh and Muhr, David and Brunner, Manuel and Jodlbauer, Herbert and Dehmer, Matthias and Emmert-Streib, Frank},
  doi          = {10.3389/frai.2021.576892},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {6},
  pages        = {576892},
  shortjournal = {Front. Artif. Intell.},
  title        = {Ensuring the robustness and reliability of data-driven knowledge discovery models in production and manufacturing},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Identification of suicidal ideation in the canadian
community health survey—mental health component using deep learning.
<em>FRAI</em>, <em>4</em>, 561528. (<a
href="https://doi.org/10.3389/frai.2021.561528">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Introduction: Suicidal ideation (SI) is prevalent in the general population, and is a risk factor for suicide. Predicting which patients are likely to have SI remains challenging. Deep Learning (DL) may be a useful tool in this context, as it can be used to find patterns in complex, heterogeneous, and incomplete datasets. An automated screening system for SI could help prompt clinicians to be more attentive to patients at risk for suicide.Methods: Using the Canadian Community Health Survey—Mental Health Component, we trained a DL model based on 23,859 survey responses to classify patients with and without SI. Models were created to classify both lifetime SI and SI over the last 12 months. From 582 possible parameters we produced 96- and 21-feature versions of the models. Models were trained using an undersampling procedure that balanced the training set between SI and non-SI; validation was done on held-out data.Results: For lifetime SI, the 96 feature model had an Area under the receiver operating curve (AUC) of 0.79 and the 21 feature model had an AUC of 0.77. For SI in the last 12 months the 96 feature model had an AUC of 0.71 and the 21 feature model had an AUC of 0.68. In addition, sensitivity analyses demonstrated feature relationships in line with existing literature.Discussion: Although further study is required to ensure clinical relevance and sample generalizability, this study is an initial proof of concept for the use of DL to improve identification of SI. Sensitivity analyses can help improve the interpretability of DL models. This kind of model would help start conversations with patients which could lead to improved care and a reduction in suicidal behavior.},
  archive      = {J_FRAI},
  author       = {Desai, Sneha and Tanguay-Sela, Myriam and Benrimoh, David and Fratila, Robert and Brown, Eleanor and Perlman, Kelly and John, Ann and DelPozo-Banos, Marcos and Low, Nancy and Israel, Sonia and Palladini, Lisa and Turecki, Gustavo},
  doi          = {10.3389/frai.2021.561528},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {6},
  pages        = {561528},
  shortjournal = {Front. Artif. Intell.},
  title        = {Identification of suicidal ideation in the canadian community health Survey—Mental health component using deep learning},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Editorial: Machine learning for water resources.
<em>FRAI</em>, <em>4</em>, 699862. (<a
href="https://doi.org/10.3389/frai.2021.699862">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Mariethoz, Gregoire and Gómez-Hernández, J. Jaime},
  doi          = {10.3389/frai.2021.699862},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {5},
  pages        = {699862},
  shortjournal = {Front. Artif. Intell.},
  title        = {Editorial: Machine learning for water resources},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Corrigendum: Using crowd-sourced speech data to study
socially constrained variation in nonmodal phonation. <em>FRAI</em>,
<em>4</em>, 692064. (<a
href="https://doi.org/10.3389/frai.2021.692064">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Gittelson, Ben and Leemann, Adrian and Tomaschek, Fabian},
  doi          = {10.3389/frai.2021.692064},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {5},
  pages        = {692064},
  shortjournal = {Front. Artif. Intell.},
  title        = {Corrigendum: Using crowd-sourced speech data to study socially constrained variation in nonmodal phonation},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Medical information mart for intensive care: A foundation
for the fusion of artificial intelligence and real-world data.
<em>FRAI</em>, <em>4</em>, 691626. (<a
href="https://doi.org/10.3389/frai.2021.691626">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Rogers, Paul and Wang, Dong and Lu, Zhiyuan},
  doi          = {10.3389/frai.2021.691626},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {5},
  pages        = {691626},
  shortjournal = {Front. Artif. Intell.},
  title        = {Medical information mart for intensive care: A foundation for the fusion of artificial intelligence and real-world data},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A survey of topological machine learning methods.
<em>FRAI</em>, <em>4</em>, 681108. (<a
href="https://doi.org/10.3389/frai.2021.681108">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The last decade saw an enormous boost in the field of computational topology: methods and concepts from algebraic and differential topology, formerly confined to the realm of pure mathematics, have demonstrated their utility in numerous areas such as computational biology personalised medicine, and time-dependent data analysis, to name a few. The newly-emerging domain comprising topology-based techniques is often referred to as topological data analysis (TDA). Next to their applications in the aforementioned areas, TDA methods have also proven to be effective in supporting, enhancing, and augmenting both classical machine learning and deep learning models. In this paper, we review the state of the art of a nascent field we refer to as “topological machine learning,” i.e., the successful symbiosis of topology-based methods and machine learning algorithms, such as deep neural networks. We identify common threads, current applications, and future challenges.},
  archive      = {J_FRAI},
  author       = {Hensel, Felix and Moor, Michael and Rieck, Bastian},
  doi          = {10.3389/frai.2021.681108},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {5},
  pages        = {681108},
  shortjournal = {Front. Artif. Intell.},
  title        = {A survey of topological machine learning methods},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Similarities and differences in gene expression networks
between the breast cancer cell line michigan cancer foundation-7 and
invasive human breast cancer tissues. <em>FRAI</em>, <em>4</em>, 674370.
(<a href="https://doi.org/10.3389/frai.2021.674370">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Failure to adequately characterize cell lines, and understand the differences between in vitro and in vivo biology, can have serious consequences on the translatability of in vitro scientific studies to human clinical trials. This project focuses on the Michigan Cancer Foundation-7 (MCF-7) cells, a human breast adenocarcinoma cell line that is commonly used for in vitro cancer research, with over 42,000 publications in PubMed. In this study, we explore the key similarities and differences in gene expression networks of MCF-7 cell lines compared to human breast cancer tissues. We used two MCF-7 data sets, one data set collected by ARCHS4 including 1032 samples and one data set from Gene Expression Omnibus GSE50705 with 88 estradiol-treated MCF-7 samples. The human breast invasive ductal carcinoma (BRCA) data set came from The Cancer Genome Atlas, including 1212 breast tissue samples. Weighted Gene Correlation Network Analysis (WGCNA) and functional annotations of the data showed that MCF-7 cells and human breast tissues have only minimal similarity in biological processes, although some fundamental functions, such as cell cycle, are conserved. Scaled connectivity—a network topology metric—also showed drastic differences in the behavior of genes between MCF-7 and BRCA data sets. Finally, we used canSAR to compute ligand-based druggability scores of genes in the data sets, and our results suggested that using MCF-7 to study breast cancer may lead to missing important gene targets. Our comparison of the networks of MCF-7 and human breast cancer highlights the nuances of using MCF-7 to study human breast cancer and can contribute to better experimental design and result interpretation of study involving this cell line.},
  archive      = {J_FRAI},
  author       = {Tran, Vy and Kim, Robert and Maertens, Mikhail and Hartung, Thomas and Maertens, Alexandra},
  doi          = {10.3389/frai.2021.674370},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {5},
  pages        = {674370},
  shortjournal = {Front. Artif. Intell.},
  title        = {Similarities and differences in gene expression networks between the breast cancer cell line michigan cancer foundation-7 and invasive human breast cancer tissues},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A matrix-variate t model for networks. <em>FRAI</em>,
<em>4</em>, 674166. (<a
href="https://doi.org/10.3389/frai.2021.674166">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Networks represent a useful tool to describe relationships among financial firms and network analysis has been extensively used in recent years to study financial connectedness. An aspect, which is often neglected, is that network observations come with errors from different sources, such as estimation and measurement errors, thus a proper statistical treatment of the data is needed before network analysis can be performed. We show that node centrality measures can be heavily affected by random errors and propose a flexible model based on the matrix-variate t distribution and a Bayesian inference procedure to de-noise the data. We provide an application to a network among European financial institutions.},
  archive      = {J_FRAI},
  author       = {Billio, Monica and Casarin, Roberto and Costola, Michele and Iacopini, Matteo},
  doi          = {10.3389/frai.2021.674166},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {5},
  pages        = {674166},
  shortjournal = {Front. Artif. Intell.},
  title        = {A matrix-variate t model for networks},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The applicability of self-play algorithms to trading and
forecasting financial markets. <em>FRAI</em>, <em>4</em>, 668465. (<a
href="https://doi.org/10.3389/frai.2021.668465">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The central research question to answer in this study is whether the AI methodology of Self-Play can be applied to financial markets. In typical use-cases of Self-Play, two AI agents play against each other in a particular game, e.g., chess or Go. By repeatedly playing the game, they learn its rules as well as possible winning strategies. When considering financial markets, however, we usually have one player—the trader—that does not face one individual adversary but competes against a vast universe of other market participants. Furthermore, the optimal behaviour in financial markets is not described via a winning strategy, but via the objective of maximising profits while managing risks appropriately. Lastly, data issues cause additional challenges, since, in finance, they are quite often incomplete, noisy and difficult to obtain. We will show that academic research using Self-Play has mostly not focused on finance, and if it has, it was usually restricted to stock markets, not considering the large FX, commodities and bond markets. Despite those challenges, we see enormous potential of applying self-play concepts and algorithms to financial markets and economic forecasts.},
  archive      = {J_FRAI},
  author       = {Posth, Jan-Alexander and Kotlarz, Piotr and Misheva, Branka Hadji and Osterrieder, Joerg and Schwendner, Peter},
  doi          = {10.3389/frai.2021.668465},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {5},
  pages        = {668465},
  shortjournal = {Front. Artif. Intell.},
  title        = {The applicability of self-play algorithms to trading and forecasting financial markets},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Topology applied to machine learning: From global to local.
<em>FRAI</em>, <em>4</em>, 668302. (<a
href="https://doi.org/10.3389/frai.2021.668302">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Through the use of examples, we explain one way in which applied topology has evolved since the birth of persistent homology in the early 2000s. The first applications of topology to data emphasized the global shape of a dataset, such as the three-circle model for 3 × 3 pixel patches from natural images, or the configuration space of the cyclo-octane molecule, which is a sphere with a Klein bottle attached via two circles of singularity. In these studies of global shape, short persistent homology bars are disregarded as sampling noise. More recently, however, persistent homology has been used to address questions about the local geometry of data. For instance, how can local geometry be vectorized for use in machine learning problems? Persistent homology and its vectorization methods, including persistence landscapes and persistence images, provide popular techniques for incorporating both local geometry and global topology into machine learning. Our meta-hypothesis is that the short bars are as important as the long bars for many machine learning tasks. In defense of this claim, we survey applications of persistent homology to shape recognition, agent-based modeling, materials science, archaeology, and biology. Additionally, we survey work connecting persistent homology to geometric features of spaces, including curvature and fractal dimension, and various methods that have been used to incorporate persistent homology into machine learning.},
  archive      = {J_FRAI},
  author       = {Adams, Henry and Moy, Michael},
  doi          = {10.3389/frai.2021.668302},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {5},
  pages        = {668302},
  shortjournal = {Front. Artif. Intell.},
  title        = {Topology applied to machine learning: From global to local},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Chatbots as a tool to scale mentoring processes:
Individually supporting self-study in higher education. <em>FRAI</em>,
<em>4</em>, 668220. (<a
href="https://doi.org/10.3389/frai.2021.668220">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Like most curricula in the humanities and social sciences, the curriculum of pre-service teacher training in educational sciences often includes time-consuming reading and writing tasks, which require high quality support and feedback in a timely manner. A well-known way to provide this support to students is one-to-one mentoring. However, limited time and resources in the German university context require to effectively scale the benefits of individual feedback. The use of scalable technologies to support learning processes seems to be promising, but its development usually requires a deep technical understanding. With an interdisciplinary approach, this contribution investigates how personal mentoring can be made available to as many students as possible, taking into account the didactic, organizational and technical frameworks at universities. We describe the development and implementation process of two chatbots that both aim to support students of educational sciences in their self-study of the seminar topics and literature. The chatbots were used by over 700 students during the course of 1 year and our evaluations show promising results that bear the potential to improve the availability of digital mentoring support for all students.},
  archive      = {J_FRAI},
  author       = {Neumann, Alexander Tobias and Arndt, Tamar and Köbis, Laura and Meissner, Roy and Martin, Anne and de Lange, Peter and Pengel, Norbert and Klamma, Ralf and Wollersheim, Heinz-Werner},
  doi          = {10.3389/frai.2021.668220},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {5},
  pages        = {668220},
  shortjournal = {Front. Artif. Intell.},
  title        = {Chatbots as a tool to scale mentoring processes: Individually supporting self-study in higher education},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Forecasting quoted depth with the limit order book.
<em>FRAI</em>, <em>4</em>, 667780. (<a
href="https://doi.org/10.3389/frai.2021.667780">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Liquidity plays a vital role in the financial markets, affecting a myriad of factors including stock prices, returns, and risk. In the stock market, liquidity is usually measured through the order book, which captures the orders placed by traders to buy and sell stocks at different price points. The introduction of electronic trading systems in recent years made the deeper layers of the order book more accessible to traders and thus of greater interest to researchers. This paper examines the efficacy of leveraging the deeper layers of the order book when forecasting quoted depth—a measure of liquidity—on a per-minute basis. Using Deep Feed Forward Neural Networks, we show that the deeper layers do provide additional information compared to the upper layers alone.},
  archive      = {J_FRAI},
  author       = {Libman, Daniel and Haber, Simi and Schaps, Mary},
  doi          = {10.3389/frai.2021.667780},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {5},
  pages        = {667780},
  shortjournal = {Front. Artif. Intell.},
  title        = {Forecasting quoted depth with the limit order book},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Robot gaze behavior affects honesty in human-robot
interaction. <em>FRAI</em>, <em>4</em>, 663190. (<a
href="https://doi.org/10.3389/frai.2021.663190">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the use of humanoid robots proliferates, an increasing amount of people may find themselves face-to-“face” with a robot in everyday life. Although there is a plethora of information available on facial social cues and how we interpret them in the field of human-human social interaction, we cannot assume that these findings flawlessly transfer to human-robot interaction. Therefore, more research on facial cues in human-robot interaction is required. This study investigated deception in human-robot interaction context, focusing on the effect that eye contact with a robot has on honesty toward this robot. In an iterative task, participants could assist a humanoid robot by providing it with correct information, or potentially secure a reward for themselves by providing it with incorrect information. Results show that participants are increasingly honest after the robot establishes eye contact with them, but only if this is in response to deceptive behavior. Behavior is not influenced by the establishment of eye contact if the participant is actively engaging in honest behavior. These findings support the notion that humanoid robots can be perceived as, and treated like, social agents, since the herein described effect mirrors one present in human-human social interaction.},
  archive      = {J_FRAI},
  author       = {Schellen, Elef and Bossi, Francesco and Wykowska, Agnieszka},
  doi          = {10.3389/frai.2021.663190},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {5},
  pages        = {663190},
  shortjournal = {Front. Artif. Intell.},
  title        = {Robot gaze behavior affects honesty in human-robot interaction},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). InferBERT: A transformer-based causal inference framework
for enhancing pharmacovigilance. <em>FRAI</em>, <em>4</em>, 659622. (<a
href="https://doi.org/10.3389/frai.2021.659622">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Background: T ransformer-based language models have delivered clear improvements in a wide range of natural language processing (NLP) tasks. However, those models have a significant limitation; specifically, they cannot infer causality, a prerequisite for deployment in pharmacovigilance, and health care. Therefore, these transformer-based language models should be developed to infer causality to address the key question of the cause of a clinical outcome.Results: In this study, we propose an innovative causal inference model–InferBERT, by integrating the A Lite Bidirectional Encoder Representations from Transformers (ALBERT) and Judea Pearl’s Do-calculus to establish potential causality in pharmacovigilance. Two FDA Adverse Event Reporting System case studies, including Analgesics-related acute liver failure and Tramadol-related mortalities, were employed to evaluate the proposed InferBERT model. The InferBERT model yielded accuracies of 0.78 and 0.95 for identifying Analgesics-related acute liver failure and Tramadol-related death cases, respectively. Meanwhile, the inferred causes of the two clinical outcomes, (i.e. acute liver failure and death) were highly consistent with clinical knowledge. Furthermore, inferred causes were organized into a causal tree using the proposed recursive do-calculus algorithm to improve the model’s understanding of causality. Moreover, the high reproducibility of the proposed InferBERT model was demonstrated by a robustness assessment.Conclusion: The empirical results demonstrated that the proposed InferBERT approach is able to both predict clinical events and to infer their causes. Overall, the proposed InferBERT model is a promising approach to establish causal effects behind text-based observational data to enhance our understanding of intrinsic causality.Availability and implementation: The InferBERT model and preprocessed FAERS data sets are available on GitHub at https://github.com/XingqiaoWang/DeepCausalPV-master.},
  archive      = {J_FRAI},
  author       = {Wang, Xingqiao and Xu, Xiaowei and Tong, Weida and Roberts, Ruth and Liu, Zhichao},
  doi          = {10.3389/frai.2021.659622},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {5},
  pages        = {659622},
  shortjournal = {Front. Artif. Intell.},
  title        = {InferBERT: A transformer-based causal inference framework for enhancing pharmacovigilance},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The promise of AI in detection, diagnosis, and epidemiology
for combating COVID-19: Beyond the hype. <em>FRAI</em>, <em>4</em>,
652669. (<a href="https://doi.org/10.3389/frai.2021.652669">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {COVID-19 has created enormous suffering, affecting lives, and causing deaths. The ease with which this type of coronavirus can spread has exposed weaknesses of many healthcare systems around the world. Since its emergence, many governments, research communities, commercial enterprises, and other institutions and stakeholders around the world have been fighting in various ways to curb the spread of the disease. Science and technology have helped in the implementation of policies of many governments that are directed toward mitigating the impacts of the pandemic and in diagnosing and providing care for the disease. Recent technological tools, artificial intelligence (AI) tools in particular, have also been explored to track the spread of the coronavirus, identify patients with high mortality risk and diagnose patients for the disease. In this paper, areas where AI techniques are being used in the detection, diagnosis and epidemiological predictions, forecasting and social control for combating COVID-19 are discussed, highlighting areas of successful applications and underscoring issues that need to be addressed to achieve significant progress in battling COVID-19 and future pandemics. Several AI systems have been developed for diagnosing COVID-19 using medical imaging modalities such as chest CT and X-ray images. These AI systems mainly differ in their choices of the algorithms for image segmentation, classification and disease diagnosis. Other AI-based systems have focused on predicting mortality rate, long-term patient hospitalization and patient outcomes for COVID-19. AI has huge potential in the battle against the COVID-19 pandemic but successful practical deployments of these AI-based tools have so far been limited due to challenges such as limited data accessibility, the need for external evaluation of AI models, the lack of awareness of AI experts of the regulatory landscape governing the deployment of AI tools in healthcare, the need for clinicians and other experts to work with AI experts in a multidisciplinary context and the need to address public concerns over data collection, privacy, and protection. Having a dedicated team with expertise in medical data collection, privacy, access and sharing, using federated learning whereby AI scientists hand over training algorithms to the healthcare institutions to train models locally, and taking full advantage of biomedical data stored in biobanks can alleviate some of problems posed by these challenges. Addressing these challenges will ultimately accelerate the translation of AI research into practical and useful solutions for combating pandemics.},
  archive      = {J_FRAI},
  author       = {Abdulkareem, Musa and Petersen, Steffen E.},
  doi          = {10.3389/frai.2021.652669},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {5},
  pages        = {652669},
  shortjournal = {Front. Artif. Intell.},
  title        = {The promise of AI in detection, diagnosis, and epidemiology for combating COVID-19: Beyond the hype},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Machine learning-based modeling of spatio-temporally varying
responses of rainfed corn yield to climate, soil, and management in the
u.s. Corn belt. <em>FRAI</em>, <em>4</em>, 647999. (<a
href="https://doi.org/10.3389/frai.2021.647999">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Better understanding the variabilities in crop yield and production is critical to assessing the vulnerability and resilience of food production systems. Both environmental (climatic and edaphic) conditions and management factors affect the variabilities of crop yield. In this study, we conducted a comprehensive data-driven analysis in the U.S. Corn Belt to understand and model how rainfed corn yield is affected by climate variability and extremes, soil properties (soil available water capacity, soil organic matter), and management practices (planting date and fertilizer applications). Exploratory data analyses revealed that corn yield responds non-linearly to temperature, while the negative vapor pressure deficit (VPD) effect on corn yield is monotonic and more prominent. Higher mean yield and inter-annual yield variability are found associated with high soil available water capacity, while lower inter-annual yield variability is associated with high soil organic matter (SOM). We also identified region-dependent relationships between planting date and yield and a strong correlation between planting date and the April weather condition (temperature and rainfall). Next, we built machine learning models using the random forest and LASSO algorithms, respectively, to predict corn yield with all climatic, soil properties, and management factors. The random forest model achieved a high prediction accuracy for annual yield at county level as early as in July (R2 = 0.781) and outperformed LASSO. The gained insights from this study lead to improved understanding of how corn yield responds to climate variability and projected change in the U.S. Corn Belt and globally.},
  archive      = {J_FRAI},
  author       = {Xu, Tianfang and Guan, Kaiyu and Peng, Bin and Wei, Shiqi and Zhao, Lei},
  doi          = {10.3389/frai.2021.647999},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {5},
  pages        = {647999},
  shortjournal = {Front. Artif. Intell.},
  title        = {Machine learning-based modeling of spatio-temporally varying responses of rainfed corn yield to climate, soil, and management in the U.S. corn belt},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Reduction of survey sites in dialectology: A new methodology
based on clustering. <em>FRAI</em>, <em>4</em>, 642505. (<a
href="https://doi.org/10.3389/frai.2021.642505">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many language change studies aim for a partial revisitation, i.e., selecting survey sites from previous dialect studies. The central issue of survey site reduction, however, has often been addressed only qualitatively. Cluster analysis offers an innovative means of identifying the most representative survey sites among a set of original survey sites. In this paper, we present a general methodology for finding representative sites for an intended study, potentially applicable to any collection of data about dialects or linguistic variation. We elaborate the quantitative steps of the proposed methodology in the context of the “Linguistic Atlas of Japan” (LAJ). Next, we demonstrate the full application of the methodology on the “Linguistic Atlas of German-speaking Switzerland” (Germ.: “Sprachatlas der Deutschen Schweiz”—SDS), with the explicit aim of selecting survey sites corresponding to the aims of the current project “Swiss German Dialects Across Time and Space” (SDATS), which revisits SDS 70 years later. We find that depending on the circumstances and requirements of a study, the proposed methodology, introducing cluster analysis into the survey site reduction process, allows for a greater objectivity in comparison to traditional approaches. We suggest, however, that the suitability of any set of candidate survey sites resulting from the proposed methodology be rigorously revised by experts due to potential incongruences, such as the overlap of objectives and variables across the original and intended studies and ongoing dialect change.},
  archive      = {J_FRAI},
  author       = {Jeszenszky, Péter and Steiner, Carina and Leemann, Adrian},
  doi          = {10.3389/frai.2021.642505},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {5},
  pages        = {642505},
  shortjournal = {Front. Artif. Intell.},
  title        = {Reduction of survey sites in dialectology: A new methodology based on clustering},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Improving the robustness of object detection through a
multi-camera–based fusion algorithm using fuzzy logic. <em>FRAI</em>,
<em>4</em>, 638951. (<a
href="https://doi.org/10.3389/frai.2021.638951">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A single camera creates a bounding box (BB) for the detected object with certain accuracy through a convolutional neural network (CNN). However, a single RGB camera may not be able to capture the actual object within the BB even if the CNN detector accuracy is high for the object. In this research, we present a solution to this limitation through the usage of multiple cameras, projective transformation, and a fuzzy logic–based fusion. The proposed algorithm generates a “confidence score” for each frame to check the trustworthiness of the BB generated by the CNN detector. As a first step toward this solution, we created a two-camera setup to detect objects. Agricultural weed is used as objects to be detected. A CNN detector generates BB for each camera when weed is present. Then a projective transformation is used to project one camera’s image plane to another camera’s image plane. The intersect over union (IOU) overlap of the BB is computed when objects are detected correctly. Four different scenarios are generated based on how far the object is from the multi-camera setup, and IOU overlap is calculated for each scenario (ground truth). When objects are detected correctly and bounding boxes are at correct distance, the IOU overlap value should be close to the ground truth IOU overlap value. On the other hand, the IOU overlap value should differ if BBs are at incorrect positions. Mamdani fuzzy rules are generated using this reasoning, and three different confidence scores (“high,” “ok,” and “low”) are given to each frame based on accuracy and position of BBs. The proposed algorithm was then tested under different conditions to check its validity. The confidence score of the proposed fuzzy system for three different scenarios supports the hypothesis that the multi-camera–based fusion algorithm improved the overall robustness of the detection system.},
  archive      = {J_FRAI},
  author       = {Khan, Md Nazmuzzaman and Al Hasan, Mohammad and Anwar, Sohel},
  doi          = {10.3389/frai.2021.638951},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {5},
  pages        = {638951},
  shortjournal = {Front. Artif. Intell.},
  title        = {Improving the robustness of object detection through a multi-Camera–Based fusion algorithm using fuzzy logic},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A perspective on building ethical datasets for children’s
conversational agents. <em>FRAI</em>, <em>4</em>, 637532. (<a
href="https://doi.org/10.3389/frai.2021.637532">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial intelligence (AI)-powered technologies are becoming an integral part of youth&#39;s environments, impacting how they socialize and learn. Children (12 years of age and younger) often interact with AI through conversational agents (e.g., Siri and Alexa) that they speak with to receive information about the world. Conversational agents can mimic human social interactions, and it is important to develop socially intelligent agents appropriate for younger populations. Yet it is often unclear what data are curated to power many of these systems. This article applies a sociocultural developmental approach to examine child-centric intelligent conversational agents, including an overview of how children&#39;s development influences their social learning in the world and how that relates to AI. Examples are presented that reflect potential data types available for training AI models to generate children&#39;s conversational agents&#39; speech. The ethical implications for building different datasets and training models using them are discussed as well as future directions for the use of social AI-driven technology for children.},
  archive      = {J_FRAI},
  author       = {Bailey, Jakki O. and Patel, Barkha and Gurari, Danna},
  doi          = {10.3389/frai.2021.637532},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {5},
  pages        = {637532},
  shortjournal = {Front. Artif. Intell.},
  title        = {A perspective on building ethical datasets for children&#39;s conversational agents},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A transfer learning–based active learning framework for
brain tumor classification. <em>FRAI</em>, <em>4</em>, 635766. (<a
href="https://doi.org/10.3389/frai.2021.635766">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Brain tumor is one of the leading causes of cancer-related death globally among children and adults. Precise classification of brain tumor grade (low-grade and high-grade glioma) at an early stage plays a key role in successful prognosis and treatment planning. With recent advances in deep learning, artificial intelligence–enabled brain tumor grading systems can assist radiologists in the interpretation of medical images within seconds. The performance of deep learning techniques is, however, highly depended on the size of the annotated dataset. It is extremely challenging to label a large quantity of medical images, given the complexity and volume of medical data. In this work, we propose a novel transfer learning–based active learning framework to reduce the annotation cost while maintaining stability and robustness of the model performance for brain tumor classification. In this retrospective research, we employed a 2D slice–based approach to train and fine-tune our model on the magnetic resonance imaging (MRI) training dataset of 203 patients and a validation dataset of 66 patients which was used as the baseline. With our proposed method, the model achieved area under receiver operating characteristic (ROC) curve (AUC) of 82.89% on a separate test dataset of 66 patients, which was 2.92% higher than the baseline AUC while saving at least 40% of labeling cost. In order to further examine the robustness of our method, we created a balanced dataset, which underwent the same procedure. The model achieved AUC of 82% compared with AUC of 78.48% for the baseline, which reassures the robustness and stability of our proposed transfer learning augmented with active learning framework while significantly reducing the size of training data.},
  archive      = {J_FRAI},
  author       = {Hao, Ruqian and Namdar, Khashayar and Liu, Lin and Khalvati, Farzad},
  doi          = {10.3389/frai.2021.635766},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {5},
  pages        = {635766},
  shortjournal = {Front. Artif. Intell.},
  title        = {A transfer Learning–Based active learning framework for brain tumor classification},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Interpretability versus accuracy: A comparison of machine
learning models built using different algorithms, performance measures,
and features to predict e. Coli levels in agricultural water.
<em>FRAI</em>, <em>4</em>, 628441. (<a
href="https://doi.org/10.3389/frai.2021.628441">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Since E. coli is considered a fecal indicator in surface water, government water quality standards and industry guidance often rely on E. coli monitoring to identify when there is an increased risk of pathogen contamination of water used for produce production (e.g., for irrigation). However, studies have indicated that E. coli testing can present an economic burden to growers and that time lags between sampling and obtaining results may reduce the utility of these data. Models that predict E. coli levels in agricultural water may provide a mechanism for overcoming these obstacles. Thus, this proof-of-concept study uses previously published datasets to train, test, and compare E. coli predictive models using multiple algorithms and performance measures. Since the collection of different feature data carries specific costs for growers, predictive performance was compared for models built using different feature types [geospatial, water quality, stream traits, and/or weather features]. Model performance was assessed against baseline regression models. Model performance varied considerably with root-mean-squared errors and Kendall’s Tau ranging between 0.37 and 1.03, and 0.07 and 0.55, respectively. Overall, models that included turbidity, rain, and temperature outperformed all other models regardless of the algorithm used. Turbidity and weather factors were also found to drive model accuracy even when other feature types were included in the model. These findings confirm previous conclusions that machine learning models may be useful for predicting when, where, and at what level E. coli (and associated hazards) are likely to be present in preharvest agricultural water sources. This study also identifies specific algorithm-predictor combinations that should be the foci of future efforts to develop deployable models (i.e., models that can be used to guide on-farm decision-making and risk mitigation). When deploying E. coli predictive models in the field, it is important to note that past research indicates an inconsistent relationship between E. coli levels and foodborne pathogen presence. Thus, models that predict E. coli levels in agricultural water may be useful for assessing fecal contamination status and ensuring compliance with regulations but should not be used to assess the risk that specific pathogens of concern (e.g., Salmonella, Listeria) are present.},
  archive      = {J_FRAI},
  author       = {Weller, Daniel L. and Love, Tanzy M. T. and Wiedmann, Martin},
  doi          = {10.3389/frai.2021.628441},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {5},
  pages        = {628441},
  shortjournal = {Front. Artif. Intell.},
  title        = {Interpretability versus accuracy: A comparison of machine learning models built using different algorithms, performance measures, and features to predict e. coli levels in agricultural water},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Quantification: The view from natural language generation.
<em>FRAI</em>, <em>4</em>, 627177. (<a
href="https://doi.org/10.3389/frai.2021.627177">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quantification is one of the central topics in language and computation, and the interplay of collectivity, distributivity, cumulativity, and plurality is at the heart of the semantics of quantification expressions. However, its aspects are usually discussed piecemeal, distributed, and only from an interpretative perspective with selected linguistic examples, often blurring the overall picture. In this article, quantification phenomena are investigated from the perspective of natural language generation. Starting with a small-scale, but realistic scenario, the necessary steps toward generating quantifier expressions for a perceived situation are explained. Together with the automatically generated descriptions of the scenario, the observations made are shown to present new insights into the interplay, and the semantics of quantification expressions and plurals, in general. The results highlight the importance of taking different points of view in the field of language and computation.},
  archive      = {J_FRAI},
  author       = {Carstensen, Kai-Uwe},
  doi          = {10.3389/frai.2021.627177},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {5},
  pages        = {627177},
  shortjournal = {Front. Artif. Intell.},
  title        = {Quantification: The view from natural language generation},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Virtual cohorts and synthetic data in dementia: An
illustration of their potential to advance research. <em>FRAI</em>,
<em>4</em>, 613956. (<a
href="https://doi.org/10.3389/frai.2021.613956">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When attempting to answer questions of interest, scientists often encounter hurdles that may stem from limited access to existing adequate datasets as a consequence of poor data sharing practices, constraining administrative practices. Further, when attempting to integrate data, differences in existing datasets also impose challenges that limit opportunities for data integration. As a result, the pace of scientific advancements is suboptimal. Synthetic data and virtual cohorts generated using innovative computational techniques represent an opportunity to overcome some of these limitations and consequently, to advance scientific developments. In this paper, we demonstrate the use of virtual cohorts techniques to generate a synthetic dataset that mirrors a deeply phenotyped sample of preclinical dementia research participants.},
  archive      = {J_FRAI},
  author       = {Muniz-Terrera, Graciela and Mendelevitch, Ofer and Barnes, Rodrigo and Lesh, Michael D.},
  doi          = {10.3389/frai.2021.613956},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {5},
  pages        = {613956},
  shortjournal = {Front. Artif. Intell.},
  title        = {Virtual cohorts and synthetic data in dementia: An illustration of their potential to advance research},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An explainable multimodal neural network architecture for
predicting epilepsy comorbidities based on administrative claims data.
<em>FRAI</em>, <em>4</em>, 610197. (<a
href="https://doi.org/10.3389/frai.2021.610197">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Epilepsy is a complex brain disorder characterized by repetitive seizure events. Epilepsy patients often suffer from various and severe physical and psychological comorbidities (e.g., anxiety, migraine, and stroke). While general comorbidity prevalences and incidences can be estimated from epidemiological data, such an approach does not take into account that actual patient-specific risks can depend on various individual factors, including medication. This motivates to develop a machine learning approach for predicting risks of future comorbidities for individual epilepsy patients. In this work, we use inpatient and outpatient administrative health claims data of around 19,500 U.S. epilepsy patients. We suggest a dedicated multimodal neural network architecture (Deep personalized LOngitudinal convolutional RIsk model—DeepLORI) to predict the time-dependent risk of six common comorbidities of epilepsy patients. We demonstrate superior performance of DeepLORI in a comparison with several existing methods. Moreover, we show that DeepLORI-based predictions can be interpreted on the level of individual patients. Using a game theoretic approach, we identify relevant features in DeepLORI models and demonstrate that model predictions are explainable in light of existing knowledge about the disease. Finally, we validate the model on independent data from around 97,000 patients, showing good generalization and stable prediction performance over time.},
  archive      = {J_FRAI},
  author       = {Linden, Thomas and De Jong, Johann and Lu, Chao and Kiri, Victor and Haeffs, Kathrin and Fröhlich, Holger},
  doi          = {10.3389/frai.2021.610197},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {5},
  pages        = {610197},
  shortjournal = {Front. Artif. Intell.},
  title        = {An explainable multimodal neural network architecture for predicting epilepsy comorbidities based on administrative claims data},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). COVID-FACT: A fully-automated capsule network-based
framework for identification of COVID-19 cases from chest CT scans.
<em>FRAI</em>, <em>4</em>, 598932. (<a
href="https://doi.org/10.3389/frai.2021.598932">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The newly discovered Coronavirus Disease 2019 (COVID-19) has been globally spreading and causing hundreds of thousands of deaths around the world as of its first emergence in late 2019. The rapid outbreak of this disease has overwhelmed health care infrastructures and arises the need to allocate medical equipment and resources more efficiently. The early diagnosis of this disease will lead to the rapid separation of COVID-19 and non-COVID cases, which will be helpful for health care authorities to optimize resource allocation plans and early prevention of the disease. In this regard, a growing number of studies are investigating the capability of deep learning for early diagnosis of COVID-19. Computed tomography (CT) scans have shown distinctive features and higher sensitivity compared to other diagnostic tests, in particular the current gold standard, i.e., the Reverse Transcription Polymerase Chain Reaction (RT-PCR) test. Current deep learning-based algorithms are mainly developed based on Convolutional Neural Networks (CNNs) to identify COVID-19 pneumonia cases. CNNs, however, require extensive data augmentation and large datasets to identify detailed spatial relations between image instances. Furthermore, existing algorithms utilizing CT scans, either extend slice-level predictions to patient-level ones using a simple thresholding mechanism or rely on a sophisticated infection segmentation to identify the disease. In this paper, we propose a two-stage fully automated CT-based framework for identification of COVID-19 positive cases referred to as the “COVID-FACT”. COVID-FACT utilizes Capsule Networks, as its main building blocks and is, therefore, capable of capturing spatial information. In particular, to make the proposed COVID-FACT independent from sophisticated segmentations of the area of infection, slices demonstrating infection are detected at the first stage and the second stage is responsible for classifying patients into COVID and non-COVID cases. COVID-FACT detects slices with infection, and identifies positive COVID-19 cases using an in-house CT scan dataset, containing COVID-19, community acquired pneumonia, and normal cases. Based on our experiments, COVID-FACT achieves an accuracy of &lt;mml:math id=&quot;m1&quot; xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;90.82&lt;/mml:mn&gt;&lt;mml:mtext&gt;%&lt;/mml:mtext&gt;&lt;/mml:mrow&gt;&lt;/mml:math&gt;, a sensitivity of &lt;mml:math id=&quot;m2&quot; xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;94.55&lt;/mml:mn&gt;&lt;mml:mtext&gt;%&lt;/mml:mtext&gt;&lt;/mml:mrow&gt;&lt;/mml:math&gt;, a specificity of &lt;mml:math id=&quot;m3&quot; xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;86.04&lt;/mml:mn&gt;&lt;mml:mtext&gt;%&lt;/mml:mtext&gt;&lt;/mml:mrow&gt;&lt;/mml:math&gt;, and an Area Under the Curve (AUC) of 0.98, while depending on far less supervision and annotation, in comparison to its counterparts.},
  archive      = {J_FRAI},
  author       = {Heidarian, Shahin and Afshar, Parnian and Enshaei, Nastaran and Naderkhani, Farnoosh and Rafiee, Moezedin Javad and Babaki Fard, Faranak and Samimi, Kaveh and Atashzar, S. Farokh and Oikonomou, Anastasia and Plataniotis, Konstantinos N. and Mohammadi, Arash},
  doi          = {10.3389/frai.2021.598932},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {5},
  pages        = {598932},
  shortjournal = {Front. Artif. Intell.},
  title        = {COVID-FACT: A fully-automated capsule network-based framework for identification of COVID-19 cases from chest CT scans},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Preventing failures by dataset shift detection in
safety-critical graph applications. <em>FRAI</em>, <em>4</em>, 589632.
(<a href="https://doi.org/10.3389/frai.2021.589632">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dataset shift refers to the problem where the input data distribution may change over time (e.g., between training and test stages). Since this can be a critical bottleneck in several safety-critical applications such as healthcare, drug-discovery, etc., dataset shift detection has become an important research issue in machine learning. Though several existing efforts have focused on image/video data, applications with graph-structured data have not received sufficient attention. Therefore, in this paper, we investigate the problem of detecting shifts in graph structured data through the lens of statistical hypothesis testing. Specifically, we propose a practical two-sample test based approach for shift detection in large-scale graph structured data. Our approach is very flexible in that it is suitable for both undirected and directed graphs, and eliminates the need for equal sample sizes. Using empirical studies, we demonstrate the effectiveness of the proposed test in detecting dataset shifts. We also corroborate these findings using real-world datasets, characterized by directed graphs and a large number of nodes.},
  archive      = {J_FRAI},
  author       = {Song, Hoseung and Thiagarajan, Jayaraman J. and Kailkhura, Bhavya},
  doi          = {10.3389/frai.2021.589632},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {5},
  pages        = {589632},
  shortjournal = {Front. Artif. Intell.},
  title        = {Preventing failures by dataset shift detection in safety-critical graph applications},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Explainable AI and reinforcement learning—a systematic
review of current approaches and trends. <em>FRAI</em>, <em>4</em>,
550030. (<a href="https://doi.org/10.3389/frai.2021.550030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Research into Explainable Artificial Intelligence (XAI) has been increasing in recent years as a response to the need for increased transparency and trust in AI. This is particularly important as AI is used in sensitive domains with societal, ethical, and safety implications. Work in XAI has primarily focused on Machine Learning (ML) for classification, decision, or action, with detailed systematic reviews already undertaken. This review looks to explore current approaches and limitations for XAI in the area of Reinforcement Learning (RL). From 520 search results, 25 studies (including 5 snowball sampled) are reviewed, highlighting visualization, query-based explanations, policy summarization, human-in-the-loop collaboration, and verification as trends in this area. Limitations in the studies are presented, particularly a lack of user studies, and the prevalence of toy-examples and difficulties providing understandable explanations. Areas for future study are identified, including immersive visualization, and symbolic representation.},
  archive      = {J_FRAI},
  author       = {Wells, Lindsay and Bednarz, Tomasz},
  doi          = {10.3389/frai.2021.550030},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {5},
  pages        = {550030},
  shortjournal = {Front. Artif. Intell.},
  title        = {Explainable AI and reinforcement Learning—A systematic review of current approaches and trends},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). CNN-based LCD transcription of blood pressure from a mobile
phone camera. <em>FRAI</em>, <em>4</em>, 543176. (<a
href="https://doi.org/10.3389/frai.2021.543176">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Routine blood pressure (BP) measurement in pregnancy is commonly performed using automated oscillometric devices. Since no wireless oscillometric BP device has been validated in preeclamptic populations, a simple approach for capturing readings from such devices is needed, especially in low-resource settings where transmission of BP data from the field to central locations is an important mechanism for triage. To this end, a total of 8192 BP readings were captured from the Liquid Crystal Display (LCD) screen of a standard Omron M7 self-inflating BP cuff using a cellphone camera. A cohort of 49 lay midwives captured these data from 1697 pregnant women carrying singletons between 6 weeks and 40 weeks gestational age in rural Guatemala during routine screening. Images exhibited a wide variability in their appearance due to variations in orientation and parallax; environmental factors such as lighting, shadows; and image acquisition factors such as motion blur and problems with focus. Images were independently labeled for readability and quality by three annotators (BP range: 34–203 mm Hg) and disagreements were resolved. Methods to preprocess and automatically segment the LCD images into diastolic BP, systolic BP and heart rate using a contour-based technique were developed. A deep convolutional neural network was then trained to convert the LCD images into numerical values using a multi-digit recognition approach. On readable low- and high-quality images, this proposed approach achieved a 91% classification accuracy and mean absolute error of 3.19 mm Hg for systolic BP and 91% accuracy and mean absolute error of 0.94 mm Hg for diastolic BP. These error values are within the FDA guidelines for BP monitoring when poor quality images are excluded. The performance of the proposed approach was shown to be greatly superior to state-of-the-art open-source tools (Tesseract and the Google Vision API). The algorithm was developed such that it could be deployed on a phone and work without connectivity to a network.},
  archive      = {J_FRAI},
  author       = {Kulkarni, Samruddhi S. and Katebi, Nasim and Valderrama, Camilo E. and Rohloff, Peter and Clifford, Gari D.},
  doi          = {10.3389/frai.2021.543176},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {5},
  pages        = {543176},
  shortjournal = {Front. Artif. Intell.},
  title        = {CNN-based LCD transcription of blood pressure from a mobile phone camera},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Neuronal sequence models for bayesian online inference.
<em>FRAI</em>, <em>4</em>, 530937. (<a
href="https://doi.org/10.3389/frai.2021.530937">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Various imaging and electrophysiological studies in a number of different species and brain regions have revealed that neuronal dynamics associated with diverse behavioral patterns and cognitive tasks take on a sequence-like structure, even when encoding stationary concepts. These neuronal sequences are characterized by robust and reproducible spatiotemporal activation patterns. This suggests that the role of neuronal sequences may be much more fundamental for brain function than is commonly believed. Furthermore, the idea that the brain is not simply a passive observer but an active predictor of its sensory input, is supported by an enormous amount of evidence in fields as diverse as human ethology and physiology, besides neuroscience. Hence, a central aspect of this review is to illustrate how neuronal sequences can be understood as critical for probabilistic predictive information processing, and what dynamical principles can be used as generators of neuronal sequences. Moreover, since different lines of evidence from neuroscience and computational modeling suggest that the brain is organized in a functional hierarchy of time scales, we will also review how models based on sequence-generating principles can be embedded in such a hierarchy, to form a generative model for recognition and prediction of sensory input. We shortly introduce the Bayesian brain hypothesis as a prominent mathematical description of how online, i.e., fast, recognition, and predictions may be computed by the brain. Finally, we briefly discuss some recent advances in machine learning, where spatiotemporally structured methods (akin to neuronal sequences) and hierarchical networks have independently been developed for a wide range of tasks. We conclude that the investigation of specific dynamical and structural principles of sequential brain activity not only helps us understand how the brain processes information and generates predictions, but also informs us about neuroscientific principles potentially useful for designing more efficient artificial neuronal networks for machine learning tasks.},
  archive      = {J_FRAI},
  author       = {Frölich, Sascha and Marković, Dimitrije and Kiebel, Stefan J.},
  doi          = {10.3389/frai.2021.530937},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {5},
  pages        = {530937},
  shortjournal = {Front. Artif. Intell.},
  title        = {Neuronal sequence models for bayesian online inference},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Corrigendum: The autonomous mind: The right to freedom of
thought in the twenty-first century. <em>FRAI</em>, <em>4</em>, 672279.
(<a href="https://doi.org/10.3389/frai.2021.672279">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {McCarthy-Jones, Simon},
  doi          = {10.3389/frai.2021.672279},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {4},
  pages        = {672279},
  shortjournal = {Front. Artif. Intell.},
  title        = {Corrigendum: the autonomous mind: the right to freedom of thought in the twenty-first century},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Contact tracing in healthcare settings during the COVID-19
pandemic using bluetooth low energy and artificial intelligence—a
viewpoint. <em>FRAI</em>, <em>4</em>, 666599. (<a
href="https://doi.org/10.3389/frai.2021.666599">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The COVID-19 pandemic has inflicted great damage with effects that will likely linger for a long time. This crisis has highlighted the importance of contact tracing in healthcare settings because hospitalized patients are among the high risk for complications and death. Moreover, effective contact tracing schemes are not yet available in healthcare settings. A good contact tracing technology in healthcare settings should be equipped with six features: promptness, simplicity, high precision, integration, minimized privacy concerns, and social fairness. One potential solution that addresses all of these elements leverages an indoor real-time location system based on Bluetooth Low Energy and artificial intelligence.},
  archive      = {J_FRAI},
  author       = {Tang, Guanglin and Westover, Kenneth and Jiang, Steve},
  doi          = {10.3389/frai.2021.666599},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {4},
  pages        = {666599},
  shortjournal = {Front. Artif. Intell.},
  title        = {Contact tracing in healthcare settings during the COVID-19 pandemic using bluetooth low energy and artificial Intelligence—A viewpoint},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Applications of topological data analysis in oncology.
<em>FRAI</em>, <em>4</em>, 659037. (<a
href="https://doi.org/10.3389/frai.2021.659037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The emergence of the information age in the last few decades brought with it an explosion of biomedical data. But with great power comes great responsibility: there is now a pressing need for new data analysis algorithms to be developed to make sense of the data and transform this information into knowledge which can be directly translated into the clinic. Topological data analysis (TDA) provides a promising path forward: using tools from the mathematical field of algebraic topology, TDA provides a framework to extract insights into the often high-dimensional, incomplete, and noisy nature of biomedical data. Nowhere is this more evident than in the field of oncology, where patient-specific data is routinely presented to clinicians in a variety of forms, from imaging to single cell genomic sequencing. In this review, we focus on applications involving persistent homology, one of the main tools of TDA. We describe some recent successes of TDA in oncology, specifically in predicting treatment responses and prognosis, tumor segmentation and computer-aided diagnosis, disease classification, and cellular architecture determination. We also provide suggestions on avenues for future research including utilizing TDA to analyze cancer time-series data such as gene expression changes during pathogenesis, investigation of the relation between angiogenic vessel structure and treatment efficacy from imaging data, and experimental confirmation that geometric and topological connectivity implies functional connectivity in the context of cancer.},
  archive      = {J_FRAI},
  author       = {Bukkuri, Anuraag and Andor, Noemi and Darcy, Isabel K.},
  doi          = {10.3389/frai.2021.659037},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {4},
  pages        = {659037},
  shortjournal = {Front. Artif. Intell.},
  title        = {Applications of topological data analysis in oncology},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Considering performance in the automated and manual coding
of sociolinguistic variables: Lessons from variable (ING).
<em>FRAI</em>, <em>4</em>, 648543. (<a
href="https://doi.org/10.3389/frai.2021.648543">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Impressionistic coding of sociolinguistic variables like English (ING), the alternation between pronunciations like talkin&#39; and talking, has been a central part of the analytic workflow in studies of language variation and change for over a half-century. Techniques for automating the measurement and coding for a wide range of sociolinguistic data have been on the rise over recent decades but procedures for coding some features, especially those without clearly defined acoustic correlates like (ING), have lagged behind others, such as vowels and sibilants. This paper explores computational methods for automatically coding variable (ING) in speech recordings, examining the use of automatic speech recognition procedures related to forced alignment (using the Montreal Forced Aligner) as well as supervised machine learning algorithms (linear and radial support vector machines, and random forests). Considering the automated coding of pronunciation variables like (ING) raises broader questions for sociolinguistic methods, such as how much different human analysts agree in their impressionistic codes for such variables and what data might act as the “gold standard” for training and testing of automated procedures. This paper explores several of these considerations in automated, and manual, coding of sociolinguistic variables and provides baseline performance data for automated and manual coding methods. We consider multiple ways of assessing algorithms&#39; performance, including agreement with human coders, as well as the impact on the outcome of an analysis of (ING) that includes linguistic and social factors. Our results show promise for automated coding methods but also highlight that variability in results should be expected even with careful human coded data. All data for our study come from the public Corpus of Regional African American Language and code and derivative datasets (including our hand-coded data) are available with the paper.},
  archive      = {J_FRAI},
  author       = {Kendall, Tyler and Vaughn, Charlotte and Farrington, Charlie and Gunter, Kaylynn and McLean, Jaidan and Tacata, Chloe and Arnson, Shelby},
  doi          = {10.3389/frai.2021.648543},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {4},
  pages        = {648543},
  shortjournal = {Front. Artif. Intell.},
  title        = {Considering performance in the automated and manual coding of sociolinguistic variables: Lessons from variable (ING)},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Machine learning analysis of hydrologic exchange flows and
transit time distributions in a large regulated river. <em>FRAI</em>,
<em>4</em>, 648071. (<a
href="https://doi.org/10.3389/frai.2021.648071">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hydrologic exchange between river channels and adjacent subsurface environments is a key process that influences water quality and ecosystem function in river corridors. High-resolution numerical models were often used to resolve the spatial and temporal variations of exchange flows, which are computationally expensive. In this study, we adopt Random Forest (RF) and Extreme Gradient Boosting (XGB) approaches for deriving reduced order models of hydrologic exchange flows and associated transit time distributions, with integrated field observations (e.g., bathymetry) and hydrodynamic simulation data (e.g., river velocity, depth). The setup allows an improved understanding of the influences of various physical, spatial, and temporal factors on the hydrologic exchange flows and transit times. The predictors also contain those derived using hybrid clustering, leveraging our previous work on river corridor system hydromorphic classification. The machine learning-based predictive models are developed and validated along the Columbia River Corridor, and the results show that the top parameters are the thickness of the top geological formation layer, the flow regime, river velocity, and river depth; the RF and XGB models can achieve 70% to 80% accuracy and therefore are effective alternatives to the computational demanding numerical models of exchange flows and transit time distributions. Each machine learning model with its favorable configuration and setup have been evaluated. The transferability of the models to other river reaches and larger scales, which mostly depends on data availability, is also discussed.},
  archive      = {J_FRAI},
  author       = {Ren, Huiying and Song, Xuehang and Fang, Yilin and Hou, Z. Jason and Scheibe, Timothy D.},
  doi          = {10.3389/frai.2021.648071},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {4},
  pages        = {648071},
  shortjournal = {Front. Artif. Intell.},
  title        = {Machine learning analysis of hydrologic exchange flows and transit time distributions in a large regulated river},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Food/non-food classification of real-life egocentric images
in low- and middle-income countries based on image tagging features.
<em>FRAI</em>, <em>4</em>, 644712. (<a
href="https://doi.org/10.3389/frai.2021.644712">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Malnutrition, including both undernutrition and obesity, is a significant problem in low- and middle-income countries (LMICs). In order to study malnutrition and develop effective intervention strategies, it is crucial to evaluate nutritional status in LMICs at the individual, household, and community levels. In a multinational research project supported by the Bill &amp;amp; Melinda Gates Foundation, we have been using a wearable technology to conduct objective dietary assessment in sub-Saharan Africa. Our assessment includes multiple diet-related activities in urban and rural families, including food sources (e.g., shopping, harvesting, and gathering), preservation/storage, preparation, cooking, and consumption (e.g., portion size and nutrition analysis). Our wearable device (“eButton” worn on the chest) acquires real-life images automatically during wake hours at preset time intervals. The recorded images, in amounts of tens of thousands per day, are post-processed to obtain the information of interest. Although we expect future Artificial Intelligence (AI) technology to extract the information automatically, at present we utilize AI to separate the acquired images into two binary classes: images with (Class 1) and without (Class 0) edible items. As a result, researchers need only to study Class-1 images, reducing their workload significantly. In this paper, we present a composite machine learning method to perform this classification, meeting the specific challenges of high complexity and diversity in the real-world LMIC data. Our method consists of a deep neural network (DNN) and a shallow learning network (SLN) connected by a novel probabilistic network interface layer. After presenting the details of our method, an image dataset acquired from Ghana is utilized to train and evaluate the machine learning system. Our comparative experiment indicates that the new composite method performs better than the conventional deep learning method assessed by integrated measures of sensitivity, specificity, and burden index, as indicated by the Receiver Operating Characteristic (ROC) curve.},
  archive      = {J_FRAI},
  author       = {Chen, Guangzong and Jia, Wenyan and Zhao, Yifan and Mao, Zhi-Hong and Lo, Benny and Anderson, Alex K. and Frost, Gary and Jobarteh, Modou L. and McCrory, Megan A. and Sazonov, Edward and Steiner-Asiedu, Matilda and Ansong, Richard S. and Baranowski, Thomas and Burke, Lora and Sun, Mingui},
  doi          = {10.3389/frai.2021.644712},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {4},
  pages        = {644712},
  shortjournal = {Front. Artif. Intell.},
  title        = {Food/Non-food classification of real-life egocentric images in low- and middle-income countries based on image tagging features},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Using twitter data for the study of language change in
low-resource languages. A panel study of relative pronouns in frisian.
<em>FRAI</em>, <em>4</em>, 644554. (<a
href="https://doi.org/10.3389/frai.2021.644554">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the usability of Twitter as a resource for the study of language change in progress in low-resource languages. It is a panel study of a vigorous change in progress, the loss of final t in four relative pronouns (dy&#39;t, dêr&#39;t, wêr&#39;t, wa&#39;t) in Frisian, a language spoken by ± 450,000 speakers in the north-west of the Netherlands. This paper deals with the issues encountered in retrieving and analyzing tweets in low-resource languages, in the analysis of low-frequency variables, and in gathering background information on Twitterers. In this panel study we were able to identify and track 159 individual Twitterers, whose Frisian (and Dutch) tweets posted in the era 2010–2019 were collected. Nevertheless, a solid analysis of the sociolinguistic factors in this language change in progress was hampered by unequal age distributions among the Twitterers, the fact that the youngest birth cohorts have given up Twitter almost completely after 2014 and that the variables have a low frequency and are unequally spread over Twitterers.},
  archive      = {J_FRAI},
  author       = {Dijkstra, Jelske and Heeringa, Wilbert and Jongbloed-Faber, Lysbeth and Van de Velde, Hans},
  doi          = {10.3389/frai.2021.644554},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {4},
  pages        = {644554},
  shortjournal = {Front. Artif. Intell.},
  title        = {Using twitter data for the study of language change in low-resource languages. a panel study of relative pronouns in frisian},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Closed-form results for prior constraints in sum-product
networks. <em>FRAI</em>, <em>4</em>, 644062. (<a
href="https://doi.org/10.3389/frai.2021.644062">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Incorporating constraints is a major concern in probabilistic machine learning. A wide variety of problems require predictions to be integrated with reasoning about constraints, from modeling routes on maps to approving loan predictions. In the former, we may require the prediction model to respect the presence of physical paths between the nodes on the map, and in the latter, we may require that the prediction model respect fairness constraints that ensure that outcomes are not subject to bias. Broadly speaking, constraints may be probabilistic, logical or causal, but the overarching challenge is to determine if and how a model can be learnt that handles a declared constraint. To the best of our knowledge, treating this in a general way is largely an open problem. In this paper, we investigate how the learning of sum-product networks, a newly introduced and increasingly popular class of tractable probabilistic models, is possible with declared constraints. We obtain correctness results about the training of these models, by establishing a relationship between probabilistic constraints and the model&#39;s parameters.},
  archive      = {J_FRAI},
  author       = {Papantonis, Ioannis and Belle, Vaishak},
  doi          = {10.3389/frai.2021.644062},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {4},
  pages        = {644062},
  shortjournal = {Front. Artif. Intell.},
  title        = {Closed-form results for prior constraints in sum-product networks},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The promise of AI for DILI prediction. <em>FRAI</em>,
<em>4</em>, 638410. (<a
href="https://doi.org/10.3389/frai.2021.638410">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Drug-induced liver injury (DILI) is a common reason for the withdrawal of a drug from the market. Early assessment of DILI risk is an essential part of drug development, but it is rendered challenging prior to clinical trials by the complex factors that give rise to liver damage. Artificial intelligence (AI) approaches, particularly those building on machine learning, range from random forests to more recent techniques such as deep learning, and provide tools that can analyze chemical compounds and accurately predict some of their properties based purely on their structure. This article reviews existing AI approaches to predicting DILI and elaborates on the challenges that arise from the as yet limited availability of data. Future directions are discussed focusing on rich data modalities, such as 3D spheroids, and the slow but steady increase in drugs annotated with DILI risk labels.},
  archive      = {J_FRAI},
  author       = {Vall, Andreu and Sabnis, Yogesh and Shi, Jiye and Class, Reiner and Hochreiter, Sepp and Klambauer, Günter},
  doi          = {10.3389/frai.2021.638410},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {4},
  pages        = {638410},
  shortjournal = {Front. Artif. Intell.},
  title        = {The promise of AI for DILI prediction},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Artificial intelligence for prognostic scores in oncology: A
benchmarking study. <em>FRAI</em>, <em>4</em>, 625573. (<a
href="https://doi.org/10.3389/frai.2021.625573">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Introduction: Prognostic scores are important tools in oncology to facilitate clinical decision-making based on patient characteristics. To date, classic survival analysis using Cox proportional hazards regression has been employed in the development of these prognostic scores. With the advance of analytical models, this study aimed to determine if more complex machine-learning algorithms could outperform classical survival analysis methods.Methods: In this benchmarking study, two datasets were used to develop and compare different prognostic models for overall survival in pan-cancer populations: a nationwide EHR-derived de-identified database for training and in-sample testing and the OAK (phase III clinical trial) dataset for out-of-sample testing. A real-world database comprised 136K first-line treated cancer patients across multiple cancer types and was split into a 90% training and 10% testing dataset, respectively. The OAK dataset comprised 1,187 patients diagnosed with non-small cell lung cancer. To assess the effect of the covariate number on prognostic performance, we formed three feature sets with 27, 44 and 88 covariates. In terms of methods, we benchmarked ROPRO, a prognostic score based on the Cox model, against eight complex machine-learning models: regularized Cox, Random Survival Forests (RSF), Gradient Boosting (GB), DeepSurv (DS), Autoencoder (AE) and Super Learner (SL). The C-index was used as the performance metric to compare different models.Results: For in-sample testing on the real-world database the resulting C-index [95% CI] values for RSF 0.720 [0.716, 0.725], GB 0.722 [0.718, 0.727], DS 0.721 [0.717, 0.726] and lastly, SL 0.723 [0.718, 0.728] showed significantly better performance as compared to ROPRO 0.701 [0.696, 0.706]. Similar results were derived across all feature sets. However, for the out-of-sample validation on OAK, the stronger performance of the more complex models was not apparent anymore. Consistently, the increase in the number of prognostic covariates did not lead to an increase in model performance.Discussion: The stronger performance of the more complex models did not generalize when applied to an out-of-sample dataset. We hypothesize that future research may benefit by adding multimodal data to exploit advantages of more complex models.},
  archive      = {J_FRAI},
  author       = {Loureiro, Hugo and Becker, Tim and Bauer-Mehren, Anna and Ahmidi, Narges and Weberpals, Janick},
  doi          = {10.3389/frai.2021.625573},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {4},
  pages        = {625573},
  shortjournal = {Front. Artif. Intell.},
  title        = {Artificial intelligence for prognostic scores in oncology: A benchmarking study},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The future of computational linguistics: On beyond alchemy.
<em>FRAI</em>, <em>4</em>, 625341. (<a
href="https://doi.org/10.3389/frai.2021.625341">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Over the decades, fashions in Computational Linguistics have changed again and again, with major shifts in motivations, methods and applications. When digital computers first appeared, linguistic analysis adopted the new methods of information theory, which accorded well with the ideas that dominated psychology and philosophy. Then came formal language theory and the idea of AI as applied logic, in sync with the development of cognitive science. That was followed by a revival of 1950s-style empiricism—AI as applied statistics—which in turn was followed by the age of deep nets. There are signs that the climate is changing again, and we offer some thoughts about paths forward, especially for younger researchers who will soon be the leaders.},
  archive      = {J_FRAI},
  author       = {Church, Kenneth and Liberman, Mark},
  doi          = {10.3389/frai.2021.625341},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {4},
  pages        = {625341},
  shortjournal = {Front. Artif. Intell.},
  title        = {The future of computational linguistics: On beyond alchemy},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An application of an embedded model estimator to a synthetic
nonstationary reservoir model with multiple secondary variables.
<em>FRAI</em>, <em>4</em>, 624697. (<a
href="https://doi.org/10.3389/frai.2021.624697">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A method (Ember) for nonstationary spatial modeling with multiple secondary variables by combining Geostatistics with Random Forests is applied to a three-dimensional Reservoir Model. It extends the Random Forest method to an interpolation algorithm retaining similar consistency properties to both Geostatistical algorithms and Random Forests. It allows embedding of simpler interpolation algorithms into the process, combining them through the Random Forest training process. The algorithm estimates a conditional distribution at each target location. The family of such distributions is called the model envelope. An algorithm to produce stochastic simulations from the envelope is demonstrated. This algorithm allows the influence of the secondary variables, as well as the variability of the result to vary by location in the simulation.},
  archive      = {J_FRAI},
  author       = {Daly, Colin},
  doi          = {10.3389/frai.2021.624697},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {4},
  pages        = {624697},
  shortjournal = {Front. Artif. Intell.},
  title        = {An application of an embedded model estimator to a synthetic nonstationary reservoir model with multiple secondary variables},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Ethical questions raised by AI-supported mentoring in higher
education. <em>FRAI</em>, <em>4</em>, 624050. (<a
href="https://doi.org/10.3389/frai.2021.624050">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mentoring is a highly personal and individual process, in which mentees take advantage of expertise and experience to expand their knowledge and to achieve individual goals. The emerging use of AI in mentoring processes in higher education not only necessitates the adherence to applicable laws and regulations (e.g., relating to data protection and non-discrimination) but further requires a thorough understanding of ethical norms, guidelines, and unresolved issues (e.g., integrity of data, safety, and security of systems, and confidentiality, avoiding bias, insuring trust in and transparency of algorithms). Mentoring in Higher Education requires one of the highest degrees of trust, openness, and social–emotional support, as much is at the stake for mentees, especially their academic attainment, career options, and future life choices. However, ethical compromises seem to be common when digital systems are introduced, and the underlying ethical questions in AI-supported mentoring are still insufficiently addressed in research, development, and application. One of the challenges is to strive for privacy and data economy on the one hand, while Big Data is the prerequisite of AI-supported environments on the other hand. How can ethical norms and general guidelines of AIED be respected in complex digital mentoring processes? This article strives to start a discourse on the relevant ethical questions and in this way raise awareness for the ethical development and use of future data-driven, AI-supported mentoring environments in higher education.},
  archive      = {J_FRAI},
  author       = {Köbis, Laura and Mehner, Caroline},
  doi          = {10.3389/frai.2021.624050},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {4},
  pages        = {624050},
  shortjournal = {Front. Artif. Intell.},
  title        = {Ethical questions raised by AI-supported mentoring in higher education},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A novel machine learning model for dose prediction in
prostate volumetric modulated arc therapy using output initialization
and optimization priorities. <em>FRAI</em>, <em>4</em>, 624038. (<a
href="https://doi.org/10.3389/frai.2021.624038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Treatment planning for prostate volumetric modulated arc therapy (VMAT) can take 5–30 min per plan to optimize and calculate, limiting the number of plan options that can be explored before the final plan decision. Inspired by the speed and accuracy of modern machine learning models, such as residual networks, we hypothesized that it was possible to use a machine learning model to bypass the time-intensive dose optimization and dose calculation steps, arriving directly at an estimate of the resulting dose distribution for use in multi-criteria optimization (MCO). In this study, we present a novel machine learning model for predicting the dose distribution for a given patient with a given set of optimization priorities. Our model innovates upon the existing machine learning techniques by utilizing optimization priorities and our understanding of dose map shapes to initialize the dose distribution before dose refinement via a voxel-wise residual network. Each block of the residual network individually updates the initialized dose map before passing to the next block. Our model also utilizes contiguous and atrous patch sampling to effectively increase the receptive fields of each layer in the residual network, decreasing its number of layers, increasing model prediction and training speed, and discouraging overfitting without compromising on the accuracy. For analysis, 100 prostate VMAT cases were used to train and test the model. The model was evaluated by the training and testing errors produced by 50 iterations of 10-fold cross-validation, with 100 cases randomly shuffled into the subsets at each iteration. The error of the model is modest for this data, with average dose map root-mean-square errors (RMSEs) of 2.38 ± 0.47% of prescription dose overall patients and all optimization priority combinations in the patient testing sets. The model was also evaluated at iteratively smaller training set sizes, suggesting that the model requires between 60 and 90 patients for optimal performance. This model may be used for quickly estimating the Pareto set of feasible dose objectives, which may directly accelerate the treatment planning process and indirectly improve final plan quality by allowing more time for plan refinement.},
  archive      = {J_FRAI},
  author       = {Jensen, P. James and Zhang, Jiahan and Koontz, Bridget F. and Wu, Q. Jackie},
  doi          = {10.3389/frai.2021.624038},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {4},
  pages        = {624038},
  shortjournal = {Front. Artif. Intell.},
  title        = {A novel machine learning model for dose prediction in prostate volumetric modulated arc therapy using output initialization and optimization priorities},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Nudging healthy choices in food search through visual
attractiveness. <em>FRAI</em>, <em>4</em>, 621743. (<a
href="https://doi.org/10.3389/frai.2021.621743">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recipe websites are becoming increasingly popular to support people in their home cooking. However, most of these websites prioritize popular recipes, which tend to be unhealthy. Drawing upon research on visual biases and nudges, this paper investigates whether healthy food choices can be supported in food search by depicting attractive images alongside recipes, as well as by re-ranking search results on health. After modelling the visual attractiveness of recipe images, we asked 239 users to search for specific online recipes and to select those they liked the most. Our analyses revealed that users tended to choose a healthier recipe if a visually attractive image was depicted alongside it, as well as if it was listed at the top of a list of search results. Even though less popular recipes were promoted this way, it did not come at the cost of a user’s level of satisfaction.},
  archive      = {J_FRAI},
  author       = {Starke, Alain D. and Willemsen, Martijn C. and Trattner, Christoph},
  doi          = {10.3389/frai.2021.621743},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {4},
  pages        = {621743},
  shortjournal = {Front. Artif. Intell.},
  title        = {Nudging healthy choices in food search through visual attractiveness},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Computed tomography radiomics kinetics as early imaging
correlates of osteoradionecrosis in oropharyngeal cancer patients.
<em>FRAI</em>, <em>4</em>, 618469. (<a
href="https://doi.org/10.3389/frai.2021.618469">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Osteoradionecrosis (ORN) is a major side-effect of radiation therapy in oropharyngeal cancer (OPC) patients. In this study, we demonstrate that early prediction of ORN is possible by analyzing the temporal evolution of mandibular subvolumes receiving radiation. For our analysis, we use computed tomography (CT) scans from 21 OPC patients treated with Intensity Modulated Radiation Therapy (IMRT) with subsequent radiographically-proven ≥ grade II ORN, at three different time points: pre-IMRT, 2-months, and 6-months post-IMRT. For each patient, radiomic features were extracted from a mandibular subvolume that developed ORN and a control subvolume that received the same dose but did not develop ORN. We used a Multivariate Functional Principal Component Analysis (MFPCA) approach to characterize the temporal trajectories of these features. The proposed MFPCA model performs the best at classifying ORN vs. Control subvolumes with an area under curve (AUC) = 0.74 [95% confidence interval (C.I.): 0.61–0.90], significantly outperforming existing approaches such as a pre-IMRT features model or a delta model based on changes at intermediate time points, i.e., at 2- and 6-month follow-up. This suggests that temporal trajectories of radiomics features derived from sequential pre- and post-RT CT scans can provide markers that are correlates of RT-induced mandibular injury, and consequently aid in earlier management of ORN.},
  archive      = {J_FRAI},
  author       = {Barua, Souptik and Elhalawani, Hesham and Volpe, Stefania and Al Feghali, Karine A. and Yang, Pei and Ng, Sweet Ping and Elgohari, Baher and Granberry, Robin C. and Mackin, Dennis S. and Gunn, G. Brandon and Hutcheson, Katherine A. and Chambers, Mark S. and Court, Laurence E. and Mohamed, Abdallah S. R. and Fuller, Clifton D. and Lai, Stephen Y. and Rao, Arvind},
  doi          = {10.3389/frai.2021.618469},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {4},
  pages        = {618469},
  shortjournal = {Front. Artif. Intell.},
  title        = {Computed tomography radiomics kinetics as early imaging correlates of osteoradionecrosis in oropharyngeal cancer patients},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Causal datasheet for datasets: An evaluation guide for
real-world data analysis and data collection design using bayesian
networks. <em>FRAI</em>, <em>4</em>, 612551. (<a
href="https://doi.org/10.3389/frai.2021.612551">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Developing data-driven solutions that address real-world problems requires understanding of these problems’ causes and how their interaction affects the outcome–often with only observational data. Causal Bayesian Networks (BN) have been proposed as a powerful method for discovering and representing the causal relationships from observational data as a Directed Acyclic Graph (DAG). BNs could be especially useful for research in global health in Lower and Middle Income Countries, where there is an increasing abundance of observational data that could be harnessed for policy making, program evaluation, and intervention design. However, BNs have not been widely adopted by global health professionals, and in real-world applications, confidence in the results of BNs generally remains inadequate. This is partially due to the inability to validate against some ground truth, as the true DAG is not available. This is especially problematic if a learned DAG conflicts with pre-existing domain doctrine. Here we conceptualize and demonstrate an idea of a “Causal Datasheet” that could approximate and document BN performance expectations for a given dataset, aiming to provide confidence and sample size requirements to practitioners. To generate results for such a Causal Datasheet, a tool was developed which can generate synthetic Bayesian networks and their associated synthetic datasets to mimic real-world datasets. The results given by well-known structure learning algorithms and a novel implementation of the OrderMCMC method using the Quotient Normalized Maximum Likelihood score were recorded. These results were used to populate the Causal Datasheet, and recommendations could be made dependent on whether expected performance met user-defined thresholds. We present our experience in the creation of Causal Datasheets to aid analysis decisions at different stages of the research process. First, one was deployed to help determine the appropriate sample size of a planned study of sexual and reproductive health in Madhya Pradesh, India. Second, a datasheet was created to estimate the performance of an existing maternal health survey we conducted in Uttar Pradesh, India. Third, we validated generated performance estimates and investigated current limitations on the well-known ALARM dataset. Our experience demonstrates the utility of the Causal Datasheet, which can help global health practitioners gain more confidence when applying BNs.},
  archive      = {J_FRAI},
  author       = {Butcher, Bradley and Huang, Vincent S. and Robinson, Christopher and Reffin, Jeremy and Sgaier, Sema K. and Charles, Grace and Quadrianto, Novi},
  doi          = {10.3389/frai.2021.612551},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {4},
  pages        = {612551},
  shortjournal = {Front. Artif. Intell.},
  title        = {Causal datasheet for datasets: An evaluation guide for real-world data analysis and data collection design using bayesian networks},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Generative adversarial networks–enabled human–artificial
intelligence collaborative applications for creative and design
industries: A systematic review of current approaches and trends.
<em>FRAI</em>, <em>4</em>, 604234. (<a
href="https://doi.org/10.3389/frai.2021.604234">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The future of work and workplace is very much in flux. A vast amount has been written about artificial intelligence (AI) and its impact on work, with much of it focused on automation and its impact in terms of potential job losses. This review will address one area where AI is being added to creative and design practitioners’ toolbox to enhance their creativity, productivity, and design horizons. A designer’s primary purpose is to create, or generate, the most optimal artifact or prototype, given a set of constraints. We have seen AI encroaching into this space with the advent of generative networks and generative adversarial networks (GANs) in particular. This area has become one of the most active research fields in machine learning over the past number of years, and a number of these techniques, particularly those around plausible image generation, have garnered considerable media attention. We will look beyond automatic techniques and solutions and see how GANs are being incorporated into user pipelines for design practitioners. A systematic review of publications indexed on ScienceDirect, SpringerLink, Web of Science, Scopus, IEEExplore, and ACM DigitalLibrary was conducted from 2015 to 2020. Results are reported according to PRISMA statement. From 317 search results, 34 studies (including two snowball sampled) are reviewed, highlighting key trends in this area. The studies’ limitations are presented, particularly a lack of user studies and the prevalence of toy-examples or implementations that are unlikely to scale. Areas for future study are also identified.},
  archive      = {J_FRAI},
  author       = {Hughes, Rowan T. and Zhu, Liming and Bednarz, Tomasz},
  doi          = {10.3389/frai.2021.604234},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {4},
  pages        = {604234},
  shortjournal = {Front. Artif. Intell.},
  title        = {Generative adversarial Networks–Enabled Human–Artificial intelligence collaborative applications for creative and design industries: A systematic review of current approaches and trends},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Supervised learning computer vision benchmark for snake
species identification from photographs: Implications for herpetology
and global health. <em>FRAI</em>, <em>4</em>, 582110. (<a
href="https://doi.org/10.3389/frai.2021.582110">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We trained a computer vision algorithm to identify 45 species of snakes from photos and compared its performance to that of humans. Both human and algorithm performance is substantially better than randomly guessing (null probability of guessing correctly given 45 classes = 2.2%). Some species (e.g., Boa constrictor) are routinely identified with ease by both algorithm and humans, whereas other groups of species (e.g., uniform green snakes, blotched brown snakes) are routinely confused. A species complex with largely molecular species delimitation (North American ratsnakes) was the most challenging for computer vision. Humans had an edge at identifying images of poor quality or with visual artifacts. With future improvement, computer vision could play a larger role in snakebite epidemiology, particularly when combined with information about geographic location and input from human experts.},
  archive      = {J_FRAI},
  author       = {Durso, Andrew M. and Moorthy, Gokula Krishnan and Mohanty, Sharada P. and Bolon, Isabelle and Salathé, Marcel and Ruiz de Castañeda, Rafael},
  doi          = {10.3389/frai.2021.582110},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {4},
  pages        = {582110},
  shortjournal = {Front. Artif. Intell.},
  title        = {Supervised learning computer vision benchmark for snake species identification from photographs: Implications for herpetology and global health},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). AI-based estimation of end-systolic elastance from
arm-pressure and systolic time intervals. <em>FRAI</em>, <em>4</em>,
579541. (<a href="https://doi.org/10.3389/frai.2021.579541">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Left ventricular end-systolic elastance (Ees) is a major determinant of cardiac systolic function and ventricular-arterial interaction. Previous methods for the Ees estimation require the use of the echocardiographic ejection fraction (EF). However, given that EF expresses the stroke volume as a fraction of end-diastolic volume (EDV), accurate interpretation of EF is attainable only with the additional measurement of EDV. Hence, there is still need for a simple, reliable, noninvasive method to estimate Ees. This study proposes a novel artificial intelligence—based approach to estimate Ees using the information embedded in clinically relevant systolic time intervals, namely the pre-ejection period (PEP) and ejection time (ET). We developed a training/testing scheme using virtual subjects (n = 4,645) from a previously validated in-silico model. Extreme Gradient Boosting regressor was employed to model Ees using as inputs arm cuff pressure, PEP, and ET. Results showed that Ees can be predicted with high accuracy achieving a normalized RMSE equal to 9.15% (r = 0.92) for a wide range of Ees values from 1.2 to 4.5 mmHg/ml. The proposed model was found to be less sensitive to measurement errors (±10–30% of the actual value) in blood pressure, presenting low test errors for the different levels of noise (RMSE did not exceed 0.32 mmHg/ml). In contrast, a high sensitivity was reported for measurements errors in the systolic timing features. It was demonstrated that Ees can be reliably estimated from the traditional arm-pressure and echocardiographic PEP and ET. This approach constitutes a step towards the development of an easy and clinically applicable method for assessing left ventricular systolic function.},
  archive      = {J_FRAI},
  author       = {Bikia, Vasiliki and Adamopoulos, Dionysios and Pagoulatou, Stamatia and Rovas, Georgios and Stergiopulos, Nikolaos},
  doi          = {10.3389/frai.2021.579541},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {4},
  pages        = {579541},
  shortjournal = {Front. Artif. Intell.},
  title        = {AI-based estimation of end-systolic elastance from arm-pressure and systolic time intervals},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Deep learning and its application for healthcare delivery in
low and middle income countries. <em>FRAI</em>, <em>4</em>, 553987. (<a
href="https://doi.org/10.3389/frai.2021.553987">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As anyone who has witnessed firsthand knows, healthcare delivery in low-resource settings is fundamentally different from more affluent settings. Artificial Intelligence, including Machine Learning and more specifically Deep Learning, has made amazing advances over the past decade. Significant resources are now dedicated to problems in the field of medicine, but with the potential to further the digital divide by neglecting underserved areas and their specific context. In the general case, Deep Learning remains a complex technology requiring deep technical expertise. This paper explores advances within the narrower field of deep learning image analysis that reduces barriers to adoption and allows individuals with less specialized software skills to effectively employ these techniques. This enables a next wave of innovation, driven largely by problem domain expertise and the creative application of this technology to unaddressed concerns in LMIC settings. The paper also explores the central role of NGOs in problem identification, data acquisition and curation, and integration of new technologies into healthcare systems.},
  archive      = {J_FRAI},
  author       = {Williams, Douglas and Hornung, Heiko and Nadimpalli, Adi and Peery, Ashton},
  doi          = {10.3389/frai.2021.553987},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {4},
  pages        = {553987},
  shortjournal = {Front. Artif. Intell.},
  title        = {Deep learning and its application for healthcare delivery in low and middle income countries},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An overcomplete approach to fitting drift-diffusion decision
models to trial-by-trial data. <em>FRAI</em>, <em>4</em>, 531316. (<a
href="https://doi.org/10.3389/frai.2021.531316">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Drift-diffusion models or DDMs are becoming a standard in the field of computational neuroscience. They extend models from signal detection theory by proposing a simple mechanistic explanation for the observed relationship between decision outcomes and reaction times (RT). In brief, they assume that decisions are triggered once the accumulated evidence in favor of a particular alternative option has reached a predefined threshold. Fitting a DDM to empirical data then allows one to interpret observed group or condition differences in terms of a change in the underlying model parameters. However, current approaches only yield reliable parameter estimates in specific situations (c.f. fixed drift rates vs drift rates varying over trials). In addition, they become computationally unfeasible when more general DDM variants are considered (e.g., with collapsing bounds). In this note, we propose a fast and efficient approach to parameter estimation that relies on fitting a “self-consistency” equation that RT fulfill under the DDM. This effectively bypasses the computational bottleneck of standard DDM parameter estimation approaches, at the cost of estimating the trial-specific neural noise variables that perturb the underlying evidence accumulation process. For the purpose of behavioral data analysis, these act as nuisance variables and render the model “overcomplete,” which is finessed using a variational Bayesian system identification scheme. However, for the purpose of neural data analysis, estimates of neural noise perturbation terms are a desirable (and unique) feature of the approach. Using numerical simulations, we show that this “overcomplete” approach matches the performance of current parameter estimation approaches for simple DDM variants, and outperforms them for more complex DDM variants. Finally, we demonstrate the added-value of the approach, when applied to a recent value-based decision making experiment.},
  archive      = {J_FRAI},
  author       = {Feltgen, Q. and Daunizeau, J.},
  doi          = {10.3389/frai.2021.531316},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {4},
  pages        = {531316},
  shortjournal = {Front. Artif. Intell.},
  title        = {An overcomplete approach to fitting drift-diffusion decision models to trial-by-trial data},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Toward the impact of non-pharmaceutical interventions and
vaccination on the COVID-19 pandemic with time-dependent SEIR model.
<em>FRAI</em>, <em>4</em>, 648579. (<a
href="https://doi.org/10.3389/frai.2021.648579">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The outbreak of COVID-19, caused by the SARS-CoV-2 coronavirus, has been declared a pandemic by the World Health Organization (WHO) in March, 2020 and rapidly spread to over 210 countries and territories around the world. By December 24, there are over 77M cumulative confirmed cases with more than 1.72M deaths worldwide. To mathematically describe the dynamic of the COVID-19 pandemic, we propose a time-dependent SEIR model considering the incubation period. Furthermore, we take immunity, reinfection, and vaccination into account and propose the SEVIS model. Unlike the classic SIR based models with constant parameters, our dynamic models not only predicts the number of cases, but also monitors the trajectories of changing parameters, such as transmission rate, recovery rate, and the basic reproduction number. Tracking these parameters, we observe the significant decrease in the transmission rate in the U.S. after the authority announced a series of orders aiming to prevent the spread of the virus, such as closing non-essential businesses and lockdown restrictions. Months later, as restrictions being gradually lifted, we notice a new surge of infection emerges as the transmission rates show increasing trends in some states. Using our epidemiology models, people can track, timely monitor, and predict the COVID-19 pandemic with precision. To illustrate and validate our model, we use the national level data (the U.S.) and the state level data (New York and North Dakota), and the resulting relative prediction errors for the infected group and recovered group are mostly lower than 0.5%. We also simulate the long-term development of the pandemic based on our proposed models to explore when the crisis will end under certain conditions.},
  archive      = {J_FRAI},
  author       = {Li, Yuexin and Ge, Linqiang and Zhou, Yang and Cao, Xuan and Zheng, Jingyi},
  doi          = {10.3389/frai.2021.648579},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {3},
  pages        = {648579},
  shortjournal = {Front. Artif. Intell.},
  title        = {Toward the impact of non-pharmaceutical interventions and vaccination on the COVID-19 pandemic with time-dependent SEIR model},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Assessment of a spatiotemporal deep learning approach for
soil moisture prediction and filling the gaps in between soil moisture
observations. <em>FRAI</em>, <em>4</em>, 636234. (<a
href="https://doi.org/10.3389/frai.2021.636234">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Soil moisture (SM) plays a significant role in determining the probability of flooding in a given area. Currently, SM is most commonly modeled using physically-based numerical hydrologic models. Modeling the natural processes that take place in the soil is difficult and requires assumptions. Besides, hydrologic model runtime is highly impacted by the extent and resolution of the study domain. In this study, we propose a data-driven modeling approach using Deep Learning (DL) models. There are different types of DL algorithms that serve different purposes. For example, the Convolutional Neural Network (CNN) algorithm is well suited for capturing and learning spatial patterns, while the Long Short-Term Memory (LSTM) algorithm is designed to utilize time-series information and to learn from past observations. A DL algorithm that combines the capabilities of CNN and LSTM called ConvLSTM was recently developed. In this study, we investigate the applicability of the ConvLSTM algorithm in predicting SM in a study area located in south Louisiana in the United States. This study reveals that ConvLSTM significantly outperformed CNN in predicting SM. We tested the performance of ConvLSTM based models by using a combination of different sets of predictors and different LSTM sequence lengths. The study results show that ConvLSTM models can predict SM with a mean areal Root Mean Squared Error (RMSE) of 2.5% and mean areal correlation coefficients of 0.9 for our study area. ConvLSTM models can also provide predictions between discrete SM observations, making them potentially useful for applications such as filling observational gaps between satellite overpasses.},
  archive      = {J_FRAI},
  author       = {ElSaadani, Mohamed and Habib, Emad and Abdelhameed, Ahmed M. and Bayoumi, Magdy},
  doi          = {10.3389/frai.2021.636234},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {3},
  pages        = {636234},
  shortjournal = {Front. Artif. Intell.},
  title        = {Assessment of a spatiotemporal deep learning approach for soil moisture prediction and filling the gaps in between soil moisture observations},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Conformational changes of the receptor binding domain of
SARS-CoV-2 spike protein and prediction of a b-cell antigenic epitope
using structural data. <em>FRAI</em>, <em>4</em>, 630955. (<a
href="https://doi.org/10.3389/frai.2021.630955">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {COVID-19, the illness caused by the SARS-CoV-2 virus, is now a worldwide pandemic with mortality in hundreds of thousands as infections continue to increase. Containing the spread of this viral infection and decreasing the mortality rate is a major challenge. Identifying appropriate antigenic epitopes from the viral proteins is a very important task for vaccine production and the development of diagnostic kits and antibody therapy. A novel antigenic epitope would be specific to the SARS-CoV-2 virus and can distinguish infections caused by common cold viruses. In this study two approaches are employed to identify both continuous and conformational B-cell antigenic epitopes. To achieve this goal, we modeled a complete structure of the receptor binding domain (RBD) of the spike protein using recently deposited coordinates (6vxx, 6vsb, and 6w41) in the protein data bank. In addition, we also modeled the RBD-ACE2 receptor complex for SARS-CoV-2 using the SARS-CoV RBD-ACE2 complex (3D0J) as a reference model. Finally, structure based predicted antigenic epitopes were compared to the ACE2 binding region of RBD of SARS-CoV-2. The identified conformational epitopes show overlaps with the ACE2-receptor binding region of the RBD of SARS-CoV-2. Strategies defined in the current study identified novel antigenic epitope that is specific to the SARS-CoV-2 virus. Integrating such approach in the diagnosis can distinguish infections caused by common cold viruses from SARS-CoV-2 virus.},
  archive      = {J_FRAI},
  author       = {Khare, Sangeeta and Azevedo, Marli and Parajuli, Pravin and Gokulan, Kuppan},
  doi          = {10.3389/frai.2021.630955},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {3},
  pages        = {630955},
  shortjournal = {Front. Artif. Intell.},
  title        = {Conformational changes of the receptor binding domain of SARS-CoV-2 spike protein and prediction of a B-cell antigenic epitope using structural data},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An attempt to boost posterior population expansion using
fast machine learning algorithms. <em>FRAI</em>, <em>4</em>, 624629. (<a
href="https://doi.org/10.3389/frai.2021.624629">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In hydrogeology, inverse techniques have become indispensable to characterize subsurface parameters and their uncertainty. When modeling heterogeneous, geologically realistic discrete model spaces, such as categorical fields, Monte Carlo methods are needed to properly sample the solution space. Inversion algorithms use a forward operator, such as a numerical groundwater solver. The forward operator often represents the bottleneck for the high computational cost of the Monte Carlo sampling schemes. Even if efficient sampling methods (for example Posterior Population Expansion, PoPEx) have been developed, they need significant computing resources. It is therefore desirable to speed up such methods. As only a few models generated by the sampler have a significant likelihood, we propose to predict the significance of generated models by means of machine learning. Only models labeled as significant are passed to the forward solver, otherwise, they are rejected. This work compares the performance of AdaBoost, Random Forest, and convolutional neural network as classifiers integrated with the PoPEx framework. During initial iterations of the algorithm, the forward solver is always executed and subsurface models along with the likelihoods are stored. Then, the machine learning schemes are trained on the available data. We demonstrate the technique using a simulation of a tracer test in a fluvial aquifer. The geology is modeled by the multiple-point statistical approach, the field contains four geological facies, with associated permeability, porosity, and specific storage values. MODFLOW is used for groundwater flow and transport simulation. The solution of the inverse problem is used to estimate the 10 days protection zone around the pumping well. The estimated speed-ups with Random Forest and AdaBoost were higher than with the convolutional neural network. To validate the approach, computing times of inversion without and with machine learning schemes were computed and the error against the reference solution was calculated. For the same mean error, accelerated PoPEx achieved a speed-up rate of up to 2 with respect to the standard PoPEx.},
  archive      = {J_FRAI},
  author       = {Juda, Przemysław and Renard, Philippe},
  doi          = {10.3389/frai.2021.624629},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {3},
  pages        = {624629},
  shortjournal = {Front. Artif. Intell.},
  title        = {An attempt to boost posterior population expansion using fast machine learning algorithms},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A machine learning approach to monitor the emergence of late
intrauterine growth restriction. <em>FRAI</em>, <em>4</em>, 622616. (<a
href="https://doi.org/10.3389/frai.2021.622616">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Late intrauterine growth restriction (IUGR) is a fetal pathological condition characterized by chronic hypoxia secondary to placental insufficiency, resulting in an abnormal rate of fetal growth. This pathology has been associated with increased fetal and neonatal morbidity and mortality. In standard clinical practice, late IUGR diagnosis can only be suspected in the third trimester and ultimately confirmed at birth. This study presents a radial basis function support vector machine (RBF-SVM) classification based on quantitative features extracted from fetal heart rate (FHR) signals acquired using routine cardiotocography (CTG) in a population of 160 healthy and 102 late IUGR fetuses. First, the individual performance of each time, frequency, and nonlinear feature was tested. To improve the unsatisfactory results of univariate analysis we firstly adopted a Recursive Feature Elimination approach to select the best subset of FHR-based parameters contributing to the discrimination of healthy vs. late IUGR fetuses. A fine tuning of the RBF-SVM model parameters resulted in a satisfactory classification performance in the training set (accuracy 0.93, sensitivity 0.93, specificity 0.84). Comparable results were obtained when applying the model on a totally independent testing set. This investigation supports the use of a multivariate approach for the in utero identification of late IUGR condition based on quantitative FHR features encompassing different domains. The proposed model allows describing the relationships among features beyond the traditional linear approaches, thus improving the classification performance. This framework has the potential to be proposed as a screening tool for the identification of late IUGR fetuses.},
  archive      = {J_FRAI},
  author       = {Pini, Nicolò and Lucchini, Maristella and Esposito, Giuseppina and Tagliaferri, Salvatore and Campanile, Marta and Magenes, Giovanni and Signorini, Maria G.},
  doi          = {10.3389/frai.2021.622616},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {3},
  pages        = {622616},
  shortjournal = {Front. Artif. Intell.},
  title        = {A machine learning approach to monitor the emergence of late intrauterine growth restriction},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Human- versus artificial intelligence. <em>FRAI</em>,
<em>4</em>, 622364. (<a
href="https://doi.org/10.3389/frai.2021.622364">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {AI is one of the most debated subjects of today and there seems little common understanding concerning the differences and similarities of human intelligence and artificial intelligence. Discussions on many relevant topics, such as trustworthiness, explainability, and ethics are characterized by implicit anthropocentric and anthropomorphistic conceptions and, for instance, the pursuit of human-like intelligence as the golden standard for Artificial Intelligence. In order to provide more agreement and to substantiate possible future research objectives, this paper presents three notions on the similarities and differences between human- and artificial intelligence: 1) the fundamental constraints of human (and artificial) intelligence, 2) human intelligence as one of many possible forms of general intelligence, and 3) the high potential impact of multiple (integrated) forms of narrow-hybrid AI applications. For the time being, AI systems will have fundamentally different cognitive qualities and abilities than biological systems. For this reason, a most prominent issue is how we can use (and “collaborate” with) these systems as effectively as possible? For what tasks and under what conditions, decisions are safe to leave to AI and when is human judgment required? How can we capitalize on the specific strengths of human- and artificial intelligence? How to deploy AI systems effectively to complement and compensate for the inherent constraints of human cognition (and vice versa)? Should we pursue the development of AI “partners” with human (-level) intelligence or should we focus more at supplementing human limitations? In order to answer these questions, humans working with AI systems in the workplace or in policy making have to develop an adequate mental model of the underlying ‘psychological’ mechanisms of AI. So, in order to obtain well-functioning human-AI systems, Intelligence Awareness in humans should be addressed more vigorously. For this purpose a first framework for educational content is proposed.},
  archive      = {J_FRAI},
  author       = {Korteling, J. E. (Hans). and van de Boer-Visschedijk, G. C. and Blankendaal, R. A. M. and Boonekamp, R. C. and Eikelboom, A. R.},
  doi          = {10.3389/frai.2021.622364},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {3},
  pages        = {622364},
  shortjournal = {Front. Artif. Intell.},
  title        = {Human- versus artificial intelligence},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Application of Seq2Seq models on code correction.
<em>FRAI</em>, <em>4</em>, 590215. (<a
href="https://doi.org/10.3389/frai.2021.590215">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We apply various seq2seq models on programming language correction tasks on Juliet Test Suite for C/C++ and Java of Software Assurance Reference Datasets and achieve 75% (for C/C++) and 56% (for Java) repair rates on these tasks. We introduce pyramid encoder in these seq2seq models, which significantly increases the computational efficiency and memory efficiency, while achieving similar repair rate to their nonpyramid counterparts. We successfully carry out error type classification task on ITC benchmark examples (with only 685 code instances) using transfer learning with models pretrained on Juliet Test Suite, pointing out a novel way of processing small programming language datasets.},
  archive      = {J_FRAI},
  author       = {Huang, Shan and Zhou, Xiao and Chin, Sang},
  doi          = {10.3389/frai.2021.590215},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {3},
  pages        = {590215},
  shortjournal = {Front. Artif. Intell.},
  title        = {Application of Seq2Seq models on code correction},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Editorial: Music and AI. <em>FRAI</em>, <em>4</em>, 651446.
(<a href="https://doi.org/10.3389/frai.2021.651446">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Bonnici, Alexandra and Dannenberg, Roger B. and Kemper, Steven and Camilleri, Kenneth P.},
  doi          = {10.3389/frai.2021.651446},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {2},
  pages        = {651446},
  shortjournal = {Front. Artif. Intell.},
  title        = {Editorial: Music and AI},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Generalizable machine learning in neuroscience using graph
neural networks. <em>FRAI</em>, <em>4</em>, 618372. (<a
href="https://doi.org/10.3389/frai.2021.618372">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although a number of studies have explored deep learning in neuroscience, the application of these algorithms to neural systems on a microscopic scale, i.e. parameters relevant to lower scales of organization, remains relatively novel. Motivated by advances in whole-brain imaging, we examined the performance of deep learning models on microscopic neural dynamics and resulting emergent behaviors using calcium imaging data from the nematode C. elegans. As one of the only species for which neuron-level dynamics can be recorded, C. elegans serves as the ideal organism for designing and testing models bridging recent advances in deep learning and established concepts in neuroscience. We show that neural networks perform remarkably well on both neuron-level dynamics prediction and behavioral state classification. In addition, we compared the performance of structure agnostic neural networks and graph neural networks to investigate if graph structure can be exploited as a favourable inductive bias. To perform this experiment, we designed a graph neural network which explicitly infers relations between neurons from neural activity and leverages the inferred graph structure during computations. In our experiments, we found that graph neural networks generally outperformed structure agnostic models and excel in generalization on unseen organisms, implying a potential path to generalizable machine learning in neuroscience.},
  archive      = {J_FRAI},
  author       = {Wang, Paul Y. and Sapra, Sandalika and George, Vivek Kurien and Silva, Gabriel A.},
  doi          = {10.3389/frai.2021.618372},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {2},
  pages        = {618372},
  shortjournal = {Front. Artif. Intell.},
  title        = {Generalizable machine learning in neuroscience using graph neural networks},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Case report: Utilizing AI and NLP to assist with healthcare
and rehabilitation during the COVID-19 pandemic. <em>FRAI</em>,
<em>4</em>, 613637. (<a
href="https://doi.org/10.3389/frai.2021.613637">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The COVID-19 pandemic has profoundly affected healthcare systems and healthcare delivery worldwide. Policy makers are utilizing social distancing and isolation policies to reduce the risk of transmission and spread of COVID-19, while the research, development, and testing of antiviral treatments and vaccines are ongoing. As part of these isolation policies, in-person healthcare delivery has been reduced, or eliminated, to avoid the risk of COVID-19 infection in high-risk and vulnerable populations, particularly those with comorbidities. Clinicians, occupational therapists, and physiotherapists have traditionally relied on in-person diagnosis and treatment of acute and chronic musculoskeletal (MSK) and neurological conditions and illnesses. The assessment and rehabilitation of persons with acute and chronic conditions has, therefore, been particularly impacted during the pandemic. This article presents a perspective on how Artificial Intelligence and Machine Learning (AI/ML) technologies, such as Natural Language Processing (NLP), can be used to assist with assessment and rehabilitation for acute and chronic conditions.},
  archive      = {J_FRAI},
  author       = {Carriere, Jay and Shafi, Hareem and Brehon, Katelyn and Pohar Manhas, Kiran and Churchill, Katie and Ho, Chester and Tavakoli, Mahdi},
  doi          = {10.3389/frai.2021.613637},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {2},
  pages        = {613637},
  shortjournal = {Front. Artif. Intell.},
  title        = {Case report: Utilizing AI and NLP to assist with healthcare and rehabilitation during the COVID-19 pandemic},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An exploration of stress: Leveraging online data from
crowdsourcing platforms. <em>FRAI</em>, <em>4</em>, 591529. (<a
href="https://doi.org/10.3389/frai.2021.591529">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Background: Early detection of community health risk factors such as stress is of great interest to health policymakers, but representative data collection is often expensive and time-consuming. It is important to investigate the use of alternative means of data collection such as crowdsourcing platforms.Methods: An online sample of Amazon Mechanical Turk (MTurk) workers (N = 500) filled out, for themselves and their child, demographic information and the 10-item Perceived Stress Scale (PSS-10), designed to measure the degree to which situations in one’s life are appraised as stressful. Internal consistency reliability of the PSS-10 was examined via Cronbach’s alpha. Analysis of variance (ANOVA) was utilized to explore trends in the average perceived stress of both adults and their children. Last, Rasch trees were utilized to detect differential item functioning (DIF) in the set of PSS-10 items.Results: The PSS-10 showed adequate internal consistency reliability (Cronbach’s alpha = 0.73). ANOVA results suggested that stress scores significantly differed by education (p = 0.024), employment status (p = 0.0004), and social media usage (p = 0.015). Rasch trees, a recursive partitioning technique based on the Rasch model, indicated that items on the PSS-10 displayed DIF attributable to physical health for adults and social media usage for children.Conclusion: The key conclusion is that this data collection scheme shows promise, allowing public health officials to examine health risk factors such as perceived stress quickly and cost effectively.},
  archive      = {J_FRAI},
  author       = {Roddy, James and Robinson, Samantha},
  doi          = {10.3389/frai.2021.591529},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {2},
  pages        = {591529},
  shortjournal = {Front. Artif. Intell.},
  title        = {An exploration of stress: Leveraging online data from crowdsourcing platforms},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Artificial intelligence and telehealth may provide early
warning of epidemics. <em>FRAI</em>, <em>4</em>, 556848. (<a
href="https://doi.org/10.3389/frai.2021.556848">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The COVID-19 pandemic produced a very sudden and serious impact on public health around the world, greatly adding to the burden of overloaded professionals and national medical systems. Recent medical research has demonstrated the value of using online systems to predict emerging spatial distributions of transmittable diseases. Concerned internet users often resort to online sources in an effort to explain their medical symptoms. This raises the prospect that incidence of COVID-19 may be tracked online by search queries and social media posts analyzed by advanced methods in data science, such as Artificial Intelligence. Online queries can provide early warning of an impending epidemic, which is valuable information needed to support planning timely interventions. Identification of the location of clusters geographically helps to support containment measures by providing information for decision-making and modeling.},
  archive      = {J_FRAI},
  author       = {Arslan, Janan and Benke, Kurt K.},
  doi          = {10.3389/frai.2021.556848},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {1},
  pages        = {556848},
  shortjournal = {Front. Artif. Intell.},
  title        = {Artificial intelligence and telehealth may provide early warning of epidemics},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Addressing fairness, bias, and appropriate use of artificial
intelligence and machine learning in global health. <em>FRAI</em>,
<em>3</em>, 561802. (<a
href="https://doi.org/10.3389/frai.2020.561802">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In Low- and Middle- Income Countries (LMICs), machine learning (ML) and artificial intelligence (AI) offer attractive solutions to address the shortage of health care resources and improve the capacity of the local health care infrastructure. However, AI and ML should also be used cautiously, due to potential issues of fairness and algorithmic bias that may arise if not applied properly. Furthermore, populations in LMICs can be particularly vulnerable to bias and fairness in AI algorithms, due to a lack of technical capacity, existing social bias against minority groups, and a lack of legal protections. In order to address the need for better guidance within the context of global health, we describe three basic criteria (Appropriateness, Fairness, and Bias) that can be used to help evaluate the use of machine learning and AI systems: 1) APPROPRIATENESS is the process of deciding how the algorithm should be used in the local context, and properly matching the machine learning model to the target population; 2) BIAS is a systematic tendency in a model to favor one demographic group vs another, which can be mitigated but can lead to unfairness; and 3) FAIRNESS involves examining the impact on various demographic groups and choosing one of several mathematical definitions of group fairness that will adequately satisfy the desired set of legal, cultural, and ethical requirements. Finally, we illustrate how these principles can be applied using a case study of machine learning applied to the diagnosis and screening of pulmonary disease in Pune, India. We hope that these methods and principles can help guide researchers and organizations working in global health who are considering the use of machine learning and artificial intelligence.},
  archive      = {J_FRAI},
  author       = {Fletcher, Richard Ribón and Nakeshimana, Audace and Olubeko, Olusubomi},
  doi          = {10.3389/frai.2020.561802},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {4},
  pages        = {561802},
  shortjournal = {Front. Artif. Intell.},
  title        = {Addressing fairness, bias, and appropriate use of artificial intelligence and machine learning in global health},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Control sequence ranking for critical system based on health
of equipment thanks to choquet integral. <em>FRAI</em>, <em>3</em>,
614853. (<a href="https://doi.org/10.3389/frai.2020.614853">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a ranking method of operating sequences based on the actual condition of complex systems. This objective is achieved using the health checkup concept and the multiattribute utility theory. Our contribution is the proposal of sequences ranking process using data and experts’ judgments. The ranking results in a decision-making element; it allows experts to have an objective and concise overall ranking to be used for decision making. A case study is presented based on an experimental platform; it allows us to compare two aggregation operators: the weighted mean and the Choquet integral.},
  archive      = {J_FRAI},
  author       = {Bouaziz, Mohammed-Farouk and Marange, Pascale and Voisin, Alexandre and Petin, Jean-Francois},
  doi          = {10.3389/frai.2020.614853},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {3},
  pages        = {614853},
  shortjournal = {Front. Artif. Intell.},
  title        = {Control sequence ranking for critical system based on health of equipment thanks to choquet integral},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Using natural language processing and artificial
intelligence to explore the nutrition and sustainability of recipes and
food. <em>FRAI</em>, <em>3</em>, 621577. (<a
href="https://doi.org/10.3389/frai.2020.621577">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we discuss the use of natural language processing and artificial intelligence to analyze nutritional and sustainability aspects of recipes and food. We present the state-of-the-art and some use cases, followed by a discussion of challenges. Our perspective on addressing these is that while they typically have a technical nature, they nevertheless require an interdisciplinary approach combining natural language processing and artificial intelligence with expert domain knowledge to create practical tools and comprehensive analysis for the food domain.},
  archive      = {J_FRAI},
  author       = {van Erp, Marieke and Reynolds, Christian and Maynard, Diana and Starke, Alain and Ibáñez Martín, Rebeca and Andres, Frederic and Leite, Maria C. A. and Alvarez de Toledo, Damien and Schmidt Rivera, Ximena and Trattner, Christoph and Brewer, Steven and Adriano Martins, Carla and Kluczkovski, Alana and Frankowska, Angelina and Bridle, Sarah and Levy, Renata Bertazzi and Rauber, Fernanda and Tereza da Silva, Jacqueline and Bosma, Ulbe},
  doi          = {10.3389/frai.2020.621577},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {2},
  pages        = {621577},
  shortjournal = {Front. Artif. Intell.},
  title        = {Using natural language processing and artificial intelligence to explore the nutrition and sustainability of recipes and food},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Clinical enhancement in AI-based post-processed fast-scan
low-dose CBCT for head and neck adaptive radiotherapy. <em>FRAI</em>,
<em>3</em>, 614384. (<a
href="https://doi.org/10.3389/frai.2020.614384">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Purpose: To assess image quality and uncertainty in organ-at-risk segmentation on cone beam computed tomography (CBCT) enhanced by deep-learning convolutional neural network (DCNN) for head and neck cancer.Methods: An in-house DCNN was trained using forty post-operative head and neck cancer patients with their planning CT and first-fraction CBCT images. Additional fifteen patients with repeat simulation CT (rCT) and CBCT scan taken on the same day (oCBCT) were used for validation and clinical utility assessment. Enhanced CBCT (eCBCT) images were generated from the oCBCT using the in-house DCNN. Quantitative imaging quality improvement was evaluated using HU accuracy, signal-to-noise-ratio (SNR), and structural similarity index measure (SSIM). Organs-at-risk (OARs) were delineated on o/eCBCT and compared with manual structures on the same day rCT. Contour accuracy was assessed using dice similarity coefficient (DSC), Hausdorff distance (HD), and center of mass (COM) displacement. Qualitative assessment of users’ confidence in manual segmenting OARs was performed on both eCBCT and oCBCT by visual scoring.Results: eCBCT organs-at-risk had significant improvement on mean pixel values, SNR (p &amp;lt; 0.05), and SSIM (p &amp;lt; 0.05) compared to oCBCT images. Mean DSC of eCBCT-to-rCT (0.83 ± 0.06) was higher than oCBCT-to-rCT (0.70 ± 0.13). Improvement was observed for mean HD of eCBCT-to-rCT (0.42 ± 0.13 cm) vs. oCBCT-to-rCT (0.72 ± 0.25 cm). Mean COM was less for eCBCT-to-rCT (0.28 ± 0.19 cm) comparing to oCBCT-to-rCT (0.44 ± 0.22 cm). Visual scores showed OAR segmentation was more accessible on eCBCT than oCBCT images.Conclusion: DCNN improved fast-scan low-dose CBCT in terms of the HU accuracy, image contrast, and OAR delineation accuracy, presenting potential of eCBCT for adaptive radiotherapy.},
  archive      = {J_FRAI},
  author       = {Chen, Wen and Li, Yimin and Yuan, Nimu and Qi, Jinyi and Dyer, Brandon A. and Sensoy, Levent and Benedict, Stanley H. and Shang, Lu and Rao, Shyam and Rong, Yi},
  doi          = {10.3389/frai.2020.614384},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {2},
  pages        = {614384},
  shortjournal = {Front. Artif. Intell.},
  title        = {Clinical enhancement in AI-based post-processed fast-scan low-dose CBCT for head and neck adaptive radiotherapy},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Graph neural networks for maximum constraint satisfaction.
<em>FRAI</em>, <em>3</em>, 580607. (<a
href="https://doi.org/10.3389/frai.2020.580607">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many combinatorial optimization problems can be phrased in the language of constraint satisfaction problems. We introduce a graph neural network architecture for solving such optimization problems. The architecture is generic; it works for all binary constraint satisfaction problems. Training is unsupervised, and it is sufficient to train on relatively small instances; the resulting networks perform well on much larger instances (at least 10-times larger). We experimentally evaluate our approach for a variety of problems, including Maximum Cut and Maximum Independent Set. Despite being generic, we show that our approach matches or surpasses most greedy and semi-definite programming based algorithms and sometimes even outperforms state-of-the-art heuristics for the specific problems.},
  archive      = {J_FRAI},
  author       = {Tönshoff, Jan and Ritzert, Martin and Wolf, Hinrikus and Grohe, Martin},
  doi          = {10.3389/frai.2020.580607},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {2},
  pages        = {580607},
  shortjournal = {Front. Artif. Intell.},
  title        = {Graph neural networks for maximum constraint satisfaction},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). RECLAIM: Toward a new era of refurbishment and
remanufacturing of industrial equipment. <em>FRAI</em>, <em>3</em>,
570562. (<a href="https://doi.org/10.3389/frai.2020.570562">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Refurbishment and remanufacturing are the industrial processes whereby used products or parts that constitute the product are restored. Remanufacturing is the process of restoring the functionality of the product or a part of it to “as-new” quality, whereas refurbishment is the process of restoring the product itself or part of it to “like-new” quality, without being as thorough as remanufacturing. Within this context, the EU-funded project RECLAIM presents a new idea on refurbishment and remanufacturing based on big data analytics, machine learning, predictive analytics, and optimization models using deep learning techniques and digital twin models with the aim of enabling the stakeholders to make informed decisions about whether to remanufacture, upgrade, or repair heavy machinery that is toward its end-of-life. The RECLAIM project additionally provides novel strategies and technologies that enable the reuse of industrial equipment in old, renewed, and new factories, with the goal of saving valuable resources by recycling equipment and using them in a different application, instead of discarding them after use. For instance, RECLAIM provides a simulation engine using digital twin in order to predict maintenance needs and potential faults of large industrial equipment. This simulation engine keeps the virtual twins available to store all available information during the lifetime of a machine, such as maintenance operations, and this information can be used to perform an economic estimation of the machine&#39;s refurbishment costs. The RECLAIM project envisages developing new technologies and strategies aligned with the circular economy and in support of a new model for the management of large industrial equipment that approaches the end of its design life. This model aims to reduce substantially the opportunity cost of retaining strategies (both moneywise and resourcewise) by allowing relatively old equipment that faces the prospect of decommissioning to reclaim its functionalities and role in the overall production system.},
  archive      = {J_FRAI},
  author       = {Zacharaki, Angeliki and Vafeiadis, Thanasis and Kolokas, Nikolaos and Vaxevani, Aikaterini and Xu, Yuchun and Peschl, Michael and Ioannidis, Dimosthenis and Tzovaras, Dimitrios},
  doi          = {10.3389/frai.2020.570562},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {2},
  pages        = {570562},
  shortjournal = {Front. Artif. Intell.},
  title        = {RECLAIM: Toward a new era of refurbishment and remanufacturing of industrial equipment},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). On the adaptability of recurrent neural networks for
real-time jazz improvisation accompaniment. <em>FRAI</em>, <em>3</em>,
508727. (<a href="https://doi.org/10.3389/frai.2020.508727">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Jazz improvisation on a given lead sheet with chords is an interesting scenario for studying the behaviour of artificial agents when they collaborate with humans. Specifically in jazz improvisation, the role of the accompanist is crucial for reflecting the harmonic and metric characteristics of a jazz standard, while identifying in real-time the intentions of the soloist and adapt the accompanying performance parameters accordingly. This paper presents a study on a basic implementation of an artificial jazz accompanist, which provides accompanying chord voicings to a human soloist that is conditioned by the soloing input and the harmonic and metric information provided in a lead sheet chart. The model of the artificial agent includes a separate model for predicting the intentions of the human soloist, towards providing proper accompaniment to the human performer in real-time. Simple implementations of Recurrent Neural Networks are employed both for modeling the predictions of the artificial agent and for modeling the expectations of human intention. A publicly available dataset is modified with a probabilistic refinement process for including all the necessary information for the task at hand and test-case compositions on two jazz standards show the ability of the system to comply with the harmonic constraints within the chart. Furthermore, the system is indicated to be able to provide varying output with different soloing conditions, while there is no significant sacrifice of “musicality” in generated music, as shown in subjective evaluations. Some important limitations that need to be addressed for obtaining more informative results on the potential of the examined approach are also discussed.},
  archive      = {J_FRAI},
  author       = {Kritsis, Kosmas and Kylafi, Theatina and Kaliakatsos-Papakostas, Maximos and Pikrakis, Aggelos and Katsouros, Vassilis},
  doi          = {10.3389/frai.2020.508727},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {2},
  pages        = {508727},
  shortjournal = {Front. Artif. Intell.},
  title        = {On the adaptability of recurrent neural networks for real-time jazz improvisation accompaniment},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Listener modeling and context-aware music recommendation
based on country archetypes. <em>FRAI</em>, <em>3</em>, 508725. (<a
href="https://doi.org/10.3389/frai.2020.508725">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Music preferences are strongly shaped by the cultural and socio-economic background of the listener, which is reflected, to a considerable extent, in country-specific music listening profiles. Previous work has already identified several country-specific differences in the popularity distribution of music artists listened to. In particular, what constitutes the “music mainstream” strongly varies between countries. To complement and extend these results, the article at hand delivers the following major contributions: First, using state-of-the-art unsupervized learning techniques, we identify and thoroughly investigate (1) country profiles of music preferences on the fine-grained level of music tracks (in contrast to earlier work that relied on music preferences on the artist level) and (2) country archetypes that subsume countries sharing similar patterns of listening preferences. Second, we formulate four user models that leverage the user’s country information on music preferences. Among others, we propose a user modeling approach to describe a music listener as a vector of similarities over the identified country clusters or archetypes. Third, we propose a context-aware music recommendation system that leverages implicit user feedback, where context is defined via the four user models. More precisely, it is a multi-layer generative model based on a variational autoencoder, in which contextual features can influence recommendations through a gating mechanism. Fourth, we thoroughly evaluate the proposed recommendation system and user models on a real-world corpus of more than one billion listening records of users around the world (out of which we use 369 million in our experiments) and show its merits vis-à-vis state-of-the-art algorithms that do not exploit this type of context information.},
  archive      = {J_FRAI},
  author       = {Schedl, Markus and Bauer, Christine and Reisinger, Wolfgang and Kowald, Dominik and Lex, Elisabeth},
  doi          = {10.3389/frai.2020.508725},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {2},
  pages        = {508725},
  shortjournal = {Front. Artif. Intell.},
  title        = {Listener modeling and context-aware music recommendation based on country archetypes},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Editorial: Financial intermediation versus
disintermediation: Opportunities and challenges in the FinTech era.
<em>FRAI</em>, <em>3</em>, 629105. (<a
href="https://doi.org/10.3389/frai.2020.629105">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Duygun, Meryem and Hashem, Shatha Qamhieh and Tanda, Alessandra},
  doi          = {10.3389/frai.2020.629105},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {1},
  pages        = {629105},
  shortjournal = {Front. Artif. Intell.},
  title        = {Editorial: financial intermediation versus disintermediation: opportunities and challenges in the FinTech era},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Identifying ingredient substitutions using a knowledge graph
of food. <em>FRAI</em>, <em>3</em>, 621766. (<a
href="https://doi.org/10.3389/frai.2020.621766">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {People can affect change in their eating patterns by substituting ingredients in recipes. Such substitutions may be motivated by specific goals, like modifying the intake of a specific nutrient or avoiding a particular category of ingredients. Determining how to modify a recipe can be difficult because people need to 1) identify which ingredients can act as valid replacements for the original and 2) figure out whether the substitution is “good” for their particular context, which may consider factors such as allergies, nutritional contents of individual ingredients, and other dietary restrictions. We propose an approach to leverage both explicit semantic information about ingredients, encapsulated in a knowledge graph of food, and implicit semantics, captured through word embeddings, to develop a substitutability heuristic to rank plausible substitute options automatically. Our proposed system also helps determine which ingredient substitution options are “healthy” using nutritional information and food classification constraints. We evaluate our substitutability heuristic, diet-improvement ingredient substitutability heuristic (DIISH), using a dataset of ground-truth substitutions scraped from ingredient substitution guides and user reviews of recipes, demonstrating that our approach can help reduce the human effort required to make recipes more suitable for specific dietary needs.},
  archive      = {J_FRAI},
  author       = {Shirai, Sola S. and Seneviratne, Oshani and Gordon, Minor E. and Chen, Ching-Hua and McGuinness, Deborah L.},
  doi          = {10.3389/frai.2020.621766},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {1},
  pages        = {621766},
  shortjournal = {Front. Artif. Intell.},
  title        = {Identifying ingredient substitutions using a knowledge graph of food},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). EmotionNet nano: An efficient deep convolutional neural
network design for real-time facial expression recognition.
<em>FRAI</em>, <em>3</em>, 609673. (<a
href="https://doi.org/10.3389/frai.2020.609673">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While recent advances in deep learning have led to significant improvements in facial expression classification (FEC), a major challenge that remains a bottleneck for the widespread deployment of such systems is their high architectural and computational complexities. This is especially challenging given the operational requirements of various FEC applications, such as safety, marketing, learning, and assistive living, where real-time requirements on low-cost embedded devices is desired. Motivated by this need for a compact, low latency, yet accurate system capable of performing FEC in real-time on low-cost embedded devices, this study proposes EmotionNet Nano, an efficient deep convolutional neural network created through a human-machine collaborative design strategy, where human experience is combined with machine meticulousness and speed in order to craft a deep neural network design catered toward real-time embedded usage. To the best of the author’s knowledge, this is the very first deep neural network architecture for facial expression recognition leveraging machine-driven design exploration in its design process, and exhibits unique architectural characteristics such as high architectural heterogeneity and selective long-range connectivity not seen in previous FEC network architectures. Two different variants of EmotionNet Nano are presented, each with a different trade-off between architectural and computational complexity and accuracy. Experimental results using the CK + facial expression benchmark dataset demonstrate that the proposed EmotionNet Nano networks achieved accuracy comparable to state-of-the-art FEC networks, while requiring significantly fewer parameters. Furthermore, we demonstrate that the proposed EmotionNet Nano networks achieved real-time inference speeds (e.g., &amp;gt;25 FPS and &amp;gt;70 FPS at 15 and 30 W, respectively) and high energy efficiency (e.g., &amp;gt;1.7 images/sec/watt at 15 W) on an ARM embedded processor, thus further illustrating the efficacy of EmotionNet Nano for deployment on embedded devices.},
  archive      = {J_FRAI},
  author       = {Lee, James Ren and Wang, Linda and Wong, Alexander},
  doi          = {10.3389/frai.2020.609673},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {1},
  pages        = {609673},
  shortjournal = {Front. Artif. Intell.},
  title        = {EmotionNet nano: An efficient deep convolutional neural network design for real-time facial expression recognition},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Automated disengagement tracking within an intelligent
tutoring system. <em>FRAI</em>, <em>3</em>, 595627. (<a
href="https://doi.org/10.3389/frai.2020.595627">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper describes a new automated disengagement tracking system (DTS) that detects learners’ maladaptive behaviors, e.g. mind-wandering and impetuous responding, in an intelligent tutoring system (ITS), called AutoTutor. AutoTutor is a conversation-based intelligent tutoring system designed to help adult literacy learners improve their reading comprehension skills. Learners interact with two computer agents in natural language in 30 lessons focusing on word knowledge, sentence processing, text comprehension, and digital literacy. Each lesson has one to three dozen questions to assess and enhance learning. DTS automatically retrieves and aggregates a learner&#39;s response accuracies and time on the first three to five questions in a lesson, as a baseline performance for the lesson when they are presumably engaged, and then detects disengagement by observing if the learner&#39;s following performance significantly deviates from the baseline. DTS is computed with an unsupervised learning method and thus does not rely on any self-reports of disengagement. We analyzed the response time and accuracy of 252 adult literacy learners who completed lessons in AutoTutor. Our results show that items that the detector identified as the learner being disengaged had a performance accuracy of 18.5%, in contrast to 71.8% for engaged items. Moreover, the three post-test reading comprehension scores from Woodcock Johnson III, RISE, and RAPID had a significant association with the accuracy of engaged items, but not disengaged items.},
  archive      = {J_FRAI},
  author       = {Chen, Su and Fang, Ying and Shi, Genghu and Sabatini, John and Greenberg, Daphne and Frijters, Jan and Graesser, Arthur C.},
  doi          = {10.3389/frai.2020.595627},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {1},
  pages        = {595627},
  shortjournal = {Front. Artif. Intell.},
  title        = {Automated disengagement tracking within an intelligent tutoring system},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Instance segmentation to estimate consumption of corn ears
by wild animals for GMO preference tests. <em>FRAI</em>, <em>3</em>,
593622. (<a href="https://doi.org/10.3389/frai.2020.593622">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Genetically Modified (GMO) Corn Experiment was performed to test the hypothesis that wild animals prefer Non-GMO corn and avoid eating GMO corn, which resulted in the collection of complex image data of consumed corn ears. This study develops a deep learning-based image processing pipeline that aims to estimate the consumption of corn by identifying corn and its bare cob from these images, which will aid in testing the hypothesis in the GMO Corn Experiment. Ablation uses mask regional convolutional neural network (Mask R-CNN) for instance segmentation. Based on image data annotation, two approaches for segmentation were discussed: identifying whole corn ears and bare cob parts with and without corn kernels. The Mask R-CNN model was trained for both approaches and segmentation results were compared. Out of the two, the latter approach, i.e., without the kernel, was chosen to estimate the corn consumption because of its superior segmentation performance and estimation accuracy. Ablation experiments were performed with the latter approach to obtain the best model with the available data. The estimation results of these models were included and compared with manually labeled test data with R2 = 0.99 which showed that use of the Mask R-CNN model to estimate corn consumption provides highly accurate results, thus, allowing it to be used further on all collected data and help test the hypothesis of the GMO Corn Experiment. These approaches may also be applied to other plant phenotyping tasks (e.g., yield estimation and plant stress quantification) that require instance segmentation.},
  archive      = {J_FRAI},
  author       = {Adke, Shrinidhi and Haro von Mogel, Karl and Jiang, Yu and Li, Changying},
  doi          = {10.3389/frai.2020.593622},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {1},
  pages        = {593622},
  shortjournal = {Front. Artif. Intell.},
  title        = {Instance segmentation to estimate consumption of corn ears by wild animals for GMO preference tests},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). AI data-driven personalisation and disability inclusion.
<em>FRAI</em>, <em>3</em>, 571955. (<a
href="https://doi.org/10.3389/frai.2020.571955">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study aims to help people working in the field of AI understand some of the unique issues regarding disabled people and examines the relationship between the terms “Personalisation” and “Classification” with regard to disability inclusion. Classification using big data struggles to cope with the individual uniqueness of disabled people, and whereas developers tend to design for the majority so ignoring outliers, designing for edge cases would be a more inclusive approach. Other issues that are discussed in the study include personalising mobile technology accessibility settings with interoperable profiles to allow ubiquitous accessibility; the ethics of using genetic data-driven personalisation to ensure babies are not born with disabilities; the importance of including disabled people in decisions to help understand AI implications; the relationship between localisation and personalisation as assistive technologies need localising in terms of language as well as culture; the ways in which AI could be used to create personalised symbols for people who find it difficult to communicate in speech or writing; and whether blind or visually impaired person will be permitted to “drive” an autonomous car. This study concludes by suggesting that the relationship between the terms “Personalisation” and “Classification” with regards to AI and disability inclusion is a very unique one because of the heterogeneity in contrast to the other protected characteristics and so needs unique solutions.},
  archive      = {J_FRAI},
  author       = {Wald, Mike},
  doi          = {10.3389/frai.2020.571955},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {1},
  pages        = {571955},
  shortjournal = {Front. Artif. Intell.},
  title        = {AI data-driven personalisation and disability inclusion},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Algorithmic probability-guided machine learning on
non-differentiable spaces. <em>FRAI</em>, <em>3</em>, 567356. (<a
href="https://doi.org/10.3389/frai.2020.567356">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We show how complexity theory can be introduced in machine learning to help bring together apparently disparate areas of current research. We show that this model-driven approach may require less training data and can potentially be more generalizable as it shows greater resilience to random attacks. In an algorithmic space the order of its element is given by its algorithmic probability, which arises naturally from computable processes. We investigate the shape of a discrete algorithmic space when performing regression or classification using a loss function parametrized by algorithmic complexity, demonstrating that the property of differentiation is not required to achieve results similar to those obtained using differentiable programming approaches such as deep learning. In doing so we use examples which enable the two approaches to be compared (small, given the computational power required for estimations of algorithmic complexity). We find and report that 1) machine learning can successfully be performed on a non-smooth surface using algorithmic complexity; 2) that solutions can be found using an algorithmic-probability classifier, establishing a bridge between a fundamentally discrete theory of computability and a fundamentally continuous mathematical theory of optimization methods; 3) a formulation of an algorithmically directed search technique in non-smooth manifolds can be defined and conducted; 4) exploitation techniques and numerical methods for algorithmic search to navigate these discrete non-differentiable spaces can be performed; in application of the (a) identification of generative rules from data observations; (b) solutions to image classification problems more resilient against pixel attacks compared to neural networks; (c) identification of equation parameters from a small data-set in the presence of noise in continuous ODE system problem, (d) classification of Boolean NK networks by (1) network topology, (2) underlying Boolean function, and (3) number of incoming edges.},
  archive      = {J_FRAI},
  author       = {Hernández-Orozco, Santiago and Zenil, Hector and Riedel, Jürgen and Uccello, Adam and Kiani, Narsis A. and Tegnér, Jesper},
  doi          = {10.3389/frai.2020.567356},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {1},
  pages        = {567356},
  shortjournal = {Front. Artif. Intell.},
  title        = {Algorithmic probability-guided machine learning on non-differentiable spaces},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Using crowd-sourced speech data to study socially
constrained variation in nonmodal phonation. <em>FRAI</em>, <em>3</em>,
565682. (<a href="https://doi.org/10.3389/frai.2020.565682">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study examines the status of nonmodal phonation (e.g. breathy and creaky voice) in British English using smartphone recordings from over 2,500 speakers. With this novel data collection method, it uncovers effects that have not been reported in past work, such as a relationship between speakers’ education and their production of nonmodal phonation. The results also confirm that previous findings on nonmodal phonation, including the greater use of creaky voice by male speakers than female speakers, extend to a much larger and more diverse sample than has been considered previously. This confirmation supports the validity of using crowd-sourced data for phonetic analyses. The acoustic correlates that were examined include fundamental frequency, H1*-H2*, cepstral peak prominence, and harmonic-to-noise ratio.},
  archive      = {J_FRAI},
  author       = {Gittelson, Ben and Leemann, Adrian and Tomaschek, Fabian},
  doi          = {10.3389/frai.2020.565682},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {1},
  pages        = {565682},
  shortjournal = {Front. Artif. Intell.},
  title        = {Using crowd-sourced speech data to study socially constrained variation in nonmodal phonation},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). That’s cool. Computational sociolinguistic methods for
investigating individual lexico-grammatical variation. <em>FRAI</em>,
<em>3</em>, 547531. (<a
href="https://doi.org/10.3389/frai.2020.547531">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The present study deals with variation in the use of lexico-grammatical patterns and emphasizes the need to embrace individual variation. Targeting the pattern that’s adj (as in that’s right, that’s nice or that’s okay) as a case study, we use a tailor-made Python script to systematically retrieve grammatical and semantic information about all instances of this construction in BNC2014 as well as sociolinguistic information enabling us to study social and individual lexico-grammatical variation among speakers who have used this pattern. The dataset amounts to 4,394 tokens produced by 445 speakers using 159 adjective types in 931 conversations. Using detailed descriptive statistics and mixed-effects regression models, we show that while the choice of some adjectives is partly determined by social variables, situational and especially individual variation is rampant overall. Adopting a cognitive-linguistic perspective and relying on the notion of entrenchment, we interpret these findings as reflecting individual speakers&#39; routines. We argue that computational sociolinguistics is in an ideal position to contribute to the data-driven investigation of individual lexico-grammatical variation and encourage computational sociolinguists to grab this opportunity. For the routines of individual speakers ultimately both underlie and compromise systematic social variation and trigger and steer well-known types of language change including grammaticalization, pragmaticalization and change by invited inference.},
  archive      = {J_FRAI},
  author       = {Schmid, Hans-Jörg and Würschinger, Quirin and Fischer, Sebastian and Küchenhoff, Helmut},
  doi          = {10.3389/frai.2020.547531},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {1},
  pages        = {547531},
  shortjournal = {Front. Artif. Intell.},
  title        = {That’s cool. computational sociolinguistic methods for investigating individual lexico-grammatical variation},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). AI for improving children’s health: A community case study.
<em>FRAI</em>, <em>3</em>, 544972. (<a
href="https://doi.org/10.3389/frai.2020.544972">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Indian health care system lacks the infrastructure to meet the health care demands of the country. Physician and nurse availability is 30 and 50% below WHO recommendations, respectively, and has led to a steep imbalance between the demand for health care and the infrastructure available to support it. Among other concerns, India still struggles with challenges like undernutrition, with 38% of children under the age of five being underweight. Despite these challenges, technological advancements, mobile phone ubiquity and rising patient awareness offers a huge opportunity for artificial intelligence to enable efficient healthcare delivery, by improved targeting of constrained resources. The Saathealth mobile app provides low-middle income parents of young children nflwith interactive children’s health, nutrition and development content in the form of an entertaining video series, a gamified quiz journey and targeted notifications. The app iteratively evolves the user journey based on dynamic data and predictive algorithms, empowering a shift from reactive to proactive care. Saathealth users have registered over 500,000 sessions and over 200 million seconds on-app engagement over a year, comparing favorably with engagement on other digital health interventions in underserved communities. We have used valuable app analytics data and insights from our 45,000 users to build scalable, predictive models that were validated for specific use cases. Using the Random Forest model with heterogeneous data allowed us to predict user churn with a 93% accuracy. Predicting user lifetimes on the mobile app for preliminary insights gave us an RMSE of 25.09 days and an R2 value of 0.91, reflecting closely correlated predictions. These predictive algorithms allow us to incentivize users with optimized offers and omni-channel nudges, to increase engagement with content as well as other targeted online and offline behaviors. The algorithms also optimize the effectiveness of our intervention by augmenting personalized experiences and directing limited health resources toward populations that are most resistant to digital first interventions. These and similar AI powered algorithms will allow us to lengthen and deepen the lifetime relationship with our health consumers, making more of them effective, proactive participants in improving children’s health, nutrition and early cognitive development.},
  archive      = {J_FRAI},
  author       = {Ganju, Aakash and Satyan, Srini and Tanna, Vatsal and Menezes, Sonia Rebecca},
  doi          = {10.3389/frai.2020.544972},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {1},
  pages        = {544972},
  shortjournal = {Front. Artif. Intell.},
  title        = {AI for improving children’s health: A community case study},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Digital articulation: Examining text-based linguistic
performances in mobile communication through keystroke-logging analysis.
<em>FRAI</em>, <em>3</em>, 539920. (<a
href="https://doi.org/10.3389/frai.2020.539920">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study examines how text-based mobile communication practices are performatively constructed as individuals compose messages key-by-key on virtual keyboards, and how these synchronous performances (Mobile interface theory: embodied space and locative media. New York, NY: Routledge) reflect the iterative process of constructing and maintaining interpersonal relationships. In doing so, this study reports on keystroke-logging analysis (see Writ. Commun. 30, 358–392) in order to observe how participants (N = 10) composed text as part of everyday mobile communication for the period of one week, subsequently producing 179,996 individual keystroke log-file records. Participants used LogKey, a virtual keyboard application made exclusively for this study to run on the Android mobile operating system. Analysis of keystroke log-file data suggest that timing processes of composing text-messages may differ as participants messaged with different categories of interlocutors, composed on different communication applications, and composed paralinguistic features—such as variants of Lol and Haha Thurlow and Brown, (Discourse Anal. Online, 2003, 1, 1); Tagg, (Discourse of text messaging. 2012, Bloomsbury, UK)—at different turn-taking positions. This evidence suggests that keystroke-logging methods may contribute to understanding of how individuals manage interpersonal relationships in real-time (Please reply! the replying norm in adolescent SMS communication,” in The inside text: social, cultural and design perspectives on SMS. (Norwell, MA: Springer), 53–73); (Beyond genre: closings and relational work in texting,” in Digital discourse: language in the new media. (Oxford: Oxford University Press), 67–85), and suggests future direction for methodologically studying linguistic performances as part of text-based mobile communication.},
  archive      = {J_FRAI},
  author       = {Schneier, Joel},
  doi          = {10.3389/frai.2020.539920},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {1},
  pages        = {539920},
  shortjournal = {Front. Artif. Intell.},
  title        = {Digital articulation: Examining text-based linguistic performances in mobile communication through keystroke-logging analysis},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Avoiding conflict: When speaker coordination does not
require conceptual agreement. <em>FRAI</em>, <em>3</em>, 523920. (<a
href="https://doi.org/10.3389/frai.2020.523920">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we discuss the socialization hypothesis—the idea that speakers of the same (linguistic) community should share similar concepts given that they are exposed to similar environments and operate in highly-coordinated social contexts—and challenge the fact that it is assumed to constitute a prerequisite to successful communication. We do so using distributional semantic models of meaning (DSMs) which create lexical representations via latent aggregation of co-occurrence information between words and contexts. We argue that DSMs constitute particularly adequate tools for exploring the socialization hypothesis given that 1) they provide full control over the notion of background environment, formally characterized as the training corpus from which distributional information is aggregated; and 2) their geometric structure allows for exploiting alignment-based similarity metrics to measure inter-subject alignment over an entire semantic space, rather than a set of limited entries. We propose to model coordination between two different DSMs trained on two distinct corpora as dimensionality selection over a dense matrix obtained via Singular Value Decomposition This approximates an ad-hoc coordination scenario between two speakers as the attempt to align their similarity ratings on a set of word pairs. Our results underline the specific way in which linguistic information is spread across singular vectors, and highlight the need to distinguish agreement from mere compatibility in alignment-based notions of conceptual similarity. Indeed, we show that compatibility emerges from idiosyncrasy so that the unique and distinctive aspects of speakers’ background experiences can actually facilitate—rather than impede—coordination and communication between them. We conclude that the socialization hypothesis may constitute an unnecessary prerequisite to successful communication and that, all things considered, communication is probably best formalized as the cooperative act of avoiding conflict, rather than maximizing agreement.},
  archive      = {J_FRAI},
  author       = {Kabbach, Alexandre and Herbelot, Aurélie},
  doi          = {10.3389/frai.2020.523920},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {1},
  pages        = {523920},
  shortjournal = {Front. Artif. Intell.},
  title        = {Avoiding conflict: When speaker coordination does not require conceptual agreement},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Evolving musical sight reading exercises using expert
models. <em>FRAI</em>, <em>3</em>, 497530. (<a
href="https://doi.org/10.3389/frai.2020.497530">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sight reading skills are widely considered to be crucial for all musicians. However, given that sight reading involves playing sheet music without having seen it before, once an exercise has been completed by a student it can no longer be used as a sight reading exercise for them. In this paper we present a novel evolutionary algorithm for generating musical sight reading exercises in the Western art music tradition. Using models based on expert examples, the algorithm generates material suitable for practice which is both technically appropriate and aesthetically pleasing with respect to an instrument and difficulty level. This overcomes the resource constraint in using traditional practice exercises, which are exhausted quickly by students and teachers due to their limited quantity.},
  archive      = {J_FRAI},
  author       = {Pierce, Charlotte and Hendtlass, Tim and Bartel, Anthony and Woodward, Clinton J.},
  doi          = {10.3389/frai.2020.497530},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {1},
  pages        = {497530},
  shortjournal = {Front. Artif. Intell.},
  title        = {Evolving musical sight reading exercises using expert models},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
</ul>

</body>
</html>
