<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>FCOMP_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="fcomp---127">FCOMP - 127</h2>
<ul>
<li><details>
<summary>
(2021). Editorial: Perspectives on multisensory human-food
interaction. <em>FCOMP</em>, <em>3</em>, 811311. (<a
href="https://doi.org/10.3389/fcomp.2021.811311">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FCOMP},
  author       = {Velasco, Carlos and Obrist, Marianna and Huisman, Gijs and Nijholt, Anton and Spence, Charles and Motoki, Kosuke and Narumi, Takuji},
  doi          = {10.3389/fcomp.2021.811311},
  journal      = {Frontiers in Computer Science},
  month        = {12},
  pages        = {811311},
  shortjournal = {Front. Comput. Sci.},
  title        = {Editorial: Perspectives on multisensory human-food interaction},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Corrigendum: CSL-SHARE: A multimodal wearable sensor-based
human activity dataset. <em>FCOMP</em>, <em>3</em>, 800056. (<a
href="https://doi.org/10.3389/fcomp.2021.800056">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FCOMP},
  author       = {Liu, Hui and Hartmann, Yale and Schultz, Tanja},
  doi          = {10.3389/fcomp.2021.800056},
  journal      = {Frontiers in Computer Science},
  month        = {12},
  pages        = {800056},
  shortjournal = {Front. Comput. Sci.},
  title        = {Corrigendum: CSL-SHARE: a multimodal wearable sensor-based human activity dataset},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Teaching human-computer interaction modules—and then came
COVID-19. <em>FCOMP</em>, <em>3</em>, 793466. (<a
href="https://doi.org/10.3389/fcomp.2021.793466">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In teaching Human-Computer Interaction at university level, it has always been beneficial to explain the related theory and engage students in a practical way, whether individually or in groups. And then came COVID-19. Face-to-face classes were replaced by emergency remote teaching methods. Students became student numbers in cyber space. The danger became real to convert back to the traditional way of presenting lectures, namely a lecturer doing all the talking and the students being the passive audience. This paper describes how the author had to adapt and innovate in terms of teaching Human-Computer Interaction modules to university students in a practical way during the COVID-19 pandemic. Frequent online quizzes, audio messages, online group discussion, smaller topic-dedicated practical activities, and webinars encouraging student participation, were employed. Instead of having access to eye-tracking technology in a usability laboratory, students had to innovate for usability evaluation assignments by employing observation, think-aloud protocols, and performance and self-reported metrics as data gathering methods. The laboratory had to be replaced by COVID-compliant places of residence. The outcomes of adapting previously-used teaching methods and inventing new ways to encourage student participation, were surprisingly positive. An additional advantage was that many of these methods turned out to be so successful that their application could be continued and extended to post-pandemic times for a blended learning approach to further enrich Human-Computer Interaction teaching.},
  archive      = {J_FCOMP},
  author       = {De Wet, Lizette},
  doi          = {10.3389/fcomp.2021.793466},
  journal      = {Frontiers in Computer Science},
  month        = {12},
  pages        = {793466},
  shortjournal = {Front. Comput. Sci.},
  title        = {Teaching human-computer interaction Modules—And then came COVID-19},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Opportunity++: A multimodal dataset for video- and wearable,
object and ambient sensors-based human activity recognition.
<em>FCOMP</em>, <em>3</em>, 792065. (<a
href="https://doi.org/10.3389/fcomp.2021.792065">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FCOMP},
  author       = {Ciliberto, Mathias and Fortes Rey, Vitor and Calatroni, Alberto and Lukowicz, Paul and Roggen, Daniel},
  doi          = {10.3389/fcomp.2021.792065},
  journal      = {Frontiers in Computer Science},
  month        = {12},
  pages        = {792065},
  shortjournal = {Front. Comput. Sci.},
  title        = {Opportunity++: A multimodal dataset for video- and wearable, object and ambient sensors-based human activity recognition},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Singular learning of deep multilayer perceptrons for
EEG-based emotion recognition. <em>FCOMP</em>, <em>3</em>, 786964. (<a
href="https://doi.org/10.3389/fcomp.2021.786964">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human emotion recognition is an important issue in human–computer interactions, and electroencephalograph (EEG) has been widely applied to emotion recognition due to its high reliability. In recent years, methods based on deep learning technology have reached the state-of-the-art performance in EEG-based emotion recognition. However, there exist singularities in the parameter space of deep neural networks, which may dramatically slow down the training process. It is very worthy to investigate the specific influence of singularities when applying deep neural networks to EEG-based emotion recognition. In this paper, we mainly focus on this problem, and analyze the singular learning dynamics of deep multilayer perceptrons theoretically and numerically. The results can help us to design better algorithms to overcome the serious influence of singularities in deep neural networks for EEG-based emotion recognition.},
  archive      = {J_FCOMP},
  author       = {Guo, Weili and Li, Guangyu and Lu, Jianfeng and Yang, Jian},
  doi          = {10.3389/fcomp.2021.786964},
  journal      = {Frontiers in Computer Science},
  month        = {12},
  pages        = {786964},
  shortjournal = {Front. Comput. Sci.},
  title        = {Singular learning of deep multilayer perceptrons for EEG-based emotion recognition},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). SynActJ: Easy-to-use automated analysis of synaptic
activity. <em>FCOMP</em>, <em>3</em>, 777837. (<a
href="https://doi.org/10.3389/fcomp.2021.777837">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neuronal synapses are highly dynamic communication hubs that mediate chemical neurotransmission via the exocytic fusion and subsequent endocytic recycling of neurotransmitter-containing synaptic vesicles (SVs). Functional imaging tools allow for the direct visualization of synaptic activity by detecting action potentials, pre- or postsynaptic calcium influx, SV exo- and endocytosis, and glutamate release. Fluorescent organic dyes or synapse-targeted genetic molecular reporters, such as calcium, voltage or neurotransmitter sensors and synapto-pHluorins reveal synaptic activity by undergoing rapid changes in their fluorescence intensity upon neuronal activity on timescales of milliseconds to seconds, which typically are recorded by fast and sensitive widefield live cell microscopy. The analysis of the resulting time-lapse movies in the past has been performed by either manually picking individual structures, custom scripts that have not been made widely available to the scientific community, or advanced software toolboxes that are complicated to use. For the precise, unbiased and reproducible measurement of synaptic activity, it is key that the research community has access to bio-image analysis tools that are easy-to-apply and allow the automated detection of fluorescent intensity changes in active synapses. Here we present SynActJ (Synaptic Activity in ImageJ), an easy-to-use fully open-source workflow that enables automated image and data analysis of synaptic activity. The workflow consists of a Fiji plugin performing the automated image analysis of active synapses in time-lapse movies via an interactive seeded watershed segmentation that can be easily adjusted and applied to a dataset in batch mode. The extracted intensity traces of each synaptic bouton are automatically processed, analyzed, and plotted using an R Shiny workflow. We validate the workflow on time-lapse images of stimulated synapses expressing the SV exo-/endocytosis reporter Synaptophysin-pHluorin or a synapse-targeted calcium sensor, Synaptophysin-RGECO. We compare the automatic workflow to manual analysis and compute calcium-influx and SV exo-/endocytosis kinetics and other parameters for synaptic vesicle recycling under different conditions. We predict SynActJ to become an important tool for the analysis of synaptic activity and synapse properties.},
  archive      = {J_FCOMP},
  author       = {Schmied, Christopher and Soykan, Tolga and Bolz, Svenja and Haucke, Volker and Lehmann, Martin},
  doi          = {10.3389/fcomp.2021.777837},
  journal      = {Frontiers in Computer Science},
  month        = {12},
  pages        = {777837},
  shortjournal = {Front. Comput. Sci.},
  title        = {SynActJ: Easy-to-use automated analysis of synaptic activity},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). What does sleeping brain tell about stress? A pilot
functional near-infrared spectroscopy study into stress-related cortical
hemodynamic features during sleep. <em>FCOMP</em>, <em>3</em>, 774949.
(<a href="https://doi.org/10.3389/fcomp.2021.774949">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {People with mental stress often experience disturbed sleep, suggesting stress-related abnormalities in brain activity during sleep. However, no study has looked at the physiological oscillations in brain hemodynamics during sleep in relation to stress. In this pilot study, we aimed to explore the relationships between bedtime stress and the hemodynamics in the prefrontal cortex during the first sleep cycle. We tracked the stress biomarkers, salivary cortisol, and secretory immunoglobulin A (sIgA) on a daily basis and utilized the days of lower levels of measured stress as natural controls to the days of higher levels of measured stress. Cortical hemodynamics was measured using a cutting-edge wearable functional near-infrared spectroscopy (fNIRS) system. Time-domain, frequency-domain features as well as nonlinear features were derived from the cleaned hemodynamic signals. We proposed an original ensemble algorithm to generate an average importance score for each feature based on the assessment of six statistical and machine learning techniques. With all channels counted in, the top five most referred feature types are Hurst exponent, mean, the ratio of the major/minor axis standard deviation of the Poincaré plot of the signal, statistical complexity, and crest factor. The left rostral prefrontal cortex (RLPFC) was the most relevant sub-region. Significantly strong correlations were found between the hemodynamic features derived at this sub-region and all three stress indicators. The dorsolateral prefrontal cortex (DLPFC) is also a relevant cortical area. The areas of mid-DLPFC and caudal-DLPFC both demonstrated significant and moderate association to all three stress indicators. No relevance was found in the ventrolateral prefrontal cortex. The preliminary results shed light on the possible role of the RLPCF, especially the left RLPCF, in processing stress during sleep. In addition, our findings echoed the previous stress studies conducted during wake time and provides supplementary evidence on the relevance of the dorsolateral prefrontal cortex in stress responses during sleep. This pilot study serves as a proof-of-concept for a new research paradigm to stress research and identified exciting opportunities for future studies.},
  archive      = {J_FCOMP},
  author       = {Liang, Zilu},
  doi          = {10.3389/fcomp.2021.774949},
  journal      = {Frontiers in Computer Science},
  month        = {12},
  pages        = {774949},
  shortjournal = {Front. Comput. Sci.},
  title        = {What does sleeping brain tell about stress? a pilot functional near-infrared spectroscopy study into stress-related cortical hemodynamic features during sleep},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Assessing the believability of computer players in video
games: A new protocol and computer tool. <em>FCOMP</em>, <em>3</em>,
774763. (<a href="https://doi.org/10.3389/fcomp.2021.774763">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we address the challenge of believability in multiplayer video games. Our contribution is a system for assessing the believability of computer players. The state of the art examines existing methods and identifies seven distinguishing features that differ considerably from one assessment to the next. Our investigation reveals that assessment procedures typically alter gameplay, posing a considerable danger of bias. This is a major flaw since computer players are evaluated in a specific context rather than in the context of the game as it should be played, potentially skewing the findings of the evaluation. As a result, we begin on a trial-and-error process, with each new proposal building on the achievements of the previous one while removing the flaws. New proposals are tested with new assessments, a total of three experiments are then presented. We created a computer program that partially automates the execution of the assessment procedure, making these trials easier to implement. At the end, thanks to our proposal, gamers can assess the believability of computer players indirectly by employing reporting forms that alert users to the presence of bots. We assume that the more a bot is reported, the less credible it becomes. We ran a final experiment to test our proposal, which yielded extremely encouraging results.},
  archive      = {J_FCOMP},
  author       = {Even, Cindy and Bosser, Anne-Gwenn and Buche, Cédric},
  doi          = {10.3389/fcomp.2021.774763},
  journal      = {Frontiers in Computer Science},
  month        = {12},
  pages        = {774763},
  shortjournal = {Front. Comput. Sci.},
  title        = {Assessing the believability of computer players in video games: A new protocol and computer tool},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Teaching students how to frame human-computer interactions
using instrumentalism, technological determinism, and a quadrant
learning activity. <em>FCOMP</em>, <em>3</em>, 771731. (<a
href="https://doi.org/10.3389/fcomp.2021.771731">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper describes an innovative learning activity for educating students about human-computer interaction. The goal of this learning activity is to familiarize students with the way instrumentalists on the one hand, and technological determinists on the other, conceive of human-technology interaction, and to assess which theory students favor. This paper describes and evaluates the efficacy of this learning activity and presents preliminary data on student responses. It also establishes a framework for understanding how students initially perceive human-technology interaction and how that understanding can be used to personalize and improve their learning. Instrumentalists believe that technology can be understood simply as a tool or neutral instrument that humans use to achieve their own ends. In contrast, technological determinists believe that technology is not fully under human control, that it has some degree of autonomy, and that it has its own ends. Exposing students to these two theories of human-technological interaction provides five benefits: First, the competing theories deepen students’ ability to describe how technology and humans interact. Second, they provide an ethical framework that students can use to describe how technology and humans should interact. Third, they provide students with a vocabulary that they can use to talk about human freedom and how the design of computing technology may constrain or expand that freedom. Fourth, by challenging students to articulate what theory they favor, the learning is personalized. Fifth, because the learning activity challenges students to express their personal beliefs about how humans and technology interact, the learning activity can help instructors develop a clearer understanding of those beliefs and whether they reinforce what Erin Cech has identified as a culture of depoliticization and disengagement in engineering culture.},
  archive      = {J_FCOMP},
  author       = {Fernandez, Luke},
  doi          = {10.3389/fcomp.2021.771731},
  journal      = {Frontiers in Computer Science},
  month        = {12},
  pages        = {771731},
  shortjournal = {Front. Comput. Sci.},
  title        = {Teaching students how to frame human-computer interactions using instrumentalism, technological determinism, and a quadrant learning activity},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Building an artificial intelligence laboratory based on real
world data: The experience of gemelli generator. <em>FCOMP</em>,
<em>3</em>, 768266. (<a
href="https://doi.org/10.3389/fcomp.2021.768266">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The problem of transforming Real World Data into Real World Evidence is becoming increasingly important in the frameworks of Digital Health and Personalized Medicine, especially with the availability of modern algorithms of Artificial Intelligence high computing power, and large storage facilities.Even where Real World Data are well maintained in a hospital data warehouse and are made available for research purposes, many aspects need to be addressed to build an effective architecture enabling researchers to extract knowledge from data.We describe the first year of activity at Gemelli Generator RWD, the challenges we faced and the solutions we put in place to build a Real World Data laboratory at the service of patients and health researchers. Three classes of services are available today: retrospective analysis of existing patient data for descriptive and clustering purposes; automation of knowledge extraction, ranging from text mining, patient selection for trials, to generation of new research hypotheses; and finally the creation of Decision Support Systems, with the integration of data from the hospital data warehouse, apps, and Internet of Things.},
  archive      = {J_FCOMP},
  author       = {Damiani, A. and Masciocchi, C. and Lenkowicz, J. and Capocchiano, N. D. and Boldrini, L. and Tagliaferri, L. and Cesario, A. and Sergi, P. and Marchetti, A. and Luraschi, A. and Patarnello, S. and Valentini, V.},
  doi          = {10.3389/fcomp.2021.768266},
  journal      = {Frontiers in Computer Science},
  month        = {12},
  pages        = {768266},
  shortjournal = {Front. Comput. Sci.},
  title        = {Building an artificial intelligence laboratory based on real world data: The experience of gemelli generator},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multimodal affect models: An investigation of relative
salience of audio and visual cues for emotion prediction.
<em>FCOMP</em>, <em>3</em>, 767767. (<a
href="https://doi.org/10.3389/fcomp.2021.767767">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {People perceive emotions via multiple cues, predominantly speech and visual cues, and a number of emotion recognition systems utilize both audio and visual cues. Moreover, the perception of static aspects of emotion (speaker&#39;s arousal level is high/low) and the dynamic aspects of emotion (speaker is becoming more aroused) might be perceived via different expressive cues and these two aspects are integrated to provide a unified sense of emotion state. However, existing multimodal systems only focus on single aspect of emotion perception and the contributions of different modalities toward modeling static and dynamic emotion aspects are not well explored. In this paper, we investigate the relative salience of audio and video modalities to emotion state prediction and emotion change prediction using a Multimodal Markovian affect model. Experiments conducted in the RECOLA database showed that audio modality is better at modeling the emotion state of arousal and video for emotion state of valence, whereas audio shows superior advantages over video in modeling emotion changes for both arousal and valence.},
  archive      = {J_FCOMP},
  author       = {Wu, Jingyao and Dang, Ting and Sethu, Vidhyasaharan and Ambikairajah, Eliathamby},
  doi          = {10.3389/fcomp.2021.767767},
  journal      = {Frontiers in Computer Science},
  month        = {12},
  pages        = {767767},
  shortjournal = {Front. Comput. Sci.},
  title        = {Multimodal affect models: An investigation of relative salience of audio and visual cues for emotion prediction},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Breathing in-depth: A parametrization study on RGB-d
respiration extraction methods. <em>FCOMP</em>, <em>3</em>, 757277. (<a
href="https://doi.org/10.3389/fcomp.2021.757277">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As depth cameras have gotten smaller, more affordable, and more precise, they have also emerged as a promising sensor in ubiquitous systems, particularly for detecting objects, scenes, and persons. This article sets out to systematically evaluate how suitable depth data can be for picking up users’ respiration, from small distance changes across the torso over time. We contribute a large public dataset of depth data over time from 19 persons taken in a large variety of circumstances. On this data, we evaluate and compare different state-of-the-art methods and show that their individual performance significantly depends on a range of conditions and parameters. We investigate the influence of the observed torso region (e.g., the chest), the user posture and activity, the distance to the depth camera, the respiratory rate, the gender, and user specific peculiarities. Best results hereby are obtained from the chest whereas the abdomen is least suited for detecting the user’s breathing. In terms of accuracy and signal quality, the largest differences are observed on different user postures and activities. All methods can maintain a mean accuracy of above 92% when users are sitting, but half of the observed methods only achieve a mean accuracy of 51% while standing. When users are standing and additionally move their arms in front of their upper body, mean accuracy values between the worst and best performing methods range from 21 to 87%. Increasing the distance to the depth camera furthermore results in lower signal quality and decreased accuracy on all methods. Optimal results can be obtained at distances of 1–2 m. Different users have been found to deliver varying qualities of breathing signals. Causes range from clothing, over long hair, to movement. Other parameters have shown to play a minor role in the detection of users’ breathing.},
  archive      = {J_FCOMP},
  author       = {Kempfle, Jochen and Van Laerhoven, Kristof},
  doi          = {10.3389/fcomp.2021.757277},
  journal      = {Frontiers in Computer Science},
  month        = {12},
  pages        = {757277},
  shortjournal = {Front. Comput. Sci.},
  title        = {Breathing in-depth: A parametrization study on RGB-D respiration extraction methods},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Design and evaluation of a hands-free video game controller
for individuals with motor impairments. <em>FCOMP</em>, <em>3</em>,
751455. (<a href="https://doi.org/10.3389/fcomp.2021.751455">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Over the past few decades, video gaming has evolved at a tremendous rate although game input methods have been slower to change. Game input methods continue to rely on two-handed control of the joystick and D-pad or the keyboard and mouse for simultaneously controlling player movement and camera actions. Bi-manual input poses a significant play impediment to those with severe motor impairments. In this work, we propose and evaluate a hands-free game input control method that uses real-time facial expression recognition. Through our novel input method, our goal is to enable and empower individuals with neurological and neuromuscular diseases, who may lack hand muscle control, to be able to independently play video games. To evaluate the usability and acceptance of our system, we conducted a remote user study with eight severely motor-impaired individuals. Our results indicate high user satisfaction and greater preference for our input system with participants rating the input system as easy to learn. With this work, we aim to highlight that facial expression recognition can be a valuable input method.},
  archive      = {J_FCOMP},
  author       = {Taheri , Atieh and Weissman , Ziv and Sra, Misha},
  doi          = {10.3389/fcomp.2021.751455},
  journal      = {Frontiers in Computer Science},
  month        = {12},
  pages        = {751455},
  shortjournal = {Front. Comput. Sci.},
  title        = {Design and evaluation of a hands-free video game controller for individuals with motor impairments},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Digital therapeutics: Virtual coaching powered by artificial
intelligence on real-world data. <em>FCOMP</em>, <em>3</em>, 750428. (<a
href="https://doi.org/10.3389/fcomp.2021.750428">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An ever-increasing number of people need to cope with one or more chronic conditions for a significant portion of their life. Digital Therapeutics (DTx) focused on the prevention, management, or treatment of chronic diseases are promising in alleviating the personal socio-economic burden caused. In this paper we describe a proposed DTx methodology covering three main components: observation (which data is collected), understanding (how to acquire knowledge based on the data collected), and coaching (how to communicate the acquired knowledge to the user). We focus on an emerging form of automated virtual coaching, delivered through conversational agents allowing interaction with end-users using natural language. Our methodology will be applied in the new generation of the Healthentia platform, an eClinical solution that captures clinical outcomes from mobile, medical and Internet of Things (IoT) devices, using a patient-centric mobile application and offers Artificial Intelligence (AI) driven smart services. While we are unable to provide data to prove its effectiveness, we illustrate the potential of the proposed architecture to deliver DTx by describing how the methodology can be applied to a use-case consisting of a clinical trial for treatment of a chronic condition, combining testing of a new medication and a lifestyle intervention, which will be partly implemented and evaluated in the context of the European research project RE-SAMPLE (REal-time data monitoring for Shared, Adaptive, Multi-domain and Personalised prediction, and decision making for Long-term Pulmonary care Ecosystems).},
  archive      = {J_FCOMP},
  author       = {op den Akker, Harm and Cabrita, Miriam and Pnevmatikakis, Aristodemos},
  doi          = {10.3389/fcomp.2021.750428},
  journal      = {Frontiers in Computer Science},
  month        = {12},
  pages        = {750428},
  shortjournal = {Front. Comput. Sci.},
  title        = {Digital therapeutics: Virtual coaching powered by artificial intelligence on real-world data},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An evaluation of speech-based recognition of emotional and
physiological markers of stress. <em>FCOMP</em>, <em>3</em>, 750284. (<a
href="https://doi.org/10.3389/fcomp.2021.750284">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Life in modern societies is fast-paced and full of stress-inducing demands. The development of stress monitoring methods is a growing area of research due to the personal and economic advantages that timely detection provides. Studies have shown that speech-based features can be utilised to robustly predict several physiological markers of stress, including emotional state, continuous heart rate, and the stress hormone, cortisol. In this contribution, we extend previous works by the authors, utilising three German language corpora including more than 100 subjects undergoing a Trier Social Stress Test protocol. We present cross-corpus and transfer learning results which explore the efficacy of the speech signal to predict three physiological markers of stress—sequentially measured saliva-based cortisol, continuous heart rate as beats per minute (BPM), and continuous respiration. For this, we extract several features from audio as well as video and apply various machine learning architectures, including a temporal context-based Long Short-Term Memory Recurrent Neural Network (LSTM-RNN). For the task of predicting cortisol levels from speech, deep learning improves on results obtained by conventional support vector regression—yielding a Spearman correlation coefficient (ρ) of 0.770 and 0.698 for cortisol measurements taken 10 and 20 min after the stress period for the two corpora applicable—showing that audio features alone are sufficient for predicting cortisol, with audiovisual fusion to an extent improving such results. We also obtain a Root Mean Square Error (RMSE) of 38 and 22 BPM for continuous heart rate prediction on the two corpora where this information is available, and a normalised RMSE (NRMSE) of 0.120 for respiration prediction (−10: 10). Both of these continuous physiological signals show to be highly effective markers of stress (based on cortisol grouping analysis), both when available as ground truth and when predicted using speech. This contribution opens up new avenues for future exploration of these signals as proxies for stress in naturalistic settings.},
  archive      = {J_FCOMP},
  author       = {Baird, Alice and Triantafyllopoulos, Andreas and Zänkert, Sandra and Ottl, Sandra and Christ, Lukas and Stappen, Lukas and Konzok, Julian and Sturmbauer, Sarah and Meßner, Eva-Maria and Kudielka, Brigitte M. and Rohleder, Nicolas and Baumeister, Harald and Schuller, Björn W.},
  doi          = {10.3389/fcomp.2021.750284},
  journal      = {Frontiers in Computer Science},
  month        = {12},
  pages        = {750284},
  shortjournal = {Front. Comput. Sci.},
  title        = {An evaluation of speech-based recognition of emotional and physiological markers of stress},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). IoT as non-pharmaceutical interventions for the safety of
living environments in COVID-19 pandemic age. <em>FCOMP</em>,
<em>3</em>, 733645. (<a
href="https://doi.org/10.3389/fcomp.2021.733645">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The outbreak of the Sars-Cov-2 pandemic has changed our perception of safety in shared and public living environments including healthcare facilities, shops, schools, and enterprises. The Internet of Things (IoT) represents a suitable solution for managing anti-pandemic smart devices (e.g., UV lights, smart cameras, etc.) and increasing citizens’ safety in public health crises. In this paper, we highlighted how IoT technologies can be exploited as non-pharmaceutical interventions presenting the SAFE PLACE project as an implementation of this concept. The project meant to design and develop an IoT system to ensure the safety and salubrity of shared environments. Advanced algorithms will be exploited to detect and classify humans’ presence, gathering, usage of personal protective equipment, and considering carefully the privacy protection of individuals.},
  archive      = {J_FCOMP},
  author       = {Gamberini, Luciano and Pluchino, Patrik and Bacchin, Davide and Zanella, Andrea and Orso, Valeria and Anna, Spagnolli and Mapelli, Daniela},
  doi          = {10.3389/fcomp.2021.733645},
  journal      = {Frontiers in Computer Science},
  month        = {12},
  pages        = {733645},
  shortjournal = {Front. Comput. Sci.},
  title        = {IoT as non-pharmaceutical interventions for the safety of living environments in COVID-19 pandemic age},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Brain-computer interfaces and creative expression: Interface
considerations for rehabilitative and therapeutic interactions.
<em>FCOMP</em>, <em>3</em>, 718605. (<a
href="https://doi.org/10.3389/fcomp.2021.718605">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {By translating brain signals into new kinds of outputs, Brain-Computer Interface (BCI) systems hold tremendous potential as both transformative rehabilitation and communication tools. BCIs can be considered a unique technology, in that they are able to provide a direct link between the brain and the external environment. By affording users with opportunities for communication and self-expression, BCI systems serve as a bridge between abled-bodied and disabled users, in turn reducing existing barriers between these groups. This perspective piece explores the complex shifting relationship between neuroadaptive systems and humans by foregrounding personal experience and embodied interaction as concepts through which to evaluate digital environments cultivated through the design of BCI interfaces. To underscore the importance of fostering human-centered experiences through technologically mediated interactions, this work offers a conceptual framework through which the rehabilitative and therapeutic possibilities of BCI user-system engagement could be furthered. By inviting somatic analysis towards the design of BCI interfaces and incorporating tenets of creative arts therapies practices into hybrid navigation paradigms for self-expressive applications, this work highlights the need for examining individual technological interactions as sites with meaning-making potentiality, as well as those conceived through unique exchanges based on user-specific needs for communication. Designing BCI interfaces in ways that afford users with increased options for navigation, as well as with the ability to share subjective and collective experiences, helps to redefine existing boundaries of digital and physical user-system interactions and encourages the reimagining of these systems as novel digital health tools for recovery.},
  archive      = {J_FCOMP},
  author       = {Scott, Stephanie M. and Raftery, Chris},
  doi          = {10.3389/fcomp.2021.718605},
  journal      = {Frontiers in Computer Science},
  month        = {12},
  pages        = {718605},
  shortjournal = {Front. Comput. Sci.},
  title        = {Brain-computer interfaces and creative expression: Interface considerations for rehabilitative and therapeutic interactions},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A reflection on the state of multisensory human–food
interaction research. <em>FCOMP</em>, <em>3</em>, 694691. (<a
href="https://doi.org/10.3389/fcomp.2021.694691">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a perspective article on the state of multisensory human–food interaction (MHFI) research and lay out some reflections for research and development in this area of inquiry, based on a revision of the different spaces that we have co-created with researchers in this space. We begin by conceptualizing and defining MHFI, before moving onto presenting some of its major themes, as well as possible ways in which such themes can guide future research in the area. This article provides key definitions and foundations for the area of MHFI, as well as a first point of contact for those interested in it.},
  archive      = {J_FCOMP},
  author       = {Velasco, Carlos and Wang, Qian Janice and Obrist, Marianna and Nijholt, Anton},
  doi          = {10.3389/fcomp.2021.694691},
  journal      = {Frontiers in Computer Science},
  month        = {12},
  pages        = {694691},
  shortjournal = {Front. Comput. Sci.},
  title        = {A reflection on the state of multisensory Human–Food interaction research},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Editorial: Biomedical signals for human-computer
interaction. <em>FCOMP</em>, <em>3</em>, 799952. (<a
href="https://doi.org/10.3389/fcomp.2021.799952">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FCOMP},
  author       = {Plácido da Silva, Hugo and Garcia, Nuno M. and Solovey, Erin T.},
  doi          = {10.3389/fcomp.2021.799952},
  journal      = {Frontiers in Computer Science},
  month        = {11},
  pages        = {799952},
  shortjournal = {Front. Comput. Sci.},
  title        = {Editorial: Biomedical signals for human-computer interaction},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Deep learning-based sentiment analysis and topic modeling on
tourism during covid-19 pandemic. <em>FCOMP</em>, <em>3</em>, 775368.
(<a href="https://doi.org/10.3389/fcomp.2021.775368">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Covid-19 pandemic has disrupted the world economy and significantly influenced the tourism industry. Millions of people have shared their emotions, views, facts, and circumstances on numerous social media platforms, which has resulted in a massive flow of information. The high-density social media data has drawn many researchers to extract valuable information and understand the user’s emotions during the pandemic time. The research looks at the data collected from the micro-blogging site Twitter for the tourism sector, emphasizing sub-domains hospitality and healthcare. The sentiment of approximately 20,000 tweets have been calculated using Valence Aware Dictionary for Sentiment Reasoning (VADER) model. Furthermore, topic modeling was used to reveal certain hidden themes and determine the narrative and direction of the topics related to tourism healthcare, and hospitality. Topic modeling also helped us to identify inter-cluster similar terms and analyzing the flow of information from a group of a similar opinion. Finally, a cutting-edge deep learning classification model was used with different epoch sizes of the dataset to anticipate and classify the people’s feelings. The deep learning model has been tested with multiple parameters such as training set accuracy, test set accuracy, validation loss, validation accuracy, etc., and resulted in more than a 90% in training set accuracy tourism hospitality and healthcare reported 80.9 and 78.7% respectively on test set accuracy.},
  archive      = {J_FCOMP},
  author       = {Mishra, Ram Krishn and Urolagin, Siddhaling and Jothi, J. Angel Arul and Neogi, Ashwin Sanjay and Nawaz, Nishad},
  doi          = {10.3389/fcomp.2021.775368},
  journal      = {Frontiers in Computer Science},
  month        = {11},
  pages        = {775368},
  shortjournal = {Front. Comput. Sci.},
  title        = {Deep learning-based sentiment analysis and topic modeling on tourism during covid-19 pandemic},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Image processing filters for grids of cells analogous to
filters processing grids of pixels. <em>FCOMP</em>, <em>3</em>, 774396.
(<a href="https://doi.org/10.3389/fcomp.2021.774396">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intra- and extra-cellular processes shape tissues together. For understanding how neighborhood relationships between cells play a role in this process, having image processing filters based on these relationships would be beneficial. Those operations are known and their application to microscopy image data typically requires programming skills. User-friendly general purpose tools for pursuing image processing on a level of neighboring cells were yet missing. In this manuscript I demonstrate image processing filters which process grids of cells on tissue level and the analogy to their better known counter parts processing grids of pixels. The tools are available as part of free and open source software in the ImageJ/Fiji and napari ecosystems and their application does not require any programming experience.},
  archive      = {J_FCOMP},
  author       = {Haase , Robert},
  doi          = {10.3389/fcomp.2021.774396},
  journal      = {Frontiers in Computer Science},
  month        = {11},
  pages        = {774396},
  shortjournal = {Front. Comput. Sci.},
  title        = {Image processing filters for grids of cells analogous to filters processing grids of pixels},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Diffusion state transitions in single-particle trajectories
of MET receptor tyrosine kinase measured in live cells. <em>FCOMP</em>,
<em>3</em>, 757653. (<a
href="https://doi.org/10.3389/fcomp.2021.757653">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Single-particle tracking enables the analysis of the dynamics of biomolecules in living cells with nanometer spatial and millisecond temporal resolution. This technique reports on the mobility of membrane proteins and is sensitive to the molecular state of a biomolecule and to interactions with other biomolecules. Trajectories describe the mobility of single particles over time and provide information such as the diffusion coefficient and diffusion state. Changes in particle dynamics within single trajectories lead to segmentation, which allows to extract information on transitions of functional states of a biomolecule. Here, mean-squared displacement analysis is developed to classify trajectory segments into immobile, confined diffusing, and freely diffusing states, and to extract the occurrence of transitions between these modes. We applied this analysis to single-particle tracking data of the membrane receptor MET in live cells and analyzed state transitions in single trajectories of the un-activated receptor and the receptor bound to the ligand internalin B. We found that internalin B-bound MET shows an enhancement of transitions from freely and confined diffusing states into the immobile state as compared to un-activated MET. Confined diffusion acts as an intermediate state between immobile and free, as this state is most likely to change the diffusion state in the following segment. This analysis can be readily applied to single-particle tracking data of other membrane receptors and intracellular proteins under various conditions and contribute to the understanding of molecular states and signaling pathways.},
  archive      = {J_FCOMP},
  author       = {Rahm, Johanna V. and Malkusch, Sebastian and Endesfelder, Ulrike and Dietz, Marina S. and Heilemann, Mike},
  doi          = {10.3389/fcomp.2021.757653},
  journal      = {Frontiers in Computer Science},
  month        = {11},
  pages        = {757653},
  shortjournal = {Front. Comput. Sci.},
  title        = {Diffusion state transitions in single-particle trajectories of MET receptor tyrosine kinase measured in live cells},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The origin of patterns. <em>FCOMP</em>, <em>3</em>, 747195.
(<a href="https://doi.org/10.3389/fcomp.2021.747195">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The question is discussed from where the patterns arise that are recognized in the world. Are they elements of the outside world, or do they originate from the concepts that live in the mind of the observer? It is argued that they are created during observation, due to the knowledge on which the observation ability is based. For an experienced observer this may result in a direct recognition of an object or phenomenon without any reasoning. Afterwards and using conscious effort he may be able to supply features or arguments that he might have used for his recognition. The discussion is phrased in the philosophical debate between monism, in which the observer is an element of the observed world, and dualism, in which these two are fully separated. Direct recognition can be understood from a monistic point of view. After the definition of features and the formulation of a reasoning, dualism may arise. An artificial pattern recognition system based on these specifications thereby creates a clear dualistic situation. It fully separates the two worlds by physical sensors and mechanical reasoning. This dualistic position can be solved by a responsible integration of artificially intelligent systems in human controlled applications. A set of simple experiments based on the classification of histopathological slides is presented to illustrate the discussion.},
  archive      = {J_FCOMP},
  author       = {Duin, Robert P. W.},
  doi          = {10.3389/fcomp.2021.747195},
  journal      = {Frontiers in Computer Science},
  month        = {11},
  pages        = {747195},
  shortjournal = {Front. Comput. Sci.},
  title        = {The origin of patterns},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Real-time music following in score sheet images via
multi-resolution prediction. <em>FCOMP</em>, <em>3</em>, 718340. (<a
href="https://doi.org/10.3389/fcomp.2021.718340">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The task of real-time alignment between a music performance and the corresponding score (sheet music), also known as score following, poses a challenging multi-modal machine learning problem. Training a system that can solve this task robustly with live audio and real sheet music (i.e., scans or score images) requires precise ground truth alignments between audio and note-coordinate positions in the score sheet images. However, these kinds of annotations are difficult and costly to obtain, which is why research in this area mainly utilizes synthetic audio and sheet images to train and evaluate score following systems. In this work, we propose a method that does not solely rely on note alignments but is additionally capable of leveraging data with annotations of lower granularity, such as bar or score system alignments. This allows us to use a large collection of real-world piano performance recordings coarsely aligned to scanned score sheet images and, as a consequence, improve over current state-of-the-art approaches.},
  archive      = {J_FCOMP},
  author       = {Henkel , Florian and Widmer , Gerhard},
  doi          = {10.3389/fcomp.2021.718340},
  journal      = {Frontiers in Computer Science},
  month        = {11},
  pages        = {718340},
  shortjournal = {Front. Comput. Sci.},
  title        = {Real-time music following in score sheet images via multi-resolution prediction},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Emotionalism within people-oriented software design.
<em>FCOMP</em>, <em>3</em>, 717787. (<a
href="https://doi.org/10.3389/fcomp.2021.717787">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In designing most software applications, much effort is placed upon the functional goals, making a software system useful. However, the failure to consider emotional goals, which make a software system pleasurable to use, can result in disappointment and system rejection even if utilitarian goals are well implemented. Although several studies have emphasised the importance of people’s emotional goals in developing software, there is little advice on how to address these goals in the software system development process. This paper bridges the gap between emotional goals elicitation and the software system design process by proposing a novel technique entitled the Emotional Goal Systematic Analysis Technique (EG-SAT) to systematically analyse people’s emotional goals in cooperation with functional and quality goals. EG-SAT allows in-depth analysis of emotional goals to build a software system and provides a visual notation for representing the analysis, facilitating communication and documentation. EG-SAT provides traceability of emotional goals in system design by connecting the emotional goals to functional and quality goals. To demonstrate the method in use, a two-part evaluation is conducted. First, EG-SAT is used to analyse the emotional goals of potential users of a mobile learning application that provides information about low carbon living for tradespeople and professionals in the building industry in Australia. The results of using EG-SAT in this case study are compared with a professionally developed baseline. Second, we ran a semi-controlled experiment in which 12 participants were asked to apply EG-SAT and another technique to our case study. The outcomes show that EG-SAT helped participants analyse emotional goals and gain valuable insights about the functional and non-functional goals for addressing people’s emotional goals. The key novelty of the EG-SAT is in proposing an easy to learn and easy to use technique that helps system analysts gain insights on how to address people’s emotional goals. Furthermore, the EG-SAT enables system analysts to convert emotional goals to traditional functional and non-functional goals that existing software engineering methodologies can analyse without demanding excessive effort.},
  archive      = {J_FCOMP},
  author       = {Sherkat, Mohammadhossein and Miller, Tim and Mendoza, Antonette and Burrows, Rachel},
  doi          = {10.3389/fcomp.2021.717787},
  journal      = {Frontiers in Computer Science},
  month        = {11},
  pages        = {717787},
  shortjournal = {Front. Comput. Sci.},
  title        = {Emotionalism within people-oriented software design},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). To play and to be played: Exploring the design of urban
machines for playful placemaking. <em>FCOMP</em>, <em>3</em>, 635949.
(<a href="https://doi.org/10.3389/fcomp.2021.635949">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Within the paradigm of the smart and playable city, the urban landscape and street furniture have provided a fertile platform for pragmatic and hedonic goals of urban liveability through technology augmentation. Smart street furniture has grown from being a novelty to become a common sight in metropolitan cities, co-opted for improving the efficiency of services. However, as we consider technologies that are increasingly smarter, with human-like intelligence, we navigate towards uncharted waters when discussing the consequences of their integration with the urban landscape. The implications of a new genre of street furniture embedded with artificial intelligence, where the machine has autonomy and is an active player itself, are yet to be fully understood. In this article, we analyse the evolving design of public benches along the axes of smartness and disruption to understand their qualities as playful, urban machines in public spaces. We present a concept-driven speculative design case study, as an exploration of a smart, sensing, and disruptive urban machine for playful placemaking. With the emergence of artificial intelligence, we expand on the potential of urban machines to partake an increasingly active role as co-creators of play and playful placemaking in the cities of tomorrow.},
  archive      = {J_FCOMP},
  author       = {Chew, Louis and Hespanhol, Luke and Loke, Lian},
  doi          = {10.3389/fcomp.2021.635949},
  journal      = {Frontiers in Computer Science},
  month        = {11},
  pages        = {635949},
  shortjournal = {Front. Comput. Sci.},
  title        = {To play and to be played: Exploring the design of urban machines for playful placemaking},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Editorial: Alzheimer’s dementia recognition through
spontaneous speech. <em>FCOMP</em>, <em>3</em>, 780169. (<a
href="https://doi.org/10.3389/fcomp.2021.780169">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FCOMP},
  author       = {Luz, Saturnino and Haider, Fasih and de la Fuente Garcia, Sofia and Fromm, Davida and MacWhinney, Brian},
  doi          = {10.3389/fcomp.2021.780169},
  journal      = {Frontiers in Computer Science},
  month        = {10},
  pages        = {780169},
  shortjournal = {Front. Comput. Sci.},
  title        = {Editorial: Alzheimer&#39;s dementia recognition through spontaneous speech},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Editorial: Compelling COVID-19 graphical simulations.
<em>FCOMP</em>, <em>3</em>, 779793. (<a
href="https://doi.org/10.3389/fcomp.2021.779793">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FCOMP},
  author       = {Johnson-Glenberg, Mina C.},
  doi          = {10.3389/fcomp.2021.779793},
  journal      = {Frontiers in Computer Science},
  month        = {10},
  pages        = {779793},
  shortjournal = {Front. Comput. Sci.},
  title        = {Editorial: Compelling COVID-19 graphical simulations},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). CSL-SHARE: A multimodal wearable sensor-based human
activity dataset. <em>FCOMP</em>, <em>3</em>, 759136. (<a
href="https://doi.org/10.3389/fcomp.2021.759136">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FCOMP},
  author       = {Liu, Hui and Hartmann, Yale and Schultz, Tanja},
  doi          = {10.3389/fcomp.2021.759136},
  journal      = {Frontiers in Computer Science},
  month        = {10},
  pages        = {759136},
  shortjournal = {Front. Comput. Sci.},
  title        = {CSL-SHARE: A multimodal wearable sensor-based human activity dataset},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Manifesto for digital social touch in crisis.
<em>FCOMP</em>, <em>3</em>, 754050. (<a
href="https://doi.org/10.3389/fcomp.2021.754050">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This qualitative exploratory research paper presents a Manifesto for Digital Social Touch in Crisis - a provocative call to action to designers, developers and researchers to rethink and reimagine social touch through a deeper engagement with the social and sensory aspects of touch. This call is motivated by concerns that social touch is in a crisis signaled by a decline in social touch over the past 2 decades, the problematics of inappropriate social touch, and the well documented impact of a lack of social touch on communication, relationships, and well-being and health. These concerns shape how social touch enters the digital realm and raise questions for how and when the complex space of social touch is mediated by technologies, as well the societal implications. The paper situates the manifesto in the key challenges facing haptic designers and developers identified through a series of interdisciplinary collaborative workshops with participants from computer science, design, engineering, HCI and social science from both within industry and academia, and the research literature on haptics. The features and purpose of the manifesto form are described, along with our rationale for its use, and the method of the manifesto development. The starting points, opportunities and challenges, dominant themes and tensions that shaped the manifesto statements are then elaborated on. The paper shows the potential of the manifesto form to bridge between HCI, computer science and engineers, and social scientists on the topic of social touch.},
  archive      = {J_FCOMP},
  author       = {Jewitt, Carey and Price, Sara and Steimle, Jürgen and Huisman, Gijs and Golmohammadi, Lili and Pourjafarian, Narges and Frier, William and Howard, Thomas and Ipakchian Askari, Sima and Ornati, Michela and Panëels, Sabrina and Weda, Judith},
  doi          = {10.3389/fcomp.2021.754050},
  journal      = {Frontiers in Computer Science},
  month        = {10},
  pages        = {754050},
  shortjournal = {Front. Comput. Sci.},
  title        = {Manifesto for digital social touch in crisis},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A workflow for rapid unbiased quantification of fibrillar
feature alignment in biological images. <em>FCOMP</em>, <em>3</em>,
745831. (<a href="https://doi.org/10.3389/fcomp.2021.745831">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Measuring the organization of the cellular cytoskeleton and the surrounding extracellular matrix (ECM) is currently of wide interest as changes in both local and global alignment can highlight alterations in cellular functions and material properties of the extracellular environment. Different approaches have been developed to quantify these structures, typically based on fiber segmentation or on matrix representation and transformation of the image, each with its own advantages and disadvantages. Here we present AFT − Alignment by Fourier Transform, a workflow to quantify the alignment of fibrillar features in microscopy images exploiting 2D Fast Fourier Transforms (FFT). Using pre-existing datasets of cell and ECM images, we demonstrate our approach and compare and contrast this workflow with two other well-known ImageJ algorithms to quantify image feature alignment. These comparisons reveal that AFT has a number of advantages due to its grid-based FFT approach. 1) Flexibility in defining the window and neighborhood sizes allows for performing a parameter search to determine an optimal length scale to carry out alignment metrics. This approach can thus easily accommodate different image resolutions and biological systems. 2) The length scale of decay in alignment can be extracted by comparing neighborhood sizes, revealing the overall distance that features remain anisotropic. 3) The approach is ambivalent to the signal source, thus making it applicable for a wide range of imaging modalities and is dependent on fewer input parameters than segmentation methods. 4) Finally, compared to segmentation methods, this algorithm is computationally inexpensive, as high-resolution images can be evaluated in less than a second on a standard desktop computer. This makes it feasible to screen numerous experimental perturbations or examine large images over long length scales. Implementation is made available in both MATLAB and Python for wider accessibility, with example datasets for single images and batch processing. Additionally, we include an approach to automatically search parameters for optimum window and neighborhood sizes, as well as to measure the decay in alignment over progressively increasing length scales.},
  archive      = {J_FCOMP},
  author       = {Marcotti, Stefania and Belo de Freitas, Deandra and Troughton, Lee D and Kenny, Fiona N and Shaw, Tanya J and Stramer, Brian M and Oakes, Patrick W},
  doi          = {10.3389/fcomp.2021.745831},
  journal      = {Frontiers in Computer Science},
  month        = {10},
  pages        = {745831},
  shortjournal = {Front. Comput. Sci.},
  title        = {A workflow for rapid unbiased quantification of fibrillar feature alignment in biological images},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Cybersecurity policy framework in saudi arabia: Literature
review. <em>FCOMP</em>, <em>3</em>, 736874. (<a
href="https://doi.org/10.3389/fcomp.2021.736874">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Saudi Arabia has a goal of ensuring that it has at least two cities among the top 100 smart cities of the future. However, increasing connectivity and incorporation of smart solutions in cities still raises concerns over cyber security with threats arising daily including denial of services and phishing as some of the most significant. Saudi Arabia, therefore, needs a cybersecurity policy framework that will ensure effective protection for all stakeholders in the smart city from these cyber threats. User acceptance is foremost important in any new technology, including smart-cities. Due to ongoing cyber threats and in the absence of an efficient cyber policies, Saudi end-user community is not keen to accept newer technologies where their interaction with online medium is required. The proliferation of smart cities globally affords the opportunity to analyze and compare the efforts made in Saudi Arabia with other nations like the USA, India and Singapore which is the premier smart city model in the globe currently. This review looks at the similarities and differences between KSA’s cyber security policy framework with these three nations. The review will note some of the defining characteristics and approaches to cyber security in the smart cities of USA, India, and Singapore. After reviewing the current framework in Saudi Arabia, this paper will make suggestions such as updating Saudi’s cybercrime legislation like in the US or formulating a master cyber security plan as seen in Singapore that will improve KSA’s framework creating the best framework model for cyber security in its smart cities.},
  archive      = {J_FCOMP},
  author       = {Alhalafi, Nawaf and Veeraraghavan, Prakash},
  doi          = {10.3389/fcomp.2021.736874},
  journal      = {Frontiers in Computer Science},
  month        = {10},
  pages        = {736874},
  shortjournal = {Front. Comput. Sci.},
  title        = {Cybersecurity policy framework in saudi arabia: Literature review},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Automated deep lineage tree analysis using a bayesian single
cell tracking approach. <em>FCOMP</em>, <em>3</em>, 734559. (<a
href="https://doi.org/10.3389/fcomp.2021.734559">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Single-cell methods are beginning to reveal the intrinsic heterogeneity in cell populations, arising from the interplay of deterministic and stochastic processes. However, it remains challenging to quantify single-cell behaviour from time-lapse microscopy data, owing to the difficulty of extracting reliable cell trajectories and lineage information over long time-scales and across several generations. Therefore, we developed a hybrid deep learning and Bayesian cell tracking approach to reconstruct lineage trees from live-cell microscopy data. We implemented a residual U-Net model coupled with a classification CNN to allow accurate instance segmentation of the cell nuclei. To track the cells over time and through cell divisions, we developed a Bayesian cell tracking methodology that uses input features from the images to enable the retrieval of multi-generational lineage information from a corpus of thousands of hours of live-cell imaging data. Using our approach, we extracted 20,000 + fully annotated single-cell trajectories from over 3,500 h of video footage, organised into multi-generational lineage trees spanning up to eight generations and fourth cousin distances. Benchmarking tests, including lineage tree reconstruction assessments, demonstrate that our approach yields high-fidelity results with our data, with minimal requirement for manual curation. To demonstrate the robustness of our minimally supervised cell tracking methodology, we retrieve cell cycle durations and their extended inter- and intra-generational family relationships in 5,000 + fully annotated cell lineages. We observe vanishing cycle duration correlations across ancestral relatives, yet reveal correlated cyclings between cells sharing the same generation in extended lineages. These findings expand the depth and breadth of investigated cell lineage relationships in approximately two orders of magnitude more data than in previous studies of cell cycle heritability, which were reliant on semi-manual lineage data analysis.},
  archive      = {J_FCOMP},
  author       = {Ulicna, Kristina and Vallardi, Giulia and Charras, Guillaume and Lowe, Alan R.},
  doi          = {10.3389/fcomp.2021.734559},
  journal      = {Frontiers in Computer Science},
  month        = {10},
  pages        = {734559},
  shortjournal = {Front. Comput. Sci.},
  title        = {Automated deep lineage tree analysis using a bayesian single cell tracking approach},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Automated student group collaboration assessment and
recommendation system using individual role and behavioral cues.
<em>FCOMP</em>, <em>3</em>, 728801. (<a
href="https://doi.org/10.3389/fcomp.2021.728801">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Early development of specific skills can help students succeed in fields like Science, Technology, Engineering and Mathematics. Different education standards consider “Collaboration” as a required and necessary skill that can help students excel in these fields. Instruction-based methods is the most common approach, adopted by teachers to instill collaborative skills. However, it is difficult for a single teacher to observe multiple student groups and provide constructive feedback to each student. With growing student population and limited teaching staff, this problem seems unlikely to go away. Development of machine-learning-based automated systems for student group collaboration assessment and feedback can help address this problem. Building upon our previous work, in this paper, we propose simple CNN deep-learning models that take in spatio-temporal representations of individual student roles and behavior annotations as input for group collaboration assessment. The trained classification models are further used to develop an automated recommendation system to provide individual-level or group-level feedback. The recommendation system suggests different roles each student in the group could have assumed that would facilitate better overall group collaboration. To the best of our knowledge, we are the first to develop such a feedback system. We also list the different challenges faced when working with the annotation data and describe the approaches we used to address those challenges.},
  archive      = {J_FCOMP},
  author       = {Som, Anirudh and Kim, Sujeong and Lopez-Prado, Bladimir and Dhamija, Svati and Alozie, Nonye and Tamrakar, Amir},
  doi          = {10.3389/fcomp.2021.728801},
  journal      = {Frontiers in Computer Science},
  month        = {10},
  pages        = {728801},
  shortjournal = {Front. Comput. Sci.},
  title        = {Automated student group collaboration assessment and recommendation system using individual role and behavioral cues},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Geodesic uncertainty in diffusion MRI. <em>FCOMP</em>,
<em>3</em>, 718131. (<a
href="https://doi.org/10.3389/fcomp.2021.718131">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study theoretical and operational issues of geodesic tractography, a geometric methodology for retrieving biologically plausible neural fibers in the brain from diffusion weighted magnetic resonance imaging. The premise is that true positives are geodesics in a suitably constructed metric space, but unlike traditional first order methods these are not a priori constrained to connect nongeneric points on subdimensional manifolds, such as the characteristics in traditional streamline methods. By virtue of the Hopf-Rinow theorem geodesic tractography furnishes a huge amount of redundancy, ensuring the a priori existence of at least one tentative fiber between any two points and permitting additional tractometric and data-extrinsic constraints for (fuzzy or crisp) classification of true and false positives. In our feasibility study we consider a hybrid paradigm that unifies existing ideas on tractography, combining deterministic and probabilistic elements in a way naturally supported by metric geometry. Particular attention is paid to an analytical prediction of geodesic deviation on numerically computed geodesics, a ‘tidal’ effect induced by small perturbations resulting from data noise. Taking these effects into account clarifies the inherent uncertainty of geodesics, while simultaneosuly offering a dimensionality reduction of the tractography problem.},
  archive      = {J_FCOMP},
  author       = {Sengers, Rick and Florack, Luc and Fuster, Andrea},
  doi          = {10.3389/fcomp.2021.718131},
  journal      = {Frontiers in Computer Science},
  month        = {10},
  pages        = {718131},
  shortjournal = {Front. Comput. Sci.},
  title        = {Geodesic uncertainty in diffusion MRI},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). XFinder: Detecting unknown anomalies in distributed machine
learning scenario. <em>FCOMP</em>, <em>3</em>, 710384. (<a
href="https://doi.org/10.3389/fcomp.2021.710384">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, the emergence of distributed machine learning has enabled deep learning models to ensure data security and privacy while training efficiently. Anomaly detection for network traffic in distributed machine learning scenarios is of great significance for network security. Although deep neural networks have made remarkable achievements in anomaly detection for network traffic, they mainly focus on closed sets, that is, assuming that all anomalies are known. However, in a real network environment, unknown abnormalities are fatal risks faced by the system because they have no labels and occur before the known anomalies. In this study, we design and implement XFinder, a dynamic unknown traffic anomaly detection framework in distributed machine learning. XFinder adopts an online mode to detect unknown anomalies in real-time. XFinder detects unknown anomalies by the unknowns detector, transfers the unknown anomalies to the prior knowledge base by the network updater, and adopts the online mode to report new anomalies in real-time. The experimental results show that the average accuracy of the unknown anomaly detection of our model is increased by 27% and the average F1-Score is improved by 20%. Compared with the offline mode, XFinder’s detection time is reduced by an average of approximately 33% on three datasets, and can better meet the network requirement.},
  archive      = {J_FCOMP},
  author       = {Du, Haizhou and Wang, Shiwei and Huo, Huan},
  doi          = {10.3389/fcomp.2021.710384},
  journal      = {Frontiers in Computer Science},
  month        = {10},
  pages        = {710384},
  shortjournal = {Front. Comput. Sci.},
  title        = {XFinder: Detecting unknown anomalies in distributed machine learning scenario},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Adventure mode: A speculative rideshare design.
<em>FCOMP</em>, <em>3</em>, 707081. (<a
href="https://doi.org/10.3389/fcomp.2021.707081">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most smart city projections presume efficiency, predictability, and control as core design principles for smart transportation. Adventure Mode is a speculative design proposal developed as part of a research project with a major automotive company that proposes uses and interactions for Autonomous Vehicles (AVs) and rideshare advancements that defy these normative presumptions. Adventure Mode reframes the focus of moving vehicles from destination-based experiences to journey-based ones. Adventure Mode pushes the probabilities for unexpected encounters and anonymous play in increasingly predictable and predicted urban environments. It embraces the submission to algorithmic decision and chance as a ludic modality in human-computer interactions and urban artificial intelligence.},
  archive      = {J_FCOMP},
  author       = {Sherman, Stephanie and Smith, Ash Eliza and Forster, Deborah and Emmenegger, Colleen},
  doi          = {10.3389/fcomp.2021.707081},
  journal      = {Frontiers in Computer Science},
  month        = {10},
  pages        = {707081},
  shortjournal = {Front. Comput. Sci.},
  title        = {Adventure mode: A speculative rideshare design},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). SimpleChartsRI: A user-friendly web-tool for creating
effective visualizations. <em>FCOMP</em>, <em>3</em>, 706939. (<a
href="https://doi.org/10.3389/fcomp.2021.706939">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data visualization tools can help teachers engage students who are visual learners. Current web-tools that focus on the creation of visualizations are not beginner-friendly and require little support for teachers wishing to implement visualizations into their classrooms. As a result, teachers rarely use visualization tools. This paper addresses the lack of visualization tool usage in classrooms, analyzes why this is based on previous research and current research we conducted, and offers potential focuses a visualization tool should have—through the lens of our own tool SimpleChartsRI—for pedagogical use. SimpleChartsRI aims to help high-school teachers create effective visualizations through a simple user-friendly interface that guides them on best practices.},
  archive      = {J_FCOMP},
  author       = {Matthew Michael, Spaulding and Khang, Sean and Sally, Hamouda},
  doi          = {10.3389/fcomp.2021.706939},
  journal      = {Frontiers in Computer Science},
  month        = {10},
  pages        = {706939},
  shortjournal = {Front. Comput. Sci.},
  title        = {SimpleChartsRI: A user-friendly web-tool for creating effective visualizations},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A deep audiovisual approach for human confidence
classification. <em>FCOMP</em>, <em>3</em>, 674533. (<a
href="https://doi.org/10.3389/fcomp.2021.674533">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Research on self-efficacy and confidence has spread across several subfields of psychology and neuroscience. The role of one’s confidence is very crucial in the formation of attitude and communication skills. The importance of differentiating the levels of confidence is quite visible in this domain. With the recent advances in extracting behavioral insight from a signal in multiple applications, detecting confidence is found to have great importance. One such prominent application is detecting confidence in interview conversations. We have collected an audiovisual data set of interview conversations with 34 candidates. Every response (from each of the candidate) of this data set is labeled with three levels of confidence: high, medium, and low. Furthermore, we have also developed algorithms to efficiently compute such behavioral confidence from speech and video. A deep learning architecture is proposed for detecting confidence levels (high, medium, and low) from an audiovisual clip recorded during an interview. The achieved unweighted average recall (UAR) reaches 85.9% on audio data and 73.6% on video data captured from an interview session.},
  archive      = {J_FCOMP},
  author       = {Chanda, Sushovan and Fitwe, Kedar and Deshpande, Gauri and Schuller, Björn W. and Patel, Sachin},
  doi          = {10.3389/fcomp.2021.674533},
  journal      = {Frontiers in Computer Science},
  month        = {10},
  pages        = {674533},
  shortjournal = {Front. Comput. Sci.},
  title        = {A deep audiovisual approach for human confidence classification},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Design and analysis of a collaborative story generation game
for social robots. <em>FCOMP</em>, <em>3</em>, 674333. (<a
href="https://doi.org/10.3389/fcomp.2021.674333">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Storytelling plays a central role in human socializing and entertainment, and research on conducting storytelling with robots is gaining interest. However, much of this research assumes that story content is curated. In this paper, we introduce the task of collaborative story generation, where an artificial intelligence agent, or a robot, and a person collaborate to create a unique story by taking turns adding to it. We present a collaborative story generation system which works with a human storyteller to create a story by generating new utterances based on the story so far. Our collaborative story generation system consists of a publicly-available large scale language model that was tuned on a dataset of writing prompts and short stories, and a ranker that samples from the language model and chooses the best possible output. We improve storytelling quality by optimizing the ranker’s sample size to strike a balance between quality and computational cost. Since latency can be detrimental to human-robot interaction, we examine the performance-latency trade-offs of our approach and find the optimal ranker sample size that strikes the best balance between quality and computational cost. We evaluate our system by having human participants play the collaborative story generation game and comparing the stories they create with our system to a naive baseline. Next, we conduct a detailed elicitation survey that sheds light on issues to consider when adapting our collaborative story generation system to a social robot. Finally, in a first step towards allowing human players to control the genre or mood of stories generated, we present preliminary work on steering story generation sentiment polarity with a sentiment analysis model. We find that our proposed method achieves a good balance of steering capability and text coherence. Our evaluation shows that participants have a positive view of collaborative story generation with a social robot and consider rich, emotive capabilities to be key to an enjoyable experience.},
  archive      = {J_FCOMP},
  author       = {Nichols, Eric and Gao, Leo and Vasylkiv, Yurii and Gomez, Randy},
  doi          = {10.3389/fcomp.2021.674333},
  journal      = {Frontiers in Computer Science},
  month        = {10},
  pages        = {674333},
  shortjournal = {Front. Comput. Sci.},
  title        = {Design and analysis of a collaborative story generation game for social robots},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Editorial: Uncertainty visualization and decision making.
<em>FCOMP</em>, <em>3</em>, 758406. (<a
href="https://doi.org/10.3389/fcomp.2021.758406">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FCOMP},
  author       = {Theron, Roberto and Padilla, Lace M.},
  doi          = {10.3389/fcomp.2021.758406},
  journal      = {Frontiers in Computer Science},
  month        = {9},
  pages        = {758406},
  shortjournal = {Front. Comput. Sci.},
  title        = {Editorial: Uncertainty visualization and decision making},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Three-year review of the 2018–2020 SHL challenge on
transportation and locomotion mode recognition from mobile sensors.
<em>FCOMP</em>, <em>3</em>, 713719. (<a
href="https://doi.org/10.3389/fcomp.2021.713719">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Sussex-Huawei Locomotion-Transportation (SHL) Recognition Challenges aim to advance and capture the state-of-the-art in locomotion and transportation mode recognition from smartphone motion (inertial) sensors. The goal of this series of machine learning and data science challenges was to recognize eight locomotion and transportation activities (Still, Walk, Run, Bus, Car, Train, Subway). The three challenges focused on time-independent (SHL 2018), position-independent (SHL 2019) and user-independent (SHL 2020) evaluations, respectively. Overall, we received 48 submissions (out of 93 teams who registered interest) involving 201 scientists over the three years. The survey captures the state-of-the-art through a meta-analysis of the contributions to the three challenges, including approaches, recognition performance, computational requirements, software tools and frameworks used. It was shown that state-of-the-art methods can distinguish with relative ease most modes of transportation, although the differentiating between subtly distinct activities, such as rail transport (Train and Subway) and road transport (Bus and Car) still remains challenging. We summarize insightful methods from participants that could be employed to address practical challenges of transportation mode recognition, for instance, to tackle over-fitting, to employ robust representations, to exploit data augmentation, and to exploit smart post-processing techniques to improve performance. Finally, we present baseline results to compare the three challenges with a unified recognition pipeline and decision window length.},
  archive      = {J_FCOMP},
  author       = {Wang, Lin and Gjoreski, Hristijan and Ciliberto, Mathias and Lago, Paula and Murao, Kazuya and Okita, Tsuyoshi and Roggen, Daniel},
  doi          = {10.3389/fcomp.2021.713719},
  journal      = {Frontiers in Computer Science},
  month        = {9},
  pages        = {713719},
  shortjournal = {Front. Comput. Sci.},
  title        = {Three-year review of the 2018–2020 SHL challenge on transportation and locomotion mode recognition from mobile sensors},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An analysis of personalized learning opportunities in 3D VR.
<em>FCOMP</em>, <em>3</em>, 673826. (<a
href="https://doi.org/10.3389/fcomp.2021.673826">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to its constantly developing technological background, VR and AR technology has been gaining increasing popularity not just in industry or business but in education as well. Research in the field of Cognitive Infocommunications (CogInfoCom) shows that using existing digital technologies, online collaboration and cooperation technologies in 3D VR supports cognitive processes, including the finding, processing, memorization and recalling of information. 3D VR environments are also capable of providing users with a much higher level of comprehension when it comes to sharing and interpreting digital workflows. The paper presents a study carried out with the participation of 90 students. The aim of this study is to investigate how the application of 3D VR platforms as personalized educational environments can also increase VR learning efficiency. Besides considering participants’ test performance, metrics such as results on visual, auditory and reading-based learning tests for information acquisition, as well as responses on Kolb’s learning styles questionnaires are taken into consideration. The participants’ learning styles, information acquisition habits were also observed, allowing us to create and offer a variety of learning pathways based on a variety of content types in the 3D VR environment. The students within the study were divided into two groups: a test group receiving personalized training in the MaxWhere 3D VR classroom, and a control group that studied in a general MaxWhere 3D VR space. This research applies both quantitative and qualitative methods to report findings. The goal was to create adaptive learning environments capable of deriving models of learners and providing personalized learning experiences. We studied the correlation between effectiveness of the tasks and Kolb’s learning styles. The study shows the major importance of choosing the optimal task type regarding each Kolb learning style and personalized learning environment. The MaxWhere 3D spaces show a high potential for personalizing VR education. The non-intrusive guiding capabilities of VR environments and of the educational content integrated in the 3D VR spaces were very successful, because the students were able to score 20 percent higher on the tests after studying in VR than after using traditional educational tools. Students also performed the same tasks with 8-10 percent faster response times.},
  archive      = {J_FCOMP},
  author       = {Horváth, Ildikó},
  doi          = {10.3389/fcomp.2021.673826},
  journal      = {Frontiers in Computer Science},
  month        = {9},
  pages        = {673826},
  shortjournal = {Front. Comput. Sci.},
  title        = {An analysis of personalized learning opportunities in 3D VR},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Understanding the experiences of remote workers:
Opportunities for ambient workspaces at home. <em>FCOMP</em>,
<em>3</em>, 673585. (<a
href="https://doi.org/10.3389/fcomp.2021.673585">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the COVID-19 pandemic has forced many to work remotely from home, collaborating solely through digital technologies, a growing population of remote home workers are faced with profound wellbeing challenges. Passive sensing devices and ambient feedback have great potential to support the wellbeing of the remote workers, but there is a lack of background and understanding of the domestic workplace in terms of physical and affective dimensions and challenges to wellbeing. There are profound research gaps on wellbeing in the domestic workplace, with the current push for remote home and hybrid working making this topic timely. To address these gaps and shape a starting point for an “ambient workspaces” agenda, we conducted an exploratory study to map physical and affective aspects of working from home. The study involved both qualitative and quantitative measures of occupant experience, including sensor wristbands, and a custom web application for self-reporting mood and aspects of the environment. It included 13 participants for a period of 4 weeks, during a period of exclusive home working. Based on quantitative and qualitative analysis, our study addresses wellbeing challenges of the domestic workplace, establishes correlations between mood and physical aspects, and discusses the impact of feedback mechanisms in the domestic workplace on the behavior of remote workers. Insights from these observations are then used to inform a future design agenda for ambient technologies that supports the wellbeing of remote workers; addressing the design opportunities for ambient interventions in domestic workspaces. This work offers three contributions: 1) qualitatively and quantitatively informed understandings of the experiences of home-workers; 2) a future design agenda for “ambient home workspaces”; and 3) we propose three design concepts for ambient feedback and human–AI interactions in the built environment, to illustrate the utility of the design agenda.},
  archive      = {J_FCOMP},
  author       = {Margariti, Eleni Kallopi and Ali, Ridita and Benthem de Grave, Remco and Verweij, David and Smeddinck, Jan and Kirk, David},
  doi          = {10.3389/fcomp.2021.673585},
  journal      = {Frontiers in Computer Science},
  month        = {9},
  pages        = {673585},
  shortjournal = {Front. Comput. Sci.},
  title        = {Understanding the experiences of remote workers: Opportunities for ambient workspaces at home},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Discovering key topics from short, real-world medical
inquiries via natural language processing. <em>FCOMP</em>, <em>3</em>,
672867. (<a href="https://doi.org/10.3389/fcomp.2021.672867">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Millions of unsolicited medical inquiries are received by pharmaceutical companies every year. It has been hypothesized that these inquiries represent a treasure trove of information, potentially giving insight into matters regarding medicinal products and the associated medical treatments. However, due to the large volume and specialized nature of the inquiries, it is difficult to perform timely, recurrent, and comprehensive analyses. Here, we combine biomedical word embeddings, non-linear dimensionality reduction, and hierarchical clustering to automatically discover key topics in real-world medical inquiries from customers. This approach does not require ontologies nor annotations. The discovered topics are meaningful and medically relevant, as judged by medical information specialists, thus demonstrating that unsolicited medical inquiries are a source of valuable customer insights. Our work paves the way for the machine-learning-driven analysis of medical inquiries in the pharmaceutical industry, which ultimately aims at improving patient care.},
  archive      = {J_FCOMP},
  author       = {Ziletti, A. and Berns, C. and Treichel, O. and Weber, T. and Liang, J. and Kammerath, S. and Schwaerzler, M. and Virayah, J. and Ruau, D. and Ma, X. and Mattern, A.},
  doi          = {10.3389/fcomp.2021.672867},
  journal      = {Frontiers in Computer Science},
  month        = {9},
  pages        = {672867},
  shortjournal = {Front. Comput. Sci.},
  title        = {Discovering key topics from short, real-world medical inquiries via natural language processing},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Simulation agent-based model to demonstrate the transmission
of COVID-19 and effectiveness of different public health strategies.
<em>FCOMP</em>, <em>3</em>, 642321. (<a
href="https://doi.org/10.3389/fcomp.2021.642321">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {COVID-19 has changed the world fundamentally since its outbreak in January 2020. Public health experts and administrations around the world suggested and implemented various intervention strategies to slow down the transmission of the virus. To illustrate to the general public how the virus is transmitted and how different intervention strategies can check the transmission, we built an agent-based model (ABM) to simulate the transmission of the virus in the real world and demonstrate how to prevent its spread with public health strategies.},
  archive      = {J_FCOMP},
  author       = {Wang, Yixing and Xiong, Hainan and Liu, Sijie and Jung, Ara and Stone, Trish and Chukoskie, Leanne},
  doi          = {10.3389/fcomp.2021.642321},
  journal      = {Frontiers in Computer Science},
  month        = {9},
  pages        = {642321},
  shortjournal = {Front. Comput. Sci.},
  title        = {Simulation agent-based model to demonstrate the transmission of COVID-19 and effectiveness of different public health strategies},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Robot concept acquisition based on interaction between
probabilistic and deep generative models. <em>FCOMP</em>, <em>3</em>,
618069. (<a href="https://doi.org/10.3389/fcomp.2021.618069">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a method for multimodal concept formation. In this method, unsupervised multimodal clustering and cross-modal inference, as well as unsupervised representation learning, can be performed by integrating the multimodal latent Dirichlet allocation (MLDA)-based concept formation and variational autoencoder (VAE)-based feature extraction. Multimodal clustering, representation learning, and cross-modal inference are critical for robots to form multimodal concepts from sensory data. Various models have been proposed for concept formation. However, in previous studies, features were extracted using manually designed or pre-trained feature extractors and representation learning was not performed simultaneously. Moreover, the generative probabilities of the features extracted from the sensory data could be predicted, but the sensory data could not be predicted in the cross-modal inference. Therefore, a method that can perform clustering, feature learning, and cross-modal inference among multimodal sensory data is required for concept formation. To realize such a method, we extend the VAE to the multinomial VAE (MNVAE), the latent variables of which follow a multinomial distribution, and construct a model that integrates the MNVAE and MLDA. In the experiments, the multimodal information of the images and words acquired by a robot was classified using the integrated model. The results demonstrated that the integrated model can classify the multimodal information as accurately as the previous model despite the feature extractor learning in an unsupervised manner, suitable image features for clustering can be learned, and cross-modal inference from the words to images is possible.},
  archive      = {J_FCOMP},
  author       = {Kuniyasu, Ryo and Nakamura, Tomoaki and Taniguchi, Tadahiro and Nagai, Takayuki},
  doi          = {10.3389/fcomp.2021.618069},
  journal      = {Frontiers in Computer Science},
  month        = {9},
  pages        = {618069},
  shortjournal = {Front. Comput. Sci.},
  title        = {Robot concept acquisition based on interaction between probabilistic and deep generative models},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Impossible (food) experiences in extended reality.
<em>FCOMP</em>, <em>3</em>, 716846. (<a
href="https://doi.org/10.3389/fcomp.2021.716846">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce a model to think about impossible experiences in mixed and virtual reality, while emphasizing the role of said experiences in the context of food. This reality-impossibility model includes two continua, namely, the reality-fantasy character of objects and environments, and the extent to which they follow the laws of physics-other laws. We present a series of examples in each of the quadrants of the model and discuss both the research possibilities and implications of impossible experiences.},
  archive      = {J_FCOMP},
  author       = {Velasco, Carlos and Barbosa Escobar, Francisco and Petit, Olivia and Wang, Qian Janice},
  doi          = {10.3389/fcomp.2021.716846},
  journal      = {Frontiers in Computer Science},
  month        = {8},
  pages        = {716846},
  shortjournal = {Front. Comput. Sci.},
  title        = {Impossible (Food) experiences in extended reality},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Interactive urban play to encourage active mobility:
Usability study of a web-based augmented reality application.
<em>FCOMP</em>, <em>3</em>, 706162. (<a
href="https://doi.org/10.3389/fcomp.2021.706162">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Owing to increasing cases of sedentary lifestyles and their negative impact on health, practical solutions are needed to address the physical and mental wellbeing of citizens and to enhance their standard of living. Among the problems are premature mortality rates caused by physical inactivity, which leads to chronic diseases. Innovative solutions are needed to address many of the problems that we face as a society. Location-based games have been identified as effective solutions for increasing physical activity, enhancing social interaction, and exploration in urban environments. In this pilot study, we explore how to encourage active mobility (walking and cycling) through urban play by integrating technology into the built environment. We examined the usability of a web-based augmented reality application in providing interactive experience to users as they explored the urban environment looking for tasks. Overall, participants’ perceptions of the usability of the application were positive; they enjoyed how the application revealed the tasks at each location and all the checkpoints at the different locations had at least a couple of visitors. We present limitations and future research directions.},
  archive      = {J_FCOMP},
  author       = {Oduor, Michael and Perälä, Timo},
  doi          = {10.3389/fcomp.2021.706162},
  journal      = {Frontiers in Computer Science},
  month        = {8},
  pages        = {706162},
  shortjournal = {Front. Comput. Sci.},
  title        = {Interactive urban play to encourage active mobility: Usability study of a web-based augmented reality application},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Effect of user personality on efficacy of a mental support
system based on ambient intelligence: A case study. <em>FCOMP</em>,
<em>3</em>, 702069. (<a
href="https://doi.org/10.3389/fcomp.2021.702069">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One solution supporting a healthy mental state for humans is controlling the environment with ambient intelligence technology. We are developing a mental support system for healthy people that automatically changes environmental conditions, such as sound volume and light color, depending on the user’s mental state, which is monitored according to physiological signals such as sympathetic nerve activity. In our previous basic study under laboratory-controlled conditions, the system was applied to improve the user’s concentration level as they performed calculation tasks. Results indicated that the system improved the task performance, but individual variations existed, with some users improving greatly but others much less. For the future practical application of the system, determining the causes of the variation in efficacy is important. Considering that the brain structure and activity differ according to an individual’s personality, we investigated the relationship between the user’s personality and task performance with our system’s support. The results showed a clear correlation between the extraversion score and task performance. Our study presents an example where the system’s efficacy is sensitive to the user’s personality and indicates the importance of considering the user’s personality when designing a mental support system based on ambient intelligence.},
  archive      = {J_FCOMP},
  author       = {Iwashita, Motoko and Ishida, Kenji and Ishikawa, Makiko},
  doi          = {10.3389/fcomp.2021.702069},
  journal      = {Frontiers in Computer Science},
  month        = {8},
  pages        = {702069},
  shortjournal = {Front. Comput. Sci.},
  title        = {Effect of user personality on efficacy of a mental support system based on ambient intelligence: A case study},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Adaptation mechanisms in human–agent interaction: Effects on
user’s impressions and engagement. <em>FCOMP</em>, <em>3</em>, 696682.
(<a href="https://doi.org/10.3389/fcomp.2021.696682">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Adaptation is a key mechanism in human–human interaction. In our work, we aim at endowing embodied conversational agents with the ability to adapt their behavior when interacting with a human interlocutor. With the goal to better understand what the main challenges concerning adaptive agents are, we investigated the effects on the user’s experience of three adaptation models for a virtual agent. The adaptation mechanisms performed by the agent take into account the user’s reaction and learn how to adapt on the fly during the interaction. The agent’s adaptation is realized at several levels (i.e., at the behavioral, conversational, and signal levels) and focuses on improving the user’s experience along different dimensions (i.e., the user’s impressions and engagement). In our first two studies, we aim to learn the agent’s multimodal behaviors and conversational strategies to dynamically optimize the user’s engagement and impressions of the agent, by taking them as input during the learning process. In our third study, our model takes both the user’s and the agent’s past behavior as input and predicts the agent’s next behavior. Our adaptation models have been evaluated through experimental studies sharing the same interacting scenario, with the agent playing the role of a virtual museum guide. These studies showed the impact of the adaptation mechanisms on the user’s experience of the interaction and their perception of the agent. Interacting with an adaptive agent vs. a nonadaptive agent tended to be more positively perceived. Finally, the effects of people’s a priori about virtual agents found in our studies highlight the importance of taking into account the user’s expectancies in human–agent interaction.},
  archive      = {J_FCOMP},
  author       = {Biancardi, Beatrice and Dermouche, Soumia and Pelachaud, Catherine},
  doi          = {10.3389/fcomp.2021.696682},
  journal      = {Frontiers in Computer Science},
  month        = {8},
  pages        = {696682},
  shortjournal = {Front. Comput. Sci.},
  title        = {Adaptation mechanisms in Human–Agent interaction: Effects on user’s impressions and engagement},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Embodiment and performance in the supernumerary hand
illusion in augmented reality. <em>FCOMP</em>, <em>3</em>, 694916. (<a
href="https://doi.org/10.3389/fcomp.2021.694916">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In teleoperations, robots are generally used because related tasks are too dangerous, uncomfortable or impossible for humans to perform. When using augmented reality to control robotic limbs in such teleoperations, it is essential to understand how these extra virtual limbs are experienced. In particular, the relationship between the embodiment experience of the user and relevant outcomes such as task performance must be examined. In this article, we study the relationship between experienced embodiment of a supernumerary virtual arm that acts alongside a user’s two real arms, and their task performance in augmented reality. Specifically, we compare how well users can trace a virtual half ring placed just outside of personal space using their virtual arm in a condition where there is expected to be low embodiment (a floating disconnected hand) and a condition where there is expected to be high embodiment (a connected arm and hand). Embodiment is measured quantitatively through skin conductance response and qualitatively through ownership, agency, and self-location questionnaires. Performance is measured in terms of tracing precision. The results show positive correlations between subjective ownership and agency, and agency and performance, but no correlation between subjective or objective ownership and performance. Also, ownership ratings were low overall, while the agency ratings were significantly higher for the disconnected hand condition than the connected arm condition, as was performance. Notably, the presence of the virtual arm evoked incorrect expectations of the movement capabilities of the arm, which may have contributed to an overall preference for the unrealistic disconnected hand over the more realistic connected arm in this particular task. Our results imply that methods to increase performance in various teleoperations can indeed be found in the experience of embodiment: not necessarily directly through ownership, but through ownership mediated by agency.},
  archive      = {J_FCOMP},
  author       = {Rosa, Nina and Veltkamp, Remco C. and Hürst, Wolfgang and Brouwer, Anne-Marie and Gijsbertse, Kaj and Cocu, Ioana and Werkhoven, Peter},
  doi          = {10.3389/fcomp.2021.694916},
  journal      = {Frontiers in Computer Science},
  month        = {8},
  pages        = {694916},
  shortjournal = {Front. Comput. Sci.},
  title        = {Embodiment and performance in the supernumerary hand illusion in augmented reality},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Respecting human autonomy in critical care clinical decision
support. <em>FCOMP</em>, <em>3</em>, 690576. (<a
href="https://doi.org/10.3389/fcomp.2021.690576">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Clinical Decision Support (CDS) aims at helping physicians optimize their decisions. However, as each patient is unique in their characteristics and preferences, it is difficult to define the optimal outcome. Human physicians should retain autonomy over their decisions, to ensure that tradeoffs are made in a way that fits the unique patient. We tend to consider autonomy in the sense of not influencing decision-making. However, as CDS aims to improve decision-making, its very aim is to influence decision-making. We advocate for an alternative notion of autonomy as enabling the physician to make decisions in accordance with their professional goals and values and the goals and values of the patient. This perspective retains the role of autonomy as a gatekeeper for safeguarding other human values, while letting go of the idea that CDS should not influence the physician in any way. Rather than trying to refrain from incorporating human values into CDS, we should instead aim for a value-aware CDS that actively supports the physician in considering tradeoffs in human values. We suggest a conversational AI approach to enable the CDS to become value-aware and the use of story structures to help the user integrate facts and data-driven learnings provided by the CDS with their own value judgements in a natural way.},
  archive      = {J_FCOMP},
  author       = {Hendriks, Monique and Willemsen, Martijn C. and Sartor, Francesco and Hoonhout, Jettie},
  doi          = {10.3389/fcomp.2021.690576},
  journal      = {Frontiers in Computer Science},
  month        = {8},
  pages        = {690576},
  shortjournal = {Front. Comput. Sci.},
  title        = {Respecting human autonomy in critical care clinical decision support},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Development of an instrument to measure conceptualizations
and competencies about conversational agents on the example of smart
speakers. <em>FCOMP</em>, <em>3</em>, 685277. (<a
href="https://doi.org/10.3389/fcomp.2021.685277">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The concept of digital literacy has been introduced as a new cultural technique, which is regarded as essential for successful participation in a (future) digitized world. Regarding the increasing importance of AI, literacy concepts need to be extended to account for AI-related specifics. The easy handling of the systems results in increased usage, contrasting limited conceptualizations (e.g., imagination of future importance) and competencies (e.g., knowledge about functional principles). In reference to voice-based conversational agents as a concrete application of AI, the present paper aims for the development of a measurement to assess the conceptualizations and competencies about conversational agents. In a first step, a theoretical framework of “AI literacy” is transferred to the context of conversational agent literacy. Second, the “conversational agent literacy scale” (short CALS) is developed, constituting the first attempt to measure interindividual differences in the “(il) literate” usage of conversational agents. 29 items were derived, of which 170 participants answered. An explanatory factor analysis identified five factors leading to five subscales to assess CAL: storage and transfer of the smart speaker’s data input; smart speaker’s functional principles; smart speaker’s intelligent functions, learning abilities; smart speaker’s reach and potential; smart speaker’s technological (surrounding) infrastructure. Preliminary insights into construct validity and reliability of CALS showed satisfying results. Third, using the newly developed instrument, a student sample’s CAL was assessed, revealing intermediated values. Remarkably, owning a smart speaker did not lead to higher CAL scores, confirming our basic assumption that usage of systems does not guarantee enlightened conceptualizations and competencies. In sum, the paper contributes to the first insights into the operationalization and understanding of CAL as a specific subdomain of AI-related competencies.},
  archive      = {J_FCOMP},
  author       = {Wienrich, Carolin and Carolus, Astrid},
  doi          = {10.3389/fcomp.2021.685277},
  journal      = {Frontiers in Computer Science},
  month        = {8},
  pages        = {685277},
  shortjournal = {Front. Comput. Sci.},
  title        = {Development of an instrument to measure conceptualizations and competencies about conversational agents on the example of smart speakers},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi_scale_tools: A python library to exploit multi-scale
whole slide images. <em>FCOMP</em>, <em>3</em>, 684521. (<a
href="https://doi.org/10.3389/fcomp.2021.684521">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Algorithms proposed in computational pathology can allow to automatically analyze digitized tissue samples of histopathological images to help diagnosing diseases. Tissue samples are scanned at a high-resolution and usually saved as images with several magnification levels, namely whole slide images (WSIs). Convolutional neural networks (CNNs) represent the state-of-the-art computer vision methods targeting the analysis of histopathology images, aiming for detection, classification and segmentation. However, the development of CNNs that work with multi-scale images such as WSIs is still an open challenge. The image characteristics and the CNN properties impose architecture designs that are not trivial. Therefore, single scale CNN architectures are still often used. This paper presents Multi_Scale_Tools, a library aiming to facilitate exploiting the multi-scale structure of WSIs. Multi_Scale_Tools currently include four components: a pre-processing component, a scale detector, a multi-scale CNN for classification and a multi-scale CNN for segmentation of the images. The pre-processing component includes methods to extract patches at several magnification levels. The scale detector allows to identify the magnification level of images that do not contain this information, such as images from the scientific literature. The multi-scale CNNs are trained combining features and predictions that originate from different magnification levels. The components are developed using private datasets, including colon and breast cancer tissue samples. They are tested on private and public external data sources, such as The Cancer Genome Atlas (TCGA). The results of the library demonstrate its effectiveness and applicability. The scale detector accurately predicts multiple levels of image magnification and generalizes well to independent external data. The multi-scale CNNs outperform the single-magnification CNN for both classification and segmentation tasks. The code is developed in Python and it will be made publicly available upon publication. It aims to be easy to use and easy to be improved with additional functions.},
  archive      = {J_FCOMP},
  author       = {Marini, Niccolò and Otálora, Sebastian and Podareanu, Damian and van Rijthoven, Mart and van der Laak, Jeroen and Ciompi, Francesco and Müller, Henning and Atzori, Manfredo},
  doi          = {10.3389/fcomp.2021.684521},
  journal      = {Frontiers in Computer Science},
  month        = {8},
  pages        = {684521},
  shortjournal = {Front. Comput. Sci.},
  title        = {Multi_Scale_Tools: A python library to exploit multi-scale whole slide images},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Readability enhancement for PDF documents. <em>FCOMP</em>,
<em>3</em>, 628832. (<a
href="https://doi.org/10.3389/fcomp.2021.628832">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Readability has been studied for decades, ranging from traditional paper reading to digital document reading, Web page reading, etc. Different audiences have different needs and the needs trigger the researchers to investigate innovative solutions. For example, in recent years, researchers have studied readability enhancement of English articles for non-native English readers, either on paper reading or hypertext document reading. Using a variety of methods, researchers were able to enhance the reading comprehension and the users’ satisfaction on hypertext document reading, such as changing content presentation with visual-syntactic text formatting (VSTF) format or Jenga format. In terms of dynamically changing content presentation for reading, one less explored format is Portable Document Format (PDF), which was traditionally viewed within a modern Web browser or Adobe Acrobat reader on the desktop. PDF format was standardized as an open format in 2008 and has been widely used to keep a fixed-layout content. However, a fixed layout document presents a challenge to apply existing transformation methods, not mention on mobile devices. In this paper, we not only present a system that uses a novel algorithm to decode PDF documents and apply content transformation to enhance its readability, but we also generalize it to a framework that allows the users to apply customizations and the developers to customize their needs. Although we used Jenga format as an example to enhance the readability of PDF documents, we envision the proposed framework can be used to adopt different customizations and transformation methods. The current result is promising, and we believe it is worth further investigation to make PDF documents readable and accessible for different populations, such as non-native English readers, people with dyslexia or special needs, etc.},
  archive      = {J_FCOMP},
  author       = {Yu, Chen-Hsiang and Shelton, Zachary and Abou Nassif Mourad, Omar and Oulal, Mohamed A.},
  doi          = {10.3389/fcomp.2021.628832},
  journal      = {Frontiers in Computer Science},
  month        = {8},
  pages        = {628832},
  shortjournal = {Front. Comput. Sci.},
  title        = {Readability enhancement for PDF documents},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Application-aware intrusion detection: A systematic
literature review, implications for automotive systems, and
applicability of AutoML. <em>FCOMP</em>, <em>3</em>, 567873. (<a
href="https://doi.org/10.3389/fcomp.2021.567873">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modern and flexible application-level software platforms increase the attack surface of connected vehicles and thereby require automotive engineers to adopt additional security control techniques. These techniques encompass host-based intrusion detection systems (HIDSs) that detect suspicious activities in application contexts. Such application-aware HIDSs originate in information and communications technology systems and have a great potential to deal with the flexible nature of application-level software platforms. However, the elementary characteristics of known application-aware HIDS approaches and thereby the implications for their transfer to the automotive sector are unclear. In previous work, we presented a systematic literature review (SLR) covering the state of the art of application-aware HIDS approaches. We synthesized our findings by means of a fine-grained classification for each approach specified through a feature model and corresponding variant models. These models represent the approaches’ elementary characteristics. Furthermore, we summarized key findings and inferred implications for the transfer of application-aware HIDSs to the automotive sector. In this article, we extend the previous work by several aspects. We adjust the quality evaluation process within the SLR to be able to consider high quality conference publications, which results in an extended final pool of publications. For supporting HIDS developers on the task of configuring HIDS analysis techniques based on machine learning, we report on initial results on the applicability of AutoML. Furthermore, we present lessons learned regarding the application of the feature and variant model approach for SLRs. Finally, we more thoroughly describe the SLR study design.},
  archive      = {J_FCOMP},
  author       = {Schubert, David and Eikerling , Hendrik and Holtmann , Jörg},
  doi          = {10.3389/fcomp.2021.567873},
  journal      = {Frontiers in Computer Science},
  month        = {8},
  pages        = {567873},
  shortjournal = {Front. Comput. Sci.},
  title        = {Application-aware intrusion detection: A systematic literature review, implications for automotive systems, and applicability of AutoML},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Digital scientist 2035—an outlook on innovation and
education. <em>FCOMP</em>, <em>3</em>, 710972. (<a
href="https://doi.org/10.3389/fcomp.2021.710972">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the advent of the fourth industrial revolution accompanied by the Internet of Things, the implementation of smart technologies and digitalization already had a great impact in our society, especially when considering exponential innovation and human development. In this context, some types of employment have already been replaced or have been enhanced by the use of robots, human-machines interfaces and Artificial Intelligence systems. And there is likely more to come. If innovation can be viewed as a direct or indirect outcome of scientific research, which role will a scientist play in 2035? We developed a survey to investigate the opinions of scientists with respect to the possible future implementation of disruptive technologies, their feelings and approaches to digitalization, and particularly the impact of digital transformation on scientific education. In a futuristic scenario, we can imagine that scientists will be supported by technologies, carrying out numerous experiments, managing big datasets, producing accurate results, increasing communication, openness and collaboration among the worldwide scientific community, where ethics, regulations and social norms will always be observed. The new era of Digital Science is coming, in which humans will start to incorporate more disruptive and advanced technologies into their daily life; essential aspects for exponential innovation and development.},
  archive      = {J_FCOMP},
  author       = {Barbazzeni, Beatrice and Friebe, Michael},
  doi          = {10.3389/fcomp.2021.710972},
  journal      = {Frontiers in Computer Science},
  month        = {7},
  pages        = {710972},
  shortjournal = {Front. Comput. Sci.},
  title        = {Digital scientist 2035—An outlook on innovation and education},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The brain-as-computer metaphor. <em>FCOMP</em>, <em>3</em>,
681416. (<a href="https://doi.org/10.3389/fcomp.2021.681416">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FCOMP},
  author       = {Davis, Martin},
  doi          = {10.3389/fcomp.2021.681416},
  journal      = {Frontiers in Computer Science},
  month        = {7},
  pages        = {681416},
  shortjournal = {Front. Comput. Sci.},
  title        = {The brain-as-computer metaphor},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). What sort of robots do we want to interact with? Reflecting
on the human side of human-artificial intelligence interaction.
<em>FCOMP</em>, <em>3</em>, 671012. (<a
href="https://doi.org/10.3389/fcomp.2021.671012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FCOMP},
  author       = {Hildt, Elisabeth},
  doi          = {10.3389/fcomp.2021.671012},
  journal      = {Frontiers in Computer Science},
  month        = {7},
  pages        = {671012},
  shortjournal = {Front. Comput. Sci.},
  title        = {What sort of robots do we want to interact with? reflecting on the human side of human-artificial intelligence interaction},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A canonical set of operations for editing dashboard layouts
in virtual reality. <em>FCOMP</em>, <em>3</em>, 659600. (<a
href="https://doi.org/10.3389/fcomp.2021.659600">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Virtual reality (VR) is a powerful technological framework that can be considered as comprising any kind of device that allows for 3D environments to be simulated and interacted with via a digital interface. Depending on the specific technologies used, VR can allow users to experience a virtual world through their different senses, i.e., most often sight, but also through touch, hearing, and smell. In this paper, it is argued that a key impediment to the widespread adoption of VR technology today is the lack of interoperability between users’’ existing digital life (including 2D documents, videos, the Web, and even mobile applications) and the 3D spaces. Without such interoperability, 3D spaces offered by current VR platforms seem empty and lacking in functionality. In order to improve this situation, it is suggested that users could benefit from being able to create dashboard layouts (comprising 2D displays) for themselves in the 3D spaces, allowing them to arrange, view and interact with their existing 2D content alongside the 3D objects. Therefore, the objective of this research is to help users organize and arrange 2D content in 3D spaces depending on their needs. To this end, following a discussion on why this is a challenging problem—both from a scientific and from a practical perspective—a set of operations are proposed that are meant to be minimal and canonical and enable the creation of dashboard layouts in 3D. Based on a reference implementation on the MaxWhere VR platform, a set of experiments were carried out to measure how much time users needed to recreate existing layouts inside an empty version of the corresponding 3D spaces, and the precision with which they could do so. Results showed that users were able to carry out this task, on average, at a rate of less than 45 s per 2D display at an acceptably high precision.},
  archive      = {J_FCOMP},
  author       = {Setti, Tarek and Csapo, Adam B.},
  doi          = {10.3389/fcomp.2021.659600},
  journal      = {Frontiers in Computer Science},
  month        = {7},
  pages        = {659600},
  shortjournal = {Front. Comput. Sci.},
  title        = {A canonical set of operations for editing dashboard layouts in virtual reality},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Visual continuity of protein secondary structure rendering:
Application to SARS-CoV-2 mpro in virtual reality. <em>FCOMP</em>,
<em>3</em>, 642172. (<a
href="https://doi.org/10.3389/fcomp.2021.642172">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ribbon diagrams are important for protein visualization, used to convey the secondary structure in a clear and concise manner. However, most algorithms used to generate these diagrams do not maintain visual continuity when viewing a molecular trajectory, with certain sections of ribbons flipping between clockwise and counterclockwise twists. Here we outline a new method which prevents this artifact by morphing between consecutive cross sections instead of rotating. This yields diagrams which are well suited for viewing dynamic simulations, such as those used for interactive molecular dynamics. We illustrate the utility of this algorithm by using it to visualize iMD-VR (interactive molecular dynamics in virtual reality) simulations of the secondary structure of the SARS-CoV-2 main protease (Mpro), which is being investigated as a potential target for COVID drug therapies.},
  archive      = {J_FCOMP},
  author       = {Jamieson-Binnie, Alexander D. and Glowacki, David R.},
  doi          = {10.3389/fcomp.2021.642172},
  journal      = {Frontiers in Computer Science},
  month        = {7},
  pages        = {642172},
  shortjournal = {Front. Comput. Sci.},
  title        = {Visual continuity of protein secondary structure rendering: Application to SARS-CoV-2 mpro in virtual reality},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Catch the bus: Probing other-than-human perspectives in
design research. <em>FCOMP</em>, <em>3</em>, 636107. (<a
href="https://doi.org/10.3389/fcomp.2021.636107">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Prompted by Catch the Bus, an experimental street game design project with and for autonomous buses, this study explores strategies to substantiate the speculation about other-than-human perspectives. It builds on philosophical arguments about the role of species similarity in grasping nonhuman experience and applies these arguments to thing perspectives. Gameplay and props from Catch the Bus instantiate a kind of similarity between human players and autonomous buses that emerges through the adoption of certain choreographies and sensing capabilities. The study contributes theoretical arguments to the debate of other-than-human perspectives in more-than-human design.},
  archive      = {J_FCOMP},
  author       = {Bedö, Viktor},
  doi          = {10.3389/fcomp.2021.636107},
  journal      = {Frontiers in Computer Science},
  month        = {7},
  pages        = {636107},
  shortjournal = {Front. Comput. Sci.},
  title        = {Catch the bus: Probing other-than-human perspectives in design research},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Evaluation of user experience, cognitive load, and training
performance of a gamified cognitive training application for children
with learning disabilities. <em>FCOMP</em>, <em>3</em>, 617056. (<a
href="https://doi.org/10.3389/fcomp.2021.617056">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study presents a gamified application for children with learning disabilities, designed to train and improve their working memory capacity. The application takes the form of a treasure hunt and is designed according to a framework incorporating a set of guidelines derived from accessibility, usability, and cognitive load theory principles, and from gamification techniques. The aim is to motivate and engage the children in working memory-training activities and exploit their working memory capacity. The main focus of this study is the evaluation of the cognitive load level induced by the application, the children’s perceived experience, and their training performance over the training period. A sample of 12 Egyptian children with learning disabilities completed a five-week training period using the application, followed by an evaluation process. The evaluation took the form of a simple usability survey, an unstructured observation, and a cognitive load measurement scale. The purpose was to evaluate the children’s perceived experience, assess the level of cognitive load experienced in each of the activities, and measure the expected improvement in the children’s training performance. The results revealed that all the children enjoyed playing the gamified application, were eager to participate in the daily training, and the cognitive load experienced during the training was found to be generally appropriate, although some areas for improvement were identified. Finally, the children’s training performance and their perceived experience were better in the gamified activities with a lower cognitive load level.},
  archive      = {J_FCOMP},
  author       = {Shaban, Adel and Pearson, Elaine and Chang, Victor},
  doi          = {10.3389/fcomp.2021.617056},
  journal      = {Frontiers in Computer Science},
  month        = {7},
  pages        = {617056},
  shortjournal = {Front. Comput. Sci.},
  title        = {Evaluation of user experience, cognitive load, and training performance of a gamified cognitive training application for children with learning disabilities},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Spine and individual vertebrae segmentation in computed
tomography images using geometric flows and shape priors.
<em>FCOMP</em>, <em>3</em>, 592296. (<a
href="https://doi.org/10.3389/fcomp.2021.592296">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The surgical treatment of injuries to the spine often requires the placement of pedicle screws. To prevent damage to nearby blood vessels and nerves, the individual vertebrae and their surrounding tissue must be precisely localized. To aid surgical planning in this context we present a clinically applicable geometric flow based method to segment the human spinal column from computed tomography (CT) scans. We first apply anisotropic diffusion and flux computation to mitigate the effects of region inhomogeneities and partial volume effects at vertebral boundaries in such data. The first pipeline of our segmentation approach uses a region-based geometric flow, requires only a single manually identified seed point to initiate, and runs efficiently on a multi-core central processing unit (CPU). A shape-prior formulation is employed in a separate second pipeline to segment individual vertebrae, using both region and boundary based terms to augment the initial segmentation. We validate our method on four different clinical databases, each of which has a distinct intensity distribution. Our approach obviates the need for manual segmentation, significantly reduces inter- and intra-observer differences, runs in times compatible with use in a clinical workflow, achieves Dice scores that are comparable to the state of the art, and yields precise vertebral surfaces that are well within the acceptable 2 mm mark for surgical interventions.},
  archive      = {J_FCOMP},
  author       = {Khandelwal, Pulkit and Collins, D. Louis and Siddiqi, Kaleem},
  doi          = {10.3389/fcomp.2021.592296},
  journal      = {Frontiers in Computer Science},
  month        = {7},
  pages        = {592296},
  shortjournal = {Front. Comput. Sci.},
  title        = {Spine and individual vertebrae segmentation in computed tomography images using geometric flows and shape priors},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Security efficiency maximization for multi-UAV–aided network
with mobile edge computing. <em>FCOMP</em>, <em>3</em>, 691854. (<a
href="https://doi.org/10.3389/fcomp.2021.691854">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, we consider a security efficiency maximization problem in a multiple unmanned aerial vehicle (UAV)-aided system with mobile edge computing (MEC). Two kinds of UAVs, including multiple computing UAVs (CUAVs) and multiple jamming UAVs (JUAVs), are considered in this system. CUAVs would receive partial computation bits and send the computation results to ground users. JUAVs do not undertake computing tasks and only send interference signals to counter potential ground eavesdroppers. We jointly optimize the ground user scheduling, UAV power, and UAV trajectory to maximize the security efficiency. The original problem is non-convex and difficult to solve. We first use the Dinkelbach method combined with continuous convex approximation technology, and then propose three corresponding subproblems, including user scheduling subproblem, UAV power subproblem, and UAV trajectory problem. Further, we apply the branch and bound method to solve the user scheduling subproblem, and optimize the two remaining subproblems by introducing auxiliary variables and Taylor expansion. The simulation results show that the proposed scheme can obtain better secure off-loading efficiency with respect to the existing schemes.},
  archive      = {J_FCOMP},
  author       = {Mu, Guangchen},
  doi          = {10.3389/fcomp.2021.691854},
  journal      = {Frontiers in Computer Science},
  month        = {6},
  pages        = {691854},
  shortjournal = {Front. Comput. Sci.},
  title        = {Security efficiency maximization for multi-UAV–Aided network with mobile edge computing},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The three a’s of wearable and ubiquitous computing:
Activity, affect, and attention. <em>FCOMP</em>, <em>3</em>, 691622. (<a
href="https://doi.org/10.3389/fcomp.2021.691622">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FCOMP},
  author       = {Van Laerhoven, Kristof},
  doi          = {10.3389/fcomp.2021.691622},
  journal      = {Frontiers in Computer Science},
  month        = {6},
  pages        = {691622},
  shortjournal = {Front. Comput. Sci.},
  title        = {The three a’s of wearable and ubiquitous computing: Activity, affect, and attention},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Is fun for wellness engaging? Evaluation of user experience
of an online intervention to promote well-being and physical activity.
<em>FCOMP</em>, <em>3</em>, 690389. (<a
href="https://doi.org/10.3389/fcomp.2021.690389">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Online well-being interventions demonstrate great promise in terms of both engagement and outcomes. Fun For Wellness (FFW) is a novel online intervention grounded in self-efficacy theory and intended to improve multidimensional well-being and physical activity through multi-modal methods. These strategies include capability-enhancing opportunities, learning experiences such as games, video vignettes, and self-assessments. RCT studies have suggested that FFW is efficacious in improving subjective and domain-specific well-being, and effective in improving mental health, physical health, physical activity, and self-efficacy in United States. adults who are overweight and in the general population. The present study uses qualitative and quantitative user experience data collected during two RCT trials to understand and evaluate engagement with FFW, its drivers, and its outcomes. Results suggest that FFW is enjoyable, moderately engaging, and easy to use; and contributes to positive outcomes including skill development and enhanced confidence, for both overweight individuals and the general adult population. Drivers of engagement appear to include rewards, gamification, scenario-based learning, visual tracking for self-monitoring, ease of use and simple communications, and the entertaining, interactive nature of program activities. Findings indicate that there are opportunities to streamline and simplify the experience. These results can help improve FFW and contribute to the science of engagement with online interventions designed to improve well-being.},
  archive      = {J_FCOMP},
  author       = {Scarpa, Michael P. and Prilletensky, Isaac and McMahon, Adam and Myers, Nicholas D. and Prilleltensky, Ora and Lee, Seungmin and Pfeiffer, Karin A. and Bateman, André G. and Brincks, Ahnalee M.},
  doi          = {10.3389/fcomp.2021.690389},
  journal      = {Frontiers in Computer Science},
  month        = {6},
  pages        = {690389},
  shortjournal = {Front. Comput. Sci.},
  title        = {Is fun for wellness engaging? evaluation of user experience of an online intervention to promote well-being and physical activity},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Ice core science meets computer vision: Challenges and
perspectives. <em>FCOMP</em>, <em>3</em>, 690276. (<a
href="https://doi.org/10.3389/fcomp.2021.690276">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Polar ice cores play a central role in studies of the earth’s climate system through natural archives. A pressing issue is the analysis of the oldest, highly thinned ice core sections, where the identification of paleoclimate signals is particularly challenging. For this, state-of-the-art imaging by laser-ablation inductively-coupled plasma mass spectrometry (LA-ICP-MS) has the potential to be revolutionary due to its combination of micron-scale 2D chemical information with visual features. However, the quantitative study of record preservation in chemical images raises new questions that call for the expertise of the computer vision community. To illustrate this new inter-disciplinary frontier, we describe a selected set of key questions. One critical task is to assess the paleoclimate significance of single line profiles along the main core axis, which we show is a scale-dependent problem for which advanced image analysis methods are critical. Another important issue is the evaluation of post-depositional layer changes, for which the chemical images provide rich information. Accordingly, the time is ripe to begin an intensified exchange between the two scientific communities of computer vision and ice core science. The collaborative building of a new framework for investigating high-resolution chemical images with automated image analysis techniques will also benefit the already wide-spread application of laser-ablation inductively-coupled plasma mass spectrometry chemical imaging in the geosciences.},
  archive      = {J_FCOMP},
  author       = {Bohleber, Pascal and Roman, Marco and Barbante, Carlo and Vascon, Sebastiano and Siddiqi, Kaleem and Pelillo, Marcello},
  doi          = {10.3389/fcomp.2021.690276},
  journal      = {Frontiers in Computer Science},
  month        = {6},
  pages        = {690276},
  shortjournal = {Front. Comput. Sci.},
  title        = {Ice core science meets computer vision: Challenges and perspectives},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Crowdsourcing ecologically-valid dialogue data for german.
<em>FCOMP</em>, <em>3</em>, 686050. (<a
href="https://doi.org/10.3389/fcomp.2021.686050">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite their increasing success, user interactions with smart speech assistants (SAs) are still very limited compared to human-human dialogue. One way to make SA interactions more natural is to train the underlying natural language processing modules on data which reflects how humans would talk to a SA if it was capable of understanding and producing natural dialogue given a specific task. Such data can be collected applying a Wizard-of-Oz approach (WOz), where user and system side are played by humans. WOz allows researchers to simulate human-machine interaction while benefitting from the fact that all participants are human and thus dialogue-competent. More recent approaches have leveraged simple templates specifying a dialogue scenario for crowdsourcing large-scale datasets. Template-based collection efforts, however, come at the cost of data diversity and naturalness. We present a method to crowdsource dialogue data for the SA domain in the WOz framework, which aims at limiting researcher-induced bias in the data while still allowing for a low-resource, scalable data collection. Our method can also be applied to languages other than English (in our case German), for which fewer crowd-workers may be available. We collected data asynchronously, relying only on existing functionalities of Amazon Mechanical Turk, by formulating the task as a dialogue continuation task. Coherence in dialogues is ensured, as crowd-workers always read the dialogue history, and as a unifying scenario is provided for each dialogue. In order to limit bias in the data, rather than using template-based scenarios, we handcrafted situated scenarios which aimed at not pre-script-ing the task into every single detail and not priming the participants’ lexical choices. Our scenarios cued people’s knowledge of common situations and entities relevant for our task, without directly mentioning them, but relying on vague language and circumlocutions. We compare our data (which we publish as the CROWDSS corpus; n = 113 dialogues) with data from MultiWOZ, showing that our scenario approach led to considerably less scripting and priming and thus more ecologically-valid dialogue data. This suggests that small investments in the collection setup can go a long way in improving data quality, even in a low-resource setup.},
  archive      = {J_FCOMP},
  author       = {Frommherz, Yannick and Zarcone, Alessandra},
  doi          = {10.3389/fcomp.2021.686050},
  journal      = {Frontiers in Computer Science},
  month        = {6},
  pages        = {686050},
  shortjournal = {Front. Comput. Sci.},
  title        = {Crowdsourcing ecologically-valid dialogue data for german},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The trustworthiness of voice assistants in the context of
healthcare investigating the effect of perceived expertise on the
trustworthiness of voice assistants, providers, data receivers, and
automatic speech recognition. <em>FCOMP</em>, <em>3</em>, 685250. (<a
href="https://doi.org/10.3389/fcomp.2021.685250">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As an emerging market for voice assistants (VA), the healthcare sector imposes increasing requirements on the users’ trust in the technological system. To encourage patients to reveal sensitive data requires patients to trust in the technological counterpart. In an experimental laboratory study, participants were presented a VA, which was introduced as either a “specialist” or a “generalist” tool for sexual health. In both conditions, the VA asked the exact same health-related questions. Afterwards, participants assessed the trustworthiness of the tool and further source layers (provider, platform provider, automatic speech recognition in general, data receiver) and reported individual characteristics (disposition to trust and disclose sexual information). Results revealed that perceiving the VA as a specialist resulted in higher trustworthiness of the VA and of the provider, the platform provider and automatic speech recognition in general. Furthermore, the provider’s trustworthiness affected the perceived trustworthiness of the VA. Presenting both a theoretical line of reasoning and empirical data, the study points out the importance of the users’ perspective on the assistant. In sum, this paper argues for further analyses of trustworthiness in voice-based systems and its effects on the usage behavior as well as the impact on responsible design of future technology.},
  archive      = {J_FCOMP},
  author       = {Wienrich, Carolin and Reitelbach, Clemens and Carolus, Astrid},
  doi          = {10.3389/fcomp.2021.685250},
  journal      = {Frontiers in Computer Science},
  month        = {6},
  pages        = {685250},
  shortjournal = {Front. Comput. Sci.},
  title        = {The trustworthiness of voice assistants in the context of healthcare investigating the effect of perceived expertise on the trustworthiness of voice assistants, providers, data receivers, and automatic speech recognition},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The participant journey map: Understanding the design of
interactive augmented play spaces. <em>FCOMP</em>, <em>3</em>, 674132.
(<a href="https://doi.org/10.3389/fcomp.2021.674132">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Augmented Play Spaces (APS) are (semi-) public environments where playful interaction is facilitated by enriching the existing environment with interactive technology. APS can potentially facilitate social interaction and physical activity in (semi-)public environments. In controlled settings APS show promising effects. However, people’s willingness to engage with APS in situ, depends on many factors that do not occur in aforementioned controlled settings (where participation is obvious). To be able to achieve and demonstrate the positive effects of APS when implemented in (semi-)public environments, it is important to gain more insight in how to motivate people to engage with them and better understand when and how those decisions can be influenced by certain (design) factors. The Participant Journey Map (PJM) was developed following multiple iterations. First, based on related work, and insights gained from previously developed and implemented APS, a concept of the PJM was developed. Next, to validate and refine the PJM, interviews with 6 experts with extensive experience with developing and implementing APS were conducted. The first part of these interviews focused on influential (design) factors for engaging people into APS. In the second part, experts were asked to provide feedback on the first concept of the PJM. Based on the insights from the expert interviews, the PJM was adjusted and refined. The Participant Journey Map consists of four layers: Phases, States, Transitions and Influential Factors. There are two overarching phases: ‘Onboarding’ and ‘Participation’ and 6 states a (potential) participant goes through when engaging with an APS: ‘Transit,’ ‘Awareness,’ ‘Interest,’ ‘Intention,’ ‘Participation,’ ‘Finishing.’ Transitions indicate movements between states. Influential factors are the factors that influence these transitions. The PJM supports directions for further research and the design and implementation of APS. It contributes to previous work by providing a detailed overview of a participant journey and the factors that influence motivation to engage with APS. Notable additions are the detailed overview of influential factors, the introduction of the states ‘Awareness,’ ‘Intention’ and ‘Finishing’ and the non-linear approach. This will support taking into account these often overlooked, key moments in future APS research and design projects. Additionally, suggestions for future research into the design of APS are given.},
  archive      = {J_FCOMP},
  author       = {Mast, Danica and de Vries, Sanne I. and Broekens, Joost and Verbeek, Fons J.},
  doi          = {10.3389/fcomp.2021.674132},
  journal      = {Frontiers in Computer Science},
  month        = {6},
  pages        = {674132},
  shortjournal = {Front. Comput. Sci.},
  title        = {The participant journey map: Understanding the design of interactive augmented play spaces},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Development and evaluation of technology enhanced
interaction framework method for designing accessible technologies for
visually impaired people. <em>FCOMP</em>, <em>3</em>, 671414. (<a
href="https://doi.org/10.3389/fcomp.2021.671414">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This research developed and evaluated a software development support method to help non-expert developers evaluating or gathering requirements and designing or evaluating digital technology solutions to accessibility barriers people with visual impairment encounter. The Technology Enhanced Interaction Framework (TEIF) Visual Impairment (VI) Method was developed through literature review and interviews with 20 students with visual impairment, 10 adults with visual impairment and five accessibility experts. It is an extension of the Technology Enhanced Interaction Framework (TEIF) and its “HI-Method” that had been developed and validated and evaluated for hearing impairment and supports other methods by providing multiple-choice questions to help identify requirements, the answers to which help provide technology suggestions that support the design stage. Four accessibility experts and three developer experts reviewed and validated the TEIF VI-Method. It was experimentally evaluated by 18 developers using the TEIF VI-Method and another 18 developers using their preferred “Other Methods” to identify the requirements and solution to a scenario involving barriers for people with visual impairment. The “Other Methods” group were then shown the TEIF VI-Method and both groups were asked their opinions of its ease of use. The mean number of correctly selected requirements was significantly higher (p &amp;lt; 0.001) for developers using the TEIF VI-Method (X̄ = 8.83) than the Other Method (X̄ = 6.22). Developers using the TEIF VI-Method ranked technology solutions closer to the expert rankings than developers using Other Methods (p &amp;lt; 0.05). All developers found the TEIF VI-Method easy to follow. Developers could evaluate requirements and technology solutions to interaction problems involving people with visual impairment using the TEIF VI-Method better than existing Other Methods. Developers could benefit from using the TEIF VI-Method when developing technology solutions to interaction problems faced by people with visual impairment.},
  archive      = {J_FCOMP},
  author       = {Angkananon, Kewalin and Wald, Mike and Phetkeaw, Thimaporn},
  doi          = {10.3389/fcomp.2021.671414},
  journal      = {Frontiers in Computer Science},
  month        = {6},
  pages        = {671414},
  shortjournal = {Front. Comput. Sci.},
  title        = {Development and evaluation of technology enhanced interaction framework method for designing accessible technologies for visually impaired people},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Evaluating a novel p300-based real-time image ranking BCI.
<em>FCOMP</em>, <em>3</em>, 661224. (<a
href="https://doi.org/10.3389/fcomp.2021.661224">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Brain–computer interfaces (BCIs) establish communication between a human brain and a computer or external devices by translating the electroencephalography (EEG) signal into computer commands. After stimulating a sensory organ, a positive deflection of the EEG signal between 250 and 700 ms can be measured. This signal component of the event-related potential (ERP) is called “P300.” Numerous studies have provided evidence that the P300 amplitude and latency are linked to sensory perception, engagement, and cognition. Combining the advances in technology, classification methods, and signal processing, we developed a novel image ranking system called the Unicorn Blondy Check. In this study, the application was tested on 21 subjects using three different visual oddball paradigms. Two consisted of female faces and gray-scale images, while the third test paradigm consisted of familiar and unfamiliar faces. The images were displayed for a duration of 150 ms in a randomized order. The system was trained using 50 trials and tested with 30 trials. The EEG data were acquired using the Unicorn Hybrid Black eight-channel BCI system. These synchronized recordings were analyzed, and the achieved classification accuracies were calculated. The EEG signal was averaged over all participants and for every paradigm separately. Analysis of the EEG data revealed a significant shift in the P300 latency dependent on the paradigm and decreased amplitude for a lower target to non-target ratio. The image ranking application achieved a mean accuracy of 100 and 95.5% for ranking female faces above gray-scale images with ratios of 1:11 and 5:11, respectively. In the case of four familiar faces to 24 unfamiliar faces, 86.4% was reached. The obtained results illustrate this novel system’s functionality due to accuracies above chance levels for all subjects.},
  archive      = {J_FCOMP},
  author       = {Sutaj, Ngadhnjim and Walchshofer, Martin and Schreiner, Leonhard and Turchet, Luca and Pretl, Harald and Guger, Christoph},
  doi          = {10.3389/fcomp.2021.661224},
  journal      = {Frontiers in Computer Science},
  month        = {6},
  pages        = {661224},
  shortjournal = {Front. Comput. Sci.},
  title        = {Evaluating a novel p300-based real-time image ranking BCI},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The CoronaSurveys system for COVID-19 incidence data
collection and processing. <em>FCOMP</em>, <em>3</em>, 641237. (<a
href="https://doi.org/10.3389/fcomp.2021.641237">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {CoronaSurveys is an ongoing interdisciplinary project developing a system to infer the incidence of COVID-19 around the world using anonymous open surveys. The surveys have been translated into 60 languages and are continuously collecting participant responses from any country in the world. The responses collected are pre-processed, organized, and stored in a version-controlled repository, which is publicly available to the scientific community. In addition, the CoronaSurveys team has devised several estimates computed on the basis of survey responses and other data, and makes them available on the project’s website in the form of tables, as well as interactive plots and maps. In this paper, we describe the computational system developed for the CoronaSurveys project. The system includes multiple components and processes, including the web survey, the mobile apps, the cleaning and aggregation process of the survey responses, the process of storage and publication of the data, the processing of the data and the computation of estimates, and the visualization of the results. In this paper we describe the system architecture and the major challenges we faced in designing and deploying it.},
  archive      = {J_FCOMP},
  author       = {Baquero, Carlos and Casari, Paolo and Fernandez Anta, Antonio and García-García, Amanda and Frey, Davide and Garcia-Agundez, Augusto and Georgiou, Chryssis and Girault, Benjamin and Ortega, Antonio and Goessens, Mathieu and Hernández-Roig, Harold A. and Nicolaou, Nicolas and Stavrakis, Efstathios and Ojo, Oluwasegun and Roberts, Julian C. and Sanchez, Ignacio},
  doi          = {10.3389/fcomp.2021.641237},
  journal      = {Frontiers in Computer Science},
  month        = {6},
  pages        = {641237},
  shortjournal = {Front. Comput. Sci.},
  title        = {The CoronaSurveys system for COVID-19 incidence data collection and processing},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Alzheimer’s dementia recognition from spontaneous speech
using disfluency and interactional features. <em>FCOMP</em>, <em>3</em>,
640669. (<a href="https://doi.org/10.3389/fcomp.2021.640669">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Alzheimer’s disease (AD) is a progressive, neurodegenerative disorder mainly characterized by memory loss with deficits in other cognitive domains, including language, visuospatial abilities, and changes in behavior. Detecting diagnostic biomarkers that are noninvasive and cost-effective is of great value not only for clinical assessments and diagnostics but also for research purposes. Several previous studies have investigated AD diagnosis via the acoustic, lexical, syntactic, and semantic aspects of speech and language. Other studies include approaches from conversation analysis that look at more interactional aspects, showing that disfluencies such as fillers and repairs, and purely nonverbal features such as inter-speaker silence, can be key features of AD conversations. These kinds of features, if useful for diagnosis, may have many advantages: They are simple to extract and relatively language-, topic-, and task-independent. This study aims to quantify the role and contribution of these features of interaction structure in predicting whether a dialogue participant has AD. We used a subset of the Carolinas Conversation Collection dataset of patients with AD at moderate stage within the age range 60–89 and similar-aged non-AD patients with other health conditions. Our feature analysis comprised two sets: disfluency features, including indicators such as self-repairs and fillers, and interactional features, including overlaps, turn-taking behavior, and distributions of different types of silence both within patient speech and between patient and interviewer speech. Statistical analysis showed significant differences between AD and non-AD groups for several disfluency features (edit terms, verbatim repeats, and substitutions) and interactional features (lapses, gaps, attributable silences, turn switches per minute, standardized phonation time, and turn length). For the classification of AD patient conversations vs. non-AD patient conversations, we achieved 83% accuracy with disfluency features, 83% accuracy with interactional features, and an overall accuracy of 90% when combining both feature sets using support vector machine classifiers. The discriminative power of these features, perhaps combined with more conventional linguistic features, therefore shows potential for integration into noninvasive clinical assessments for AD at advanced stages.},
  archive      = {J_FCOMP},
  author       = {Nasreen, Shamila and Rohanian, Morteza and Hough, Julian and Purver, Matthew},
  doi          = {10.3389/fcomp.2021.640669},
  journal      = {Frontiers in Computer Science},
  month        = {6},
  pages        = {640669},
  shortjournal = {Front. Comput. Sci.},
  title        = {Alzheimer’s dementia recognition from spontaneous speech using disfluency and interactional features},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Making virtual learning environments accessible to people
with disabilities in universities in uganda. <em>FCOMP</em>, <em>3</em>,
638275. (<a href="https://doi.org/10.3389/fcomp.2021.638275">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Public and private universities in Uganda have been using Virtual Learning Environments (VLEs) since early 2000s to support delivery of blended learning owing to the increased uptake of technology in many aspects of life, and the benefits of blended learning/eLearning. eLearning is of particular benefit to people with disabilities, since they may find it difficult to attend classes on a university campus. Accessibility of a VLE has a strong impact on user engagement and adoption and consequently on students’ learning outcomes. Current research on use of VLEs and eLearning in general in Ugandan universities focuses on sensitization and training, the potential of social media like WhatsApp and Facebook, and required resources like Internet connectivity, and change management. In stark contrast, there is no investigation of accessibility to people with disabilities, even though about 12.4% of the population have some form of disability. This paper examines the extent to which Uganda’s policy environment promotes making eLearning accessible, reviews the accessibility of a sample of VLEs of public and private universities in Uganda, and suggests recommendations on addressing the existing accessibility gaps in policy and implementation of VLEs.},
  archive      = {J_FCOMP},
  author       = {Baguma, Rehema and Wolters, Maria K.},
  doi          = {10.3389/fcomp.2021.638275},
  journal      = {Frontiers in Computer Science},
  month        = {6},
  pages        = {638275},
  shortjournal = {Front. Comput. Sci.},
  title        = {Making virtual learning environments accessible to people with disabilities in universities in uganda},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Patient safety through nursing documentation: Barriers
identified by healthcare professionals and students. <em>FCOMP</em>,
<em>3</em>, 624555. (<a
href="https://doi.org/10.3389/fcomp.2021.624555">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Background: Although access to accurate patient documentation is recognized as a prerequisite for delivering of safe and continuous municipal elderly care, healthcare professionals often fail to provide comprehensive clinical information in an accurate and timely manner. The aim of this study was to understand the perceptions of healthcare professionals and healthcare students regarding existing barriers to patient safety through the performance of documentation practices.Methods: Using a qualitative, exploratory design, this study conducted six focus group interviews with nurses and social educators (n = 12) involved in primary care practice and nursing and social educator bachelor’s degree students from a University College (n = 11). Data were analyzed using qualitative content analysis.Results: Four themes emerged from the analysis, which described barriers to patient safety and quality in documentation practices: “Individual factors,” “Social factors,” “Organizational factors,” and “Technological factors.” Each theme also included several sub-themes.Conclusion: According to the findings, several barriers negatively influenced documentation practices and information exchange, which may place primary care patients in a vulnerable and exposed situation. To achieve successful documentation, increased awareness and efforts by the individual professional are necessary. However, primary care services must facilitate the achievement of these goals by providing adequate resources, clear mission statements, and understandable policies.},
  archive      = {J_FCOMP},
  author       = {Bjerkan, Jorunn and Valderaune, Victor and Olsen, Rose Mari},
  doi          = {10.3389/fcomp.2021.624555},
  journal      = {Frontiers in Computer Science},
  month        = {6},
  pages        = {624555},
  shortjournal = {Front. Comput. Sci.},
  title        = {Patient safety through nursing documentation: Barriers identified by healthcare professionals and students},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Corrigendum: A virtual tour of a hardly accessible
archaeological site: The effect of immersive virtual reality in user
experience, learning and attitude change. <em>FCOMP</em>, <em>3</em>,
697259. (<a href="https://doi.org/10.3389/fcomp.2021.697259">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FCOMP},
  author       = {Kyrlitsias, Christos and Christofi, Maria and Michael-Grigoriou, Despina and Banakou, Domna and Ioannou, Andri},
  doi          = {10.3389/fcomp.2021.697259},
  journal      = {Frontiers in Computer Science},
  month        = {5},
  pages        = {697259},
  shortjournal = {Front. Comput. Sci.},
  title        = {Corrigendum: a virtual tour of a hardly accessible archaeological site: the effect of immersive virtual reality in user experience, learning and attitude change},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Editorial: Serious games. <em>FCOMP</em>, <em>3</em>,
686348. (<a href="https://doi.org/10.3389/fcomp.2021.686348">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FCOMP},
  author       = {Vaz de Carvalho, Carlos and González González, Carina Soledad and Popescu, Elvira and Rugelj, Jože},
  doi          = {10.3389/fcomp.2021.686348},
  journal      = {Frontiers in Computer Science},
  month        = {5},
  pages        = {686348},
  shortjournal = {Front. Comput. Sci.},
  title        = {Editorial: Serious games},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). “Alexa, i feel for you!” Observers’ empathetic reactions
towards a conversational agent. <em>FCOMP</em>, <em>3</em>, 682982. (<a
href="https://doi.org/10.3389/fcomp.2021.682982">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conversational agents and smart speakers have grown in popularity offering a variety of options for use, which are available through intuitive speech operation. In contrast to the standard dyad of a single user and a device, voice-controlled operations can be observed by further attendees resulting in new, more social usage scenarios. Referring to the concept of ‘media equation’ and to research on the idea of ‘computers as social actors,’ which describes the potential of technology to trigger emotional reactions in users, this paper asks for the capacity of smart speakers to elicit empathy in observers of interactions. In a 2 × 2 online experiment, 140 participants watched a video of a man talking to an Amazon Echo either rudely or neutrally (factor 1), addressing it as ‘Alexa’ or ‘Computer’ (factor 2). Controlling for participants’ trait empathy, the rude treatment results in participants’ significantly higher ratings of empathy with the device, compared to the neutral treatment. The form of address had no significant effect. Results were independent of the participants’ gender and usage experience indicating a rather universal effect, which confirms the basic idea of the media equation. Implications for users, developers and researchers were discussed in the light of (future) omnipresent voice-based technology interaction scenarios.},
  archive      = {J_FCOMP},
  author       = {Carolus, Astrid and Wienrich, Carolin and Törke, Anna and Friedel, Tobias and Schwietering, Christian and Sperzel, Mareike},
  doi          = {10.3389/fcomp.2021.682982},
  journal      = {Frontiers in Computer Science},
  month        = {5},
  pages        = {682982},
  shortjournal = {Front. Comput. Sci.},
  title        = {‘Alexa, i feel for you!’ observers’ empathetic reactions towards a conversational agent},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Computation on structures - the challenge of seamless
integration of theory and rigorous scientific practice. <em>FCOMP</em>,
<em>3</em>, 670602. (<a
href="https://doi.org/10.3389/fcomp.2021.670602">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FCOMP},
  author       = {Schewe, Klaus-Dieter},
  doi          = {10.3389/fcomp.2021.670602},
  journal      = {Frontiers in Computer Science},
  month        = {5},
  pages        = {670602},
  shortjournal = {Front. Comput. Sci.},
  title        = {Computation on structures - the challenge of seamless integration of theory and rigorous scientific practice},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Taste in motion: The effect of projection mapping of a
boiling effect on food expectation, food perception, and purchasing
behavior. <em>FCOMP</em>, <em>3</em>, 662824. (<a
href="https://doi.org/10.3389/fcomp.2021.662824">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The appearance of food affects its taste. Many studies have examined how to improve the taste of foods by manipulating their appearance. Most of those studies have focused on static appearances, such as color and texture; however, the impact of the dynamic appearance has not been explored. In this study, the perceptions (sweetness, sourness, saltiness, spiciness, temperature, deliciousness) and value judgments (the price of food, appetite) perceived from food before and after tasting with a projection-based dynamic boiling texture were investigated. The results revealed that the dynamic texture influences expectations for saltiness, spiciness, temperature, deliciousness, price, and appetite before eating the meal and perceived saltiness, spiciness, and appetite when eating. In addition, its influence on the consumers’ behavior was also investigated through an empirical user study in a restaurant. The results indicated that the consumers had a greater tendency to order the meal when they saw it with the projection-based boiling effect. From these, this study demonstrates the effect of projection mapping of a boiling effect on food expectation, perception and consumer behavior.},
  archive      = {J_FCOMP},
  author       = {Suzuki, Yuji and Narumi, Takuji and Tanikawa, Tomohiro and Hirose, Michitaka},
  doi          = {10.3389/fcomp.2021.662824},
  journal      = {Frontiers in Computer Science},
  month        = {5},
  pages        = {662824},
  shortjournal = {Front. Comput. Sci.},
  title        = {Taste in motion: The effect of projection mapping of a boiling effect on food expectation, food perception, and purchasing behavior},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Developing an error map for cognitive navigation system.
<em>FCOMP</em>, <em>3</em>, 661904. (<a
href="https://doi.org/10.3389/fcomp.2021.661904">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Global Navigation Satellite System (GNSS) positioning is a widely used and a key intelligent transportation system (ITS) technology. An automotive navigation system is necessary when driving to an unfamiliar location. One difficulty regarding GNSS positioning occurs when an error is caused by various factors, which reduces the positioning accuracy and impacts the performance of applications such as navigation systems. However, there is no way for users to be aware of the magnitude of the error. In this paper, we propose a cognitive navigation system that uses an error map to provide users with information about the magnitude of errors to better understand the positioning accuracy. This technology can allow us to develop a new navigation system that offers a more user-friendly interface. We propose that the method will develop an error map by using two low-cost GNSS receivers to provide information about the magnitude of errors. We also recommend some applications that will work with the error map.},
  archive      = {J_FCOMP},
  author       = {Ito, Atsushi and Nakamura, Yosuke and Hiramatsu, Yuko and Kitani, Tomoya and Hatano, Hiroyuki},
  doi          = {10.3389/fcomp.2021.661904},
  journal      = {Frontiers in Computer Science},
  month        = {5},
  pages        = {661904},
  shortjournal = {Front. Comput. Sci.},
  title        = {Developing an error map for cognitive navigation system},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Experiment in a box (XB): An interactive technology
framework for sustainable health practices. <em>FCOMP</em>, <em>3</em>,
661890. (<a href="https://doi.org/10.3389/fcomp.2021.661890">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents the Experiment in a Box (XB) framework to support interactive technology design for building health skills. The XB provides a suite of experiments—time-limited, loosely structured evaluations of health heuristics for a user-as-experimenter to select from and then test in order to determine that heuristic’s efficacy, and to explore how it might be incorporated into the person’s life and when necessary, to support their health and wellbeing. The approach leverages self-determination theory to support user autonomy and competence to build actionable, personal health knowledge skills and practice (KSP). In the three studies of XB presented, we show that with even the short engagement of an XB experiment, participants develop health practices from the interventions that are still in use long after the intervention is finished. To situate the XB approach relative to other work around health practices in HCI in particular, we contribute two design continua for this design space: insourcing to outsourcing and habits to heuristics. From this analysis, we demonstrate that XB is situated in a largely under-explored area for interactive health interventions: the insourcing and heuristic oriented area of the design space. Overall, the work offers a new scaffolding, the XB Framework, to instantiate time-limited interactive technology interventions to support building KSP that can thrive in that person, significantly both post-interventions, and independent of that technology.},
  archive      = {J_FCOMP},
  author       = {schraefel, m. c. and Muresan, George Catalin and Hekler, Eric},
  doi          = {10.3389/fcomp.2021.661890},
  journal      = {Frontiers in Computer Science},
  month        = {5},
  pages        = {661890},
  shortjournal = {Front. Comput. Sci.},
  title        = {Experiment in a box (XB): An interactive technology framework for sustainable health practices},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Wearable devices for gait analysis in intelligent
healthcare. <em>FCOMP</em>, <em>3</em>, 661676. (<a
href="https://doi.org/10.3389/fcomp.2021.661676">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, we review the role of wearable devices in tracking our daily locomotion. We discuss types of wearable devices that can be used, methods for gait analyses, and multiple healthcare-related applications aided by artificial intelligence. Impaired walking and locomotion are common resulting from injuries, degenerative pathologies, musculoskeletal disorders, and various neurological damages. Daily tracking and gait analysis are convenient and efficient approaches for monitoring human walking, where concreate and rich data can be obtained for examining our posture control mechanism during body movement and providing enhanced clinical pieces of evidence for diagnoses and treatments. Many sensors in wearable devices can help to record data of walking and running; spatiotemporal and kinematic variables can be further calculated in gait analysis. We report our previous works in gait analysis, discussing applications of wearable devices for detecting foot and ankle lesions, supporting surgeons in early diagnosis, and helping physicians with rehabilitation.},
  archive      = {J_FCOMP},
  author       = {Liu, Xin and Zhao, Chen and Zheng, Bin and Guo, Qinwei and Duan, Xiaoqin and Wulamu, Aziguli and Zhang, Dezheng},
  doi          = {10.3389/fcomp.2021.661676},
  journal      = {Frontiers in Computer Science},
  month        = {5},
  pages        = {661676},
  shortjournal = {Front. Comput. Sci.},
  title        = {Wearable devices for gait analysis in intelligent healthcare},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Exploring the brain activity related to missing penalty
kicks: An fNIRS study. <em>FCOMP</em>, <em>3</em>, 661466. (<a
href="https://doi.org/10.3389/fcomp.2021.661466">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {At vital moments in professional soccer matches, penalties were often missed. Psychological factors, such as anxiety and pressure, are among the critical causes of the mistakes, commonly known as choking under pressure. Nevertheless, the factors have not been fully explored. In this study, we used functional near-infrared spectroscopy (fNIRS) to investigate the influence of the brain on this process. An in-situ study was set-up (N = 22), in which each participant took 15 penalties under three different pressure conditions: without a goalkeeper, with an amiable goalkeeper, and with a competitive goalkeeper. Both experienced and inexperienced soccer players were recruited, and the brain activation was compared across groups. Besides, fNIRS activation was compared between sessions that participants felt anxious against sessions without anxiety report, and between penalty-scoring and -missing sessions. The results show that the task-relevant brain region, the motor cortex, was more activated when players were not experiencing performance anxiety. The activation of task-irrelevant areas was shown to be related to players experiencing anxiety and missing penalties, especially the prefrontal cortex (PFC). More particularly, an overall higher activation of the PFC and an increase of PFC lateral asymmetry were related to anxious players and missed penalties, which can be caused by players&#39; worries about the consequences of scoring or missing the penalty kicks. When experienced players were feeling anxious, their left temporal cortex activation increased, which could be an indication that experienced overthink the situation and neglect their automated skills. Besides, the left temporal cortex activation is higher when inexperienced players succeeded to score a penalty. Overall, the results of this study are in line with the neural efficiency theory and demonstrate the feasibility and ecological validity to detect neurological clues relevant to anxiety and performance from fNIRS recordings in the field.},
  archive      = {J_FCOMP},
  author       = {Slutter, Max W. J. and Thammasan, Nattapong and Poel, Mannes},
  doi          = {10.3389/fcomp.2021.661466},
  journal      = {Frontiers in Computer Science},
  month        = {5},
  pages        = {661466},
  shortjournal = {Front. Comput. Sci.},
  title        = {Exploring the brain activity related to missing penalty kicks: An fNIRS study},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Speech pauses and pronominal anaphors. <em>FCOMP</em>,
<em>3</em>, 659539. (<a
href="https://doi.org/10.3389/fcomp.2021.659539">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the usefulness of speech pauses for determining whether third person neuter gender singular pronouns refer to individual or abstract entities in Danish spoken language. The annotations of dyadic map task dialogues and spontaneous first encounters are analyzed and used in machine learning experiments act to automatically identify the anaphoric functions of pronouns and the type of abstract reference. The analysis of the data shows that abstract reference is more often performed by marked (stressed or demonstrative pronouns) than by unmarked personal pronouns in Danish speech as in English, and therefore previous studies of abstract reference in the former language are corrected. The data also show that silent and filled pauses precede significantly more often third person singular neuter gender pronouns when they refer to abstract entities than when they refer to individual entities. Since abstract entities are not the most salient ones and referring to them is cognitively more hard than referring to individual entities, pauses signal this complex processes. This is in line with perception studies, which connect pauses with the expression of abstract or complex concepts. We also found that unmarked pronouns referring to an entity type usually referred to by a marked pronoun are significantly more often preceded by a speech pause than marked pronouns with the same referent type. This indicates that speech pauses can also signal that the referent of a pronoun of a certain type is not the most expected one. Finally, language models were produced from the annotated map task and first encounter dialogues in order to train machine learning experiments to predict the function of third person neuter gender singular pronouns as a first step toward the identification of the anaphoric antecedents. The language models from the map task dialogues were also used for training classifiers to determine the referent type (speech act, event, fact or proposition) of abstract anaphors. In all cases, the best results were obtained by a multilayer perceptron with an F1-score between 0.52 and 0.67 for the three-class function prediction task and of 0.73 for the referential type prediction.},
  archive      = {J_FCOMP},
  author       = {Navarretta, Costanza},
  doi          = {10.3389/fcomp.2021.659539},
  journal      = {Frontiers in Computer Science},
  month        = {5},
  pages        = {659539},
  shortjournal = {Front. Comput. Sci.},
  title        = {Speech pauses and pronominal anaphors},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A comparison of connected speech tasks for detecting early
alzheimer’s disease and mild cognitive impairment using natural language
processing and machine learning. <em>FCOMP</em>, <em>3</em>, 634360. (<a
href="https://doi.org/10.3389/fcomp.2021.634360">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Alzheimer’s disease (AD) has a long pre-clinical period, and so there is a crucial need for early detection, including of Mild Cognitive Impairment (MCI). Computational analysis of connected speech using Natural Language Processing and machine learning has been found to indicate disease and could be utilized as a rapid, scalable test for early diagnosis. However, there has been a focus on the Cookie Theft picture description task, which has been criticized. Fifty participants were recruited – 25 healthy controls (HC), 25 mild AD or MCI (AD+MCI) – and these completed five connected speech tasks: picture description, a conversational map reading task, recall of an overlearned narrative, procedural recall and narration of a wordless picture book. A high-dimensional set of linguistic features were automatically extracted from each transcript and used to train Support Vector Machines to classify groups. Performance varied, with accuracy for HC vs. AD+MCI classification ranging from 62% using picture book narration to 78% using overlearned narrative features. This study shows that, importantly, the conditions of the speech task have an impact on the discourse produced, which influences accuracy in detection of AD beyond the length of the sample. Further, we report the features important for classification using different tasks, showing that a focus on the Cookie Theft picture description task may narrow the understanding of how early AD pathology impacts speech.},
  archive      = {J_FCOMP},
  author       = {Clarke, Natasha and Barrick, Thomas R. and Garrard, Peter},
  doi          = {10.3389/fcomp.2021.634360},
  journal      = {Frontiers in Computer Science},
  month        = {5},
  pages        = {634360},
  shortjournal = {Front. Comput. Sci.},
  title        = {A comparison of connected speech tasks for detecting early alzheimer’s disease and mild cognitive impairment using natural language processing and machine learning},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). E-commerce design by older adults: The selection and
placement of web objects on shopping sites. <em>FCOMP</em>, <em>3</em>,
631241. (<a href="https://doi.org/10.3389/fcomp.2021.631241">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study offers insights, gathered from co-design activities with older adults, on the design of e-commerce websites. Twenty older adults (aged 52–75 years) took part in a paper-based design activity in which they were presented with a web browser window, cutouts of a selection of web objects (e.g., product images and “add to cart” buttons) in a range of designs, and office stationery for making annotations and asked to select and place web objects onto the browser window to express their design ideas for two types of shopping experience: purchasing a grocery item that is inexpensive and typically purchased in multiples (carrots) and purchasing an assistive technology item which is considered expensive and normally purchased as a one-off (wheelchair). Objects selected frequently by the older adults for inclusion in both types of e-commerce websites included product images, price, and an “add to cart” button. Some objects were selected for inclusion depending on the type of website—quantity selection was selected for the cheap, multiple purchase item, whereas descriptions, reviews, and shipping/return information were deemed important only for the expensive, single-item purchase. Regarding the relative placement of the “add to cart” button, participants most often placed the button close to the quantity selection and/or the price. Furthermore, participants expressed that having these three elements presented within a visually distinctive “buy box” would be beneficial. This study offers insight into which website elements are deemed important by this older adult participant group for e-commerce websites and how the elements should be arranged, and the results also indicate that some design requirements may differ between different types of shopping experience. The findings can potentially benefit designers, developers, and industries to more fully grasp the potential of usable online shopping applications.},
  archive      = {J_FCOMP},
  author       = {Osman, Rozianawaty and Hwang, Faustina},
  doi          = {10.3389/fcomp.2021.631241},
  journal      = {Frontiers in Computer Science},
  month        = {5},
  pages        = {631241},
  shortjournal = {Front. Comput. Sci.},
  title        = {E-commerce design by older adults: The selection and placement of web objects on shopping sites},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Exploring deep transfer learning techniques for alzheimer’s
dementia detection. <em>FCOMP</em>, <em>3</em>, 624683. (<a
href="https://doi.org/10.3389/fcomp.2021.624683">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Examination of speech datasets for detecting dementia, collected via various speech tasks, has revealed links between speech and cognitive abilities. However, the speech dataset available for this research is extremely limited because the collection process of speech and baseline data from patients with dementia in clinical settings is expensive. In this paper, we study the spontaneous speech dataset from a recent ADReSS challenge, a Cookie Theft Picture (CTP) dataset with balanced groups of participants in age, gender, and cognitive status. We explore state-of-the-art deep transfer learning techniques from image, audio, speech, and language domains. We envision that one advantage of transfer learning is to eliminate the design of handcrafted features based on the tasks and datasets. Transfer learning further mitigates the limited dementia-relevant speech data problem by inheriting knowledge from similar but much larger datasets. Specifically, we built a variety of transfer learning models using commonly employed MobileNet (image), YAMNet (audio), Mockingjay (speech), and BERT (text) models. Results indicated that the transfer learning models of text data showed significantly better performance than those of audio data. Performance gains of the text models may be due to the high similarity between the pre-training text dataset and the CTP text dataset. Our multi-modal transfer learning introduced a slight improvement in accuracy, demonstrating that audio and text data provide limited complementary information. Multi-task transfer learning resulted in limited improvements in classification and a negative impact in regression. By analyzing the meaning behind the Alzheimer&#39;s disease (AD)/non-AD labels and Mini-Mental State Examination (MMSE) scores, we observed that the inconsistency between labels and scores could limit the performance of the multi-task learning, especially when the outputs of the single-task models are highly consistent with the corresponding labels/scores. In sum, we conducted a large comparative analysis of varying transfer learning models focusing less on model customization but more on pre-trained models and pre-training datasets. We revealed insightful relations among models, data types, and data labels in this research area.},
  archive      = {J_FCOMP},
  author       = {Zhu, Youxiang and Liang, Xiaohui and Batsis, John A. and Roth, Robert M.},
  doi          = {10.3389/fcomp.2021.624683},
  journal      = {Frontiers in Computer Science},
  month        = {5},
  pages        = {624683},
  shortjournal = {Front. Comput. Sci.},
  title        = {Exploring deep transfer learning techniques for alzheimer&#39;s dementia detection},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). FusionNet: A deep fully residual convolutional neural
network for image segmentation in connectomics. <em>FCOMP</em>,
<em>3</em>, 613981. (<a
href="https://doi.org/10.3389/fcomp.2021.613981">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cellular-resolution connectomics is an ambitious research direction with the goal of generating comprehensive brain connectivity maps using high-throughput, nano-scale electron microscopy. One of the main challenges in connectomics research is developing scalable image analysis algorithms that require minimal user intervention. Deep learning has provided exceptional performance in image classification tasks in computer vision, leading to a recent explosion in popularity. Similarly, its application to connectomic analyses holds great promise. Here, we introduce a deep neural network architecture, FusionNet, with a focus on its application to accomplish automatic segmentation of neuronal structures in connectomics data. FusionNet combines recent advances in machine learning, such as semantic segmentation and residual neural networks, with summation-based skip connections. This results in a much deeper network architecture and improves segmentation accuracy. We demonstrate the performance of the proposed method by comparing it with several other popular electron microscopy segmentation methods. We further illustrate its flexibility through segmentation results for two different tasks: cell membrane segmentation and cell nucleus segmentation.},
  archive      = {J_FCOMP},
  author       = {Quan, Tran Minh and Hildebrand, David Grant Colburn and Jeong, Won-Ki},
  doi          = {10.3389/fcomp.2021.613981},
  journal      = {Frontiers in Computer Science},
  month        = {5},
  pages        = {613981},
  shortjournal = {Front. Comput. Sci.},
  title        = {FusionNet: A deep fully residual convolutional neural network for image segmentation in connectomics},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Applications of biological and physiological signals in
commercial video gaming and game research: A review. <em>FCOMP</em>,
<em>3</em>, 557608. (<a
href="https://doi.org/10.3389/fcomp.2021.557608">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video gaming is now available as a fully immersive experience that creates responsive inputs and outputs concerning the user, and some experimental developers have integrated the use of the voice, brain, or muscles as input controls. The use of physiological signal equipment can provide valuable information regarding the emotion of a player or patient during gameplay. In this article, we discuss five of the most common biosignals that are used in gaming research, and their function and devices that may be used for measurement. We break down those individual signals and present examples of research studies that implement them. We also discuss the usage of biological signals within commercial gaming and conclude with some possible future directions for the use of biological signals in gaming and game research.},
  archive      = {J_FCOMP},
  author       = {Hughes, Alayna and Jorda, Sergi},
  doi          = {10.3389/fcomp.2021.557608},
  journal      = {Frontiers in Computer Science},
  month        = {5},
  pages        = {557608},
  shortjournal = {Front. Comput. Sci.},
  title        = {Applications of biological and physiological signals in commercial video gaming and game research: A review},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Brain-computer interfaces, open-source, and democratizing
the future of augmented consciousness. <em>FCOMP</em>, <em>3</em>,
661300. (<a href="https://doi.org/10.3389/fcomp.2021.661300">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accessibility, adaptability, and transparency of Brain-Computer Interface (BCI) tools and the data they collect will likely impact how we collectively navigate a new digital age. This discussion reviews some of the diverse and transdisciplinary applications of BCI technology and draws speculative inferences about the ways in which BCI tools, combined with machine learning (ML) algorithms may shape the future. BCIs come with substantial ethical and risk considerations, and it is argued that open source principles may help us navigate complex dilemmas by encouraging experimentation and making developments public as we build safeguards into this new paradigm. Bringing open-source principles of adaptability and transparency to BCI tools can help democratize the technology, permitting more voices to contribute to the conversation of what a BCI-driven future should look like. Open-source BCI tools and access to raw data, in contrast to black-box algorithms and limited access to summary data, are critical facets enabling artists, DIYers, researchers and other domain experts to participate in the conversation about how to study and augment human consciousness. Looking forward to a future in which augmented and virtual reality become integral parts of daily life, BCIs will likely play an increasingly important role in creating closed-loop feedback for generative content. Brain-computer interfaces are uniquely situated to provide artificial intelligence (AI) algorithms the necessary data for determining the decoding and timing of content delivery. The extent to which these algorithms are open-source may be critical to examine them for integrity, implicit bias, and conflicts of interest.},
  archive      = {J_FCOMP},
  author       = {Bernal, Guillermo and Montgomery, Sean M. and Maes, Pattie},
  doi          = {10.3389/fcomp.2021.661300},
  journal      = {Frontiers in Computer Science},
  month        = {4},
  pages        = {661300},
  shortjournal = {Front. Comput. Sci.},
  title        = {Brain-computer interfaces, open-source, and democratizing the future of augmented consciousness},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). EEG-based auditory attention detection and its possible
future applications for passive BCI. <em>FCOMP</em>, <em>3</em>, 661178.
(<a href="https://doi.org/10.3389/fcomp.2021.661178">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The ability to discriminate and attend one specific sound source in a complex auditory environment is a fundamental skill for efficient communication. Indeed, it allows us to follow a family conversation or discuss with a friend in a bar. This ability is challenged in hearing-impaired individuals and more precisely in those with a cochlear implant (CI). Indeed, due to the limited spectral resolution of the implant, auditory perception remains quite poor in a noisy environment or in presence of simultaneous auditory sources. Recent methodological advances allow now to detect, on the basis of neural signals, which auditory stream within a set of multiple concurrent streams an individual is attending to. This approach, called EEG-based auditory attention detection (AAD), is based on fundamental research findings demonstrating that, in a multi speech scenario, cortical tracking of the envelope of the attended speech is enhanced compared to the unattended speech. Following these findings, other studies showed that it is possible to use EEG/MEG (Electroencephalography/Magnetoencephalography) to explore auditory attention during speech listening in a Cocktail-party-like scenario. Overall, these findings make it possible to conceive next-generation hearing aids combining customary technology and AAD. Importantly, AAD has also a great potential in the context of passive BCI, in the educational context as well as in the context of interactive music performances. In this mini review, we firstly present the different approaches of AAD and the main limitations of the global concept. We then expose its potential applications in the world of non-clinical passive BCI.},
  archive      = {J_FCOMP},
  author       = {Belo, Joan and Clerc, Maureen and Schön, Daniele},
  doi          = {10.3389/fcomp.2021.661178},
  journal      = {Frontiers in Computer Science},
  month        = {4},
  pages        = {661178},
  shortjournal = {Front. Comput. Sci.},
  title        = {EEG-based auditory attention detection and its possible future applications for passive BCI},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Operationalizing behavior change theory as part of
persuasive technology: A scoping review on social comparison.
<em>FCOMP</em>, <em>3</em>, 656873. (<a
href="https://doi.org/10.3389/fcomp.2021.656873">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Theories from psychology or the social sciences are commonly used as a starting point when designing persuasive technologies that aim to evoke a specific behavior change. Ideally, using these theories would (1) help guide the design of the persuasive technology and (2) help evaluate and inform the theory. In this paper, we focused on the first aspect and looked at how papers report on how a theory guided the design of persuasive technology. We performed a scoping review focused on the operationalization of social comparison theory as part of persuasive design. We chose social comparison due to its ubiquitous use in persuasive design as well as its potential positive or negative influence on the user. The former requires careful consideration in a persuasive design prototype. We focused on the proceedings of the Persuasive Technology conference from 2006 to 2020 to gain an understanding of the use of social comparison theory as part of persuasive design. Twelve studies met our inclusion criteria. Explanations of how the theory guides design decisions leading to the final operationalization were sparse. We suggest that conducting manipulation checks and using a systematic approach to reporting design decisions including the potential grounding of design elements in theory could highlight and clarify theoretical insights, and could increase our understanding of how social comparison—and behavior change theory in general—could be efficiently operationalized in persuasive technologies.},
  archive      = {J_FCOMP},
  author       = {Lemke, Mailin and de Vries, Roelof A. J.},
  doi          = {10.3389/fcomp.2021.656873},
  journal      = {Frontiers in Computer Science},
  month        = {4},
  pages        = {656873},
  shortjournal = {Front. Comput. Sci.},
  title        = {Operationalizing behavior change theory as part of persuasive technology: A scoping review on social comparison},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Comparing the emergence of technical and social sciences
research in artificial intelligence. <em>FCOMP</em>, <em>3</em>, 653235.
(<a href="https://doi.org/10.3389/fcomp.2021.653235">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Applications of Artificial Intelligence (AI) can be examined from perspectives of different disciplines and research areas ranging from computer science and security, engineering, policymaking, and sociology. The technical scholarship of emerging technologies usually precedes the discussion of their societal implications but can benefit from social science insight in scientific development. Therefore, there is an urgent need for scientists and engineers developing AI algorithms and applications to actively engage with scholars in the social sciences. Without collaborative engagement, developers may encounter resistance to the approval and adoption of their technological advancements. This paper reviews a dataset, collected by Elsevier from the Scopus database, of papers on AI application published between 1997 and 2018, and examines how the co-development of technical and social science communities has grown throughout AI&#39;s earliest to latest stages of development. Thus far, more AI research exists that combines social science and technical explorations than AI scholarship of social sciences alone, and both categories are dwarfed by technical research. Moreover, we identify a relative absence of AI research related to its societal implications such as governance, ethics, or moral implications of the technology. The future of AI scholarship will benefit from both technical and social science examinations of the discipline&#39;s risk assessment, governance, and public engagement needs, to foster advances in AI that are sustainable, risk-informed, and societally beneficial.},
  archive      = {J_FCOMP},
  author       = {Ligo, Alexandre K. and Rand, Krista and Bassett, Jason and Galaitsi, S. E. and Trump, Benjamin D. and Jayabalasingham, Bamini and Collins, Thomas and Linkov, Igor},
  doi          = {10.3389/fcomp.2021.653235},
  journal      = {Frontiers in Computer Science},
  month        = {4},
  pages        = {653235},
  shortjournal = {Front. Comput. Sci.},
  title        = {Comparing the emergence of technical and social sciences research in artificial intelligence},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Analysis and classification of word co-occurrence networks
from alzheimer’s patients and controls. <em>FCOMP</em>, <em>3</em>,
649508. (<a href="https://doi.org/10.3389/fcomp.2021.649508">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we construct word co-occurrence networks from transcript data of controls and patients with potential Alzheimer’s disease using the ADReSS challenge dataset of spontaneous speech. We examine measures of the structure of these networks for significant differences, finding that networks from Alzheimer’s patients have a lower heterogeneity and centralization, but a higher edge density. We then use these measures, a network embedding method and some measures from the word frequency distribution to classify the transcripts into control or Alzheimer’s, and to estimate the cognitive test score of a participant based on the transcript. We find it is possible to distinguish between the AD and control networks on structure alone, achieving 66.7% accuracy on the test set, and to predict cognitive scores with a root mean squared error of 5.675. Using the network measures is more successful than using the network embedding method. However, if the networks are shuffled we find relatively few of the measures are different, indicating that word frequency drives many of the network properties. This observation is borne out by the classification experiments, where word frequency measures perform similarly to the network measures.},
  archive      = {J_FCOMP},
  author       = {Millington, Tristan and Luz, Saturnino},
  doi          = {10.3389/fcomp.2021.649508},
  journal      = {Frontiers in Computer Science},
  month        = {4},
  pages        = {649508},
  shortjournal = {Front. Comput. Sci.},
  title        = {Analysis and classification of word co-occurrence networks from alzheimer’s patients and controls},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Sonic seasoning and other multisensory influences on the
coffee drinking experience. <em>FCOMP</em>, <em>3</em>, 644054. (<a
href="https://doi.org/10.3389/fcomp.2021.644054">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The coffee drinking experience undoubtedly depends greatly on the quality of the coffee bean and the method of preparation. However, beyond the product-intrinsic qualities of the beverage itself, there are also a host of other product-extrinsic factors that have been shown to influence the coffee-drinking experience. This review summarizes the influence of everything from the multisensory atmosphere through to the sound of coffee preparation, and from the typeface on the coffee packaging through the drinking vessel. Furthermore, the emerging science around sonic seasoning, whereby specific pieces of music or soundscapes, either pre-composed or bespoke, are used to bring out specific aspects in the taste (e.g., sweetness or bitterness) or aroma/flavor (nutty, dark chocolate, dried fruit notes, etc.) of a coffee beverage is also discussed in depth. Relevant related research with other complex drinks such as beer and wine are also mentioned where relevant.},
  archive      = {J_FCOMP},
  author       = {Spence, Charles},
  doi          = {10.3389/fcomp.2021.644054},
  journal      = {Frontiers in Computer Science},
  month        = {4},
  pages        = {644054},
  shortjournal = {Front. Comput. Sci.},
  title        = {Sonic seasoning and other multisensory influences on the coffee drinking experience},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multimodal capture of patient behaviour for improved
detection of early dementia: Clinical feasibility and preliminary
results. <em>FCOMP</em>, <em>3</em>, 642633. (<a
href="https://doi.org/10.3389/fcomp.2021.642633">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Non-invasive automatic screening for Alzheimer’s disease has the potential to improve diagnostic accuracy while lowering healthcare costs. Previous research has shown that patterns in speech, language, gaze, and drawing can help detect early signs of cognitive decline. In this paper, we describe a highly multimodal system for unobtrusively capturing data during real clinical interviews conducted as part of cognitive assessments for Alzheimer’s disease. The system uses nine different sensor devices (smartphones, a tablet, an eye tracker, a microphone array, and a wristband) to record interaction data during a specialist’s first clinical interview with a patient, and is currently in use at Karolinska University Hospital in Stockholm, Sweden. Furthermore, complementary information in the form of brain imaging, psychological tests, speech therapist assessment, and clinical meta-data is also available for each patient. We detail our data-collection and analysis procedure and present preliminary findings that relate measures extracted from the multimodal recordings to clinical assessments and established biomarkers, based on data from 25 patients gathered thus far. Our findings demonstrate feasibility for our proposed methodology and indicate that the collected data can be used to improve clinical assessments of early dementia.},
  archive      = {J_FCOMP},
  author       = {Jonell, Patrik and Moëll, Birger and Håkansson, Krister and Henter, Gustav Eje and Kucherenko, Taras and Mikheeva, Olga and Hagman, Göran and Holleman, Jasper and Kivipelto, Miia and Kjellström, Hedvig and Gustafson, Joakim and Beskow, Jonas},
  doi          = {10.3389/fcomp.2021.642633},
  journal      = {Frontiers in Computer Science},
  month        = {4},
  pages        = {642633},
  shortjournal = {Front. Comput. Sci.},
  title        = {Multimodal capture of patient behaviour for improved detection of early dementia: Clinical feasibility and preliminary results},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Crossing the “cookie theft” corpus chasm: Applying what BERT
learns from outside data to the ADReSS challenge dementia detection
task. <em>FCOMP</em>, <em>3</em>, 642517. (<a
href="https://doi.org/10.3389/fcomp.2021.642517">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large amounts of labeled data are a prerequisite to training accurate and reliable machine learning models. However, in the medical domain in particular, this is also a stumbling block as accurately labeled data are hard to obtain. DementiaBank, a publicly available corpus of spontaneous speech samples from a picture description task widely used to study Alzheimer&#39;s disease (AD) patients&#39; language characteristics and for training classification models to distinguish patients with AD from healthy controls, is relatively small—a limitation that is further exacerbated when restricting to the balanced subset used in the Alzheimer&#39;s Dementia Recognition through Spontaneous Speech (ADReSS) challenge. We build on previous work showing that the performance of traditional machine learning models on DementiaBank can be improved by the addition of normative data from other sources, evaluating the utility of such extrinsic data to further improve the performance of state-of-the-art deep learning based methods on the ADReSS challenge dementia detection task. To this end, we developed a new corpus of professionally transcribed recordings from the Wisconsin Longitudinal Study (WLS), resulting in 1366 additional Cookie Theft Task transcripts, increasing the available training data by an order of magnitude. Using these data in conjunction with DementiaBank is challenging because the WLS metadata corresponding to these transcripts do not contain dementia diagnoses. However, cognitive status of WLS participants can be inferred from results of several cognitive tests including semantic verbal fluency available in WLS data. In this work, we evaluate the utility of using the WLS ‘controls’ (participants without indications of abnormal cognitive status), and these data in conjunction with inferred ‘cases’ (participants with such indications) for training deep learning models to discriminate between language produced by patients with dementia and healthy controls. We find that incorporating WLS data during training a BERT model on ADReSS data improves its performance on the ADReSS dementia detection task, supporting the hypothesis that incorporating WLS data adds value in this context. We also demonstrate that weighted cost functions and additional prediction targets may be effective ways to address issues arising from class imbalance and confounding effects due to data provenance.},
  archive      = {J_FCOMP},
  author       = {Guo, Yue and Li, Changye and Roan, Carol and Pakhomov, Serguei and Cohen, Trevor},
  doi          = {10.3389/fcomp.2021.642517},
  journal      = {Frontiers in Computer Science},
  month        = {4},
  pages        = {642517},
  shortjournal = {Front. Comput. Sci.},
  title        = {Crossing the “Cookie theft” corpus chasm: Applying what BERT learns from outside data to the ADReSS challenge dementia detection task},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Systematic evaluation of design choices for deep facial
action coding across pose. <em>FCOMP</em>, <em>3</em>, 636094. (<a
href="https://doi.org/10.3389/fcomp.2021.636094">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The performance of automated facial expression coding is improving steadily. Advances in deep learning techniques have been key to this success. While the advantage of modern deep learning techniques is clear, the contribution of critical design choices remains largely unknown, especially for facial action unit occurrence and intensity across pose. Using the The Facial Expression Recognition and Analysis 2017 (FERA 2017) database, which provides a common protocol to evaluate robustness to pose variation, we systematically evaluated design choices in pre-training, feature alignment, model size selection, and optimizer details. Informed by the findings, we developed an architecture that exceeds state-of-the-art on FERA 2017. The architecture achieved a 3.5% increase in F1 score for occurrence detection and a 5.8% increase in Intraclass Correlation (ICC) for intensity estimation. To evaluate the generalizability of the architecture to unseen poses and new dataset domains, we performed experiments across pose in FERA 2017 and across domains in Denver Intensity of Spontaneous Facial Action (DISFA) and the UNBC Pain Archive.},
  archive      = {J_FCOMP},
  author       = {Niinuma, Koichiro and Onal Ertugrul, Itir and Cohn, Jeffrey F. and Jeni, László A.},
  doi          = {10.3389/fcomp.2021.636094},
  journal      = {Frontiers in Computer Science},
  month        = {4},
  pages        = {636094},
  shortjournal = {Front. Comput. Sci.},
  title        = {Systematic evaluation of design choices for deep facial action coding across pose},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Urban play as catalyst for social wellbeing post-pandemic.
<em>FCOMP</em>, <em>3</em>, 634145. (<a
href="https://doi.org/10.3389/fcomp.2021.634145">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FCOMP},
  author       = {Innocent, Troy and Stevens, Quentin},
  doi          = {10.3389/fcomp.2021.634145},
  journal      = {Frontiers in Computer Science},
  month        = {4},
  pages        = {634145},
  shortjournal = {Front. Comput. Sci.},
  title        = {Urban play as catalyst for social wellbeing post-pandemic},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). RGB colors and ecological optics. <em>FCOMP</em>,
<em>3</em>, 630370. (<a
href="https://doi.org/10.3389/fcomp.2021.630370">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Object color space is highly structured due to optical constraints (radiant power non-negative, reflectance factors between zero and unity) and ecological context (daylight illuminant). In this setting trichromacy induces a natural geometry through a unique spectral tripartition. Different from null-context colorimetry, one gains two desirable relations: The colorimetric coordinates are coarse-grained spectral reflectance factors and there is a direct link to color experiences, since RGB–coordinates provide ostensive definitions. The framework allows one to deal with subtractive color mixture, source variation, effects of metamerism and relations between scenes and image data in a unified, structured manner. In ecological contexts, colors are effectively object properties. The formal framework is linear algebra and convex geometry. Applications in human biology, computer graphics, design, etc., are immediate.},
  archive      = {J_FCOMP},
  author       = {Koenderink, Jan and van Doorn, Andrea and Gegenfurtner, Karl},
  doi          = {10.3389/fcomp.2021.630370},
  journal      = {Frontiers in Computer Science},
  month        = {4},
  pages        = {630370},
  shortjournal = {Front. Comput. Sci.},
  title        = {RGB colors and ecological optics},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Longitudinal speech biomarkers for automated alzheimer’s
detection. <em>FCOMP</em>, <em>3</em>, 624694. (<a
href="https://doi.org/10.3389/fcomp.2021.624694">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce a novel audio processing architecture, the Open Voice Brain Model (OVBM), improving detection accuracy for Alzheimer&#39;s (AD) longitudinal discrimination from spontaneous speech. We also outline the OVBM design methodology leading us to such architecture, which in general can incorporate multimodal biomarkers and target simultaneously several diseases and other AI tasks. Key in our methodology is the use of multiple biomarkers complementing each other, and when two of them uniquely identify different subjects in a target disease we say they are orthogonal. We illustrate the OBVM design methodology by introducing sixteen biomarkers, three of which are orthogonal, demonstrating simultaneous above state-of-the-art discrimination for two apparently unrelated diseases such as AD and COVID-19. Depending on the context, throughout the paper we use OVBM indistinctly to refer to the specific architecture or to the broader design methodology. Inspired by research conducted at the MIT Center for Brain Minds and Machines (CBMM), OVBM combines biomarker implementations of the four modules of intelligence: The brain OS chunks and overlaps audio samples and aggregates biomarker features from the sensory stream and cognitive core creating a multi-modal graph neural network of symbolic compositional models for the target task. In this paper we apply the OVBM design methodology to the automated diagnostic of Alzheimer&#39;s Dementia (AD) patients, achieving above state-of-the-art accuracy of 93.8% using only raw audio, while extracting a personalized subject saliency map designed to longitudinally track relative disease progression using multiple biomarkers, 16 in the reported AD task. The ultimate aim is to help medical practice by detecting onset and treatment impact so that intervention options can be longitudinally tested. Using the OBVM design methodology, we introduce a novel lung and respiratory tract biomarker created using 200,000+ cough samples to pre-train a model discriminating cough cultural origin. Transfer Learning is subsequently used to incorporate features from this model into various other biomarker-based OVBM architectures. This biomarker yields consistent improvements in AD detection in all the starting OBVM biomarker architecture combinations we tried. This cough dataset sets a new benchmark as the largest audio health dataset with 30,000+ subjects participating in April 2020, demonstrating for the first time cough cultural bias.},
  archive      = {J_FCOMP},
  author       = {Laguarta, Jordi and Subirana, Brian},
  doi          = {10.3389/fcomp.2021.624694},
  journal      = {Frontiers in Computer Science},
  month        = {4},
  pages        = {624694},
  shortjournal = {Front. Comput. Sci.},
  title        = {Longitudinal speech biomarkers for automated alzheimer&#39;s detection},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Towards an automatic speech-based diagnostic test for
alzheimer’s disease. <em>FCOMP</em>, <em>3</em>, 624594. (<a
href="https://doi.org/10.3389/fcomp.2021.624594">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic Speech Recognition (ASR) is widely used in many applications and tools. Smartphones, video games, and cars are a few examples where people use ASR routinely and often daily. A less commonly used, but potentially very important arena for using ASR, is the health domain. For some people, the impact on life could be enormous. The goal of this work is to develop an easy-to-use, non-invasive, inexpensive speech-based diagnostic test for dementia that can easily be applied in a clinician’s office or even at home. While considerable work has been published along these lines, increasing dramatically recently, it is primarily of theoretical value and not yet practical to apply. A large gap exists between current scientific understanding, and the creation of a diagnostic test for dementia. The aim of this paper is to bridge this gap between theory and practice by engineering a practical test. Experimental evidence suggests that strong discrimination between subjects with a diagnosis of probable Alzheimer’s vs. matched normal controls can be achieved with a combination of acoustic features from speech, linguistic features extracted from a transcription of the speech, and results of a mini mental state exam. A fully automatic speech recognition system tuned for the speech-to-text aspect of this application, including automatic punctuation, is also described.},
  archive      = {J_FCOMP},
  author       = {Sadeghian, Roozbeh and Schaffer, J. David and Zahorian, Stephen A.},
  doi          = {10.3389/fcomp.2021.624594},
  journal      = {Frontiers in Computer Science},
  month        = {4},
  pages        = {624594},
  shortjournal = {Front. Comput. Sci.},
  title        = {Towards an automatic speech-based diagnostic test for alzheimer’s disease},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Empathy cannot sustain action in technology accessibility.
<em>FCOMP</em>, <em>3</em>, 617044. (<a
href="https://doi.org/10.3389/fcomp.2021.617044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FCOMP},
  author       = {Horton, Sarah},
  doi          = {10.3389/fcomp.2021.617044},
  journal      = {Frontiers in Computer Science},
  month        = {4},
  pages        = {617044},
  shortjournal = {Front. Comput. Sci.},
  title        = {Empathy cannot sustain action in technology accessibility},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). How the visual design of video game antagonists affects
perception of morality. <em>FCOMP</em>, <em>3</em>, 531713. (<a
href="https://doi.org/10.3389/fcomp.2021.531713">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The visual design of antagonists—typically thought of as “bad guys”—is crucial for game design. Antagonists are key to providing the backdrop to a game&#39;s setting and motivating a player&#39;s actions. The visual representation of antagonists is important because it affects player expectations about the character&#39;s personality and potential actions. Particularly important is how players perceive an antagonist&#39;s morality. For example, an antagonist appearing disloyal might foreshadow betrayal; a character who looks cruel suggests that tough fights are ahead; or, a player might be surprised when a friendly looking character attacks them. Today, the art of designing character morality is informed by archetypal elements, existing characters, and the artist&#39;s own background. However, little work has provided insight into how an antagonist&#39;s appearance can lead players to make moral judgments. Using Mechanical Turk, we collected participant ratings on a stimulus image set of 105 antagonists from popular video games. The results of our work provide insights into how the visual attributes of antagonists can influence judgments of character morality. Our findings provide a valuable new lens for understanding and deepening an important aspect of game design. Our results can be used to help ensure that a particular character design has the best chance to be universally seen as “evil,” or to help create more complex and conflicted emotional experiences through carefully designed characters that do not appear to be bad. Our research extends current research practices that seek to build an understanding of game design and provides exciting new directions for exploring how design and aesthetic practices can be better studied and supported.},
  archive      = {J_FCOMP},
  author       = {Pradantyo, Reyhan and Birk, Max V. and Bateman, Scott},
  doi          = {10.3389/fcomp.2021.531713},
  journal      = {Frontiers in Computer Science},
  month        = {4},
  pages        = {531713},
  shortjournal = {Front. Comput. Sci.},
  title        = {How the visual design of video game antagonists affects perception of morality},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Disruption in chinese e-commerce during COVID-19.
<em>FCOMP</em>, <em>3</em>, 668711. (<a
href="https://doi.org/10.3389/fcomp.2021.668711">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The recent outbreak of the novel coronavirus (COVID-19) has infected millions of citizens worldwide and claimed many lives. This paper examines the impact of COVID-19 on Chinese e-commerce by analyzing behavioral changes observed on a large online shopping platform. We first conduct a time series analysis to identify product categories that faced the most extensive disruptions. The time-lagged analysis shows that behavioral patterns of shopping actions are highly responsive to the epidemic&#39;s development. Based on these findings, we present a consumer demand prediction method by encompassing the epidemic statistics and behavioral features of COVID-19-related products. Experimental results demonstrate that our predictions outperform existing baselines and further extend to long-term and province-level forecasts. Finally, we discuss how our market analysis and prediction can help better prepare for future pandemics by gaining extra time to launch preventive measures.},
  archive      = {J_FCOMP},
  author       = {Yuan, Yuan and Guan, Muzhi and Zhou, Zhilun and Kim, Sundong and Cha, Meeyoung and Jin, Depeng and Li, Yong},
  doi          = {10.3389/fcomp.2021.668711},
  journal      = {Frontiers in Computer Science},
  month        = {3},
  pages        = {668711},
  shortjournal = {Front. Comput. Sci.},
  title        = {Disruption in chinese E-commerce during COVID-19},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The use of brain–computer interfaces in games is not ready
for the general public. <em>FCOMP</em>, <em>3</em>, 628773. (<a
href="https://doi.org/10.3389/fcomp.2021.628773">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FCOMP},
  author       = {Cattan, Grégoire},
  doi          = {10.3389/fcomp.2021.628773},
  journal      = {Frontiers in Computer Science},
  month        = {3},
  pages        = {628773},
  shortjournal = {Front. Comput. Sci.},
  title        = {The use of Brain–Computer interfaces in games is not ready for the general public},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Recognition of alzheimer’s dementia from the transcriptions
of spontaneous speech using fastText and CNN models. <em>FCOMP</em>,
<em>3</em>, 624558. (<a
href="https://doi.org/10.3389/fcomp.2021.624558">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Alzheimer’s dementia (AD) is a type of neurodegenerative disease that is associated with a decline in memory. However, speech and language impairments are also common in Alzheimer’s dementia patients. This work is an extension of our previous work, where we had used spontaneous speech for Alzheimer’s dementia recognition employing log-Mel spectrogram and Mel-frequency cepstral coefficients (MFCC) as inputs to deep neural networks (DNN). In this work, we explore the transcriptions of spontaneous speech for dementia recognition and compare the results with several baseline results. We explore two models for dementia recognition: 1) fastText and 2) convolutional neural network (CNN) with a single convolutional layer, to capture the n-gram-based linguistic information from the input sentence. The fastText model uses a bag of bigrams and trigrams along with the input text to capture the local word orderings. In the CNN-based model, we try to capture different n-grams (we use n = 2, 3, 4, 5) present in the text by adapting the kernel sizes to n. In both fastText and CNN architectures, the word embeddings are initialized using pretrained GloVe vectors. We use bagging of 21 models in each of these architectures to arrive at the final model using which the performance on the test data is assessed. The best accuracies achieved with CNN and fastText models on the text data are 79.16 and 83.33%, respectively. The best root mean square errors (RMSE) on the prediction of mini-mental state examination (MMSE) score are 4.38 and 4.28 for CNN and fastText, respectively. The results suggest that the n-gram-based features are worth pursuing, for the task of AD detection. fastText models have competitive results when compared to several baseline methods. Also, fastText models are shallow in nature and have the advantage of being faster in training and evaluation, by several orders of magnitude, compared to deep models.},
  archive      = {J_FCOMP},
  author       = {Meghanani, Amit and Anoop, C. S. and Ramakrishnan, Angarai Ganesan},
  doi          = {10.3389/fcomp.2021.624558},
  journal      = {Frontiers in Computer Science},
  month        = {3},
  pages        = {624558},
  shortjournal = {Front. Comput. Sci.},
  title        = {Recognition of alzheimer’s dementia from the transcriptions of spontaneous speech using fastText and CNN models},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multisensory experiences: A primer. <em>FCOMP</em>,
<em>3</em>, 614524. (<a
href="https://doi.org/10.3389/fcomp.2021.614524">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a primer on multisensory experiences, the different components of this concept, as well as a reflection of its implications for individuals and society. We define multisensory experiences, illustrate how to understand them, elaborate on the role of technology in such experiences, and present the three laws of multisensory experiences, which can guide discussion on their implications. Further, we introduce the case of multisensory experiences in the context of eating and human-food interaction to illustrate how its components operationalize. We expect that this article provides a first point of contact for those interested in multisensory experiences, as well as multisensory experiences in the context of human-food interaction.},
  archive      = {J_FCOMP},
  author       = {Velasco, Carlos and Obrist, Marianna},
  doi          = {10.3389/fcomp.2021.614524},
  journal      = {Frontiers in Computer Science},
  month        = {3},
  pages        = {614524},
  shortjournal = {Front. Comput. Sci.},
  title        = {Multisensory experiences: A primer},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Cyber hygiene maturity assessment framework for smart grid
scenarios. <em>FCOMP</em>, <em>3</em>, 614337. (<a
href="https://doi.org/10.3389/fcomp.2021.614337">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cyber hygiene is a relatively new paradigm premised on the idea that organizations and stakeholders are able to achieve additional robustness and overall cybersecurity strength by implementing and following sound security practices. It is a preventive approach entailing high organizational culture and education for information cybersecurity to enhance resilience and protect sensitive data. In an attempt to achieve high resilience of Smart Grids against negative impacts caused by different types of common, predictable but also uncommon, unexpected, and uncertain threats and keep entities safe, the Secure and PrivatE smArt gRid (SPEAR) Horizon 2020 project has created an organization-wide cyber hygiene policy and developed a Cyber Hygiene Maturity assessment Framework (CHMF). This article presents the assessment framework for evaluating Cyber Hygiene Level (CHL) in relation to the Smart Grids. Complementary to the SPEAR Cyber Hygiene Maturity Model (CHMM), we propose a self-assessment methodology based on a questionnaire for Smart Grid cyber hygiene practices evaluation. The result of the assessment can be used as a cyber-health check to define countermeasures and to reapprove cyber hygiene rules and security standards and specifications adopted by the Smart Grid operator organization. The proposed methodology is one example of a resilient approach to cybersecurity. It can be applied for the assessment of the CHL of Smart Grids operating organizations with respect to a number of recommended good practices in cyber hygiene.},
  archive      = {J_FCOMP},
  author       = {Skarga-Bandurova, Inna and Kotsiuba, Igor and Velasco, Erkuden Rios},
  doi          = {10.3389/fcomp.2021.614337},
  journal      = {Frontiers in Computer Science},
  month        = {3},
  pages        = {614337},
  shortjournal = {Front. Comput. Sci.},
  title        = {Cyber hygiene maturity assessment framework for smart grid scenarios},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A declarative model for web accessibility requirements and
its implementation. <em>FCOMP</em>, <em>3</em>, 605772. (<a
href="https://doi.org/10.3389/fcomp.2021.605772">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The web has become the primary source of information for many people. Many services are provided on the web. Despite extensive guidelines for the accessibility of web pages, many websites are not accessible, making these websites difficult or impossible to use for people with disabilities. Evaluating the accessibility of web pages can either be done manually, which is a very laborious task, or by using automated tools. Unfortunately, the results from different tools are often inconsistent because of the ambiguity of the current guidelines. In this paper, a declarative approach for describing the requirements for accessible web pages is presented. This declarative model can help developers of accessibility evaluation tools to create tools that produce more consistent results and are easier to maintain.},
  archive      = {J_FCOMP},
  author       = {Pelzetter, Jens},
  doi          = {10.3389/fcomp.2021.605772},
  journal      = {Frontiers in Computer Science},
  month        = {3},
  pages        = {605772},
  shortjournal = {Front. Comput. Sci.},
  title        = {A declarative model for web accessibility requirements and its implementation},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Influencing followership: Understanding the perspective of
those leading active discussions on quora. <em>FCOMP</em>, <em>3</em>,
582242. (<a href="https://doi.org/10.3389/fcomp.2021.582242">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As social media influence become increasingly popular, understanding why some posts are highly followed than others, especially from the perspective of those leading the discussion allows us to gain insight on how followership is being influenced. A qualitative study of eight participants leading active discussions on Quora was conducted using semi-structured in-depth interviews, followed by thematic analysis. The open coding method was used to iteratively code related answers to develop themes. Results suggest that copyright tactics, controversial answers and sharing new information are some of the mechanisms for influencing followership. These mechanisms are built overtime through conscious strong engagement and by writing a consistently well-thought-out answer. The motivation for leading and writing answers on Quora were more intrinsic than extrinsic, and most participants believed influencing followership should not be a concern if one has the right message.},
  archive      = {J_FCOMP},
  author       = {Nwadiugwu, Martin C. and Nwadiugwu, Cynthia C.},
  doi          = {10.3389/fcomp.2021.582242},
  journal      = {Frontiers in Computer Science},
  month        = {3},
  pages        = {582242},
  shortjournal = {Front. Comput. Sci.},
  title        = {Influencing followership: Understanding the perspective of those leading active discussions on quora},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Phishing attacks: A recent comprehensive study and a new
anatomy. <em>FCOMP</em>, <em>3</em>, 563060. (<a
href="https://doi.org/10.3389/fcomp.2021.563060">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the significant growth of internet usage, people increasingly share their personal information online. As a result, an enormous amount of personal information and financial transactions become vulnerable to cybercriminals. Phishing is an example of a highly effective form of cybercrime that enables criminals to deceive users and steal important data. Since the first reported phishing attack in 1990, it has been evolved into a more sophisticated attack vector. At present, phishing is considered one of the most frequent examples of fraud activity on the Internet. Phishing attacks can lead to severe losses for their victims including sensitive information, identity theft, companies, and government secrets. This article aims to evaluate these attacks by identifying the current state of phishing and reviewing existing phishing techniques. Studies have classified phishing attacks according to fundamental phishing mechanisms and countermeasures discarding the importance of the end-to-end lifecycle of phishing. This article proposes a new detailed anatomy of phishing which involves attack phases, attacker’s types, vulnerabilities, threats, targets, attack mediums, and attacking techniques. Moreover, the proposed anatomy will help readers understand the process lifecycle of a phishing attack which in turn will increase the awareness of these phishing attacks and the techniques being used; also, it helps in developing a holistic anti-phishing system. Furthermore, some precautionary countermeasures are investigated, and new strategies are suggested.},
  archive      = {J_FCOMP},
  author       = {Alkhalil, Zainab and Hewage, Chaminda and Nawaf, Liqaa and Khan, Imtiaz},
  doi          = {10.3389/fcomp.2021.563060},
  journal      = {Frontiers in Computer Science},
  month        = {3},
  pages        = {563060},
  shortjournal = {Front. Comput. Sci.},
  title        = {Phishing attacks: A recent comprehensive study and a new anatomy},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Mobile pulmonary rehabilitation: Feasibility of delivery by
a mobile phone-based program. <em>FCOMP</em>, <em>3</em>, 546960. (<a
href="https://doi.org/10.3389/fcomp.2021.546960">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Background: Pulmonary rehabilitation (PR) has been proven effective but is not well accessed due to transport, time, cost, and physical limitations of patients. We have developed a mobile phone-based PR program (mPR) that could be offered as an alternative for those unable to attend in-person. This was developed following formative research with patients, their families and clinicians. mPR has a core text message program plus an app that includes an action plan, exercise videos, lung visualization, symptom score questionnaire and 1-min sit-to-stand test.Aims: To determine the feasibility of delivering pulmonary rehabilitation by mobile phone.Methods: A 9-week non-randomized (1-arm) pilot study was conducted. Participants were 26 adults with chronic obstructive pulmonary disease plus four family members, who were offered participation at first assessment or during group PR sessions. Outcomes included satisfaction, engagement with the program, and perceived impacts.Results: Eight people (31%) opted for text messages only, and 18 (69%) chose text messages plus the app. Three people stopped the program early, 20 said they would recommend it to others, 19 said it helped them to feel more supported, 17 said it helped them to change their behavior.Conclusion: It is feasible to deliver PR support via mobile phone, including exercise prescription and support. Our mPR program was appreciated by a small number of people with chronic respiratory disorders and family members. Suggestions for improvements are being used to inform the further development of the program, which will then be tested for effectiveness. Registered with the Australia New Zealand Clinical Trials Registry ACTRN12619000884101 (www.anzctr.org.au).},
  archive      = {J_FCOMP},
  author       = {Whittaker, Robyn and Dobson, Rosie and Candy, Sarah and Tane, Taria and Burrowes, Kelly and Reeve, Julie and Tawhai, Merryn and Taylor, Denise and Robertson, Trina and Garrett, Jeffrey and Humphrey, Gayl and Brott, Tamzin and Khan, Sabaoon Raza and Hu, Feiyu and Warren, Jim},
  doi          = {10.3389/fcomp.2021.546960},
  journal      = {Frontiers in Computer Science},
  month        = {3},
  pages        = {546960},
  shortjournal = {Front. Comput. Sci.},
  title        = {Mobile pulmonary rehabilitation: Feasibility of delivery by a mobile phone-based program},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Monitoring systems for checking websites on accessibility.
<em>FCOMP</em>, <em>3</em>, 628770. (<a
href="https://doi.org/10.3389/fcomp.2021.628770">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Web accessibility monitoring systems support users in checking entire websites for accessibility issues. Although these tools can only check the compliance with some of the many success criteria of the Web Content Accessibility Guidelines, they can assist quality assurance personnel, web administrators and web authors to discover hotspots of barriers and overlooked accessibility issues in a continuous manner. These tools should be effective in identifying accessibility issues. Furthermore, they should motivate users, as this promotes employee productivity and increases interest in accessibility in general. In a comparative study, we applied four commercial monitoring systems on two of the Stuttgart Media University’s websites. The tools are: 1) The Accessibility module of Siteimprove from Siteimprove, 2) Pope Tech from Pope Tech, 3) WorldSpace Comply (now called axe Monitor) from Deque, and 4) ARC Monitoring from The Paciello Group. The criteria catalogue consists of functional criteria that we gleaned from literature and user experience criteria based on the User Experience Questionnaire. Based on a focus group consisting of experts of Stuttgart Media University, we derived individual weights for the criteria. The functional evaluation criteria are: Coverage of the website and the guidelines, completeness, correctness, support in locating errors, support for manual checks, degree of implementing gamification patterns, support for various input and report formats, and methodological support for the Website Accessibility Conformance Evaluation Methodology 1.0 and for the German procurement law for public authorities Barrierefreie Informationstechnik-Verordnung 2.0. For determination of the user experience criteria, we conducted exploratory think-aloud user tests (n = 15) using a coaching approach. Every participant tested all tools for 15 min (within-subject design). The participants completed post-test questionnaires, including the User Experience Questionnaire. According to our results, Siteimprove turned out to be the best tool for our purposes.},
  archive      = {J_FCOMP},
  author       = {Burkard, Andreas and Zimmermann, Gottfried and Schwarzer, Bettina},
  doi          = {10.3389/fcomp.2021.628770},
  journal      = {Frontiers in Computer Science},
  month        = {2},
  pages        = {628770},
  shortjournal = {Front. Comput. Sci.},
  title        = {Monitoring systems for checking websites on accessibility},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Learning language and acoustic models for identifying
alzheimer’s dementia from speech. <em>FCOMP</em>, <em>3</em>, 624659.
(<a href="https://doi.org/10.3389/fcomp.2021.624659">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Alzheimer’s dementia (AD) is a chronic neurodegenerative illness that manifests in a gradual decline of cognitive function. Early identification of AD is essential for managing the ensuing cognitive deficits, which may lead to a better prognostic outcome. Speech data can serve as a window into cognitive functioning and can be used to screen for early signs of AD. This paper describes methods for learning models using speech samples from the DementiaBank database, for identifying which subjects have Alzheimer’s dementia. We consider two machine learning tasks: 1) binary classification to distinguish patients from healthy controls, and 2) regression to estimate each subject’s Mini-Mental State Examination (MMSE) score. To develop models that can use acoustic and/or language features, we explore a variety of dimension reduction techniques, training algorithms, and fusion strategies. Our best performing classification model, using language features with dimension reduction and regularized logistic regression, achieves an accuracy of 85.4% on a held-out test set. On the regression task, a linear regression model trained on a reduced set of language features achieves a root mean square error (RMSE) of 5.62 on the test set. These results demonstrate the promise of using machine learning for detecting cognitive decline from speech in AD patients.},
  archive      = {J_FCOMP},
  author       = {Shah, Zehra and Sawalha, Jeffrey and Tasnim, Mashrura and Qi, Shi-ang and Stroulia, Eleni and Greiner, Russell},
  doi          = {10.3389/fcomp.2021.624659},
  journal      = {Frontiers in Computer Science},
  month        = {2},
  pages        = {624659},
  shortjournal = {Front. Comput. Sci.},
  title        = {Learning language and acoustic models for identifying alzheimer’s dementia from speech},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A mechanism to detect and prevent ethereum blockchain smart
contract reentrancy attacks. <em>FCOMP</em>, <em>3</em>, 598780. (<a
href="https://doi.org/10.3389/fcomp.2021.598780">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In Ethereum blockchain, smart contracts are immutable, public, and distributed. However, they are subject to many vulnerabilities stemming from coding errors made by developers. Seven cybersecurity incidents occurred in Ethereum smart contracts between 2016 and 2018, which led to financial losses estimated to be over US$ 289 million. Reentrancy vulnerability was the cause of two of these incidents, and the impacts went far beyond financial loss. Several reentrancy countermeasures are available, which are based on predefined patterns that are used to prevent vulnerability exploitation before the deployment of a smart contract; however, several limitations have been identified in these countermeasures. Motivated by all these issues, the objective of this article is to help developers improve the cybersecurity of smart contracts by proposing a solution that calculates the difference between the contract balance and the total balance of all participants in a smart contract before and after any operation in a transaction that changes its state. Proof-of-concept implementations show that this solution can provide a detection and prevention mechanism against reentrancy attacks during the execution of any smart contract.},
  archive      = {J_FCOMP},
  author       = {Alkhalifah, Ayman and Ng, Alex and Watters, Paul A. and Kayes, A. S. M.},
  doi          = {10.3389/fcomp.2021.598780},
  journal      = {Frontiers in Computer Science},
  month        = {2},
  pages        = {598780},
  shortjournal = {Front. Comput. Sci.},
  title        = {A mechanism to detect and prevent ethereum blockchain smart contract reentrancy attacks},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Blockchain security as “people security”: Applying
sociotechnical security to blockchain technology. <em>FCOMP</em>,
<em>2</em>, 599406. (<a
href="https://doi.org/10.3389/fcomp.2020.599406">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The notion that blockchains offer decentralized, “trustless” guarantees of security through technology is a fundamental misconception held by many advocates. This misconception hampers participants from understanding the security differences between public and private blockchains and adopting blockchain technology in suitable contexts. This paper introduces the notion of “people security” to argue that blockchains hold inherent limitations in offering accurate security guarantees to people as participants in blockchain-based infrastructure, due to the differing nature of the threats to participants reliant on blockchain as secure digital infrastructure, as well as the technical limitations between different types of blockchain architecture. This paper applies a sociotechnical security framework to assess the social, software, and infrastructural layers of blockchain applications to reconceptualize “blockchain security” as “people security.” A sociotechnical security analysis of existing macrosocial level blockchain systems surfaces discrepancies between the social, technical, and infrastructural layers of a blockchain network, the technical and governance decisions that characterize the network, and the expectations of, and threats to, participants using the network. The results identify a number of security and trust assumptions against various blockchain architectures, participants, and applications. Findings indicate that private blockchains have serious limitations for securing the interests of users in macrosocial contexts, due to their centralized nature. In contrast, public blockchains reveal trust and security shortcomings at the micro and meso-organizational levels, yet there is a lack of suitable desktop case studies by which to analyze sociotechnical security at the macrosocial level. These assumptions need to be further investigated and addressed in order for blockchain security to more accurately provide “people security”.},
  archive      = {J_FCOMP},
  author       = {Nabben, Kelsie},
  doi          = {10.3389/fcomp.2020.599406},
  journal      = {Frontiers in Computer Science},
  month        = {3},
  pages        = {599406},
  shortjournal = {Front. Comput. Sci.},
  title        = {Blockchain security as “People security”: Applying sociotechnical security to blockchain technology},
  volume       = {2},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Editorial: Creating evidence from real world patient digital
data. <em>FCOMP</em>, <em>2</em>, 636996. (<a
href="https://doi.org/10.3389/fcomp.2020.636996">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FCOMP},
  author       = {Nikles, Jane and Daza, Eric J. and McDonald, Suzanne and Hekler, Eric and Schork, Nicholas J.},
  doi          = {10.3389/fcomp.2020.636996},
  journal      = {Frontiers in Computer Science},
  month        = {2},
  pages        = {636996},
  shortjournal = {Front. Comput. Sci.},
  title        = {Editorial: Creating evidence from real world patient digital data},
  volume       = {2},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Editorial: Data-driven cognitive manufacturing—applications
in predictive maintenance and zero defect manufacturing. <em>FCOMP</em>,
<em>2</em>, 633850. (<a
href="https://doi.org/10.3389/fcomp.2020.633850">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FCOMP},
  author       = {Kiritsis, Dimitris and Lazaro, Oscar and Hodkiewicz, Melinda and Lee, Jay and Ni, Jun},
  doi          = {10.3389/fcomp.2020.633850},
  journal      = {Frontiers in Computer Science},
  month        = {2},
  pages        = {633850},
  shortjournal = {Front. Comput. Sci.},
  title        = {Editorial: Data-driven cognitive Manufacturing—Applications in predictive maintenance and zero defect manufacturing},
  volume       = {2},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Rapid transitions: Experiences with accessibility and
special education during the COVID-19 crisis. <em>FCOMP</em>,
<em>2</em>, 617006. (<a
href="https://doi.org/10.3389/fcomp.2020.617006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The ongoing outbreak of the Coronavirus Disease 2019 (COVID-19) and the ensuing preventative lock-down and shelter-in-place policies enacted around the world have caused unanticipated disruptions in the delivery of educational content and accessibility services to children, youth and adults with disabilities. The rapid move to online and remote learning, socialization, and therapeutic activities have surfaced some of the inadequacies of existing systems and infrastructures as well as opportunities for creating novel and accessible solutions. We conducted semi-structured remote interviews with nine special education teachers, therapists, community advocates, and individuals with disabilities to capture their perspectives on delivering services and supporting children and adults with disabilities and their families during the pandemic. Participants shared reflections on their experience and those who they serve during the initial phases of the COVID-19 crisis and the challenges and insights that this experience surfaced. Findings include a need to better support families in facilitating remote learning experiences for their children, developing tactile modes of engagement to complement online interactions, and the impact of a lack of contingency plans specifically to support people with disabilities and their families during crizes. The participants also described the lack of clarity about the future as one of the most difficult aspects of the pandemic. We conclude with a discussion of these findings and directions for future research.},
  archive      = {J_FCOMP},
  author       = {Long, Emily and Vijaykumar, Sruti and Gyi, Serena and Hamidi, Foad},
  doi          = {10.3389/fcomp.2020.617006},
  journal      = {Frontiers in Computer Science},
  month        = {2},
  pages        = {617006},
  shortjournal = {Front. Comput. Sci.},
  title        = {Rapid transitions: Experiences with accessibility and special education during the COVID-19 crisis},
  volume       = {2},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Verbal communication in robotics: A study on salient terms,
research fields and trends in the last decades based on a computational
linguistic analysis. <em>FCOMP</em>, <em>2</em>, 591164. (<a
href="https://doi.org/10.3389/fcomp.2020.591164">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Verbal communication is an expanding field in robotics showing a significant increase in both the industrial and research field. The application of verbal communication in robotics aims to reach a natural human-like interaction with robots. In this study, we investigated how salient terms related to verbal communication in robotics have evolved over the years, what are the topics that recur in the related literature, and what are their trends. The study is based on a computational linguistic analysis conducted on a database of 7,435 scientific publications over the last 2 decades. This comprehensive dataset was extracted from the Scopus database using specific key-words. Our results show how relevant terms of verbal communication evolved, which are the main coherent topics and how they have changed over the years. We highlighted positive and negative trends for the most coherent topics and the distribution over the years for the most significant ones. In particular, verbal communication resulted in being highly relevant for social robotics. Potentially, achieving natural verbal communication with a robot can have a great impact on the scientific, societal, and economic role of robotics in the future.},
  archive      = {J_FCOMP},
  author       = {Marin Vargas, Alessandro and Cominelli, Lorenzo and Dell’Orletta, Felice and Scilingo, Enzo Pasquale},
  doi          = {10.3389/fcomp.2020.591164},
  journal      = {Frontiers in Computer Science},
  month        = {2},
  pages        = {591164},
  shortjournal = {Front. Comput. Sci.},
  title        = {Verbal communication in robotics: A study on salient terms, research fields and trends in the last decades based on a computational linguistic analysis},
  volume       = {2},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Pauses for detection of alzheimer’s disease. <em>FCOMP</em>,
<em>2</em>, 624488. (<a
href="https://doi.org/10.3389/fcomp.2020.624488">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pauses, disfluencies and language problems in Alzheimer’s disease can be naturally modeled by fine-tuning Transformer-based pre-trained language models such as BERT and ERNIE. Using this method with pause-encoded transcripts, we achieved 89.6% accuracy on the test set of the ADReSS (Alzheimer’s Dementia Recognition through Spontaneous Speech) Challenge. The best accuracy was obtained with ERNIE, plus an encoding of pauses. Robustness is a challenge for large models and small training sets. Ensemble over many runs of BERT/ERNIE fine-tuning reduced variance and improved accuracy. We found that um was used much less frequently in Alzheimer’s speech, compared to uh. We discussed this interesting finding from linguistic and cognitive perspectives.},
  archive      = {J_FCOMP},
  author       = {Yuan, Jiahong and Cai, Xingyu and Bian, Yuchen and Ye, Zheng and Church, Kenneth},
  doi          = {10.3389/fcomp.2020.624488},
  journal      = {Frontiers in Computer Science},
  month        = {1},
  pages        = {624488},
  shortjournal = {Front. Comput. Sci.},
  title        = {Pauses for detection of alzheimer’s disease},
  volume       = {2},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Visualizing uncertainty for non-expert end users: The
challenge of the deterministic construal error. <em>FCOMP</em>,
<em>2</em>, 590232. (<a
href="https://doi.org/10.3389/fcomp.2020.590232">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There is a growing body of evidence that numerical uncertainty expressions can be used by non-experts to improve decision quality. Moreover, there is some evidence that similar advantages extend to graphic expressions of uncertainty. However, visualizing uncertainty introduces challenges as well. Here, we discuss key misunderstandings that may arise from uncertainty visualizations, in particular the evidence that users sometimes fail to realize that the graphic depicts uncertainty. Instead they have a tendency to interpret the image as representing some deterministic quantity. We refer to this as the deterministic construal error. Although there is now growing evidence for the deterministic construal error, few studies are designed to detect it directly because they inform participants upfront that the visualization expresses uncertainty. In a natural setting such cues would be absent, perhaps making the deterministic assumption more likely. Here we discuss the psychological roots of this key but underappreciated misunderstanding as well as possible solutions. This is a critical question because it is now clear that members of the public understand that predictions involve uncertainty and have greater trust when uncertainty is included. Moreover, they can understand and use uncertainty predictions to tailor decisions to their own risk tolerance, as long as they are carefully expressed, taking into account the cognitive processes involved.},
  archive      = {J_FCOMP},
  author       = {Joslyn, Susan and Savelli, Sonia},
  doi          = {10.3389/fcomp.2020.590232},
  journal      = {Frontiers in Computer Science},
  month        = {1},
  pages        = {590232},
  shortjournal = {Front. Comput. Sci.},
  title        = {Visualizing uncertainty for non-expert end users: The challenge of the deterministic construal error},
  volume       = {2},
  year         = {2021},
}
</textarea>
</details></li>
</ul>

</body>
</html>
