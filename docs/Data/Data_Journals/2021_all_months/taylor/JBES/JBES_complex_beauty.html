<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>JBES_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="jbes---76">JBES - 76</h2>
<ul>
<li><details>
<summary>
(2021). Correction. <em>JBES</em>, <em>39</em>(4), 1080. (<a
href="https://doi.org/10.1080/07350015.2021.1970572">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JBES},
  doi          = {10.1080/07350015.2021.1970572},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {10},
  number       = {4},
  pages        = {1080},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Correction},
  volume       = {39},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Closed-form multi-factor copula models with
observation-driven dynamic factor loadings. <em>JBES</em>,
<em>39</em>(4), 1066–1079. (<a
href="https://doi.org/10.1080/07350015.2020.1763806">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We develop new multi-factor dynamic copula models with time-varying factor loadings and observation-driven dynamics. The new models are highly flexible, scalable to high dimensions, and ensure positivity of covariance and correlation matrices. A closed-form likelihood expression allows for straightforward parameter estimation and likelihood inference. We apply the new model to a large panel of 100 U.S. stocks over the period 2001–2014. The proposed multi-factor structure is much better than existing (single-factor) models at describing stock return dependence dynamics in high-dimensions. The new factor models also improve one-step-ahead copula density forecasts and global minimum variance portfolio performance. Finally, we investigate different mechanisms to allocate firms into groups and find that a simple industry classification outperforms alternatives based on observable risk factors, such as size, value, or momentum.},
  archive      = {J_JBES},
  author       = {Anne Opschoor and André Lucas and István Barra and Dick van Dijk},
  doi          = {10.1080/07350015.2020.1763806},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {10},
  number       = {4},
  pages        = {1066-1079},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Closed-form multi-factor copula models with observation-driven dynamic factor loadings},
  volume       = {39},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Price dividend ratio and long-run stock returns: A
score-driven state space model. <em>JBES</em>, <em>39</em>(4),
1054–1065. (<a
href="https://doi.org/10.1080/07350015.2020.1763805">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract– In this article, we develop a general framework to analyze state space models with time-varying system matrices, where time variation is driven by the score of the conditional likelihood. We derive a new filter that allows for the simultaneous estimation of the state vector and of the time-varying matrices. We use this method to study the time-varying relationship between the price dividend ratio, expected stock returns and expected dividend growth in the United States since 1880. We find a significant increase in the long-run equilibrium value of the price dividend ratio over time, associated with a fall in the long-run expected rate of return on stocks. The latter can be attributed mainly to a decrease in the natural rate of interest, as the long-run risk premium has only slightly fallen.},
  archive      = {J_JBES},
  author       = {Davide Delle Monache and Ivan Petrella and Fabrizio Venditti},
  doi          = {10.1080/07350015.2020.1763805},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {10},
  number       = {4},
  pages        = {1054-1065},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Price dividend ratio and long-run stock returns: A score-driven state space model},
  volume       = {39},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A framework for eliciting, incorporating, and disciplining
identification beliefs in linear models. <em>JBES</em>, <em>39</em>(4),
1038–1053. (<a
href="https://doi.org/10.1080/07350015.2020.1753528">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To estimate causal effects from observational data, an applied researcher must impose beliefs. The instrumental variables exclusion restriction, for example, represents the belief that the instrument has no direct effect on the outcome of interest. Yet beliefs about instrument validity do not exist in isolation. Applied researchers often discuss the likely direction of selection and the potential for measurement error in their articles but lack formal tools for incorporating this information into their analyses. Failing to use all relevant information not only leaves money on the table; it runs the risk of leading to a contradiction in which one holds mutually incompatible beliefs about the problem at hand. To address these issues, we first characterize the joint restrictions relating instrument invalidity, treatment endogeneity, and non-differential measurement error in a workhorse linear model, showing how beliefs over these three dimensions are mutually constrained by each other and the data. Using this information, we propose a Bayesian framework to help researchers elicit their beliefs, incorporate them into estimation, and ensure their mutual coherence. We conclude by illustrating our framework in a number of examples drawn from the empirical microeconomics literature.},
  archive      = {J_JBES},
  author       = {Francis J. DiTraglia and Camilo García-Jimeno},
  doi          = {10.1080/07350015.2020.1753528},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {10},
  number       = {4},
  pages        = {1038-1053},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {A framework for eliciting, incorporating, and disciplining identification beliefs in linear models},
  volume       = {39},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Randomization tests for equality in dependence structure.
<em>JBES</em>, <em>39</em>(4), 1026–1037. (<a
href="https://doi.org/10.1080/07350015.2020.1753527">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We develop a new statistical procedure to test whether the dependence structure is identical between two groups. Rather than relying on a single index such as Pearson’s correlation coefficient or Kendall’s τ , we consider the entire dependence structure by investigating the dependence functions (copulas). The critical values are obtained by a modified randomization procedure designed to exploit asymptotic group invariance conditions. Implementation of the test is intuitive and simple, and does not require any specification of a tuning parameter or weight function. At the same time, the test exhibits excellent finite sample performance, with the null rejection rates almost equal to the nominal level even when the sample size is extremely small. Two empirical applications concerning the dependence between income and consumption, and the Brexit effect on European financial market integration are provided.},
  archive      = {J_JBES},
  author       = {Juwon Seo},
  doi          = {10.1080/07350015.2020.1753527},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {10},
  number       = {4},
  pages        = {1026-1037},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Randomization tests for equality in dependence structure},
  volume       = {39},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Generalized jump regressions for local moments.
<em>JBES</em>, <em>39</em>(4), 1015–1025. (<a
href="https://doi.org/10.1080/07350015.2020.1753526">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We develop new high-frequency-based inference procedures for analyzing the relationship between jumps in instantaneous moments of stochastic processes. The estimation consists of two steps: the nonparametric determination of the jumps as differences in local averages, followed by a minimum-distance type estimation of the parameters of interest under general loss functions that include both least-square and more robust quantile regressions as special cases. The resulting asymptotic distribution of the estimator, derived under an infill asymptotic setting, is highly nonstandard and generally not mixed normal. In addition, we establish the validity of a novel bootstrap algorithm for making feasible inference including bias-correction. The new methods are applied in a study on the relationship between trading intensity and spot volatility in the U.S. equity market at the time of important macroeconomic news announcement.},
  archive      = {J_JBES},
  author       = {Tim Bollerslev and Jia Li and Leonardo Salim Saker Chaves},
  doi          = {10.1080/07350015.2020.1753526},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {10},
  number       = {4},
  pages        = {1015-1025},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Generalized jump regressions for local moments},
  volume       = {39},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Discerning solution concepts for discrete games.
<em>JBES</em>, <em>39</em>(4), 1001–1014. (<a
href="https://doi.org/10.1080/07350015.2020.1753525">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The empirical analysis of discrete complete-information games has relied on behavioral restrictions in the form of solution concepts, such as Nash equilibrium. Choosing the right solution concept is crucial not just for the identification of payoff parameters, but also for the validity and informativeness of counterfactual exercises and policy implications. We say that a solution concept is discernible if it is possible to determine whether it generated the observed data on the players’ behavior and covariates. We propose a set of conditions that make it possible to discern solution concepts. In particular, our conditions are sufficient to tell whether the players’ choices emerged from Nash equilibria. We can also discriminate between rationalizable behavior, maxmin behavior, and collusive behavior. Finally, we identify the correlation structure of unobserved shocks in our model using a novel approach.},
  archive      = {J_JBES},
  author       = {Nail Kashaev and Bruno Salcedo},
  doi          = {10.1080/07350015.2020.1753525},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {10},
  number       = {4},
  pages        = {1001-1014},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Discerning solution concepts for discrete games},
  volume       = {39},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Inference in additively separable models with a
high-dimensional set of conditioning variables. <em>JBES</em>,
<em>39</em>(4), 984–1000. (<a
href="https://doi.org/10.1080/07350015.2020.1753524">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article studies nonparametric series estimation and inference for the effect of a single variable of interest x on an outcome y in the presence of potentially high-dimensional conditioning variables z . The context is an additively separable model E [ y ∣ ∣ x , z ] = g 0 ( x ) + h 0 ( z ) E [ y | x , z ] = g 0 ( x ) + h 0 ( z ) E[y|x,z]=g0(x)+h0(z) . The model is high-dimensional in the sense that the series of approximating functions for h 0 ( z ) can have more terms than the sample size, thereby allowing z potentially to have very many measured characteristics. The model is required to be approximately sparse: h 0 ( z ) can be approximated using only a small subset of series terms whose identities are unknown. This article proposes an estimation and inference method for g 0 ( x ) called Post-Nonparametric Double Selection , which is a generalization of Post-Double Selection . Rates of convergence and asymptotic normality for the estimator are derived and hold over a large class of sparse data-generating processes. A simulation study illustrates finite sample estimation properties of the proposed estimator and coverage properties of the corresponding confidence intervals. Finally, an empirical application to college admissions policy demonstrates the practical implementation of the proposed method.},
  archive      = {J_JBES},
  author       = {Damian Kozbur},
  doi          = {10.1080/07350015.2020.1753524},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {10},
  number       = {4},
  pages        = {984-1000},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Inference in additively separable models with a high-dimensional set of conditioning variables},
  volume       = {39},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Generic conditions for forecast dominance. <em>JBES</em>,
<em>39</em>(4), 972–983. (<a
href="https://doi.org/10.1080/07350015.2020.1741376">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent studies have analyzed whether one forecast method dominates another under a class of consistent scoring functions. While the existing literature focuses on empirical tests of forecast dominance, little is known about the theoretical conditions under which one forecast dominates another. To address this question, we derive a new characterization of dominance among forecasts of the mean functional. We present various scenarios under which dominance occurs. Unlike existing results, our results allow for the case that the forecasts’ underlying information sets are not nested, and allow for uncalibrated forecasts that suffer, for example, from model misspecification or parameter estimation error. We illustrate the empirical relevance of our results via data examples from finance and economics.},
  archive      = {J_JBES},
  author       = {Fabian Krüger and Johanna F. Ziegel},
  doi          = {10.1080/07350015.2020.1741376},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {10},
  number       = {4},
  pages        = {972-983},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Generic conditions for forecast dominance},
  volume       = {39},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Threshold regression with a threshold boundary.
<em>JBES</em>, <em>39</em>(4), 953–971. (<a
href="https://doi.org/10.1080/07350015.2020.1740712">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article studies computation, estimation, inference, and testing for linearity in threshold regression with a threshold boundary. We first put forward a new algorithm to ease the computation of the threshold boundary, and develop the asymptotics for the least squares estimator in both the fixed-threshold-effect framework and the small-threshold-effect framework. We also show that the inverting-likelihood-ratio method is not suitable to construct confidence sets for the threshold parameters, while the nonparametric posterior interval is still applicable. We then propose a new score-type test to test for the existence of threshold effects. Comparing with the usual Wald-type test, it is computationally less intensive, and its critical values are easier to obtain by the simulation method. Simulation studies corroborate the theoretical results. We finally conduct two empirical applications in labor economics to illustrate the nonconstancy of thresholds.},
  archive      = {J_JBES},
  author       = {Ping Yu and Xiaodong Fan},
  doi          = {10.1080/07350015.2020.1740712},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {10},
  number       = {4},
  pages        = {953-971},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Threshold regression with a threshold boundary},
  volume       = {39},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Measuring granger causality in quantiles. <em>JBES</em>,
<em>39</em>(4), 937–952. (<a
href="https://doi.org/10.1080/07350015.2020.1739531">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider measures of Granger causality in quantiles, which detect and quantify both linear and nonlinear causal effects between random variables. The measures are based on nonparametric quantile regressions and defined as logarithmic functions of restricted and unrestricted expectations of quantile check loss functions. They can consistently be estimated by replacing the unknown expectations of check loss functions by their nonparametric kernel estimates. We derive a Bahadur-type representation for the nonparametric estimator of the measures. We establish the asymptotic distribution of this estimator, which can be used to build tests for the statistical significance of the measures. Thereafter, we show the validity of a smoothed local bootstrap that can be used in finite-sample settings to perform statistical tests. A Monte Carlo simulation study reveals that the bootstrap-based test has a good finite-sample size and power properties for a variety of data-generating processes and different sample sizes. Finally, we provide an empirical application to illustrate the usefulness of measuring Granger causality in quantiles. We quantify the degree of predictability of the quantiles of equity risk premium using the variance risk premium, unemployment rate, inflation, and the effective federal funds rate. The empirical results show that the variance risk premium and effective federal funds rate have a strong predictive power for predicting the risk premium when compared to that of the predictive power of the other two macro variables. In particular, the variance risk premium is able to predict the center, lower, and upper quantiles of the distribution of the risk premium; however, the effective federal funds rate predicts only the lower and upper quantiles. Nevertheless, unemployment and inflation rates have no effect on the risk premium.},
  archive      = {J_JBES},
  author       = {Xiaojun Song and Abderrahim Taamouti},
  doi          = {10.1080/07350015.2020.1739531},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {10},
  number       = {4},
  pages        = {937-952},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Measuring granger causality in quantiles},
  volume       = {39},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A score-driven conditional correlation model for noisy and
asynchronous data: An application to high-frequency covariance dynamics.
<em>JBES</em>, <em>39</em>(4), 920–936. (<a
href="https://doi.org/10.1080/07350015.2020.1739530">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The analysis of the intraday dynamics of covariances among high-frequency returns is challenging due to asynchronous trading and market microstructure noise. Both effects lead to significant data reduction and may severely affect the estimation of the covariances if traditional methods for low-frequency data are employed. We propose to model intraday log-prices through a multivariate local-level model with score-driven covariance matrices and to treat asynchronicity as a missing value problem. The main advantages of this approach are: (i) all available data are used when filtering the covariances, (ii) market microstructure noise is taken into account, (iii) estimation is performed by standard maximum likelihood. Our empirical analysis, performed on 1-sec NYSE data, shows that opening hours are dominated by idiosyncratic risk and that a market factor progressively emerges in the second part of the day. The method can be used as a nowcasting tool for high-frequency data, allowing to study the real-time response of covariances to macro-news announcements and to build intraday portfolios with very short optimization horizons.},
  archive      = {J_JBES},
  author       = {Giuseppe Buccheri and Giacomo Bormetti and Fulvio Corsi and Fabrizio Lillo},
  doi          = {10.1080/07350015.2020.1739530},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {10},
  number       = {4},
  pages        = {920-936},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {A score-driven conditional correlation model for noisy and asynchronous data: An application to high-frequency covariance dynamics},
  volume       = {39},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Testing the multivariate regular variation model.
<em>JBES</em>, <em>39</em>(4), 907–919. (<a
href="https://doi.org/10.1080/07350015.2020.1737533">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we propose a test for the multivariate regular variation (MRV) model. The test is based on testing whether the extreme value indices of the radial component conditional on the angular component falling in different subsets are the same. Combining the test on the constancy across extreme value indices in different directions with testing the regular variation of the radial component, we obtain the test for testing MRV. Simulation studies demonstrate the good performance of the proposed tests. We apply this test to examine two datasets used in previous studies that are assumed to follow the MRV model.},
  archive      = {J_JBES},
  author       = {John H. J. Einmahl and Fan Yang and Chen Zhou},
  doi          = {10.1080/07350015.2020.1737533},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {10},
  number       = {4},
  pages        = {907-919},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Testing the multivariate regular variation model},
  volume       = {39},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Dynamic bivariate peak over threshold model for joint tail
risk dynamics of financial markets. <em>JBES</em>, <em>39</em>(4),
892–906. (<a
href="https://doi.org/10.1080/07350015.2020.1737083">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a novel dynamic bivariate peak over threshold (PoT) model to study the time-varying behavior of joint tail risk in financial markets. The proposed framework provides simultaneous modeling for dynamics of marginal and joint tail risk, and generalizes the existing tail risk literature from univariate dimension to multivariate dimension. We introduce a natural and interpretable tail connectedness measure and examine the dynamics of joint tail behavior of global stock markets: empirical evidence suggests markets from the same continent have time-varying and high-level joint tail risk, and tail connectedness increases during periods of crisis. We further enrich the tail risk literature by developing a novel portfolio optimization procedure based on bivariate joint tail risk minimization, which gives promising risk-rewarding performance in backtesting.},
  archive      = {J_JBES},
  author       = {Zifeng Zhao},
  doi          = {10.1080/07350015.2020.1737083},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {10},
  number       = {4},
  pages        = {892-906},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Dynamic bivariate peak over threshold model for joint tail risk dynamics of financial markets},
  volume       = {39},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A discussion of “text selection.” <em>JBES</em>,
<em>39</em>(4), 888–891. (<a
href="https://doi.org/10.1080/07350015.2021.1961785">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Kelly, Manela, and Moreira provided an economic model of word choice in text. A writer is modeled as someone who is first choosing whether to use a word at all (selection problem) and then deciding how often a selected word should be used (positive counts problem). The resulting model leads to better sufficient reduction for large number of words/phrases in the text as demonstrated many diverse applications that use information captured from the text of the front page of the Wall Street Journal such as back-casting regulatory capital ratio of banks, and forecasting and nowcasting U.S. macroeconomic variables. Researchers interested in quantifying information in text will benefit from reading the article and thinking about some of the issues raised in the article. I provide background, context from other foundational papers, a very short summary of the article, and make some broad observations in my discussion.},
  archive      = {J_JBES},
  author       = {Nitish Ranjan Sinha},
  doi          = {10.1080/07350015.2021.1961785},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {10},
  number       = {4},
  pages        = {888-891},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {A discussion of “Text selection”},
  volume       = {39},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Discussion on “text selection.” <em>JBES</em>,
<em>39</em>(4), 883–887. (<a
href="https://doi.org/10.1080/07350015.2021.1942890">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This is a discussion on the paper &quot;Text Selection&quot; by Kelly et al. (2021).},
  archive      = {J_JBES},
  author       = {Xiaofei Xu and Ying Chen and Steven Kou},
  doi          = {10.1080/07350015.2021.1942890},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {10},
  number       = {4},
  pages        = {883-887},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Discussion on “Text selection”},
  volume       = {39},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Discussion of “text selection” by bryan kelly, asaf manela,
and alan moreira. <em>JBES</em>, <em>39</em>(4), 880–882. (<a
href="https://doi.org/10.1080/07350015.2021.1948420">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JBES},
  author       = {Markus Pelger},
  doi          = {10.1080/07350015.2021.1948420},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {10},
  number       = {4},
  pages        = {880-882},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Discussion of “Text selection” by bryan kelly, asaf manela, and alan moreira},
  volume       = {39},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Text selection. <em>JBES</em>, <em>39</em>(4), 859–879. (<a
href="https://doi.org/10.1080/07350015.2021.1947843">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Text data is ultra-high dimensional, which makes machine learning techniques indispensable for textual analysis. Text is often selected—journalists, speechwriters, and others craft messages to target their audiences’ limited attention. We develop an economically motivated high-dimensional selection model that improves learning from text (and from sparse counts data more generally). Our model is especially useful when the choice to include a phrase is more interesting than the choice of how frequently to repeat it. It allows for parallel estimation, making it computationally scalable. A first application revisits the partisanship of the U.S. congressional speech. We find that earlier spikes in partisanship manifested in increased repetition of different phrases, whereas the upward trend starting in the 1990s is due to distinct phrase selection. Additional applications show how our model can backcast, nowcast, and forecast macroeconomic indicators using newspaper text, and that it substantially improves out-of-sample fit relative to alternative approaches.},
  archive      = {J_JBES},
  author       = {Bryan Kelly and Asaf Manela and Alan Moreira},
  doi          = {10.1080/07350015.2021.1947843},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {10},
  number       = {4},
  pages        = {859-879},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Text selection},
  volume       = {39},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Who is the key player? A network analysis of juvenile
delinquency. <em>JBES</em>, <em>39</em>(3), 849–857. (<a
href="https://doi.org/10.1080/07350015.2020.1737082">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article presents a methodology for empirically identifying the key player, whose removal from the network leads to the optimal change in aggregate activity level in equilibrium [Ballester, C., Calvó-Armengol, A., and Zenou, Y. (2006), “Who’s Who in Networks. Wanted: The Key Player,” Econometrica , 74: 1403–1417], allowing the network links to rewire after the removal of the key player. First, we propose an IV-based estimation strategy for the social-interaction effect, which is needed to determine the equilibrium activity level of a network, taking into account the potential network endogeneity. Next, to simulate the network evolution process after the removal of the key player, we adopt the general network formation model in Mele [( Citation 2017 ), “A Structural Model of Dense Network Formation,” Econometrica , 85: 825–850] and extend it to incorporate the unobserved individual heterogeneity in link formation decisions. We illustrate the methodology by providing the key player rankings in juvenile delinquency using information on friendship networks among U.S. teenagers. We find that the key player is not necessarily the most active delinquent or the delinquent who ranks the highest in standard (not microfounded) centrality measures. We also find that, compared to a policy that removes the most active delinquent from the network, a key-player-targeted policy leads to a much higher delinquency reduction.},
  archive      = {J_JBES},
  author       = {Lung-Fei Lee and Xiaodong Liu and Eleonora Patacchini and Yves Zenou},
  doi          = {10.1080/07350015.2020.1737082},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {7},
  number       = {3},
  pages        = {849-857},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Who is the key player? a network analysis of juvenile delinquency},
  volume       = {39},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A correction for regression discontinuity designs with
group-specific mismeasurement of the running variable. <em>JBES</em>,
<em>39</em>(3), 833–848. (<a
href="https://doi.org/10.1080/07350015.2020.1737081">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When the running variable in a regression discontinuity (RD) design is measured with error, identification of the local average treatment effect of interest will typically fail. While the form of this measurement error varies across applications, in many cases the measurement error structure is heterogeneous across different groups of observations. We develop a novel measurement error correction procedure capable of addressing heterogeneous mismeasurement structures by leveraging auxiliary information. We also provide adjusted asymptotic variance and standard errors that take into consideration the variability introduced by the estimation of nuisance parameters, and honest confidence intervals that account for potential misspecification. Simulations provide evidence that the proposed procedure corrects the bias introduced by heterogeneous measurement error and achieves empirical coverage closer to nominal test size than “naive” alternatives. Two empirical illustrations demonstrate that correcting for measurement error can either reinforce the results of a study or provide a new empirical perspective on the data.},
  archive      = {J_JBES},
  author       = {Otávio Bartalotti and Quentin Brummet and Steven Dieterle},
  doi          = {10.1080/07350015.2020.1737081},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {7},
  number       = {3},
  pages        = {833-848},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {A correction for regression discontinuity designs with group-specific mismeasurement of the running variable},
  volume       = {39},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Nonparametric tests for treatment effect heterogeneity with
duration outcomes. <em>JBES</em>, <em>39</em>(3), 816–832. (<a
href="https://doi.org/10.1080/07350015.2020.1737080">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article proposes different tests for treatment effect heterogeneity when the outcome of interest, typically a duration variable, may be right-censored. The proposed tests study whether a policy (1) has zero distributional (average) effect for all subpopulations defined by covariate values, and (2) has homogeneous average effect across different subpopulations. The proposed tests are based on two-step Kaplan–Meier integrals and do not rely on parametric distributional assumptions, shape restrictions, or on restricting the potential treatment effect heterogeneity across different subpopulations. Our framework is suitable not only to exogenous treatment allocation but can also account for treatment noncompliance—an important feature in many applications. The proposed tests are consistent against fixed alternatives, and can detect nonparametric alternatives converging to the null at the parametric n − 1 / 2 -rate, n being the sample size. Critical values are computed with the assistance of a multiplier bootstrap. The finite sample properties of the proposed tests are examined by means of a Monte Carlo study and an application about the effect of labor market programs on unemployment duration. Open-source software is available for implementing all proposed tests.},
  archive      = {J_JBES},
  author       = {Pedro H. C. Sant’Anna},
  doi          = {10.1080/07350015.2020.1737080},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {7},
  number       = {3},
  pages        = {816-832},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Nonparametric tests for treatment effect heterogeneity with duration outcomes},
  volume       = {39},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An inverse norm sign test of location parameter for
high-dimensional data. <em>JBES</em>, <em>39</em>(3), 807–815. (<a
href="https://doi.org/10.1080/07350015.2020.1736084">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the one sample location testing problem for high-dimensional data, where the data dimension is potentially much larger than the sample size. We devise a novel inverse norm sign test (INST) that is consistent and has much improved power than many existing popular tests. We further construct a general class of weighted spatial sign tests which includes these existing tests, and show that INST is the optimal member within this class, in that it is consistent and is uniformly more powerful than all other members. We establish the asymptotic null distribution and local power property of the class of tests rigorously. Extensive numerical experiments demonstrate the superiority of INST in terms of both efficiency and robustness.},
  archive      = {J_JBES},
  author       = {Long Feng and Binghui Liu and Yanyuan Ma},
  doi          = {10.1080/07350015.2020.1736084},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {7},
  number       = {3},
  pages        = {807-815},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {An inverse norm sign test of location parameter for high-dimensional data},
  volume       = {39},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Semiparametric estimation in continuous-time: Asymptotics
for integrated volatility functionals with small and large bandwidths.
<em>JBES</em>, <em>39</em>(3), 793–806. (<a
href="https://doi.org/10.1080/07350015.2020.1733583">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article studies the estimation of integrated volatility functionals, which is a semiparametric two-step estimation problem in the nonstationary continuous-time setting. We generalize the asymptotic normality results of Jacod and Rosenbaum to a wider range of bandwidths. Moreover, we employ matrix calculus to obtain a new analytical bias correction and variance estimation method. The proposed method gives more succinct expressions than the element-by-element analytical method of the above cited article. In addition, it has a computational advantage over the jackknife/simulation-based method proposed by Li, Liu, and Xiu. Comprehensive simulation studies demonstrate that our method has good finite sample performance for a variety of volatility functionals, including quadraticity, determinant, continuous beta, and eigenvalues.},
  archive      = {J_JBES},
  author       = {Xiye Yang},
  doi          = {10.1080/07350015.2020.1733583},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {7},
  number       = {3},
  pages        = {793-806},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Semiparametric estimation in continuous-time: Asymptotics for integrated volatility functionals with small and large bandwidths},
  volume       = {39},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Incorporating graphical structure of predictors in sparse
quantile regression. <em>JBES</em>, <em>39</em>(3), 783–792. (<a
href="https://doi.org/10.1080/07350015.2020.1730859">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quantile regression in high-dimensional settings is useful in analyzing high-dimensional heterogeneous data. In this article, different from existing methods in quantile regression which treat all the predictors equally with the same priori, we take advantage of the graphical structure among predictors to improve the performance of parameter estimation, model selection, and prediction in sparse quantile regression. It is shown under mild conditions that the proposed method enjoys the model selection consistency and the oracle properties. An alternating direction method of multipliers algorithm with a linearization technique is proposed to implement the proposed method numerically, and its convergence is justified. Simulation studies are conducted, showing that the proposed method is superior to existing methods in terms of estimation accuracy and predictive power. The proposed method is also applied to a real dataset.},
  archive      = {J_JBES},
  author       = {Zhanfeng Wang and Xianhui Liu and Wenlu Tang and Yuanyuan Lin},
  doi          = {10.1080/07350015.2020.1730859},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {7},
  number       = {3},
  pages        = {783-792},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Incorporating graphical structure of predictors in sparse quantile regression},
  volume       = {39},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A generalized method of moments estimator for structural
vector autoregressions based on higher moments. <em>JBES</em>,
<em>39</em>(3), 772–782. (<a
href="https://doi.org/10.1080/07350015.2020.1730858">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {I propose a generalized method of moments estimator for structural vector autoregressions with independent and non-Gaussian shocks. The shocks are identified by exploiting information contained in higher moments of the data. Extending the standard identification approach, which relies on the covariance, to the coskewness and cokurtosis allows the simultaneous interaction to be identified and estimated without any further restrictions. I analyze the finite sample properties of the estimator and apply it to illustrate the simultaneous interaction between economic activity, oil, and stock prices. Supplementary materials for this article are available online.},
  archive      = {J_JBES},
  author       = {Sascha Alexander Keweloh},
  doi          = {10.1080/07350015.2020.1730858},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {7},
  number       = {3},
  pages        = {772-782},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {A generalized method of moments estimator for structural vector autoregressions based on higher moments},
  volume       = {39},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Dynamic semiparametric factor model with structural breaks.
<em>JBES</em>, <em>39</em>(3), 757–771. (<a
href="https://doi.org/10.1080/07350015.2020.1730857">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For the change-point analysis of a high-dimensional time series, we consider a semiparametric model with dynamic structural break factors. With our model, the observations are described by a few low-dimensional factors with time-invariant loading functions of the covariates. Regarding the structural break, the factors are assumed to be nonstationary and follow a vector autoregression process with a change in the parameter values. In addition, to account for the known spatial discrepancies, we introduce discrete loading functions. We study the theoretical properties of the estimates of the loading functions and the factors. Moreover, we provide both the consistency and the asymptotic normality for making an inference on the estimated breakpoint. Importantly, our results hold for both large and small breaks in the factor dependency structure. The estimation precision is further illustrated via a simulation study. Finally, we present two empirical applications in modeling the dynamics of the minimum wage policy in China and analyzing a limit order book dataset. Supplementary materials for this article are available online.},
  archive      = {J_JBES},
  author       = {Likai Chen and Weining Wang and Wei Biao Wu},
  doi          = {10.1080/07350015.2020.1730857},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {7},
  number       = {3},
  pages        = {757-771},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Dynamic semiparametric factor model with structural breaks},
  volume       = {39},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Nonparametric quantile regression estimation with mixed
discrete and continuous data. <em>JBES</em>, <em>39</em>(3), 741–756.
(<a href="https://doi.org/10.1080/07350015.2020.1730856">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we investigate the problem of nonparametrically estimating a conditional quantile function with mixed discrete and continuous covariates. A local linear smoothing technique combining both continuous and discrete kernel functions is introduced to estimate the conditional quantile function. We propose using a fully data-driven cross-validation approach to choose the bandwidths, and further derive the asymptotic optimality theory. In addition, we also establish the asymptotic distribution and uniform consistency (with convergence rates) for the local linear conditional quantile estimators with the data-dependent optimal bandwidths. Simulations show that the proposed approach compares well with some existing methods. Finally, an empirical application with the data taken from the IMDb website is presented to analyze the relationship between box office revenues and online rating scores. Supplementary materials for this article are available online.},
  archive      = {J_JBES},
  author       = {Degui Li and Qi Li and Zheng Li},
  doi          = {10.1080/07350015.2020.1730856},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {7},
  number       = {3},
  pages        = {741-756},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Nonparametric quantile regression estimation with mixed discrete and continuous data},
  volume       = {39},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multidimensional economic dispersion index and application.
<em>JBES</em>, <em>39</em>(3), 729–740. (<a
href="https://doi.org/10.1080/07350015.2020.1730185">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Gini index is widely used in economics as a measure of inequality with respect to income or wealth. However, it is not applicable when we consider evaluating the inequality level using more than one social resources. To comprehensively evaluate the social inequality level, we propose a multidimensional economic dispersion index (MEDI) based on the Lorenz hyper-surface determined by the distributions of multiple social resources. The MEDI is a natural extension of the Gini index and is equivalent to the Gini index in the presence of only one resource. We propose an estimator for the MEDI with good statistical properties and develop an algorithm to calculate the estimate. We further apply the MEDI for an empirical analysis to evaluate the social inequality level of Chinese provincial capitals. The results reveal some interesting phenomena of Chinese social inequalities and also demonstrate how the MEDI captures more information in complex economic situations than the classical Gini index.},
  archive      = {J_JBES},
  author       = {Yifan Xia and Ling Zhang and Iris L. Li},
  doi          = {10.1080/07350015.2020.1730185},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {7},
  number       = {3},
  pages        = {729-740},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Multidimensional economic dispersion index and application},
  volume       = {39},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Bayesian inference for regression copulas. <em>JBES</em>,
<em>39</em>(3), 712–728. (<a
href="https://doi.org/10.1080/07350015.2020.1721295">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a new semiparametric distributional regression smoother that is based on a copula decomposition of the joint distribution of the vector of response values. The copula is high-dimensional and constructed by inversion of a pseudo regression, where the conditional mean and variance are semiparametric functions of covariates modeled using regularized basis functions. By integrating out the basis coefficients, an implicit copula process on the covariate space is obtained, which we call a “regression copula.” We combine this with a nonparametric margin to define a copula model, where the entire distribution—including the mean and variance—of the response is a smooth semiparametric function of the covariates. The copula is estimated using both Hamiltonian Monte Carlo and variational Bayes; the latter of which is scalable to high dimensions. Using real data examples and a simulation study, we illustrate the efficacy of these estimators and the copula model. In a substantive example, we estimate the distribution of half-hourly electricity spot prices as a function of demand and two time covariates using radial bases and horseshoe regularization. The copula model produces distributional estimates that are locally adaptive with respect to the covariates, and predictions that are more accurate than those from benchmark models. Supplementary materials for this article are available online.},
  archive      = {J_JBES},
  author       = {Michael Stanley Smith and Nadja Klein},
  doi          = {10.1080/07350015.2020.1721295},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {7},
  number       = {3},
  pages        = {712-728},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Bayesian inference for regression copulas},
  volume       = {39},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Varying-coefficient panel data models with nonstationarity
and partially observed factor structure. <em>JBES</em>, <em>39</em>(3),
700–711. (<a
href="https://doi.org/10.1080/07350015.2020.1721294">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we study a varying-coefficient panel data model with both nonstationarity and partially observed factor structure. Two approaches are proposed. The first approach proposed in the main text considers a sieve based method to estimate the unknown coefficients as well as the factors and loading functions simultaneously, while the second approach proposed in the online supplementary document involving the principal component analysis provides an alternative estimation method. We establish asymptotic properties for them, compare the asymptotic efficiency of the two estimation methods and examine the theoretical findings through extensive Monte Carlo simulations. In an empirical study, we use our newly proposed model and the first method to study the returns to scale of large U.S. commercial banks, where some overlooked modeling issues in the literature of production econometrics are addressed. Supplementary materials for this article are available online.},
  archive      = {J_JBES},
  author       = {Chaohua Dong and Jiti Gao and Bin Peng},
  doi          = {10.1080/07350015.2020.1721294},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {7},
  number       = {3},
  pages        = {700-711},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Varying-coefficient panel data models with nonstationarity and partially observed factor structure},
  volume       = {39},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Unified tests for a dynamic predictive regression.
<em>JBES</em>, <em>39</em>(3), 684–699. (<a
href="https://doi.org/10.1080/07350015.2020.1714632">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Testing for predictability of asset returns has been a long history in economics and finance. Recently, based on a simple predictive regression, Kostakis, Magdalinos, and Stamatogiannis derived a Wald type test based on the context of the extended instrumental variable (IVX) methodology for testing predictability of stock returns, and Demetrescu showed that the local power of the standard IVX-based test could be improved for some range of alternative hypotheses and the tuning parameter when a lagged predicted variable is added to the predictive regression on purpose, which poses an important question on whether the predictive model should include a lagged predicted variable. This article proposes novel robust procedures for testing both the existence of a lagged predicted variable and the predictability of asset returns regardless of regressors being stationary or nearly integrated or unit root and the AR model for regressors with or without an intercept. A simulation study confirms the good finite sample performance of the proposed tests before illustrating their practical usefulness in analyzing real financial datasets.},
  archive      = {J_JBES},
  author       = {Bingduo Yang and Xiaohui Liu and Liang Peng and Zongwu Cai},
  doi          = {10.1080/07350015.2020.1714632},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {7},
  number       = {3},
  pages        = {684-699},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Unified tests for a dynamic predictive regression},
  volume       = {39},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Inducing sparsity and shrinkage in time-varying parameter
models. <em>JBES</em>, <em>39</em>(3), 669–683. (<a
href="https://doi.org/10.1080/07350015.2020.1713796">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time-varying parameter (TVP) models have the potential to be over-parameterized, particularly when the number of variables in the model is large. Global-local priors are increasingly used to induce shrinkage in such models. But the estimates produced by these priors can still have appreciable uncertainty. Sparsification has the potential to reduce this uncertainty and improve forecasts. In this article, we develop computationally simple methods which both shrink and sparsify TVP models. In a simulated data exercise, we show the benefits of our shrink-then-sparsify approach in a variety of sparse and dense TVP regressions. In a macroeconomic forecasting exercise, we find our approach to substantially improve forecast performance relative to shrinkage alone.},
  archive      = {J_JBES},
  author       = {Florian Huber and Gary Koop and Luca Onorante},
  doi          = {10.1080/07350015.2020.1713796},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {7},
  number       = {3},
  pages        = {669-683},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Inducing sparsity and shrinkage in time-varying parameter models},
  volume       = {39},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Fitting vast dimensional time-varying covariance models.
<em>JBES</em>, <em>39</em>(3), 652–668. (<a
href="https://doi.org/10.1080/07350015.2020.1713795">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Estimation of time-varying covariances is a key input in risk management and asset allocation. ARCH-type multivariate models are used widely for this purpose. Estimation of such models is computationally costly and parameter estimates are meaningfully biased when applied to a moderately large number of assets. Here, we propose a novel estimation approach that suffers from neither of these issues, even when the number of assets is in the hundreds. The theory of this new method is developed in some detail. The performance of the proposed method is investigated using extensive simulation studies and empirical examples. Supplementary materials for this article are available online.},
  archive      = {J_JBES},
  author       = {Cavit Pakel and Neil Shephard and Kevin Sheppard and Robert F. Engle},
  doi          = {10.1080/07350015.2020.1713795},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {7},
  number       = {3},
  pages        = {652-668},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Fitting vast dimensional time-varying covariance models},
  volume       = {39},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). What happens after an investment spike—investment events and
firm performance. <em>JBES</em>, <em>39</em>(3), 636–651. (<a
href="https://doi.org/10.1080/07350015.2019.1708369">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Our study aims at investigating the relationship between investment spikes and subsequent productivity development at the firm level. We propose a novel identification scheme for the effects of an investment spike, using matching techniques and a tailored econometric modeling. It allows us to find efficiency differentials against matched firms in periods adjacent to the spike. We showed that TFP persistently falls after an investment spike, which is consistent with learning-by-doing models of firm decisions. As a result of capital deepening labor productivity actually rises after a spike. The capital deepening of larger firms is smaller and although the responses of TFP across size classes are similar, the labor productivity rise of smaller firms is more pronounced. Moreover, the positive correlation of responses of labor and K / L in periods after a spike shows that investments spikes induce complementarity between production factors.},
  archive      = {J_JBES},
  author       = {Michał Gradzewicz},
  doi          = {10.1080/07350015.2019.1708369},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {7},
  number       = {3},
  pages        = {636-651},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {What happens after an investment Spike—Investment events and firm performance},
  volume       = {39},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Dynamic two stage modeling for category-level and
brand-level purchases using potential outcome approach with bayes
inference. <em>JBES</em>, <em>39</em>(3), 622–635. (<a
href="https://doi.org/10.1080/07350015.2019.1702047">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose an econometric two-stage model for category-level purchase and brand-level purchase that allows for simultaneous brand purchases in the analysis of scanner panel data. The proposed model formulation is consistent with the traditional theory of consumer behavior. We conduct Bayesian estimation with the Markov chain Monte Carlo algorithm for our proposed model. The simulation studies show that previously proposed related models can cause severe bias in predicting future brand choices, while the proposed method can effectively predict them. Additionally in a marketing application, the proposed method can examine brand switching behaviors that existing methods cannot. Moreover, we show that the prediction accuracy of the proposed method is higher than that of existing methods.},
  archive      = {J_JBES},
  author       = {Kei Miyazaki and Takahiro Hoshino and Ulf Böckenholt},
  doi          = {10.1080/07350015.2019.1702047},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {7},
  number       = {3},
  pages        = {622-635},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Dynamic two stage modeling for category-level and brand-level purchases using potential outcome approach with bayes inference},
  volume       = {39},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). High-frequency lead-lag effects and cross-asset linkages: A
multi-asset lagged adjustment model. <em>JBES</em>, <em>39</em>(3),
605–621. (<a
href="https://doi.org/10.1080/07350015.2019.1697699">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Motivated by the empirical evidence of high-frequency lead-lag effects and cross-asset linkages, we introduce a multi-asset price formation model which generalizes standard univariate microstructure models of lagged price adjustment. Econometric inference on such model provides: (i) a unified statistical test for the presence of lead-lag correlations in the latent price process and for the existence of a multi-asset price formation mechanism; (ii) separate estimation of contemporaneous and lagged dependencies; (iii) an unbiased estimator of the integrated covariance of the efficient martingale price process that is robust to microstructure noise, asynchronous trading, and lead-lag dependencies. Through an extensive simulation study, we compare the proposed estimator to alternative approaches and show its advantages in recovering the true lead-lag structure of the latent price process. Our application to a set of NYSE stocks provides empirical evidence for the existence of a multi-asset price formation mechanism and sheds light on its market microstructure determinants. Supplementary materials for this article are available online.},
  archive      = {J_JBES},
  author       = {Giuseppe Buccheri and Fulvio Corsi and Stefano Peluso},
  doi          = {10.1080/07350015.2019.1697699},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {7},
  number       = {3},
  pages        = {605-621},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {High-frequency lead-lag effects and cross-asset linkages: A multi-asset lagged adjustment model},
  volume       = {39},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Exponential-type GARCH models with linear-in-variance risk
premium. <em>JBES</em>, <em>39</em>(2), 589–603. (<a
href="https://doi.org/10.1080/07350015.2019.1691564">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the implications of the intertemporal capital asset pricing model is that the risk premium of the market portfolio is a linear function of its variance. Yet, estimation theory of classical GARCH-in-mean models with linear-in-variance risk premium requires strong assumptions and is incomplete. We show that exponential-type GARCH models such as EGARCH or Log-GARCH are more natural in dealing with linear-in-variance risk premia. For the popular and more difficult case of EGARCH-in-mean, we derive conditions for the existence of a unique stationary and ergodic solution and invertibility following a stochastic recurrence equation approach. We then show consistency and asymptotic normality of the quasi-maximum likelihood estimator under weak moment assumptions. An empirical application estimates the dynamic risk premia of a variety of stock indices using both EGARCH-M and Log-GARCH-M models. Supplementary materials for this article are available online.},
  archive      = {J_JBES},
  author       = {Christian M. Hafner and Dimitra Kyriakopoulou},
  doi          = {10.1080/07350015.2019.1691564},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {3},
  number       = {2},
  pages        = {589-603},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Exponential-type GARCH models with linear-in-variance risk premium},
  volume       = {39},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Copula-based random effects models for clustered data.
<em>JBES</em>, <em>39</em>(2), 575–588. (<a
href="https://doi.org/10.1080/07350015.2019.1688665">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In a binary choice panel data framework, probabilities of the outcomes of several individuals depend on the correlation of the unobserved heterogeneity. I propose a random effects estimator that models the correlation of the unobserved heterogeneity among individuals in the same cluster using a copula. I discuss the asymptotic efficiency of the estimator relative to standard random effects estimators, and to choose the copula I propose a specification test. The implementation of the estimator requires the numerical approximation of high-dimensional integrals, for which I propose an algorithm that works for Archimedean copulas that does not suffer from the curse of dimensionality. This method is illustrated with an application of labor supply in married couples, finding that about one half of the difference in probability of a woman being employed when her husband is also employed, relative to those whose husband is unemployed, is explained by correlation in the unobservables. Supplementary materials for this article are available online.},
  archive      = {J_JBES},
  author       = {Santiago Pereda-Fernández},
  doi          = {10.1080/07350015.2019.1688665},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {3},
  number       = {2},
  pages        = {575-588},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Copula-based random effects models for clustered data},
  volume       = {39},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Equality-minded treatment choice. <em>JBES</em>,
<em>39</em>(2), 561–574. (<a
href="https://doi.org/10.1080/07350015.2019.1688664">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The goal of many randomized experiments and quasi-experimental studies in economics is to inform policies that aim to raise incomes and reduce economic inequality. A policy maximizing the sum of individual incomes may not be desirable if it magnifies economic inequality and post-treatment redistribution of income is infeasible. This article develops a method to estimate the optimal treatment assignment policy based on observable individual covariates when the policy objective is to maximize an equality-minded rank-dependent social welfare function , which puts higher weight on individuals with lower-ranked outcomes. We estimate the optimal policy by maximizing a sample analog of the rank-dependent welfare over a properly constrained set of policies. We show that the average social welfare attained by our estimated policy converges to the maximal attainable welfare at n − 1 / 2 rate uniformly over a large class of data distributions when the propensity score is known. We also show that this rate is minimax optimal. We provide an application of our method using the data from the National JTPA Study. Supplementary materials for this article are available online.},
  archive      = {J_JBES},
  author       = {Toru Kitagawa and Aleksey Tetenov},
  doi          = {10.1080/07350015.2019.1688664},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {3},
  number       = {2},
  pages        = {561-574},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Equality-minded treatment choice},
  volume       = {39},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The impact of food prices on conflict revisited.
<em>JBES</em>, <em>39</em>(2), 547–560. (<a
href="https://doi.org/10.1080/07350015.2019.1684301">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Studies that examine the impact of food prices on conflict usually assume that (all) changes in international food prices are exogenous shocks for individual countries or local areas. By isolating strictly exogenous shifts in global food commodity prices, we show that this assumption could seriously distort estimations of the impact on conflict in African regions. Specifically, we show that increases in food prices that are caused by harvest shocks outside Africa raise conflict significantly, whereas a “naive” regression of conflict on international food prices uncovers an inverse relationship. We also find that higher food prices lead to more conflict in regions with more agricultural production. Again, we document that failing to account for exogenous price changes exhibits a considerable bias in the impact. In addition, we show that the conventional approach to evaluate such effects; that is, estimations that include time fixed effects, ignores an important positive baseline effect that is common for all regions. Supplementary materials for this article are available online.},
  archive      = {J_JBES},
  author       = {Jasmien De Winne and Gert Peersman},
  doi          = {10.1080/07350015.2019.1684301},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {3},
  number       = {2},
  pages        = {547-560},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {The impact of food prices on conflict revisited},
  volume       = {39},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Sharp bounds on functionals of the joint distribution in the
analysis of treatment effects. <em>JBES</em>, <em>39</em>(2), 532–546.
(<a href="https://doi.org/10.1080/07350015.2019.1684300">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article proposes an identification and estimation method that allows researchers to bound continuous functionals of the joint distribution of potential outcomes from the literature on treatment effects. The focus is on a model where no restrictions are imposed on treatment selection. The method can sharply bound interesting parameters when analytical bounds are difficult to derive, can be used in settings in which instruments are available, and can easily accommodate additional model constraints. However, computational considerations for the method are found to be important and are discussed in detail. Supplementary materials for this article are available online.},
  archive      = {J_JBES},
  author       = {Thomas M. Russell},
  doi          = {10.1080/07350015.2019.1684300},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {3},
  number       = {2},
  pages        = {532-546},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Sharp bounds on functionals of the joint distribution in the analysis of treatment effects},
  volume       = {39},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A nodewise regression approach to estimating large
portfolios. <em>JBES</em>, <em>39</em>(2), 520–531. (<a
href="https://doi.org/10.1080/07350015.2019.1683018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article investigates the large sample properties of the variance, weights, and risk of high-dimensional portfolios where the inverse of the covariance matrix of excess asset returns is estimated using a technique called nodewise regression. Nodewise regression provides a direct estimator for the inverse covariance matrix using the least absolute shrinkage and selection operator to estimate the entries of a sparse precision matrix. We show that the variance, weights, and risk of the global minimum variance portfolios and the Markowitz mean-variance portfolios are consistently estimated with more assets than observations. We show, empirically, that the nodewise regression-based approach performs well in comparison to factor models and shrinkage methods. Supplementary materials for this article are available online.},
  archive      = {J_JBES},
  author       = {Laurent Callot and Mehmet Caner and A. Özlem Önder and Esra Ulaşan},
  doi          = {10.1080/07350015.2019.1683018},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {3},
  number       = {2},
  pages        = {520-531},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {A nodewise regression approach to estimating large portfolios},
  volume       = {39},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Wild bootstrap and asymptotic inference with multiway
clustering. <em>JBES</em>, <em>39</em>(2), 505–519. (<a
href="https://doi.org/10.1080/07350015.2019.1677473">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study two cluster-robust variance estimators (CRVEs) for regression models with clustering in two dimensions and give conditions under which t -statistics based on each of them yield asymptotically valid inferences. In particular, one of the CRVEs requires stronger assumptions about the nature of the intra-cluster correlations. We then propose several wild bootstrap procedures and state conditions under which they are asymptotically valid for each type of t -statistic. Extensive simulations suggest that using certain bootstrap procedures with one of the t -statistics generally performs very well. An empirical example confirms that bootstrap inferences can differ substantially from conventional ones.},
  archive      = {J_JBES},
  author       = {James G. MacKinnon and Morten Ørregaard Nielsen and Matthew D. Webb},
  doi          = {10.1080/07350015.2019.1677473},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {3},
  number       = {2},
  pages        = {505-519},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Wild bootstrap and asymptotic inference with multiway clustering},
  volume       = {39},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). High-dimensional macroeconomic forecasting using message
passing algorithms. <em>JBES</em>, <em>39</em>(2), 493–504. (<a
href="https://doi.org/10.1080/07350015.2019.1677472">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article proposes two distinct contributions to econometric analysis of large information sets and structural instabilities. First, it treats a regression model with time-varying coefficients, stochastic volatility, and exogenous predictors, as an equivalent high-dimensional static regression problem with thousands of covariates. Inference in this specification proceeds using Bayesian hierarchical priors that shrink the high-dimensional vector of coefficients either toward zero or time-invariance. Second, it introduces the frameworks of factor graphs and message passing as a means of designing efficient Bayesian estimation algorithms. In particular, a generalized approximate message passing algorithm is derived that has low algorithmic complexity and is trivially parallelizable. The result is a comprehensive methodology that can be used to estimate time-varying parameter regressions with arbitrarily large number of exogenous predictors. In a forecasting exercise for U.S. price inflation this methodology is shown to work very well. Supplementary materials for this article are available online.},
  archive      = {J_JBES},
  author       = {Dimitris Korobilis},
  doi          = {10.1080/07350015.2019.1677472},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {3},
  number       = {2},
  pages        = {493-504},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {High-dimensional macroeconomic forecasting using message passing algorithms},
  volume       = {39},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Gaussian processes and bayesian moment estimation.
<em>JBES</em>, <em>39</em>(2), 482–492. (<a
href="https://doi.org/10.1080/07350015.2019.1668799">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given a set of moment restrictions (MRs) that overidentify a parameter θ , we investigate a semiparametric Bayesian approach for inference on θ that does not restrict the data distribution F apart from the MRs. As main contribution, we construct a degenerate Gaussian process prior that, conditionally on θ , restricts the F generated by this prior to satisfy the MRs with probability one. Our prior works even in the more involved case where the number of MRs is larger than the dimension of θ . We demonstrate that the corresponding posterior for θ is computationally convenient. Moreover, we show that there exists a link between our procedure, the generalized empirical likelihood with quadratic criterion and the limited information likelihood-based procedures. We provide a frequentist validation of our procedure by showing consistency and asymptotic normality of the posterior distribution of θ . The finite sample properties of our method are illustrated through Monte Carlo experiments and we provide an application to demand estimation in the airline market.},
  archive      = {J_JBES},
  author       = {Jean-Pierre Florens and Anna Simoni},
  doi          = {10.1080/07350015.2019.1668799},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {3},
  number       = {2},
  pages        = {482-492},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Gaussian processes and bayesian moment estimation},
  volume       = {39},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The evolving impact of global, region-specific, and
country-specific uncertainty. <em>JBES</em>, <em>39</em>(2), 466–481.
(<a href="https://doi.org/10.1080/07350015.2019.1668798">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We develop a dynamic factor model with time-varying parameters and stochastic volatility, estimate it using a large panel of macroeconomic and financial data for 22 countries and decompose the variance of each variable in terms of contributions from uncertainty common to all countries (“global uncertainty”), region-specific uncertainty, and country-specific uncertainty. Among other findings, the estimates suggest that global uncertainty plays a primary role in explaining the volatility of inflation, interest rates, and stock prices, although to a varying extent over time, while all uncertainty components are found to play a nonnegligible role for real economic activity, credit, and money for most countries. Supplementary materials for this article are available online.},
  archive      = {J_JBES},
  author       = {Haroon Mumtaz and Alberto Musso},
  doi          = {10.1080/07350015.2019.1668798},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {3},
  number       = {2},
  pages        = {466-481},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {The evolving impact of global, region-specific, and country-specific uncertainty},
  volume       = {39},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Measuring asset market linkages: Nonlinear dependence and
tail risk. <em>JBES</em>, <em>39</em>(2), 453–465. (<a
href="https://doi.org/10.1080/07350015.2019.1668797">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional measures of dependence in time series are based on correlations or periodograms. These are adequate in many circumstances but, in others, especially when trying to assess market linkages and tail risk during abnormal times (e.g., financial contagion), they might be inappropriate. In particular, popular tail dependence measures based on exceedance correlations and marginal expected shortfall (MES) have large variances and also contain limited information on tail risk. Motivated by these limitations, we introduce the (tail-restricted) integrated regression function, and we show how it characterizes conditional dependence and persistence. We propose simple estimates for these measures and establish their asymptotic properties. We employ the proposed methods to analyze the dependence structure of some of the major international stock market indices before, during, and after the 2007–2009 financial crisis. Monte Carlo simulations and the application show that our new measures are more reliable and accurate than competing methods based on MES or exceedance correlations for testing tail dependence. Supplementary materials for this article are available online.},
  archive      = {J_JBES},
  author       = {Juan Carlos Escanciano and Javier Hualde},
  doi          = {10.1080/07350015.2019.1668797},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {3},
  number       = {2},
  pages        = {453-465},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Measuring asset market linkages: Nonlinear dependence and tail risk},
  volume       = {39},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Semiparametric GARCH via bayesian model averaging.
<em>JBES</em>, <em>39</em>(2), 437–452. (<a
href="https://doi.org/10.1080/07350015.2019.1668796">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the dynamic structure of financial markets is subject to dramatic change, a model capable of providing consistently accurate volatility estimates should not make rigid assumptions on how prices change over time. Most volatility models impose a particular parametric functional form that relates an observed price change to a volatility forecast (news impact function). Here, a new class of functional coefficient semiparametric volatility models is proposed, where the news impact function is allowed to be any smooth function. The ability of the proposed model to estimate volatility is studied and compared to the well-known parametric proposals, in both a simulation study and an empirical study with real financial market data. The news impact function is estimated using a Bayesian model averaging approach, implemented via a carefully developed Markov chain Monte Carlo sampling algorithm. Using simulations it is shown that the proposed flexible semiparametric model is able to learn the shape of the news impact function very effectively, from observed data. When applied to real financial time series, the proposed model suggests that news impact functions have quite different shapes over different asset types, but a consistent shape within the same asset class. Supplementary materials for this article are available online.},
  archive      = {J_JBES},
  author       = {Wilson Ye Chen and Richard H. Gerlach},
  doi          = {10.1080/07350015.2019.1668796},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {3},
  number       = {2},
  pages        = {437-452},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Semiparametric GARCH via bayesian model averaging},
  volume       = {39},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A framework for separating individual-level treatment
effects from spillover effects. <em>JBES</em>, <em>39</em>(2), 422–436.
(<a href="https://doi.org/10.1080/07350015.2019.1668795">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article suggests a causal framework for separating individual-level treatment effects and spillover effects such as general equilibrium, interference, or interaction effects related to treatment distribution. We relax the stable unit treatment value assumption assuming away treatment-dependent interaction between study participants and permit spillover effects within aggregates, for example, regions. Based on our framework, we systematically categorize the individual-level and spillover effects considered in the previous literature and clarify the assumptions required for identification under different designs, for instance, based on randomization or selection on observables. Furthermore, we propose a novel difference-in-differences approach and apply it to a policy intervention extending unemployment benefit durations in selected regions of Austria that arguably affected ineligibles in treated regions through general equilibrium effects in local labor markets.},
  archive      = {J_JBES},
  author       = {Martin Huber and Andreas Steinmayr},
  doi          = {10.1080/07350015.2019.1668795},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {3},
  number       = {2},
  pages        = {422-436},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {A framework for separating individual-level treatment effects from spillover effects},
  volume       = {39},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Identification of random resource shares in collective
households without preference similarity restrictions. <em>JBES</em>,
<em>39</em>(2), 402–421. (<a
href="https://doi.org/10.1080/07350015.2019.1665532">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Resource shares, defined as the fraction of total household spending going to each person in a household, are important for assessing individual material well-being, inequality, and poverty. They are difficult to identify because consumption is measured typically at the household level, and many goods are jointly consumed, so that individual level consumption in multi-person households is not directly observed. We consider random resource shares, which vary across observationally identical households. We provide theorems that identify the distribution of random resource shares across households, including children’s shares. We also provide a new method of identifying the level of fixed or random resource shares that does not require previously needed preference similarity restrictions or marriage market assumptions. Our results can be applied to data with or without price variation. We apply our results to households in Malawi, estimating the distributions of child and of female poverty across households.},
  archive      = {J_JBES},
  author       = {Geoffrey R. Dunbar and Arthur Lewbel and Krishna Pendakur},
  doi          = {10.1080/07350015.2019.1665532},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {3},
  number       = {2},
  pages        = {402-421},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Identification of random resource shares in collective households without preference similarity restrictions},
  volume       = {39},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Homogeneity pursuit in single index models based panel data
analysis. <em>JBES</em>, <em>39</em>(2), 386–401. (<a
href="https://doi.org/10.1080/07350015.2019.1665531">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Panel data analysis is an important topic in statistics and econometrics. Traditionally, in panel data analysis, all individuals are assumed to share the same unknown parameters, e.g. the same coefficients of covariates when the linear models are used, and the differences between the individuals are accounted for by cluster effects. This kind of modelling only makes sense if our main interest is on the global trend, this is because it would not be able to tell us anything about the individual attributes which are sometimes very important. In this paper, we propose a modelling based on the single index models embedded with homogeneity for panel data analysis, which builds the individual attributes in the model and is parsimonious at the same time. We develop a data driven approach to identify the structure of homogeneity, and estimate the unknown parameters and functions based on the identified structure. Asymptotic properties of the resulting estimators are established. Intensive simulation studies conducted in this paper also show the resulting estimators work very well when sample size is finite. Finally, the proposed modelling is applied to a public financial dataset and a UK climate dataset, the results reveal some interesting findings.},
  archive      = {J_JBES},
  author       = {Heng Lian and Xinghao Qiao and Wenyang Zhang},
  doi          = {10.1080/07350015.2019.1665531},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {3},
  number       = {2},
  pages        = {386-401},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Homogeneity pursuit in single index models based panel data analysis},
  volume       = {39},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Semiparametric estimation of first-price auction models.
<em>JBES</em>, <em>39</em>(2), 373–385. (<a
href="https://doi.org/10.1080/07350015.2019.1665530">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we propose a two-step semiparametric procedure to estimate first-price auction models. In the first step, we estimate the bid density and distribution using local polynomial method, and recover a sample of (pseudo) private values. In the second step, we apply the method of moments to the sample of private values to estimate a finite set of parameters that characterize the density of private values. We show that our estimator attains the parametric consistency rate and is asymptotically normal. And we also determine its asymptotic variance. The advantage of our approach is that it can accommodate multiple auction covariates. Monte Carlo exercises show that the estimator performs well both in estimating the value density and in choosing the revenue maximizing reserve price. Supplementary materials for this article are available online.},
  archive      = {J_JBES},
  author       = {Gaurab Aryal and Maria F. Gabrielli and Quang Vuong},
  doi          = {10.1080/07350015.2019.1665530},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {3},
  number       = {2},
  pages        = {373-385},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Semiparametric estimation of first-price auction models},
  volume       = {39},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multivalued treatments and decomposition analysis: An
application to the WIA program. <em>JBES</em>, <em>39</em>(1), 358–371.
(<a href="https://doi.org/10.1080/07350015.2019.1660664">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article provides a general estimation and inference framework to study how different levels of program participation affect participants’ outcomes. We decompose differences in the outcome distribution into (i) a structure effect, arising due to the conditional outcome distributions given covariates associated with different levels of participation; and (ii) a composition effect, arising due to differences in the distributions of observable characteristics. These counterfactual differences are equivalent to the multivalued treatment effects for the treated under a conditional independence assumption. We propose efficient nonparametric estimators based on propensity score weighting together with uniform inference theory. We employ our methods to study the effects of the Workforce Investment Act (WIA) programs on participants’ earnings. We find that heterogeneity in levels of program participation is an important dimension to evaluate the WIA and other social programs in which participation varies. The results of this article, both theoretically and empirically, provide rigorous assessment of intervention programs and relevant suggestions to improve their performance and cost-effectiveness. Supplementary materials for this article are available online.},
  archive      = {J_JBES},
  author       = {Wallice Ao and Sebastian Calonico and Ying-Ying Lee},
  doi          = {10.1080/07350015.2019.1660664},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {1},
  number       = {1},
  pages        = {358-371},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Multivalued treatments and decomposition analysis: An application to the WIA program},
  volume       = {39},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Smoothing quantile regressions. <em>JBES</em>,
<em>39</em>(1), 338–357. (<a
href="https://doi.org/10.1080/07350015.2019.1660177">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose to smooth the objective function, rather than only the indicator on the check function, in a linear quantile regression context. Not only does the resulting smoothed quantile regression estimator yield a lower mean squared error and a more accurate Bahadur–Kiefer representation than the standard estimator, but it is also asymptotically differentiable. We exploit the latter to propose a quantile density estimator that does not suffer from the curse of dimensionality. This means estimating the conditional density function without worrying about the dimension of the covariate vector. It also allows for two-stage efficient quantile regression estimation. Our asymptotic theory holds uniformly with respect to the bandwidth and quantile level. Finally, we propose a rule of thumb for choosing the smoothing bandwidth that should approximate well the optimal bandwidth. Simulations confirm that our smoothed quantile regression estimator indeed performs very well in finite samples. Supplementary materials for this article are available online.},
  archive      = {J_JBES},
  author       = {Marcelo Fernandes and Emmanuel Guerre and Eduardo Horta},
  doi          = {10.1080/07350015.2019.1660177},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {1},
  number       = {1},
  pages        = {338-357},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Smoothing quantile regressions},
  volume       = {39},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Statistical inference on panel data models: A kernel ridge
regression method. <em>JBES</em>, <em>39</em>(1), 325–337. (<a
href="https://doi.org/10.1080/07350015.2019.1660176">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose statistical inferential procedures for nonparametric panel data models with interactive fixed effects in a kernel ridge regression framework. Compared with the traditional sieve methods, our method is automatic in the sense that it does not require the choice of basis functions and truncation parameters. The model complexity is controlled by a continuous regularization parameter which can be automatically selected by the generalized cross-validation. Based on the empirical process theory and functional analysis tools, we derive the joint asymptotic distributions for the estimators in the heterogeneous setting. These joint asymptotic results are then used to construct the confidence intervals for the regression means and the prediction intervals for future observations, both being the first provably valid intervals in literature. The marginal asymptotic normality of the functional estimators in a homogeneous setting is also obtained. Our estimators can also be readily modified and applied to other widely used semiparametric models, such as partially linear models. Simulation and real data analyses demonstrate the advantages of our method. Supplementary materials for this article are available online.},
  archive      = {J_JBES},
  author       = {Shunan Zhao and Ruiqi Liu and Zuofeng Shang},
  doi          = {10.1080/07350015.2019.1660176},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {1},
  number       = {1},
  pages        = {325-337},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Statistical inference on panel data models: A kernel ridge regression method},
  volume       = {39},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Confidence intervals for bias and size distortion in IV and
local projections-IV models. <em>JBES</em>, <em>39</em>(1), 307–324. (<a
href="https://doi.org/10.1080/07350015.2019.1660175">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we propose methods to construct confidence intervals for the bias of the two-stage least squares estimator, and the size distortion of the associated Wald test in instrumental variables models with heteroscedasticity and serial correlation. Importantly our framework covers the local projections—instrumental variable model as well. Unlike tests for weak instruments, whose distributions are nonstandard and depend on nuisance parameters that cannot be consistently estimated, the confidence intervals for the strength of identification are straightforward and computationally easy to calculate, as they are obtained from inverting a chi-squared distribution. Furthermore, they provide more information to researchers on instrument strength than the binary decision offered by tests. Monte Carlo simulations show that the confidence intervals have good, albeit conservative, in some cases, small sample coverage. We illustrate the usefulness of the proposed methods in two empirical situations: the estimation of the intertemporal elasticity of substitution in a linearized Euler equation, and government spending multipliers. Supplementary materials for this article are available online.},
  archive      = {J_JBES},
  author       = {Gergely Ganics and Atsushi Inoue and Barbara Rossi},
  doi          = {10.1080/07350015.2019.1660175},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {1},
  number       = {1},
  pages        = {307-324},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Confidence intervals for bias and size distortion in IV and local projections-IV models},
  volume       = {39},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Bias-corrected common correlated effects pooled estimation
in dynamic panels. <em>JBES</em>, <em>39</em>(1), 294–306. (<a
href="https://doi.org/10.1080/07350015.2019.1654879">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article extends the common correlated effects pooled (CCEP) estimator to homogenous dynamic panels. In this setting, CCEP suffers from a large bias when the time span ( T ) of the dataset is fixed. We develop a bias-corrected CCEP estimator that is consistent as the number of cross-sectional units ( N ) tends to infinity, for T fixed or growing large, provided that the specification is augmented with a sufficient number of cross-sectional averages, and lags thereof. Monte Carlo experiments show that the correction offers strong improvements in terms of bias and variance. We apply our approach to estimate the dynamic impact of temperature shocks on aggregate output growth.},
  archive      = {J_JBES},
  author       = {Ignace De Vos and Gerdie Everaert},
  doi          = {10.1080/07350015.2019.1654879},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {1},
  number       = {1},
  pages        = {294-306},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Bias-corrected common correlated effects pooled estimation in dynamic panels},
  volume       = {39},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Empirical likelihood ratio tests of conditional moment
restrictions with unknown functions. <em>JBES</em>, <em>39</em>(1),
282–293. (<a
href="https://doi.org/10.1080/07350015.2019.1647845">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article introduces empirical likelihood ratio tests for conditional moment models in which the unknown parameter contains infinite-dimensional components. We allow unknown functions to be included in the conditional moment restrictions. We discusses (1) the limiting distribution of the sieve conditional empirical likelihood ratio (SCELR) test statistic for functionals of parameters under the null hypothesis and local alternatives; and (2) the limiting distribution of the SCELR test statistic for conditional moment restrictions (a consistent specification test) under the null hypothesis and local alternatives. A Monte Carlo study examines finite sample performance. We then apply these tests in an empirical application to construct confidence intervals for Engel curves and test restrictions on the curves.},
  archive      = {J_JBES},
  author       = {Jing Tao},
  doi          = {10.1080/07350015.2019.1647845},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {1},
  number       = {1},
  pages        = {282-293},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Empirical likelihood ratio tests of conditional moment restrictions with unknown functions},
  volume       = {39},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Causal interpretations of black-box models. <em>JBES</em>,
<em>39</em>(1), 272–281. (<a
href="https://doi.org/10.1080/07350015.2019.1624293">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The fields of machine learning and causal inference have developed many concepts, tools, and theory that are potentially useful for each other. Through exploring the possibility of extracting causal interpretations from black-box machine-trained models, we briefly review the languages and concepts in causal inference that may be interesting to machine learning researchers. We start with the curious observation that Friedman’s partial dependence plot has exactly the same formula as Pearl’s back-door adjustment and discuss three requirements to make causal interpretations: a model with good predictive performance, some domain knowledge in the form of a causal diagram and suitable visualization tools. We provide several illustrative examples and find some interesting and potentially causal relations using visualization tools for black-box models.},
  archive      = {J_JBES},
  author       = {Qingyuan Zhao and Trevor Hastie},
  doi          = {10.1080/07350015.2019.1624293},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {1},
  number       = {1},
  pages        = {272-281},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Causal interpretations of black-box models},
  volume       = {39},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A dynamic model of vaccine compliance: How fake news
undermined the danish HPV vaccine program. <em>JBES</em>,
<em>39</em>(1), 259–271. (<a
href="https://doi.org/10.1080/07350015.2019.1623045">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Increased vaccine hesitancy presents challenges to public health and undermines efforts to eradicate diseases such as measles, rubella, and polio. The decline is partly attributed to misconceptions that are shared on social media, such as the debunked association between vaccines and autism. Perhaps, more damaging to vaccine uptake are cases where trusted mainstream media run stories that exaggerate the risks associated with vaccines. It is important to understand the underlying causes of vaccine refusal, because these may be prevented, or countered, in a timely manner by educational campaigns. In this article, we develop a dynamic model of vaccine compliance that can help pinpoint events that disrupted vaccine compliance. We apply the framework to Danish HPV vaccine data, which experienced a sharp decline in compliance following the broadcast of a controversial TV documentary, and we show that media coverage significantly predicts vaccine uptake.},
  archive      = {J_JBES},
  author       = {Peter Reinhard Hansen and Matthias Schmidtblaicher},
  doi          = {10.1080/07350015.2019.1623045},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {1},
  number       = {1},
  pages        = {259-271},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {A dynamic model of vaccine compliance: How fake news undermined the danish HPV vaccine program},
  volume       = {39},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Exploring encouragement, treatment, and spillover effects
using principal stratification, with application to a field experiment
on teens’ museum attendance. <em>JBES</em>, <em>39</em>(1), 244–258. (<a
href="https://doi.org/10.1080/07350015.2019.1647843">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article revisits results from a field experiment, conducted in Florence, Italy, to study the effects of incentives provided to high school teens to motivate them to visit art museums. In the experiment, different classes of students were randomized to three types of encouragement and were offered a free visit to a main museum in the city. Using the principal stratification framework, the article explores causal pathways that may lead students to increase future visits, as induced by the encouragement received, or by the individual experience of the proposed free museum visit, or by the spillover of classmates’ experience. We do so by estimating and interpreting the causal effects of the three forms of encouragement within the principal strata defined by compliance behaviors. Bayesian inferential methods are used to derive the posterior distributions of weakly identified causal parameters.},
  archive      = {J_JBES},
  author       = {Laura Forastiere and Patrizia Lattarulo and Marco Mariani and Fabrizia Mealli and Laura Razzolini},
  doi          = {10.1080/07350015.2019.1647843},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {1},
  number       = {1},
  pages        = {244-258},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Exploring encouragement, treatment, and spillover effects using principal stratification, with application to a field experiment on teens’ museum attendance},
  volume       = {39},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). From local to global: External validity in a fertility
natural experiment. <em>JBES</em>, <em>39</em>(1), 217–243. (<a
href="https://doi.org/10.1080/07350015.2019.1639407">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study issues related to external validity for treatment effects using over 100 replications of the Angrist and Evans natural experiment on the effects of sibling sex composition on fertility and labor supply. The replications are based on census data from around the world going back to 1960. We decompose sources of error in predicting treatment effects in external contexts in terms of macro and micro sources of variation. In our empirical setting, we find that macro covariates dominate over micro covariates for reducing errors in predicting treatments, an issue that past studies of external validity have been unable to evaluate. We develop methods for two applications to evidence-based decision-making, including determining where to locate an experiment and whether policy-makers should commission new experiments or rely on an existing evidence base for making a policy decision.},
  archive      = {J_JBES},
  author       = {Rajeev Dehejia and Cristian Pop-Eleches and Cyrus Samii},
  doi          = {10.1080/07350015.2019.1639407},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {1},
  number       = {1},
  pages        = {217-243},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {From local to global: External validity in a fertility natural experiment},
  volume       = {39},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Measurement error without the proxy exclusion restriction.
<em>JBES</em>, <em>39</em>(1), 200–216. (<a
href="https://doi.org/10.1080/07350015.2019.1617156">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract– This article studies the identification of the coefficients in a linear equation when data on the outcome, covariates, and an error-laden proxy for a latent variable are available. We maintain that the measurement error in the proxy is classical and relax the assumption that the proxy is excluded from the outcome equation. This enables the proxy to directly affect the outcome and allows for differential measurement error. Without the proxy exclusion restriction, we first show that the effects of the latent variable, the proxy, and the covariates are not identified. We then derive the sharp identification regions for these effects under any configuration of three auxiliary assumptions. The first weakens the assumption of no measurement error by imposing an upper bound on the noise-to-signal ratio. The second imposes an upper bound on the outcome equation coefficient of determination that would obtain had there been no measurement error. The third weakens the proxy exclusion restriction by specifying whether the latent variable and its proxy affect the outcome in the same or the opposite direction, if at all. Using the College Scorecard aggregate data, we illustrate our framework by studying the financial returns to college selectivity and characteristics and student characteristics when the average SAT score at an institution may directly affect earnings and serves as a proxy for the average ability of the student cohort.},
  archive      = {J_JBES},
  author       = {Karim Chalak and Daniel Kim},
  doi          = {10.1080/07350015.2019.1617156},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {1},
  number       = {1},
  pages        = {200-216},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Measurement error without the proxy exclusion restriction},
  volume       = {39},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Improved nonparametric bootstrap tests of lorenz dominance.
<em>JBES</em>, <em>39</em>(1), 189–199. (<a
href="https://doi.org/10.1080/07350015.2019.1647214">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One income or wealth distribution is said to Lorenz dominate another when the Lorenz curve for the former is nowhere below that of the latter, indicating a (weakly) more equitable allocation of resources. Existing tests of the null of Lorenz dominance based on pairs of samples of income or wealth achieve the nominal rejection rate asymptotically when the two Lorenz curves are equal, but are conservative at other null configurations. We propose new nonparametric bootstrap tests of Lorenz dominance based on preliminary estimation of a contact set. Our tests achieve the nominal rejection rate asymptotically on the boundary of the null; that is, when Lorenz dominance is satisfied, and the Lorenz curves coincide on some interval. Numerical simulations indicate that our tests enjoy substantially improved power compared to existing procedures at relevant sample sizes. Supplementary materials for this article are available online.},
  archive      = {J_JBES},
  author       = {Zhenting Sun and Brendan K. Beare},
  doi          = {10.1080/07350015.2019.1647214},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {1},
  number       = {1},
  pages        = {189-199},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Improved nonparametric bootstrap tests of lorenz dominance},
  volume       = {39},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Regression analysis with individual-specific patterns of
missing covariates. <em>JBES</em>, <em>39</em>(1), 179–188. (<a
href="https://doi.org/10.1080/07350015.2019.1635486">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is increasingly common to collect data from heterogeneous sources in practice. Two major challenges complicate the statistical analysis of such data. First, only a small proportion of units have complete information across all sources. Second, the missing data patterns vary across individuals. Our motivating online-loan data have 93\% missing covariates where the missing pattern is individual-specific. The existing regression analysis with missing covariates either are inefficient or require additional modeling assumptions on the covariates. We propose a simple yet efficient iterative least squares estimator of the regression coefficient for the data with individual-specific missing patterns. Our method has several desirable features. First, it does not require any modeling assumptions on the covariates. Second, the imputation of the missing covariates involves feasible one-dimensional nonparametric regressions, and can maximally use the information across units and the relationship among the covariates. Third, the iterative least squares estimate is both computationally and statistically efficient. We study the asymptotic properties of our estimator and apply it to the motivating online-loan data. Supplementary materials for this article are available online. KEY WORDS: High missing rate; Individual-specific missing; Iterative least squares; Missing covariates.},
  archive      = {J_JBES},
  author       = {Huazhen Lin and Wei Liu and Wei Lan},
  doi          = {10.1080/07350015.2019.1635486},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {1},
  number       = {1},
  pages        = {179-188},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Regression analysis with individual-specific patterns of missing covariates},
  volume       = {39},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Dealing with endogeneity in threshold models using copulas.
<em>JBES</em>, <em>39</em>(1), 166–178. (<a
href="https://doi.org/10.1080/07350015.2019.1647213">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We suggest a new method dealing with the problem of endogeneity of the threshold variable in structural threshold regression models based on copula theory. This method enables us to relax the assumption that the threshold variable is normally distributed and to capture the dependence structure between the threshold regression error term and the threshold variable independently of the marginal distribution of the threshold variable. For Gaussian and Student’s t copulas, this dependent structure can be captured by copula-type transformations of the distribution of the threshold variable, for each regime of the model. Augmenting the threshold model under these transformations can control for the endogeneity problem of threshold variable. The single-factor correlation structure of the threshold regression error term with these transformations allows us to consistently estimate the threshold and the slope parameters of the model based on a least squares method. Based on a Monte Carlo study, we show that our method is robust to nonlinear dependence structures between the regression error term and the threshold variable implied by the Archimedean family of copulas. We illustrate the method by estimating a model of the foreign-trade multiplier for seven OECD economies.},
  archive      = {J_JBES},
  author       = {Dimitris Christopoulos and Peter McAdam and Elias Tzavalis},
  doi          = {10.1080/07350015.2019.1647213},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {1},
  number       = {1},
  pages        = {166-178},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Dealing with endogeneity in threshold models using copulas},
  volume       = {39},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Testing for changes in forecasting performance.
<em>JBES</em>, <em>39</em>(1), 148–165. (<a
href="https://doi.org/10.1080/07350015.2019.1641410">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the issue of forecast failure (or breakdown) and propose methods to assess retrospectively whether a given forecasting model provides forecasts which show evidence of changes with respect to some loss function. We adapt the classical structural change tests to the forecast failure context. First, we recommend that all tests should be carried with a fixed scheme to have best power. This ensures a maximum difference between the fitted in and out-of-sample means of the losses and avoids contamination issues under the rolling and recursive schemes. With a fixed scheme, Giacomini and Rossi’s (GR) test is simply a Wald test for a one-time change in the mean of the total (the in-sample plus out-of-sample) losses at a known break date, say m , the value that separates the in and out-of-sample periods. To alleviate this problem, we consider a variety of tests: maximizing the GR test over values of m within a prespecified range; a Double sup-Wald (DSW) test which for each m performs a sup-Wald test for a change in the mean of the out-of-sample losses and takes the maximum of such tests over some range; we also propose to work directly with the total loss series to define the Total Loss sup-Wald and Total Loss UDmax (TLUD) tests. Using theoretical analyses and simulations, we show that with forecasting models potentially involving lagged dependent variables, the only tests having a monotonic power function for all data-generating processes considered are the DSW and TLUD tests, constructed with a fixed forecasting window scheme. Some explanations are provided and empirical applications illustrate the relevance of our findings in practice. Supplementary materials for this article are available online.},
  archive      = {J_JBES},
  author       = {Pierre Perron and Yohei Yamamoto},
  doi          = {10.1080/07350015.2019.1641410},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {1},
  number       = {1},
  pages        = {148-165},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Testing for changes in forecasting performance},
  volume       = {39},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Testing serial correlation and ARCH effect of
high-dimensional time-series data. <em>JBES</em>, <em>39</em>(1),
136–147. (<a
href="https://doi.org/10.1080/07350015.2019.1647844">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article proposes several tests for detecting serial correlation and ARCH effect in high-dimensional data. The dimension of data p = p ( n ) p = p ( n ) p=p(n) may go to infinity when the sample size n → ∞ n → ∞ n→∞ . It is shown that the sample autocorrelations and the sample rank autocorrelations (Spearman’s rank correlation) of the L 1 -norm of data are asymptotically normal. Two portmanteau tests based, respectively, on the norm and its rank are shown to be asymptotically χ 2 -distributed, and the corresponding weighted portmanteau tests are shown to be asymptotically distributed as a linear combination of independent χ 2 random variables. These tests are dimension-free, that is, independent of p , and the norm rank-based portmanteau test and its weighted counterpart can be used for heavy-tailed time series. We further discuss two standardized norm-based tests. Simulation results show that the proposed test statistics have satisfactory sizes and are powerful even for the case of small n and large p . We apply the tests to two real datasets. Supplementary materials for this article are available online.},
  archive      = {J_JBES},
  author       = {Shiqing Ling and Ruey S. Tsay and Yaxing Yang},
  doi          = {10.1080/07350015.2019.1647844},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {1},
  number       = {1},
  pages        = {136-147},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Testing serial correlation and ARCH effect of high-dimensional time-series data},
  volume       = {39},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Spatial modeling approach for dynamic network formation and
interactions. <em>JBES</em>, <em>39</em>(1), 120–135. (<a
href="https://doi.org/10.1080/07350015.2019.1639395">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study primarily seeks to answer the following question: How do social networks evolve over time and affect individual economic activity? To provide an adequate empirical tool to answer this question, we propose a new modeling approach for longitudinal data of networks and activity outcomes. The key features of our model are the inclusion of dynamic effects and the use of time-varying latent variables to determine unobserved individual traits in network formation and activity interactions. The proposed model combines two well-known models in the field: latent space model for dynamic network formation and spatial dynamic panel data model for network interactions. This combination reflects real situations, where network links and activity outcomes are interdependent and jointly influenced by unobserved individual traits. Moreover, this combination enables us to (1) manage the endogenous selection issue inherited in network interaction studies, and (2) investigate the effect of homophily and individual heterogeneity in network formation. We develop a Bayesian Markov chain Monte Carlo sampling approach to estimate the model. We also provide a Monte Carlo experiment to analyze the performance of our estimation method and apply the model to a longitudinal student network data in Taiwan to study the friendship network formation and peer effect on academic performance. Supplementary materials for this article are available online.},
  archive      = {J_JBES},
  author       = {Xiaoyi Han and Chih-Sheng Hsieh and Stanley I. M. Ko},
  doi          = {10.1080/07350015.2019.1639395},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {1},
  number       = {1},
  pages        = {120-135},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Spatial modeling approach for dynamic network formation and interactions},
  volume       = {39},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Forecasting inflation in a data-rich environment: The
benefits of machine learning methods. <em>JBES</em>, <em>39</em>(1),
98–119. (<a
href="https://doi.org/10.1080/07350015.2019.1637745">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inflation forecasting is an important but difficult task. Here, we explore advances in machine learning (ML) methods and the availability of new datasets to forecast U.S. inflation. Despite the skepticism in the previous literature, we show that ML models with a large number of covariates are systematically more accurate than the benchmarks. The ML method that deserves more attention is the random forest model, which dominates all other models. Its good performance is due not only to its specific method of variable selection but also the potential nonlinearities between past key macroeconomic variables and inflation. Supplementary materials for this article are available online.},
  archive      = {J_JBES},
  author       = {Marcelo C. Medeiros and Gabriel F. R. Vasconcelos and Álvaro Veiga and Eduardo Zilberman},
  doi          = {10.1080/07350015.2019.1637745},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {1},
  number       = {1},
  pages        = {98-119},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Forecasting inflation in a data-rich environment: The benefits of machine learning methods},
  volume       = {39},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Sequential text-term selection in vector space models.
<em>JBES</em>, <em>39</em>(1), 82–97. (<a
href="https://doi.org/10.1080/07350015.2019.1634079">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Text mining has recently attracted a great deal of attention with the accumulation of text documents in all fields. In this article, we focus on the use of textual information to explain continuous variables in the framework of linear regressions. To handle the unstructured texts, one common practice is to structuralize the text documents via vector space models. However, using words or phrases as the basic analysis terms in vector space models is in high debate. In addition, vector space models often lead to an extremely large term set and suffer from the curse of dimensionality, which makes term selection important and necessary. Toward this end, we propose a novel term screening method for vector space models under a linear regression setup. We first split the entire term space into different subspaces according to the length of terms and then conduct term screening in a sequential manner. We prove the screening consistency of the method and assess the empirical performance of the proposed method with simulations based on a dataset of online consumer reviews for cellphones. Then, we analyze the associated real data. The results show that the sequential term selection technique can effectively detect the relevant terms by a few steps.},
  archive      = {J_JBES},
  author       = {Feifei Wang and Jingyuan Liu and Hansheng Wang},
  doi          = {10.1080/07350015.2019.1634079},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {1},
  number       = {1},
  pages        = {82-97},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Sequential text-term selection in vector space models},
  volume       = {39},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). GMM estimation of non-gaussian structural vector
autoregression. <em>JBES</em>, <em>39</em>(1), 69–81. (<a
href="https://doi.org/10.1080/07350015.2019.1629940">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider estimation of the structural vector autoregression (SVAR) by the generalized method of moments (GMM). Given non-Gaussian errors and a suitable set of moment conditions, the GMM estimator is shown to achieve local identification of the structural shocks. The optimal set of moment conditions can be found by well-known moment selection criteria. Compared to recent alternatives, our approach has the advantage that the structural shocks need not be mutually independent, but only orthogonal, provided they satisfy a number of co-kurtosis conditions that prevail under independence. According to simulation results, the finite-sample performance of our estimation method is comparable, or even superior to that of the recently proposed pseudo maximum likelihood estimators. The two-step estimator is found to outperform the alternative GMM estimators. An empirical application to a small macroeconomic model estimated on postwar United States data illustrates the use of the methods.},
  archive      = {J_JBES},
  author       = {Markku Lanne and Jani Luoto},
  doi          = {10.1080/07350015.2019.1629940},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {1},
  number       = {1},
  pages        = {69-81},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {GMM estimation of non-gaussian structural vector autoregression},
  volume       = {39},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Focused information criterion and model averaging for large
panels with a multifactor error structure. <em>JBES</em>,
<em>39</em>(1), 54–68. (<a
href="https://doi.org/10.1080/07350015.2019.1623044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article considers model selection and model averaging in panel data models with a multifactor error structure. We investigate the limiting distribution of the common correlated effects estimator in a local asymptotic framework and show that the trade-off between bias and variance remains in asymptotic theory. We then propose a focused information criterion and a plug-in averaging estimator for large heterogeneous panels and examine their theoretical properties. The novel feature of the proposed method is that it aims to minimize the sample analog of the asymptotic mean squared error and can be applied to cases irrespective of whether the rank condition holds or not. Monte Carlo simulations show that both proposed selection and averaging methods generally achieve lower mean squared error than other methods. The proposed methods are applied to examine possible causes that lead to the increasing wage inequality between high-skilled and low-skilled workers in the U.S. manufacturing industries.},
  archive      = {J_JBES},
  author       = {Shou-Yung Yin and Chu-An Liu and Chang-Ching Lin},
  doi          = {10.1080/07350015.2019.1623044},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {1},
  number       = {1},
  pages        = {54-68},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Focused information criterion and model averaging for large panels with a multifactor error structure},
  volume       = {39},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-horizon forecast comparison. <em>JBES</em>,
<em>39</em>(1), 40–53. (<a
href="https://doi.org/10.1080/07350015.2019.1620074">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce tests for multi-horizon superior predictive ability (SPA). Rather than comparing forecasts of different models at multiple horizons individually, we propose to jointly consider all horizons of a forecast path. We define the concepts of uniform and average SPA. The former entails superior performance at each individual horizon, while the latter allows inferior performance at some horizons to be compensated by others. The article illustrates how the tests lead to more coherent conclusions, and how they are better able to differentiate between models than the single-horizon tests. We provide an extension of the previously introduced model confidence set to allow for multi-horizon comparison of more than two models. Simulations demonstrate appropriate size and high power. An illustration of the tests on a large set of macroeconomic variables demonstrates the empirical benefits of multi-horizon comparison.},
  archive      = {J_JBES},
  author       = {Rogier Quaedvlieg},
  doi          = {10.1080/07350015.2019.1620074},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {1},
  number       = {1},
  pages        = {40-53},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Multi-horizon forecast comparison},
  volume       = {39},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Disentangling sources of high frequency market
microstructure noise. <em>JBES</em>, <em>39</em>(1), 18–39. (<a
href="https://doi.org/10.1080/07350015.2019.1617158">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Employing tick-by-tick maximum likelihood estimation on several leading models from the financial economics literature, we find that the market microstructure noise is mostly explained by a linear model where the trade direction, that is, whether the trade is buyer or seller initiated, is multiplied by the dynamic quoted bid-ask spread. Although reasonably stable intraday, this model manifests variability across days and stocks. Among different observable high frequency financial characteristics of the underlying stocks, this variability is best explained by the tick-to-spread ratio, implying that discreteness is the first residual source of noise. We determine the bid-ask bounce effect as the next source of noise.},
  archive      = {J_JBES},
  author       = {Simon Clinet and Yoann Potiron},
  doi          = {10.1080/07350015.2019.1617158},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {1},
  number       = {1},
  pages        = {18-39},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Disentangling sources of high frequency market microstructure noise},
  volume       = {39},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Shrinkage estimation of factor models with global and
group-specific factors. <em>JBES</em>, <em>39</em>(1), 1–17. (<a
href="https://doi.org/10.1080/07350015.2019.1617157">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article develops an adaptive group lasso estimator for factor models with both global and group-specific factors. The global factors can affect all variables, whereas the group-specific factors are only allowed to affect the variables within a certain group. We propose a new method to separately identify the spaces spanned by global and group-specific factors, and we develop a new shrinkage estimator that can consistently estimate the factor loadings and determine the number of factors simultaneously. The asymptotic result shows that the proposed estimator can select the true model specification with a probability approaching one. An information criterion is developed to select the optimal tuning parameters in the shrinkage estimation. Monte Carlo simulations confirm our asymptotic theory, and the proposed estimator performs well in finite samples. In an empirical application, we implement the proposed method to a dataset consisting of Eurozone, United States, and United Kingdom macroeconomic variables, and we detect one global factor, one U.S.-specific factor, and one Eurozone-specific factor.},
  archive      = {J_JBES},
  author       = {Xu Han},
  doi          = {10.1080/07350015.2019.1617157},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {1},
  number       = {1},
  pages        = {1-17},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Shrinkage estimation of factor models with global and group-specific factors},
  volume       = {39},
  year         = {2021},
}
</textarea>
</details></li>
</ul>

</body>
</html>
