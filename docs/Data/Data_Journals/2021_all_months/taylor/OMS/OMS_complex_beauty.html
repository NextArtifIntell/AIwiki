<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>OMS_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="oms---55">OMS - 55</h2>
<ul>
<li><details>
<summary>
(2021a). Correction. <em>OMS</em>, <em>36</em>(6), 1317–1318. (<a
href="https://doi.org/10.1080/10556788.2018.1527890">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_OMS},
  doi          = {10.1080/10556788.2018.1527890},
  journal      = {Optimization Methods and Software},
  number       = {6},
  pages        = {1317-1318},
  shortjournal = {Optim. Methods Softw.},
  title        = {Correction},
  volume       = {36},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Universal intermediate gradient method for convex problems
with inexact oracle. <em>OMS</em>, <em>36</em>(6), 1289–1316. (<a
href="https://doi.org/10.1080/10556788.2019.1711079">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose new first-order methods for minimization of a convex function on a simple convex set. We assume that the objective function is a composite function given as a sum of a simple convex function and a convex function with inexact Hölder-continuous subgradient. We propose Universal Intermediate Gradient Method. Our method enjoys both the universality and intermediateness properties. Following the ideas of Nesterov (Math. Program. 152 (2015), pp. 381–404) on Universal Gradient Methods, our method does not require any information about the Hölder parameter and constant and adjusts itself automatically to the local level of smoothness. On the other hand, in the spirit of the Intermediate Gradient Method proposed by Devolder et al. (CORE Discussion Paper 2013/17, 2013), our method is intermediate in the sense that it interpolates between Universal Gradient Method and Universal Fast Gradient Method. This allows to balance the rate of convergence of the method and rate of the oracle error accumulation. Under the additional assumption of strong convexity of the objective, we show how the restart technique can be used to obtain an algorithm with faster rate of convergence.},
  archive      = {J_OMS},
  author       = {Dmitry Kamzolov and Pavel Dvurechensky and Alexander V. Gasnikov},
  doi          = {10.1080/10556788.2019.1711079},
  journal      = {Optimization Methods and Software},
  number       = {6},
  pages        = {1289-1316},
  shortjournal = {Optim. Methods Softw.},
  title        = {Universal intermediate gradient method for convex problems with inexact oracle},
  volume       = {36},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). On the uniqueness of non-reducible multi-player control
problems. <em>OMS</em>, <em>36</em>(6), 1259–1288. (<a
href="https://doi.org/10.1080/10556788.2019.1694021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we consider a special class of generalized Nash equilibrium problems that cannot be reduced to a single player control problem. We find a sufficient condition, that proves the existence and uniqueness of solutions. Problems of this type can be solved by a semi-smooth Newton method. Applying the same condition as needed for the uniqueness of solutions, we derive superlinear convergence for the associated Newton method and the equivalent active-set method. We also provide detailed finite element discretizations for both methods. Numerical examples are presented to support the theoretical findings.},
  archive      = {J_OMS},
  author       = {Veronika Karl and Frank Pörner},
  doi          = {10.1080/10556788.2019.1694021},
  journal      = {Optimization Methods and Software},
  number       = {6},
  pages        = {1259-1288},
  shortjournal = {Optim. Methods Softw.},
  title        = {On the uniqueness of non-reducible multi-player control problems},
  volume       = {36},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Relaxation schemes for mathematical programmes with
switching constraints. <em>OMS</em>, <em>36</em>(6), 1223–1258. (<a
href="https://doi.org/10.1080/10556788.2019.1663425">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Switching-constrained optimization problems form a difficult class of mathematical programmes since their feasible set is almost disconnected while standard constraint qualifications are likely to fail at several feasible points. That is why the application of standard methods from nonlinear programming does not seem to be promising in order to solve such problems. In this paper, we adapt several relaxation methods which are well known from the numerical treatment of mathematical programmes with complementarity constraints to the setting of switching-constrained optimization. A detailed convergence analysis is provided for the adapted relaxation schemes of Scholtes as well as Kanzow and Schwartz. While Scholtes&#39; method and the relaxation scheme of Steffensen and Ulbrich only find weakly stationary points in general, it is shown that the adapted relaxation scheme of Kanzow and Schwartz is capable of identifying Mordukhovich-stationary points of switching-constrained programmes under suitable assumptions. Some computational experiments and a numerical comparison of the proposed methods based on examples from logical programming, switching control, and portfolio optimization close the paper.},
  archive      = {J_OMS},
  author       = {Christian Kanzow and Patrick Mehlitz and Daniel Steck},
  doi          = {10.1080/10556788.2019.1663425},
  journal      = {Optimization Methods and Software},
  number       = {6},
  pages        = {1223-1258},
  shortjournal = {Optim. Methods Softw.},
  title        = {Relaxation schemes for mathematical programmes with switching constraints},
  volume       = {36},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A generic coordinate descent solver for non-smooth convex
optimisation. <em>OMS</em>, <em>36</em>(6), 1202–1222. (<a
href="https://doi.org/10.1080/10556788.2019.1658758">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a generic coordinate descent solver for the minimisation of a non-smooth convex objective with structure. The method can deal in particular with problems with linear constraints. The implementation makes use of efficient residual updates and automatically determines which dual variables should be duplicated. A list of basic functional atoms is pre-compiled for efficiency and a modelling language in Python allows the user to combine them at run time. So, the algorithm can be used to solve a large variety of problems including Lasso, sparse multinomial logistic regression, linear and quadratic programmes.},
  archive      = {J_OMS},
  author       = {Olivier Fercoq},
  doi          = {10.1080/10556788.2019.1658758},
  journal      = {Optimization Methods and Software},
  number       = {6},
  pages        = {1202-1222},
  shortjournal = {Optim. Methods Softw.},
  title        = {A generic coordinate descent solver for non-smooth convex optimisation},
  volume       = {36},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Inexact model: A framework for optimization and variational
inequalities. <em>OMS</em>, <em>36</em>(6), 1155–1201. (<a
href="https://doi.org/10.1080/10556788.2021.1924714">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a general algorithmic framework for the first-order methods in optimization in a broad sense, including minimization problems, saddle-point problems and variational inequalities (VIs). This framework allows obtaining many known methods as a special case, the list including accelerated gradient method, composite optimization methods, level-set methods, Bregman proximal methods. The idea of the framework is based on constructing an inexact model of the main problem component, i.e. objective function in optimization or operator in VIs. Besides reproducing known results, our framework allows constructing new methods, which we illustrate by constructing a universal conditional gradient method and a universal method for VIs with a composite structure. This method works for smooth and non-smooth problems with optimal complexity without a priori knowledge of the problem&#39;s smoothness. As a particular case of our general framework, we introduce relative smoothness for operators and propose an algorithm for VIs with such operators. We also generalize our framework for relatively strongly convex objectives and strongly monotone VIs.},
  archive      = {J_OMS},
  author       = {Fedor Stonyakin and Alexander Tyurin and Alexander Gasnikov and Pavel Dvurechensky and Artem Agafonov and Darina Dvinskikh and Mohammad Alkousa and Dmitry Pasechnyuk and Sergei Artamonov and Victorya Piskunova},
  doi          = {10.1080/10556788.2021.1924714},
  journal      = {Optimization Methods and Software},
  number       = {6},
  pages        = {1155-1201},
  shortjournal = {Optim. Methods Softw.},
  title        = {Inexact model: A framework for optimization and variational inequalities},
  volume       = {36},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Improving dynamic programming for travelling salesman with
precedence constraints: Parallel morin–marsten bounding. <em>OMS</em>,
<em>36</em>(6), 1128–1154. (<a
href="https://doi.org/10.1080/10556788.2020.1817447">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The precedence constrained traveling salesman (TSP-PC), also known as sequential ordering problem (SOP), consists of finding an optimal tour that satisfies the namesake constraints. Mixed integer-linear programming works well with the ‘lightly constrained’ TSP-PCs, close to asymmetric TSP, as well as the with the ‘heavily constrained’ (Gouveia, Ruthmair, 2015). Dynamic programming (DP) works well with the heavily constrained (Salii, 2019). However, judging by the open TSPLIB SOP instances, the worst for any method are the ‘medium’. We implement a parallel Morin–Marsten branch-and-bound scheme for DP (DPBB). We show how the lower bound heuristic parameterizes DPBB&#39;s worst-case complexity and DPBB ‘inherits’ the abstract travel cost aggregation feature of the DP, permitting its direct use with both the conventional and bottleneck TSP-PC. The scheme was tested on TSPLIB instances, with best known upper bounds (TSP-PC), or those found by restricted DP (Bottleneck TSP-PC), and lower bounds from a greedy-type heuristic. Our O PEN MP-based parallel implementation achieved 20-fold speedup for larger instances. We close the long-standing kro124p.4.sop (conventional TSP-PC) and both kro124p.4.sop and ry48p.2.sop (Bottleneck TSP-PC).},
  archive      = {J_OMS},
  author       = {Yaroslav. V. Salii and Andrey S. Sheka},
  doi          = {10.1080/10556788.2020.1817447},
  journal      = {Optimization Methods and Software},
  number       = {6},
  pages        = {1128-1154},
  shortjournal = {Optim. Methods Softw.},
  title        = {Improving dynamic programming for travelling salesman with precedence constraints: Parallel Morin–Marsten bounding},
  volume       = {36},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Cooperative differential games with continuous updating
using hamilton–jacobi–bellman equation. <em>OMS</em>, <em>36</em>(6),
1099–1127. (<a
href="https://doi.org/10.1080/10556788.2020.1802456">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper examines a class of cooperative differential games with continuous updating. Here it is assumed that at each time instant players have or use information about the game structure defined for a closed time interval with fixed duration. The current time continuously evolves with the updating interval. The main problems considered in a cooperative setting with continuous updating is how to define players&#39; cooperative behaviour, how to construct a cooperative trajectory, how to define the characteristic function and how to arrive at a cooperative solution. This paper also addresses the properties of the solution and presents some techniques to fix the process by which a cooperative solution is constructed. Theoretical results are demonstrated on a differential game model of non-renewable resource extraction, initial and continuous updating versions are also considered. Comparison of cooperative strategies, trajectories, characteristic functions and corresponding Shapley values is presented.},
  archive      = {J_OMS},
  author       = {Ovanes Petrosian and Anna Tur and Zeyang Wang and Hongwei Gao},
  doi          = {10.1080/10556788.2020.1802456},
  journal      = {Optimization Methods and Software},
  number       = {6},
  pages        = {1099-1127},
  shortjournal = {Optim. Methods Softw.},
  title        = {Cooperative differential games with continuous updating using Hamilton–Jacobi–Bellman equation},
  volume       = {36},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Preface to the special issue. <em>OMS</em>, <em>36</em>(6),
1097–1098. (<a
href="https://doi.org/10.1080/10556788.2021.2061218">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_OMS},
  author       = {Oleg Khamisov and Anton Eremeev and Vladimir Ushakov},
  doi          = {10.1080/10556788.2021.2061218},
  journal      = {Optimization Methods and Software},
  number       = {6},
  pages        = {1097-1098},
  shortjournal = {Optim. Methods Softw.},
  title        = {Preface to the special issue},
  volume       = {36},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Accelerating fourier–motzkin elimination using bit pattern
trees. <em>OMS</em>, <em>36</em>(5), 1082–1095. (<a
href="https://doi.org/10.1080/10556788.2020.1712600">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paper concerns the elimination of a set of variables from a system of linear inequalities. We employ the widely used Fourier–Motzkin elimination method extended with the Chernikov rules. A straightforward implementation of the algorithm results in extensive enumeration during the most computationally demanding stage. We propose a new way of checking Chernikov rules using bit pattern trees as an accelerating data structure to avoid extensive enumeration. The bit pattern tree is a data structure based on k -d tree used to accelerate the double description method. First we describe an adaptation of that approach to check the second Chernikov rule in Fourier–Motzkin elimination. We also propose a new algorithm that employs bit pattern trees to accelerate both Chernikov rules. Presented results of computational evaluation prove competitiveness of the proposed algorithms.},
  archive      = {J_OMS},
  author       = {S. I. Bastrakov and A. V. Churkin and N. Yu. Zolotykh},
  doi          = {10.1080/10556788.2020.1712600},
  journal      = {Optimization Methods and Software},
  number       = {5},
  pages        = {1082-1095},
  shortjournal = {Optim. Methods Softw.},
  title        = {Accelerating Fourier–Motzkin elimination using bit pattern trees},
  volume       = {36},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Adaptive trust-region algorithms for unconstrained
optimization. <em>OMS</em>, <em>36</em>(5), 1059–1081. (<a
href="https://doi.org/10.1080/10556788.2019.1698578">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose two trust-region algorithms for unconstrained optimization. The trust-region algorithms minimize a model of the objective function within the trust-region, next update the size of the region and then repeat the procedure to find a first-order stationary point for the objective function. The size of the trust-region at each step is very critical to the effectiveness of the algorithm, particularly for large-scale problems, because minimizing the model at each step needs the gradient and the Hessian information of the objective function. Our modified trust-region algorithms are opportunistic in the sense that they explore beyond the trust-region if the boundary of the region prevents the algorithm from accepting a more beneficial point. It occurs when there is a very good agreement between the model and the objective function on the trust-region boundary, and we can find a step outside the trust-region with smaller value of the model while at which the agreement between the model and the objective function remains good. We show that the algorithms are convergent. Initial numerical experiments show that the proposed algorithms are more efficient than the traditional trust-region algorithm for a large majority of problems in the CUTEst suite.},
  archive      = {J_OMS},
  author       = {Mostafa Rezapour and Thomas J. Asaki},
  doi          = {10.1080/10556788.2019.1698578},
  journal      = {Optimization Methods and Software},
  number       = {5},
  pages        = {1059-1081},
  shortjournal = {Optim. Methods Softw.},
  title        = {Adaptive trust-region algorithms for unconstrained optimization},
  volume       = {36},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Adjoint-based SQP method with block-wise quasi-newton
jacobian updates for nonlinear optimal control. <em>OMS</em>,
<em>36</em>(5), 1030–1058. (<a
href="https://doi.org/10.1080/10556788.2019.1653869">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nonlinear model predictive control (NMPC) generally requires the solution of a non-convex dynamic optimization problem at each sampling instant under strict timing constraints, based on a set of differential equations that can often be stiff and/or that may include implicit algebraic equations. This paper provides a local convergence analysis for the recently proposed adjoint-based sequential quadratic programming (SQP) algorithm that is based on a block-structured variant of the two-sided rank-one (TR1) quasi-Newton update formula to efficiently compute Jacobian matrix approximations in a sparsity preserving fashion. A particularly efficient algorithm implementation is proposed in case an implicit integration scheme is used for discretization of the optimal control problem, in which matrix factorization and matrix-matrix operations can be avoided entirely. The convergence analysis results as well as the computational performance of the proposed optimization algorithm are illustrated for two simulation case studies of NMPC.},
  archive      = {J_OMS},
  author       = {Pedro Hespanhol and Rien Quirynen},
  doi          = {10.1080/10556788.2019.1653869},
  journal      = {Optimization Methods and Software},
  number       = {5},
  pages        = {1030-1058},
  shortjournal = {Optim. Methods Softw.},
  title        = {Adjoint-based SQP method with block-wise quasi-newton jacobian updates for nonlinear optimal control},
  volume       = {36},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Accelerated multiple step-size methods for solving
unconstrained optimization problems. <em>OMS</em>, <em>36</em>(5),
998–1029. (<a
href="https://doi.org/10.1080/10556788.2019.1653868">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Two transformations of gradient-descent iterative methods for solving unconstrained optimization are proposed. The first transformation is called modification and it is defined using a small enlargement of the step size in various gradient-descent methods. The second transformation is termed as hybridization and it is defined as a composition of gradient-descent methods with the Picard–Mann hybrid iterative process. As a result, several accelerated gradient-descent methods for solving unconstrained optimization problems are presented, investigated theoretically and numerically compared. The proposed methods are globally convergent for uniformly convex functions satisfying certain condition under the assumption that the step size is determined by the backtracking line search. In addition, the convergence on strictly convex quadratic functions is discussed. Numerical comparisons show better behaviour of the proposed methods with respect to some existing methods in view of the Dolan and Moré&#39;s performance profile with respect to all analysed characteristics: number of iterations, the CPU time, and the number of function evaluations.},
  archive      = {J_OMS},
  author       = {Branislav Ivanov and Predrag S. Stanimirović and Gradimir V. Milovanović and Snežana Djordjević and Ivona Brajević},
  doi          = {10.1080/10556788.2019.1653868},
  journal      = {Optimization Methods and Software},
  number       = {5},
  pages        = {998-1029},
  shortjournal = {Optim. Methods Softw.},
  title        = {Accelerated multiple step-size methods for solving unconstrained optimization problems},
  volume       = {36},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Adaptive online distributed optimization in dynamic
environments. <em>OMS</em>, <em>36</em>(5), 973–997. (<a
href="https://doi.org/10.1080/10556788.2019.1637433">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a dynamic regret analysis on the decentralized online convex optimization problems computed over a network of agents. The goal is to distributively optimize a global function which can be decomposed into the summation of local cost functions associated with each agent. By exploiting the convexity of cost functions, previous studies have shown that the dynamic regret of a decentralized gradient-based algorithm can be upper bounded by the path-length of the comparator sequence and the connectivity in the underlying network. In this paper, we illustrate that the dynamic regret can be further improved by allowing the learner to use a class of adaptive search directions and step-sizes from estimates of first and second moments of the gradients. Specifically, we develop a new class of decentralized and stochastic algorithms based on the adaptive gradient method in the dynamic environment and show that their regret bounds for certain realistic classes of loss functions are considerably better than existing bounds. Numerical simulations verify the theoretical results and demonstrate the efficiency of the new proposed method in practice.},
  archive      = {J_OMS},
  author       = {Parvin Nazari and Esmaeil Khorram and Davoud Ataee Tarzanagh},
  doi          = {10.1080/10556788.2019.1637433},
  journal      = {Optimization Methods and Software},
  number       = {5},
  pages        = {973-997},
  shortjournal = {Optim. Methods Softw.},
  title        = {Adaptive online distributed optimization in dynamic environments},
  volume       = {36},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multidimensional global optimization using numerical
estimates of objective function derivatives. <em>OMS</em>,
<em>36</em>(5), 952–972. (<a
href="https://doi.org/10.1080/10556788.2019.1630624">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a method for solving the computation-costly multidimensional global optimization problems. The method is efficient in the one-dimensional case and its combination with the nested reduction scheme competitive with optimization methods reducing multidimensional problems by using space-filling (Peano) curves. The developed method is based on an approach, in which not only the minimized function values but also the values of derivatives of these functions are used to increase the efficiency of global optimization. The required values of the derivatives are estimated numerically by handling the available search information. The results of the executed experiments confirm the developed approach is promising.},
  archive      = {J_OMS},
  author       = {Victor Gergel and Alexey Goryachih},
  doi          = {10.1080/10556788.2019.1630624},
  journal      = {Optimization Methods and Software},
  number       = {5},
  pages        = {952-972},
  shortjournal = {Optim. Methods Softw.},
  title        = {Multidimensional global optimization using numerical estimates of objective function derivatives},
  volume       = {36},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Computational performance of a projection and rescaling
algorithm. <em>OMS</em>, <em>36</em>(5), 934–951. (<a
href="https://doi.org/10.1080/10556788.2019.1615910">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper documents a computational implementation of a projection and rescaling algorithm for finding most interior solutions to the pair of feasibility problems f i n d x ∈ L ∩ ℝ n + a n d f i n d x ˆ ∈ L ⊥ ∩ ℝ n + , f i n d x ∈ L ∩ R + n a n d f i n d x ˆ ∈ L ⊥ ∩ R + n , find x∈L∩R+nandfind xˆ∈L⊥∩R+n, where L denotes a linear subspace in ℝ n R n Rn and L ⊥ L ⊥ L⊥ denotes its orthogonal complement. The projection and rescaling algorithm is a recently developed method that combines a basic procedure involving only low-cost operations with a periodic rescaling step. We give a full description of a MATLAB implementation of this algorithm and present multiple sets of numerical experiments on synthetic problem instances with varied levels of conditioning. Our computational experiments provide promising evidence of the effectiveness of the projection and rescaling algorithm. Our MATLAB code is publicly available. Furthermore, the simplicity of the algorithm makes a computational implementation in other environments completely straightforward.},
  archive      = {J_OMS},
  author       = {Javier Peña and Negar Soheili},
  doi          = {10.1080/10556788.2019.1615910},
  journal      = {Optimization Methods and Software},
  number       = {5},
  pages        = {934-951},
  shortjournal = {Optim. Methods Softw.},
  title        = {Computational performance of a projection and rescaling algorithm},
  volume       = {36},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Study of the numerical efficiency of structured abs-normal
forms. <em>OMS</em>, <em>36</em>(5), 909–933. (<a
href="https://doi.org/10.1080/10556788.2019.1613654">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The abs-normal form (ANF) can be used to represent almost any piecewise linear function. Several of these piecewise linear functions exhibit a certain structure that has an impact on the numerical efficiency of the ANF representation. In this paper, three common structures are investigated that typically arise in applications and require special numerical treatment: the sum, the composition, and the component-wise maximum/minimum of several functions. For these structures, the corresponding expressions of the resulting abs-normal form are provided, as well as some alternatives. The theoretical observations are supported by numerical results.},
  archive      = {J_OMS},
  author       = {Torsten Falko Bosse and Sri Hari Krishna Narayanan},
  doi          = {10.1080/10556788.2019.1613654},
  journal      = {Optimization Methods and Software},
  number       = {5},
  pages        = {909-933},
  shortjournal = {Optim. Methods Softw.},
  title        = {Study of the numerical efficiency of structured abs-normal forms},
  volume       = {36},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Loan interest rate nash models with solvency constraints in
the banking sector. <em>OMS</em>, <em>36</em>(5), 891–908. (<a
href="https://doi.org/10.1080/10556788.2021.1891537">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper attempts to study loan interest rate Nash game models in the banking sector under regulatory solvency constraints. By taking solvency constraints as Basel I, Basel II, and Expected Shortfall (ES), we obtain results regarding the existence of loan interest rate equilibrium. A sensitivity analysis for solvency models and some numerical results are presented. Numerical results show that the weighted loan interest rate of the Mongolian banking system is consistent with the base case of the theoretical weighted loan interest rate corresponding to the Nash equilibrium.},
  archive      = {J_OMS},
  author       = {G. Battulga and L. Altangerel and G. Battur},
  doi          = {10.1080/10556788.2021.1891537},
  journal      = {Optimization Methods and Software},
  number       = {5},
  pages        = {891-908},
  shortjournal = {Optim. Methods Softw.},
  title        = {Loan interest rate nash models with solvency constraints in the banking sector},
  volume       = {36},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A generic framework for approximation analysis of greedy
algorithms for star bicoloring. <em>OMS</em>, <em>36</em>(4), 869–890.
(<a href="https://doi.org/10.1080/10556788.2019.1649671">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a generic framework for the design and comparison of polynomial-time approximation algorithms for M INIMUM S TAR B ICOLORING . This generic framework is parameterized by algorithms which produce sequences of distance- 2 independent sets. As our main technical result we show that, when the parameterized algorithm produces sequences of distance- 2 independent sets that remove at least Ω ( n ϵ ) Ω ( n ϵ ) Ω(nϵ) edges during each step, the generic framework produces a polynomial-time approximation algorithm for M INIMUM S TAR B ICOLORING that is always at least O ( n 1 − ϵ / ( 1 + ϵ ) ) of optimal. Under the generic framework, we model two algorithms for M INIMUM S TAR B ICOLORING from the literature: Complete Direct Cover ( CDC ) [Hossain and Steihaug, Computing a sparse Jacobian matrix by rows and columns , Optim. Methods Softw. 10 (1998), pp. 33–48] and ASBC [Juedes and Jones, Coloring Jacobians revisited: A new algorithm for star and acyclic bicoloring , Optim. Methods Softw. 27(1–3) (2012), pp. 295–309]. We apply our main result to show approximation upper bounds of O ( n 3 / 4 ) and O ( n 2 / 3 ) , respectively, for these two algorithms. Our approximation upper bound for CDC is the first known approximation analysis for this algorithm. In addition to modelling CDC and ASBC , we use the generic framework to build and analyze three new O ( n 2 / 3 ) approximation algorithms for M INIMUM S TAR B ICOLORING : M AX -N EIGHBORHOOD , M AX -R ATIO c , and L OCAL -S EARCH- k .},
  archive      = {J_OMS},
  author       = {David W. Juedes and Jeffrey S. Jones},
  doi          = {10.1080/10556788.2019.1649671},
  journal      = {Optimization Methods and Software},
  number       = {4},
  pages        = {869-890},
  shortjournal = {Optim. Methods Softw.},
  title        = {A generic framework for approximation analysis of greedy algorithms for star bicoloring},
  volume       = {36},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Optimization of triangular networks with spatial
constraints. <em>OMS</em>, <em>36</em>(4), 842–868. (<a
href="https://doi.org/10.1080/10556788.2019.1604703">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A common representation of a three dimensional object in computer applications, such as graphics and design, is in the form of a triangular mesh. In many instances, individual or groups of triangles in such representation need to satisfy spatial constraints that are imposed either by observation from the real world, or by concrete design specifications of the object. As these problems tend to be of large scale, choosing a mathematical optimization approach can be particularly challenging. In this paper, we model various geometric constraints as convex sets in Euclidean spaces, and find the corresponding projections in closed forms. We also present an interesting idea to successfully manoeuvre around some important non-convex constraints while still preserving the intrinsic nature of the original design problem. We then use these constructions in modern first-order splitting methods to find optimal solutions.},
  archive      = {J_OMS},
  author       = {Valentin R. Koch and Hung M. Phan},
  doi          = {10.1080/10556788.2019.1604703},
  journal      = {Optimization Methods and Software},
  number       = {4},
  pages        = {842-868},
  shortjournal = {Optim. Methods Softw.},
  title        = {Optimization of triangular networks with spatial constraints},
  volume       = {36},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Two-machine routing open shop on a tree: Instance reduction
and efficiently solvable subclass. <em>OMS</em>, <em>36</em>(4),
821–841. (<a
href="https://doi.org/10.1080/10556788.2020.1734802">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider two-machine routing open shop problem on a tree. In this problem, a transportation network with a tree-like structure is given, and each node contains some jobs to be processed by two mobile machines. Machines are initially located in the predefined node called the depot , have to traverse the network to perform their operations on each job (and each job has to be processed by both machines in arbitrary order), and machines have to return to the depot after performing all the operations. The goal is to construct a feasible schedule for machines to process all the jobs and to return to the depot in shortest time possible. This problem is known to be NP-hard even in the case when the transportation network consists of just two nodes. We propose an instance reduction procedure which allows to transform any instance of the problem to a simplified instance on a chain with limited number of jobs. The reduction considered preserves the standard lower bound on the optimum. We describe four possible outcomes of this procedure and prove that in three of them the initial instance can be solved to the optimum in linear time, thus introducing a wide polynomially solvable subclass of the problem considered. Our research can be used as a foundation to construct efficient approximation algorithms for the two-machine routing open shop on a tree.},
  archive      = {J_OMS},
  author       = {I. D. Chernykh and E. V. Lgotina},
  doi          = {10.1080/10556788.2020.1734802},
  journal      = {Optimization Methods and Software},
  number       = {4},
  pages        = {821-841},
  shortjournal = {Optim. Methods Softw.},
  title        = {Two-machine routing open shop on a tree: Instance reduction and efficiently solvable subclass},
  volume       = {36},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). New perspective on some classical results in analysis and
optimization. <em>OMS</em>, <em>36</em>(4), 811–820. (<a
href="https://doi.org/10.1080/10556788.2020.1731748">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paper illustrates connections between classical results of Analysis and Optimization. The focus is on new elementary proofs of Implicit Function Theorem, Lusternik&#39;s Theorem, and optimality conditions for equality constrained optimization problems. The proofs are based on Fermat&#39;s Theorem and the Weierstrass Theorem and do not use the contraction mapping principle or other advanced results of Real Analysis, so they can be used in any introductory course on Optimization or Real Analysis without the requirement of the advanced background in analysis. The paper also presents a simple proof of Implicit Function Theorem in normed linear spaces.},
  archive      = {J_OMS},
  author       = {Olga Brezhneva and Yuri G. Evtushenko and Alexey A. Tret&#39;yakov},
  doi          = {10.1080/10556788.2020.1731748},
  journal      = {Optimization Methods and Software},
  number       = {4},
  pages        = {811-820},
  shortjournal = {Optim. Methods Softw.},
  title        = {New perspective on some classical results in analysis and optimization},
  volume       = {36},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Primal–dual accelerated gradient methods with
small-dimensional relaxation oracle. <em>OMS</em>, <em>36</em>(4),
773–810. (<a
href="https://doi.org/10.1080/10556788.2020.1731747">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a new variant of accelerated gradient descent is proposed. The proposed method does not require any information about the objective function, uses exact line search for the practical accelerations of convergence, converges according to the well-known lower bounds for both convex and non-convex objective functions, possesses primal–dual properties and can be applied in the non-euclidian set-up. As far as we know this is the first such method possessing all of the above properties at the same time. We also present a universal version of the method which is applicable to non-smooth problems. We demonstrate how in practice one can efficiently use the combination of line-search and primal-duality by considering a convex optimization problem with a simple structure (for example, linearly constrained).},
  archive      = {J_OMS},
  author       = {Yurii Nesterov and Alexander Gasnikov and Sergey Guminov and Pavel Dvurechensky},
  doi          = {10.1080/10556788.2020.1731747},
  journal      = {Optimization Methods and Software},
  number       = {4},
  pages        = {773-810},
  shortjournal = {Optim. Methods Softw.},
  title        = {Primal–dual accelerated gradient methods with small-dimensional relaxation oracle},
  volume       = {36},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Inverse stable point problem on trees under an extension of
chebyshev norm and bottleneck hamming distance. <em>OMS</em>,
<em>36</em>(4), 755–772. (<a
href="https://doi.org/10.1080/10556788.2020.1713778">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the inverse optimization problem, we modify parameters of the original problem at minimum total cost so as to make a prespecified solution optimal with respect to new parameters. We extend in this paper a class of inverse single facility problems on trees, including inverse balance point, inverse 1-median and inverse 1-center problem, and call it the inverse stable point problem. For the general situation where variables are both edge lengths and vertex weights under an extension of Chebyshev norm and bottleneck Hamming distance, we first derive an algorithm that reduces the corresponding problem to the one under either Chebyshev norm or bottleneck Hamming distance and then develop an approximation approach for the problem. Special cases concerning the problem under this extension with strongly polynomial time algorithms are also discussed.},
  archive      = {J_OMS},
  author       = {Van Huy Pham and Kien Trung Nguyen and Tran Thu Le},
  doi          = {10.1080/10556788.2020.1713778},
  journal      = {Optimization Methods and Software},
  number       = {4},
  pages        = {755-772},
  shortjournal = {Optim. Methods Softw.},
  title        = {Inverse stable point problem on trees under an extension of chebyshev norm and bottleneck hamming distance},
  volume       = {36},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Composite optimization for the resource allocation problem.
<em>OMS</em>, <em>36</em>(4), 720–754. (<a
href="https://doi.org/10.1080/10556788.2020.1712599">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we consider resource allocation problem stated as a convex minimization problem with linear constraints. To solve this problem, we use gradient and accelerated gradient descent applied to the dual problem and prove the convergence rate both for the primal iterates and the dual iterates. We obtain faster convergence rates than the ones known in the literature. We also provide economic interpretation for these two methods. This means that iterations of the algorithms naturally correspond to the process of price and production adjustment in order to obtain the desired production volume in the economy. Overall, we show how these actions of the economic agents lead the whole system to the equilibrium.},
  archive      = {J_OMS},
  author       = {Anastasiya Ivanova and Pavel Dvurechensky and Alexander Gasnikov and Dmitry Kamzolov},
  doi          = {10.1080/10556788.2020.1712599},
  journal      = {Optimization Methods and Software},
  number       = {4},
  pages        = {720-754},
  shortjournal = {Optim. Methods Softw.},
  title        = {Composite optimization for the resource allocation problem},
  volume       = {36},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). GLS and VNS based heuristics for conflict-free
minimum-latency aggregation scheduling in WSN. <em>OMS</em>,
<em>36</em>(4), 697–719. (<a
href="https://doi.org/10.1080/10556788.2019.1710836">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a conflict-free minimum latency data aggregation problem that occurs in different wireless networks. Given a network that is presented as an undirected graph with one selected vertex (a sink), the goal is to find a spanning aggregation tree rooted in the sink and to define a conflict-free aggregation minimum length schedule along the arcs of the tree directed to the sink. Herewith, at the same time slot, each element of the network can either send or receive at most one message. Only one message should be sent by each network element during the whole aggregation session, and the conflicts caused by signal interference should be excluded. This problem is NP-hard and remains NP-hard even in the case when the aggregation tree is given. Therefore, the development of efficient approximation algorithms is very important for this problem. In this paper, we present new heuristic algorithms based on genetic local search and variable neighbourhood search metaheuristics. We conducted an extensive simulation that demonstrates the superiority of our algorithms compared with the best of the previous approaches.},
  archive      = {J_OMS},
  author       = {Roman Plotnikov and Adil Erzin and Vyacheslav Zalyubovskiy},
  doi          = {10.1080/10556788.2019.1710836},
  journal      = {Optimization Methods and Software},
  number       = {4},
  pages        = {697-719},
  shortjournal = {Optim. Methods Softw.},
  title        = {GLS and VNS based heuristics for conflict-free minimum-latency aggregation scheduling in WSN},
  volume       = {36},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). On black-box optimization in divide-and-conquer SAT solving.
<em>OMS</em>, <em>36</em>(4), 672–696. (<a
href="https://doi.org/10.1080/10556788.2019.1685993">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Solving hard instances of the Boolean satisfiability problem (SAT) in practice is an interestingly nontrivial area. The heuristic nature of SAT solvers makes it impossible to know in advance how long it will take to solve any particular SAT instance. One way of coping with this disadvantage is the Divide-and-Conquer approach when an original SAT instance is decomposed into a set of simpler subproblems. However, the way it is decomposed plays a crucial role in the resulting effectiveness of solving. In the present study, we reduce the problem of choosing a proper decomposition to a stochastic pseudo-Boolean black-box optimization problem. Several optimization algorithms of different types were used to analyse a number of hard SAT-based optimization problems, related to SAT-based cryptanalysis of state-of-the-art stream ciphers. A meticulous computational study showed that some of the considered optimization algorithms perform much better than the others in the context of the problems from the considered class. It turned out that the obtained results also pose some cryptographic interest.},
  archive      = {J_OMS},
  author       = {O. S. Zaikin and S. E. Kochemazov},
  doi          = {10.1080/10556788.2019.1685993},
  journal      = {Optimization Methods and Software},
  number       = {4},
  pages        = {672-696},
  shortjournal = {Optim. Methods Softw.},
  title        = {On black-box optimization in divide-and-conquer SAT solving},
  volume       = {36},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Preface. <em>OMS</em>, <em>36</em>(4), 671. (<a
href="https://doi.org/10.1080/10556788.2022.2061213">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_OMS},
  author       = {Milojica Jaćimović and Michael Khachay and Yury Kochetov and Mikhail Posypkin},
  doi          = {10.1080/10556788.2022.2061213},
  journal      = {Optimization Methods and Software},
  number       = {4},
  pages        = {671},
  shortjournal = {Optim. Methods Softw.},
  title        = {Preface},
  volume       = {36},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Correction. <em>OMS</em>, <em>36</em>(2-3), 669. (<a
href="https://doi.org/10.1080/10556788.2021.1923133">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_OMS},
  doi          = {10.1080/10556788.2021.1923133},
  journal      = {Optimization Methods and Software},
  number       = {2-3},
  pages        = {669},
  shortjournal = {Optim. Methods Softw.},
  title        = {Correction},
  volume       = {36},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A modified direction approach for proper efficiency of
multiobjective optimization. <em>OMS</em>, <em>36</em>(2-3), 653–668.
(<a href="https://doi.org/10.1080/10556788.2021.1891538">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to generate properly efficient solutions of a general multiobjective optimization problem, a unified direction approach was introduced by Ghaznavi et al. (Optim. Methods Softw., 2019). However, there are some deficiencies in this work, and a counterexample is given to show that properly efficient solutions of a general multiobjective optimization problem cannot be obtained via optimal solutions of the proposed scalarized problem. In the present paper, by adding slack variables and surplus variables, we modify the direction scheme proposed by Ghaznavi et al. (Optim. Methods Softw., 2019), and achieve necessary and sufficient conditions for (weakly and properly) efficient solutions of a general multiobjective optimization problem via optimal solutions of the corresponding scalarized problem. Further, the efficiency of our method is demonstrated by numerical examples. This work fills some gaps in the work of Ghaznavi et al. (Optim. Methods Softw., 2019).},
  archive      = {J_OMS},
  author       = {Liping Tang and Xinmin Yang},
  doi          = {10.1080/10556788.2021.1891538},
  journal      = {Optimization Methods and Software},
  number       = {2-3},
  pages        = {653-668},
  shortjournal = {Optim. Methods Softw.},
  title        = {A modified direction approach for proper efficiency of multiobjective optimization},
  volume       = {36},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Optimality conditions via a unified direction approach for
(approximate) efficiency in multiobjective optimization. <em>OMS</em>,
<em>36</em>(2-3), 627–652. (<a
href="https://doi.org/10.1080/10556788.2019.1571589">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The presented paper addresses scalarization techniques for multiobjective optimization problems. A new scalarization technique for solving a general multiobjective optimization problem is proposed. This scalarization method is called the unified direction method, because it generalizes the Pascoletti–Serafini approach (direction approach). Some theoretical results related to the suggested scalarization technique are established, especially the ability of the method for generating (properly, weakly) efficient solutions is shown. Moreover, the relation between approximate optimal solutions of the proposed single objective problem and approximate (weakly, properly) efficient solutions of the multiobjective optimization problem is investigated. In fact, easy-to-check, necessary and sufficient conditions for ϵ -(weak, proper) efficiency are obtained. Moreover, the effectiveness of the proposed approach is illustrated with some illustrative computational examples.},
  archive      = {J_OMS},
  author       = {M. Ghaznavi and F. Akbari and E. Khorram},
  doi          = {10.1080/10556788.2019.1571589},
  journal      = {Optimization Methods and Software},
  number       = {2-3},
  pages        = {627-652},
  shortjournal = {Optim. Methods Softw.},
  title        = {Optimality conditions via a unified direction approach for (approximate) efficiency in multiobjective optimization},
  volume       = {36},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Optimal train control via switched system dynamic
optimization. <em>OMS</em>, <em>36</em>(2-3), 602–626. (<a
href="https://doi.org/10.1080/10556788.2019.1604704">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper considers an optimal train control problem with two challenging, non-standard constraints: a speed constraint that is piecewise-constant with respect to the train&#39;s position, and control constraints that are non-smooth functions of the train&#39;s speed. We formulate this problem as an optimal switching control problem in which the mode switching times are decision variables to be optimized, and the track gradient and speed limit in each mode are constant. Then, using control parameterization and time-scaling techniques, we approximate the switching control problem by a finite-dimensional optimization problem, which is still subject to the challenging speed limit constraint (imposed continuously during each mode) and the non-smooth control constraints. We show that the speed constraint can be transformed into a finite number of point constraints. We also show that the non-smooth control constraints can be approximated by a sequence of conventional (smooth) inequality constraints. The resulting approximate problem can be viewed as a nonlinear programming problem and solved using gradient-based optimization algorithms, where the gradients of the cost and constraint functions are computed via the sensitivity method. A case study using data for a real subway line shows that the proposed method yields a realistic optimal control profile without the undesirable control fluctuations that can occur with the pseudospectral method.},
  archive      = {J_OMS},
  author       = {Weifeng Zhong and Qun Lin and Ryan Loxton and Kok Lay Teo},
  doi          = {10.1080/10556788.2019.1604704},
  journal      = {Optimization Methods and Software},
  number       = {2-3},
  pages        = {602-626},
  shortjournal = {Optim. Methods Softw.},
  title        = {Optimal train control via switched system dynamic optimization},
  volume       = {36},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A primal-dual interior point trust-region method for
nonlinear semidefinite programming. <em>OMS</em>, <em>36</em>(2-3),
569–601. (<a
href="https://doi.org/10.1080/10556788.2020.1801678">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a primal-dual interior point trust-region method for solving nonlinear semidefinite programming problems. The method consists of the outer iteration (SDPIP) that finds a Karush–Kuhn–Tucker (KKT) point and the inner iteration (SDPTR) that calculates an approximate barrier KKT point. Algorithm SDPTR combines a commutative class of Newton-like directions with the steepest descent type direction within the framework of the trust-region strategy. We present a trust-region method in primal-dual space and prove the global convergence property of the proposed method. Some numerical experiments are given. In addition, we also present second-order approximations to the primal-dual merit function, and a trust-region method in primal space in Appendix.},
  archive      = {J_OMS},
  author       = {Hiroshi Yamashita and Hiroshi Yabe and Kouhei Harada},
  doi          = {10.1080/10556788.2020.1801678},
  journal      = {Optimization Methods and Software},
  number       = {2-3},
  pages        = {569-601},
  shortjournal = {Optim. Methods Softw.},
  title        = {A primal-dual interior point trust-region method for nonlinear semidefinite programming},
  volume       = {36},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Applications of matroids in electric network theory.
<em>OMS</em>, <em>36</em>(2-3), 560–568. (<a
href="https://doi.org/10.1080/10556788.2020.1740220">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Professor Masao Iri and his students had several important contributions to the theory of electric networks. He was one of the first scientists who recognized the importance of matroid theory in studying the qualitative problems of electric networks. The present paper summarizes his results in the unique solvability of linear active networks and in the existence of hybrid immittance description of linear multiports. Then his contribution to the proper understanding of the duality principle in electric network theory is presented. The last two sections are strongly related to the concept of genericity, leading to some results in the qualitatively reliable synthesis of linear multiports and to some considerations on how to store the data of linear multiports. These applications require a broad spectrum of matroidal tools, like the matroid partition, intersection and parity algorithms and concepts like matroid union, gammoids, transversal matroids, etc. The survey is extended by some more recent results showing that the influence of Professor Iri to the younger generation of researchers will be thriving for many years to come.},
  archive      = {J_OMS},
  author       = {András Recski},
  doi          = {10.1080/10556788.2020.1740220},
  journal      = {Optimization Methods and Software},
  number       = {2-3},
  pages        = {560-568},
  shortjournal = {Optim. Methods Softw.},
  title        = {Applications of matroids in electric network theory},
  volume       = {36},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). On basic operations related to network induction of
discrete convex functions. <em>OMS</em>, <em>36</em>(2-3), 519–559. (<a
href="https://doi.org/10.1080/10556788.2020.1818080">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Discrete convex functions are used in many areas, including operations research, discrete-event systems, game theory, and economics. The objective of this paper is to investigate basic operations such as direct sum, splitting, and aggregation that are related to network induction of discrete convex functions as well as discrete convex sets. Various kinds of discrete convex functions in discrete convex analysis are considered such as integrally convex functions, L-convex functions, M-convex functions, multimodular functions, and discrete midpoint convex functions.},
  archive      = {J_OMS},
  author       = {Kazuo Murota},
  doi          = {10.1080/10556788.2020.1818080},
  journal      = {Optimization Methods and Software},
  number       = {2-3},
  pages        = {519-559},
  shortjournal = {Optim. Methods Softw.},
  title        = {On basic operations related to network induction of discrete convex functions},
  volume       = {36},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). A survey of fundamental operations on discrete convex
functions of various kinds. <em>OMS</em>, <em>36</em>(2-3), 472–518. (<a
href="https://doi.org/10.1080/10556788.2019.1692345">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Discrete convex functions are used in many areas, including operations research, discrete-event systems, game theory, and economics. The objective of this paper is to offer a survey on fundamental operations for various kinds of discrete convex functions in discrete convex analysis such as integrally convex functions, L-convex functions, M-convex functions, and multimodular functions.},
  archive      = {J_OMS},
  author       = {Kazuo Murota},
  doi          = {10.1080/10556788.2019.1692345},
  journal      = {Optimization Methods and Software},
  number       = {2-3},
  pages        = {472-518},
  shortjournal = {Optim. Methods Softw.},
  title        = {A survey of fundamental operations on discrete convex functions of various kinds},
  volume       = {36},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Solving SDP completely with an interior point oracle.
<em>OMS</em>, <em>36</em>(2-3), 425–471. (<a
href="https://doi.org/10.1080/10556788.2020.1850720">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We suppose the existence of an oracle which solves any semidefinite programming (SDP) problem satisfying strong feasibility (i.e. Slater&#39;s condition) simultaneously at its primal and dual sides. We note that such an oracle might not be able to directly solve general SDPs even after certain regularization schemes are applied. In this work we fill this gap and show how to use such an oracle to ‘completely solve’ an arbitrary SDP. Completely solving entails, for example, distinguishing between weak/strong feasibility/infeasibility and detecting when the optimal value is attained or not. We will employ several tools, including a variant of facial reduction where all auxiliary problems are ensured to satisfy strong feasibility at all sides. Our main technical innovation, however, is an analysis of double facial reduction , which is the process of applying facial reduction twice: first to the original problem and then once more to the dual of the regularized problem obtained during the first run. Although our discussion is focused on semidefinite programming, the majority of the results are proved for general convex cones.},
  archive      = {J_OMS},
  author       = {Bruno F. Lourenço and Masakazu Muramatsu and Takashi Tsuchiya},
  doi          = {10.1080/10556788.2020.1850720},
  journal      = {Optimization Methods and Software},
  number       = {2-3},
  pages        = {425-471},
  shortjournal = {Optim. Methods Softw.},
  title        = {Solving SDP completely with an interior point oracle},
  volume       = {36},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An ADMM-based interior-point method for large-scale linear
programming. <em>OMS</em>, <em>36</em>(2-3), 389–424. (<a
href="https://doi.org/10.1080/10556788.2020.1821200">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a new framework to implement interior point method (IPM) in order to solve some very large-scale linear programs (LPs). Traditional IPMs typically use Newton&#39;s method to approximately solve a subproblem that aims to minimize a log-barrier penalty function at each iteration. Due its connection to Newton&#39;s method, IPM is often classified as second-order method – a genre that is attached with stability and accuracy at the expense of scalability. Indeed, computing a Newton step amounts to solving a large system of linear equations, which can be efficiently implemented if the input data are reasonably sized and/or sparse and/or well-structured. However, in case the above premises fail, then the challenge still stands on the way for a traditional IPM. To deal with this challenge, one approach is to apply the iterative procedure, such as preconditioned conjugate gradient method, to solve the system of linear equations. Since the linear system is different in each iteration, it is difficult to find good pre-conditioner to achieve the overall solution efficiency. In this paper, an alternative approach is proposed. Instead of applying Newton&#39;s method, we resort to the alternating direction method of multipliers (ADMM) to approximately minimize the log-barrier penalty function at each iteration, under the framework of primal–dual path-following for a homogeneous self-dual embedded LP model. The resulting algorithm is an ADMM-Based Interior Point Method, abbreviated as ABIP in this paper. The new method inherits stability from IPM and scalability from ADMM. Because of its self-dual embedding structure, ABIP is set to solve any LP without requiring prior knowledge about its feasibility. We conduct extensive numerical experiments testing ABIP with large-scale LPs from NETLIB and machine learning applications. The results demonstrate that ABIP compares favourably with other LP solvers including SDPT3, MOSEK, DSDP-CG and SCS.},
  archive      = {J_OMS},
  author       = {Tianyi Lin and Shiqian Ma and Yinyu Ye and Shuzhong Zhang},
  doi          = {10.1080/10556788.2020.1821200},
  journal      = {Optimization Methods and Software},
  number       = {2-3},
  pages        = {389-424},
  shortjournal = {Optim. Methods Softw.},
  title        = {An ADMM-based interior-point method for large-scale linear programming},
  volume       = {36},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A newton-bracketing method for a simple conic optimization
problem. <em>OMS</em>, <em>36</em>(2-3), 371–388. (<a
href="https://doi.org/10.1080/10556788.2020.1782906">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For the Lagrangian-DNN relaxation of quadratic optimization problems (QOPs), we propose a Newton-bracketing method to improve the performance of the bisection-projection method implemented in BBCPOP [ACM Tran. Softw., 45(3):34 (2019)]. The relaxation problem is converted into the problem of finding the largest zero y ∗ y ∗ y∗ of a continuously differentiable (except at y ∗ y ∗ y∗ ) convex function g : ℝ → ℝ g : R → R g:R→R such that g ( y ) = 0 g ( y ) = 0 g(y)=0 if y ≤ y ∗ y ≤ y ∗ y≤y∗ and g ( y ) &gt; 0 g ( y ) &gt; 0 g(y)&amp;gt;0 otherwise. In theory, the method generates lower and upper bounds of y ∗ both converging to y ∗ . Their convergence is quadratic if the right derivative of g at y ∗ is positive. Accurate computation of g ′ ( y ) is necessary for the robustness of the method, but it is difficult to achieve in practice. As an alternative, we present a secant-bracketing method. We demonstrate that the method improves the quality of the lower bounds obtained by BBCPOP and SDPNAL+ for binary QOP instances from BIQMAC. Moreover, new lower bounds for the unknown optimal values of large scale QAP instances from QAPLIB are reported.},
  archive      = {J_OMS},
  author       = {Sunyoung Kim and Masakazu Kojima and Kim-Chuan Toh},
  doi          = {10.1080/10556788.2020.1782906},
  journal      = {Optimization Methods and Software},
  number       = {2-3},
  pages        = {371-388},
  shortjournal = {Optim. Methods Softw.},
  title        = {A newton-bracketing method for a simple conic optimization problem},
  volume       = {36},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An alternating direction method of multipliers for the
eigenvalue complementarity problem. <em>OMS</em>, <em>36</em>(2-3),
337–370. (<a
href="https://doi.org/10.1080/10556788.2020.1734804">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce an Alternating Direction Method of Multipliers (ADMM) for finding a solution of the nonsymmetric Eigenvalue Complementarity Problem (EiCP). A simpler version of this method is proposed for the symmetric EiCP, that is, for the computation of a Stationary Point (SP) of a Standard Fractional Quadratic Program. The algorithm is also extended for the computation of an SP of a Standard Quadratic Program (StQP). Convergence analyses of these three versions of ADMM are presented. The main computational effort of ADMM is the solution of a Strictly Convex StQP, which can be efficiently solved by a Block Principal Pivoting algorithm. Furthermore, this algorithm provides a stopping criterion for ADMM that improves very much its efficacy to compute an accurate solution of the EiCP. Numerical results indicate that ADMM is in general very efficient for solving symmetric EiCPs in terms of the number of iterations and computational effort, but is less efficient for the solution of nonsymmetric EiCPs. However, ADMM is able to provide a good initial point for a fast second-order method, such as the so-called Semismooth Newton method. The resulting hybrid ADMM and SN algorithm seems to be quite efficient in practice for the solution of nonsymmetric EiCPs.},
  archive      = {J_OMS},
  author       = {Joaquim J. Júdice and Masao Fukushima and Alfredo Iusem and J. M. Martinez and Valentina Sessa},
  doi          = {10.1080/10556788.2020.1734804},
  journal      = {Optimization Methods and Software},
  number       = {2-3},
  pages        = {337-370},
  shortjournal = {Optim. Methods Softw.},
  title        = {An alternating direction method of multipliers for the eigenvalue complementarity problem},
  volume       = {36},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A pfaffian formula for matching polynomials of outerplanar
graphs. <em>OMS</em>, <em>36</em>(2-3), 332–336. (<a
href="https://doi.org/10.1080/10556788.2020.1769620">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An outerplanar graph is a graph that can be drawn on the plane without crossing edges so that all vertices are on the infinite face. Most organic compounds have outerplanar graph structures. The number of matchings in the skeleton graphs of organic compounds is known as the topological index Z , introduced in the early 70s to investigate correlation between molecular structures and physical properties. This paper provides a simple formula that expresses the number of matchings, and more generally the matching polynomial, of an outerplanar graph by the Pfaffian of a certain skew-symmetrc matrix.},
  archive      = {J_OMS},
  author       = {Satoru Iwata},
  doi          = {10.1080/10556788.2020.1769620},
  journal      = {Optimization Methods and Software},
  number       = {2-3},
  pages        = {332-336},
  shortjournal = {Optim. Methods Softw.},
  title        = {A pfaffian formula for matching polynomials of outerplanar graphs},
  volume       = {36},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Extended formulations of lower-truncated transversal
polymatroids. <em>OMS</em>, <em>36</em>(2-3), 326–331. (<a
href="https://doi.org/10.1080/10556788.2020.1769619">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Extended formulations of ( k , l ) ( k , l ) (k,l) -sparsity matroids defined on graphs with n vertices and m edges are investigated by Iwata et al. [ Extended formulations for sparsity matroids , Math. Program. 158 (2016), pp. 565–574]. This note interprets results on ( k , l ) ( k , l ) (k,l) -lower-truncated transversal polymatroids by the first author in 1983, from the viewpoint of extended formulations, and shows the same O ( m n ) bound when k ≥ l and a better bound O ( m 2 ) when k &lt; l . A unified polymatroidal approach is given to derive more general understanding.},
  archive      = {J_OMS},
  author       = {Hiroshi Imai and Keiko Imai and Hidefumi Hiraishi},
  doi          = {10.1080/10556788.2020.1769619},
  journal      = {Optimization Methods and Software},
  number       = {2-3},
  pages        = {326-331},
  shortjournal = {Optim. Methods Softw.},
  title        = {Extended formulations of lower-truncated transversal polymatroids},
  volume       = {36},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Minimum point-overlap labelling*. <em>OMS</em>,
<em>36</em>(2-3), 316–325. (<a
href="https://doi.org/10.1080/10556788.2020.1833880">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In an application of map labelling to air-traffic control, labels should be placed with as few overlaps as possible since labels include important information about airplanes. Motivated by this application, de Berg and Gerrits (Comput. Geom. 2012) proposed a problem of maximizing the number of free labels (i.e. labels not intersecting with any other label) and developed approximation algorithms for their problem under various label-placement models. In this paper, we propose an alternative problem of minimizing a degree of overlap at a point. Specifically, the objective of this problem is to minimize the maximum of λ ( p ) over p ∈ R 2 , where λ ( p ) is defined as the sum of weights of labels that overlap with a point p . We develop a 4-approximation algorithm by LP-rounding under the 4-position model. We also investigate the case when labels are rectangles with bounded height/length ratios.},
  archive      = {J_OMS},
  author       = {Yuya Higashikawa and Keiko Imai and Takeharu Shiraga and Noriyoshi Sukegawa and Yusuke Yokosuka},
  doi          = {10.1080/10556788.2020.1833880},
  journal      = {Optimization Methods and Software},
  number       = {2-3},
  pages        = {316-325},
  shortjournal = {Optim. Methods Softw.},
  title        = {Minimum point-overlap labelling*},
  volume       = {36},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). On the abs-polynomial expansion of piecewise smooth
functions. <em>OMS</em>, <em>36</em>(2-3), 301–315. (<a
href="https://doi.org/10.1080/10556788.2020.1817448">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tom Streubel has observed that for functions in abs-normal form, generalized Taylor expansions of arbitrary order d ⎯ ⎯ − 1 d ¯ − 1 d¯−1 can be generated by algorithmic piecewise differentiation. Abs-normal form means that the real or vector valued function is defined by an evaluation procedure that involves the absolute value function | ⋅ | | ⋅ | |⋅| apart from arithmetic operations and d ⎯ ⎯ d ¯ d¯ times continuously differentiable univariate intrinsic functions. The additive terms in Streubel&#39;s expansion are abs-polynomial, i.e. involve neither divisions nor intrinsics. When and where no absolute values occur, Moore&#39;s recurrences can be used to propagate univariate Taylor polynomials through the evaluation procedure with a computational effort of O ( d ¯ 2 ) , provided all univariate intrinsics are defined as solutions of linear ODEs. This regularity assumption holds for all standard intrinsics, but for irregular elementaries one has to resort to Faa di Bruno&#39;s formula, which has exponential complexity in d ¯ . As already conjectured, we show that the Moore recurrences can be adapted for regular intrinsics to the abs-normal case. Finally, we observe that where the intrinsics are real analytic the expansions can be extended to infinite series that converge absolutely on spherical domains.},
  archive      = {J_OMS},
  author       = {A. Griewank and T. Streubel and C. Tischendorf},
  doi          = {10.1080/10556788.2020.1817448},
  journal      = {Optimization Methods and Software},
  number       = {2-3},
  pages        = {301-315},
  shortjournal = {Optim. Methods Softw.},
  title        = {On the abs-polynomial expansion of piecewise smooth functions},
  volume       = {36},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Mts: A light framework for parallelizing tree search codes.
<em>OMS</em>, <em>36</em>(2-3), 279–300. (<a
href="https://doi.org/10.1080/10556788.2019.1692344">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We describe mts, a generic framework for parallelizing certain types of tree search programmes including reverse search, backtracking, branch and bound and satisfiability testing. It abstracts and generalizes the ideas used in parallelizing lrs, a reverse search code for vertex enumeration. mts supports sharing information between processes which is important for applications such as satisfiability testing and branch-and-bound. No parallelization is implemented in the legacy single processor programmes minimizing the changes needed and simplifying debugging. mts is written in C, uses MPI for parallelization and can be used on a network of computers. We give four examples of reverse search codes parallelized by using mts: topological sorts, spanning trees, triangulations and Galton-Watson trees. We also give a parallelization of two codes for satisfiability testing. We give experimental results comparing the parallel codes with other codes for the same problems.},
  archive      = {J_OMS},
  author       = {David Avis and Charles Jordan},
  doi          = {10.1080/10556788.2019.1692344},
  journal      = {Optimization Methods and Software},
  number       = {2-3},
  pages        = {279-300},
  shortjournal = {Optim. Methods Softw.},
  title        = {Mts: A light framework for parallelizing tree search codes},
  volume       = {36},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Signed ring families and signed posets. <em>OMS</em>,
<em>36</em>(2-3), 262–278. (<a
href="https://doi.org/10.1080/10556788.2020.1740219">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The one-to-one correspondence between finite distributive lattices and finite partially ordered sets (posets) is a well-known theorem of G. Birkhoff. This implies a nice representation of any distributive lattice by its corresponding poset, where the size of the former (distributive lattice) is often exponential in the size of the underlying set of the latter (poset). A lot of engineering and economic applications bring us distributive lattices as a ring family of sets which is closed with respect to the set union and intersection. When it comes to a ring family of sets, the underlying set is partitioned into subsets (or components) and we have a poset structure on the partition. This is a set-theoretical variant of the Birkhoff theorem revealing the correspondence between finite ring families and finite posets on partitions of the underlying sets, which was pursued by Masao Iri around 1978, especially concerned with what is called the principal partition of discrete systems such as graphs, matroids, and polymatroids. In the present paper we investigate a signed-set version of the Birkhoff-Iri decomposition in terms of signed ring family, which corresponds to Reiner&#39;s result on signed posets, a signed counterpart of the Birkhoff theorem. We show that given a signed ring family, we have a signed partition of the underlying set together with a signed poset on the signed partition which represents the given signed ring family. This representation is unique up to certain reflections.},
  archive      = {J_OMS},
  author       = {Kazutoshi Ando and Satoru Fujishige},
  doi          = {10.1080/10556788.2020.1740219},
  journal      = {Optimization Methods and Software},
  number       = {2-3},
  pages        = {262-278},
  shortjournal = {Optim. Methods Softw.},
  title        = {Signed ring families and signed posets},
  volume       = {36},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Inexact SARAH algorithm for stochastic optimization.
<em>OMS</em>, <em>36</em>(1), 237–258. (<a
href="https://doi.org/10.1080/10556788.2020.1818081">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We develop and analyse a variant of the SARAH algorithm, which does not require computation of the exact gradient. Thus this new method can be applied to general expectation minimization problems rather than only finite sum problems. While the original SARAH algorithm, as well as its predecessor, SVRG, requires an exact gradient computation on each outer iteration, the inexact variant of SARAH (iSARAH), which we develop here, requires only stochastic gradient computed on a mini-batch of sufficient size. The proposed method combines variance reduction via sample size selection and iterative stochastic gradient updates. We analyse the convergence rate of the algorithms for strongly convex and non-strongly convex cases, under smooth assumption with appropriate mini-batch size selected for each case. We show that with an additional, reasonable, assumption iSARAH achieves the best-known complexity among stochastic methods in the case of non-strongly convex stochastic functions.},
  archive      = {J_OMS},
  author       = {Lam M. Nguyen and Katya Scheinberg and Martin Takáč},
  doi          = {10.1080/10556788.2020.1818081},
  journal      = {Optimization Methods and Software},
  number       = {1},
  pages        = {237-258},
  shortjournal = {Optim. Methods Softw.},
  title        = {Inexact SARAH algorithm for stochastic optimization},
  volume       = {36},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multistage stochastic programs with a random number of
stages: Dynamic programming equations, solution methods, and application
to portfolio selection. <em>OMS</em>, <em>36</em>(1), 211–236. (<a
href="https://doi.org/10.1080/10556788.2020.1800007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce the class of multistage stochastic optimization problems with a random number of stages. For such problems, we show how to write dynamic programming equations and how to solve these equations using the Stochastic Dual Dynamic Programming algorithm. Finally, we consider a portfolio selection problem over an optimization period of random duration. For several instances of this problem, we show the gain obtained using a policy that takes the randomness of the number of stages into account over a policy built taking a fixed number of stages (namely the maximal possible number of stages).},
  archive      = {J_OMS},
  author       = {Vincent Guigues},
  doi          = {10.1080/10556788.2020.1800007},
  journal      = {Optimization Methods and Software},
  number       = {1},
  pages        = {211-236},
  shortjournal = {Optim. Methods Softw.},
  title        = {Multistage stochastic programs with a random number of stages: Dynamic programming equations, solution methods, and application to portfolio selection},
  volume       = {36},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A dual approach for optimal algorithms in distributed
optimization over networks. <em>OMS</em>, <em>36</em>(1), 171–210. (<a
href="https://doi.org/10.1080/10556788.2020.1750013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study dual-based algorithms for distributed convex optimization problems over networks, where the objective is to minimize a sum ∑ m i = 1 f i ( z ) ∑ i = 1 m f i ( z ) ∑ i = 1 m f i ( z ) of functions over in a network. We provide complexity bounds for four different cases, namely: each function f i f i f i is strongly convex and smooth, each function is either strongly convex or smooth, and when it is convex but neither strongly convex nor smooth. Our approach is based on the dual of an appropriately formulated primal problem, which includes a graph that models the communication restrictions. We propose distributed algorithms that achieve the same optimal rates as their centralized counterparts (up to constant and logarithmic factors), with an additional optimal cost related to the spectral properties of the network. Initially, we focus on functions for which we can explicitly minimize its Legendre–Fenchel conjugate, i.e. admissible or dual friendly functions. Then, we study distributed optimization algorithms for non-dual friendly functions, as well as a method to improve the dependency on the parameters of the functions involved. Numerical analysis of the proposed algorithms is also provided.},
  archive      = {J_OMS},
  author       = {César A. Uribe and Soomin Lee and Alexander Gasnikov and Angelia Nedić},
  doi          = {10.1080/10556788.2020.1750013},
  journal      = {Optimization Methods and Software},
  number       = {1},
  pages        = {171-210},
  shortjournal = {Optim. Methods Softw.},
  title        = {A dual approach for optimal algorithms in distributed optimization over networks},
  volume       = {36},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). On inexact solution of auxiliary problems in tensor methods
for convex optimization. <em>OMS</em>, <em>36</em>(1), 145–170. (<a
href="https://doi.org/10.1080/10556788.2020.1731749">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study the auxiliary problems that appear in p -order tensor methods for unconstrained minimization of convex functions with ν -Hölder continuous p th derivatives. This type of auxiliary problems corresponds to the minimization of a ( p + ν ) ( p + ν ) ( p + ν ) -order regularization of the p th-order Taylor approximation of the objective. For the case p = 3, we consider the use of Gradient Methods with Bregman distance. When the regularization parameter is sufficiently large, we prove that the referred methods take at most O ( log ⁡ ( ϵ − 1 ) ) iterations to find either a suitable approximate stationary point of the tensor model or an ε -approximate stationary point of the original objective function.},
  archive      = {J_OMS},
  author       = {G.N. Grapiglia and Yu. Nesterov},
  doi          = {10.1080/10556788.2020.1731749},
  journal      = {Optimization Methods and Software},
  number       = {1},
  pages        = {145-170},
  shortjournal = {Optim. Methods Softw.},
  title        = {On inexact solution of auxiliary problems in tensor methods for convex optimization},
  volume       = {36},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). COCO: A platform for comparing continuous optimizers in a
black-box setting. <em>OMS</em>, <em>36</em>(1), 114–144. (<a
href="https://doi.org/10.1080/10556788.2020.1808977">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce COCO, an open-source platform for Comparing Continuous Optimizers in a black-box setting. COCO aims at automatizing the tedious and repetitive task of benchmarking numerical optimization algorithms to the greatest possible extent. The platform and the underlying methodology allow to benchmark in the same framework deterministic and stochastic solvers for both single and multiobjective optimization. We present the rationals behind the (decade-long) development of the platform as a general proposition for guidelines towards better benchmarking. We detail underlying fundamental concepts of COCO such as the definition of a problem as a function instance, the underlying idea of instances, the use of target values, and runtime defined by the number of function calls as the central performance measure. Finally, we give a quick overview of the basic code structure and the currently available test suites.},
  archive      = {J_OMS},
  author       = {Nikolaus Hansen and Anne Auger and Raymond Ros and Olaf Mersmann and Tea Tušar and Dimo Brockhoff},
  doi          = {10.1080/10556788.2020.1808977},
  journal      = {Optimization Methods and Software},
  number       = {1},
  pages        = {114-144},
  shortjournal = {Optim. Methods Softw.},
  title        = {COCO: A platform for comparing continuous optimizers in a black-box setting},
  volume       = {36},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Modified popov’s explicit iterative algorithms for solving
pseudomonotone equilibrium problems. <em>OMS</em>, <em>36</em>(1),
82–113. (<a
href="https://doi.org/10.1080/10556788.2020.1734805">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes two algorithms that are based on a subgradient and an inertial scheme with the explicit iterative method for solving pseudomonotone equilibrium problems. The weak convergence of both algorithms is well-established under standard assumptions on the cost bifunction. The advantage of these algorithms is that they did not require any line search procedure or any knowledge about bifunction Lipschitz-type constants for step-size evaluation. A practical explanation of this is that they use a sequence of step-size that are revised at each iteration based on some previous iteration. For a numerical experiment, we consider a well-known Nash-Cournot equilibrium model of electricity markets and also other test problems to assist the well-established convergence results and be able to see that our proposed algorithms have a competitive advantage over the time of execution and the number of iterations.},
  archive      = {J_OMS},
  author       = {Habib ur Rehman and Poom Kumam and Yeol Je Cho and Yusuf I. Suleiman and Wiyada Kumam},
  doi          = {10.1080/10556788.2020.1734805},
  journal      = {Optimization Methods and Software},
  number       = {1},
  pages        = {82-113},
  shortjournal = {Optim. Methods Softw.},
  title        = {Modified popov&#39;s explicit iterative algorithms for solving pseudomonotone equilibrium problems},
  volume       = {36},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Mathematical programs with equilibrium constraints: A
sequential optimality condition, new constraint qualifications and
algorithmic consequences. <em>OMS</em>, <em>36</em>(1), 45–81. (<a
href="https://doi.org/10.1080/10556788.2019.1702661">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mathematical programs with equilibrium constraints is a difficult class of constrained optimization problems. The feasible set has a very special structure and violates most of the standard constraint qualifications. Thus, the Karush–Kuhn–Tucker conditions are not necessarily satisfied at minimizers, and the convergence assumptions of many methods for solving constrained optimization problems are not fulfilled. Thus, it is necessary, from a theoretical and numerical point of view, to consider suitable optimality conditions, tailored constraints qualifications, and designed algorithms for solving such optimization problems. In this paper, we present a new sequential optimality condition useful for the convergence analysis of several methods for solving mathematical programs with equilibrium constraints such as relaxations schemes, complementarity-penalty methods, and interior-relaxation methods. Furthermore, the weakest constraint qualification for M-stationarity associated with such sequential optimality condition is presented. Relations between the old and new constraint qualifications, as well as the algorithmic consequences, will be discussed.},
  archive      = {J_OMS},
  author       = {Alberto Ramos},
  doi          = {10.1080/10556788.2019.1702661},
  journal      = {Optimization Methods and Software},
  number       = {1},
  pages        = {45-81},
  shortjournal = {Optim. Methods Softw.},
  title        = {Mathematical programs with equilibrium constraints: A sequential optimality condition, new constraint qualifications and algorithmic consequences},
  volume       = {36},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An accelerated communication-efficient primal-dual
optimization framework for structured machine learning. <em>OMS</em>,
<em>36</em>(1), 20–44. (<a
href="https://doi.org/10.1080/10556788.2019.1650361">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Distributed optimization algorithms are essential for training machine learning models on very large-scale datasets. However, they often suffer from communication bottlenecks. Confronting this issue, a communication-efficient primal-dual coordinate ascent framework (CoCoA) and its improved variant CoCoA+ have been proposed, achieving a convergence rate of 𝒪 ( 1 / t ) O ( 1 / t ) O(1/t) for solving empirical risk minimization problems with Lipschitz continuous losses. In this paper, an accelerated variant of CoCoA+ is proposed and shown to possess a convergence rate of O ( 1 / t 2 ) in terms of reducing suboptimality. The analysis of this rate is also notable in that the convergence rate bounds involve constants that, except in extreme cases, are significantly reduced compared to those previously provided for CoCoA+. The results of numerical experiments are provided to show that acceleration can lead to significant performance gains.},
  archive      = {J_OMS},
  author       = {Chenxin Ma and Martin Jaggi and Frank E. Curtis and Nathan Srebro and Martin Takáč},
  doi          = {10.1080/10556788.2019.1650361},
  journal      = {Optimization Methods and Software},
  number       = {1},
  pages        = {20-44},
  shortjournal = {Optim. Methods Softw.},
  title        = {An accelerated communication-efficient primal-dual optimization framework for structured machine learning},
  volume       = {36},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An inertial extrapolation method for convex simple bilevel
optimization. <em>OMS</em>, <em>36</em>(1), 1–19. (<a
href="https://doi.org/10.1080/10556788.2019.1619729">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a scalar objective minimization problem over the solution set of another optimization problem. This problem is known as a simple bilevel optimization problem and has drawn a significant attention in the last few years. Our inner problem consists of minimizing the sum of smooth and non-smooth functions while the outer one is the minimization of a smooth convex function. We first formulate and give strong convergence analysis of an inertial algorithm for fixed-point problem of a non-expansive operator in an infinite dimensional Hilbert space. Then we convert the simple bilevel optimization problem to a fixed-point problem of a non-expansive operator in finite dimensional space and design the corresponding algorithm and establish its convergence. Our numerical experiments show that the proposed method in this paper outperforms the currently known best algorithm to solve the class of bilevel optimization problem considered.},
  archive      = {J_OMS},
  author       = {Yekini Shehu and Phan Tu Vuong and Alain Zemkoho},
  doi          = {10.1080/10556788.2019.1619729},
  journal      = {Optimization Methods and Software},
  number       = {1},
  pages        = {1-19},
  shortjournal = {Optim. Methods Softw.},
  title        = {An inertial extrapolation method for convex simple bilevel optimization},
  volume       = {36},
  year         = {2021},
}
</textarea>
</details></li>
</ul>

</body>
</html>
