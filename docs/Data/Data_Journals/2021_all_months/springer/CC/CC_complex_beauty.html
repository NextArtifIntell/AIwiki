<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>CC_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="cc---112">CC - 112</h2>
<ul>
<li><details>
<summary>
(2021). Density peaks clustering based on jaccard similarity and
label propagation. <em>CC</em>, <em>13</em>(6), 1609–1626. (<a
href="https://doi.org/10.1007/s12559-021-09906-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cognitive computing involves discovering hidden rules and patterns in massive volumes of data. Density peaks clustering (DPC) is a powerful data mining tool that can identify density peaks in decision graphs and assign labels to them without requiring iterations. It can efficiently and simply detect clusters of arbitrary shapes. However, on the one hand, density measurement using the ϵ neighbor or Gaussian kernel only reflects the global structure of the data, so that correct density peaks cannot be found, and performance on manifold datasets is weakened. On the other hand, the one-step allocation strategy results in chain reaction. Once a point with high density is misallocated, a series of points will be incorrectly assigned. To solve this problem, this paper proposes the Jaccard coefficient to measure the similarity between points. The proposed density measurement based on Jaccard coefficient is only related to the k points that share the max similarity with the given point, which can reflect the local structure of manifold datasets, and the density peaks can be identified accurately. Aiming at the chain reaction caused by the assignment strategy of DPC, we develop a two-step allocation strategy based on label propagation and the proposed measurement of similarity. The first step is to assign labels to points close to the clustering centers, where these are equal to labeled points in the label propagation algorithm. The second step is to complete the assignment of labels to the remaining points according to labeled data which is the nearest to each unassigned sample. We compared the proposed algorithm with four algorithms on synthetic datasets and real-world datasets. The three metrics among these algorithms show that the proposed algorithm outperforms other algorithms. The results of clustering on synthetic datasets verified the effectiveness of the proposed method for manifold datasets, and three metrics on the UCI datasets and the Olivetti Faces dataset show that it can reveal the patterns and associations of real-world datasets.},
  archive      = {J_CC},
  author       = {Qin, Xiaowei and Han, Xiaoxia and Chu, Junwen and Zhang, Yan and Xu, Xinying and Xie, Jun and Xie, Gang},
  doi          = {10.1007/s12559-021-09906-w},
  journal      = {Cognitive Computation},
  month        = {11},
  number       = {6},
  pages        = {1609-1626},
  shortjournal = {Cogn. Comput.},
  title        = {Density peaks clustering based on jaccard similarity and label propagation},
  volume       = {13},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Scaffold-a549: A benchmark 3D fluorescence image dataset for
unsupervised nuclei segmentation. <em>CC</em>, <em>13</em>(6),
1603–1608. (<a
href="https://doi.org/10.1007/s12559-021-09944-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A general trend of nuclei segmentation is the transition from two-dimensional to three-dimensional nuclei segmentation and from traditional image processing methods to data-driven cognitively inspired methods. Existing nuclei segmentation datasets do not meet this trend: They either do not contain enough samples for training the deep learning model or not contain challenging 3D structure. Thus, large-scale datasets are critically demanded for nuclei segmentation tasks. In this paper, we introduce a new benchmark nuclei segmentation dataset termed as Scaffold-A549 for 3D cell culture on bio-scaffold. The A549 human non-small cell lung cancer cells are seeded in the bio-scaffold for cell culture and the samples with different density of nuclei are captured using confocal laser scanning microscope at the first, third, and eighth culture day. A total of 21 3D images are collected containing more than 10,000 nucleus and each of the images containing more than 800 nucleus are annotated manually for evaluation. Scaffold-A549 presents one large, diverse, challenging, and publicly available dataset and can be widely used for the research on 3D unsupervised nuclei segmentation.},
  archive      = {J_CC},
  author       = {Yao, Kai and Huang, Kaizhu and Sun, Jie and Jing, Linzhi and Huang, Dejian and Jude, Curran},
  doi          = {10.1007/s12559-021-09944-4},
  journal      = {Cognitive Computation},
  month        = {11},
  number       = {6},
  pages        = {1603-1608},
  shortjournal = {Cogn. Comput.},
  title        = {Scaffold-a549: A benchmark 3D fluorescence image dataset for unsupervised nuclei segmentation},
  volume       = {13},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multiple reliable structured patches for object tracking.
<em>CC</em>, <em>13</em>(6), 1593–1602. (<a
href="https://doi.org/10.1007/s12559-020-09741-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is essential to build the effective appearance model for object tracking in computer vision. Most object trackers can be roughly divided into two categories according to the appearance model: the bounding box model and the patch model. The bounding box model cannot handle shape deformation and occlusion of the non-rigid moving object effectively. The patch model is prone to be disturbed by complex backgrounds. In this paper, we propose a robust multi-structured-patch appearance model to represent the target for object tracking. The proposed appearance model is aimed to exploit and identify reliable patches that can be tracked effectively through the whole tracking process. According to attention mechanism in biological vision system, a coarse-to-fine strategy is usually used to search the target. Therefore, the proposed appearance model is represented by robust patches in different sizes, in which the bigger patches search the rough region of the target and the smaller patches estimate the accurate location. Experimental results on OTB100 dataset show that the proposed method outperforms state-of-the-art trackers.},
  archive      = {J_CC},
  author       = {Wu, Siyuan and Huang, Ju and Feng, Yachuang and Sun, Bangyong},
  doi          = {10.1007/s12559-020-09741-5},
  journal      = {Cognitive Computation},
  month        = {11},
  number       = {6},
  pages        = {1593-1602},
  shortjournal = {Cogn. Comput.},
  title        = {Multiple reliable structured patches for object tracking},
  volume       = {13},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Deep nonlinear ensemble framework for stock index
forecasting and uncertainty analysis. <em>CC</em>, <em>13</em>(6),
1574–1592. (<a
href="https://doi.org/10.1007/s12559-021-09961-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stock index forecasting plays an important role in avoiding risk and increasing returns for financial regulators and investors. However, due to the volatility and uncertainty of the stock market, forecasting stock indices accurately is challenging. In this paper, a deep nonlinear ensemble framework is proposed for stock index forecasting and uncertainty analysis. (1) Singular spectrum analysis (SSA) is utilized to extract features from a raw stock index and eliminate the interference. (2) Enhanced weighted support vector machine (EWSVM) is proposed for forecasting each component that is decomposed, of which the penalty weights are based on the time order and the hyperparameters are optimized using the simulated annealing algorithm. (3) Recurrent neural network (RNN) is used to integrate the forecast of each component into the final point forecast. (4) Gaussian process regression (GPR) is applied to obtain the interval forecast of the original stock index. Two practical cases (Nikkei 225 Index, Japan and Hang Seng Index, Hong Kong, China) are utilized to evaluate the performance of the proposed model. In terms of the results of point forecasting, the MAE, $${R}^{2}$$ , MAPE, and RMSE of Nikkei 225 Index are 66.0745, 0.9972, 0.0066, and 80.0381, and those of Hang Seng Index are 79.2145,0.9968, 0.0073, and 96.7740. In terms of the results of interval forecasting, the $${CP}_{95\%}$$ , $${MWP}_{95\%}$$ , and $${MC}_{95\%}$$ of Nikkei 225 Index are 0.89979, 0.05746, and 0.06385, and those of Hang Seng Index are 0.97985, 0.28223, and 0.28803. Forecasting stock indices accurately is crucial for investment decision and risk management and is extremely meaningful to investors and financial regulators. In this paper, the SSA-EWSVM-RNN-GPR model is used to forecast the closing prices of stock indices, and compared with eight benchmark models, the proposed SSA-EWSVM-RNN-GPR model can be an effective tool for both point and interval forecasting of stock indices.},
  archive      = {J_CC},
  author       = {Wang, Jujie and Feng, Liu and Li, Yang and He, Junjie and Feng, Chunchen},
  doi          = {10.1007/s12559-021-09961-3},
  journal      = {Cognitive Computation},
  month        = {11},
  number       = {6},
  pages        = {1574-1592},
  shortjournal = {Cogn. Comput.},
  title        = {Deep nonlinear ensemble framework for stock index forecasting and uncertainty analysis},
  volume       = {13},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A graph-based semi-supervised multi-label learning method
based on label correlation consistency. <em>CC</em>, <em>13</em>(6),
1564–1573. (<a
href="https://doi.org/10.1007/s12559-021-09912-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-label learning deals with the problem which each data example can be represented by an instance and associated with a set of labels, i.e., every example can be classified into multiple classes simultaneously. Most of the existing multi-label learning methods are supervised which cannot deal with such application scenarios where manually labeling the data is very expensive and time-consuming while the unlabeled data are very cheap and easy to obtain. This paper proposes an ensemble learning method which integrates multi-label learning and graph-based semi-supervised learning into one framework. The label correlation consistency is introduced to deal with the multi-label learning. The proposed method has been evaluated on five public multi-label datasets by comparing it with state-of-the-art supervised and semi-supervised multi-label methods according to multiple evaluation metrics to confirm its effectiveness. Experimental results show that the proposed method can achieve the comparable performance compared with the state-of-the-art methods. Furthermore, it is more confident on every single predicted label.},
  archive      = {J_CC},
  author       = {Zhang, Qin and Zhong, Guoqiang and Dong, Junyu},
  doi          = {10.1007/s12559-021-09912-y},
  journal      = {Cognitive Computation},
  month        = {11},
  number       = {6},
  pages        = {1564-1573},
  shortjournal = {Cogn. Comput.},
  title        = {A graph-based semi-supervised multi-label learning method based on label correlation consistency},
  volume       = {13},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An improved neuro-fuzzy generalized predictive control of
ultra-supercritical power plant. <em>CC</em>, <em>13</em>(6), 1556–1563.
(<a href="https://doi.org/10.1007/s12559-021-09949-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A generalized predictive control method based on neuro-fuzzy network (NFN-GPC) is presented for a 1000-MW ultra-supercritical (USC) power plant to improve control performance. First, to decrease the nonlinearity, local linear models are elaborately constructed for approximating the studied system by virtue of neuro-fuzzy network (NFN). Second, a compensation mechanism is delicately developed to further increase the accuracy of local models. Through gauss function and B-spline function, the memberships of local models which represent the weights of local regions are determined. Finally, based on the obtained models, a multi-variable generalized predictive controller is designed to realize the optimal control over the whole operating region combined with the membership of the current neuro-fuzzy network. This scheme closely connects engineering with artificial intelligence; compared with traditional generalized predictive control, the merit of proposed NFN-GPC is that it can capture the details over the whole operating range which can get more accurate and faster control effects. The simulation results show that the proposed neuro-fuzzy generalized predictive control method can achieve the satisfactory performance even in the case of strong coupling and nonlinearity. In conclusion, the proposed method is an effective long-term approach to control the USC power plant.},
  archive      = {J_CC},
  author       = {Cheng, Chuanliang and Peng, Chen and Zeng, Deliang and Gang, Yusen and Mi, Hanyu},
  doi          = {10.1007/s12559-021-09949-z},
  journal      = {Cognitive Computation},
  month        = {11},
  number       = {6},
  pages        = {1556-1563},
  shortjournal = {Cogn. Comput.},
  title        = {An improved neuro-fuzzy generalized predictive control of ultra-supercritical power plant},
  volume       = {13},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Classification-level and class-level complement information
measures based on neighborhood decision systems. <em>CC</em>,
<em>13</em>(6), 1530–1555. (<a
href="https://doi.org/10.1007/s12559-021-09921-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Information measures in neighborhood decision systems underlie information processing and uncertainty measurement, especially regarding neighborhood rough sets. Their constructions on covering structuring and neighborhood counting can acquire theoretical extensions and practical compactness but become difficult and rare when comparing the sample counting approach and its defects. In terms of three-way information measures (i.e., information entropy, conditional entropy, and mutual information), classification-level and class-level complement information measures are established by extending equivalence decision systems to neighborhood decision systems; thus, the construction on nonrepetitive neighborhoods becomes ingenious, and the study of criss-cross structuring and granulation properties becomes valuable. At the classification level, neighborhood-complement information measures are proposed by imitation; they perfectly expand existing complement information measures, and thus, they offer an extended isomorphism regarding systematicity. At the class level, neighborhood-complement information measures are determined by decomposition to generate a hierarchical isomorphism, and they also induce equivalence-complement information measures to yield a degenerate isomorphism. Then, granulation nonmonotonicity and monotonicity of neighborhood-complement information measures are revealed at these two levels, and their uncertainty mechanisms are analyzed deeply by three-level granular structures. Finally, all complement measures are calculated programmatically, and their relationships and nonmonotonicity or monotonicity are effectively verified by virtue of table examples and data experiments. In summary, systematically, there are four criss-cross modes of three-way complement information measures based on two knowledge granulations and two decision levels; the variably extended and degenerated isomorphisms and hierarchically decomposed and integrated isomorphisms are thoroughly uncovered, the granulation nonmonotonicity and monotonicity are deeply mined, and all achievements are found to have good application prospects for feature reduction and rule induction in machine learning.},
  archive      = {J_CC},
  author       = {Zhang, Xianyong and Fan, Yunrui and Chen, Shuai and Tang, Lingyu and Lv, Zhiying},
  doi          = {10.1007/s12559-021-09921-x},
  journal      = {Cognitive Computation},
  month        = {11},
  number       = {6},
  pages        = {1530-1555},
  shortjournal = {Cogn. Comput.},
  title        = {Classification-level and class-level complement information measures based on neighborhood decision systems},
  volume       = {13},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Idempotent computing rules and novel comparative laws for
hesitant fuzzy cognitive information and their application to
multiattribute decision making. <em>CC</em>, <em>13</em>(6), 1515–1529.
(<a href="https://doi.org/10.1007/s12559-021-09937-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hesitant fuzzy cognitive information provides an effective and convenient form for expressing human subjective cognition about the research object, i.e., hesitant fuzzy sets (HFSs). Studies on decision making with HFSs have become an important branch in decision theory, in which operational laws of hesitant fuzzy elements (HFEs) play a core role in the solution. However, current HFE computational laws have the disadvantages of subjectivity and dimensional problems. Therefore, how to define an objective HFE operational rule without dimensional problems is an open issue. This paper introduces an idempotent HFE computing rule to overcome current disadvantages. The weighted mean of HFEs under the developed computing rule is further discussed. In addition, a novel comparison law between HFEs is proposed. The property of idempotence is introduced to provide an intuitive integrated result of HFEs. To decrease the integrated HFEs dimensions, the sliding window model is utilized. Fundamental mathematical properties of the developed operations are discussed. Furthermore, the normal weighted means of HFEs are extended by using the developed idempotent computing rules. Finally, a novel comparison law for comparing HFEs is designed, which is further used to provide a multiattribute decision procedure. Additive idempotent is developed as a special and intuitive property for the HFE additive operation. Normal weighted means of HFEs, including arithmetic and geometric means, are correspondingly derived. Numerical examples have shown that the proposed HFE operational laws are valid, which can effectively decrease the dimensions of integrated results. The developed idempotent computing rules provide a novel HFE algebra structure, which includes the additive operation, multiplicative operation, scalar multiplication and power operation. By using the sliding window model, the developed idempotent computing rules can effectively reduce the integrated HFEs dimensions. The strength of the developed computational model is that integrating two identical pieces of cognitive information produces the same result. In addition, the modified HFE comparison law can overcome the drawback of current comparison laws, and a much more reasonable comparison result can be obtained.},
  archive      = {J_CC},
  author       = {Tao, Zhifu and Zhou, Ligang and Liu, Jinpei and Chen, Huayou},
  doi          = {10.1007/s12559-021-09937-3},
  journal      = {Cognitive Computation},
  month        = {11},
  number       = {6},
  pages        = {1515-1529},
  shortjournal = {Cogn. Comput.},
  title        = {Idempotent computing rules and novel comparative laws for hesitant fuzzy cognitive information and their application to multiattribute decision making},
  volume       = {13},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Consensus building in multi-criteria group decision-making
with single-valued neutrosophic sets. <em>CC</em>, <em>13</em>(6),
1496–1514. (<a
href="https://doi.org/10.1007/s12559-021-09913-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to obtain high satisfaction from experts, the consensus reaching process (CRP) is an essential requirement for dealing with multi-criteria group decision making (MCGDM) problems. Single-valued neutrosophic number (SVNN) is an effective tool to describe the uncertainty of the expert cognition. Thus, we develop a consensus reaching model for single-valued neutrosophic MCGDM in this paper. First, each expert makes his/her judgment on each alternative with respect to multiple criteria by SVNNs, and the group solution is obtained by the generalized Shapley single-valued neutrosophic Choquet integral (GS-SVNCI) operator to consider the correlations among elements comprehensively. Second, the projection-based consensus measure is proposed to reflect the agreement between the individual and collective opinions. Then, a threshold value is used to determine the CRP whether to be executed based on the expert’s consensus level. If yes, the feedback mechanism provides the experts with personalized adjustment advices based on their psychic utility to group pressure. Finally, we illustrate the feasibility of the proposed consensus model by an example and analyze the superiority by comparing with some existing MCGDM methods and different CRP models. The developed consensus model can consider interrelationships between experts, which is more effective and reasonable to obtain the collective resolution. Further, the consensus measure based on the projection can comprehensively reflect the closeness between the individual and collective opinions. In addition, the personalized adjustment advices considering the experts’ psychic utility to group pressure improve their acceptance of these advices.},
  archive      = {J_CC},
  author       = {You, Xinli and Hou, Fujun and Lou, Zhenkai},
  doi          = {10.1007/s12559-021-09913-x},
  journal      = {Cognitive Computation},
  month        = {11},
  number       = {6},
  pages        = {1496-1514},
  shortjournal = {Cogn. Comput.},
  title        = {Consensus building in multi-criteria group decision-making with single-valued neutrosophic sets},
  volume       = {13},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-segment majority voting decision fusion for MI EEG
brain-computer interfacing. <em>CC</em>, <em>13</em>(6), 1484–1495. (<a
href="https://doi.org/10.1007/s12559-021-09953-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Brain-computer interfaces (BCIs) based on the electroencephalogram (EEG) generated during motor imagery (MI) have the potential to be used in brain-controlled prosthetics, neurorehabilitation and gaming. Many MI EEG classification systems segment EEG into windows for classification. However, a comprehensive analysis of decision fusion based on the segmented EEG data, within the context of different classifiers, has not been carried out. This study presents a multi-segment majority voting (MSMV) decision fusion approach in which an EEG trial is segmented using overlapping windows. Segments are labelled and a final classification label for the trial is derived through majority voting, using the common spatial pattern (CSP) features. The impact of the MSMV approach on the classification accuracy of six classifiers was investigated. The effects of window size and overlap were analysed. Results were generated using five different subsets of EEG channels, and channel subsets for static EEG analysis are also proposed. The BCI Competition III dataset IVa was used. The MSMV decision fusion approach was found to significantly improve the classification accuracy for linear discriminant analysis (LDA), support vector machine (SVM), naïve-Bayes (NB) and random forest (RF) classifiers. The classification accuracy was improved by 5.02%, 4.41%, 1.25% and 3.62% for the SVM, LDA, NB and RF classifiers, respectively. The channel analysis indicated the importance of central-parietal and central-frontal electrode regions for MI EEG classification. MSMV decision fusion improved MI EEG classification performance and could be considered for future studies, particularly in online systems that deal with buffered data.},
  archive      = {J_CC},
  author       = {Padfield, Natasha and Ren, Jinchang and Qing, Chunmei and Murray, Paul and Zhao, Huimin and Zheng, Jiangbin},
  doi          = {10.1007/s12559-021-09953-3},
  journal      = {Cognitive Computation},
  month        = {11},
  number       = {6},
  pages        = {1484-1495},
  shortjournal = {Cogn. Comput.},
  title        = {Multi-segment majority voting decision fusion for MI EEG brain-computer interfacing},
  volume       = {13},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An efficient medical assistive diagnostic algorithm for
visualisation of structural and tissue details in CT and MRI fusion.
<em>CC</em>, <em>13</em>(6), 1471–1483. (<a
href="https://doi.org/10.1007/s12559-021-09958-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Clinicians often have to switch amongst radiographic scans in order to trace out patterns in various tissue striations. The conglomerated view of structural and anatomical view in medical scans can facilitate the physicians to execute precise diagnosis, intraoperative guidance, and planning preoperative procedures. Due to inherent physical limitations, source images have prevalence of noise and ambient light. This results in lower contrast and limited visual perception of striations and tissues in fused radiographic images. This paper proposes a concatenated filtering image fusion approach employing space segmentation and non-prior-based contrast enhancement. The latent row rank theory approach implements sub-space segmentation addressing the issue of noise removal, and the non-local-prior-based enhancement removes the ambient light from source images fortifying edge details and information. This complex fusion framework is designed in non-sub-sampled contourlet transform which exhibits computational efficiency. The final fused image obtained using local Laplacian energy fusion rule results in improved localisation of structural and anatomical details of brain tissue and outperforms high-performing fusion methods in literature both objectively with high fusion rate along with better quality visual results.},
  archive      = {J_CC},
  author       = {Goyal, Bhawna and Dogra, Ayush and Khoond, Rahul and Al-Turjman, Fadi},
  doi          = {10.1007/s12559-021-09958-y},
  journal      = {Cognitive Computation},
  month        = {11},
  number       = {6},
  pages        = {1471-1483},
  shortjournal = {Cogn. Comput.},
  title        = {An efficient medical assistive diagnostic algorithm for visualisation of structural and tissue details in CT and MRI fusion},
  volume       = {13},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Survey on machine learning and deep learning applications in
breast cancer diagnosis. <em>CC</em>, <em>13</em>(6), 1451–1470. (<a
href="https://doi.org/10.1007/s12559-020-09813-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cancer is a fatal disease caused due to the undesirable spread of cells. Breast carcinoma is the most invasive tumors and is the main reason for cancer deaths in females. Therefore, early diagnosis and prognosis have become necessary to increase survivability and reduce death rates in the long run. New artificial intelligence technologies are assisting radiologists in medical image scrutiny, thereby improving cancer patients’ status. This survey enrolls peer-reviewed, newly developed computer-aided diagnosis (CAD) systems implementing machine learning (ML) and deep learning (DL) techniques for diagnosing breast carcinoma, compares them with previously established methods, and provides technical details with the pros and cons for each model. We also discuss some open issues, research gaps, and future research directions for the advanced CAD models in medical image analysis. Over the past decade, machine learning and deep learning have emerged as a subfield of artificial intelligence (AI), whose healthcare industry applications have provided excellent results with reduced cost and improved efficiency. This survey analyzes different classifiers of machine learning and deep learning approaches for breast cancer diagnosis. Results from previous studies proved that deep learning outperforms conventional machine learning for diagnosing breast carcinoma when the dataset is broad. Research gaps from the recent studies depict that practical and scientific research is an urgent necessity for improving healthcare in the long run.},
  archive      = {J_CC},
  author       = {Chugh, Gunjan and Kumar, Shailender and Singh, Nanhay},
  doi          = {10.1007/s12559-020-09813-6},
  journal      = {Cognitive Computation},
  month        = {11},
  number       = {6},
  pages        = {1451-1470},
  shortjournal = {Cogn. Comput.},
  title        = {Survey on machine learning and deep learning applications in breast cancer diagnosis},
  volume       = {13},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A novel visual-textual sentiment analysis framework for
social media data. <em>CC</em>, <em>13</em>(6), 1433–1450. (<a
href="https://doi.org/10.1007/s12559-021-09929-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sentiment analysis (SA) has turned out to be a new pattern in social networking, avidly helping people to realize views expressed in user-generated content and conventional platforms of social media. For performing numerous social media analytics tasks, SA of online user-produced content is vital. The performance of the sentiment classifiers utilizing a single modality, i.e., visual or textual, is still not matured because of the wide variety of data platforms. In this paper, we propose a new framework called VIsual-TExtual SA (VITESA) that carries out visual analysis and textual analysis for polarity classification. In the VITESA framework, Brownian Movement-based Meerkat Clan Algorithm-centered DenseNet (BMMCA-DenseNet) is proposed that integrates textual and visual information for robust SA. In the visual phase, the images that are in the Flickr dataset are taken as input, and the operations: (1) preprocessing (2) feature extraction, and (3) feature selection utilizing Improved Coyote Optimization Algorithm (ICOA) are executed. In the textual phase, the user comments as of the Twitter dataset are taken as input, and the operations: (1) preprocessing (2) word embedding using adaptive Embedding for Language Models (ELMo), (3) emoticon and non-emoticon feature extraction, and SentiWordNet polarity assignment is carried out. The final stages of both phases are given as input to the proposed BMMCA-DenseNet classifier and intended to categorize the data into positive and negative polarity. The performance of BMMCA-DenseNet is compared with certain existing algorithms, and various performance metrics are evaluated. The proposed BMMCA-DenseNet classifier performs the polarity classification of the visual-textual data into two classes: positive or negative. The classifier categorizes the polarity of visual-textual data comprising 97% of accuracy, 94.44% of precision, 94.41% of recall, 94.41% of F-measure, 91.75% of Matthew’s Correlation Coefficient, 94.43% of sensitivity, 97.13% of specificity, and also minimal error. The experiment is performed to evaluate the performance of the proposed method. The outcomes exhibit that BMMCA-DenseNet attains remarkable performance over other existing techniques. The result enhances the textual-visual communication systematically to improve sentiment prediction utilizing both information sources.},
  archive      = {J_CC},
  author       = {Jindal, Kanika and Aron, Rajni},
  doi          = {10.1007/s12559-021-09929-3},
  journal      = {Cognitive Computation},
  month        = {11},
  number       = {6},
  pages        = {1433-1450},
  shortjournal = {Cogn. Comput.},
  title        = {A novel visual-textual sentiment analysis framework for social media data},
  volume       = {13},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A convolutional stacked bidirectional LSTM with a
multiplicative attention mechanism for aspect category and sentiment
detection. <em>CC</em>, <em>13</em>(6), 1423–1432. (<a
href="https://doi.org/10.1007/s12559-021-09948-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditionally, sentiment analysis is a binary classification task that aims to categorize a piece of text as positive or negative. This approach, however, can be too simplistic when the text under scrutiny contains more than one opinion target. Hence, aspect-based sentiment analysis provides fine-grained sentiment understanding of the product, service, or policy. Machine learning and deep learning algorithms play an important role in this kind of task. Also, attention mechanism has shown breakthrough in the field of natural language processing. Therefore, we propose a convolutional stacked bidirectional long short-term memory with a multiplicative attention mechanism for aspect category and sentiment polarity detection. More specifically, we treat the proposed model as a multiclass classification problem. The proposed model is evaluated using SemEval-2015 and SemEval-2016 dataset. Our proposed model outperforms state-of-the-art results in aspect-based sentiment analysis.},
  archive      = {J_CC},
  author       = {J, Ashok Kumar and Trueman, Tina Esther and Cambria, Erik},
  doi          = {10.1007/s12559-021-09948-0},
  journal      = {Cognitive Computation},
  month        = {11},
  number       = {6},
  pages        = {1423-1432},
  shortjournal = {Cogn. Comput.},
  title        = {A convolutional stacked bidirectional LSTM with a multiplicative attention mechanism for aspect category and sentiment detection},
  volume       = {13},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Online handwriting, signature and touch dynamics: Tasks and
potential applications in the field of security and health. <em>CC</em>,
<em>13</em>(5), 1406–1421. (<a
href="https://doi.org/10.1007/s12559-021-09938-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Advantageous property of behavioural signals (e.g. handwriting), in contrast to morphological ones (e.g. iris, fingerprint, hand geometry), is the possibility to ask a user to perform many different tasks. This article summarises recent findings and applications of different handwriting/drawing tasks in the field of security and health. More specifically, it is focused on on-line handwriting and hand-based interaction, i.e. signals that utilise a digitizing device (specific devoted or general-purpose tablet/smartphone) during the realization of the tasks. Such devices permit the acquisition of on-surface dynamics as well as in-air movements in time, thus providing complex and richer information when compared to the conventional “pen and paper” method. Although the scientific literature reports a wide range of tasks and applications, in this paper, we summarize only those providing competitive results (e.g. in terms of discrimination power) and having a significant impact in the field.},
  archive      = {J_CC},
  author       = {Faundez-Zanuy, Marcos and Mekyska, Jiri and Impedovo, Donato},
  doi          = {10.1007/s12559-021-09938-2},
  journal      = {Cognitive Computation},
  month        = {9},
  number       = {5},
  pages        = {1406-1421},
  shortjournal = {Cogn. Comput.},
  title        = {Online handwriting, signature and touch dynamics: Tasks and potential applications in the field of security and health},
  volume       = {13},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Decoding premovement patterns with task-related component
analysis. <em>CC</em>, <em>13</em>(5), 1389–1405. (<a
href="https://doi.org/10.1007/s12559-021-09941-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Noninvasive brain–computer interface (BCI)-based electroencephalograms (EEGs) have made great progress in cognitive activities detection. However, the decoding of premovements from EEG signals remains a challenge for noninvasive BCI. This work aims to decode human intention (movement or rest) before movement onset from EEG signals. We propose to decode premovement patterns from movement-related cortical potential activities with task-related component analysis and canonical correlation patterns (TRCA+CCPs). Specifically, we first optimize the MRCP data with the spatial filter TRCA. CCPs are then extracted from the optimized signals. The extracted CCPs are classified with the linear discriminated analysis classifier. We applied the classification in a sliding window, which changes from readiness potential (RP section) to movement-monitoring potential (MMP section). The classification result on event-related desynchronization (ERD) indicates that the motor cortex becomes active as the limbs move. When applying classification between elbow flexion and rest, the proposed TRCA+CCP method achieves an accuracy of 0.9001±0.0997 in the RP section. The previous methods, discriminative canonical pattern matching + common spatial pattern (DCPM+CSP) and the optimized DCPM+CSP method, exhibit accuracy values of 0.7827± 0.1276 and 0.8141±0.1295 for the RP section, respectively. Compared with these methods, the proposed TRCA+CCP method achieves higher average accuracy in the RP section. The proposed TRCA+CCP method can decode the patterns in the RP section efficiently, which indicates that the premovement patterns in EEG signals can be decoded before execution of the movement. The system is expected to assist movement detection in ERD analysis.},
  archive      = {J_CC},
  author       = {Duan, Feng and Jia, Hao and Sun, Zhe and Zhang, Kai and Dai, Yangyang and Zhang, Yu},
  doi          = {10.1007/s12559-021-09941-7},
  journal      = {Cognitive Computation},
  month        = {9},
  number       = {5},
  pages        = {1389-1405},
  shortjournal = {Cogn. Comput.},
  title        = {Decoding premovement patterns with task-related component analysis},
  volume       = {13},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The effect of fatigue on the performance of online writer
recognition. <em>CC</em>, <em>13</em>(5), 1374–1388. (<a
href="https://doi.org/10.1007/s12559-021-09943-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The performance of biometric modalities based on things done by the subject, like signature and text-based recognition, may be affected by the subject’s state. Fatigue is one of the conditions that can significantly affect the outcome of handwriting tasks. Recent research has already shown that physical fatigue produces measurable differences in some features extracted from common writing and drawing tasks. It is important to establish to which extent physical fatigue contributes to the intra-person variability observed in these biometric modalities and also to know whether the performance of recognition methods is affected by fatigue. In this paper, we assess the impact of fatigue on intra-user variability and on the performance of signature-based and text-based writer recognition approaches encompassing both identification and verification. Several signature and text recognition methods are considered and applied to samples gathered after different levels of induced fatigue, measured by metabolic and mechanical assessment and also by subjective perception. The recognition methods are dynamic time warping and multi-section vector quantization, for signatures, and allographic text-dependent recognition for text in capital letters. For each fatigue level, the identification and verification performance of these methods is measured. Signature shows no statistically significant intra-user impact, but text does. On the other hand, performance of signature-based recognition approaches is negatively impacted by fatigue, whereas the impact is not noticeable in text-based recognition, provided long enough sequences are considered.},
  archive      = {J_CC},
  author       = {Sesa-Nogueras, Enric and Faundez-Zanuy, Marcos and Garnacho-Castaño, Manuel-Vicente},
  doi          = {10.1007/s12559-021-09943-5},
  journal      = {Cognitive Computation},
  month        = {9},
  number       = {5},
  pages        = {1374-1388},
  shortjournal = {Cogn. Comput.},
  title        = {The effect of fatigue on the performance of online writer recognition},
  volume       = {13},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Training affective computer vision models by crowdsourcing
soft-target labels. <em>CC</em>, <em>13</em>(5), 1363–1373. (<a
href="https://doi.org/10.1007/s12559-021-09936-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Emotion detection classifiers traditionally predict discrete emotions. However, emotion expressions are often subjective, thus requiring a method to handle compound and ambiguous labels. We explore the feasibility of using crowdsourcing to acquire reliable soft-target labels and evaluate an emotion detection classifier trained with these labels. We hypothesize that training with labels that are representative of the diversity of human interpretation of an image will result in predictions that are similarly representative on a disjoint test set. We also hypothesize that crowdsourcing can generate distributions which mirror those generated in a lab setting. We center our study on the Child Affective Facial Expression (CAFE) dataset, a gold standard collection of images depicting pediatric facial expressions along with 100 human labels per image. To test the feasibility of crowdsourcing to generate these labels, we used Microworkers to acquire labels for 207 CAFE images. We evaluate both unfiltered workers and workers selected through a short crowd filtration process. We then train two versions of a ResNet-152 neural network on soft-target CAFE labels using the original 100 annotations provided with the dataset: (1) a classifier trained with traditional one-hot encoded labels and (2) a classifier trained with vector labels representing the distribution of CAFE annotator responses. We compare the resulting softmax output distributions of the two classifiers with a 2-sample independent t-test of L1 distances between the classifier’s output probability distribution and the distribution of human labels. While agreement with CAFE is weak for unfiltered crowd workers, the filtered crowd agree with the CAFE labels 100% of the time for happy, neutral, sad, and “fear + surprise” and 88.8% for “anger + disgust.” While the F1-score for a one-hot encoded classifier is much higher (94.33% vs. 78.68%) with respect to the ground truth CAFE labels, the output probability vector of the crowd-trained classifier more closely resembles the distribution of human labels (t = 3.2827, p = 0.0014). For many applications of affective computing, reporting an emotion probability distribution that accounts for the subjectivity of human interpretation can be more useful than an absolute label. Crowdsourcing, including a sufficient filtering mechanism for selecting reliable crowd workers, is a feasible solution for acquiring soft-target labels.},
  archive      = {J_CC},
  author       = {Washington, Peter and Kalantarian, Haik and Kent, Jack and Husic, Arman and Kline, Aaron and Leblanc, Emilie and Hou, Cathy and Mutlu, Cezmi and Dunlap, Kaitlyn and Penev, Yordan and Stockham, Nate and Chrisman, Brianna and Paskov, Kelley and Jung, Jae-Yoon and Voss, Catalin and Haber, Nick and Wall, Dennis P.},
  doi          = {10.1007/s12559-021-09936-4},
  journal      = {Cognitive Computation},
  month        = {9},
  number       = {5},
  pages        = {1363-1373},
  shortjournal = {Cogn. Comput.},
  title        = {Training affective computer vision models by crowdsourcing soft-target labels},
  volume       = {13},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A novel multi-attribute group decision-making method based
on q-rung dual hesitant fuzzy information and extended power average
operators. <em>CC</em>, <em>13</em>(5), 1345–1362. (<a
href="https://doi.org/10.1007/s12559-021-09932-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-attribute group decision-making (MAGDM) is one of the most active research fields in modern social cognition and decision science theory. An obvious challenge in MAGDM problems is that it is not easy to appropriately describe decision-makers’ (DMs’) cognitive information, which is because the cognition of DMs is usually diverse and contains a lot of uncertainties and fuzziness. The recently proposed q-rung dual hesitant fuzzy set (q-RDHFS), encompassing diverse cognition and providing wide information space, has been proved to be effective to depict DMs’ cognitive information in the MAGDM process. However, existing operations and aggregation operators of q-RDHFSs still have limitations, which result in the weakness of existing q-RDHFS-based MAGDM methods. Therefore, this paper aims at introducing new operational rules and aggregation operators to deal with q-rung dual hesitant fuzzy information. To this end, we first propose a wide range of generalized operations for q-rung dual hesitant fuzzy elements (q-RDHFEs) based on Archimedean t-norm and t-conorm. Second, we put forward some new aggregation operators by generalizing the recently invented extended power average (EPA) operator into q-RDHFSs. Existing literature has revealed the powerfulness and flexibility of the EPA operator over the classical power average operator. Finally, a new MAGDM approach based on the proposed operators is developed. Our proposed method can effectively handle MAGDM problems with q-rung dual hesitant fuzzy cognitive information. Some numerical examples are conducted to demonstrate the validity of the new MAGDM method. Further, we conduct parameter analysis and comparative analysis to prove the flexibility and superiority of our proposed MAGDM method, respectively. In a word, this paper contributes to a new q-rung dual hesitant fuzzy MAGDM method, which absorbs the advantages of EPA operator and Archimedean operations. This method can be applied to describe complex cognitive information and solving realistic MAGDM problems effectively.},
  archive      = {J_CC},
  author       = {Li, Li and Ji, Chunliang and Wang, Jun},
  doi          = {10.1007/s12559-021-09932-8},
  journal      = {Cognitive Computation},
  month        = {9},
  number       = {5},
  pages        = {1345-1362},
  shortjournal = {Cogn. Comput.},
  title        = {A novel multi-attribute group decision-making method based on q-rung dual hesitant fuzzy information and extended power average operators},
  volume       = {13},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Real-time lane detection by using biologically inspired
attention mechanism to learn contextual information. <em>CC</em>,
<em>13</em>(5), 1333–1344. (<a
href="https://doi.org/10.1007/s12559-021-09935-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Background State-of-the-art lane detection methods have achieved prominent performance in complex scenarios, but many limits have also existed. For example, only a fixed number of lanes can be detected, and the cost of detection time is unaffordable in many cases. Methods Inspired by human vision, attention mechanism makes network learning more concerned features. In this paper, we propose a real-time lane detection method by using attention mechanism. The network proposed consists of three modules: an encoder module that extracts the feature of lanes; the instance feature maps of lanes are predicted by two decoder modules, namely binary decoder and embeddable decoder. In the encoder, we use the biologically inspired attention to extract features, which contain many details of the target area. The correlation between the features obtained from the convolutions and that extracted by the attention is established to learn the contextual information. In the decoder, the contextual information is fused with the features from up-sampling, to compensate for the lost detailed information. Binary decoder classifies all the pixels into lane or background. Embeddable decoder obtains the distinguishable lanes. And then, the outputs of the binary decoder serve as one of the inputs to the embeddable decoder to guiding the generation of exact pixel points on the lanes. Results Comparative experiments on two benchmarks (TuSimple and Caltech lanes datasets) show that the proposed method is independent of lane number and lane pattern. It can handle an indefinite number of lanes and run at 10ms in the TuSimple dataset. Conclusions Experiments verify that our method outperforms a lot of state-of-the-art methods while maintaining a real-time performance.},
  archive      = {J_CC},
  author       = {Zhang, Lu and Jiang, Fengling and Kong, Bin and Yang, Jing and Wang, Can},
  doi          = {10.1007/s12559-021-09935-5},
  journal      = {Cognitive Computation},
  month        = {9},
  number       = {5},
  pages        = {1333-1344},
  shortjournal = {Cogn. Comput.},
  title        = {Real-time lane detection by using biologically inspired attention mechanism to learn contextual information},
  volume       = {13},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Recognizing emotion cause in conversations. <em>CC</em>,
<em>13</em>(5), 1317–1332. (<a
href="https://doi.org/10.1007/s12559-021-09925-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We address the problem of recognizing emotion cause in conversations, define two novel sub-tasks of this problem, and provide a corresponding dialogue-level dataset, along with strong transformer-based baselines. The dataset is available at https://github.com/declare-lab/RECCON . Recognizing the cause behind emotions in text is a fundamental yet under-explored area of research in NLP. Advances in this area hold the potential to improve interpretability and performance in affect-based models. Identifying emotion causes at the utterance level in conversations is particularly challenging due to the intermingling dynamics among the interlocutors. We introduce the task of Recognizing Emotion Cause in CONversations with an accompanying dataset named RECCON, containing over 1,000 dialogues and 10,000 utterance cause/effect pairs. Furthermore, we define different cause types based on the source of the causes, and establish strong Transformer-based baselines to address two different sub-tasks on this dataset. Our transformer-based baselines, which leverage contextual pre-trained embeddings, such as RoBERTa, outperform the state-of-the-art emotion cause extraction approaches on our dataset. We introduce a new task highly relevant for (explainable) emotion-aware artificial intelligence: recognizing emotion cause in conversations, provide a new highly challenging publicly available dialogue-level dataset for this task, and give strong baseline results on this dataset.},
  archive      = {J_CC},
  author       = {Poria, Soujanya and Majumder, Navonil and Hazarika, Devamanyu and Ghosal, Deepanway and Bhardwaj, Rishabh and Jian, Samson Yu Bai and Hong, Pengfei and Ghosh, Romila and Roy, Abhinaba and Chhaya, Niyati and Gelbukh, Alexander and Mihalcea, Rada},
  doi          = {10.1007/s12559-021-09925-7},
  journal      = {Cognitive Computation},
  month        = {9},
  number       = {5},
  pages        = {1317-1332},
  shortjournal = {Cogn. Comput.},
  title        = {Recognizing emotion cause in conversations},
  volume       = {13},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Binary chimp optimization algorithm (BChOA): A new binary
meta-heuristic for solving optimization problems. <em>CC</em>,
<em>13</em>(5), 1297–1316. (<a
href="https://doi.org/10.1007/s12559-021-09933-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Chimp optimization algorithm (ChOA) is a newly proposed meta-heuristic algorithm inspired by chimps’ individual intelligence and sexual motivation in their group hunting. The preferable performance of ChOA has been approved among other well-known meta-heuristic algorithms. However, its continuous nature makes it unsuitable for solving binary problems. Therefore, this paper proposes a novel binary version of ChOA and attempts to prove that the transfer function is the most important part of binary algorithms. Therefore, four S-shaped and V-shaped transfer functions, as well as a novel binary approach, have been utilized to investigate the efficiency of binary ChOAs (BChOA) in terms of convergence speed and local minima avoidance. In this regard, forty-three unimodal, multimodal, and composite optimization functions and ten IEEE CEC06-2019 benchmark functions were utilized to evaluate the efficiency of BChOAs. Furthermore, to validate the performance of BChOAs, four newly proposed binary optimization algorithms were compared with eighteen novel state-of-the-art algorithms. The results indicate that both the novel binary approach and V-shaped transfer functions improve the efficiency of BChOAs in a statistically significant way.},
  archive      = {J_CC},
  author       = {Wang, Jianhao and Khishe, Mohammad and Kaveh, Mehrdad and Mohammadi, Hassan},
  doi          = {10.1007/s12559-021-09933-7},
  journal      = {Cognitive Computation},
  month        = {9},
  number       = {5},
  pages        = {1297-1316},
  shortjournal = {Cogn. Comput.},
  title        = {Binary chimp optimization algorithm (BChOA): A new binary meta-heuristic for solving optimization problems},
  volume       = {13},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). MTFFNet: A multi-task feature fusion framework for chinese
painting classification. <em>CC</em>, <em>13</em>(5), 1287–1296. (<a
href="https://doi.org/10.1007/s12559-021-09896-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Different artists have their unique painting styles, which can be hardly recognized by ordinary people without professional knowledge. How to intelligently analyze such artistic styles via underlying features remains to be a challenging research problem. In this paper, we propose a novel multi-task feature fusion architecture (MTFFNet), for cognitive classification of traditional Chinese paintings. Specifically, by taking the full advantage of the pre-trained DenseNet as backbone, MTFFNet benefits from the fusion of two different types of feature information: semantic and brush stroke features. These features are learned from the RGB images and auxiliary gray-level co-occurrence matrix (GLCM) in an end-to-end manner, to enhance the discriminative power of the features for the first time. Through abundant experiments, our results demonstrate that our proposed model MTFFNet achieves significantly better classification performance than many state-of-the-art approaches. In this paper, an end-to-end multi-task feature fusion method for Chinese painting classification is proposed. We come up with a new model named MTFFNet, composed of two branches, in which one branch is top-level RGB feature learning and the other branch is low-level brush stroke feature learning. The semantic feature learning branch takes the original image of traditional Chinese painting as input, extracting the color and semantic information of the image, while the brush feature learning branch takes the GLCM feature map as input, extracting the texture and edge information of the image. Multi-kernel learning SVM (supporting vector machine) is selected as the final classifier. Evaluated by experiments, this method improves the accuracy of Chinese painting classification and enhances the generalization ability. By adopting the end-to-end multi-task feature fusion method, MTFFNet could extract more semantic features and texture information in the image. When compared with state-of-the-art classification method for Chinese painting, the proposed method achieves much higher accuracy on our proposed datasets, without lowering speed or efficiency. The proposed method provides an effective solution for cognitive classification of Chinese ink painting, where the accuracy and efficiency of the approach have been fully validated.},
  archive      = {J_CC},
  author       = {Jiang, Wei and Wang, Xiaoyu and Ren, Jinchang and Li, Sen and Sun, Meijun and Wang, Zheng and Jin, Jesse S.},
  doi          = {10.1007/s12559-021-09896-9},
  journal      = {Cognitive Computation},
  month        = {9},
  number       = {5},
  pages        = {1287-1296},
  shortjournal = {Cogn. Comput.},
  title        = {MTFFNet: A multi-task feature fusion framework for chinese painting classification},
  volume       = {13},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Causal asymmetry analysis in the view of concept-cognitive
learning by incremental concept tree. <em>CC</em>, <em>13</em>(5),
1274–1286. (<a
href="https://doi.org/10.1007/s12559-021-09930-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Causal asymmetry is an important feature in the description of causality, and it has attracted wide attention in the field of physics and philosophy. It hypothesizes that there is a pervasive and fundamental bias in humans’ understanding of physical causation. However, how to express the causal asymmetry in computer science is still an open, interesting, and important issue. In this paper, we propose a solution to this issue by introducing an incremental concept tree (ICT) representation. The ICT is a structure description method originated from the concept tree and attribute topology methods in the field of concept cognitive learning. It focuses on figuring the cognitive process of human being and has been applied to casual analysis. Firstly, we introduce the concept of “causal asymmetry” into the field of concept-cognitive learning according to the internal unity of attribute topology and causality. Secondly, an Incremental concept tree is designed to represent the incremental evolution of the concepts as time arrows on the basis of attribute topology. Finally, we perform an experimental analysis of the Acute Inflammations data to illustrate the feasibility of the proposed algorithm in visualizing causal asymmetry and compare the ICT to the other structural representations. The experimental results show that the ICT is a promising tool for figuring out the casual asymmetry in the view of concept cognitive learning.},
  archive      = {J_CC},
  author       = {Zhang, Tao and Rong, Mei and Shan, Haoran and Liu, Mingxin},
  doi          = {10.1007/s12559-021-09930-w},
  journal      = {Cognitive Computation},
  month        = {9},
  number       = {5},
  pages        = {1274-1286},
  shortjournal = {Cogn. Comput.},
  title        = {Causal asymmetry analysis in the view of concept-cognitive learning by incremental concept tree},
  volume       = {13},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A new GAN-based approach to data augmentation and image
segmentation for crack detection in thermal imaging tests. <em>CC</em>,
<em>13</em>(5), 1263–1273. (<a
href="https://doi.org/10.1007/s12559-021-09922-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a popular nondestructive testing (NDT) technique, thermal imaging test demonstrates competitive performance in crack detection, especially for detecting subsurface cracks. In thermal imaging test, the temperature of the crack area is higher than that of the non-crack area during the NDT process. By extracting the features of the thermal image sequences, the temperature curve of each spatial point is employed for crack detection. Nevertheless, the quality of thermal images is influenced by the noises due to the complex thermal environment in NDT. In this paper, a modified generative adversarial network (GAN) is employed to improve the image segmentation performance. To improve the feature extraction ability and alleviate the influence of noises, a penalty term is put forward in the loss function of the conventional GAN. A data preprocessing method is developed where the principle component analysis algorithm is adopted for feature extraction. The data argumentation technique is utilized to guarantee the quantity of the training samples. To validate its effectiveness in thermal imaging NDT, the modified GAN is applied to detect the cracks on the eddy current pulsed thermography NDT dataset.},
  archive      = {J_CC},
  author       = {Tian, Lulu and Wang, Zidong and Liu, Weibo and Cheng, Yuhua and Alsaadi, Fuad E. and Liu, Xiaohui},
  doi          = {10.1007/s12559-021-09922-w},
  journal      = {Cognitive Computation},
  month        = {9},
  number       = {5},
  pages        = {1263-1273},
  shortjournal = {Cogn. Comput.},
  title        = {A new GAN-based approach to data augmentation and image segmentation for crack detection in thermal imaging tests},
  volume       = {13},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Intuitionistic fuzzy three-factor ratio models and
multi-preference fusion. <em>CC</em>, <em>13</em>(5), 1246–1262. (<a
href="https://doi.org/10.1007/s12559-021-09928-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generally, decision-makers (DMs) can provide subjective opinions based on their risk attitude and intuitionistic preference for specific alternatives and attributes, which can be taken as cognitive information. For instance, alternative A is better than alternatives B and C, or attribute 3 is the most important. These multi-dimensional preferences and social cognitive behavior described by DMs based on their subjective evaluation should be taken into account when making a decision. How to fuse multiple, uncertain, imprecise but important preferences and cognitive information and then make a decision in an intuitionistic fuzzy environment is becoming a practical issue. Therefore, this paper defines a three-factor ratio of the intuitionistic fuzzy number and then proposes a basic intuitionistic fuzzy three-factor ratio (IFTR) model. To present DMs’ risk preferences, this paper constructs two extreme IFTR models and describes risk preferences with a risk appetite parameter. For DMs’ alternative preferences, this paper develops a continuous IFTR model in which alternative preferences are fused to calculate the optimal risk appetite parameter. To fully consider DMs’ risk, alternative, and attribute preferences, this paper further proposes a generalized IFTR model. Thus, risk, alternative, and attribute preferences, which can be viewed as the social cognitive information, can be fused in an intuitionistic fuzzy decision-making and group decision-making process simultaneously. An illustrative example to address the problem of demolishing old urban villages is provided to show the effectiveness of the proposed models.},
  archive      = {J_CC},
  author       = {Zhou, Wei and Xu, Zeshui},
  doi          = {10.1007/s12559-021-09928-4},
  journal      = {Cognitive Computation},
  month        = {9},
  number       = {5},
  pages        = {1246-1262},
  shortjournal = {Cogn. Comput.},
  title        = {Intuitionistic fuzzy three-factor ratio models and multi-preference fusion},
  volume       = {13},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Bifurcation and oscillations of a multi-ring coupling neural
network with discrete delays. <em>CC</em>, <em>13</em>(5), 1233–1245.
(<a href="https://doi.org/10.1007/s12559-021-09920-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is well known that brain neural networks are composed of hundreds of millions of neurons with complicated connections. It is noteworthy that there are a large number of neural circuits formed by the coupling relationship in neural networks. However, the vast majority of existing studies on ring-structured networks were restricted to models with fewer neurons or single-ring structure. Here, we design a multi-ring coupling network model, which includes a large number of neurons and multiple rings, to simulate the brain network with multiple neural circuits, and use bifurcation theory to investigate the dynamic behavior of bifurcations and oscillations of the proposed model. Instead of the traditional method, the Coates flow graph method is used to derive explicit expressions for the higher-order determinants of the model. Then, the stability and Hopf bifurcation of the model are studied with the sum of discrete delays of each ring as the bifurcation parameter, and the explicit formula for its critical value is deduced. Our results suggest that in some cases, the stability of the model gradually deteriorates with increasing time delay and eventually destabilizes the system at some critical value. More specifically, the development of the instability (increasing time delay) leads to limit cycle and periodic oscillations, and the amplitude and period of the system are also affected by it.},
  archive      = {J_CC},
  author       = {Zhou, Shuai and Xiao, Min and Wang, Lu and Cheng, Zunshui},
  doi          = {10.1007/s12559-021-09920-y},
  journal      = {Cognitive Computation},
  month        = {9},
  number       = {5},
  pages        = {1233-1245},
  shortjournal = {Cogn. Comput.},
  title        = {Bifurcation and oscillations of a multi-ring coupling neural network with discrete delays},
  volume       = {13},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Deep neural approaches to relation triplets extraction: A
comprehensive survey. <em>CC</em>, <em>13</em>(5), 1215–1232. (<a
href="https://doi.org/10.1007/s12559-021-09917-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The task of relation extraction is about identifying entities and relations among them in free text for the enrichment of structured knowledge bases (KBs). In this paper, we present a comprehensive survey of this important research topic in natural language processing. Recently, with the advances made in the continuous representation of words (word embeddings) and deep neural architectures, many research works are published in the area of relation extraction. To help future research, we present a comprehensive review of the recently published research works in relation extraction. Previous surveys on this task covered only one aspect of relation extraction that is pipeline-based relation extraction approaches at the sentence level. In this survey, we cover sentence-level relation extraction to document-level relation extraction, pipeline-based approaches to joint extraction approaches, annotated datasets to distantly supervised datasets along with few very recent research directions such as zero-shot or few-shot relation extraction, noise mitigation in distantly supervised datasets. Regarding neural architectures, we cover convolutional models, recurrent network models, attention network models, and graph convolutional models in this survey. We survey more than 100 publications in the field of relation extraction and present them in a structured way based on their similarity in the specific task they tried to solve, their model architecture, the datasets they used for experiments. We include the current state-of-the-art performance in several datasets in this paper for comparison. In this paper, we have covered different aspects of research in relation extraction field with a key focus on recent deep neural network-based methods. Also, we identify possible future research directions. Hopefully, this will help future researchers to identify the current research gaps and take the field forward.},
  archive      = {J_CC},
  author       = {Nayak, Tapas and Majumder, Navonil and Goyal, Pawan and Poria, Soujanya},
  doi          = {10.1007/s12559-021-09917-7},
  journal      = {Cognitive Computation},
  month        = {9},
  number       = {5},
  pages        = {1215-1232},
  shortjournal = {Cogn. Comput.},
  title        = {Deep neural approaches to relation triplets extraction: A comprehensive survey},
  volume       = {13},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The big-2/ROSe model of online personality. <em>CC</em>,
<em>13</em>(5), 1198–1214. (<a
href="https://doi.org/10.1007/s12559-021-09866-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Big-5/OCEAN personality traits model, one of the central approaches to psychometrics, has been shown to have many applications over a variety of disciplines. In particular, correlations have been studied leading to effective characterization of people’s behavior, and the model has become notorious for its role in the Cambridge Analytica/Facebook scandal surrounding the 2016 US presidential elections. In this paper, we develop Big-2 (or ROSe, for Relationship to Others and to Self), a model via which the personality of users of online platforms can be studied using a lightweight set of markers focused on online behavior, avoiding the major data privacy pitfalls afflicting approaches based on more powerful models that characterize personal aspects of the human psyche. Evaluation of Big-2’s effectiveness is done in two parts: a quantitative evaluation on a specific prediction task and a qualitative one based on an analysis of the different ways in which the Big-2 traits can be derived from online behavior, proposing a general template to guide such efforts. Quantitative results show that our lightweight model can match or surpass the performance of Big-5 in a prediction task, while qualitative results show that it is feasible to implement the model based on the observation of basic online user behavior. Our main result is a general-purpose model that can be used to characterize the personality traits of users of online platforms in an ethical manner. Our proposed model provides a valuable tool to carry out effective and explainable analyses of online personality, avoiding the collection of unnecessary user data that would open the possibility for ethical violations.},
  archive      = {J_CC},
  author       = {Simari, Gerardo I. and Martinez, Maria Vanina and Gallo, Fabio R. and Falappa, Marcelo A.},
  doi          = {10.1007/s12559-021-09866-1},
  journal      = {Cognitive Computation},
  month        = {9},
  number       = {5},
  pages        = {1198-1214},
  shortjournal = {Cogn. Comput.},
  title        = {The big-2/ROSe model of online personality},
  volume       = {13},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Unsupervised sentiment analysis by transferring multi-source
knowledge. <em>CC</em>, <em>13</em>(5), 1185–1197. (<a
href="https://doi.org/10.1007/s12559-020-09792-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sentiment analysis (SA) is an important research area in cognitive computation—thus, in-depth studies of patterns of sentiment analysis are necessary. At present, rich-resource data-based SA has been well-developed, while the more challenging and practical multi-source unsupervised SA (i.e., a target-domain SA by transferring from multiple source domains) is seldom studied. The challenges behind this problem mainly locate in the lack of supervision information, the semantic gaps among domains (i.e., domain shifts), and the loss of knowledge. However, existing methods either lack the distinguishable capacity of the semantic gaps among domains or lose private knowledge. To alleviate these problems, we propose a two-stage domain adaptation framework. In the first stage, a multi-task methodology-based shared-private architecture is employed to explicitly model the domain-common features and the domain-specific features for the labeled source domains. In the second stage, two elaborate mechanisms are embedded in the shared-private architecture to transfer knowledge from multiple source domains. The first mechanism is a selective domain adaptation (SDA) method, which transfers knowledge from the closest source domain. And the second mechanism is a target-oriented ensemble (TOE) method, in which knowledge is transferred through a well-designed ensemble method. Extensive experiment evaluations verify that the performance of the proposed framework outperforms unsupervised state-of-the-art competitors. What can be concluded from the experiments is that transferring from very different distributed source domains may degrade the target-domain performance, and it is crucial to choose proper source domains to transfer from.},
  archive      = {J_CC},
  author       = {Dai, Yong and Liu, Jian and Zhang, Jian and Fu, Hongguang and Xu, Zenglin},
  doi          = {10.1007/s12559-020-09792-8},
  journal      = {Cognitive Computation},
  month        = {9},
  number       = {5},
  pages        = {1185-1197},
  shortjournal = {Cogn. Comput.},
  title        = {Unsupervised sentiment analysis by transferring multi-source knowledge},
  volume       = {13},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A picture fuzzy multiple criteria decision-making approach
based on the combined TODIM-VIKOR and entropy weighted method.
<em>CC</em>, <em>13</em>(5), 1172–1184. (<a
href="https://doi.org/10.1007/s12559-021-09892-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Picture fuzzy set (PFS) is more effective tool for handling the uncertainty and vagueness in the real world and it can contain more information than intuitionistic fuzzy set (IFS). In this paper, we proposed a new entropy measure in terms of PFSs and some of its properties are discussed in detail. An example involving linguistic variables is established to show the validity of the proposed information measure. Furthermore, we proposed an entropy-based decision-making method to solve picture fuzzy MCDM (multi-criteria decision-making) problems with the integration of subjective and objective weights to make the evaluation result more objectively. Besides, we used TODIM (a Portuguese acronym for Interactive Multi-Criteria Decision-Making) to obtain the overall dominance degrees and VIKOR (VlseKriterijumska Op-timizacija I Kompromisno Resenje) is used to obtain the compromise ranking of alternatives in the framework of PFS and so-called TODIM-VIKOR. An illustrative example is developed to demonstrate the validity and reliability of the proposed approach and compared the results with some existing approaches. The proposed TODIM-VIKOR approach is more suitable than the existing ones to deal with uncertain and imprecise information and offers numerous choices to the decision-maker for accessing the finest alternatives. MS Classification: 94A15, 94A24, 26D15},
  archive      = {J_CC},
  author       = {Arya, Vikas and Kumar, Satish},
  doi          = {10.1007/s12559-021-09892-z},
  journal      = {Cognitive Computation},
  month        = {9},
  number       = {5},
  pages        = {1172-1184},
  shortjournal = {Cogn. Comput.},
  title        = {A picture fuzzy multiple criteria decision-making approach based on the combined TODIM-VIKOR and entropy weighted method},
  volume       = {13},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Applying attention-based models for detecting cognitive
processes and mental health conditions. <em>CC</em>, <em>13</em>(5),
1154–1171. (<a
href="https://doi.org/10.1007/s12559-021-09901-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {According to the psychological literature, implicit motives allow for the characterization of behavior, subsequent success, and long-term development. Contrary to personality traits, implicit motives are often deemed to be rather stable personality characteristics. Normally, implicit motives are obtained by Operant Motives, unconscious intrinsic desires measured by the Operant Motive Test (OMT). The OMT test requires participants to write freely descriptions associated with a set of provided images and questions. In this work, we explore different recent machine learning techniques and various text representation techniques for facing the problem of the OMT classification task. We focused on advanced language representations (e.g, BERT, XLM, and DistilBERT) and deep Supervised Autoencoders for solving the OMT task. We performed an exhaustive analysis and compared their performance against fully connected neural networks and traditional support vector classifiers. Our comparative study highlights the importance of BERT which outperforms the traditional machine learning techniques by a relative improvement of 7.9%. In addition, we performed an analysis of how the BERT attention mechanism is being modified. Our findings indicate that the writing style features acquire higher importance at the moment of accurately identifying the different OMT categories. This is the first time that a study to determine the performance of different transformer-based architectures in the OMT task is performed. Similarly, our work propose, for the first time, using deep supervised autoencoders in the OMT classification task. Our experiments demonstrate that transformer-based methods exhibit the best empirical results, obtaining a relative improvement of 7.9% over the competitive baseline suggested as part of the GermEval 2020 challenge. Additionally, we show that features associated with the writing style are more important than content-based words. Some of these findings show strong connections to previously reported behavioral research on the implicit psychometrics theory.},
  archive      = {J_CC},
  author       = {Villatoro-Tello, Esaú and Parida, Shantipriya and Kumar, Sajit and Motlicek, Petr},
  doi          = {10.1007/s12559-021-09901-1},
  journal      = {Cognitive Computation},
  month        = {9},
  number       = {5},
  pages        = {1154-1171},
  shortjournal = {Cogn. Comput.},
  title        = {Applying attention-based models for detecting cognitive processes and mental health conditions},
  volume       = {13},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Mel-frequency cepstral coefficient features based on
standard deviation and principal component analysis for language
identification systems. <em>CC</em>, <em>13</em>(5), 1136–1153. (<a
href="https://doi.org/10.1007/s12559-021-09914-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spoken language identification (LID) is the process of determining and classifying natural language from a given content and dataset. Data must be processed to extract useful features to perform LID. The mel-frequency cepstral coefficient (MFCC) is one of the most popular feature extraction techniques in LID. The MFCC features are generated to serve as inputs for the classification stage. In this study, reduction in the MFCC feature dimension is investigated because large data size affects the computational time and resources (i.e., memory space) and slows the identification speed. The implementation of data reduction techniques to retain the most important feature parameters is also evaluated in this study. The investigation of data reduction is based on standard deviation (STD) calculation and principal component analysis (PCA). The features based on MFCC and the reduced dimensions based on STD and PCA results are then used as inputs to an optimized extreme learning machine (ELM) classifier called the optimized genetic algorithm-ELM (OGA-ELM). Several sets of data samples with one dimension of principal components (i.e., 119) are utilized for the evaluation. The results are generated using two different datasets. The first dataset is derived from eight separate languages, whereas the second dataset is a part of the National Institute of Standards and Technology Language Recognition Evaluation 2009 dataset. To evaluate the performance of the proposed method, this study utilizes several assessment measures, namely, accuracy, recall, precision, F-measure, G-mean, and identification time. The best LID performance is observed when the MFCC based on STD and PCA features with 119 feature dimensions is used with OGA-ELM as the classifier. The experimental results show that the proposed MFCC method achieves 99.38% accuracy using the first dataset. Additionally, it achieves accuracies of up to 97.60%, 96.80%, and 91.20% using the second dataset with durations of 30, 10, and 3 s, respectively. The proposed MFCC method exhibits the fastest computational time in all experiments, requiring only a few seconds to identify languages. Using a data reduction technique can substantially speed up the computational time, overcome resource limitations, and improve LID performance.},
  archive      = {J_CC},
  author       = {Albadr, Musatafa Abbas Abbood and Tiun, Sabrina and Ayob, Masri and Mohammed, Manal and AL-Dhief, Fahad Taha},
  doi          = {10.1007/s12559-021-09914-w},
  journal      = {Cognitive Computation},
  month        = {9},
  number       = {5},
  pages        = {1136-1153},
  shortjournal = {Cogn. Comput.},
  title        = {Mel-frequency cepstral coefficient features based on standard deviation and principal component analysis for language identification systems},
  volume       = {13},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). HANA: Hierarchical attention network assembling for semantic
segmentation. <em>CC</em>, <em>13</em>(5), 1128–1135. (<a
href="https://doi.org/10.1007/s12559-021-09911-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semantic segmentation is a crucial issue in the field of computer vision, and it aims to assign each pixel in an image to a semantic object category. Modern cognitive research has presented that the biological system contains hidden features and explicit features, although they both contain useful information, the hidden features need further processing to make them explicit or clear. Inspired by this theory, a semantic segmentation framework named hierarchical attention network assembling is proposed. Multiple auxilary information of different levels corresponding to the two kinds of features of the cognitive system are exploited. Then we further process the hidden information to make them explicit for the semantic segmentation. While in the traditional methods, limited assistance of the auxiliary tasks with only hidden information is provided. In this study, the attention mechanism is utilized and two auxiliary tasks are introduced as attention modules to give explicit guidance to the semantic segmentation task. Two hierarchical sub-networks—an object-level bounding box attention network and an edge-level boundary attention network together serve as explicit auxiliary tasks, of which the first network driven by the object detection aims to aggrandize the consistency constraint of pixels belonging to the same object, and the second one driven by the boundary detection aims to improve the segmentation accuracy within the boundary regions. With the proposed method, the performance achieves 78.3% mean IOU on PASCAL VOC 2012. The explicit guidance of the two auxiliary tasks can well assist the semantic segmentation task.},
  archive      = {J_CC},
  author       = {Liu, Wei and Li, Ding and Su, Hongqi},
  doi          = {10.1007/s12559-021-09911-z},
  journal      = {Cognitive Computation},
  month        = {9},
  number       = {5},
  pages        = {1128-1135},
  shortjournal = {Cogn. Comput.},
  title        = {HANA: Hierarchical attention network assembling for semantic segmentation},
  volume       = {13},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Aspect-based sentiment analysis for user reviews.
<em>CC</em>, <em>13</em>(5), 1114–1127. (<a
href="https://doi.org/10.1007/s12559-021-09855-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aspect-based sentiment analysis (ABSA) can help consumers provide clear and objective sentiment recommendations through massive quantities of data and is conducive to overcoming ambiguous human weaknesses in subjective judgments. However, the robustness and accuracy of existing sentiment analysis methods must still be improved. We first propose a deep-level semiself-help sentiment annotation system based on the bidirectional encoder representation from transformers (BERT) weakly supervised classifier to address this problem. Fine-grained annotation of restaurant reviews under 18 latitudes solves the problems of insufficient data and low label accuracy. On this basis, bagging traditional machine learning algorithms and annotation systems, a novel classification model for specific aspects is proposed to explore consumer behavior preferences, real consumer feelings, and whether they are willing to consume again. The proposed approach can effectively improve the accuracy of the ABSA tasks and reduce the space-time complexity. Moreover, the proposed model can significantly reduce the quantity of data annotation engineering required.},
  archive      = {J_CC},
  author       = {Zhang, Yin and Du, Jinyang and Ma, Xiao and Wen, Haoyu and Fortino, Giancarlo},
  doi          = {10.1007/s12559-021-09855-4},
  journal      = {Cognitive Computation},
  month        = {9},
  number       = {5},
  pages        = {1114-1127},
  shortjournal = {Cogn. Comput.},
  title        = {Aspect-based sentiment analysis for user reviews},
  volume       = {13},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). U2F-GAN: Weakly supervised super-pixel segmentation in
thyroid ultrasound images. <em>CC</em>, <em>13</em>(5), 1099–1113. (<a
href="https://doi.org/10.1007/s12559-021-09909-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Precise nodule segmentation in thyroid ultrasound images is important for clinical quantitative analysis and diagnosis. Fully supervised deep learning method can effectively extract representative features from nodules and background. Despite the great success, deep learning–based segmentation methods still face a critical hindrance: the difficulty in acquiring sufficient training data due to high annotation costs. To this end, we propose a weakly supervised framework called uncertainty to fine generative adversarial network (U2F-GAN) for nodule segmentation in thyroid ultrasound images that exploits only a handful of rough bounding box annotations to successfully generate reliable labels from these weak supervisions. Based on feature-matching GAN, the proposed method alternates between generating masks and learning a segmentation network in an adversarial manner. Super-pixel processing mechanism is adopted to reflect low-level image structure features for learning and inferring semantic segmentation, which largely improve the efficiency of training process. In addition, we introduce a similarity comparison module and a distributed loss function with constraints to effectively remove noise in localization annotations and enhance the generalization capability of the network, thus strengthen the overall segmentation performance. Compared to existing weakly supervised approaches, our proposed U2F-GAN yields a significant performance boost. The segmentation results are also comparable to fully supervised methods, but the annotation burden is much lower. Also, the training speed of the network model is much faster than other methods with weak supervisions, which enables the network to be updated in time, thus is beneficial to high-throughput medical image setting.},
  archive      = {J_CC},
  author       = {Liu, Ruoyun and Zhou, Shichong and Guo, Yi and Wang, Yuanyuan and Chang, Cai},
  doi          = {10.1007/s12559-021-09909-7},
  journal      = {Cognitive Computation},
  month        = {9},
  number       = {5},
  pages        = {1099-1113},
  shortjournal = {Cogn. Comput.},
  title        = {U2F-GAN: Weakly supervised super-pixel segmentation in thyroid ultrasound images},
  volume       = {13},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Neural mechanisms of maintenance and manipulation of
information of temporal sequences in working memory. <em>CC</em>,
<em>13</em>(4), 1085–1098. (<a
href="https://doi.org/10.1007/s12559-021-09907-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Working memory is a fundamental function of cognition, allowing one to hold memory “in mind” and then to guide flexible behaviors. Although the maintenance mechanisms of working memory have attracted a lot of attention, the manipulation mechanisms are less studied. To elucidate the mechanisms of working memory manipulation, we hypothesize that the prefrontal cortex (PFC) maintains information of a sample stimulus in a persistent activity of a subarea, and then, in another subarea, encodes sequence information of the sample and a test stimulus involved in a delayed match-to-category task. To test the hypothesis, we develop a network model that performs a delayed match-to-category task. Category information of a sample stimulus is maintained in a persistent activity of a positive-feedback-loop network, and the temporal information of the sample and test stimulus is represented by learning of a recurrent network. Furthermore, the task-specific decision is made by learning the connection between the area encoding temporal sequence and a decision area. Our model is further extended to more complex tasks to examine the generality of the temporal representation in PFC. The representation of temporal sequences is organized so that the PFC activities encoding the sequence information become orthogonal to each other, producing the representation of various temporal sequences of stimuli. The temporal representation enables the system to adapt to the change of task context only by relearning of the connections between the recurrent network and a decision layer. The results suggest that the PFC may generate a task-independent, temporal information of stimuli to guide various behaviors.},
  archive      = {J_CC},
  author       = {Tokuhara, Hikaru and Fujita, Kazuhisa and Kashimori, Yoshiki},
  doi          = {10.1007/s12559-021-09907-9},
  journal      = {Cognitive Computation},
  month        = {7},
  number       = {4},
  pages        = {1085-1098},
  shortjournal = {Cogn. Comput.},
  title        = {Neural mechanisms of maintenance and manipulation of information of temporal sequences in working memory},
  volume       = {13},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-task pruning via filter index sharing: A
many-objective optimization approach. <em>CC</em>, <em>13</em>(4),
1070–1084. (<a
href="https://doi.org/10.1007/s12559-021-09894-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {State-of-the-art deep neural network plays an increasingly important role in artificial intelligence, while the huge number of parameters in networks brings high memory cost and computational complexity. To solve this problem, filter pruning is widely used for neural network compression and acceleration. However, existing algorithms focus mainly on pruning single model, and few results are available to multi-task pruning that is capable of pruning multi-model and promoting the learning performance. By utilizing the filter sharing technique, this paper aimed to establish a multi-task pruning framework for simultaneously pruning and merging filters in multi-task networks. An optimization problem of selecting the important filters is solved by developing a many-objective optimization algorithm where three criteria are adopted as objectives for the many-objective optimization problem. With the purpose of keeping the network structure, an index matrix is introduced to regulate the information sharing during multi-task training. The proposed multi-task pruning algorithm is quite flexible that can be performed with either adaptive or pre-specified pruning rates. Extensive experiments are performed to verify the applicability and superiority of the proposed method on both single-task and multi-task pruning.},
  archive      = {J_CC},
  author       = {Cheng, Hanjing and Wang, Zidong and Ma, Lifeng and Liu, Xiaohui and Wei, Zhihui},
  doi          = {10.1007/s12559-021-09894-x},
  journal      = {Cognitive Computation},
  month        = {7},
  number       = {4},
  pages        = {1070-1084},
  shortjournal = {Cogn. Comput.},
  title        = {Multi-task pruning via filter index sharing: A many-objective optimization approach},
  volume       = {13},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multiple attribute decision making based on neutrosophic
preference relation. <em>CC</em>, <em>13</em>(4), 1061–1069. (<a
href="https://doi.org/10.1007/s12559-021-09893-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The single-valued neutrosophic set (SVNS) performs well in retrieving indeterminate cognitive information for decision makers to solve problems from the perspective of multiple attribute decision making (MADM). Preference relation is used in decision-making as a fundamental tool for decision makers to express their preference. In this context, the SVNS-based preference relation is one of the most useful extensions in that it quantitatively reflects the preference degree. However, the previous studies have paid little attention to the preference degree between alternatives, making the outcomes of decision making inaccurate. Therefore, it is necessary and meaningful to propose the MADM method with SVNS based on the preference relation which takes into account preference information between alternatives. A neutrosophic preference relation is proposed by means of the full of utilization decision information to combine SVNS with preference relation. With respect to the proposed MADM method, the evaluation decision matrix is provided by decision makers and the weights of attribute are gained by using the entropy of SVNS. Then, the neutrosophic preference relation is utilized to obtain evaluation preference matrix. Finally, through full-order relation formed by aggregating the preference relation, the ranking order of all alternatives is obtained and the most desirable alternative is readily determined. By an illustrative example, the proposed method is validated, and its advantages are analyzed by comparison and contrast with the other methods. This method makes full use of decision makers’ cognitve information and takes into account the preference information between alternatives. The outcomes of decision-making demonstrate that the proposed method has the capacity to handle MADM issues.},
  archive      = {J_CC},
  author       = {Jiang, Wen and Wang, Meijuan and Deng, Xinyang},
  doi          = {10.1007/s12559-021-09893-y},
  journal      = {Cognitive Computation},
  month        = {7},
  number       = {4},
  pages        = {1061-1069},
  shortjournal = {Cogn. Comput.},
  title        = {Multiple attribute decision making based on neutrosophic preference relation},
  volume       = {13},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-view clustering with latent low-rank proxy graph
learning. <em>CC</em>, <em>13</em>(4), 1049–1060. (<a
href="https://doi.org/10.1007/s12559-021-09889-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With advances in information acquisition technologies, multi-view data are increasing dramatically in a variety of real-world applications, whereas such data is usually corrupted by noises and outliers. Many existing multi-view graph clustering (MVGC) methods usually learn a consensus affinity graph using a late-fusion scheme in semantic space, which compound the challenge of leveraging the underlying relationships among corrupted multi-view data. In this paper, we propose a novel clustering method for handing corrupted multi-view data, hereafter referred to as Latent Low-Rank Proxy Graph Learning (LLPGL). Specifically, by projecting the multi-view data into a low-dimension proxy feature space, LLPGL can learn a low-dimension yet low-rank latent proxy from corrupted view data. Meanwhile, by employing the adaptive neighbor graph learning over the clean proxy, a high-quality affinity graph can be learned for clustering purpose. Then, an effective optimization algorithm is proposed to solve the model of LLPGL. Experimental results on five widely used real-world benchmarks validate the effectiveness of the proposed method.Consequently, the proposed method can be used to cluster the corrupted multi-view data for real-life applications.},
  archive      = {J_CC},
  author       = {Dai, Jian and Ren, Zhenwen and Luo, Yunzhi and Song, Hong and Yang, Jian},
  doi          = {10.1007/s12559-021-09889-8},
  journal      = {Cognitive Computation},
  month        = {7},
  number       = {4},
  pages        = {1049-1060},
  shortjournal = {Cogn. Comput.},
  title        = {Multi-view clustering with latent low-rank proxy graph learning},
  volume       = {13},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Commentary on “d-intuitionistic hesitant fuzzy sets and
their application in multiple attribute decision making.” <em>CC</em>,
<em>13</em>(4), 1047–1048. (<a
href="https://doi.org/10.1007/s12559-021-09884-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Li and Chen (Cognit Comput. 2018; 10:496–505) proposed the concept of the D-intuitionistic hesitant fuzzy set as well as proposed a method for comparing two D-intuitionistic fuzzy sets. Li and Chen have proposed the concept of the D-intuitionistic hesitant fuzzy set by introducing the degree of belief of the decision maker regarding the opinion of an expert in the existing definition of an intuitionistic hesitant fuzzy set. In future, other researchers may use Li and Chen’s comparing method in their research work. However, after a deep study, it is observed that Li and Chen’s comparing method fails to differentiate two distinct D-intuitionistic fuzzy sets. It is inappropriate to use Li and Chen’s comparing method.},
  archive      = {J_CC},
  author       = {Mishra, Akansha and Kumar, Amit and Appadoo, S. S.},
  doi          = {10.1007/s12559-021-09884-z},
  journal      = {Cognitive Computation},
  month        = {7},
  number       = {4},
  pages        = {1047-1048},
  shortjournal = {Cogn. Comput.},
  title        = {Commentary on “D-intuitionistic hesitant fuzzy sets and their application in multiple attribute decision making”},
  volume       = {13},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Clustering ensemble based on sample’s certainty.
<em>CC</em>, <em>13</em>(4), 1034–1046. (<a
href="https://doi.org/10.1007/s12559-021-09876-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The objective of clustering ensemble is to fuse multiple base partitions (BPs) to find the underlying data structure. It has been observed that sample can change its neighbors in different BPs and different samples have different relationship stability of sample. This difference shows that samples may have different contributions to the detection of underlying data structure. In addition, clustering ensemble aims to integrate the inconsistent parts of BPs by initially extracting the consistent parts. However, the existing clustering ensemble methods treat all samples equally. They neither consider sample relationship stability nor whether sample belongs to the consistent result or the inconsistent result in BPs. To tackle these deficiencies, we introduce the certainty of a sample to qualify its neighbor relationship stability and propose a formula to calculate this certainty. Then, we develop a clustering ensemble algorithm based on the sample’s certainty. It is based on the following idea: the neighbor relationship of cluster core in BPs is more stable, and different cluster cores usually do not form neighbor relationships in BPs. This idea forms the basis of the clustering ensemble process. According to the sample’s certainty, this algorithm divides a dataset into two subsets: cluster core samples and cluster halo samples. Then, the proposed algorithm discovers a clear core structure using cluster core samples and gradually assigns cluster halo samples to the core structure. The experiments on six synthetic datasets illustrate how our algorithm works. This algorithm has excellent performance and outperforms twelve state-of-the-art clustering ensemble algorithms on twelve real datasets.},
  archive      = {J_CC},
  author       = {Ji, Xia and Liu, Shuaishuai and Zhao, Peng and Li, Xuejun and Liu, Qiong},
  doi          = {10.1007/s12559-021-09876-z},
  journal      = {Cognitive Computation},
  month        = {7},
  number       = {4},
  pages        = {1034-1046},
  shortjournal = {Cogn. Comput.},
  title        = {Clustering ensemble based on sample’s certainty},
  volume       = {13},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-attribute cognitive decision making via convex
combination of weighted vector similarity measures for single-valued
neutrosophic sets. <em>CC</em>, <em>13</em>(4), 1019–1033. (<a
href="https://doi.org/10.1007/s12559-021-09883-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Similarity measure (SM) proves to be a necessary tool in cognitive decision making processes. A single-valued neutrosophic set (SVNS) is just a particular instance of neutrosophic sets (NSs), which is capable of handling uncertainty and impreciseness/vagueness with a better degree of accuracy. The present article proposes two new weighted vector SMs for SVNSs, by taking the convex combination of vector SMs of Jaccard and Dice and Jaccard and cosine vector SMs. The applications of the proposed measures are validated by solving few multi-attribute decision-making (MADM) problems under neutrosophic environment. Moreover, to prevent the spread of COVID-19 outbreak, we also demonstrate the problem of selecting proper antivirus face mask with the help of our newly constructed measures. The best deserving alternative is calculated based on the highest SM values between the set of alternatives with an ideal alternative. Meticulous comparative analysis is presented to show the effectiveness of the proposed measures with the already established ones in the literature. Finally, illustrative examples are demonstrated to show the reliability, feasibility, and applicability of the proposed decision-making method. The comparison of the results manifests a fair agreement of the outcomes for the best alternative, proving that our proposed measures are effective. Moreover, the presented SMs are assured to have multifarious applications in the field of pattern recognition, image clustering, medical diagnosis, complex decision-making problems, etc. In addition, the newly constructed measures have the potential of being applied to problems of group decision making where the human cognition-based thought processes play a major role.},
  archive      = {J_CC},
  author       = {Borah, Gourangajit and Dutta, Palash},
  doi          = {10.1007/s12559-021-09883-0},
  journal      = {Cognitive Computation},
  month        = {7},
  number       = {4},
  pages        = {1019-1033},
  shortjournal = {Cogn. Comput.},
  title        = {Multi-attribute cognitive decision making via convex combination of weighted vector similarity measures for single-valued neutrosophic sets},
  volume       = {13},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Investigating gender bias in BERT. <em>CC</em>,
<em>13</em>(4), 1008–1018. (<a
href="https://doi.org/10.1007/s12559-021-09881-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we analyze the gender bias induced by BERT in downstream tasks. We also propose solutions to reduce gender bias. Contextual language models (CLMs) have pushed the NLP benchmarks to a new height. It has become a new norm to utilize CLM-provided word embeddings in downstream tasks such as text classification. However, unless addressed, CLMs are prone to learn intrinsic gender bias in the dataset. As a result, predictions of downstream NLP models can vary noticeably by varying gender words, such as replacing “he” to “she”, or even gender-neutral words. In this paper, we focus our analysis on a popular CLM, i.e., $$\text {BERT}$$ . We analyze the gender bias it induces in five downstream tasks related to emotion and sentiment intensity prediction. For each task, we train a simple regressor utilizing $$\text {BERT}$$ ’s word embeddings. We then evaluate the gender bias in regressors using an equity evaluation corpus. Ideally and from the specific design, the models should discard gender informative features from the input. However, the results show a significant dependence of the system’s predictions on gender-particular words and phrases. We claim that such biases can be reduced by removing gender-specific features from word embedding. Hence, for each layer in BERT, we identify directions that primarily encode gender information. The space formed by such directions is referred to as the gender subspace in the semantic space of word embeddings. We propose an algorithm that finds fine-grained gender directions, i.e., one primary direction for each BERT layer. This obviates the need of realizing gender subspace in multiple dimensions and prevents other crucial information from being omitted. Experiments show that removing embedding components in gender directions achieves great success in reducing BERT-induced bias in the downstream tasks. The investigation reveals significant gender bias a contextualized language model ( i.e., $$\text {BERT}$$ ) induces in downstream tasks. The proposed solution seems promising in reducing such biases.},
  archive      = {J_CC},
  author       = {Bhardwaj, Rishabh and Majumder, Navonil and Poria, Soujanya},
  doi          = {10.1007/s12559-021-09881-2},
  journal      = {Cognitive Computation},
  month        = {7},
  number       = {4},
  pages        = {1008-1018},
  shortjournal = {Cogn. Comput.},
  title        = {Investigating gender bias in BERT},
  volume       = {13},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A novel robust soft-computed range-free localization
algorithm against malicious anchor nodes. <em>CC</em>, <em>13</em>(4),
992–1007. (<a href="https://doi.org/10.1007/s12559-021-09879-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A wireless sensor network consists of a set of low-cost, small, and low-powered sensor nodes. Information about the position of a sensor node is essential for many applications such as topology control, clustering, geographical routing, object tracking, and environmental monitoring. This article introduces a novel robust range-free genetic-based algorithm (RRGA) for the task of localization that is resistant to anchor node compromise attacks. The genetic algorithm (GA) serves to find the best set of anchors that can be utilized in a localization process to achieve higher accuracy. The other ordinary sensor nodes estimate their own locations using this set of the selected anchors. The algorithm can perform well even in the presence of malicious anchors. The performance of the presented algorithm was assessed in terms of localization accuracy, storage space, border problem, and resiliency against anchor node compromise attacks. The assessment was conducted through simulation. According to the results, compared to other algorithms, the presented RRGA algorithm decreases the localization error for at least about 10% in normal conditions and at least about 50% in the case of malicious anchor node attacks. It also reduces the effect of the border problem for at least about 10% in normal conditions and at least about 60% in the case of malicious anchor node attacks. Besides, the required storage space is improved for at least about 50%. The results suggest that the RRGA performs better than other localization algorithms.},
  archive      = {J_CC},
  author       = {Banihashemian, Seyed Saber and Adibnia, Fazlollah},
  doi          = {10.1007/s12559-021-09879-w},
  journal      = {Cognitive Computation},
  month        = {7},
  number       = {4},
  pages        = {992-1007},
  shortjournal = {Cogn. Comput.},
  title        = {A novel robust soft-computed range-free localization algorithm against malicious anchor nodes},
  volume       = {13},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). SE-DCGAN: A new method of semantic image restoration.
<em>CC</em>, <em>13</em>(4), 981–991. (<a
href="https://doi.org/10.1007/s12559-021-09877-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image restoration is a technique that utilizes the edge of a corrupted area. The information content of the damaged information area is inferred based on the remaining information of these images, and then the damaged area is filled to achieve image restoration. To solve the problem of image occlusion in practical applications, a squeeze-excitation network-deep convolution generative adversarial network (SE-DCGAN) was proposed. First, many new sharp images are generated using SE-DCGAN. Then, in the generated image, the most similar image is found based on the context semantics of the original image and the encoding of the unfilled portion to fill the original image. SE-DCGAN introduces maxout activation with powerful fitting capabilities to improve image generation efficiency and avoid image generation redundancy. Experiments based on three datasets of CelebA, Street View House Number and anime avatars, showed that our method successfully predicted a large number of missing regions. This method improves the recognition rate of occluded images, produces high-quality perceptual results, and is flexible enough to handle a variety of masks or obstructions.},
  archive      = {J_CC},
  author       = {Zhang, Fangyan and Wang, Xin and Sun, Tongfeng and Xu, Xinzheng},
  doi          = {10.1007/s12559-021-09877-y},
  journal      = {Cognitive Computation},
  month        = {7},
  number       = {4},
  pages        = {981-991},
  shortjournal = {Cogn. Comput.},
  title        = {SE-DCGAN: A new method of semantic image restoration},
  volume       = {13},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Improving neural machine translation model with deep
encoding information. <em>CC</em>, <em>13</em>(4), 972–980. (<a
href="https://doi.org/10.1007/s12559-021-09860-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Availability of very high computational power along with the development of deep neural network (DNN) technology has enabled rapid progress of machine translation technology. The powerful representation ability of the deep neural network also enables the neural machine translation technology (NMT) to exploit the available large-scale bilingual parallel corpus as well as the computing power to provide a highly effective translation model. Nevertheless, the existing neural machine translation models only utilize the top layer encoder information, whereas the information available in deeper encoding layers is often ignored. This significantly constrains the performance of the translation model. To address this issue, in this paper, we propose a novel neural machine translation model which can fully exploit the deep encoding information. The core idea is to use different ways of aggregating the information from different encoding layers. We further design three different aggregation strategies including parallel layer, multi-layer, and dynamic layer encoding information aggregations. Three translation models are correspondingly trained and compared with the baseline transformer model for the Chinese-to-English translation task. The experimental results indicate that the BLEU-4 score of the proposed model has been increased by 0.89 compared with that of the benchmark model. Experiments demonstrate the effectiveness of the proposed method.},
  archive      = {J_CC},
  author       = {Duan, Guiduo and Yang, Haobo and Qin, Ke and Huang, Tianxi},
  doi          = {10.1007/s12559-021-09860-7},
  journal      = {Cognitive Computation},
  month        = {7},
  number       = {4},
  pages        = {972-980},
  shortjournal = {Cogn. Comput.},
  title        = {Improving neural machine translation model with deep encoding information},
  volume       = {13},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Some information measures based on centroid, orthocenter,
circumcenter and incenter points of transformed triangular fuzzy numbers
and their applications. <em>CC</em>, <em>13</em>(4), 946–971. (<a
href="https://doi.org/10.1007/s12559-021-09842-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cognitive computing has deep extents, which embrace different features of cognition. In the decision-making process, multi-criteria decision making is credited as a cognitive-based human action. However, to treat and unite the information from several resources, the most vital stage is data collection. Intuitionistic fuzzy set (IFS) is one of the most robust and trustworthy tools to accomplish the imprecise information with the help of the membership degrees. In addition to this, an information measure plays an essential role in treating uncertain information to reach the final decision based on the degree of the separation between the pairs of the numbers. Motivated by these, this paper aims to present the novel information measures using four different centers namely centroid, orthocenter, circumcenter and incenter under the IFS environment to address the cognitive-based human decision-making problems. The present work is divided into three folds. The first fold is to propose a technique of transforming intuitionistic fuzzy values into general triangular fuzzy numbers (TFNs). The right-angled and isosceles TFNs are special cases of the proposed transformation technique. The second fold is to develop distance and similarity measures using four different centers namely centroid, orthocenter, circumcenter and incenter of transformed TFNs. The basic axioms of the proposed measures are investigated in detail. The third fold is to justify superiority and validity of the proposed measures. The effectiveness of the developed measures is examined by applying it in clustering as well as the pattern recognition problems, and their results are correlated with some prevailing studies. Additionally, a clustering technique is discussed based on the stated measures to classify the objects. A detailed comparative analysis is done with some of the existing measures and concludes that several existing measures fail to discriminate the results under the different instances such as division by zero problems or counter-intuitive cases while the proposed measure has successfully overcome this drawback.},
  archive      = {J_CC},
  author       = {Garg, Harish and Rani, Dimple},
  doi          = {10.1007/s12559-021-09842-9},
  journal      = {Cognitive Computation},
  month        = {7},
  number       = {4},
  pages        = {946-971},
  shortjournal = {Cogn. Comput.},
  title        = {Some information measures based on centroid, orthocenter, circumcenter and incenter points of transformed triangular fuzzy numbers and their applications},
  volume       = {13},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A motor rehabilitation BMI system design through improving
the SJIT model and introducing an MPC-based auxiliary controller.
<em>CC</em>, <em>13</em>(4), 936–945. (<a
href="https://doi.org/10.1007/s12559-021-09878-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the brain-machine interface (BMI) system, improving the motor recovery function of the joint and enabling the joint to adequately track the target trajectory are our main concerns. In this paper, to further improve the motor recovery effectiveness, two tasks are completed. First, a classical single-joint information transmission (SJIT) model is analyzed and improved by introducing several neurons. Second, an auxiliary controller that provides control inputs to the cerebral cortex is designed based on the model predictive control (MPC) strategy and is used to formulate a closed-loop motor rehabilitation BMI system based on the improved model. The simulation results show that the improved model can more accurately track the target movement trajectory than the SJIT model, and the designed BMI system can adequately recover the motor function of the joint. The sum of squared error (SSE) between the desired joint position trajectory and the output joint position trajectory is only $$1.2842 \times 10^{-5}$$ . In addition, under noises and disturbances, the BMI system can well recover the motor function of the joint. The model improvement and the designed BMI system are both effective.},
  archive      = {J_CC},
  author       = {Pan, Hongguang and Mi, Wenyu and Zhong, Weimin and Sun, Jinggao},
  doi          = {10.1007/s12559-021-09878-x},
  journal      = {Cognitive Computation},
  month        = {7},
  number       = {4},
  pages        = {936-945},
  shortjournal = {Cogn. Comput.},
  title        = {A motor rehabilitation BMI system design through improving the SJIT model and introducing an MPC-based auxiliary controller},
  volume       = {13},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Probabilistic dual-hesitant pythagorean fuzzy sets and their
application in multi-attribute group decision-making. <em>CC</em>,
<em>13</em>(4), 919–935. (<a
href="https://doi.org/10.1007/s12559-021-09858-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As modern socioeconomic decision-making problems are becoming more and more complex, it also becomes more and more difficult to appropriately depict decision makers’ cognitive information in decision-making process. In addition, in group decision-making problems, decision makers’ cognition is usually diverse, which makes it more complicated to express the overall preference information. Recently, the dual-hesitant Pythagorean fuzzy sets (DHPFSs) have been proved to be an effective tool to depict decision makers’ evaluation values in multi-attribute group decision-making (MAGDM) procedure. The basic elements of DHPFSs are dual-hesitant Pythagorean fuzzy numbers (DHFNs), which are characterized by some possible membership degrees and non-membership degrees. In a DHFN, all members have the same importance, which indicates that multiple occurrence and appearance of some elements is ignored. Hence, the DHPFSs still have some drawbacks when expressing decision makers’ evaluation information in MAGDM problems. This paper aims at proposing a novel tool to describe decision maker’s evaluation values and apply it in solving MAGDM problems. This paper extends the traditional DHPFSs to probabilistic dual-hesitant Pythagorean fuzzy sets (PDHPFSs), which consider not only multiple membership and non-membership degrees, but also their probabilistic information. Afterward, we investigate the applications of PDHPFSs in MAGDM process. To this end, we first introduce the concept of DHPFSs as well as some related notions, such as operational rules, score function, accuracy function, comparison method, and distance measure. Second, based on the power average and Hamy mean, some aggregation operators for DHPFSs are presented. Properties of these new operators are also discussed. Third, we put forward a novel MAGDM method under PDHPFSs. A novel MAGDM method is developed, and further, we conduct numerical examples to show the performance and advantages of the new method. Results indicate that our method can effectively handle MAGDM problems in reality. In addition, comparative analysis also reveals the advantages of our method. This paper contributed a novel MAGDM method and numerical examples as well as comparative analysis were provided to show the effectiveness and advantages of our proposed method. Our contributions provide decision makers a new manner to determine the optimal alternative in realistic MAGDM problems.},
  archive      = {J_CC},
  author       = {Ji, Chunliang and Zhang, Runtong and Wang, Jun},
  doi          = {10.1007/s12559-021-09858-1},
  journal      = {Cognitive Computation},
  month        = {7},
  number       = {4},
  pages        = {919-935},
  shortjournal = {Cogn. Comput.},
  title        = {Probabilistic dual-hesitant pythagorean fuzzy sets and their application in multi-attribute group decision-making},
  volume       = {13},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Root cause analysis based on relations among sentiment
words. <em>CC</em>, <em>13</em>(4), 903–918. (<a
href="https://doi.org/10.1007/s12559-021-09872-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sentiment analysis is a useful method to extract user preferences from product reviews; however, it cannot explain the detailed reasons for user preferences because of the exclusion of neutral sentiment words, constituting a large proportion of the words used in reviews. In contrast, there are limitations to using root cause analysis to analyze sentiment relations using sentiment words extracted from user preferences. This research aimed to extract a more fine-grained root cause by proposing a novel method capable of analyzing the root cause based on the relations between sentiment words. To identify the root causes of negative opinions in aspect-level sentiment analysis, we analyze the hierarchical and causal relations between sentiment triples and utilize hierarchical clustering based on sentiment triples’ relation to compensate for general sentiment words. The experimental results showed that the proposed method was 6.4% and 5.1% more accurate than the existing aspect-level analysis for the mobile device and clothing domains, respectively. Finally, we discussed some issues associated with the proposed method using a qualitative evaluation. In this study, a novel root cause identification method that can utilize the hierarchical and causal relations between sentiment words using negative and neutral sentiment expressions of product reviews is proposed.},
  archive      = {J_CC},
  author       = {Park, Sang-Min and Kim, Young-Gab},
  doi          = {10.1007/s12559-021-09872-3},
  journal      = {Cognitive Computation},
  month        = {7},
  number       = {4},
  pages        = {903-918},
  shortjournal = {Cogn. Comput.},
  title        = {Root cause analysis based on relations among sentiment words},
  volume       = {13},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A survey on sentiment analysis in persian: A comprehensive
system perspective covering challenges and advances in resources and
methods. <em>CC</em>, <em>13</em>(4), 882–902. (<a
href="https://doi.org/10.1007/s12559-021-09886-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Social media has been remarkably grown during the past few years. Nowadays, posting messages on social media websites has become one of the most popular Internet activities. The vast amount of user-generated content has made social media the most extensive data source of public opinion. Sentiment analysis is one of the techniques used to analyze user-generated data. The Persian language has specific features and thereby requires unique methods and models to be adopted for sentiment analysis, which are different from those in English language. Sentiment analysis in each language has specified prerequisites; hence, the direct use of methods, tools, and resources developed for English language in Persian has its limitations. The main target of this paper is to provide a comprehensive literature survey for state-of-the-art advances in Persian sentiment analysis. In this regard, the present study aims to investigate and compare the previous sentiment analysis studies on Persian texts and describe contributions presented in articles published in the last decade. First, the levels, approaches, and tasks for sentiment analysis are described. Then, a detailed survey of the sentiment analysis methods used for Persian texts is presented, and previous relevant works on Persian Language are discussed. Moreover, we present in this survey the authentic and published standard sentiment analysis resources and advances that have been done for Persian sentiment analysis. Finally, according to the state-of-the-art development of English sentiment analysis, some issues and challenges not being addressed in Persian texts are listed, and some guidelines and trends are provided for future research on Persian texts. The paper provides information to help new or established researchers in the field as well as industry developers who aim to deploy an operational complete sentiment analysis system.},
  archive      = {J_CC},
  author       = {Rajabi, Zeinab and Valavi, MohammadReza},
  doi          = {10.1007/s12559-021-09886-x},
  journal      = {Cognitive Computation},
  month        = {7},
  number       = {4},
  pages        = {882-902},
  shortjournal = {Cogn. Comput.},
  title        = {A survey on sentiment analysis in persian: A comprehensive system perspective covering challenges and advances in resources and methods},
  volume       = {13},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). One-shot cluster-based approach for the detection of
COVID–19 from chest x–ray images. <em>CC</em>, <em>13</em>(4), 873–881.
(<a href="https://doi.org/10.1007/s12559-020-09774-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Coronavirus disease (COVID-19) has infected over more than 28.3 million people around the globe and killed 913K people worldwide as on 11 September 2020. With this pandemic, to combat the spreading of COVID-19, effective testing methodologies and immediate medical treatments are much required. Chest X-rays are the widely available modalities for immediate diagnosis of COVID-19. Hence, automation of detection of COVID-19 from chest X-ray images using machine learning approaches is of greater demand. A model for detecting COVID-19 from chest X-ray images is proposed in this paper. A novel concept of cluster-based one-shot learning is introduced in this work. The introduced concept has an advantage of learning from a few samples against learning from many samples in case of deep leaning architectures. The proposed model is a multi-class classification model as it classifies images of four classes, viz., pneumonia bacterial, pneumonia virus, normal, and COVID-19. The proposed model is based on ensemble of Generalized Regression Neural Network (GRNN) and Probabilistic Neural Network (PNN) classifiers at decision level. The effectiveness of the proposed model has been demonstrated through extensive experimentation on a publicly available dataset consisting of 306 images. The proposed cluster-based one-shot learning has been found to be more effective on GRNN and PNN ensembled model to distinguish COVID-19 images from that of the other three classes. It has also been experimentally observed that the model has a superior performance over contemporary deep learning architectures. The concept of one-shot cluster-based learning is being first of its kind in literature, expected to open up several new dimensions in the field of machine learning which require further researching for various applications.},
  archive      = {J_CC},
  author       = {Aradhya, V. N. Manjunath and Mahmud, Mufti and Guru, D. S. and Agarwal, Basant and Kaiser, M. Shamim},
  doi          = {10.1007/s12559-020-09774-w},
  journal      = {Cognitive Computation},
  month        = {7},
  number       = {4},
  pages        = {873-881},
  shortjournal = {Cogn. Comput.},
  title        = {One-shot cluster-based approach for the detection of COVID–19 from chest x–ray images},
  volume       = {13},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Visual cognition–inspired multi-view vehicle
re-identification via laplacian-regularized correlative sparse ranking.
<em>CC</em>, <em>13</em>(4), 859–872. (<a
href="https://doi.org/10.1007/s12559-019-09687-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vehicle re-identification has gradually gained attention and widespread applications. However, most of the existing methods learn the discriminative features for identities by single-feature channel only. It is worth noting that visual cognition of the human eyes is a multi-channel system which usually seeks a sparse representation. Therefore, integrating the multi-view information in sparse representation is a natural way to boost computer vision tasks in challenging scenarios. In this paper, we propose to mine multi-view deep features via Laplacian-regularized correlative sparse ranking for vehicle re-identification. Specifically, first, we employ multiple baseline networks to generate features. Then, we explore the feature correlation via enforcing the correlation term into the multi-view Laplacian sparse ranking framework. The original rankings are obtained by the reconstruction coefficients between the probe and gallery. Finally, we utilize a re-ranking technique to further boost performance. Experimental results on public benchmark VeRi-776 and VehicleID datasets demonstrate that our approach outperforms state-of-the-art approaches. The Laplacian-regularized correlative sparse ranking as a general framework can be used in any multi-view feature fusion and will obtain more competitive results.},
  archive      = {J_CC},
  author       = {Zheng, Aihua and Dong, Jiacheng and Lin, Xianmin and Liu, Lidan and Jiang, Bo and Luo, Bin},
  doi          = {10.1007/s12559-019-09687-3},
  journal      = {Cognitive Computation},
  month        = {7},
  number       = {4},
  pages        = {859-872},
  shortjournal = {Cogn. Comput.},
  title        = {Visual Cognition–Inspired multi-view vehicle re-identification via laplacian-regularized correlative sparse ranking},
  volume       = {13},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Style-neutralized pattern classification based on
adversarially trained upgraded u-net. <em>CC</em>, <em>13</em>(4),
845–858. (<a href="https://doi.org/10.1007/s12559-019-09660-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional machine learning approaches usually hold the assumption that data for model training and in real applications are created following the identical and independent distribution (i.i.d.). However, several relevant research topics have demonstrated that such condition may not always describe the real scenarios. One particular case is that the patterns are equipped with diverse and changeable style information. In this paper, a novel classification framework named Style Neutralization Generative Adversarial Classifier (SN-GAC), based on an upgraded U-Net architecture, and trained adversarially with the Generative Adversarial Network (GAN) framework, is introduced to accomplish the classification in such disparate and inconsistent data information case. The generative model in SN-GAC neutralizes style information from the original style-discriminative patterns (style-source) by building the mapping function from them to their style-free counterparts (corresponding standard examples, standard-target). A well-learned generator in the SN-GAC framework is capable of producing the targeted style-neutralized data (generated-target), satisfying the i.i.d. condition. Additionally, SN-GAC is trained adversarially, where an independent discriminator is used to surveil and supervise the training progress of the above-mentioned generator by distinguishing between the real and the generated. Simultaneously, an auxiliary classifier is also embedded in the discriminator to assign the correct class label of both the real and generated data. This process proves effective to aid the generator to produce high-quality human-readable style-neutralized patterns. It will then be further fine-tuned for the sake of promoting the final classification performance. Extensive experiments have adequately demonstrated the effectiveness of the proposed SN-GAC framework: it outperforms several relevant state-of-the-art baselines on two empirical data sets in the non-i.i.d. data classification task.},
  archive      = {J_CC},
  author       = {Jiang, Haochuan and Huang, Kaizhu and Zhang, Rui and Hussain, Amir},
  doi          = {10.1007/s12559-019-09660-0},
  journal      = {Cognitive Computation},
  month        = {7},
  number       = {4},
  pages        = {845-858},
  shortjournal = {Cogn. Comput.},
  title        = {Style-neutralized pattern classification based on adversarially trained upgraded U-net},
  volume       = {13},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Predicting seminal quality via imbalanced learning with
evolutionary safe-level synthetic minority over-sampling technique.
<em>CC</em>, <em>13</em>(4), 833–844. (<a
href="https://doi.org/10.1007/s12559-019-09657-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Seminal quality has fallen dramatically over the past two decades. Research indicates that environmental factors, health status, and life habits might lead to the decline. Prediction of seminal quality is very useful in the early diagnosis of infertile patients. Recently, artificial intelligence (AI) technologies have been applied to the study of the male fertility potential. As it is common in many real applications about cognitive computation, seminal quality prediction faces the problem of class imbalance, and conventional algorithms are often biased towards the majority class. In this paper, an evolutionary safe-level synthetic minority over-sampling technique (ESLSMOTE) is proposed to synthesize the minority instances along the same line with different weight degree, called safe level. The profile of seminal of an individual from the fertility dataset is predicted via three classification methods with ESLSMOTE. Important indicators, such as accuracy, precision, recall, receiver operating characteristic (ROC) curve, and F1-score, are used to evaluate the performance of the classifiers with ESLSMOTE based on a tenfold cross-validation scheme. The experimental results show that the proposed ESLSMOTE can significantly improve the accuracy of back-propagation neural network, adaptive boosting, and support vector machine. The highest area under the ROC curve (97.2%) is given by the ESLSMOTE-AdaBoost model. Experimental results indicate that the ESLSMOTE-based classifiers outperform current state-of-the-art methods on predicting the seminal quality in terms of the accuracy and the area under the ROC curve. As such, the ESLSMOTE-based classifiers have the capability of predicting the seminal quality with high accuracy.},
  archive      = {J_CC},
  author       = {Ma, Jieming and Afolabi, David Olalekan and Ren, Jie and Zhen, Aiyan},
  doi          = {10.1007/s12559-019-09657-9},
  journal      = {Cognitive Computation},
  month        = {7},
  number       = {4},
  pages        = {833-844},
  shortjournal = {Cogn. Comput.},
  title        = {Predicting seminal quality via imbalanced learning with evolutionary safe-level synthetic minority over-sampling technique},
  volume       = {13},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Salient superpixel visual tracking with graph model and
iterative segmentation. <em>CC</em>, <em>13</em>(4), 821–832. (<a
href="https://doi.org/10.1007/s12559-019-09662-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visual object tracking is to locate an object of interest in a sequence of consecutive video frames, which is widely applied in many high-level computer vision tasks such as intelligent video surveillance and robotics. It is of great challenges for visual tracking methods to handle large target appearance variations caused by pose deformation, fast motion, occlusion, and surrounding environments in real-time videos. In this paper, inspired by human attention cognitive saliency model, we propose a visual tracking method based on salient superpixels which integrates the target appearance similarity and cognitive saliency, and helps to location inference and appearance model updating. The saliency of superpixel is detected by graph model and manifold ranking. We cluster the superpixels of the first four target boxes into a set corresponding to object foreground and model the target appearance with color descriptors. While tracking, the relevance is computed between the candidate superpixels and the target appearance set. We also propose an iterative threshold segmentation method to distinguish the foreground and background of superpixels based on saliency and relevance. To increase the accuracy of location inference, we explore particle filter in both confidence estimation and sampling procedures. We compared our method with the existing techniques in OTB100 dataset in terms of precision based on center location error and success rate based on overlap, and the experimental results show that our proposed method achieved substantially better performance. Promising results have shown that the proposed salient superpixel-based approach is effective to deformation, occlusion, and other challenges in object tracking.},
  archive      = {J_CC},
  author       = {Zhan, Jin and Zhao, Huimin and Zheng, Penggen and Wu, Hefeng and Wang, Leijun},
  doi          = {10.1007/s12559-019-09662-y},
  journal      = {Cognitive Computation},
  month        = {7},
  number       = {4},
  pages        = {821-832},
  shortjournal = {Cogn. Comput.},
  title        = {Salient superpixel visual tracking with graph model and iterative segmentation},
  volume       = {13},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Image captioning with memorized knowledge. <em>CC</em>,
<em>13</em>(4), 807–820. (<a
href="https://doi.org/10.1007/s12559-019-09656-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image captioning, which aims to automatically generate text description of given images, has received much attention from researchers. Most existing approaches adopt a recurrent neural network (RNN) as a decoder to generate captions conditioned on the input image information. However, traditional RNNs deal with the sequence in a recurrent way, squeezing the information of all previous words into hidden cells and updating the context information by fusing the hidden states with the current word information. This may miss the rich knowledge too far in the past. In this paper, we propose a memory-enhanced captioning model for image captioning. We firstly introduce an external memory to store the past knowledge, i.e., all the information of generated words. When predicting the next word, the decoder can retrieve knowledge information about the past by means of a selective reading mechanism. Furthermore, to better explore the knowledge stored in the memory, we introduce several variants that consider different types of past knowledge. To verify the effectiveness of the proposed model, we conduct extensive experiments and comparisons on the well-known image captioning dataset MS COCO. Compared with the state-of-the-art captioning models, the proposed memory-enhanced captioning model shows a significant improvement in terms of the performance (improving 3.5% in terms of CIDEr). The proposed memory-enhanced captioning model, as demonstrated in the experiments, is more effective and superior to the state-of-the-art methods.},
  archive      = {J_CC},
  author       = {Chen, Hui and Ding, Guiguang and Lin, Zijia and Guo, Yuchen and Shan, Caifeng and Han, Jungong},
  doi          = {10.1007/s12559-019-09656-w},
  journal      = {Cognitive Computation},
  month        = {7},
  number       = {4},
  pages        = {807-820},
  shortjournal = {Cogn. Comput.},
  title        = {Image captioning with memorized knowledge},
  volume       = {13},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A novel semi-supervised convolutional neural network method
for synthetic aperture radar image recognition. <em>CC</em>,
<em>13</em>(4), 795–806. (<a
href="https://doi.org/10.1007/s12559-019-09639-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Synthetic aperture radar (SAR) automatic target recognition (ATR) technology is one of the research hotspots in the field of image cognitive learning. Inspired by the human cognitive process, experts have designed convolutional neural network (CNN)-based SAR ATR methods. However, the performance of CNN significantly deteriorates when the labeled samples are insufficient. To effectively utilize the unlabeled samples, we present a novel semi-supervised CNN method. In the training process of our method, the information contained in the unlabeled samples is integrated into the loss function of CNN. Specifically, we first utilize CNN to obtain the class probabilities of the unlabeled samples. Thresholding processing is performed to optimize the class probabilities so that the reliability of the unlabeled samples is improved. Afterward, the optimized class probabilities are used to calculate the scatter matrices of the linear discriminant analysis (LDA) method. Finally, the loss function of CNN is modified by the scatter matrices. We choose ten types of targets from the Moving and Stationary Target Acquisition and Recognition (MSTAR) dataset. The experimental results show that the recognition accuracy of our method is significantly higher than other semi-supervised methods. It has been proved that our method can effectively improve the SAR ATR accuracy when labeled samples are insufficient.},
  archive      = {J_CC},
  author       = {Yue, Zhenyu and Gao, Fei and Xiong, Qingxu and Wang, Jun and Huang, Teng and Yang, Erfu and Zhou, Huiyu},
  doi          = {10.1007/s12559-019-09639-x},
  journal      = {Cognitive Computation},
  month        = {7},
  number       = {4},
  pages        = {795-806},
  shortjournal = {Cogn. Comput.},
  title        = {A novel semi-supervised convolutional neural network method for synthetic aperture radar image recognition},
  volume       = {13},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-scale mahalanobis kernel-based support vector machine
for classification of high-resolution remote sensing images.
<em>CC</em>, <em>13</em>(4), 787–794. (<a
href="https://doi.org/10.1007/s12559-019-09631-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Support vector machine (SVM) is a powerful cognitive and learning algorithm in the domain of pattern recognition and image classification. However, the generalization ability of SVM is limited when processing classification of high-resolution remote sensing images. One chief reason for this is that the Euclidean distance-based distance matrix in traditional SVM treats different samples equally and overlooks the global distribution of samples. To construct a more effective SVM-based classification method, this paper proposes a multi-scale Mahalanobis kernel-based SVM classifier. In this new method, we first introduce a Mahalanobis distance kernel to improve the global cognitive learning ability of SVM. Then, the Mahalanobis distance kernel is embedded to the multi-scale kernel learning (MSKL) to construct a novel multi-scale Mahalanobis kernel, in which the parameters are optimized by a bio-inspired algorithm, named differential evolution. Finally, the new method is extended to the classification of high-resolution remote sensing images based on the spatial-spectral features. The comparison experiments of five public UCI datasets and two high-resolution remote sensing images verify that the Mahalanobis distance-based method can obtain more accurate classification results than that of the Euclidean distance-based method. In addition, the proposed method produced the best classification results in all the experiments. The global cognitive learning ability of Mahalanobis distance-based method is stronger than that of the Euclidean distance-based method. In addition, this study indicates that the optimized MSKL are potential for the interpretation and understanding of complicated high-resolution remote sensing scene.},
  archive      = {J_CC},
  author       = {Sun, Genyun and Rong, Xueqian and Zhang, Aizhu and Huang, Hui and Rong, Jun and Zhang, Xuming},
  doi          = {10.1007/s12559-019-09631-5},
  journal      = {Cognitive Computation},
  month        = {7},
  number       = {4},
  pages        = {787-794},
  shortjournal = {Cogn. Comput.},
  title        = {Multi-scale mahalanobis kernel-based support vector machine for classification of high-resolution remote sensing images},
  volume       = {13},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Editorial: Special issue on recent advances in cognitive
learning and data analysis. <em>CC</em>, <em>13</em>(4), 785–786. (<a
href="https://doi.org/10.1007/s12559-020-09737-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_CC},
  author       = {Ren, Jinchang and Hussain, Amir and Zheng, Jiangbin and Liu, Cheng-Lin and Luo, Bin},
  doi          = {10.1007/s12559-020-09737-1},
  journal      = {Cognitive Computation},
  month        = {7},
  number       = {4},
  pages        = {785-786},
  shortjournal = {Cogn. Comput.},
  title        = {Editorial: Special issue on recent advances in cognitive learning and data analysis},
  volume       = {13},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). When old meets new: Emotion recognition from speech signals.
<em>CC</em>, <em>13</em>(3), 771–783. (<a
href="https://doi.org/10.1007/s12559-021-09865-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Speech is one of the most natural communication channels for expressing human emotions. Therefore, speech emotion recognition (SER) has been an active area of research with an extensive range of applications that can be found in several domains, such as biomedical diagnostics in healthcare and human–machine interactions. Recent works in SER have been focused on end-to-end deep neural networks (DNNs). However, the scarcity of emotion-labeled speech datasets inhibits the full potential of training a deep network from scratch. In this paper, we propose new approaches for classifying emotions from speech by combining conventional mel-frequency cepstral coefficients (MFCCs) with image features extracted from spectrograms by a pretrained convolutional neural network (CNN). Unlike prior studies that employ end-to-end DNNs, our methods eliminate the resource-intensive network training process. By using the best prediction model obtained, we also build an SER application that predicts emotions in real time. Among the proposed methods, the hybrid feature set fed into a support vector machine (SVM) achieves an accuracy of 0.713 in a 6-class prediction problem evaluated on the Ryerson Audio-Visual Database of Emotional Speech and Song (RAVDESS) dataset, which is higher than the previously published results. Interestingly, MFCCs taken as unique input into a long short-term memory (LSTM) network achieve a slightly higher accuracy of 0.735. Our results reveal that the proposed approaches lead to an improvement in prediction accuracy. The empirical findings also demonstrate the effectiveness of using a pretrained CNN as an automatic feature extractor for the task of emotion prediction. Moreover, the success of the MFCC-LSTM model is evidence that, despite being conventional features, MFCCs can still outperform more sophisticated deep-learning feature sets.},
  archive      = {J_CC},
  author       = {Araño, Keith April and Gloor, Peter and Orsenigo, Carlotta and Vercellis, Carlo},
  doi          = {10.1007/s12559-021-09865-2},
  journal      = {Cognitive Computation},
  month        = {5},
  number       = {3},
  pages        = {771-783},
  shortjournal = {Cogn. Comput.},
  title        = {When old meets new: Emotion recognition from speech signals},
  volume       = {13},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Analysis and prediction of COVID-19 pandemic in bangladesh
by using ANFIS and LSTM network. <em>CC</em>, <em>13</em>(3), 761–770.
(<a href="https://doi.org/10.1007/s12559-021-09859-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The dangerously contagious virus named “COVID-19” has struck the world strong and has locked down billions of people in their homes to stop the further spread. All the researchers and scientists in various fields are continually developing a vaccine and prevention methods to aid the world from this challenging situation. However, a reliable prediction of the epidemic may help control this contiguous disease until the cure is available. The machine learning techniques are one of the frontiers in predicting this outbreak’s future trend and behavior. Our research is focused on finding a suitable machine learning algorithm that can predict the COVID-19 daily new cases with higher accuracy. This research has used the adaptive neuro-fuzzy inference system (ANFIS) and the long short-term memory (LSTM) to foresee the newly infected cases in Bangladesh. We have compared both the experiments’ results, and it can be forenamed that LSTM has shown more satisfactory results. Upon study and testing on several models, we have shown that LSTM works better on a scenario-based model for Bangladesh with mean absolute percentage error (MAPE)—4.51, root-mean-square error (RMSE)—6.55, and correlation coefficient—0.75. This study is expected to shed light on COVID-19 prediction models for researchers working with machine learning techniques and avoid proven failures, especially for small imprecise datasets.},
  archive      = {J_CC},
  author       = {Chowdhury, Anjir Ahmed and Hasan, Khandaker Tabin and Hoque, Khadija Kubra Shahjalal},
  doi          = {10.1007/s12559-021-09859-0},
  journal      = {Cognitive Computation},
  month        = {5},
  number       = {3},
  pages        = {761-770},
  shortjournal = {Cogn. Comput.},
  title        = {Analysis and prediction of COVID-19 pandemic in bangladesh by using ANFIS and LSTM network},
  volume       = {13},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Attention-augmented machine memory. <em>CC</em>,
<em>13</em>(3), 751–760. (<a
href="https://doi.org/10.1007/s12559-021-09854-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Attention mechanism plays an important role in the perception and cognition of human beings. Among others, many machine learning models have been developed to memorize the sequential data, such as the Long Short-Term Memory (LSTM) network and its extensions. However, due to lack of the attention mechanism, they cannot pay special attention to the important parts of the sequences. In this paper, we present a novel machine learning method called attention-augmented machine memory (AAMM). It seamlessly integrates the attention mechanism into the memory cell of LSTM. As a result, it facilitates the network to focus on valuable information in the sequences and ignore irrelevant information during its learning. We have conducted experiments on two sequence classification tasks for pattern classification and sentiment analysis, respectively. The experimental results demonstrate the advantages of AAMM over LSTM and some other related approaches. Hence, AAMM can be considered as a substitute of LSTM in the sequence learning applications.},
  archive      = {J_CC},
  author       = {Lin, Xin and Zhong, Guoqiang and Chen, Kang and Li, Qingyang and Huang, Kaizhu},
  doi          = {10.1007/s12559-021-09854-5},
  journal      = {Cognitive Computation},
  month        = {5},
  number       = {3},
  pages        = {751-760},
  shortjournal = {Cogn. Comput.},
  title        = {Attention-augmented machine memory},
  volume       = {13},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Prosociality in cyberspace: Developing emotion and
behavioral regulation to decrease aggressive communication. <em>CC</em>,
<em>13</em>(3), 736–750. (<a
href="https://doi.org/10.1007/s12559-021-09852-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Different forms of verbal aggression are often present in cyberbullying, which may impair executive function skills that enable the regulation of emotions and behavior. Emotion and behavioral regulation has been associated with better social adjustment and more positive interactions between peers. This study aimed to understand if fostering emotion and behavioral regulation strategies could decrease aggressive communication. A quasi-experimental longitudinal design, based on a Twitter client mobile application, with pre-posttest measures was used. For the application, we explored different machine learning approaches, including computational intelligence methods. Multilevel linear modeling and frequency analyses were performed. A convenience sample of 218 adolescents (Mage = 14.67, SD = 0.84, 53% female) participated in the study. Results suggest that a Twitter client mobile application intervention based on emotion and behavioral regulation strategies may help decrease adolescents’ aggressive communication. Moreover, female and male participants who used the digital application tended to present distinct trajectories over time with regard to searching for information concerning prosocial behavior. These findings suggest that digital tools resorting to emotion and behavioral regulation strategies may be effective in reducing an aggressive communication style amongst adolescents, and consequently, promote resource seeking to engage in prosociality. These results can be significant for the design of intervention programs against cyberbullying.},
  archive      = {J_CC},
  author       = {Veiga Simão, Ana Margarida and Costa Ferreira, Paula and Pereira, Nádia and Oliveira, Sofia and Paulino, Paula and Rosa, Hugo and Ribeiro, Ricardo and Coheur, Luísa and Carvalho, João Paulo and Trancoso, Isabel},
  doi          = {10.1007/s12559-021-09852-7},
  journal      = {Cognitive Computation},
  month        = {5},
  number       = {3},
  pages        = {736-750},
  shortjournal = {Cogn. Comput.},
  title        = {Prosociality in cyberspace: Developing emotion and behavioral regulation to decrease aggressive communication},
  volume       = {13},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A robust automated machine learning system with
pseudoinverse learning. <em>CC</em>, <em>13</em>(3), 724–735. (<a
href="https://doi.org/10.1007/s12559-021-09853-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Developing a robust deep neural network (DNN) for a specific task is not only time-consuming but also requires lots of experienced human experts. In order to make deep neural networks easier to apply or even take the human experts out of the design of network architecture completely, a growing number of researches focus on robust automated machine learning (AutoML). In this paper, we investigated the robustness problem of AutoML systems based on contractive pseudoinverse learners. In our proposed method, deep neural networks were built with stacked contractive pseudoinverse learners (CPILer). Each CPILer has a Jacobian regularized reconstruction loss function and is trained with pseudoinverse learning algorithm. When sigmoid activation function is adopted in the hidden layer, the graph Laplace regularizer is derived from square Frobenius norm of the Jacobian matrix. This learning scheme not only speeds up the training process dramatically but also reduces the effort of hyperparameter tuning. In addition, the graph Laplace regularization can improve the robustness of the learning systems by reducing the sensibility to noise. An ensemble network architecture consisting of several sub-networks was designed to build the AutoML systems. The architecture hyperparameters of the system were determined in an automated way which could be considered as a data-driven way. The proposed method shown good performance in the experiments in terms of efficiency and accuracy, and outperformed the baseline methods on a series of benchmark data sets. The robustness improvement of our proposed method was also demonstrated in the experiments.},
  archive      = {J_CC},
  author       = {Wang, Ke and Guo, Ping},
  doi          = {10.1007/s12559-021-09853-6},
  journal      = {Cognitive Computation},
  month        = {5},
  number       = {3},
  pages        = {724-735},
  shortjournal = {Cogn. Comput.},
  title        = {A robust automated machine learning system with pseudoinverse learning},
  volume       = {13},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A hybrid CNN-LSTM model for psychopathic class detection
from tweeter users. <em>CC</em>, <em>13</em>(3), 709–723. (<a
href="https://doi.org/10.1007/s12559-021-09836-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In today’s digital era, the use of online social media networks, such as Google, YouTube, Facebook, and Twitter, permits people to generate a massive amount of textual content. The textual content that is produced by people reveals essential information regarding their personality, with psychopathy being among these distinct personality types. This work was aimed at classifying input texts according to the traits of psychopaths and non-psychopaths. Several studies based on traditional techniques, such as the SRPIII technique, using small-sized datasets have been conducted for the detection of psychopathic behavior. However, the purpose of the current study was to build an effective computational model for the detection of psychopaths in the domain of text analytics and computational intelligence. This study was aimed at developing a technique based on a convolutional neural network + long short-term memory (CNN-LSTM) model by using a deep learning approach to detect psychopaths. A convolutional neural network was used to extract local information from a text, while the long short-term memory was used to extract the contextual dependencies of the text. By combining the advantages of convolutional neural network and long short-term memory, the proposed hybrid CNN-LSTM was able to yield a good classification accuracy of 91.67%. Additionally, a large-sized benchmark dataset was acquired for the effective classification of the given input text into psychopath vs. non-psychopath classes, thereby enabling persons with such personality traits to be identified.},
  archive      = {J_CC},
  author       = {Alotaibi, Fahad Mazaed and Asghar, Muhammad Zubair and Ahmad, Shakeel},
  doi          = {10.1007/s12559-021-09836-7},
  journal      = {Cognitive Computation},
  month        = {5},
  number       = {3},
  pages        = {709-723},
  shortjournal = {Cogn. Comput.},
  title        = {A hybrid CNN-LSTM model for psychopathic class detection from tweeter users},
  volume       = {13},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Discriminative dictionary design for action classification
in still images and videos. <em>CC</em>, <em>13</em>(3), 698–708. (<a
href="https://doi.org/10.1007/s12559-021-09851-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we address the problem of action recognition from still images and videos. Traditional local features such as SIFT and STIP invariably pose two potential problems: 1) they are not evenly distributed in different entities of a given category and 2) many of such features are not exclusive of the visual concept the entities represent. In order to generate a dictionary taking the aforementioned issues into account, we propose a novel discriminative method for identifying robust and category specific local features which maximize the class separability to a greater extent. Specifically, we pose the selection of potent local descriptors as filtering-based feature selection problem, which ranks the local features per category based on a novel measure of distinctiveness. The underlying visual entities are subsequently represented based on the learned dictionary, and this stage is followed by action classification using the random forest model followed by label propagation refinement. The framework is validated on the action recognition datasets based on still images (Stanford-40) as well as videos (UCF-50). We get 51.2% and 66.7% recognition accuracy for Standford-40 and UCF-50, respectively. Compared to other representative methods from the literature, our approach exhibits superior performances. This proves the effectiveness of adaptive ranking methodology presented in this work.},
  archive      = {J_CC},
  author       = {Roy, Abhinaba and Banerjee, Biplab and Hussain, Amir and Poria, Soujanya},
  doi          = {10.1007/s12559-021-09851-8},
  journal      = {Cognitive Computation},
  month        = {5},
  number       = {3},
  pages        = {698-708},
  shortjournal = {Cogn. Comput.},
  title        = {Discriminative dictionary design for action classification in still images and videos},
  volume       = {13},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Pronunciation-enhanced chinese word embedding. <em>CC</em>,
<em>13</em>(3), 688–697. (<a
href="https://doi.org/10.1007/s12559-021-09850-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Chinese word embeddings have recently garnered considerable attention. Chinese characters and their sub-character components, which contain rich semantic information, are incorporated to learn Chinese word embeddings. Chinese characters can represent a combination of meaning, structure, and pronunciation. However, existing embedding learning methods focus on the structure and meaning of Chinese characters. In this study, we aim to develop an embedding learning method that can make complete use of the information represented by Chinese characters, including phonology, morphology, and semantics. Specifically, we propose a pronunciation-enhanced Chinese word embedding learning method, where the pronunciations of context characters and target characters are simultaneously encoded into the embeddings. Evaluation of word similarity, word analogy reasoning, text classification, and sentiment analysis validate the effectiveness of our proposed method.},
  archive      = {J_CC},
  author       = {Yang, Qinjuan and Xie, Haoran and Cheng, Gary and Wang, Fu Lee and Rao, Yanghui},
  doi          = {10.1007/s12559-021-09850-9},
  journal      = {Cognitive Computation},
  month        = {5},
  number       = {3},
  pages        = {688-697},
  shortjournal = {Cogn. Comput.},
  title        = {Pronunciation-enhanced chinese word embedding},
  volume       = {13},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Relationship identification between conversational agents
using emotion analysis. <em>CC</em>, <em>13</em>(3), 673–687. (<a
href="https://doi.org/10.1007/s12559-020-09806-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human relationships are influenced by the underlying emotions in their interactions. With the increasing use of social networks, relationships from textual data can also be inferred from online interactions. Such interactions result in massive amount of textual data which is available in the form of text messages, emails, and social media posts. Identification and analysis of human relationships are useful for numerous applications ranging from cybersecurity to public health. In this paper, we present a method called RIEA (Relationship Identification using Emotion Analysis), for identifying relationships between multiple intelligent agents by analyzing the conversation between them. The objective of our work is to combine concepts of cognitive psychology and natural language processing (NLP) to extract emotions and map them onto a set of relationships and analyze how relationships transform over time. We employ psychological models to label a large corpus of conversations and apply machine learning techniques to determine emotion-to-relationship mapping. We use four distinct association classes and four attachment styles using best-worst scaling method for classification. Combining the attachment and association styles given in research literature gives us the relationship combinations for our analysis. Additionally, this work studies the most common changes of behaviors and emotions and the corresponding transformations in human relationships. Our results show that RIEA can correctly detect interpersonal relationships with an accuracy of 85%. The evaluation shows that RIEA can accurately identify interpersonal relationships from conversations and can be extended for identifying more complex relationships. This study also highlights the effect of changes in emotional behavior in the development of relationships over time.},
  archive      = {J_CC},
  author       = {Qamar, Saira and Mujtaba, Hasan and Majeed, Hammad and Beg, Mirza Omer},
  doi          = {10.1007/s12559-020-09806-5},
  journal      = {Cognitive Computation},
  month        = {5},
  number       = {3},
  pages        = {673-687},
  shortjournal = {Cogn. Comput.},
  title        = {Relationship identification between conversational agents using emotion analysis},
  volume       = {13},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Possibility degree and power aggregation operators of
single-valued trapezoidal neutrosophic numbers and applications to
multi-criteria group decision-making. <em>CC</em>, <em>13</em>(3),
657–672. (<a href="https://doi.org/10.1007/s12559-020-09736-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Single-valued trapezoidal neutrosophic numbers (SVTNNs) are very useful tools to describe complex cognitive information because of their advantage in maintaining the completeness and accuracy of information. This paper develops a method based on the single-valued trapezoidal neutrosophic power-weighted aggregation operators and possibility degree of SVTNNs for dealing with multi-criteria group decision-making (MCGDM) problems. First, the limitations of the existing operations for SVTNNs are discussed, and then an improved operation is defined. Moreover, the possibility degree of two SVTNNs with consideration of the influence of risk attitudes is proposed, and the comparison rules for SVTNNs are thereby established. Based on the new operation and possibility degree of SVTNNs, the single-valued trapezoidal neutrosophic power average and single-valued trapezoidal neutrosophic power geometric operators are proposed to aggregate the single-valued trapezoidal neutrosophic information. Furthermore, a single-valued trapezoidal neutrosophic MCGDM method is developed. Finally, an example of a company selecting the most suitable green supplier is provided to present a comparative analysis between the proposed approach and other related methods. This example can demonstrate the effectiveness and flexibility of the proposed methodology.},
  archive      = {J_CC},
  author       = {Wang, Jing and Wang, Jian-qiang and Ma, Yin-xiang},
  doi          = {10.1007/s12559-020-09736-2},
  journal      = {Cognitive Computation},
  month        = {5},
  number       = {3},
  pages        = {657-672},
  shortjournal = {Cogn. Comput.},
  title        = {Possibility degree and power aggregation operators of single-valued trapezoidal neutrosophic numbers and applications to multi-criteria group decision-making},
  volume       = {13},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). VTAAN: Visual tracking with attentive adversarial network.
<em>CC</em>, <em>13</em>(3), 646–656. (<a
href="https://doi.org/10.1007/s12559-020-09727-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing tracking methods might suffer from the performance degradation due to insufficient positive samples. A typical network structure is proposed to enrich positive samples by generating masks during the tracking process. Although this structure has achieved good results, it ignores the drift problem that occurs when the tracked object is very similar to the surrounding objects. This problem is particularly significant when background interference exists and similar objects appear. To handle this problem, in this paper, we propose a novel attentive adversarial network for visual tracking. Inspired by human visual cognitive system, we propose to employ an attention mechanism to focus on each region differing the target object from the background. At the same time, we use a variant of the cross entropy (CE) function to deal with the class imbalance problem. Our network shows favorable performance compared with state-of-the-art methods on existing tracking benchmark datasets. We conclude that our novel attentive adversarial network not only enriches positive samples in the feature space but also prevents the similarity drift problem.},
  archive      = {J_CC},
  author       = {Wang, Futian and Wang, Xiaoping and Tang, Jin and Luo, Bin and Li, Chenglong},
  doi          = {10.1007/s12559-020-09727-3},
  journal      = {Cognitive Computation},
  month        = {5},
  number       = {3},
  pages        = {646-656},
  shortjournal = {Cogn. Comput.},
  title        = {VTAAN: Visual tracking with attentive adversarial network},
  volume       = {13},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A deep multi-task model for dialogue act classification,
intent detection and slot filling. <em>CC</em>, <em>13</em>(3), 626–645.
(<a href="https://doi.org/10.1007/s12559-020-09718-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An essential component of any dialogue system is understanding the language which is known as spoken language understanding (SLU). Dialogue act classification (DAC), intent detection (ID) and slot filling (SF) are significant aspects of every dialogue system. In this paper, we propose a deep learning-based multi-task model that can perform DAC, ID and SF tasks together. We use a deep bi-directional recurrent neural network (RNN) with long short-term memory (LSTM) and gated recurrent unit (GRU) as the frameworks in our multi-task model. We use attention on the LSTM/GRU output for DAC and ID. The attention outputs are fed to individual task-specific dense layers for DAC and ID. The output of LSTM/GRU is fed to softmax layer for slot filling as well. Experiments on three datasets, i.e. ATIS, TRAINS and FRAMES, show that our proposed multi-task model performs better than the individual models as well as all the pipeline models. The experimental results prove that our attention-based multi-task model outperforms the state-of-the-art approaches for the SLU tasks. For DAC, in relation to the individual model, we achieve an improvement of more than 2% for all the datasets. Similarly, for ID, we get an improvement of 1% on the ATIS dataset, while for TRAINS and FRAMES dataset, there is a significant improvement of more than 3% compared to individual models. We also get a 0.8% enhancement for ATIS and a 4% enhancement for TRAINS and FRAMES dataset for SF with respect to individual models. Results obtained clearly show that our approach is better than existing methods. The validation of the obtained results is also demonstrated using statistical significance t tests.},
  archive      = {J_CC},
  author       = {Firdaus, Mauajama and Golchha, Hitesh and Ekbal, Asif and Bhattacharyya, Pushpak},
  doi          = {10.1007/s12559-020-09718-4},
  journal      = {Cognitive Computation},
  month        = {5},
  number       = {3},
  pages        = {626-645},
  shortjournal = {Cogn. Comput.},
  title        = {A deep multi-task model for dialogue act classification, intent detection and slot filling},
  volume       = {13},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). SOAR improved artificial neural network for multistep
decision-making tasks. <em>CC</em>, <em>13</em>(3), 612–625. (<a
href="https://doi.org/10.1007/s12559-020-09716-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, artificial neural networks (ANNs) have been applied to various robot-related research areas due to their powerful spatial feature abstraction and temporal information prediction abilities. Decision-making has also played a fundamental role in the research area of robotics. How to improve ANNs with the characteristics of decision-making is a challenging research issue. ANNs are connectionist models, which means they are naturally weak in long-term planning, logical reasoning, and multistep decision-making. Considering that a small refinement of the inner network structures of ANNs will usually lead to exponentially growing data costs, an additional planning module seems necessary for the further improvement of ANNs, especially for small data learning. In this paper, we propose a state operator and result (SOAR) improved ANN (SANN) model, which takes advantage of both the long-term cognitive planning ability of SOAR and the powerful feature detection ability of ANNs. It mimics the cognitive mechanism of the human brain to improve the traditional ANN with an additional logical planning module. In addition, a data fusion module is constructed to combine the probability vector obtained by SOAR planning and the original data feature array. A data fusion module is constructed to convert the information from the logical sequences in SOAR to the probabilistic vector in ANNs. The proposed architecture is validated in two types of robot multistep decision-making experiments for a grasping task: a multiblock simulated experiment and a multicup experiment in a real scenario. The experimental results show the efficiency and high accuracy of our proposed architecture. The integration of SOAR and ANN is a good compromise between logical planning with small data and probabilistic classification with big data. It also has strong potential for more complicated tasks that require robust classification, long-term planning, and fast learning. Some potential applications include recognition of grasping order in multiobject environment and cooperative grasping of multiagents.},
  archive      = {J_CC},
  author       = {Zuo, Guoyu and Pan, Tingting and Zhang, Tielin and Yang, Yang},
  doi          = {10.1007/s12559-020-09716-6},
  journal      = {Cognitive Computation},
  month        = {5},
  number       = {3},
  pages        = {612-625},
  shortjournal = {Cogn. Comput.},
  title        = {SOAR improved artificial neural network for multistep decision-making tasks},
  volume       = {13},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Dense-CaptionNet: A sentence generation architecture for
fine-grained description of image semantics. <em>CC</em>,
<em>13</em>(3), 595–611. (<a
href="https://doi.org/10.1007/s12559-019-09697-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic image captioning, a highly challenging research problem, aims to understand and describe the contents of the complex scene in human understandable natural language. The majority of the recent solutions are based on holistic approaches where the scene is described as a whole, potentially losing the important semantic relationship of objects in the scene. We propose Dense-CaptionNet, a region-based deep architecture for fine-grained description of image semantics, which localizes and describes each object/region in the image separately and generates a more detailed description of the scene. The proposed network contains three components which work together to generate a fine-grained description of image semantics. Region descriptions and object relationships are generated by the first module, whereas the second one generates the attributes of objects present in the scene. The textual descriptions obtained as an output of the two modules are concatenated to feed as an input to the sentence generation module, which works on encoder-decoder formulation to generate a grammatically correct but single line, fine-grained description of the whole scene. The proposed Dense-CaptionNet is trained and tested using Visual Genome, MSCOCO, and IAPR TC-12 datasets. The results establish a new state-of-the-art when compared with the existing top performing methodologies, e.g., Up-Down-Captioner, Show, Attend and Tell, Semstyle, and Neural Talk, especially on complex scenes. The implementation has been shared on GitHub for other researchers: http://bit.ly/2VIhfrf},
  archive      = {J_CC},
  author       = {Khurram, I. and Fraz, M. M. and Shahzad, M. and Rajpoot, N. M.},
  doi          = {10.1007/s12559-019-09697-1},
  journal      = {Cognitive Computation},
  month        = {5},
  number       = {3},
  pages        = {595-611},
  shortjournal = {Cogn. Comput.},
  title        = {Dense-CaptionNet: A sentence generation architecture for fine-grained description of image semantics},
  volume       = {13},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Dense encoder-decoder–based architecture for skin lesion
segmentation. <em>CC</em>, <em>13</em>(2), 583–594. (<a
href="https://doi.org/10.1007/s12559-020-09805-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Melanoma is one kind of dangerous cancer that has been increasing rapidly in the world. Initial diagnosis is essential to survival, but often the disease is diagnosed in the fatal stage. The rapid growth of skin cancers raises a huge demand for accurate automatic skin lesion segmentation. While deep learning techniques, i.e., convolutional neural network (CNN), have been widely used for precise segmentation, the existing densely connected network (DenseNet) and residual network (ResNet)–based encoder-decoder architectures used non-biomedical features for skin lesion tasks. The complexity of tuned parameters, small information in the pre-trained features, and the lack of multi-scale information degrade the performance of skin lesion segmentation. To address these issues, we present encoder-decoder–based CNN for skin lesion segmentation, based on the widely used UNet architecture. We exploit the benefit of combining DenseNet and ResNet to improve the performance of skin lesion segmentation. In the encoder path, atrous spatial pyramid pooling (ASPP) is used to generate multi-scale features from different dilation rates. We used dense skip connection to combine the feature maps of both encoder and decoder paths. We evaluate our approach on ISIC 2018 dataset and achieve competitive performance as compared to other state-of-the-art approaches. Compared to the previous UNet approaches, our method gains a high Jaccard index, Dice, accuracy, and sensitivity. We think that this progress is mainly due to the combined architecture of DenseNet, ResNet, ASPP, and dense skip connection that preserve the contextual information in the encoder-decoder paths. We utilized the combined benefits of both recent DenseNet and ResNet architectures. We used ASPP to exploit multi-scale contextual information by adopting multiple dilation rates. We also implemented dense skip connections for better recovery of fine-grained information of target objects. In the future, we believe that this approach will be helpful to other medical image segmentation tasks.},
  archive      = {J_CC},
  author       = {Qamar, Saqib and Ahmad, Parvez and Shen, Linlin},
  doi          = {10.1007/s12559-020-09805-6},
  journal      = {Cognitive Computation},
  month        = {3},
  number       = {2},
  pages        = {583-594},
  shortjournal = {Cogn. Comput.},
  title        = {Dense encoder-Decoder–Based architecture for skin lesion segmentation},
  volume       = {13},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Using principal paths to walk through music and visual art
style spaces induced by convolutional neural networks. <em>CC</em>,
<em>13</em>(2), 570–582. (<a
href="https://doi.org/10.1007/s12559-021-09823-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Computational intelligence, particularly deep learning, offers powerful tools for discriminating and generating samples such as images. Deep learning methods have been used in different artistic contexts for neural style transfer, artistic style recognition, and musical genre recognition. Using a constrained manifold analysis protocol, we discuss to what extent spaces induced by deep-learning convolutional neural networks can capture historical/stylistic progressions in music and visual art. We use a path-finding algorithm, called principal path, to move from one point to another. We apply it to the vector space induced by convolutional neural networks. We perform experiments with visual artworks and songs, considering a subset of classes. Within this simplified scenario, we recover a reasonable historical/stylistic progression in several cases. We use the principal path algorithm to conduct an evolutionary analysis of vector spaces induced by convolutional neural networks. We perform several experiments in the visual art and music spaces. The principal path algorithm finds reasonable connections between visual artworks and songs from different styles/genres with respect to the historical evolution when a subset of classes is considered. This approach could be used in many areas to extract evolutionary information from an arbitrary high-dimensional space and deliver interesting cognitive insights.},
  archive      = {J_CC},
  author       = {Gardini, E. and Ferrarotti, M. J. and Cavalli, A. and Decherchi, S.},
  doi          = {10.1007/s12559-021-09823-y},
  journal      = {Cognitive Computation},
  month        = {3},
  number       = {2},
  pages        = {570-582},
  shortjournal = {Cogn. Comput.},
  title        = {Using principal paths to walk through music and visual art style spaces induced by convolutional neural networks},
  volume       = {13},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Graph-embedded multi-layer kernel ridge regression for
one-class classification. <em>CC</em>, <em>13</em>(2), 552–569. (<a
href="https://doi.org/10.1007/s12559-020-09804-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Humans can detect outliers just by using only observations of normal samples. Similarly, one-class classification (OCC) uses only normal samples to train a classification model which can be used for outlier detection. This paper proposes a multi-layer architecture for OCC by stacking various graph-embedded kernel ridge regression (KRR)-based autoencoders in a hierarchical fashion. We formulate the autoencoders under the graph-embedding framework to exploit local and global variance criteria. The use of multiple autoencoder layers allows us to project the input features into a new feature space on which we apply a graph-embedded regression-based one-class classifier. We build the proposed hierarchical OCC architecture in a progressive manner and optimize the parameters of each of the successive layers based on closed-form solutions. The performance of the proposed method is evaluated on 21 balanced and 20 imbalanced datasets. The effectiveness of the proposed method is indicated by the experimental results over 11 existing state-of-the-art kernel-based one-class classifiers. Friedman test is also performed to verify the statistical significance of the obtained results. By using two types of graph-embedding, 4 variants of graph-embedded multi-layer KRR-based one-class classification methods are presented in this paper. All 4 variants have performed better than the existing one-class classifiers in terms of the various performance metrics. Hence, they can be a viable alternative for OCC for a wide range of one-class classification tasks. As a future extension, various other autoencoder variants can be applied within the proposed architecture to increase efficiency and performance.},
  archive      = {J_CC},
  author       = {Gautam, Chandan and Tiwari, Aruna and Mishra, Pratik K. and Suresh, Sundaram and Iosifidis, Alexandros and Tanveer, M.},
  doi          = {10.1007/s12559-020-09804-7},
  journal      = {Cognitive Computation},
  month        = {3},
  number       = {2},
  pages        = {552-569},
  shortjournal = {Cogn. Comput.},
  title        = {Graph-embedded multi-layer kernel ridge regression for one-class classification},
  volume       = {13},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). GSNet: Group sequential learning for image recognition.
<em>CC</em>, <em>13</em>(2), 538–551. (<a
href="https://doi.org/10.1007/s12559-020-09815-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, deep learning has achieved great successes in the field of image cognitive learning, and designing a well-behaved convolutional neural network (CNN)-based architecture has become a challenging and important problem. The traditional group convolution cannot effectively address the severe problem of “information blocking”; hence, this work proposes an efficient CNN-based model to achieve an effective exchange of information between channels. A novel Group Sequential (GS) learning that uses a channel split operation and sequential learning methods is introduced to improve the recognition performance by increasing information communication. Several state-of-the-art models are developed based on GS blocks, and these blocks significantly boost the performance and robustness of the CNN-based models. Extensive experiments are carried out to evaluate the promising performance of the proposed GSNet framework, and experimental results show its superiority on several benchmarks (i.e., the CIFAR-10, CIFAR-100, Tiny ImageNet, ImageNet, and FOOD-101 dataset). Moreover, compared with traditional residual networks (e.g., ResNet-101), the proposed network has achieved a great improvement with fewer parameters, and the error rate of models on the FOOD-101 dataset decreases from 19.08 to 16.02%. The proposed GS block method has significant potential to improve the performance for image recognition, and advance the development of cognitive computation. The results demonstrate the superiority of the proposed method and indicate excellent generalization ability. Code is available at: https://github.com/shao15xiang/GSNet .},
  archive      = {J_CC},
  author       = {Xiang, Shao and Liang, Qiaokang and Sun, Wei and Zhang, Dan and Wang, Yaonan},
  doi          = {10.1007/s12559-020-09815-4},
  journal      = {Cognitive Computation},
  month        = {3},
  number       = {2},
  pages        = {538-551},
  shortjournal = {Cogn. Comput.},
  title        = {GSNet: Group sequential learning for image recognition},
  volume       = {13},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Detection of sociolinguistic features in digital social
networks for the detection of communities. <em>CC</em>, <em>13</em>(2),
518–537. (<a href="https://doi.org/10.1007/s12559-021-09818-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The emergence of digital social networks has transformed society, social groups, and institutions in terms of the communication and expression of their opinions. Determining how language variations allow the detection of communities, together with the relevance of specific vocabulary (proposed by the National Council of Accreditation of Colombia (Consejo Nacional de Acreditación - CNA) to determine the quality evaluation parameters for universities in Colombia) in digital assemblages could lead to a better understanding of their dynamics and social foundations, thus resulting in better communication policies and intervention where necessary. The approach presented in this paper intends to determine what are the semantic spaces (sociolinguistic features) shared by social groups in digital social networks. It includes five layers based on Design Science Research, which are integrated with Natural Language Processing techniques (NLP), Computational Linguistics (CL), and Artificial Intelligence (AI). The approach is validated through a case study wherein the semantic values of a series of “Twitter” institutional accounts belonging to Colombian Universities are analyzed in terms of the 12 quality factors established by CNA. In addition, the topics and the sociolect used by different actors in the university communities are also analyzed. The current approach allows determining the sociolinguistic features of social groups in digital social networks. Its application allows detecting the words or concepts to which each actor of a social group (university) gives more importance in terms of vocabulary.},
  archive      = {J_CC},
  author       = {Puertas, Edwin and Moreno-Sandoval, Luis Gabriel and Redondo, Javier and Alvarado-Valencia, Jorge Andres and Pomares-Quimbaya, Alexandra},
  doi          = {10.1007/s12559-021-09818-9},
  journal      = {Cognitive Computation},
  month        = {3},
  number       = {2},
  pages        = {518-537},
  shortjournal = {Cogn. Comput.},
  title        = {Detection of sociolinguistic features in digital social networks for the detection of communities},
  volume       = {13},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Co-adjustment learning for co-clustering. <em>CC</em>,
<em>13</em>(2), 504–517. (<a
href="https://doi.org/10.1007/s12559-021-09827-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Co-clustering simultaneously performs clustering on the sample and feature dimensions of the data matrix, so it can obtain better insight into the data than traditional clustering. Adjustment learning extracts valuable information from chunklets for unsupervised cluster learning in specific scenarios, but in fact it can be easily extended to semi-supervised and supervised learning situations. In this paper, we propose a novel co-clustering framework, named co-adjustment learning for co-clustering (CALCC), and CALCC can be simultaneously used in unsupervised, semi-supervised and supervised learning situations. A novel co-adjustment learning (CAL) model is proposed to extract meaningful representations in both sample space and feature space for co-clustering. CAL can not only perform the sample projection as well as feature projection under the guidance of chunklet information, it can also transform the original data into another space with improved separability. We can obtain the row partition matrix and column partition matrix by performing the clustering process on the representations learned by the CAL model. In order to prove the availability of our framework, an unsupervised case of CALCC is introduced to make an extensive comparison with several related methods (specifically including the classic co-clustering methods and the state-of-the-art methods closely related to our work) on several image and real data sets. The experimental results show the superior performance of the CAL model in discovering discriminative representations and demonstrate the effectiveness of the CALCC framework. The proposed CALCC framework, as demonstrated in the experiments, is more effective superior to the related methods. In addition, the chunklet information can be effective to enhance the expression ability of the learned representations.},
  archive      = {J_CC},
  author       = {Zhang, Ji and Wang, Hongjun and Huang, Shudong and Li, Tianrun and Jin, Peng and Deng, Ping and Zhao, Qigang},
  doi          = {10.1007/s12559-021-09827-8},
  journal      = {Cognitive Computation},
  month        = {3},
  number       = {2},
  pages        = {504-517},
  shortjournal = {Cogn. Comput.},
  title        = {Co-adjustment learning for co-clustering},
  volume       = {13},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Sigma-lognormal modeling of speech. <em>CC</em>,
<em>13</em>(2), 488–503. (<a
href="https://doi.org/10.1007/s12559-020-09803-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human movement studies and analyses have been fundamental in many scientific domains, ranging from neuroscience to education, pattern recognition to robotics, health care to sports, and beyond. Previous speech motor models were proposed to understand how speech movement is produced and how the resulting speech varies when some parameters are changed. However, the inverse approach, in which the muscular response parameters and the subject’s age are derived from real continuous speech, is not possible with such models. Instead, in the handwriting field, the kinematic theory of rapid human movements and its associated Sigma-lognormal model have been applied successfully to obtain the muscular response parameters. This work presents a speech kinematics-based model that can be used to study, analyze, and reconstruct complex speech kinematics in a simplified manner. A method based on the kinematic theory of rapid human movements and its associated Sigma-lognormal model are applied to describe and to parameterize the asymptotic impulse response of the neuromuscular networks involved in speech as a response to a neuromotor command. The method used to carry out transformations from formants to a movement observation is also presented. Experiments carried out with the (English) VTR-TIMIT database and the (German) Saarbrucken Voice Database, including people of different ages, with and without laryngeal pathologies, corroborate the link between the extracted parameters and aging, on the one hand, and the proportion between the first and second formants required in applying the kinematic theory of rapid human movements, on the other. The results should drive innovative developments in the modeling and understanding of speech kinematics.},
  archive      = {J_CC},
  author       = {Carmona-Duarte, C. and Ferrer, M. A. and Plamondon, R. and Gómez-Rodellar, A. and Gómez-Vilda, P.},
  doi          = {10.1007/s12559-020-09803-8},
  journal      = {Cognitive Computation},
  month        = {3},
  number       = {2},
  pages        = {488-503},
  shortjournal = {Cogn. Comput.},
  title        = {Sigma-lognormal modeling of speech},
  volume       = {13},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Deep learning forecasting in cryptocurrency high-frequency
trading. <em>CC</em>, <em>13</em>(2), 485–487. (<a
href="https://doi.org/10.1007/s12559-021-09841-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Like common stocks, Bitcoin price fluctuations are non-stationary and highly noisy. Due to attractiveness of Bitcoin in terms of returns and risk, Bitcoin price prediction is attracting a growing attention from both investors and researchers. Indeed, with the development of machine learning and especially deep learning, forecasting Bitcoin is receiving a particular interest. We implement and apply deep forward neural network (DFFNN) for the analysis and forecasting Bitcoin high-frequency price data. Importantly, we seek to investigate the effect of standard numerical training algorithms on the accuracy obtained by DFFNN; namely, the conjugate gradient with Powell-Beale restarts, the resilient algorithm, and Levenberg-Marquardt algorithm. The DFFNN was applied to a big dataset composed of 65,535 samples. In terms of root mean of squared errors (RMSEs), the simulation results show that the DFFNN trained with the Levenberg-Marquardt algorithm outperforms DFFNN trained with Powell-Beale restarts algorithm and DFFNN trained with resilient algorithm. In addition, the resilient algorithm is fast which suggests that it could be promising in online training and trading. The DFFNN trained with Levenberg-Marquardt algorithm is effective and easy to implement for Bitcoin high-frequency price data forecasting.},
  archive      = {J_CC},
  author       = {Lahmiri, Salim and Bekiros, Stelios},
  doi          = {10.1007/s12559-021-09841-w},
  journal      = {Cognitive Computation},
  month        = {3},
  number       = {2},
  pages        = {485-487},
  shortjournal = {Cogn. Comput.},
  title        = {Deep learning forecasting in cryptocurrency high-frequency trading},
  volume       = {13},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Pythagorean fuzzy multi-criteria decision making method
based on multiparametric similarity measure. <em>CC</em>,
<em>13</em>(2), 466–484. (<a
href="https://doi.org/10.1007/s12559-020-09781-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Big data industry decision is supremely important for companies to boost the efficiency of leadership, which can vastly accelerate industrialized. With regard to big data industry decision assessment, the intrinsic problem involves enormous inexactness, fuzziness and ambiguity. Pythagorean fuzzy sets (PFSs), managing the uncertainness depicted in non-membership with membership, are a quite practical way to capture uncertainness. Firstly, the innovative Pythagorean fuzzy score function is given to dispose the comparison issue. Innovative distance measure and similarity measure for PFSs with three parameters are explored, along with corresponding proofs therewith. Later, objective weight is ascertained by deviation-based method. Also, combined weight is skillfully designed, which can tellingly imply both subjective preference and objective preference. In addition, an approach to settle Pythagorean fuzzy problem by multiparametric similarity measure is presented. The efficacy of developed algorithm is elaborated by a big data industry decision issue. Moreover, a comparison of the introduced algorithm with the selected existing methods has been built on the basis of the division by zero issue and counterintuitive phenomena for displaying its effectiveness.},
  archive      = {J_CC},
  author       = {Peng, Xindong and Yuan, Huiyong},
  doi          = {10.1007/s12559-020-09781-x},
  journal      = {Cognitive Computation},
  month        = {3},
  number       = {2},
  pages        = {466-484},
  shortjournal = {Cogn. Comput.},
  title        = {Pythagorean fuzzy multi-criteria decision making method based on multiparametric similarity measure},
  volume       = {13},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Novel similarity measure based on the transformed
right-angled triangles between intuitionistic fuzzy sets and its
applications. <em>CC</em>, <em>13</em>(2), 447–465. (<a
href="https://doi.org/10.1007/s12559-020-09809-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intuitionistic fuzzy set (IFS) is one of the most robust and trustworthy tools for portraying the imprecise information with the help of the membership degrees. Similarity measure, one of the information measures, plays an important role in treating imperfect and ambiguous information to reach the final decision by determining the degree of similarity between the pairs of the numbers. Motivated by these, this paper aims to present a novel distance/ similarity among the IFSs based on the transformation techniques with their characteristics. To explore the study, the given IFSs are transformed into the right-angled triangle over a unit square area, and hence based on the intersection of the triangles, novel distance and similarity measures are proposed. An algorithm to solve the decision-making problems with the proposed similarity measure is developed and implemented to execute their performance over the numerous examples such as pattern recognition and clustering analysis. The reliability of the developed measure is investigated by applying it in clustering and the pattern recognition problems and their results are compared with some prevailing studies. From the investigation, we conclude that several existing measures fail to give classification results under the different instances such as “division by zero problems” or “counter-intuitive cases” while the proposed measure successfully overcomes this drawback.},
  archive      = {J_CC},
  author       = {Garg, Harish and Rani, Dimple},
  doi          = {10.1007/s12559-020-09809-2},
  journal      = {Cognitive Computation},
  month        = {3},
  number       = {2},
  pages        = {447-465},
  shortjournal = {Cogn. Comput.},
  title        = {Novel similarity measure based on the transformed right-angled triangles between intuitionistic fuzzy sets and its applications},
  volume       = {13},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Assessing mobile and smart technology applications for
active and healthy aging using a fuzzy collaborative intelligence
approach. <em>CC</em>, <em>13</em>(2), 431–446. (<a
href="https://doi.org/10.1007/s12559-020-09810-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Active and healthy living is critical in an aging society. Mobile and smart technology applications can assist in achieving this goal of healthy living. However, selecting a suitable and smart technology application for active and healthy living is difficult. To address this difficulty, a fuzzy collaborative intelligence (FCI) approach was proposed in this study to assess the suitability of a mobile and smart technology application. The FCI approach is a posterior-aggregation fuzzy analytic hierarchy process approach that combines the fuzzy inverse of column sum, partial-consensus fuzzy intersection, and fuzzy technique for order preference by similarity to the ideal solution. The FCI approach starts from the prioritization of critical factors using the fuzzy inverse of column sum by each expert. Subsequently, partial-consensus fuzzy intersection is applied to aggregate the priorities derived by all experts. Based on the aggregation result, each mobile and smart technology application for active and healthy aging is assessed using fuzzy technique for order preference by similarity to the ideal solution. The FCI approach was applied to assess five existing mobile and smart technology applications, with various aspects of life as parameters. According to experimental results, the most and least suitable mobile technology applications were smart canes and online food ordering and delivery platforms, respectively. This is because the current elderly population is not very familiar with smartphone applications. This problem will be solved over time when the current middle-age population becomes old. In addition, the ranking result obtained using the proposed methodology was considerably different from those using several existing methods. The aging of population is a natural phenomenon. The results of this study are helpful to creating an environment that is friendly and assists elderly people to age actively and healthily.},
  archive      = {J_CC},
  author       = {Chiu, Min-Chi and Chen, Toly},
  doi          = {10.1007/s12559-020-09810-9},
  journal      = {Cognitive Computation},
  month        = {3},
  number       = {2},
  pages        = {431-446},
  shortjournal = {Cogn. Comput.},
  title        = {Assessing mobile and smart technology applications for active and healthy aging using a fuzzy collaborative intelligence approach},
  volume       = {13},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). ML-CGAN: Conditional generative adversarial network with a
meta-learner structure for high-quality image generation with few
training data. <em>CC</em>, <em>13</em>(2), 418–430. (<a
href="https://doi.org/10.1007/s12559-020-09796-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Since generative adversarial network (GAN) can learn data distribution and generate new samples based on the learned data distribution, it has become a research hotspot in the area of deep learning and cognitive computation. The learning of GAN heavily depends on a large set of training data. However, in many real-world applications, it is difficult to acquire a large number of data as needed.  In this paper, we propose a novel generative adversarial network called ML-CGAN for generating authentic and diverse images with few training data. Particularly, ML-CGAN consists of two modules: the conditional generative adversarial network (CGAN) backbone and the meta-learner structure. The CGAN backbone is applied to generate images, while the meta-learner structure is an auxiliary network to provide deconvolutional weights for the generator of the CGAN backbone.  Qualitative and quantitative experimental results on the MNIST, Fashion MNIST, CelebA and CIFAR-10 data sets demonstrate the superiority of ML-CGAN over state-of-the-art models. Specifically, the results show that the meta-learner structure can learn prior knowledge and transfer it to the new tasks, which is beneficial for generating authentic and diverse images in the new tasks with few training data.},
  archive      = {J_CC},
  author       = {Ma, Ying and Zhong, Guoqiang and Liu, Wen and Wang, Yanan and Jiang, Peng and Zhang, Rui},
  doi          = {10.1007/s12559-020-09796-4},
  journal      = {Cognitive Computation},
  month        = {3},
  number       = {2},
  pages        = {418-430},
  shortjournal = {Cogn. Comput.},
  title        = {ML-CGAN: Conditional generative adversarial network with a meta-learner structure for high-quality image generation with few training data},
  volume       = {13},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Recognition of emotional states from EEG signals with
nonlinear regularity- and predictability-based entropy metrics.
<em>CC</em>, <em>13</em>(2), 403–417. (<a
href="https://doi.org/10.1007/s12559-020-09789-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, the recognition of emotions with electroencephalographic (EEG) signals has received increasing attention. Furthermore, the nonstationarity of brain has intensified the application of nonlinear methods. Nonetheless, metrics like quadratic sample entropy (QSE), amplitude-aware permutation entropy (AAPE) and permutation min-entropy (PME) have never been applied to discern between more than two emotions. Therefore, this study computes for the first time QSE, AAPE and PME for recognition of four groups of emotions. After preprocessing the EEG recordings, the three entropy metrics were computed. Then, a tenfold classification approach based on a sequential forward selection scheme and a support vector machine classifier was implemented. This procedure was applied in a multi-class scheme including the four groups of study simultaneously, and in a binary-class approach for discerning emotions two by two, regarding their levels of arousal and valence. For both schemes, QSE+AAPE and QSE+PME were combined. In both multi-class and binary-class schemes, the best results were obtained in frontal and parietal brain areas. Furthermore, in most of the cases channels from QSE and AAPE/PME were selected in the classification models, thus highlighting the complementarity between those different types of entropy indices and achieving global accuracy results higher than 90% in multi-class and binary-class schemes. The combination of regularity- and predictability-based entropy indices denoted a high degree of complementarity between those nonlinear methods. Finally, the relevance of frontal and parietal areas for recognition of emotions has revealed the essential role of those brain regions in emotional processes.},
  archive      = {J_CC},
  author       = {García-Martínez, Beatriz and Fernández-Caballero, Antonio and Zunino, Luciano and Martínez-Rodrigo, Arturo},
  doi          = {10.1007/s12559-020-09789-3},
  journal      = {Cognitive Computation},
  month        = {3},
  number       = {2},
  pages        = {403-417},
  shortjournal = {Cogn. Comput.},
  title        = {Recognition of emotional states from EEG signals with nonlinear regularity- and predictability-based entropy metrics},
  volume       = {13},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). State primitive learning to overcome catastrophic forgetting
in robotics. <em>CC</em>, <em>13</em>(2), 394–402. (<a
href="https://doi.org/10.1007/s12559-020-09784-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {People can learn continuously a wide range of tasks without catastrophic forgetting. To mimic this functioning of continual learning, current methods mainly focus on studying a one-step supervised learning problem, e.g., image classification. They aim to retain the performance of previous image classification results when neural networks are sequentially trained on new images. In this paper, we concentrate on solving multi-step robotic tasks sequentially with the proposed architecture called state primitive learning. By projecting the original state space into a low-dimensional representation, meaningful state primitives can be generated to describe tasks. Under two kinds of different constraints on the generation of state primitives, control signals corresponding to different robotic tasks can be separately addressed only with an efficient linear regression. Experiments on several robotic manipulation tasks demonstrate the new method efficacy to learn control signals under the scenario of continual learning, delivering substantially improved performance over the other comparison methods.},
  archive      = {J_CC},
  author       = {Xiong, Fangzhou and Liu, Zhiyong and Huang, Kaizhu and Yang, Xu and Qiao, Hong},
  doi          = {10.1007/s12559-020-09784-8},
  journal      = {Cognitive Computation},
  month        = {3},
  number       = {2},
  pages        = {394-402},
  shortjournal = {Cogn. Comput.},
  title        = {State primitive learning to overcome catastrophic forgetting in robotics},
  volume       = {13},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Brain-inspired active learning architecture for procedural
knowledge understanding based on human-robot interaction. <em>CC</em>,
<em>13</em>(2), 381–393. (<a
href="https://doi.org/10.1007/s12559-020-09753-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Improving robots with self-learning ability is one of the critical challenges for the researchers in the area of cognitive robotics and artificial general intelligence. This robot will decide when, where, and what to learn in a continuous visual environment by itself. Here we focus on the procedural knowledge learning, which is sequential and considered harder to understand compared with declarative knowledge in the cognitive system. Inspired by the architecture of the human brain which has integrated well different kinds of cognitive functions, a Brain-inspired Active Learning Architecture (BALA) is proposed for procedural knowledge understanding based on Baxter robot and human interaction. The BALA model contains four main parts: inspired by Primary Visual Pathway, a Convolutional Neural Network (CNN) is constructed for spatial information abstraction; inspired by the Hippocampus Pathway (especially the recurrent loops in CA3 sub-region), a Recurrent Neural Network (RNN) is built for sequential information processing related with procedural knowledge; inspired by the Prefrontal Cortex, a Knowledge Graph based on Bag Of Words (BOW) is constructed for declarative knowledge generation and association; inspired by the Basal Ganglia Pathway, we select Q matrix for Reinforcement Learning (RL). The CNN and RNN parts will be firstly pre-trained on ImageNet dataset and standard Youtube Video-Scene dataset respectively. Then, the RNN, Knowledge Graph, and Q matrix will be dynamically updated in the Baxter robot’s interactive learning procedure with human cooperators. The BALA could actively and incrementally recognize different kinds of procedural knowledge. In 22-type daily-life videos with procedure knowledge (e.g., opening the door, wiping the table, or taking the phone), the BALA model gets the best performance compared with standard CNN, RNN, RL, and other integrative methods. The BALA model is a small step on integrative intelligence interaction between the Baxter robot and human cooperator.},
  archive      = {J_CC},
  author       = {Zhang, Tielin and Zeng, Yi and Pan, Ruihan and Shi, Mengting and Lu, Enmeng},
  doi          = {10.1007/s12559-020-09753-1},
  journal      = {Cognitive Computation},
  month        = {3},
  number       = {2},
  pages        = {381-393},
  shortjournal = {Cogn. Comput.},
  title        = {Brain-inspired active learning architecture for procedural knowledge understanding based on human-robot interaction},
  volume       = {13},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A cognitive information-based decision-making algorithm
using interval-valued q-rung picture fuzzy numbers and heronian mean
operators. <em>CC</em>, <em>13</em>(2), 357–380. (<a
href="https://doi.org/10.1007/s12559-020-09811-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The complexity of the socioeconomic environment means that it is challenging to make decisions that rely on cognitive information. Decision makers normally cannot obtain a precise or sufficient level of knowledge about the problem domain and hence must provide multiple answers with interval values to depict them. This makes cognizing and decision making very difficult. To address this issue, this paper proposes a novel cognitive information-based decision-making algorithm with interval-valued q-rung picture fuzzy (IVq-RPtF) numbers. We first define the concept of the IVq-RPtF set, including the basic definition, operational laws, a score function, and an accuracy function. Considering the interrelationship between attributes, we then present the IVq-RPtF Heronian mean (IVq-RPtFHM) operators using the new operational laws. Moreover, we discuss the properties of IVq-RPtFHM operators, such as monotonicity, commutativity, and idempotency. Finally, we use a numerical example to verify the viability of the proposed method. The results show that the proposed method effectively expresses multiple types of interval cognitive information. The sensitivity analysis of the parameters shows that the ranking results are susceptible to parameter changes, but regardless of how the parameters change, the score values of the four alternatives in our example are in the range of [1.27, 1.66], within the basic scoring range of [1.352–1.472] for the four alternatives. Therefore, our proposed method based on IVq-RPtFHM operators has a stronger information aggregation ability than other methods. Compared with other methods, the proposed cognitive information-based decision-making algorithm is more widely applicable, avoids loss of cognitive information, and conducts a reasonable decision-making process.},
  archive      = {J_CC},
  author       = {Yang, Zaoli and Li, Xin and Garg, Harish and Qi, Meng},
  doi          = {10.1007/s12559-020-09811-8},
  journal      = {Cognitive Computation},
  month        = {3},
  number       = {2},
  pages        = {357-380},
  shortjournal = {Cogn. Comput.},
  title        = {A cognitive information-based decision-making algorithm using interval-valued q-rung picture fuzzy numbers and heronian mean operators},
  volume       = {13},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Bifurcation properties for fractional order delayed BAM
neural networks. <em>CC</em>, <em>13</em>(2), 322–356. (<a
href="https://doi.org/10.1007/s12559-020-09782-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the past several decades, many papers involving the stability and Hopf bifurcation of delayed neural networks have been published. However, the results on the stability and Hopf bifurcation for fractional order neural networks with delays and fractional order neural networks with leakage delays are very rare. This paper is concerned with the stability and the existence of Hopf bifurcation of fractional order BAM neural networks with or without leakage delay. The Laplace transform, stability and bifurcation theory of fractional-order differential equations and Matlab software will be applied. The stability condition and the sufficient criterion of existence of Hopf bifurcation for fractional order BAM neural networks with delay (leakage delay) are established. It is found that when the sum of two delays (leakage delay) crosses a critical value, then a Hopf bifurcation will appear. The obtained results play an important role in designing neural networks. Also the derived results are new and enrich the bifurcation theory of fractional order delayed differential equations.},
  archive      = {J_CC},
  author       = {Xu, Changjin and Liao, Maoxin and Li, Peiluan and Guo, Ying and Liu, Zixin},
  doi          = {10.1007/s12559-020-09782-w},
  journal      = {Cognitive Computation},
  month        = {3},
  number       = {2},
  pages        = {322-356},
  shortjournal = {Cogn. Comput.},
  title        = {Bifurcation properties for fractional order delayed BAM neural networks},
  volume       = {13},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Analyzing social robotics research with natural language
processing techniques. <em>CC</em>, <em>13</em>(2), 308–321. (<a
href="https://doi.org/10.1007/s12559-020-09799-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The fast growth of social robotics (SR) has not been unidirectional, but rather towards a multidisciplinary scenario, creating a need for collaboration between different fields. This divergent expansion calls for a clear analysis of the field aimed at better orienting the research, thus paving the future of social robotics. This paper aims at understanding how the SR research field evolved in the last two decades by analyzing academic publications in SR and human–robot interaction using natural language processing (NLP) techniques. The analysis spotted an overlap between SR and human–robot interaction research fields that have been disambiguated using a data-driven approach that leads to the identification of a new group of papers we clustered under the concept of “soft HRI.” This research topic has been analyzed by extracting trends and insights. Finally, another topic modelling step has been applied to identify seven sub-topics that have been discussed and analyzed picturing the current state of the art of SR. The paper reports a complete overview of the SR research field identifying various topics and sub-topics helping researchers in understanding the evolution of this field, thus supporting the strategic placing and evolution of their research activities.},
  archive      = {J_CC},
  author       = {Mazzei, Daniele and Chiarello, Filippo and Fantoni, Gualtiero},
  doi          = {10.1007/s12559-020-09799-1},
  journal      = {Cognitive Computation},
  month        = {3},
  number       = {2},
  pages        = {308-321},
  shortjournal = {Cogn. Comput.},
  title        = {Analyzing social robotics research with natural language processing techniques},
  volume       = {13},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Non-linear domain adaptation in transfer evolutionary
optimization. <em>CC</em>, <em>13</em>(2), 290–307. (<a
href="https://doi.org/10.1007/s12559-020-09777-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The cognitive ability to learn with experience is a hallmark of intelligent systems. The emerging transfer optimization paradigm pursues such human-like problem-solving prowess by leveraging useful information from various source tasks to enhance optimization efficiency on a related target task. The occurrence of harmful negative transfer is a key concern in this setting, paving the way for recent probabilistic model-based transfer evolutionary algorithms that curb this phenomenon. However, in applications where the source and target domains, i.e., the features of their respective search spaces (e.g., dimensionality) and the distribution of good solutions in those spaces, do not match, narrow focus on curbing negative effects can lead to the conservative cancellation of knowledge transfer. Taking this cue, this paper presents a novel perspective on domain adaptation in the context of evolutionary optimization, inducing positive transfers even in scenarios of source-target domain mismatch. Our first contribution is to establish a probabilistic formulation of domain adaptation, by which source and/or target tasks can be mapped to a common solution representation space in which their discrepancy is reduced. Secondly, a domain adaptive transfer evolutionary algorithm is proposed, supporting both offline construction and online data-driven learning of non-linear mapping functions. The performance of the algorithm is experimentally verified, demonstrating superior convergence rate in comparison to state-of-the-art baselines on synthetic benchmarks and a practical case study in multi-location inventory planning. Our results thus shed light on a new research direction for optimization algorithms that improve their efficacy by learning from heterogeneous experiential priors.},
  archive      = {J_CC},
  author       = {Lim, Ray and Gupta, Abhishek and Ong, Yew-Soon and Feng, Liang and Zhang, Allan N.},
  doi          = {10.1007/s12559-020-09777-7},
  journal      = {Cognitive Computation},
  month        = {3},
  number       = {2},
  pages        = {290-307},
  shortjournal = {Cogn. Comput.},
  title        = {Non-linear domain adaptation in transfer evolutionary optimization},
  volume       = {13},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Emotion aided dialogue act classification for
task-independent conversations in a multi-modal framework. <em>CC</em>,
<em>13</em>(2), 277–289. (<a
href="https://doi.org/10.1007/s12559-019-09704-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dialogue act classification (DAC) gives a significant insight into understanding the communicative intention of the user. Numerous machine learning (ML) and deep learning (DL) approaches have been proposed over the years in these regards for task-oriented/independent conversations in the form of texts. However, the affect of emotional state in determining the dialogue acts (DAs) has not been studied in depth in a multi-modal framework involving text, audio, and visual features. Conversations are intrinsically determined and regulated by direct, exquisite, and subtle emotions. The emotional state of a speaker has a considerable affect on its intentional or its pragmatic content. This paper thoroughly investigates the role of emotions in automatic identification of the DAs in task-independent conversations in a multi-modal framework (specifically audio and texts). A DL-based multi-tasking network for DAC and emotion recognition (ER) has been developed incorporating attention to facilitate the fusion of different modalities. An open source, benchmarked ER multi-modal dataset IEMOCAP has been manually annotated for its corresponding DAs to make it suitable for multi-task learning and further advance the research in multi-modal DAC. The proposed multi-task framework attains an improvement of 2.5% against its single-task DAC counterpart for manually annotated IEMOCAP dataset. Results as compared with several baselines establish the efficacy of the proposed approach and the importance of incorporating emotion while identifying the DAs.},
  archive      = {J_CC},
  author       = {Saha, Tulika and Gupta, Dhawal and Saha, Sriparna and Bhattacharyya, Pushpak},
  doi          = {10.1007/s12559-019-09704-5},
  journal      = {Cognitive Computation},
  month        = {3},
  number       = {2},
  pages        = {277-289},
  shortjournal = {Cogn. Comput.},
  title        = {Emotion aided dialogue act classification for task-independent conversations in a multi-modal framework},
  volume       = {13},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Emoji helps! A multi-modal siamese architecture for tweet
user verification. <em>CC</em>, <em>13</em>(2), 261–276. (<a
href="https://doi.org/10.1007/s12559-020-09715-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the current paper, we have proposed a new multi-modal authorship verification approach for social media texts. Authorship verification is a task of verifying whether an unknown text is written by a suspect or not. Use of social media like Facebook and Twitter is increasing day by day because of digitization. People have grown accustomed to regularly post or tweet about their everyday life, memorable incidences, random thoughts, opinions, and much more. Emojis are widely used in these tweets and posts. The writing style of a user can differ from others, since word choices, sentence structures, usage of punctuation symbols, and use of emoji can be different. We have applied a multi-modal Siamese-based framework for automatic extraction of features from the given texts and emojis. After the extraction of features, the extracted features are applied to a neural network–based architecture for binary classification. A multi-modal Twitter-based dataset is created for evaluating the performance of the proposed framework. We obtained an average accuracy of 61.56% with 78.08%, 61.50%, and 58.32% precision, recall, and f-measure values, respectively.},
  archive      = {J_CC},
  author       = {Suman, Chanchal and Saha, Sriparna and Bhattacharyya, Pushpak and Chaudhari, Rohit Shyamkant},
  doi          = {10.1007/s12559-020-09715-7},
  journal      = {Cognitive Computation},
  month        = {3},
  number       = {2},
  pages        = {261-276},
  shortjournal = {Cogn. Comput.},
  title        = {Emoji helps! a multi-modal siamese architecture for tweet user verification},
  volume       = {13},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Analyzing connections between user attributes, images, and
text. <em>CC</em>, <em>13</em>(2), 241–260. (<a
href="https://doi.org/10.1007/s12559-019-09695-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work explores the relationship between a person’s demographic/psychological traits (e.g., gender and personality) and self-identity images and captions. We use a dataset of images and captions provided by N ≈ 1350 individuals, and we automatically extract features from both the images and captions. We identify several visual and textual properties that show reliable relationships with individual differences between participants. The automated techniques presented here allow us to draw interesting conclusions from our data that would be difficult to identify manually, and these techniques are extensible to other large datasets. Additionally, we consider the task of predicting gender and personality using both single modality features and multimodal features. We show that a multimodal predictive approach outperforms purely visual methods and purely textual methods. We believe that our work on the relationship between user characteristics and user data has relevance in online settings, where users upload billions of images each day.},
  archive      = {J_CC},
  author       = {Burdick, Laura and Mihalcea, Rada and Boyd, Ryan L. and Pennebaker, James W.},
  doi          = {10.1007/s12559-019-09695-3},
  journal      = {Cognitive Computation},
  month        = {3},
  number       = {2},
  pages        = {241-260},
  shortjournal = {Cogn. Comput.},
  title        = {Analyzing connections between user attributes, images, and text},
  volume       = {13},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Exploring perception uncertainty for emotion recognition in
dyadic conversation and music listening. <em>CC</em>, <em>13</em>(2),
231–240. (<a href="https://doi.org/10.1007/s12559-019-09694-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predicting emotions automatically is an active field of research in affective computing. Considering the property of the individual’s subjectivity, the label of an emotional instance is usually created based on opinions from multiple annotators. That is, the labelled instance is often accompanied with the corresponding inter-rater disagreement information, which we call here the perception uncertainty. Such uncertainty information, as shown in previous studies, can provide supplementary information for better recognition performance in such a subjective task. In this paper, we propose a multi-task learning framework to leverage the knowledge of perception uncertainty to ameliorate the prediction performance. In particular, in our novel framework, the perception uncertainty is exploited in an explicit manner to manipulate an initial prediction dynamically, in contrast to merely estimating the emotional state and perception uncertainty simultaneously, as done in a conventional multi-task learning framework. To evaluate the feasibility and effectiveness of the proposed method, we perform extensive experiments for time- and value-continuous emotion predictions in audiovisual conversation and music listening scenarios. Compared with other state-of-the-art approaches, our approach yields remarkable performance improvements in both datasets. The obtained results indicate that integrating the perception uncertainty information can enhance the learning process.},
  archive      = {J_CC},
  author       = {Han, Jing and Zhang, Zixing and Ren, Zhao and Schuller, Björn},
  doi          = {10.1007/s12559-019-09694-4},
  journal      = {Cognitive Computation},
  month        = {3},
  number       = {2},
  pages        = {231-240},
  shortjournal = {Cogn. Comput.},
  title        = {Exploring perception uncertainty for emotion recognition in dyadic conversation and music listening},
  volume       = {13},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Affect recognition for multimodal natural language
processing. <em>CC</em>, <em>13</em>(2), 229–230. (<a
href="https://doi.org/10.1007/s12559-020-09738-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_CC},
  author       = {Poria, Soujanya and Soon, Ong Yew and Liu, Bing and Bing, Lidong},
  doi          = {10.1007/s12559-020-09738-0},
  journal      = {Cognitive Computation},
  month        = {3},
  number       = {2},
  pages        = {229-230},
  shortjournal = {Cogn. Comput.},
  title        = {Affect recognition for multimodal natural language processing},
  volume       = {13},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A mechanistic account of stress-induced performance
degradation. <em>CC</em>, <em>13</em>(1), 207–227. (<a
href="https://doi.org/10.1007/s12559-020-09725-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stress-induced performance degradation in high-pressure situations has been documented empirically and generated different explanations. The existing theories often assume the distinction between implicit and explicit processing but speculate differently on the impact that high-pressure situations have on their interaction. Although few attempts have been made so far at clarifying these underlying processes mechanistically (e.g., computationally), this paper proposes a detailed, mechanistic, and process-based account based on the Clarion cognitive architecture. This account incorporates facets of existing theories, but explores motivation, metacognition, and their effects on performance degradation. This account has been applied to different tasks that have previously suggested different explanations. These tasks were simulated within the Clarion cognitive architecture and results matched well with human data. Utilizing data from different tasks, we come up with a unified model of stress-induced performance degradation in high-pressure situations, which shows a unified, motivation-based, mechanistic account of these phenomena is possible, thus shedding light on the phenomena and pointing to mechanistic explanations of other related phenomena.},
  archive      = {J_CC},
  author       = {Wilson, Nicholas R. and Sun, Ron},
  doi          = {10.1007/s12559-020-09725-5},
  journal      = {Cognitive Computation},
  month        = {1},
  number       = {1},
  pages        = {207-227},
  shortjournal = {Cogn. Comput.},
  title        = {A mechanistic account of stress-induced performance degradation},
  volume       = {13},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Information theoretic model to simulate agent-signage
interaction for wayfinding. <em>CC</em>, <em>13</em>(1), 189–206. (<a
href="https://doi.org/10.1007/s12559-019-09689-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Signage systems are critical for communicating spatial information during wayfinding among a plethora of noise in the environment. A proper signage system can improve wayfinding performance and user experience by reducing the perceived complexity of the environment. However, previous models of sign-based wayfinding do not incorporate realistic noise or quantify the reduction in perceived complexity from the use of signage. Drawing upon concepts from information theory, we propose and validate a new agent-signage interaction model that quantifies available wayfinding information from signs for wayfinding. We conducted two online crowd-sourcing experiments to compute the distribution of a sign’s visibility and an agent’s decision-making confidence as a function of observation angle and viewing distance. We then validated this model using a virtual reality (VR) experiment with trajectories from human participants. The crowd-sourcing experiments provided a distribution of decision-making entropy (conditioned on visibility) that can be applied to any sign/environment. From the VR experiment, a training dataset of 30 trajectories was used to refine our model, and the remaining test dataset of 10 trajectories was compared with agent behavior using dynamic time warping (DTW) distance. The results revealed a reduction of 38.76% in DTW distance between the average trajectories before and after refinement. Our refined agent-signage interaction model provides realistic predictions of human wayfinding behavior using signs. These findings represent a first step towards modeling human wayfinding behavior in complex real environments in a manner that can incorporate several additional random variables (e.g., environment layout).},
  archive      = {J_CC},
  author       = {Dubey, Rohit K. and Thrash, Tyler and Kapadia, Mubbasir and Hoelscher, Christoph and Schinazi, Victor R.},
  doi          = {10.1007/s12559-019-09689-1},
  journal      = {Cognitive Computation},
  month        = {1},
  number       = {1},
  pages        = {189-206},
  shortjournal = {Cogn. Comput.},
  title        = {Information theoretic model to simulate agent-signage interaction for wayfinding},
  volume       = {13},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A weight importance analysis technique for area- and
power-efficient binary weight neural network processor design.
<em>CC</em>, <em>13</em>(1), 179–188. (<a
href="https://doi.org/10.1007/s12559-020-09794-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, the binary weight neural network (BWNN) processor design has attracted lots of attention due to its low computational complexity and memory demands. For the design of BWNN processor, emerging memory technologies such as RRAM can be used to replace conventional SRAM to save area and accessing power. However, RRAM is prone to bit errors, leading to reduced classification accuracy. To combine BWNN and RRAM to reduce the area overhead and power consumption while maintaining a high classification accuracy is a significant research challenge. In this work, we propose an automatic weight importance analysis technique and a mixed weight storage scheme to address the above-mentioned issue. For demonstration, we applied the proposed techniques to two typical BWNNs. The experimental results show that more than 78% (40%) area saving and 57% (30%) power saving can be achieved with less than 1% accuracy loss. The proposed techniques are applicable in resource- and power-constrained neural network processor design and show significant potentials for AI-based Internet-of-Things (IoT) devices that usually have low computational and storage resources.},
  archive      = {J_CC},
  author       = {Wang, Yin and Xie, Yuxiang and Gan, Jiayan and Chang, Liang and Luo, Chunbo and Zhou, Jun},
  doi          = {10.1007/s12559-020-09794-6},
  journal      = {Cognitive Computation},
  month        = {1},
  number       = {1},
  pages        = {179-188},
  shortjournal = {Cogn. Comput.},
  title        = {A weight importance analysis technique for area- and power-efficient binary weight neural network processor design},
  volume       = {13},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Optimizing sentiment classification for arabic opinion
texts. <em>CC</em>, <em>13</em>(1), 164–178. (<a
href="https://doi.org/10.1007/s12559-020-09771-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Meanwhile, products and services reviews’ provide a guide for potential customers allowing them to reach real knowledge about such products/services while making decisions. Sentiment classification is the task of analyzing opinions expressed in textual reviews automatically. The efficiency of this task is influenced by the set of representative features extracted from the reviews. Nevertheless, the value of extracted features lies as well in those that highly contribute to the classification process. Here comes the role of dimensionality reduction to eliminate the noise and reduce the feature high space while preserving required accuracies. The Arabic language and its datasets have inherent challenges. Besides, most sentiment classification studies integrating dimensionality reduction have focused on English texts, with only few studies conducted for other languages including Arabic. Massive amounts of Arabic data have been generated due to the huge population of the Arab world, and despite that, the aforementioned technical gaps are still existing for such language. This paper proposes a supervised learning approach for Arabic reviews sentiment classification. This approach utilizes optimized compact features that depend on a well representative feature set coupled with feature reduction techniques, which manages to guarantee high accuracy and time/space savings simultaneously. The employed feature set includes a triple combination of N-gram features and positive/negative N-grams counts features obtained after considering negation handling. The proposed approach examines two different linear transformation methods; principal component analysis (PCA) as an unsupervised transformation method and latent Dirichlet allocation (LDA) as a supervised transformation method. A spam detection process is executed prior to the learning for the purpose of increasing the classifier robustness. The proposed approach has been experimented with five Arabic opinion text datasets, of different domains and varying sizes (1.6 up to 94 K reviews). Experiments have been conducted for two-class (positive/negative sentiments) and three-class (positive/negative/neutral sentiments) classification problems. Accuracy values have been recorded in the range of 95.5–99.8% for the two-class classification problem and 92–97.3% for the three-class classification problem. The LDA feature reduction outperformed PCA by an average of 4.34% and 3.52% in accuracy and F1 Score measures, respectively. The overall approach outperformed the existing related works in literature by far of 23% and 34% for accuracy and F1 Score, respectively. The experimental studies and the obtained results show the efficiency of the proposed solution, which employs optimized features that rely on integrating a feature reduction module, together with a well representative feature set based on negation handled triple combination of N-gram features and positive/negative N-grams counts features. The overall results demonstrate great improvement with 24% increase in accuracy, 93% savings in the feature space, and 97% decrease in the classification execution time.},
  archive      = {J_CC},
  author       = {Saeed, Radwa M. K. and Rady, Sherine and Gharib, Tarek F.},
  doi          = {10.1007/s12559-020-09771-z},
  journal      = {Cognitive Computation},
  month        = {1},
  number       = {1},
  pages        = {164-178},
  shortjournal = {Cogn. Comput.},
  title        = {Optimizing sentiment classification for arabic opinion texts},
  volume       = {13},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Attribute normalization approaches to group decision-making
and application to software reliability assessment. <em>CC</em>,
<em>13</em>(1), 139–163. (<a
href="https://doi.org/10.1007/s12559-019-09707-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A group decision-making (GDM) process is a social cognition process, which is a sub-topic of cognitive computation. The normalization of attribute values plays an important role in multi-attribute decision-making (MADM) and GDM problems. However, this research finds that the existing normalization methods are not always reasonable for GDM problems. To solve the problem of attribute normalization in GDM systems, some new normalization models are developed in this paper. An integrative study contributes to cognitive MADM and GDM systems. In existing normalization models, there are some bounds, such as $\text {Max}(u_{j}), \text {Min}(u_{j}),\sum (u_{j}),\text {and} \sqrt {\sum (u_{j})^{2}}$ . They are limited to a single attribute vector uj. The bound of new normalization method proposed in this work is related to one or more attribute vectors, in which the attribute values are graded in the same measure system. These related attribute vectors may be distributed to all decision matrices graded by this decision system. That is, the new bound in developed normalization model is an uniform bound, which is related to a decision system. For example, this uniform bound can be written as one of $\text {Max}(.), \text {Min}(.), \sum (.),\sqrt {\sum (.)^{2}}$ . Some illustrative examples are provided. A practical application to the evaluation of software reliability is introduced in order to illustrate the feasibility and practicability of methods introduced in this paper. Some experimental and computational comparisons are provided. The results show that new normalization methods are feasibility and practicability, and they are superior to the classical normalization methods. This work has provided some new normalization models. These new methods can adapt to all decision problems, including MADM and GDM problems. Some important limitations and future research are introduced.},
  archive      = {J_CC},
  author       = {Yue, Chuan},
  doi          = {10.1007/s12559-019-09707-2},
  journal      = {Cognitive Computation},
  month        = {1},
  number       = {1},
  pages        = {139-163},
  shortjournal = {Cogn. Comput.},
  title        = {Attribute normalization approaches to group decision-making and application to software reliability assessment},
  volume       = {13},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Forecasting tourist arrivals via random forest and long
short-term memory. <em>CC</em>, <em>13</em>(1), 125–138. (<a
href="https://doi.org/10.1007/s12559-020-09747-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, deep learning has been attracting substantial attention due to its outstanding forecasting performance. However, the application of deep learning methods in solving the problem of forecasting tourist arrivals has been few. For the efficient allocation of tourism resources, tourist arrivals must be accurately predicted for government and tourism enterprises. In this study, a new hybrid deep learning approach is developed for tourist arrival forecasting. Random forest is used to reduce the dimensionality of the search query index data for selecting a small subset of informative features that contain the information that is most related to the tourist arrivals. Differential evolution algorithm is designed for choosing the lag lengths of each search query index and historical tourist arrival data for reconstructing the forecasting input. Long short-term memory (LSTM) is used for modeling the nonlinear relationship between tourist arrivals and search query index data. Two comparative examples, namely, Beijing City and Jiuzhaigou Valley, are applied for verification of the forecasting accuracy of the proposed deep learning method. The results indicate that the proposed deep learning method outperforms some time series and machine learning methods.},
  archive      = {J_CC},
  author       = {Peng, Lu and Wang, Lin and Ai, Xue-Yi and Zeng, Yu-Rong},
  doi          = {10.1007/s12559-020-09747-z},
  journal      = {Cognitive Computation},
  month        = {1},
  number       = {1},
  pages        = {125-138},
  shortjournal = {Cogn. Comput.},
  title        = {Forecasting tourist arrivals via random forest and long short-term memory},
  volume       = {13},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Brain-computer interface system based on p300 processing
with convolutional neural network, novel speller, and low number of
electrodes. <em>CC</em>, <em>13</em>(1), 108–124. (<a
href="https://doi.org/10.1007/s12559-020-09744-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The P300 wave has been successfully employed to develop brain-computer interfaces (BCI) for speller applications. However, methods to analyze the P300 require computers with high processing capability because they are computationally complex and require many electrodes. Therefore, this paper proposes a novel BCI speller system based on the P300 wave that employs a few electrodes and a processing method aimed to design ubiquitous and embedded applications. The experiments were developed with a dataset generated by our BCI data acquisition system. The BCI speller developed requires five electrodes for data acquisition, and the visual interface is an improved Donchin speller. Our BCI includes a novel processing method composed of the following modules: preprocessing, signal averaging, low computational cost convolutional neural network, and character prediction. The network has two feature extraction sections, a fully connected layer and a SoftMax layer. According to the results, the proposed BCI speller has an accuracy of 96% using just five electrodes, and it is similar to the best BCI for P300 analysis described in the literature. The processing time makes the system practical for online applications since the processing method has a low computational burden and the acquisition system has the lowest number of electrodes for P300 analysis reported in the literature. Considering the low computational burden, the low number of electrodes required, and the accuracy achieved, we conclude that our proposed BCI speller may be considered as one of the best spellers based on P300.},
  archive      = {J_CC},
  author       = {Ramirez-Quintana, Juan A. and Madrid-Herrera, Luis and Chacon-Murguia, Mario I. and Corral-Martinez, Luis F.},
  doi          = {10.1007/s12559-020-09744-2},
  journal      = {Cognitive Computation},
  month        = {1},
  number       = {1},
  pages        = {108-124},
  shortjournal = {Cogn. Comput.},
  title        = {Brain-computer interface system based on p300 processing with convolutional neural network, novel speller, and low number of electrodes},
  volume       = {13},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Fuzzy aggregated topology evolution for cognitive
multi-tasks. <em>CC</em>, <em>13</em>(1), 96–107. (<a
href="https://doi.org/10.1007/s12559-020-09807-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Evolutionary optimization aims to tune the hyper-parameters during learning in a computationally fast manner. For optimization of multi-task problems, evolution is done by creating a unified search space with a dimensionality that can include all the tasks. Multi-task evolution is achieved via selective imitation where two individuals with the same type of skill are encouraged to crossover. Due to the relatedness of the tasks, the resulting offspring may have a skill for a different task. In this way, we can simultaneously evolve a population where different individuals excel in different tasks. In this paper, we consider a type of evolution called Genetic Programming (GP) where the population of genes have a tree-like structure and can be of different lengths and hence can naturally represent multiple tasks. We apply the model to multi-task neuroevolution that aims to determine the optimal hyper-parameters of a neural network such as number of nodes, learning rate, and number of training epochs using evolution. Here each gene is encoded with the hyper parameters for a single neural network. Previously, optimization was done by enabling or disabling individual connections between neurons during evolution. This method is extremely slow and does not generalize well to new neural architectures such as Seq2Seq. To overcome this limitation, we follow a modular approach where each sub-tree in a GP can be a sub-neural architecture that is preserved during crossover across multiple tasks. Lastly, in order to leverage on the inter-task covariance for faster evolutionary search, we project the features from both tasks to common space using fuzzy membership functions. The proposed model is used to determine the optimal topology of a feed-forward neural network for classification of emotions in physiological heart signals and also a Seq2seq chatbot that can converse with kindergarten children. We can outperform baselines by over 10% in accuracy.},
  archive      = {J_CC},
  author       = {Chaturvedi, Iti and Su, Chit Lin and Welsch, Roy E.},
  doi          = {10.1007/s12559-020-09807-4},
  journal      = {Cognitive Computation},
  month        = {1},
  number       = {1},
  pages        = {96-107},
  shortjournal = {Cogn. Comput.},
  title        = {Fuzzy aggregated topology evolution for cognitive multi-tasks},
  volume       = {13},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Heterogeneous graph network embedding for sentiment analysis
on social media. <em>CC</em>, <em>13</em>(1), 81–95. (<a
href="https://doi.org/10.1007/s12559-020-09793-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, more people are used to express their attitudes on different entities in online social networks, forming user-to-entity sentiment links. These sentiment links imply positive or negative semantics. Most of current user sentiment analysis literature focuses on making a positive, neutral, or negative sentiment decision according to users’ text descriptions. Such approach, however, often fails to retrieve users’ hidden real attitudes. We design a powerful sentiment link analysis framework named graph network embedding for sentiment analysis (NESA). NESA first utilizes variational auto-encoder (VAE) to learn joint representations of users’ social relationship by preserving both the structural proximity and attribute proximity. Then, a multi-view correlation learning–based VAE is proposed to fuse the joint representation and the user-entity sentiment polarity network. By jointly optimizing the two components in a holistic learning framework, the embedding of network node information and multi-network contents is integrated and mutually reinforced. The first experimental results verify the effectiveness of adopting user, entity attributes, and social relationships for sentiment link analysis. Then we demonstrate the superiority of NESA over state-of-the-art network embedding baselines on link prediction. The last experimental results further validate that NESA model outperforms the traditional text-based sentiment prediction methods. We propose to perform sentiment analysis from network perspective; the proposed NESA model applies heterogeneous graph network embedding to fuse multi-networks information with considering their correlations and then to retrieve users’ hidden real attitudes in social networks. It provides a novel angle to resolve the sentiment analysis problem.},
  archive      = {J_CC},
  author       = {Jin, Zhigang and Zhao, Xiaofang and Liu, Yuhong},
  doi          = {10.1007/s12559-020-09793-7},
  journal      = {Cognitive Computation},
  month        = {1},
  number       = {1},
  pages        = {81-95},
  shortjournal = {Cogn. Comput.},
  title        = {Heterogeneous graph network embedding for sentiment analysis on social media},
  volume       = {13},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Robust visual saliency optimization based on bidirectional
markov chains. <em>CC</em>, <em>13</em>(1), 69–80. (<a
href="https://doi.org/10.1007/s12559-020-09724-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Saliency detection aims to automatically highlight the most important area in an image. Traditional saliency detection methods based on absorbing Markov chain only take into account boundary nodes and often lead to incorrect saliency detection when the boundaries have salient objects. In order to address this limitation and enhance saliency detection performance, this paper proposes a novel task-independent saliency detection method based on the bidirectional absorbing Markov chains that jointly exploits not only the boundary information but also the foreground prior and background prior cues. More specifically, the input image is first segmented into number of superpixels, and the four boundary nodes (duplicated as virtual nodes) are selected. Subsequently, the absorption time upon transition node’s random walk to the absorbing state is calculated to obtain the foreground possibility. Simultaneously, foreground prior (as the virtual absorbing nodes) is used to calculate the absorption time and get the background possibility. In addition, the two aforementioned results are fused to form a combined saliency map which is further optimized by using a cost function. Finally, the superpixel-level saliency results are optimized by a regularized random walks ranking model at multi-scale. The comparative experimental results on four benchmark datasets reveal superior performance of our proposed method over state-of-the-art methods reported in the literature. The experiments show that the proposed method is efficient and can be applicable to the bottom-up image saliency detection and other visual processing tasks.},
  archive      = {J_CC},
  author       = {Jiang, Fengling and Kong, Bin and Li, Jingpeng and Dashtipour, Kia and Gogate, Mandar},
  doi          = {10.1007/s12559-020-09724-6},
  journal      = {Cognitive Computation},
  month        = {1},
  number       = {1},
  pages        = {69-80},
  shortjournal = {Cogn. Comput.},
  title        = {Robust visual saliency optimization based on bidirectional markov chains},
  volume       = {13},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Modeling articulatory rehearsal in an attention-based model
of working memory. <em>CC</em>, <em>13</em>(1), 49–68. (<a
href="https://doi.org/10.1007/s12559-020-09791-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Maintenance of verbal information within human working memory occurs through two main complementary mechanisms: articulatory rehearsal and refreshing. Both are well-described in the literature but very few computational models have attempted to describe the ways they interact to maintain information. Because these interactions are difficult to apprehend without computer simulations, this paper presents a possible implementation of rehearsal within TBRS* (Time-Based Resource-Sharing Theory), a computational model operating only with refreshing and based on the TBRS verbal theory. Computer code is available at https://osf.io/taqmv/ . The implementation was tested on different benchmark findings and could replicate all main effects attributed to rehearsal, while still being accountable for the same effect as TBRS*. Four aspects of our rehearsal implementation are discussed with respect to the human behavior that is intended to be described: first, the primacy and recency effects in relation to the short-term property of rehearsal and the long-term purpose of refreshing; second, the moment at which long-term memory influences working memory performance during working memory tasks in reference to the redintegration hypothesis; third, the interplay between the two maintenance mechanisms; finally, positional coding as the appropriate representation for rehearsal.},
  archive      = {J_CC},
  author       = {Lemaire, Benoît and Heuer, Charlotte and Portrat, Sophie},
  doi          = {10.1007/s12559-020-09791-9},
  journal      = {Cognitive Computation},
  month        = {1},
  number       = {1},
  pages        = {49-68},
  shortjournal = {Cogn. Comput.},
  title        = {Modeling articulatory rehearsal in an attention-based model of working memory},
  volume       = {13},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Computer-aided dementia diagnosis based on hierarchical
extreme learning machine. <em>CC</em>, <em>13</em>(1), 34–48. (<a
href="https://doi.org/10.1007/s12559-019-09708-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The deep learning–based computer-aided diagnosis (CADx) approaches of dementia often require a lot of manual intervention. Although deep learning has a good effect on feature extraction, the current deep learning methods usually need to set a large number of parameters manually, which is time consuming. Hierarchical extreme learning machine (H-ELM) needs only less manual intervention and can extract features by a multi-layer feature representation framework, which is much faster than the traditional deep learning methods. A CADx framework based on H-ELM, named DCADx, is proposed. As common spatial pattern (CSP) and brain functional network (BFN) have been proven to have better de-redundancy effects on brain data, the DCADx contains two different data redundancy reduction methods: (1) CSP-based DCADx (i.e., DCADx-CSP model) and (2) BFN-based DCADx (i.e., DCADx-BFN model). The experimental evaluation proved the effectiveness of the proposed algorithms. The DCADx-CSP model obtained 83.2% on Alzheimer’s disease and 82.5% on Parkinson’s disease. The DCADx-BFN obtained 89.3% on Alzheimer’s disease and 88.7% on Parkinson’s disease. DCADx can make full use of the feature expression ability of H-ELM to achieve better performance. CSP and BFN can reduce the redundancy to enhance the diagnostic accuracy further.},
  archive      = {J_CC},
  author       = {Wang, Zhongyang and Xin, Junchang and Wang, Zhiqiong and Gu, Huizi and Zhao, Yue and Qian, Wei},
  doi          = {10.1007/s12559-019-09708-1},
  journal      = {Cognitive Computation},
  month        = {1},
  number       = {1},
  pages        = {34-48},
  shortjournal = {Cogn. Comput.},
  title        = {Computer-aided dementia diagnosis based on hierarchical extreme learning machine},
  volume       = {13},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Deep learning in mining biological data. <em>CC</em>,
<em>13</em>(1), 1–33. (<a
href="https://doi.org/10.1007/s12559-020-09773-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent technological advancements in data acquisition tools allowed life scientists to acquire multimodal data from different biological application domains. Categorized in three broad types (i.e. images, signals, and sequences), these data are huge in amount and complex in nature. Mining such enormous amount of data for pattern recognition is a big challenge and requires sophisticated data-intensive machine learning techniques. Artificial neural network-based learning systems are well known for their pattern recognition capabilities, and lately their deep architectures—known as deep learning (DL)—have been successfully applied to solve many complex pattern recognition problems. To investigate how DL—especially its different architectures—has contributed and been utilized in the mining of biological data pertaining to those three types, a meta-analysis has been performed and the resulting resources have been critically analysed. Focusing on the use of DL to analyse patterns in data from diverse biological domains, this work investigates different DL architectures’ applications to these data. This is followed by an exploration of available open access data sources pertaining to the three data types along with popular open-source DL tools applicable to these data. Also, comparative investigations of these tools from qualitative, quantitative, and benchmarking perspectives are provided. Finally, some open research challenges in using DL to mine biological data are outlined and a number of possible future perspectives are put forward.},
  archive      = {J_CC},
  author       = {Mahmud, Mufti and Kaiser, M. Shamim and McGinnity, T. Martin and Hussain, Amir},
  doi          = {10.1007/s12559-020-09773-x},
  journal      = {Cognitive Computation},
  month        = {1},
  number       = {1},
  pages        = {1-33},
  shortjournal = {Cogn. Comput.},
  title        = {Deep learning in mining biological data},
  volume       = {13},
  year         = {2021},
}
</textarea>
</details></li>
</ul>

</body>
</html>
