<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>AR_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="ar---65">AR - 65</h2>
<ul>
<li><details>
<summary>
(2021). Autonomous assembly planning of demonstrated skills with
reinforcement learning in simulation. <em>AR</em>, <em>45</em>(8),
1097–1110. (<a
href="https://doi.org/10.1007/s10514-021-10020-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Industrial robots used to assemble customized products in small batches require a lot of reprogramming. With this work we aim to reduce the programming complexity by autonomously finding the fastest assembly plans without any collisions with the environment. First, a digital twin of the robot uses a gym in simulation to learn which assembly skills (programmed by demonstration) are physically possible (i.e. no collisions with the environment). Only from this reduced solution space will the physical twin look for the fastest assembly plans. Experiments show that the system indeed converges to the fastest assembly plans. Moreover, pre-training in simulation drastically reduces the number of interactions before convergence compared to directly learning on the physical robot. This two-step procedure allows for the robot to autonomously find correct and fast assembly sequences, without any additional human input or mismanufactured products.},
  archive      = {J_AR},
  author       = {De Winter, Joris and EI Makrini, Ilias and Van de Perre, Greet and Nowé, Ann and Verstraten, Tom and Vanderborght, Bram},
  doi          = {10.1007/s10514-021-10020-x},
  journal      = {Autonomous Robots},
  month        = {12},
  number       = {8},
  pages        = {1097-1110},
  shortjournal = {Auton. Robot.},
  title        = {Autonomous assembly planning of demonstrated skills with reinforcement learning in simulation},
  volume       = {45},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A bayesian tracker for synthesizing mobile robot behaviour
from demonstration. <em>AR</em>, <em>45</em>(8), 1077–1096. (<a
href="https://doi.org/10.1007/s10514-021-10019-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Programming robots often involves expert knowledge in both the robot itself and the task to execute. An alternative to direct programming is for a human to show examples of the task execution and have the robot perform the task based on these examples, in a scheme known as learning or programming from demonstration. We propose and study a generic and simple learning-from-demonstration framework. Our approach is to combine the demonstrated commands according to the similarity between the demonstrated sensory trajectories and the current replay trajectory. This tracking is solely performed based on sensor values and time and completely dispenses with the usually expensive step of precomputing an internal model of the task. We analyse the behaviour of the proposed model in several simulated conditions and test it on two different robotic platforms. We show that it can reproduce different capabilities with a limited number of meta parameters.},
  archive      = {J_AR},
  author       = {Magnenat, Stéphane and Colas, Francis},
  doi          = {10.1007/s10514-021-10019-4},
  journal      = {Autonomous Robots},
  month        = {12},
  number       = {8},
  pages        = {1077-1096},
  shortjournal = {Auton. Robot.},
  title        = {A bayesian tracker for synthesizing mobile robot behaviour from demonstration},
  volume       = {45},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Search-based configuration planning and motion control
algorithms for a snake-like robot performing load-intensive operations.
<em>AR</em>, <em>45</em>(8), 1047–1076. (<a
href="https://doi.org/10.1007/s10514-021-10017-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Snake-like robots can enable workers to avoid difficult-to-reach, dangerous, and hazardous environments while enhancing their capabilities. The technologies developed for a snake-like robot can be transferred to applications such as robotic exploration, minimally invasive surgical robotics, and robotic manipulation in manufacturing industries. In this paper we consider high-load tasks, such as drilling through the studs inside a wall, using a snake-like robot. The key technical innovation in this work is to design a search-based planning algorithm for high degree of freedom articulated systems that explicitly takes into account contact with surfaces in the environment in order to garner mechanical support for performing load-intensive tasks. In case of a snake-like robot, contacts with the studs and other structural members within walls need to be exploited to its advantage for bracing against walls for support in order to climb up or perform load-intensive operations such as drilling. We present a contact-augmented graph construction, which is the main technical tool for finding stable load-bearing configurations. We also develop motion controllers for moving the robot into the planned configuration and progressing the robot during the drilling process. We validate the algorithms through simulation and introduce a preliminary experimental setup.},
  archive      = {J_AR},
  author       = {Wang, Xiaolong and Bilsky, Matthew and Bhattacharya, Subhrajit},
  doi          = {10.1007/s10514-021-10017-6},
  journal      = {Autonomous Robots},
  month        = {12},
  number       = {8},
  pages        = {1047-1076},
  shortjournal = {Auton. Robot.},
  title        = {Search-based configuration planning and motion control algorithms for a snake-like robot performing load-intensive operations},
  volume       = {45},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Sampling-based planning for non-myopic multi-robot
information gathering. <em>AR</em>, <em>45</em>(7), 1029–1046. (<a
href="https://doi.org/10.1007/s10514-021-09995-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a novel highly scalable sampling-based planning algorithm for multi-robot active information acquisition tasks in complex environments. Active information gathering scenarios include target localization and tracking, active SLAM, surveillance, environmental monitoring and others. The objective is to compute control policies for sensing robots which minimize the accumulated uncertainty of a dynamic hidden state over an a priori unknown horizon. To address this problem, we propose a new sampling-based algorithm that simultaneously explores both the robot motion space and the reachable information space. Unlike relevant sampling-based approaches, we show that the proposed algorithm is probabilistically complete, asymptotically optimal and is supported by convergence rate bounds. Moreover, we propose a novel biased sampling strategy that biases exploration towards informative areas. This allows the proposed method to quickly compute sensor policies that achieve desired levels of uncertainty in large-scale estimation tasks that may involve large sensor teams, workspaces, and dimensions of the hidden state. Extensions of the proposed algorithm to account for hidden states with no prior information are discussed. We provide extensive simulation results that corroborate the theoretical analysis and show that the proposed algorithm can address large-scale estimation tasks that are computationally challenging for existing methods.},
  archive      = {J_AR},
  author       = {Kantaros, Yiannis and Schlotfeldt, Brent and Atanasov, Nikolay and Pappas, George J.},
  doi          = {10.1007/s10514-021-09995-4},
  journal      = {Autonomous Robots},
  month        = {10},
  number       = {7},
  pages        = {1029-1046},
  shortjournal = {Auton. Robot.},
  title        = {Sampling-based planning for non-myopic multi-robot information gathering},
  volume       = {45},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Learning and planning with logical automata. <em>AR</em>,
<em>45</em>(7), 1013–1028. (<a
href="https://doi.org/10.1007/s10514-021-09993-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce a method to learn policies from expert demonstrations that are interpretable and manipulable. We achieve interpretability by modeling the interactions between high-level actions as an automaton with connections to formal logic. We achieve manipulability by integrating this automaton into planning via Logical Value Iteration, so that changes to the automaton have predictable effects on the learned behavior. These qualities allow a human user to first understand what the model has learned, and then either correct the learned behavior or zero-shot generalize to new, similar tasks. Our inference method requires only low-level trajectories and a description of the environment in order to learn high-level rules. We achieve this by using a deep Bayesian nonparametric hierarchical model. We test our model on several domains of interest and also show results for a real-world implementation on a mobile robotic arm platform for lunchbox-packing and cabinet-opening tasks.},
  archive      = {J_AR},
  author       = {Araki, Brandon and Vodrahalli, Kiran and Leech, Thomas and Vasile, Cristian-Ioan and Donahue, Mark and Rus, Daniela},
  doi          = {10.1007/s10514-021-09993-6},
  journal      = {Autonomous Robots},
  month        = {10},
  number       = {7},
  pages        = {1013-1028},
  shortjournal = {Auton. Robot.},
  title        = {Learning and planning with logical automata},
  volume       = {45},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Network offloading policies for cloud robotics: A
learning-based approach. <em>AR</em>, <em>45</em>(7), 997–1012. (<a
href="https://doi.org/10.1007/s10514-021-09987-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Today’s robotic systems are increasingly turning to computationally expensive models such as deep neural networks (DNNs) for tasks like localization, perception, planning, and object detection. However, resource-constrained robots, like low-power drones, often have insufficient on-board compute resources or power reserves to scalably run the most accurate, state-of-the art neural network compute models. Cloud robotics allows mobile robots the benefit of offloading compute to centralized servers if they are uncertain locally or want to run more accurate, compute-intensive models. However, cloud robotics comes with a key, often understated cost: communicating with the cloud over congested wireless networks may result in latency or loss of data. In fact, sending high data-rate video or LIDAR from multiple robots over congested networks can lead to prohibitive delay for real-time applications, which we measure experimentally. In this paper, we formulate a novel Robot Offloading Problem—how and when should robots offload sensing tasks, especially if they are uncertain, to improve accuracy while minimizing the cost of cloud communication? We formulate offloading as a sequential decision making problem for robots, and propose a solution using deep reinforcement learning. In both simulations and hardware experiments using state-of-the art vision DNNs, our offloading strategy improves vision task performance by between 1.3 and 2.3 $$\times $$ of benchmark offloading strategies, allowing robots the potential to significantly transcend their on-board sensing accuracy but with limited cost of cloud communication.},
  archive      = {J_AR},
  author       = {Chinchali, Sandeep and Sharma, Apoorva and Harrison, James and Elhafsi, Amine and Kang, Daniel and Pergament, Evgenya and Cidon, Eyal and Katti, Sachin and Pavone, Marco},
  doi          = {10.1007/s10514-021-09987-4},
  journal      = {Autonomous Robots},
  month        = {10},
  number       = {7},
  pages        = {997-1012},
  shortjournal = {Auton. Robot.},
  title        = {Network offloading policies for cloud robotics: A learning-based approach},
  volume       = {45},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Leveraging experience in lazy search. <em>AR</em>,
<em>45</em>(7), 979–996. (<a
href="https://doi.org/10.1007/s10514-021-10018-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lazy graph search algorithms are efficient at solving motion planning problems where edge evaluation is the computational bottleneck. These algorithms work by lazily computing the shortest potentially feasible path, evaluating edges along that path, and repeating until a feasible path is found. The order in which edges are selected is critical to minimizing the total number of edge evaluations: a good edge selector chooses edges that are not only likely to be invalid, but also eliminates future paths from consideration. We wish to learn such a selector by leveraging prior experience. We formulate this problem as a Markov Decision Process (MDP) on the state of the search problem. While solving this large MDP is generally intractable, we show that we can compute oracular selectors that can solve the MDP during training. With access to such oracles, we use imitation learning to find effective policies. If new search problems are sufficiently similar to problems solved during training, the learned policy will choose a good edge evaluation ordering and solve the motion planning problem quickly. We evaluate our algorithms on a wide range of 2D and 7D problems and show that the learned selector outperforms baseline commonly used heuristics. We further provide a novel theoretical analysis of lazy search in a Bayesian framework as well as regret guarantees on our imitation learning based approach to motion planning.},
  archive      = {J_AR},
  author       = {Bhardwaj, Mohak and Choudhury, Sanjiban and Boots, Byron and Srinivasa, Siddhartha},
  doi          = {10.1007/s10514-021-10018-5},
  journal      = {Autonomous Robots},
  month        = {10},
  number       = {7},
  pages        = {979-996},
  shortjournal = {Auton. Robot.},
  title        = {Leveraging experience in lazy search},
  volume       = {45},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Influencing leading and following in human–robot teams.
<em>AR</em>, <em>45</em>(7), 959–978. (<a
href="https://doi.org/10.1007/s10514-021-10016-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Roles such as leading and following can emerge naturally in human groups. However, in human–robot teams, such roles are often predefined due to the difficulty of scalably learning and adapting to them. In this work, we enable a robot to efficiently learn how group dynamics emerge and evolve in human teams and we leverage this understanding to plan for influencing actions for autonomous robots that guide the team toward achieving a common goal. We first develop an effective and concise representation of group dynamics, such as leading and following, by enforcing a graph structure while learning the weights of the edges corresponding to one-to-one relationships between the agents. We then develop an optimization-based robot policy that leverages this graph representation to attain an objective by influencing a human team. We apply our framework to two types of group dynamics, leading-following and predator–prey, and show that our structured representation is scalable with different human team sizes and also generalizable across different tasks. We also show that robots that utilize this representation are able to successfully influence a group to achieve various goals compared to robots that do not have access to these graph representations (Parts of this work has been published at Robotics: Science and Systems (RSS) (Kwon et al. in Proceedings of robotics: science and systems (RSS), 2019. https://doi.org/10.15607/rss.2019.xv.075 ).},
  archive      = {J_AR},
  author       = {Li, Mengxi and Kwon, Minae and Sadigh, Dorsa},
  doi          = {10.1007/s10514-021-10016-7},
  journal      = {Autonomous Robots},
  month        = {10},
  number       = {7},
  pages        = {959-978},
  shortjournal = {Auton. Robot.},
  title        = {Influencing leading and following in human–robot teams},
  volume       = {45},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Editor’s note. <em>AR</em>, <em>45</em>(7), 957. (<a
href="https://doi.org/10.1007/s10514-021-10021-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_AR},
  doi          = {10.1007/s10514-021-10021-w},
  journal      = {Autonomous Robots},
  month        = {10},
  number       = {7},
  pages        = {957},
  shortjournal = {Auton. Robot.},
  title        = {Editor’s note},
  volume       = {45},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Long-horizon humanoid navigation planning using
traversability estimates and previous experience. <em>AR</em>,
<em>45</em>(6), 937–956. (<a
href="https://doi.org/10.1007/s10514-021-09996-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Humanoids’ abilities to navigate stairs and uneven terrain make them well-suited for disaster response efforts. However, humanoid navigation in such environments is currently limited by the capabilities of navigation planners. Such planners typically consider only footstep locations, but planning with palm contacts may be necessary to cross a gap, avoid an obstacle, or maintain balance. However, considering palm contacts greatly increases the branching factor of the search, leading to impractical planning times for large environments. Planning a contact transition sequence in a large environment is important because it verifies that the robot will be able to reach a given goal. In previous work we explored using library-based methods to address difficult navigation planning problems requiring palm contacts, but such methods are not efficient when navigating an easy-to-traverse part of the environment. To maximize planning efficiency, we would like to use discrete planners when an area is easy to traverse and switch to the library-based method only when traversal becomes difficult. Thus, in this paper we present a method that (1) Plans a torso guiding path which accounts for the difficulty of traversing the environment as predicted by learned regressors; and (2) Decomposes the guiding path into a set of segments, each of which is assigned a motion mode (i.e. a set of feet and hands to use) and a planning method. Easily-traversable segments are assigned a discrete-search planner, while other segments are assigned a library-based method that fits existing motion plans to the environment near the given segment. Our results suggest that the proposed approach greatly outperforms standard discrete planning in success rate and planning time. We also show an application of the method to a real robot in a mock disaster scenario.},
  archive      = {J_AR},
  author       = {Lin, Yu-Chi and Berenson, Dmitry},
  doi          = {10.1007/s10514-021-09996-3},
  journal      = {Autonomous Robots},
  month        = {9},
  number       = {6},
  pages        = {937-956},
  shortjournal = {Auton. Robot.},
  title        = {Long-horizon humanoid navigation planning using traversability estimates and previous experience},
  volume       = {45},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Autonomous foraging with a pack of robots based on
repulsion, attraction and influence. <em>AR</em>, <em>45</em>(6),
919–935. (<a href="https://doi.org/10.1007/s10514-021-09994-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we propose a swarm algorithm with tendencies of repulsion, attraction, and influence for implementation in a pack of autonomous robots and with sensory limitations. The pack of robots performs an object transport task with a foraging approach; each object is distributed within a foraging zone and has to be transported to a specific destination (nest). The main challenge involves solving several important subtasks: search, navigation, transportation, localization and harvesting; which are associated with different stimuli in the environment. The main contribution is that the RAOI approach is extended, proposing multiple influence stimuli that are activated in a finite state machine, which is implemented in each individual without affecting swarm decentralized properties. From this extended RAOI scheme, the task performance has been improved by changing robot parameters; for this, the results are quantified with task execution time and are validated through simulations and implementations.},
  archive      = {J_AR},
  author       = {Ordaz-Rivas, Erick and Rodriguez-Liñan, Angel and Torres-Treviño, Luis},
  doi          = {10.1007/s10514-021-09994-5},
  journal      = {Autonomous Robots},
  month        = {9},
  number       = {6},
  pages        = {919-935},
  shortjournal = {Auton. Robot.},
  title        = {Autonomous foraging with a pack of robots based on repulsion, attraction and influence},
  volume       = {45},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). VIR-SLAM: Visual, inertial, and ranging SLAM for single and
multi-robot systems. <em>AR</em>, <em>45</em>(6), 905–917. (<a
href="https://doi.org/10.1007/s10514-021-09992-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Monocular cameras coupled with inertial measurements generally give high performance visual inertial odometry. However, drift can be significant with long trajectories, especially when the environment is visually challenging. In this paper, we propose a system that leverages Ultra–WideBand (UWB) ranging with one static anchor placed in the environment to correct the accumulated error whenever the anchor is visible. We also use this setup for collaborative SLAM: different robots use mutual ranging (when available) and the common anchor to estimate the transformation between each other, facilitating map fusion. Our system consists of two modules: a double layer ranging, visual, and inertial odometry for single robots, and a transformation estimation module for collaborative SLAM. We test our system on public datasets by simulating UWB measurements as well as on real robots in different environments. Experiments validate our system and show our method can outperform pure visual-inertial odometry by more than 20%, and in visually challenging environments, our method works even when the visual-inertial pipeline has significant drift. Furthermore, we can compute the inter-robot transformation matrices for collaborative SLAM at almost no extra computation cost.},
  archive      = {J_AR},
  author       = {Cao, Yanjun and Beltrame, Giovanni},
  doi          = {10.1007/s10514-021-09992-7},
  journal      = {Autonomous Robots},
  month        = {9},
  number       = {6},
  pages        = {905-917},
  shortjournal = {Auton. Robot.},
  title        = {VIR-SLAM: Visual, inertial, and ranging SLAM for single and multi-robot systems},
  volume       = {45},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Annotation scaffolds for manipulating articulated objects.
<em>AR</em>, <em>45</em>(6), 885–903. (<a
href="https://doi.org/10.1007/s10514-021-09983-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present and evaluate an approach for human-in-the-loop specification of robot–object interactions. Our method is based on the idea of model annotation: the addition of simple cues to an underlying object model to delineate a complex task. The goal is to explore simplified CAD-like interfaces to permit novice users to describe and annotate manipulation tasks that are then carried out by a robot. The constructed models meet precision requirements for modeling a variety of joint types and kinematic chains, and can be re-used after their initial design. The approach is contrasted with teleoperation and tested with a user study. We found that untrained users can create object models whose structure can be readily used to initialize joint constraints to guide the user in designing successful end-effector trajectories. We see this approach as an alternative to direct teleoperation for cases where it is more natural or practical to store the action sequence with the object as the reference frame. The approach was evaluated using the PR2 robot platform.},
  archive      = {J_AR},
  author       = {Frank-Bolton, Pablo and Leontie, Roxana and Drumwright, Evan and Simha, Rahul},
  doi          = {10.1007/s10514-021-09983-8},
  journal      = {Autonomous Robots},
  month        = {9},
  number       = {6},
  pages        = {885-903},
  shortjournal = {Auton. Robot.},
  title        = {Annotation scaffolds for manipulating articulated objects},
  volume       = {45},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A unified control strategy for autonomous aerial vehicles.
<em>AR</em>, <em>45</em>(6), 859–883. (<a
href="https://doi.org/10.1007/s10514-021-10015-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unmanned aerial vehicles (UAVs) have become popular in a wide range of applications, including many military and civilian uses. State-of-the-art control strategies for these vehicles are typically tailored to a specific platform and are often limited to a portion of the vehicle’s flight envelope. This article presents a single physics-based controller capable of aggressive maneuvering for the majority of UAVs. The controller is applicable to UAVs with the ability to apply a force along a body-fixed direction, and a moment about an arbitrary axis, which includes UAVs such as multi-copters, conventional fixed-wing, agile fixed-wing, most flying-wings, most tailsitters, some tilt-rotor/wing platforms, and some flapping-wing vehicles. We describe the implementation of this controller on numerous platforms, and demonstrate autonomous flight in outdoor flight tests for a quadrotor and an agile fixed-wing aircraft. To specifically demonstrate the extreme maneuvering capability of the control logic, we perform a rolling flip with the quadrotor and a rolling Harrier and an aggressive turnaround with the fixed-wing aircraft, all using a single controller.},
  archive      = {J_AR},
  author       = {Bulka, Eitan and Nahon, Meyer},
  doi          = {10.1007/s10514-021-10015-8},
  journal      = {Autonomous Robots},
  month        = {9},
  number       = {6},
  pages        = {859-883},
  shortjournal = {Auton. Robot.},
  title        = {A unified control strategy for autonomous aerial vehicles},
  volume       = {45},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Navigating by touch: Haptic monte carlo localization via
geometric sensing and terrain classification. <em>AR</em>,
<em>45</em>(6), 843–857. (<a
href="https://doi.org/10.1007/s10514-021-10013-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Legged robot navigation in extreme environments can hinder the use of cameras and lidar due to darkness, air obfuscation or sensor damage, whereas proprioceptive sensing will continue to work reliably. In this paper, we propose a purely proprioceptive localization algorithm which fuses information from both geometry and terrain type to localize a legged robot within a prior map. First, a terrain classifier computes the probability that a foot has stepped on a particular terrain class from sensed foot forces. Then, a Monte Carlo-based estimator fuses this terrain probability with the geometric information of the foot contact points. Results demonstrate this approach operating online and onboard an ANYmal B300 quadruped robot traversing several terrain courses with different geometries and terrain types over more than 1.2 km. The method keeps pose estimation error below 20 cm using a prior map with trained network and using sensing only from the feet, leg joints and IMU.},
  archive      = {J_AR},
  author       = {Buchanan, Russell and Bednarek, Jakub and Camurri, Marco and Nowicki, Michał R. and Walas, Krzysztof and Fallon, Maurice},
  doi          = {10.1007/s10514-021-10013-w},
  journal      = {Autonomous Robots},
  month        = {9},
  number       = {6},
  pages        = {843-857},
  shortjournal = {Auton. Robot.},
  title        = {Navigating by touch: Haptic monte carlo localization via geometric sensing and terrain classification},
  volume       = {45},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Topological path planning for autonomous information
gathering. <em>AR</em>, <em>45</em>(6), 821–842. (<a
href="https://doi.org/10.1007/s10514-021-10012-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we present two novel algorithms for information space topological planning that identify topological features in an information field and use them to plan maximally informative paths for a robot in an information gathering task. These features provide a way to rapidly incorporate global context into the informative path planning process by partitioning the state space or the path space of a robot. Our first algorithm, hierarchical hotspot information gathering, uses a topological state space partitioning by constructing a high-level map of information hotspots. We then solve a global scheduling problem over the topological graph, the solution of which is then used for path planning by a set of local greedy coverage planners within each hotspot. Our second algorithm, Topology-Aware Self Organizing Maps, extends the Self Organizing Map algorithm to discover prominent topological features in the information function. These features are used to perform a topological path space decomposition to provide a Stochastic Gradient Ascent optimization algorithm with topologically diverse initialization, improving its performance. In simulated trials and field experiments, we compare the tradeoffs of these two approaches and show that our methods that leverage topological features of the information field consistently perform competitively or better than methods that do not exploit these features, while requiring less computation time.},
  archive      = {J_AR},
  author       = {McCammon, Seth and Hollinger, Geoffrey A.},
  doi          = {10.1007/s10514-021-10012-x},
  journal      = {Autonomous Robots},
  month        = {9},
  number       = {6},
  pages        = {821-842},
  shortjournal = {Auton. Robot.},
  title        = {Topological path planning for autonomous information gathering},
  volume       = {45},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Agile and stable running locomotion control for an
untethered and one-legged hopping robot. <em>AR</em>, <em>45</em>(6),
805–819. (<a href="https://doi.org/10.1007/s10514-021-10010-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is aimed at presenting a locomotion control framework to realize agile and robust locomotion behaviors on conventional stiff-by-nature legged robots. First, a trajectory generator that is capable of characterizing angular momentum is utilized to synthesize reference CoM trajectories and associated force inputs, in accordance with the target locomotion profile. Second, the controller evaluates both force and position errors in the joint level, using a servo controller and an admittance control block. The trade-off between the position and force errors is naturally adjusted via admittance control coefficients. Implementing the controller on a 4-link, 3-jointed one-legged robot, we conducted several balancing and running experiments under challenging conditions; e.g., balancing on a moving cart, balancing on a surface with varying orientation, running on a flat surface, running on an inclined surface. The experimental study results indicated that the locomotion controller enabled the robot to perform untethered one-legged running and to maintain its balance when subject to disturbances.},
  archive      = {J_AR},
  author       = {Ugurlu, Barkan and Sariyildiz, Emre and Kawasaki, Takao and Narikiyo, Tatsuo},
  doi          = {10.1007/s10514-021-10010-z},
  journal      = {Autonomous Robots},
  month        = {9},
  number       = {6},
  pages        = {805-819},
  shortjournal = {Auton. Robot.},
  title        = {Agile and stable running locomotion control for an untethered and one-legged hopping robot},
  volume       = {45},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Incorporating learnt local and global embeddings into
monocular visual SLAM. <em>AR</em>, <em>45</em>(6), 789–803. (<a
href="https://doi.org/10.1007/s10514-021-10007-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional approaches for Visual Simultaneous Localization and Mapping (VSLAM) rely on low-level vision information for state estimation, such as handcrafted local features or the image gradient. While significant progress has been made through this track, under more challenging configuration for monocular VSLAM, e.g., varying illumination, the performance of state-of-the-art systems generally degrades. As a consequence, robustness and accuracy for monocular VSLAM are still widely concerned. This paper presents a monocular VSLAM system that fully exploits learnt features for better state estimation. The proposed system leverages both learnt local features and global embeddings at different modules of the system: direct camera pose estimation, inter-frame feature association, and loop closure detection. With a probabilistic explanation of keypoint prediction, we formulate the camera pose tracking in a direct manner and parameterize local features with uncertainty taken into account. To alleviate the quantization effect, we adapt the mapping module to generate 3D landmarks better to guarantee the system’s robustness. Detecting temporal loop closure via deep global embeddings further improves the robustness and accuracy of the proposed system. The proposed system is extensively evaluated on public datasets (Tsukuba, EuRoC, and KITTI), and compared against the state-of-the-art methods. The competitive performance of camera pose estimation confirms the effectiveness of our method.},
  archive      = {J_AR},
  author       = {Huang, Huaiyang and Ye, Haoyang and Sun, Yuxiang and Wang, Lujia and Liu, Ming},
  doi          = {10.1007/s10514-021-10007-8},
  journal      = {Autonomous Robots},
  month        = {9},
  number       = {6},
  pages        = {789-803},
  shortjournal = {Auton. Robot.},
  title        = {Incorporating learnt local and global embeddings into monocular visual SLAM},
  volume       = {45},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Semi-dense visual-inertial odometry and mapping for
computationally constrained platforms. <em>AR</em>, <em>45</em>(6),
773–787. (<a href="https://doi.org/10.1007/s10514-021-10002-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we present a direct semi-dense stereo Visual-Inertial Odometry (VIO) algorithm enabling autonomous flight for quadrotor systems with Size, Weight, and Power (SWaP) constraints. The proposed approach is validated through experiments on a 250 g, 22 cm diameter quadrotor equipped with a stereo camera and an IMU. Semi-dense methods have superior performance in low texture areas, which are often encountered in robotic tasks such as infrastructure inspection. However, due to the measurement size and iterative nonlinear optimization, these methods are computationally more expensive. As the scale of the platform shrinks down, the available computation of the on-board CPU becomes limited, making autonomous navigation using optimization-based semi-dense tracking a hard problem. We show that our direct semi-dense VIO performs comparably to other state-of-the-art methods, while taking less CPU than other optimization-based approaches, making it suitable for computationally-constrained small platforms. Our method takes less amount of CPU than the state-of-the-art semi-dense method, VI-Stereo-DSO, due to a simpler framework in the algorithm and a multi-threaded code structure allowing us to run real-time state estimation on an ARM board. With a low texture dataset obtained with our quadrotor platform, we show that this method performs significantly better than sparse methods in low texture conditions encountered in indoor navigation. Finally, we demonstrate autonomous flight on a small platform using our direct semi-dense Visual-Inertial Odometry. Supplementary code, low texture datasets and videos can be found on our github repo: https://github.com/KumarRobotics/sdd_vio .},
  archive      = {J_AR},
  author       = {Liu, Wenxin and Mohta, Kartik and Loianno, Giuseppe and Daniilidis, Kostas and Kumar, Vijay},
  doi          = {10.1007/s10514-021-10002-z},
  journal      = {Autonomous Robots},
  month        = {9},
  number       = {6},
  pages        = {773-787},
  shortjournal = {Auton. Robot.},
  title        = {Semi-dense visual-inertial odometry and mapping for computationally constrained platforms},
  volume       = {45},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Hierarchical topometric representation of 3D robotic maps.
<em>AR</em>, <em>45</em>(5), 755–771. (<a
href="https://doi.org/10.1007/s10514-021-09991-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a method for generating a hierarchical, volumetric topological map from 3D point clouds. There are three basic hierarchical levels in our map: $$storey - region - volume$$ . The advantages of our method are reflected in both input and output. In terms of input, we accept multi-storey point clouds and building structures with sloping roofs or ceilings. In terms of output, we can generate results with metric information of different dimensionality, that are suitable for different robotics applications. The algorithm generates the volumetric representation by generating volumes from a 3D voxel occupancy map. We then add passages (connections between volumes), combine small volumes into a big region and use a 2D segmentation method for better topological representation. We evaluate our method on several freely available datasets. The experiments highlight the advantages of our approach.},
  archive      = {J_AR},
  author       = {He, Zhenpeng and Sun, Hao and Hou, Jiawei and Ha, Yajun and Schwertfeger, Sören},
  doi          = {10.1007/s10514-021-09991-8},
  journal      = {Autonomous Robots},
  month        = {6},
  number       = {5},
  pages        = {755-771},
  shortjournal = {Auton. Robot.},
  title        = {Hierarchical topometric representation of 3D robotic maps},
  volume       = {45},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Topological representation of cloth state for robot
manipulation. <em>AR</em>, <em>45</em>(5), 737–754. (<a
href="https://doi.org/10.1007/s10514-021-09968-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Forty years ago the notion of configuration space (C-space) revolutionised robot motion planning for rigid and articulated objects. Despite great progress, handling deformable materials has remained elusive because of their infinite-dimensional shape-state space. Finding low-complexity representations has become a pressing research goal. This work tries to make a tiny step in this direction by proposing a state representation for textiles relying on the C-space of some distinctive points. A stratification of the configuration space for n points in the cloth is derived from that of the flag manifold, and topological techniques to determine adjacencies in manipulation-centred state graphs are developed. Their algorithmic implementation permits obtaining cloth state–space representations of different granularities and tailored to particular purposes. An example of their usage to distinguish between cloth states having different manipulation affordances is provided. Suggestions on how the proposed state graphs can serve as a common ground to link the perception, planning and manipulation of textiles are also made.},
  archive      = {J_AR},
  author       = {Strazzeri, Fabio and Torras, Carme},
  doi          = {10.1007/s10514-021-09968-7},
  journal      = {Autonomous Robots},
  month        = {6},
  number       = {5},
  pages        = {737-754},
  shortjournal = {Auton. Robot.},
  title        = {Topological representation of cloth state for robot manipulation},
  volume       = {45},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A topological extension of movement primitives for curvature
modulation and sampling of robot motion. <em>AR</em>, <em>45</em>(5),
725–735. (<a href="https://doi.org/10.1007/s10514-021-09976-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes to enrich robot motion data with trajectory curvature information. To do so, we use an approximate implementation of a topological feature named writhe, which measures the curling of a closed curve around itself, and its analog feature for two closed curves, namely the linking number. Despite these features have been established for closed curves, their definition allows for a discrete calculation that is well-defined for non-closed curves and can thus provide information about how much a robot trajectory is curling around a line in space. Such lines can be predefined by a user, observed by vision or, in our case, inferred as virtual lines in space around which the robot motion is curling. We use these topological features to augment the data of a trajectory encapsulated as a Movement Primitive (MP). We propose a method to determine how many virtual segments best characterize a trajectory and then find such segments. This results in a generative model that permits modulating curvature to generate new samples, while still staying within the dataset distribution and being able to adapt to contextual variables.},
  archive      = {J_AR},
  author       = {Colomé, Adrià and Torras, Carme},
  doi          = {10.1007/s10514-021-09976-7},
  journal      = {Autonomous Robots},
  month        = {6},
  number       = {5},
  pages        = {725-735},
  shortjournal = {Auton. Robot.},
  title        = {A topological extension of movement primitives for curvature modulation and sampling of robot motion},
  volume       = {45},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Enhancing the morphological segmentation of microscopic
fossils through localized topology-aware edge detection. <em>AR</em>,
<em>45</em>(5), 709–723. (<a
href="https://doi.org/10.1007/s10514-020-09950-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fossil single-celled marine organisms known as foraminifera are widely used in oceanographic research. The identification of species is one of the most common tasks when analyzing ocean samples. One of the primary criteria for species identification is their morphology. Automatic segmentation of images of foraminifera would aid on the identification task as well as on other morphological studies. We pose this problem as an edge detection task for which capturing the correct topological structure is essential. Due to the presence of soft edges and even unclosed segments, state-of-the-art techniques have problems capturing the correct edge structure. Standard pixel-based loss functions are also sensitive to small deformations and shifts of the edges penalizing location more heavily than actual structure. Hence, we propose a homology-based detector of local structural difference between two edge maps with a tolerable deformation. This detector is employed as a new criterion for the training and design of data-driven approaches that focus on enhancing these structural differences. Our approaches demonstrate significant improvement on morphological segmentation of foraminifera when considering region-based and topology-based metrics. Human ranking of the quality of the results by marine researchers also supports these findings.},
  archive      = {J_AR},
  author       = {Ge, Qian and Richmond, Turner and Zhong, Boxuan and Marchitto, Thomas M. and Lobaton, Edgar J.},
  doi          = {10.1007/s10514-020-09950-9},
  journal      = {Autonomous Robots},
  month        = {6},
  number       = {5},
  pages        = {709-723},
  shortjournal = {Auton. Robot.},
  title        = {Enhancing the morphological segmentation of microscopic fossils through localized topology-aware edge detection},
  volume       = {45},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Motion planning for a pair of tethered robots. <em>AR</em>,
<em>45</em>(5), 693–707. (<a
href="https://doi.org/10.1007/s10514-021-09972-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Considering an environment containing polygonal obstacles, we address the problem of planning motions for a pair of planar robots connected to one another via a cable of limited length. Much like prior problems with a single robot connected via a cable to a fixed base, straight line-of-sight visibility plays an important role. The present paper shows how the reduced visibility graph provides a natural discretization and captures the essential topological considerations very effectively for the two robot case as well. Unlike the single robot case, however, the bounded cable length introduces considerations around coordination (or equivalently, when viewed from the point of view of a centralized planner, relative timing) that complicates the matter. Indeed, the paper has to introduce a rather more involved formalization than prior single-robot work in order to establish the core theoretical result—a theorem permitting the problem to be cast as one of finding paths rather than trajectories. Once affirmed, the planning problem reduces to a straightforward graph search with an elegant representation of the connecting cable, demanding only a few extra ancillary checks that ensure sufficiency of cable to guarantee feasibility of the solution. We describe our implementation of A $${}^\star $$ search, and report experimental results. Lastly, we prescribe an optimal execution for the solutions provided by the algorithm.},
  archive      = {J_AR},
  author       = {Teshnizi, Reza H. and Shell, Dylan A.},
  doi          = {10.1007/s10514-021-09972-x},
  journal      = {Autonomous Robots},
  month        = {6},
  number       = {5},
  pages        = {693-707},
  shortjournal = {Auton. Robot.},
  title        = {Motion planning for a pair of tethered robots},
  volume       = {45},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Decidability in robot manipulation planning. <em>AR</em>,
<em>45</em>(5), 679–692. (<a
href="https://doi.org/10.1007/s10514-020-09957-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Consider the problem of planning collision-free motion of n objects movable through contact with a robot that can autonomously translate in the plane and that can move a maximum of $$m \le n$$ objects simultaneously. This represents the abstract formulation of a general class of manipulation planning problems that are proven to be decidable in this paper. The tools used for proving decidability of this simplified manipulation planning problem are, in fact, general enough to handle the decidability problem for the wider class of systems characterized by a stratified configuration space. These include, e.g., problems of legged and multi-contact locomotion, bi-manual manipulation. In addition, the approach described does not restrict the dynamics of the manipulation system modeled.},
  archive      = {J_AR},
  author       = {Vendittelli, Marilena and Cristofaro, Andrea and Laumond, Jean-Paul and Mishra, Bud},
  doi          = {10.1007/s10514-020-09957-2},
  journal      = {Autonomous Robots},
  month        = {6},
  number       = {5},
  pages        = {679-692},
  shortjournal = {Auton. Robot.},
  title        = {Decidability in robot manipulation planning},
  volume       = {45},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An optimal property of the hyperplane system in a finite
cubing. <em>AR</em>, <em>45</em>(5), 665–677. (<a
href="https://doi.org/10.1007/s10514-020-09961-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Motivated by navigation and control problems in robotics, Ghrist and Peterson introduced a class of non-positively curved (NPC) cubical complexes arising as configuration spaces of reconfigurable systems, best regarded as discretized state space representations of embodied agents such as a multi-jointed robotic arm. In current real world applications, agents are increasingly required to respond autonomously to sensory input in order for them to contend with a priori unknown obstacles to navigation. In particular, the configuration spaces in question may not be known in advance. This motivates the following problem formulation: Given a NPC cubical complex $$\mathcal {C}$$ and a point-separating collection $$\varSigma $$ of Boolean queries on its 0-skeleton, $$\mathcal {C}^{(0)}$$ , find an efficient algorithm for learning $$\mathcal {C}$$ from the outputs provided by $$\varSigma $$ along an appropriately chosen path in $$\mathcal {C}$$ . In this note, we tackle the problem of identifying $$\mathcal {C}$$ when it is known that $$\mathcal {C}$$ is CAT(0). We show that the collection of canonical hyperplanes of $$\mathcal {C}$$ is the unique solution of a sub-modular minmax problem over the space of point-separating systems of Boolean queries on $$\mathcal {C}^{(0)}$$ , which may also be formulated in terms of the quadratic form associated with the graph Laplacian of $$\mathcal {C}^{(1)}$$ .},
  archive      = {J_AR},
  author       = {Guralnik, Dan and Ghrist, Robert},
  doi          = {10.1007/s10514-020-09961-6},
  journal      = {Autonomous Robots},
  month        = {6},
  number       = {5},
  pages        = {665-677},
  shortjournal = {Auton. Robot.},
  title        = {An optimal property of the hyperplane system in a finite cubing},
  volume       = {45},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Partial caging: A clearance-based definition, datasets, and
deep learning. <em>AR</em>, <em>45</em>(5), 647–664. (<a
href="https://doi.org/10.1007/s10514-021-09969-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Caging grasps limit the mobility of an object to a bounded component of configuration space. We introduce a notion of partial cage quality based on maximal clearance of an escaping path. As computing this is a computationally demanding task even in a two-dimensional scenario, we propose a deep learning approach. We design two convolutional neural networks and construct a pipeline for real-time planar partial cage quality estimation directly from 2D images of object models and planar caging tools. One neural network, CageMaskNN, is used to identify caging tool locations that can support partial cages, while a second network that we call CageClearanceNN is trained to predict the quality of those configurations. A partial caging dataset of 3811 images of objects and more than 19 million caging tool configurations is used to train and evaluate these networks on previously unseen objects and caging tool configurations. Experiments show that evaluation of a given configuration on a GeForce GTX 1080 GPU takes less than 6 ms. Furthermore, an additional dataset focused on grasp-relevant configurations is curated and consists of 772 objects with 3.7 million configurations. We also use this dataset for 2D Cage acquisition on novel objects. We study how network performance depends on the datasets, as well as how to efficiently deal with unevenly distributed training data. In further analysis, we show that the evaluation pipeline can approximately identify connected regions of successful caging tool placements and we evaluate the continuity of the cage quality score evaluation along caging tool trajectories. Influence of disturbances is investigated and quantitative results are provided.},
  archive      = {J_AR},
  author       = {Welle, Michael C. and Varava, Anastasiia and Mahler, Jeffrey and Goldberg, Ken and Kragic, Danica and Pokorny, Florian T.},
  doi          = {10.1007/s10514-021-09969-6},
  journal      = {Autonomous Robots},
  month        = {6},
  number       = {5},
  pages        = {647-664},
  shortjournal = {Auton. Robot.},
  title        = {Partial caging: A clearance-based definition, datasets, and deep learning},
  volume       = {45},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Topological navigation graph framework. <em>AR</em>,
<em>45</em>(5), 633–646. (<a
href="https://doi.org/10.1007/s10514-021-09980-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we focus on the utilisation of reactive trajectory imitation controllers for goal-directed visual navigation in mobile robotics. We propose topological navigation graph (TNG) framework. TNG is an imitation-learning-based topological navigation framework for navigating through environments with intersecting trajectories. It represents the environment as a directed graph composed of perception and action modules. Each vertex of the graph corresponds to a trajectory and is represented by a trajectory identification classifier and a trajectory imitation controller. The edges of TNG correspond to intersections between trajectories and are represented by trajectory intersection recognition classifiers. Having a visually specified goal state, TNG navigates by forming a sequential composition plan of trajectory imitation controllers. We also propose to apply neural object detection architectures for the task of trajectory following by detecting direction of movement. We provide empirical evaluation of the proposed navigation framework and its components both in simulated and real-world environments and demonstrate that TNG allows us to utilise non-goal-directed, imitation-learning methods for goal-directed autonomous navigation.},
  archive      = {J_AR},
  author       = {Daniušis, Povilas and Juneja, Shubham and Valatka, Lukas and Petkevičius, Linas},
  doi          = {10.1007/s10514-021-09980-x},
  journal      = {Autonomous Robots},
  month        = {6},
  number       = {5},
  pages        = {633-646},
  shortjournal = {Auton. Robot.},
  title        = {Topological navigation graph framework},
  volume       = {45},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Herding by caging: A formation-based motion planning
framework for guiding mobile agents. <em>AR</em>, <em>45</em>(5),
613–631. (<a href="https://doi.org/10.1007/s10514-021-09975-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a solution to the problem of herding by caging: given a set of mobile robots (called herders) and a group of moving agents (called sheep), we guide the sheep to a target location without letting them escape from the herders along the way. We model the interaction between the herders and the sheep by defining virtual “repulsive forces” pushing the sheep away from the herders. This enables the herders to partially control the motion of the sheep. We formalize this behavior topologically by applying the notion of caging, a concept used in robotic manipulation. We demonstrate that our approach is provably correct in the sense that the sheep cannot escape from the robots under our assumed motion model. We propose an RRT-based path planning algorithm for herding by caging, demonstrate its probabilistic completeness, and evaluate it in simulations as well as on a group of real mobile robots.},
  archive      = {J_AR},
  author       = {Song, Haoran and Varava, Anastasiia and Kravchenko, Oleksandr and Kragic, Danica and Wang, Michael Yu and Pokorny, Florian T. and Hang, Kaiyu},
  doi          = {10.1007/s10514-021-09975-8},
  journal      = {Autonomous Robots},
  month        = {6},
  number       = {5},
  pages        = {613-631},
  shortjournal = {Auton. Robot.},
  title        = {Herding by caging: A formation-based motion planning framework for guiding mobile agents},
  volume       = {45},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Guest editorial: Special issue on “topological methods in
robotics.” <em>AR</em>, <em>45</em>(5), 611–612. (<a
href="https://doi.org/10.1007/s10514-021-09989-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_AR},
  author       = {Bhattacharya, Subhrajit and Pokorny, Florian T. and Choset, Howie},
  doi          = {10.1007/s10514-021-09989-2},
  journal      = {Autonomous Robots},
  month        = {6},
  number       = {5},
  pages        = {611-612},
  shortjournal = {Auton. Robot.},
  title        = {Guest editorial: Special issue on “Topological methods in robotics”},
  volume       = {45},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A novel adaptive iterative learning control approach and
human-in-the-loop control pattern for lower limb rehabilitation robot in
disturbances environment. <em>AR</em>, <em>45</em>(4), 595–610. (<a
href="https://doi.org/10.1007/s10514-021-09988-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article presents a novel adaptive iterative learning control (AILC), and designs a human-in-loop control pattern (HIL-CP), which simulates the proposed approach using different lower limb rehabilitation robot models. The stability of the AILC controller is proposed and verified via a Lyapunov-like function, where novel controller shows strong robustness in disturbances environment. Based on AILC, the core of the HIL-CP interactive control mode is to estimate the human surface electromyography by neural network model and get the real-time desired trajectory to iterate out the optimal actual tracking trajectory, which reduce the tracking error quickly and ensure the rehabilitation training effect of patients. Furthermore, the MATLAB software is employed to conduct simulation experiments the proposed approach. The simulation results show that the HIL-CP is highly efficient and rapidly convergent in a satisfied degree. The angle error is $${\mathrm{{0.25}}^\text {o}}\pm {\mathrm{{0.2}}^\text {o}} $$ for patients and $${\mathrm{{0.03}}^\text {o}}\pm {\mathrm{{0.02}}^\text {o}} $$ for healthy people. Compared with the existing sliding mode controller, it is proven that the AILC controller is much more effective and noise-tolerant ability in the presence of bounded nonlinear disturbance.},
  archive      = {J_AR},
  author       = {Sun, Zhongbo and Li, Feng and Duan, Xiaoqin and Jin, Long and Lian, Yufeng and Liu, Shuaishi and Liu, Keping},
  doi          = {10.1007/s10514-021-09988-3},
  journal      = {Autonomous Robots},
  month        = {5},
  number       = {4},
  pages        = {595-610},
  shortjournal = {Auton. Robot.},
  title        = {A novel adaptive iterative learning control approach and human-in-the-loop control pattern for lower limb rehabilitation robot in disturbances environment},
  volume       = {45},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Robot-to-robot relative pose estimation using humans as
markers. <em>AR</em>, <em>45</em>(4), 579–593. (<a
href="https://doi.org/10.1007/s10514-021-09985-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a method to determine the 3D relative pose of pairs of communicating robots by using human pose-based key-points as correspondences. We adopt a ‘leader-follower’ framework, where at first, the leader robot visually detects and triangulates the key-points using the state-of-the-art pose detector named OpenPose. Afterward, the follower robots match the corresponding 2D projections on their respective calibrated cameras and find their relative poses by solving the perspective-n-point (PnP) problem. In the proposed method, we design an efficient person re-identification technique for associating the mutually visible humans in the scene. Additionally, we present an iterative optimization algorithm to refine the associated key-points based on their local structural properties in the image space. We demonstrate that these refinement processes are essential to establish accurate key-point correspondences across viewpoints. Furthermore, we evaluate the performance of the proposed relative pose estimation system through several experiments conducted in terrestrial and underwater environments. Finally, we discuss the relevant operational challenges of this approach and analyze its feasibility for multi-robot cooperative systems in human-dominated social settings and feature-deprived environments such as underwater.},
  archive      = {J_AR},
  author       = {Islam, Md Jahidul and Mo, Jiawei and Sattar, Junaed},
  doi          = {10.1007/s10514-021-09985-6},
  journal      = {Autonomous Robots},
  month        = {5},
  number       = {4},
  pages        = {579-593},
  shortjournal = {Auton. Robot.},
  title        = {Robot-to-robot relative pose estimation using humans as markers},
  volume       = {45},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). How to train your differentiable filter. <em>AR</em>,
<em>45</em>(4), 561–578. (<a
href="https://doi.org/10.1007/s10514-021-09990-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In many robotic applications, it is crucial to maintain a belief about the state of a system, which serves as input for planning and decision making and provides feedback during task execution. Bayesian Filtering algorithms address this state estimation problem, but they require models of process dynamics and sensory observations and the respective noise characteristics of these models. Recently, multiple works have demonstrated that these models can be learned by end-to-end training through differentiable versions of recursive filtering algorithms. In this work, we investigate the advantages of differentiable filters (DFs) over both unstructured learning approaches and manually-tuned filtering algorithms, and provide practical guidance to researchers interested in applying such differentiable filters. For this, we implement DFs with four different underlying filtering algorithms and compare them in extensive experiments. Specifically, we (i) evaluate different implementation choices and training approaches, (ii) investigate how well complex models of uncertainty can be learned in DFs, (iii) evaluate the effect of end-to-end training through DFs and (iv) compare the DFs among each other and to unstructured LSTM models.},
  archive      = {J_AR},
  author       = {Kloss, Alina and Martius, Georg and Bohg, Jeannette},
  doi          = {10.1007/s10514-021-09990-9},
  journal      = {Autonomous Robots},
  month        = {5},
  number       = {4},
  pages        = {561-578},
  shortjournal = {Auton. Robot.},
  title        = {How to train your differentiable filter},
  volume       = {45},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Sensor fusion of two sonar devices for underwater 3D mapping
with an AUV. <em>AR</em>, <em>45</em>(4), 543–560. (<a
href="https://doi.org/10.1007/s10514-021-09986-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present herein a three-dimensional (3D) mapping method in one-way rectilinear scanning with an autonomous underwater vehicle (AUV) equipped with a forward looking sonar (FLS) and a profiling sonar (PS). Three-dimensional reconstruction using sonar with a finite beam width is an ill-posed problem, and additional constraints also need to be considered. Our approach involves an additional sonar and fuse acoustic measurements provided by the two sonar sensors. The FLS has a high resolution in the horizontal scan but has a uncertainty in the vertical scan. Meanwhile, the PS provides a reliable vertical profile, but its beam width is extremely narrow. An initial map is generated by the FLS and refined by combining the PS vertical scan data. To demonstrate the validity and effectiveness of the proposed method, we conducted tests in a water tank and also at sea. Finally, we presented the results of the proposed method gathered by an AUV in the tests.},
  archive      = {J_AR},
  author       = {Joe, Hangil and Cho, Hyeonwoo and Sung, Minsung and Kim, Jinwhan and Yu, Son-cheol},
  doi          = {10.1007/s10514-021-09986-5},
  journal      = {Autonomous Robots},
  month        = {5},
  number       = {4},
  pages        = {543-560},
  shortjournal = {Auton. Robot.},
  title        = {Sensor fusion of two sonar devices for underwater 3D mapping with an AUV},
  volume       = {45},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Transfer learning of coverage functions via invariant
properties in the fourier domain. <em>AR</em>, <em>45</em>(4), 519–542.
(<a href="https://doi.org/10.1007/s10514-021-09982-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The robotics community has been paying more attention to coverage functions due to their variant applications (e.g., spatial search and mapping, etc.). Due to their submodularity, greedy algorithms can find solutions with theoretical guarantees for maximizing coverage problems even if these problems are NP-hard. However, learning coverage functions is still a challenging problem since the number of function outcome for N sets is $$2^N$$ . Moreover, transfer learning of coverage functions is unexplored. This research focuses on the transfer learning of coverage functions via utilizing the invariant properties in the Fourier domain. The proposed algorithms based on these properties can construct Fourier support for learning coverage functions. Experiments conducted with these algorithms show that the robot can learn the coverage functions using less samples than the prior learning approaches in different environments. Experiments also show that the lossless compression rate of the proposed algorithms is up to 40 billion.},
  archive      = {J_AR},
  author       = {Tseng, Kuo-Shih},
  doi          = {10.1007/s10514-021-09982-9},
  journal      = {Autonomous Robots},
  month        = {5},
  number       = {4},
  pages        = {519-542},
  shortjournal = {Auton. Robot.},
  title        = {Transfer learning of coverage functions via invariant properties in the fourier domain},
  volume       = {45},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Sequence-based visual place recognition: A scale-space
approach for boundary detection. <em>AR</em>, <em>45</em>(4), 505–518.
(<a href="https://doi.org/10.1007/s10514-021-09984-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the field of visual Place Recognition (vPR), sequence-based techniques have received close attention since they combine visual information from multiple measurements to enhance the results. This paper is concerned with the task of identifying sequence boundaries, corresponding to physical scene limits of the robot’s trajectory, that can potentially be re-encountered during an autonomous mission. In contrast to other vPR techniques that select a predefined length for all the image sequences, our approach focuses on a dynamic segmentation and allows for the visual information to be consistently grouped between different visits of the same area. To achieve this, we compute similarity measurements between consecutively acquired frames to incrementally formulate a similarity signal. Then, local extrema are detected in the Scale-Space domain regardless the velocity that a camera travels and perceives the world. Accounting for any detection inconsistencies, we explore asynchronous sequence-based techniques and a novel weighted temporal consistency scheme that strengthens the performance. Our dynamically computed sequence segmentation is tested on two different vPR methods offering an improvement in the systems’ accuracy.},
  archive      = {J_AR},
  author       = {Bampis, Loukas and Gasteratos, Antonios},
  doi          = {10.1007/s10514-021-09984-7},
  journal      = {Autonomous Robots},
  month        = {5},
  number       = {4},
  pages        = {505-518},
  shortjournal = {Auton. Robot.},
  title        = {Sequence-based visual place recognition: A scale-space approach for boundary detection},
  volume       = {45},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Semantic visual SLAM in dynamic environment. <em>AR</em>,
<em>45</em>(4), 493–504. (<a
href="https://doi.org/10.1007/s10514-021-09979-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human-computer interaction requires accurate localization and effective mapping, while dynamic objects can influence the accuracy of localization and mapping. State-of-the-art SLAM algorithms assume that the environment is static. This paper proposes a new SLAM method that uses mask R-CNN to detect dynamic ob-jects in the environment and build a map containing semantic information. In our method, the reprojection error, photometric error and depth error are used to assign a robust weight to each keypoint. Thus, the dynamic points and the static points can be separated, and the geometric segmentation of the dynamic objects can be realized by using the dynamic keypoints. Each pixel is assigned a semantic label to rebuild a semantic map. Finally, our proposed method is tested on the TUM RGB-D dataset, and the experimental results show that the proposed method outperforms state-of-the-art SLAM algorithms in dynamic environments.},
  archive      = {J_AR},
  author       = {Wen, Shuhuan and Li, Pengjiang and Zhao, Yongjie and Zhang, Hong and Sun, Fuchun and Wang, Zhe},
  doi          = {10.1007/s10514-021-09979-4},
  journal      = {Autonomous Robots},
  month        = {5},
  number       = {4},
  pages        = {493-504},
  shortjournal = {Auton. Robot.},
  title        = {Semantic visual SLAM in dynamic environment},
  volume       = {45},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A fully distributed multi-robot navigation method without
pre-allocating target positions. <em>AR</em>, <em>45</em>(4), 473–492.
(<a href="https://doi.org/10.1007/s10514-021-09981-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study focuses on the multi-robot navigation problem with unpredictable state transition disturbance. The primary goal is to construct a fully distributed multi-robot navigation method without pre-allocating target positions. To this aim, a reinforcement learning based method is presented, in which a distribution of state transition module is proposed to guarantee adaptiveness when trained policies are applied in physical multi-robot systems. The method incorporates a centralized training but fully distributed execution framework. The former can eliminate non-stationarity of the environment, and the latter enables the robots to collaboratively handle partially observable scenarios. Mean while, the designed reward function can guide the robots to approach not pre-allocated target positions and the nearly optimal trajectories are achieved in continuous environment. After training, the robots make decisions independently, coordinate, and cooperate with each other to determine the next actions from their current positions before arriving in target positions without pre-allocation, in which the trajectories are nearly optimal with partial observation available for each robot. Simulations are performed with increasingly complex environments, such as the addition of static obstacles and randomly moving obstacles. The results show that the robots are able to achieve the primary goal with different state transition disturbance, which demonstrates the feasibility, effectiveness, and robustness. Furthermore, experiments are carried out using our multi-robot system corresponding to the simulation. The experimental results demonstrate the effectiveness and robustness of the proposed navigation method to handle a variety of typical robotic scenarios.},
  archive      = {J_AR},
  author       = {Zhang, Jingtao and Xu, Zhipeng and Yu, Fangchao and Tang, Qirong},
  doi          = {10.1007/s10514-021-09981-w},
  journal      = {Autonomous Robots},
  month        = {5},
  number       = {4},
  pages        = {473-492},
  shortjournal = {Auton. Robot.},
  title        = {A fully distributed multi-robot navigation method without pre-allocating target positions},
  volume       = {45},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A new meta-module design for efficient reconfiguration of
modular robots. <em>AR</em>, <em>45</em>(4), 457–472. (<a
href="https://doi.org/10.1007/s10514-021-09977-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a new meta-module design for two important classes of modular robots. The new meta-modules are three-dimensional, robust and compact, improving on the previously proposed ones. One of them applies to so-called edge-hinged modular robot units, such as M-TRAN, SuperBot, SMORES, UBot, PolyBot and CKBot, while the other one applies to so-called central-point-hinged modular robot units, which include Molecubes and Roombots. The new meta-modules use the rotational degrees of freedom of these two types of robot units in order to expand and contract, as to double or halve their length in each of the two directions of its three dimensions, therefore simulating the capabilities of Crystalline and Telecube robots. Furthermore, in the edge-hinged case we prove that the novel meta-module can also perform the scrunch, relax and transfer moves that are necessary in any tunneling-based reconfiguration algorithm for expanding/contracting modular robots such as Crystalline and Telecube. This implies that the use of meta-meta-modules is unnecessary, and that currently existing efficient reconfiguration algorithms can be applied to a much larger set of modular robots than initially intended. We also prove that the size of the new meta-modules is optimal and cannot be further reduced.},
  archive      = {J_AR},
  author       = {Parada, Irene and Sacristán, Vera and Silveira, Rodrigo I.},
  doi          = {10.1007/s10514-021-09977-6},
  journal      = {Autonomous Robots},
  month        = {5},
  number       = {4},
  pages        = {457-472},
  shortjournal = {Auton. Robot.},
  title        = {A new meta-module design for efficient reconfiguration of modular robots},
  volume       = {45},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A behavior-based framework for safe deployment of humanoid
robots. <em>AR</em>, <em>45</em>(4), 435–456. (<a
href="https://doi.org/10.1007/s10514-021-09978-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a complete framework for the safe deployment of humanoid robots in environments containing humans. Proceeding from some general guidelines, we propose several safety behaviors, classified in three categories, i.e., override, temporary override, and proactive. Activation and deactivation of these behaviors is triggered by information coming from the robot sensors and is handled by a state machine. The implementation of our safety framework is discussed with respect to a reference control architecture. In particular, it is shown that an MPC-based gait generator is ideal for realizing all behaviors related to locomotion. Simulation and experimental results on the HRP-4 and NAO humanoids, respectively, are presented to confirm the effectiveness of the proposed method.},
  archive      = {J_AR},
  author       = {Scianca, Nicola and Ferrari, Paolo and De Simone, Daniele and Lanari, Leonardo and Oriolo, Giuseppe},
  doi          = {10.1007/s10514-021-09978-5},
  journal      = {Autonomous Robots},
  month        = {5},
  number       = {4},
  pages        = {435-456},
  shortjournal = {Auton. Robot.},
  title        = {A behavior-based framework for safe deployment of humanoid robots},
  volume       = {45},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Effect of compliance on morphological control of dynamic
locomotion with HyQ. <em>AR</em>, <em>45</em>(3), 421–434. (<a
href="https://doi.org/10.1007/s10514-021-09974-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Classic control theory applied to compliant and soft robots generally involves an increment of computation that has no equivalent in biology. To tackle this, morphological computation describes a theoretical framework that takes advantage of the computational capabilities of physical bodies. However, concrete applications in robotic locomotion control are still rare. Also, the trade-off between compliance and the capacity of a physical body to facilitate its own control has not been thoroughly studied in a real locomotion task. In this paper, we address these two problems on the state-of-the-art hydraulic robot HyQ. An end-to-end neural network is trained to control HyQ’s joints positions and velocities using only Ground Reaction Forces. Our simulations and experiments demonstrate better controllability using less memory and computational resources when increasing compliance. However, we show empirically that this effect cannot be attributed to the ability of the body to perform intrinsic computation. It invites to give an increased emphasis on compliance and co-design of the controller and the robot to facilitate attempts in machine learning locomotion.},
  archive      = {J_AR},
  author       = {Urbain, Gabriel and Barasuol, Victor and Semini, Claudio and Dambre, Joni and wyffels, Francis},
  doi          = {10.1007/s10514-021-09974-9},
  journal      = {Autonomous Robots},
  month        = {3},
  number       = {3},
  pages        = {421-434},
  shortjournal = {Auton. Robot.},
  title        = {Effect of compliance on morphological control of dynamic locomotion with HyQ},
  volume       = {45},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Scale-invariant localization using quasi-semantic object
landmarks. <em>AR</em>, <em>45</em>(3), 407–420. (<a
href="https://doi.org/10.1007/s10514-021-09973-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work presents Object Landmarks, a new type of visual feature designed for visual localization over major changes in distance and scale. An Object Landmark consists of a bounding box $${\mathbf {b}}$$ defining an object, a descriptor $${\mathbf {q}}$$ of that object produced by a Convolutional Neural Network, and a set of classical point features within $${\mathbf {b}}$$ . We evaluate Object Landmarks on visual odometry and place-recognition tasks, and compare them against several modern approaches. We find that Object Landmarks enable superior localization over major scale changes, reducing error by as much as 18% and increasing robustness to failure by as much as 80% versus the state-of-the-art. They allow localization under scale change factors up to 6, where state-of-the-art approaches break down at factors of 3 or more.},
  archive      = {J_AR},
  author       = {Holliday, Andrew and Dudek, Gregory},
  doi          = {10.1007/s10514-021-09973-w},
  journal      = {Autonomous Robots},
  month        = {3},
  number       = {3},
  pages        = {407-420},
  shortjournal = {Auton. Robot.},
  title        = {Scale-invariant localization using quasi-semantic object landmarks},
  volume       = {45},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Imitation learning-based framework for learning 6-d linear
compliant motions. <em>AR</em>, <em>45</em>(3), 389–405. (<a
href="https://doi.org/10.1007/s10514-021-09971-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a novel method for learning from demonstration 6-D tasks that can be modeled as a sequence of linear motions and compliances. The focus of this paper is the learning of a single linear primitive, many of which can be sequenced to perform more complex tasks. The presented method learns from demonstrations how to take advantage of mechanical gradients in in-contact tasks, such as assembly, both for translations and rotations, without any prior information. The method assumes there exists a desired linear direction in 6-D which, if followed by the manipulator, leads the robot’s end-effector to the goal area shown in the demonstration, either in free space or by leveraging contact through compliance. First, demonstrations are gathered where the teacher explicitly shows the robot how the mechanical gradients can be used as guidance towards the goal. From the demonstrations, a set of directions is computed which would result in the observed motion at each timestep during a demonstration of a single primitive. By observing which direction is included in all these sets, we find a single desired direction which can reproduce the demonstrated motion. Finding the number of compliant axes and their directions in both rotation and translation is based on the assumption that in the presence of a desired direction of motion, all other observed motion is caused by the contact force of the environment, signalling the need for compliance. We evaluate the method on a KUKA LWR4+ robot with test setups imitating typical tasks where a human would use compliance to cope with positional uncertainty. Results show that the method can successfully learn and reproduce compliant motions by taking advantage of the geometry of the task, therefore reducing the need for localization accuracy.},
  archive      = {J_AR},
  author       = {Suomalainen, Markku and Abu-dakka, Fares J. and Kyrki, Ville},
  doi          = {10.1007/s10514-021-09971-y},
  journal      = {Autonomous Robots},
  month        = {3},
  number       = {3},
  pages        = {389-405},
  shortjournal = {Auton. Robot.},
  title        = {Imitation learning-based framework for learning 6-D linear compliant motions},
  volume       = {45},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Sensorless environment stiffness and interaction force
estimation for impedance control tuning in robotized interaction tasks.
<em>AR</em>, <em>45</em>(3), 371–388. (<a
href="https://doi.org/10.1007/s10514-021-09970-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Industrial robots are increasingly used to perform tasks requiring an interaction with the surrounding environment (e.g., assembly tasks). Such environments are usually (partially) unknown to the robot, requiring the implemented controllers to suitably react to the established interaction. Standard controllers require force/torque measurements to close the loop. However, most of the industrial manipulators do not have embedded force/torque sensor(s) and such integration results in additional costs and implementation effort. To extend the use of compliant controllers to sensorless interaction control, a model-based methodology is presented in this paper. Relying on sensorless Cartesian impedance control, two Extended Kalman Filters (EKF) are proposed: an EKF for interaction force estimation and an EKF for environment stiffness estimation. Exploiting such estimations, a control architecture is proposed to implement a sensorless force loop (exploiting the provided estimated force) with adaptive Cartesian impedance control and coupling dynamics compensation (exploiting the provided estimated environment stiffness). The described approach has been validated in both simulations and experiments. A Franka EMIKA panda robot has been used. A probing task involving different materials (i.e., with different - unknown - stiffness properties) has been considered to show the capabilities of the developed EKFs (able to converge with limited errors) and control tuning (preserving stability). Additionally, a polishing-like task and an assembly task have been implemented to show the achieved performance of the proposed methodology.},
  archive      = {J_AR},
  author       = {Roveda, Loris and Piga, Dario},
  doi          = {10.1007/s10514-021-09970-z},
  journal      = {Autonomous Robots},
  month        = {3},
  number       = {3},
  pages        = {371-388},
  shortjournal = {Auton. Robot.},
  title        = {Sensorless environment stiffness and interaction force estimation for impedance control tuning in robotized interaction tasks},
  volume       = {45},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Reliable distribution of computational load in robot teams.
<em>AR</em>, <em>45</em>(3), 351–369. (<a
href="https://doi.org/10.1007/s10514-021-09967-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modern multi-robot systems often need to solve computationally intensive tasks but operate with limited compute resources and in the presence of failures. Cooperating to share computational tasks between robots at the edge reduces execution time. We introduce and evaluate a new computation load management technology for teams of robots: Reliable Autonomous Mobile Programs (RAMPs). RAMPs use information about the computational resources available in the team and a cost model to decide where to execute. RAMPs are implemented in ROS on a collection of Raspberry Pi-based robots. The performance of RAMPs is evaluated using route planning, a typical computationally-intensive robotics application. A systematic study of RAMPs demonstrates a high likelihood of optimal or near-optimal distribution and hence efficient resource utilisation. RAMPs successfully complete in the presence of simultaneous, or successive, robot failures and network failures, while preserving near-optimal distribution.},
  archive      = {J_AR},
  author       = {Valkov, Ivan and Trinder, Phil and Chechina, Natalia},
  doi          = {10.1007/s10514-021-09967-8},
  journal      = {Autonomous Robots},
  month        = {3},
  number       = {3},
  pages        = {351-369},
  shortjournal = {Auton. Robot.},
  title        = {Reliable distribution of computational load in robot teams},
  volume       = {45},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Deep learning applied to humanoid soccer robotics: Playing
without using any color information. <em>AR</em>, <em>45</em>(3),
335–350. (<a href="https://doi.org/10.1007/s10514-021-09966-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The goal of this paper is to describe a vision system for humanoid robot soccer players that does not use any color information, and whose object detectors are based on the use of convolutional neural networks. The main features of this system are the following: (i) real-time operation in computationally constrained humanoid robots, and (ii) the ability to detect the ball, the pose of the robot players, as well as the goals, lines and other key field features robustly. The proposed vision system is validated in the RoboCup Standard Platform League, where humanoid NAO robots are used. Tests are carried out under realistic and highly demanding game conditions, where very high performance is obtained: a robot detection accuracy of 94.90%, a ball detection accuracy of 97.10%, and a correct determination of the robot orientation 99.88% of the times when the observed robot is static, and 95.52% when the robot is moving.},
  archive      = {J_AR},
  author       = {Cruz, Nicolás and Leiva, Francisco and Ruiz-del-Solar, Javier},
  doi          = {10.1007/s10514-021-09966-9},
  journal      = {Autonomous Robots},
  month        = {3},
  number       = {3},
  pages        = {335-350},
  shortjournal = {Auton. Robot.},
  title        = {Deep learning applied to humanoid soccer robotics: Playing without using any color information},
  volume       = {45},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A sketch is worth a thousand navigational instructions.
<em>AR</em>, <em>45</em>(2), 313–333. (<a
href="https://doi.org/10.1007/s10514-020-09965-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Is it possible for a robot to navigate an unknown area without the ability to understand verbal instructions? This work proposes the use of pictorial cues (hand drawn sketches) to assist navigation in scenarios where verbal instructions seem less practical. These scenarios include verbal instructions referring to novel objects or complex instructions describing fine details. Furthermore, there are patterns (textures, languages) which are difficult to describe verbally. Given a single sketch, our novel “draw in 2D and match in 3D” algorithm spots the desired content under large view variations. We show that off-the-shelf deep features, for sketch matching, have limited view point invariance. Additionally, this work exposes the challenges of using the scene text as a pictorial cue. We propose a novel strategy to overcome these challenges across multiple languages. Our “just draw it” method overcomes the language understanding barrier. We show that sketch based text spotting works, without alteration, for arbitrary font shapes, which standard text detectors find hard to spot. Even in case of custom made text detector (for arbitrary shaped fonts), sketch based text spotting demonstrates complimentary performance. We provide extensive evaluation on public datasets. We also provide a fine grained dataset “Crossroads” which includes tough scenarios for generating navigational instructions. Finally we demonstrate the performance of our view invariant sketch detectors in robotic navigation scenarios using MINOS simulator which contains reconstructed indoor environments.},
  archive      = {J_AR},
  author       = {Ahmad, Haseeb and Usama, Sardar Muhammad and Hussain, Wajahat and Anjum, Muhammad Latif},
  doi          = {10.1007/s10514-020-09965-2},
  journal      = {Autonomous Robots},
  month        = {2},
  number       = {2},
  pages        = {313-333},
  shortjournal = {Auton. Robot.},
  title        = {A sketch is worth a thousand navigational instructions},
  volume       = {45},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Road surface detection and differentiation considering
surface damages. <em>AR</em>, <em>45</em>(2), 299–312. (<a
href="https://doi.org/10.1007/s10514-020-09964-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A challenge still to be overcome in the field of visual perception for vehicle and robotic navigation on heavily damaged and unpaved roads is the task of reliable path and obstacle detection. The vast majority of the researches have scenario roads in good condition, from developed countries. These works cope with few situations of variation on the road surface and even fewer situations presenting surface damages. In this paper we present an approach for road detection considering variation in surface types, identifying paved and unpaved surfaces and also detecting damage and other information on other road surfaces that may be relevant to driving safety. Our approach makes use of Convolutional Neural Networks (CNN) to perform semantic segmentation, we use the U-NET architecture with ResNet34, in addition we use the technique known as Transfer Learning, where we first train a CNN model without using weights in the classes as a basis for a second CNN model where we use weights for each class. We also present a new Ground Truth with image segmentation, used in our approach and that allowed us to evaluate our results. Our results show that it is possible to use passive vision for these purposes, even using images captured with low cost cameras.},
  archive      = {J_AR},
  author       = {Rateke, Thiago and von Wangenheim, Aldo},
  doi          = {10.1007/s10514-020-09964-3},
  journal      = {Autonomous Robots},
  month        = {2},
  number       = {2},
  pages        = {299-312},
  shortjournal = {Auton. Robot.},
  title        = {Road surface detection and differentiation considering surface damages},
  volume       = {45},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Game tree search for minimizing detectability and maximizing
visibility. <em>AR</em>, <em>45</em>(2), 283–297. (<a
href="https://doi.org/10.1007/s10514-020-09963-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce and study the problem of planning a trajectory for an agent to carry out a scouting mission while avoiding being detected by an adversarial opponent. This introduces a multi-objective version of classical visibility-based target search and pursuit-evasion problem. In our formulation, the agent receives a positive reward for increasing its visibility (by exploring new regions) and a negative penalty every time it is detected by the opponent. The objective is to find a finite-horizon path for the agent that balances the trade off between maximizing visibility and minimizing detectability. We model this problem as a discrete, sequential, two-player, zero-sum game. We use two types of game tree search algorithms to solve this problem: minimax search tree and Monte-Carlo search tree. Both search trees can yield the optimal policy but may require possibly exponential computational time and space. We first propose three pruning techniques to reduce the computational time while preserving optimality guarantees. When the agent and the opponent are located far from each other initially, we present a variable resolution technique with longer planning horizon to further reduce computational time. Simulation results show the effectiveness of the proposed strategies in terms of computational time.},
  archive      = {J_AR},
  author       = {Zhang, Zhongshun and Smereka, Jonathon M. and Lee, Joseph and Zhou, Lifeng and Sung, Yoonchang and Tokekar, Pratap},
  doi          = {10.1007/s10514-020-09963-4},
  journal      = {Autonomous Robots},
  month        = {2},
  number       = {2},
  pages        = {283-297},
  shortjournal = {Auton. Robot.},
  title        = {Game tree search for minimizing detectability and maximizing visibility},
  volume       = {45},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Robust circumnavigation of a heterogeneous multi-agent
system. <em>AR</em>, <em>45</em>(2), 265–281. (<a
href="https://doi.org/10.1007/s10514-020-09962-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper focuses on the design of robust control laws for a heterogeneous multi-agent system composed of omnidirectional and differential-drive mobile robots under the leader–follower scheme and considering the distance and orientation measurements. It is assume that the agent leader is an omnidirectional mobile robot moving freely in the plane while the rest of the agents are the followers. The control laws are designed by means of the Backstepping approach. It is proved that, although the control laws do not need information about the velocity of the leader, the followers will circumnavigate the leader. Numerical simulations and real-time experiments exhibit the performance of the proposed control strategy.},
  archive      = {J_AR},
  author       = {González-Sierra, Jaime and Flores-Montes, Daniel and Hernandez-Martinez, Eduardo Gamaliel and Fernández-Anaya, Guillermo and Paniagua-Contro, Pablo},
  doi          = {10.1007/s10514-020-09962-5},
  journal      = {Autonomous Robots},
  month        = {2},
  number       = {2},
  pages        = {265-281},
  shortjournal = {Auton. Robot.},
  title        = {Robust circumnavigation of a heterogeneous multi-agent system},
  volume       = {45},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A hierarchical representation of behaviour supporting open
ended development and progressive learning for artificial agents.
<em>AR</em>, <em>45</em>(2), 245–264. (<a
href="https://doi.org/10.1007/s10514-020-09960-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the challenging aspects of open ended or lifelong agent development is that the final behaviour for which an agent is trained at a given moment can be an element for the future creation of one, or even several, behaviours of greater complexity, whose purpose cannot be anticipated. In this paper, we present modular influence network design (MIND), an artificial agent control architecture suited to open ended and cumulative learning. The MIND architecture encapsulates sub behaviours into modules and combines them into a hierarchy reflecting the modular and hierarchical nature of complex tasks. Compared to similar research, the main original aspect of MIND is the multi layered hierarchy using a generic control signal, the influence, to obtain an efficient global behaviour. This article shows the ability of MIND to learn a curriculum of independent didactic tasks of increasing complexity covering different aspects of a desired behaviour. In so doing we demonstrate the contributions of MIND to open-ended development: encapsulation into modules allows for the preservation and re-usability of all the skills acquired during the curriculum and their focused retraining, the modular structure serves the evolving topology by easing the coordination of new sensors, actuators and heterogeneous learning structures.},
  archive      = {J_AR},
  author       = {Suro, François and Ferber, Jacques and Stratulat, Tiberiu and Michel, Fabien},
  doi          = {10.1007/s10514-020-09960-7},
  journal      = {Autonomous Robots},
  month        = {2},
  number       = {2},
  pages        = {245-264},
  shortjournal = {Auton. Robot.},
  title        = {A hierarchical representation of behaviour supporting open ended development and progressive learning for artificial agents},
  volume       = {45},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An improved kinematic model for skid-steered wheeled
platforms. <em>AR</em>, <em>45</em>(2), 229–243. (<a
href="https://doi.org/10.1007/s10514-020-09959-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dead reckoning in wheeled mobile platforms is a method that uses the kinematic model of the platforms to estimate their pose from the integration of the wheels’ motion. Due to its integrative principle, this method is very sensitive to modeling and measurement errors. Skid-steering platforms are no exception to this and although linear motions can be very well modeled, skid-based rotations depend on a number of factors, including the type of terrain and the location of the center of mass of the platforms, which are disregarded in conventional kinematic models. This article describes an improved kinematic model that takes these factors into account and verifies the model in a variety of working conditions, including different terrains and asymmetric loads, for two different wheeled skid-steered platforms. The obtained results show significant improvements in odometry performance using the proposed model in comparison to conventional approaches.},
  archive      = {J_AR},
  author       = {Dogru, Sedat and Marques, Lino},
  doi          = {10.1007/s10514-020-09959-0},
  journal      = {Autonomous Robots},
  month        = {2},
  number       = {2},
  pages        = {229-243},
  shortjournal = {Auton. Robot.},
  title        = {An improved kinematic model for skid-steered wheeled platforms},
  volume       = {45},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). LTA*: Local tangent based a* for optimal path planning.
<em>AR</em>, <em>45</em>(2), 209–227. (<a
href="https://doi.org/10.1007/s10514-020-09956-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optimal path planning on non-convex maps is challenging: sampling-based algorithms (such as RRT) do not provide optimal solution in finite time; approaches based on visibility graphs are computationally expensive, while reduced visibility graphs (e.g., tangent graph) fail on such maps. We leverage a well-established, and surprisingly less utilized in path planning, geometrical property of convex decompositions i.e. a concave shape can be decomposed into multiple convex shapes. We propose a novel local tangent based approach, inspired by such convex decompositions, to path planning in non-convex maps. Although our local tangent approach is inspired by geometric convex decompositions, it does not require complex decomposition process. Our second contribution is an efficient corner detection method which reasons on binary pixel occupancy maps. Combined with our novel local tangent approach, which intelligently selects nodes from these corners, we modify the standard A* algorithm by feeding these nodes to its open list. With our local tangent approach, only small number of selected corners are fed to A* open list which keeps its size small even for larger maps, resulting in lower convergence time. We formally prove the optimality of our solution. Simulation on our own maps and public dataset (MAPF http://mapf.info/ ) as well as real-world experiments show that our proposed LTA* algorithm gives better convergence time and shorter path length in environments with both convex and concave obstacles.},
  archive      = {J_AR},
  author       = {Zafar, Muhammad Mateen and Anjum, Muhammad Latif and Hussain, Wajahat},
  doi          = {10.1007/s10514-020-09956-3},
  journal      = {Autonomous Robots},
  month        = {2},
  number       = {2},
  pages        = {209-227},
  shortjournal = {Auton. Robot.},
  title        = {LTA*: Local tangent based a* for optimal path planning},
  volume       = {45},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Estimating boundary dynamics using robotic sensor networks
with pointwise measurements. <em>AR</em>, <em>45</em>(2), 193–208. (<a
href="https://doi.org/10.1007/s10514-020-09954-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we consider environmental boundaries that can be represented by a time-varying closed curve. We use n robots equipped with location sensors to sample the dynamic boundary. The main difficulty during the prediction process is that only n boundary points can be observed at each time step. Our approach combines finite Fourier series for shape-estimation and polynomial fitting for point tracking in time. This combination gives a continuous parametric function that describes the boundary shape and its dynamics. We validate our strategy in simulation and with experiments using actual robots. We tested on non-convex boundaries assuming noisy measurements and inaccurate motion actuators.},
  archive      = {J_AR},
  author       = {Saldaña, David and Assunção, Renato and Hsieh, M. Ani and Campos, Mario F. M. and Kumar, Vijay},
  doi          = {10.1007/s10514-020-09954-5},
  journal      = {Autonomous Robots},
  month        = {2},
  number       = {2},
  pages        = {193-208},
  shortjournal = {Auton. Robot.},
  title        = {Estimating boundary dynamics using robotic sensor networks with pointwise measurements},
  volume       = {45},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Correction to: Four aspects of building robotic systems:
Lessons from the amazon picking challenge 2015. <em>AR</em>,
<em>45</em>(1), 191. (<a
href="https://doi.org/10.1007/s10514-020-09953-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the original publication of the article, the incorrect author photo was displayed in biography section.},
  archive      = {J_AR},
  author       = {Eppner, Clemens and Höfer, Sebastian and Jonschkowski, Rico and Martín-Martín, Roberto and Sieverling, Arne and Wall, Vincent and Brock, Oliver},
  doi          = {10.1007/s10514-020-09953-6},
  journal      = {Autonomous Robots},
  month        = {1},
  number       = {1},
  pages        = {191},
  shortjournal = {Auton. Robot.},
  title        = {Correction to: four aspects of building robotic systems: lessons from the amazon picking challenge 2015},
  volume       = {45},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Quantitative analysis of robot gesticulation behavior.
<em>AR</em>, <em>45</em>(1), 175–189. (<a
href="https://doi.org/10.1007/s10514-020-09958-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Social robot capabilities, such as talking gestures, are best produced using data driven approaches to avoid being repetitive and to show trustworthiness. However, there is a lack of robust quantitative methods that allow to compare such methods beyond visual evaluation. In this paper a quantitative analysis is performed that compares two Generative Adversarial Networks based gesture generation approaches. The aim is to measure characteristics such as fidelity to the original training data, but at the same time keep track of the degree of originality of the produced gestures. Principal Coordinate Analysis and procrustes statistics are performed and a new Fréchet Gesture Distance is proposed by adapting the Fréchet Inception Distance to gestures. These three techniques are taken together to asses the fidelity/originality of the generated gestures.},
  archive      = {J_AR},
  author       = {Zabala, Unai and Rodriguez, Igor and Martínez-Otzeta, José María and Irigoien, Itziar and Lazkano, Elena},
  doi          = {10.1007/s10514-020-09958-1},
  journal      = {Autonomous Robots},
  month        = {1},
  number       = {1},
  pages        = {175-189},
  shortjournal = {Auton. Robot.},
  title        = {Quantitative analysis of robot gesticulation behavior},
  volume       = {45},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Trajectory adaptation of biomimetic equilibrium point for
stable locomotion of a large-size hexapod robot. <em>AR</em>,
<em>45</em>(1), 155–174. (<a
href="https://doi.org/10.1007/s10514-020-09955-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a control scheme inspired by the biological equilibrium point hypothesis (EPH) to enhance the motion stability of large-size legged robots. To achieve stable walking performances of a large-size hexapod robot on different outdoor terrains, we established a compliant-leg model and developed an approach for adapting the trajectory of the equilibrium point via contact force optimization. The compliant-leg model represents well the physical property between motion state of the robot legs and the contact forces. The adaptation approach modifies the trajectory of the equilibrium point from the force equilibrium of the system, and deformation counteraction. Several real field experiments of a large-size hexapod robot walking on different terrains were carried out to validate the effectiveness and feasibility of the control scheme, which demonstrated that the biologically inspired EPH can be applied to design a simple linear controller for a large-size, heavy-duty hexapod robot to improve the stability and adaptability of the motion in unknown outdoor environments.},
  archive      = {J_AR},
  author       = {Chen, Chen and Zha, Fusheng and Guo, Wei and Li, Zhibin and Sun, Lining and Shi, Junyi},
  doi          = {10.1007/s10514-020-09955-4},
  journal      = {Autonomous Robots},
  month        = {1},
  number       = {1},
  pages        = {155-174},
  shortjournal = {Auton. Robot.},
  title        = {Trajectory adaptation of biomimetic equilibrium point for stable locomotion of a large-size hexapod robot},
  volume       = {45},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An efficient and direct method for trajectory optimization
of robots constrained by contact kinematics and forces. <em>AR</em>,
<em>45</em>(1), 135–153. (<a
href="https://doi.org/10.1007/s10514-020-09952-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we propose a trajectory generation method for robotic systems with contact kinematics and force constraints based on optimal control and reachability analysis tools. Normally, the dynamics and constraints of a contact-constrained robot are nonlinear and coupled to each other. Instead of linearizing the model and constraints, we solve the optimal control problem directly to obtain feasible state trajectories and their corresponding control inputs. A tractable optimal control problem is formulated and subsequently addressed by dual approaches, which rely on sampling-based dynamic programming and rigorous reachability analysis tools. In particular, a sampling-based method together with a Partially Observable Markov Decision Process solution approach are used to break down the end-to-end trajectory generation problem by generating a sequence of subregions that the system’s trajectory will have to pass through to reach its final destination. The distinctive characteristic of the proposed trajectory optimization algorithm is its ability to handle the intricate contact constraints, coupled with the system dynamics, in a computationally efficient way. We validate our method using extensive numerical simulations with two legged robots.},
  archive      = {J_AR},
  author       = {Lee, Jaemin and Bakolas, Efstathios and Sentis, Luis},
  doi          = {10.1007/s10514-020-09952-7},
  journal      = {Autonomous Robots},
  month        = {1},
  number       = {1},
  pages        = {135-153},
  shortjournal = {Auton. Robot.},
  title        = {An efficient and direct method for trajectory optimization of robots constrained by contact kinematics and forces},
  volume       = {45},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Deep reinforcement learning for quadrotor path following
with adaptive velocity. <em>AR</em>, <em>45</em>(1), 119–134. (<a
href="https://doi.org/10.1007/s10514-020-09951-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a solution for the path following problem of a quadrotor vehicle based on deep reinforcement learning theory. Three different approaches implementing the Deep Deterministic Policy Gradient algorithm are presented. Each approach emerges as an improved version of the preceding one. The first approach uses only instantaneous information of the path for solving the problem. The second approach includes a structure that allows the agent to anticipate to the curves. The third agent is capable to compute the optimal velocity according to the path’s shape. A training framework that combines the tensorflow-python environment with Gazebo-ROS using the RotorS simulator is built. The three agents are tested in RotorS and experimentally with the Asctec Hummingbird quadrotor. Experimental results prove the validity of the agents, which are able to achieve a generalized solution for the path following problem.},
  archive      = {J_AR},
  author       = {Rubí, Bartomeu and Morcego, Bernardo and Pérez, Ramon},
  doi          = {10.1007/s10514-020-09951-8},
  journal      = {Autonomous Robots},
  month        = {1},
  number       = {1},
  pages        = {119-134},
  shortjournal = {Auton. Robot.},
  title        = {Deep reinforcement learning for quadrotor path following with adaptive velocity},
  volume       = {45},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Autonomous quadrotor collision avoidance and destination
seeking in a GPS-denied environment. <em>AR</em>, <em>45</em>(1),
99–118. (<a href="https://doi.org/10.1007/s10514-020-09949-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a new integrated guidance and control method for autonomous collision avoidance and navigation in an unmapped GPS-denied environment that contains unknown obstacles. The algorithm is implemented on an experimental custom quadrotor that uses onboard vision sensing (i.e., an Intel RealSense R200) to detect the positions of obstacles. We demonstrate autonomous collision avoidance and destination seeking in experiments, where the quadrotor navigates unknown GPS-denied environments. All feedback measurements are obtained from onboard sensors. The new guidance and control algorithm uses a nonlinear inner-loop attitude controller; a nonlinear middle-loop velocity controller; and an ellipsoidal-potential-field outer-loop guidance algorithm for collision avoidance and destination seeking. The main analytic result regarding the inner-loop control shows that every quadrotor attitude with pitch between $$\pm 90^{\circ }$$ is a locally exponentially stable equilibrium of the closed-loop attitude dynamics, and we quantify the region of attraction for each attitude equilibrium.},
  archive      = {J_AR},
  author       = {Kirven, Thomas and Hoagg, Jesse B.},
  doi          = {10.1007/s10514-020-09949-2},
  journal      = {Autonomous Robots},
  month        = {1},
  number       = {1},
  pages        = {99-118},
  shortjournal = {Auton. Robot.},
  title        = {Autonomous quadrotor collision avoidance and destination seeking in a GPS-denied environment},
  volume       = {45},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). S4-SLAM: A real-time 3D LIDAR SLAM system for
ground/watersurface multi-scene outdoor applications. <em>AR</em>,
<em>45</em>(1), 77–98. (<a
href="https://doi.org/10.1007/s10514-020-09948-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For outdoor ground/watersurface multi-scene applications with sparse feature points, high moving speed and high dynamic noises, a real-time 3D LIDAR SLAM system (S4-SLAM) for unmanned vehicles/ships is proposed in this paper, which is composed of the odometry function in front-end and the loop closure function in back-end. Firstly, linear interpolation is used to eliminate the motion distortion caused by robot motions in the data pre-processing step. Two nodes are constructed in the odometry function: the localization node combines the improved Super4PCS with the standard ICP to realize a coarse-to-fine scan matching and outputs the location information of the robot at a high frequency (5 Hz); the correction node introduces a local map with dynamic voxel grid storage structure, which can accelerate the NDT(Normal Distributions Transform) matching process between key-frames and the local map, and then corrects the localization node at a low frequency (1 Hz) to obtain more accurate location information. In the loop closure function, a location-based loop detection approach is introduced and the overlap rate of point clouds is used to verify the loops, so that the global optimization can be carried out to obtain high-precision trajectory and map estimates. The proposed method has been extensively evaluated on the KITTI odometry benchmark and also tested in real-life campus and harbor environments. The results show that our method has low dependence on GPS/INS, high positioning accuracy (with the global drift under 1%) and good environmental robustness.},
  archive      = {J_AR},
  author       = {Zhou, Bo and He, Yi and Qian, Kun and Ma, Xudong and Li, Xiaomao},
  doi          = {10.1007/s10514-020-09948-3},
  journal      = {Autonomous Robots},
  month        = {1},
  number       = {1},
  pages        = {77-98},
  shortjournal = {Auton. Robot.},
  title        = {S4-SLAM: A real-time 3D LIDAR SLAM system for ground/watersurface multi-scene outdoor applications},
  volume       = {45},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Reinforcement based mobile robot path planning with improved
dynamic window approach in unknown environment. <em>AR</em>,
<em>45</em>(1), 51–76. (<a
href="https://doi.org/10.1007/s10514-020-09947-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile robot path planning in an unknown environment is a fundamental and challenging problem in the field of robotics. Dynamic window approach (DWA) is an effective method of local path planning, however some of its evaluation functions are inadequate and the algorithm for choosing the weights of these functions is lacking, which makes it highly dependent on the global reference and prone to fail in an unknown environment. In this paper, an improved DWA based on Q-learning is proposed. First, the original evaluation functions are modified and extended by adding two new evaluation functions to enhance the performance of global navigation. Then, considering the balance of effectiveness and speed, we define the state space, action space and reward function of the adopted Q-learning algorithm for the robot motion planning. After that, the parameters of the proposed DWA are adaptively learned by Q-learning and a trained agent is obtained to adapt to the unknown environment. At last, by a series of comparative simulations, the proposed method shows higher navigation efficiency and successful rate in the complex unknown environment. The proposed method is also validated in experiments based on XQ-4 Pro robot to verify its navigation capability in both static and dynamic environment.},
  archive      = {J_AR},
  author       = {Chang, Lu and Shan, Liang and Jiang, Chao and Dai, Yuewei},
  doi          = {10.1007/s10514-020-09947-4},
  journal      = {Autonomous Robots},
  month        = {1},
  number       = {1},
  pages        = {51-76},
  shortjournal = {Auton. Robot.},
  title        = {Reinforcement based mobile robot path planning with improved dynamic window approach in unknown environment},
  volume       = {45},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The orbiting dubins traveling salesman problem: Planning
inspection tours for a minehunting AUV. <em>AR</em>, <em>45</em>(1),
31–49. (<a href="https://doi.org/10.1007/s10514-020-09946-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Orbiting Dubins Traveling Salesman Problem (ODTSP) is to plan a minimum-time tour for a Dubins vehicle model to inspect a set of targets in the plane by orbiting each target along a circular arc. This problem arises in underwater minehunting, where targets are mine-like objects on the sea bottom that are inspected by a sonar-equipped underwater vehicle. Each orbit subtends a prescribed angle so that the target’s acoustic response is measured from a variety of target-sensor relative geometries to aid in classifying it. ODTSP tours consist of circular-arc orbits joined by Dubins paths, and the optimization problem is to partition the set of targets into orbits and determine the position, radius, direction, and vehicle entry angle of each. Algorithms are presented for the restricted case, where each orbit inspects a single target (only), and the general case, where orbits inspect multiple targets. The approach is facilitated by analytical conditions that identify admissible clusters of targets as cliques of a disk graph. The ODTSP is extended to consider path planning in the presence of a steady uniform current.},
  archive      = {J_AR},
  author       = {Wolek, Artur and McMahon, James and Dzikowicz, Benjamin R. and Houston, Brian H.},
  doi          = {10.1007/s10514-020-09946-5},
  journal      = {Autonomous Robots},
  month        = {1},
  number       = {1},
  pages        = {31-49},
  shortjournal = {Auton. Robot.},
  title        = {The orbiting dubins traveling salesman problem: Planning inspection tours for a minehunting AUV},
  volume       = {45},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Synchronous intercept strategies for a robotic
defense-intrusion game with two defenders. <em>AR</em>, <em>45</em>(1),
15–30. (<a href="https://doi.org/10.1007/s10514-020-09945-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the defense-intrusion game, in which a single attacker robot tries to reach a stationary target that is protected by two defender robots. We focus on the “synchronous intercept problem”, where both robots have to reach the attacker robot synchronously to intercept it. Assume that the attacker robot has the control policy which is based on attraction to the target and repulsion from the defenders, two kinds of synchronous intercept strategies are proposed for the defense-intrusion game, introduced here as Attacker-oriented and Neutral-position-oriented. Theoretical analysis and simulation results show that: (1) the two strategies are able to generate different synchronous intercept patterns: contact intercept pattern and stable non-contact intercept pattern, respectively. (2) The contact intercept pattern allows the defender robots to intercept the attacker robot in finite time, while the stable non-contact intercept pattern generates a periodic attractor that prevents the attack robot from reaching the target for infinite time. There is potential to apply the insights obtained into defense-intrusion in real systems, including aircraft escort and the defense of military targets or territorial boundaries.},
  archive      = {J_AR},
  author       = {Zhang, Shuai and Liu, Mingyong and Lei, Xiaokang and Yang, Panpan and Huang, Yunke and Clark, Ruaridh},
  doi          = {10.1007/s10514-020-09945-6},
  journal      = {Autonomous Robots},
  month        = {1},
  number       = {1},
  pages        = {15-30},
  shortjournal = {Auton. Robot.},
  title        = {Synchronous intercept strategies for a robotic defense-intrusion game with two defenders},
  volume       = {45},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Sensor fusion based manipulative action recognition.
<em>AR</em>, <em>45</em>(1), 1–13. (<a
href="https://doi.org/10.1007/s10514-020-09943-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Manipulative action recognition is one of the most important and challenging topic in the fields of image processing. In this paper, three kinds of sensor modules are used for motion, force and object information capture in the manipulative actions. Two fusion methods are proposed. Further, the recognition accuracy can be improved by using object as context. For the feature-level fusion method, significant features are chosen first. Then the Hidden Markov Models are built with these selected features to characterize the temporal sequence. For the decision-level fusion method, HMMs are built for each feature group. Then the decisions are fused. On top of these two fusion methods, the object/action context is modeled using Bayesian network. Assembly tasks are used for algorithm evaluation. The experimental results prove that the proposed approach is effective on manipulative action recognition task. The recognition accuracy of the decision-level, feature-level fusion methods and the Bayesian model are 72%, 80% and 90% respectively.},
  archive      = {J_AR},
  author       = {Gu, Ye and Liu, Meiqin and Sheng, Weihua and Ou, Yongsheng and Li, Yongqiang},
  doi          = {10.1007/s10514-020-09943-8},
  journal      = {Autonomous Robots},
  month        = {1},
  number       = {1},
  pages        = {1-13},
  shortjournal = {Auton. Robot.},
  title        = {Sensor fusion based manipulative action recognition},
  volume       = {45},
  year         = {2021},
}
</textarea>
</details></li>
</ul>

</body>
</html>
