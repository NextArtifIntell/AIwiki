<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>Alg_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="alg---129">Alg - 129</h2>
<ul>
<li><details>
<summary>
(2021). Maximum box problem on stochastic points. <em>Alg</em>,
<em>83</em>(12), 3741‚Äì3765. (<a
href="https://doi.org/10.1007/s00453-021-00882-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given a finite set of weighted points in $${\mathbb {R}}^d$$ (where there can be negative weights), the maximum box problem asks for an axis-aligned rectangle (i.e., box) such that the sum of the weights of the points that it contains is maximized. We consider that each point of the input has a probability of being present in the final random point set, and these events are mutually independent; then, the total weight of a maximum box is a random variable. We aim to compute both the probability that this variable is at least a given parameter, and its expectation. We show that even in $$d=1$$ these computations are #P-hard, and give pseudo-polynomial time algorithms in the case where the weights are integers in a bounded interval. For $$d=2$$ , we consider that each point is colored red or blue, where red points have weight $$+1$$ and blue points weight $$-\infty $$ . The random variable is the maximum number of red points that can be covered with a box not containing any blue point. We prove that the above two computations are also #P-hard, and give a polynomial-time algorithm for computing the probability that there is a box containing exactly two red points, no blue point, and a given point of the plane.},
  archive      = {J_Alg},
  author       = {Caraballo, Luis E. and P√©rez-Lantero, Pablo and Seara, Carlos and Ventura, Inmaculada},
  doi          = {10.1007/s00453-021-00882-z},
  journal      = {Algorithmica},
  number       = {12},
  pages        = {3741-3765},
  shortjournal = {Algorithmica},
  title        = {Maximum box problem on stochastic points},
  volume       = {83},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Approximation algorithms for maximally balanced connected
graph partition. <em>Alg</em>, <em>83</em>(12), 3715‚Äì3740. (<a
href="https://doi.org/10.1007/s00453-021-00870-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given a connected graph $$G = (V, E)$$ , we seek to partition the vertex set V into k non-empty parts such that the subgraph induced by each part is connected, and the partition is maximally balanced in the way that the maximum cardinality of these k parts is minimized. We refer this problem to as min-max balanced connected graph partition into k parts and denote it as k -BGP. The vertex-weighted version of this problem on trees has been studied since about four decades ago, which admits a linear time exact algorithm. The vertex-weighted 2-BGP and 3-BGP admit a 5/4-approximation and a 3/2-approximation, respectively. When $$k \ge 4$$ , no approximability result exists for k -BGP, i.e., the vertex unweighted variant, except a trivial k-approximation. In this paper, we present another 3/2-approximation for the 3-BGP and then extend it to become a k/2-approximation for k -BGP, for any fixed $$k \ge 3$$ . Furthermore, for 4-BGP, we propose an improved 24/13-approximation. To these purposes, we have designed several local improvement operations, which could find more applications in related graph partition problems.},
  archive      = {J_Alg},
  author       = {Chen, Yong and Chen, Zhi-Zhong and Lin, Guohui and Xu, Yao and Zhang, An},
  doi          = {10.1007/s00453-021-00870-3},
  journal      = {Algorithmica},
  number       = {12},
  pages        = {3715-3740},
  shortjournal = {Algorithmica},
  title        = {Approximation algorithms for maximally balanced connected graph partition},
  volume       = {83},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Dynamic programming approach to the generalized minimum
manhattan network problem. <em>Alg</em>, <em>83</em>(12), 3681‚Äì3714. (<a
href="https://doi.org/10.1007/s00453-021-00868-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the generalized minimum Manhattan network (GMMN) problem: given a set $$P$$ of pairs of points in the Euclidean plane $${\mathbb{R}}^2$$ , we are required to find a minimum-length geometric network which consists of axis-aligned segments and contains a shortest path in the $$L_1$$ metric (a so-called Manhattan path) for each pair in $$P$$ . This problem commonly generalizes several NP-hard network design problems that admit constant-factor approximation algorithms, such as the rectilinear Steiner arborescence (RSA) problem, and it is open whether so does the GMMN problem. As a bottom-up exploration, Schnizler (2015) focused on the intersection graphs of the rectangles defined by the pairs in $$P$$ , and gave a polynomial-time dynamic programming algorithm for the GMMN problem whose input is restricted so that both the treewidth and the maximum degree of its intersection graph are bounded by constants. In this paper, as the first attempt to remove the degree bound, we provide a polynomial-time algorithm for the star case, and extend it to the general tree case based on an improved dynamic programming approach.},
  archive      = {J_Alg},
  author       = {Masumura, Yuya and Oki, Taihei and Yamaguchi, Yutaro},
  doi          = {10.1007/s00453-021-00868-x},
  journal      = {Algorithmica},
  number       = {12},
  pages        = {3681-3714},
  shortjournal = {Algorithmica},
  title        = {Dynamic programming approach to the generalized minimum manhattan network problem},
  volume       = {83},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). <span class="math display">ùí∞</span> -bubble model for mixed
unit interval graphs and its applications: The MaxCut problem revisited.
<em>Alg</em>, <em>83</em>(12), 3649‚Äì3680. (<a
href="https://doi.org/10.1007/s00453-021-00837-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Interval graphs, intersection graphs of segments on a real line (intervals), play a key role in the study of algorithms and special structural properties. Unit interval graphs, their proper subclass, where each interval has a unit length, has also been extensively studied. We study mixed unit interval graphs‚Äîa generalization of unit interval graphs where each interval has still a unit length, but intervals of more than one type (open, closed, semi-closed) are allowed. This small modification captures a richer class of graphs. In particular, mixed unit interval graphs may contain a claw as an induced subgraph, as opposed to unit interval graphs. Heggernes, Meister, and Papadopoulos defined a representation of unit interval graphs called the bubble model which turned out to be useful in algorithm design. We extend this model to the class of mixed unit interval graphs and demonstrate the advantages of this generalized model by providing a subexponential-time algorithm for solving the MaxCut problem on mixed unit interval graphs. In addition, we derive a polynomial-time algorithm for certain subclasses of mixed unit interval graphs. We point out a substantial mistake in the proof of the polynomiality of the MaxCut problem on unit interval graphs by Boyacƒ± et al. (Inf Process Lett 121:29‚Äì33, 2017. https://doi.org/10.1016/j.ipl.2017.01.007 ). Hence, the time complexity of this problem on unit interval graphs remains open. We further provide a better algorithmic upper-bound on the clique-width of mixed unit interval graphs.},
  archive      = {J_Alg},
  author       = {Kratochv√≠l, Jan and Masa≈ô√≠k, Tom√°≈° and Novotn√°, Jana},
  doi          = {10.1007/s00453-021-00837-4},
  journal      = {Algorithmica},
  number       = {12},
  pages        = {3649-3680},
  shortjournal = {Algorithmica},
  title        = {$${\mathcal {U}}$$ -bubble model for mixed unit interval graphs and its applications: The MaxCut problem revisited},
  volume       = {83},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Local geometric spanners. <em>Alg</em>, <em>83</em>(12),
3629‚Äì3648. (<a
href="https://doi.org/10.1007/s00453-021-00860-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce the concept of local spanners for planar point sets with respect to a family of regions, and prove the existence of local spanners of small size for some families. For a geometric graph G on a point set $$P$$ and a region R belonging to a family $${\mathcal {R}}$$ , we define $$G \cap R$$ to be the part of the graph G that is inside R (or is induced by R). A local t-spanner w.r.t $${\mathcal {R}}$$ is a geometric graph G on $$P$$ such that for any region $$R \in {\mathcal {R}}$$ , the graph $$G\cap R$$ is a t-spanner for $$K(P) \cap R$$ , where $$K(P)$$ is the complete geometric graph on P. For any set $$P$$ of n points and any constant $$\varepsilon &gt; 0$$ , we prove that $$P$$ admits local $$(1 + \varepsilon )$$ -spanners of sizes $$O(n \log ^{6} n)$$ and $$O(n \log n)$$ w.r.t axis-parallel squares and vertical slabs, respectively. If adding Steiner points is allowed, then local $$(1 + \varepsilon )$$ -spanners with O(n) edges and $$O(n \log ^2 n)$$ edges can be obtained for axis-parallel squares and disks using O(n) Steiner points, respectively.},
  archive      = {J_Alg},
  author       = {Abam, Mohammad Ali and Borouny, Mohammad Sadegh},
  doi          = {10.1007/s00453-021-00860-5},
  journal      = {Algorithmica},
  number       = {12},
  pages        = {3629-3648},
  shortjournal = {Algorithmica},
  title        = {Local geometric spanners},
  volume       = {83},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Top tree compression of tries. <em>Alg</em>,
<em>83</em>(12), 3602‚Äì3628. (<a
href="https://doi.org/10.1007/s00453-021-00869-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a compressed representation of tries based on top tree compression [ICALP 2013] that works on a standard, comparison-based, pointer machine model of computation and supports efficient prefix search queries. Namely, we show how to preprocess a set of strings of total length n over an alphabet of size $$\sigma$$ into a compressed data structure of worst-case optimal size $$O(n/\log _\sigma n)$$ that given a pattern string P of length m determines if P is a prefix of one of the strings in time $$O(\min (m\log \sigma ,m + \log n))$$ . We show that this query time is in fact optimal regardless of the size of the data structure. Existing solutions either use $$\Omega (n)$$ space or rely on word RAM techniques, such as tabulation, hashing, address arithmetic, or word-level parallelism, and hence do not work on a pointer machine. Our result is the first solution on a pointer machine that achieves worst-case o(n) space. Along the way, we develop several interesting data structures that work on a pointer machine and are of independent interest. These include an optimal data structures for random access to a grammar-compressed string and an optimal data structure for a variant of the level ancestor problem.},
  archive      = {J_Alg},
  author       = {Bille, Philip and Gawrychowski, Pawe≈Ç and G√∏rtz, Inge Li and Landau, Gad M. and Weimann, Oren},
  doi          = {10.1007/s00453-021-00869-w},
  journal      = {Algorithmica},
  number       = {12},
  pages        = {3602-3628},
  shortjournal = {Algorithmica},
  title        = {Top tree compression of tries},
  volume       = {83},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Parameterized complexity of small weight automorphisms and
isomorphisms. <em>Alg</em>, <em>83</em>(12), 3567‚Äì3601. (<a
href="https://doi.org/10.1007/s00453-021-00867-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the parameterized complexity of computing nontrivial automorphisms of weight k for a given hypergraph $$X=(V,E)$$ , with k as fixed parameter, where the weight of a permutation $$\pi \in S_n$$ is the number of points moved by $$\pi$$ . Building on the earlier work of Schweitzer¬†(in: Proceedings of 19th ESA, Springer, Berlin, 2011. https://doi.org/10.1007/978-3-642-23719-5_32 ), we show the following results: (1) Computing nontrivial automorphisms of weight at most k for d-hypergraphs (that is, with edge-size bounded by d) remains fixed parameter tractable, with d treated as a second fixed parameter. Likewise, finding isomorphisms of weight k between d-hypergraphs X and Y (both defined on vertex set [n]) remains fixed parameter tractable. (2) For dealing with the exact weight k version of the problem, we introduce a more general algorithmic problem PermCode: given a permutation group¬†G by a generating set and a fixed parameter k, is there is a nontrivial element of¬†G with support at most (or exactly)¬†k? We give a method for shrinking large orbits of the given group G to obtain subgroups while maintaining existence of weight at most k elements in it. An application of this yields an FPT algorithm for finding exact weight k nontrivial automorphisms in d-hypergraphs, d as second fixed parameter. (3) For hypergraphs with edges of unbounded size, we show that the problem is in $$\textsf {FPT } ^{\textsc {GI}}$$ . (4) Computing d-hypergraph isomorphisms of weight exactly k is fixed parameter tractable. This requires a more complicated orbit shrinking technique.},
  archive      = {J_Alg},
  author       = {Arvind, V. and K√∂bler, Johannes and Kuhnert, Sebastian and Tor√°n, Jacobo},
  doi          = {10.1007/s00453-021-00867-y},
  journal      = {Algorithmica},
  number       = {12},
  pages        = {3567-3601},
  shortjournal = {Algorithmica},
  title        = {Parameterized complexity of small weight automorphisms and isomorphisms},
  volume       = {83},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Online makespan scheduling with job migration on uniform
machines. <em>Alg</em>, <em>83</em>(12), 3537‚Äì3566. (<a
href="https://doi.org/10.1007/s00453-021-00852-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the classic minimum makespan scheduling problem, we are given an input sequence of n jobs with sizes. A scheduling algorithm has to assign the jobs to m parallel machines. The objective is to minimize the makespan, which is the time it takes until all jobs are processed. In this paper, we consider online scheduling algorithms without preemption. However, we allow the online algorithm to change the assignment of up to k jobs at the end for some limited number k. For m identical machines, Albers and Hellwig (Algorithmica 79(2):598‚Äì623, 2017) give tight bounds on the competitive ratio in this model. The precise ratio depends on, and increases with, m. It lies between 4/3 and $$\approx 1.4659$$ . They show that $$k = O(m)$$ is sufficient to achieve this bound and no $$k = o(n)$$ can result in a better bound. We study m uniform machines, i.e., machines with different speeds, and show that this setting is strictly harder. For sufficiently large m, there is a $$\delta = \varTheta (1)$$ such that, for m machines with only two different machine speeds, no online algorithm can achieve a competitive ratio of less than $$1.4659 + \delta $$ with $$k = o(n)$$ . We present a new algorithm for the uniform machine setting. Depending on the speeds of the machines, our scheduling algorithm achieves a competitive ratio that lies between 4/3 and $$\approx 1.7992$$ with $$k = O(m)$$ . We also show that $$k = \varOmega (m)$$ is necessary to achieve a competitive ratio below 2. Our algorithm is based on maintaining a specific imbalance with respect to the completion times of the machines, complemented by a bicriteria approximation algorithm that minimizes the makespan and maximizes the average completion time for certain sets of machines.},
  archive      = {J_Alg},
  author       = {Englert, Matthias and Mezlaf, David and Westermann, Matthias},
  doi          = {10.1007/s00453-021-00852-5},
  journal      = {Algorithmica},
  number       = {12},
  pages        = {3537-3566},
  shortjournal = {Algorithmica},
  title        = {Online makespan scheduling with job migration on uniform machines},
  volume       = {83},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Correction to: Outer 1-planar graphs. <em>Alg</em>,
<em>83</em>(11), 3534‚Äì3535. (<a
href="https://doi.org/10.1007/s00453-021-00874-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A Correction to this paper has been published: 10.1007/s00453-015-0002-1},
  archive      = {J_Alg},
  author       = {Auer, Christopher and Bachmaier, Christian and Brandenburg, Franz J. and Glei√üner, Andreas and Hanauer, Kathrin and Neuwirth, Daniel and Reislhuber, Josef},
  doi          = {10.1007/s00453-021-00874-z},
  journal      = {Algorithmica},
  number       = {11},
  pages        = {3534-3535},
  shortjournal = {Algorithmica},
  title        = {Correction to: Outer 1-planar graphs},
  volume       = {83},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Translation invariant fr√©chet distance queries.
<em>Alg</em>, <em>83</em>(11), 3514‚Äì3533. (<a
href="https://doi.org/10.1007/s00453-021-00865-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Fr√©chet distance is a popular similarity measure between curves. For some applications, it is desirable to match the curves under translation before computing the Fr√©chet distance between them. This variant is called the Translation Invariant Fr√©chet distance, and algorithms to compute it are well studied. The query version, finding an optimal placement in the plane for a query segment where the Fr√©chet distance becomes minimized, is much less well understood. We study Translation Invariant Fr√©chet distance queries in a restricted setting of horizontal query segments. More specifically, we preprocess a trajectory in $${\mathcal {O}}(n^2 \log ^2 n)$$ time and $${\mathcal {O}}(n^{3/2})$$ space, such that for any subtrajectory and any horizontal query segment we can compute their Translation Invariant Fr√©chet distance in $${\mathcal {O}}({{\,\mathrm{polylog}\,}}n)$$ time. We hope this will be a step towards answering Translation Invariant Fr√©chet queries between arbitrary trajectories.},
  archive      = {J_Alg},
  author       = {Gudmundsson, Joachim and van Renssen, Andr√© and Saeidi, Zeinab and Wong, Sampson},
  doi          = {10.1007/s00453-021-00865-0},
  journal      = {Algorithmica},
  number       = {11},
  pages        = {3514-3533},
  shortjournal = {Algorithmica},
  title        = {Translation invariant fr√©chet distance queries},
  volume       = {83},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Maximizing dominance in the plane and its applications.
<em>Alg</em>, <em>83</em>(11), 3491‚Äì3513. (<a
href="https://doi.org/10.1007/s00453-021-00863-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given a set P of n weighted points, a set Q of m points in the plane, and a positive integer k, we consider the optimization problem of finding a subset of Q with at most k points that dominates a subset of P with maximum total weight. A set $$Q&#39;$$ of points in the plane dominates a point p in the plane if some point $$q\in Q&#39;$$ satisfies $$x(p)\leqslant x(q)$$ and $$y(p)\leqslant y(q)$$ . We present an efficient algorithm solving this problem in $$O(k(n+m)\log m)$$ time and $$O(n+m)$$ space. Our result implies algorithms with better time bounds for related problems, including the disjoint union of cliques problem for interval graphs (equivalently, the hitting intervals problem) and the top-k representative skyline points problem in the plane.},
  archive      = {J_Alg},
  author       = {Choi, Jongmin and Cabello, Sergio and Ahn, Hee-Kap},
  doi          = {10.1007/s00453-021-00863-2},
  journal      = {Algorithmica},
  number       = {11},
  pages        = {3491-3513},
  shortjournal = {Algorithmica},
  title        = {Maximizing dominance in the plane and its applications},
  volume       = {83},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Network design under general wireless interference.
<em>Alg</em>, <em>83</em>(11), 3469‚Äì3490. (<a
href="https://doi.org/10.1007/s00453-021-00866-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce the problem of finding a spanning tree along with a partition of the tree edges into the fewest number of feasible sets, where constraints on the edges define feasibility. The motivation comes from wireless networking, where we seek to model the irregularities seen in actual wireless environments. Not all node pairs may be able to communicate, even if geographically close‚Äîthus, the available pairs are specified with a link graph $${{\mathcal {G}}}=(V,E)$$ . Also, signal attenuation need not follow a nice geometric formula‚Äîhence, interference is modeled by a conflict (hyper)graph $${{\mathcal {C}}}=(E,F)$$ on the links. The objective is to maximize the efficiency of the communication, or equivalently, to minimize the length of a schedule of the tree edges in the form of a coloring. We find that in spite of all this generality, the problem can be approximated linearly in terms of a versatile parameter, the inductive independence of the conflict graph. Specifically, we give a simple algorithm that attains a $$O(\rho \log n)$$ -approximation, where n is the number of nodes and $$\rho$$ is the inductive independence. For an extension to Steiner trees, modeling multicasting, we obtain a $$O(\rho \log ^2 n)$$ -approximation. We also consider a natural geometric setting when only links longer than a threshold can be unavailable, and analyze the performance of a geometric minimum spanning tree.},
  archive      = {J_Alg},
  author       = {Halld√≥rsson, Magn√∫s M. and Kortsarz, Guy and Mitra, Pradipta and Tonoyan, Tigran},
  doi          = {10.1007/s00453-021-00866-z},
  journal      = {Algorithmica},
  number       = {11},
  pages        = {3469-3490},
  shortjournal = {Algorithmica},
  title        = {Network design under general wireless interference},
  volume       = {83},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Succinct encoding of binary strings representing
triangulations. <em>Alg</em>, <em>83</em>(11), 3432‚Äì3468. (<a
href="https://doi.org/10.1007/s00453-021-00861-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the problem of designing a succinct data structure for representing the connectivity of planar triangulations. The main result is a new succinct encoding achieving the information-theory optimal bound of 3.24 bits per vertex, while allowing efficient navigation. Our representation is based on the bijection of Poulalhon and Schaeffer (Algorithmica, 46(3):505‚Äì527, 2006) that defines a mapping between planar triangulations and a special class of spanning trees, called PS-trees. The proposed solution differs from previous approaches in that operations in planar triangulations are reduced to operations in particular parentheses sequences encoding PS-trees. Existing methods to handle balanced parentheses sequences have to be combined and extended to operate on such specific sequences, essentially for retrieving matching elements. The new encoding supports extracting the d neighbors of a query vertex in O(d) time and testing adjacency between two vertices in O(1) time. Additionally, we provide an implementation of our proposed data structure. In the experimental evaluation, our representation reaches up to 7.35 bits per vertex, improving the space usage of state-of-the-art implementations for planar embeddings.},
  archive      = {J_Alg},
  author       = {Fuentes-Sep√∫lveda, Jos√© and Seco, Diego and Via√±a, Raquel},
  doi          = {10.1007/s00453-021-00861-4},
  journal      = {Algorithmica},
  number       = {11},
  pages        = {3432-3468},
  shortjournal = {Algorithmica},
  title        = {Succinct encoding of binary strings representing triangulations},
  volume       = {83},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Connected subgraph defense games. <em>Alg</em>,
<em>83</em>(11), 3403‚Äì3431. (<a
href="https://doi.org/10.1007/s00453-021-00858-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study a security game over a network played between a defender and k attackers. Every attacker chooses, probabilistically, a node of the network to damage. The defender chooses, probabilistically as well, a connected induced subgraph of the network of $$\lambda $$ nodes to scan and clean. Each attacker wishes to maximize the probability of escaping her cleaning by the defender. On the other hand, the goal of the defender is to maximize the expected number of attackers that she catches. This game is a generalization of the model from the seminal paper of Mavronicolas et al. Mavronicolas et al. (in: International symposium on mathematical foundations of computer science, MFCS, pp 717‚Äì728, 2006). We are interested in Nash equilibria of this game, as well as in characterizing defense-optimal networks which allow for the best equilibrium defense ratio; this is the ratio of k over the expected number of attackers that the defender catches in equilibrium. We provide a characterization of the Nash equilibria of this game and defense-optimal networks. The equilibrium characterizations allow us to show that even if the attackers are centrally controlled the equilibria of the game remain the same. In addition, we give an algorithm for computing Nash equilibria. Our algorithm requires exponential time in the worst case, but it is polynomial-time for $$\lambda $$ constantly close to 1 or n. For the special case of tree-networks, we further refine our characterization which allows us to derive a polynomial-time algorithm for deciding whether a tree is defense-optimal and if this is the case it computes a defense-optimal Nash equilibrium. On the other hand, we prove that it is $${\mathtt {NP}}$$ -hard to find a best-defense strategy if the tree is not defense-optimal. We complement this negative result with a polynomial-time constant-approximation algorithm that computes solutions that are close to optimal ones for general graphs. Finally, we provide asymptotically (almost) tight bounds for the Price of Defense for any $$\lambda $$ ; this is the worst equilibrium defense ratio over all graphs.},
  archive      = {J_Alg},
  author       = {Akrida, Eleni C. and Deligkas, Argyrios and Melissourgos, Themistoklis and Spirakis, Paul G.},
  doi          = {10.1007/s00453-021-00858-z},
  journal      = {Algorithmica},
  number       = {11},
  pages        = {3403-3431},
  shortjournal = {Algorithmica},
  title        = {Connected subgraph defense games},
  volume       = {83},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Encoding two-dimensional range top-k queries. <em>Alg</em>,
<em>83</em>(11), 3379‚Äì3402. (<a
href="https://doi.org/10.1007/s00453-021-00856-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the problem of encoding two-dimensional arrays, whose elements come from a total order, for answering $${\text{Top-}}{k}$$ queries. The aim is to obtain encodings that use space close to the information-theoretic lower bound, which can be constructed efficiently. For an $$m \times n$$ array, with $$m \le n$$ , we first propose an encoding for answering 1-sided $${\textsf {Top}}{\text {-}}k{}$$ queries, whose query range is restricted to $$[1 \dots m][1 \dots a]$$ , for $$1 \le a \le n$$ . Next, we propose an encoding for answering for the general (4-sided) $${\textsf {Top}}{\text {-}}k{}$$ queries that takes $$(m\lg {{(k+1)n \atopwithdelims ()n}}+2nm(m-1)+o(n))$$ bits, which generalizes the joint Cartesian tree of Golin et al. [TCS 2016]. Compared with trivial $$O(nm\lg {n})$$ -bit encoding, our encoding takes less space when $$m = o(\lg {n})$$ . In addition to the upper bound results for the encodings, we also give lower bounds on encodings for answering 1 and 4-sided $${\textsf {Top}}{\text {-}}k{}$$ queries, which show that our upper bound results are almost optimal.},
  archive      = {J_Alg},
  author       = {Jo, Seungbum and Lingala, Rahul and Satti, Srinivasa Rao},
  doi          = {10.1007/s00453-021-00856-1},
  journal      = {Algorithmica},
  number       = {11},
  pages        = {3379-3402},
  shortjournal = {Algorithmica},
  title        = {Encoding two-dimensional range top-k queries},
  volume       = {83},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A class of random recursive tree algorithms with deletion.
<em>Alg</em>, <em>83</em>(11), 3363‚Äì3378. (<a
href="https://doi.org/10.1007/s00453-021-00859-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We examine a discrete random recursive tree growth process that, at each time step, either adds or deletes a node from the tree with fixed, complementary probabilities. Node addition follows the usual uniform attachment model. For node removal, we identify a class of deletion rules guaranteeing the current tree conditioned on its size is uniformly distributed over its range. By using generating function theory and singularity analysis, we obtain asymptotic estimates for the expectation and variance of a tree‚Äôs size, as well as its expected leaf count and root degree. In all cases, the behavior of such trees falls into three regimes determined by the insertion probability. Interestingly, the results are independent of the specific class member deletion rule used.},
  archive      = {J_Alg},
  author       = {Saunders, Arnold T.},
  doi          = {10.1007/s00453-021-00859-y},
  journal      = {Algorithmica},
  number       = {11},
  pages        = {3363-3378},
  shortjournal = {Algorithmica},
  title        = {A class of random recursive tree algorithms with deletion},
  volume       = {83},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Recognizing k-clique extendible orderings. <em>Alg</em>,
<em>83</em>(11), 3338‚Äì3362. (<a
href="https://doi.org/10.1007/s00453-021-00857-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the complexity of recognizing k-clique-extendible graphs (k-C-E graphs) introduced by Spinrad (Efficient Graph Representations, AMS 2003), which are generalizations of comparability graphs. A graph is k-clique-extendible if there is an ordering of the vertices such that whenever two overlapping k-cliques A and B have $$k-1$$ common vertices, and these common vertices appear between the two vertices $$a,b\in (A{\setminus } B)\cup (B{\setminus } A)$$ in the ordering, there is an edge between a and b, implying that $$A\cup B$$ is a $$(k+1)$$ -clique. Such an ordering is said to be a k-C-E ordering. These graphs arise in applications related to modelling preference relations. Recently, it has been shown that a maximum clique in such a graph can be found in $$n^{O(k)}$$ time [Hamburger et al. 2017] when the ordering is given. When k is 2, such graphs are precisely the well-known class of comparability graphs and when k is 3 they are called triangle-extendible graphs. It has been shown that triangle-extendible graphs appear as induced subgraphs of visibility graphs of simple polygons, and the complexity of recognizing them has been mentioned as an open problem in the literature. While comparability graphs (i.e. 2-C-E graphs) can be recognized in polynomial time, we show that recognizing k-C-E graphs is NP-hard for any fixed $$k \ge 3$$ and co-NP-hard when k is part of the input. While our NP-hardness reduction for $$k \ge 4$$ is from the betweenness problem, for $$k=3$$ , our reduction is an intricate one from the 3-colouring problem. We also show that the problems of determining whether a given ordering of the vertices of a graph is a k-C-E ordering, and that of finding a maximum clique in a k-C-E graph, given a k-C-E ordering, are hard for the parameterized complexity classes co-W[1] and W[1] respectively, when parameterized by k. However we show that the former is fixed-parameter tractable when parameterized by the treewidth of the graph. We also show that the dual parameterizations of all the problems that we study are fixed parameter tractable.},
  archive      = {J_Alg},
  author       = {Francis, Mathew and Neogi, Rian and Raman, Venkatesh},
  doi          = {10.1007/s00453-021-00857-0},
  journal      = {Algorithmica},
  number       = {11},
  pages        = {3338-3362},
  shortjournal = {Algorithmica},
  title        = {Recognizing k-clique extendible orderings},
  volume       = {83},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Near isometric terminal embeddings for doubling metrics.
<em>Alg</em>, <em>83</em>(11), 3319‚Äì3337. (<a
href="https://doi.org/10.1007/s00453-021-00843-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given a metric space (X,¬†d), a set of terminals $$K\subseteq X$$ , and a parameter $$0&lt;\epsilon &lt;1$$ , we consider metric structures (e.g., spanners, distance oracles, embedding into normed spaces) that preserve distances for all pairs in $$K\times X$$ up to a factor of $$1+\epsilon$$ , and have small size (e.g. number of edges for spanners, dimension for embeddings). While such terminal (aka source-wise) metric structures are known to exist in several settings, no terminal spanner or embedding with distortion close to 1, is currently known. Here we devise such terminal metric structures for doubling metrics, and show that essentially any metric structure with distortion $$1+\epsilon$$ and space s(|X|) has its terminal counterpart, with distortion $$1+O(\epsilon )$$ and space $$s(|K|)+n$$ . In particular, for any doubling metric on n points, a set of k terminals, and constant $$0&lt;\epsilon &lt;1$$ , there exists Moreover, surprisingly, the last two results apply if only the metric space on K is doubling, while the metric on X can be arbitrary.},
  archive      = {J_Alg},
  author       = {Elkin, Michael and Neiman, Ofer},
  doi          = {10.1007/s00453-021-00843-6},
  journal      = {Algorithmica},
  number       = {11},
  pages        = {3319-3337},
  shortjournal = {Algorithmica},
  title        = {Near isometric terminal embeddings for doubling metrics},
  volume       = {83},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). On h-topological intersection graphs. <em>Alg</em>,
<em>83</em>(11), 3281‚Äì3318. (<a
href="https://doi.org/10.1007/s00453-021-00846-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bir√≥ et al. (Discrete. Math 100(1‚Äì3):267‚Äì279, 1992) introduced the concept of H-graphs, intersection graphs of connected subgraphs of a subdivision of a graph H. They are related to and generalize many important classes of geometric intersection graphs, e.g., interval graphs, circular-arc graphs, split graphs, and chordal graphs. Our paper starts a new line of research in the area of geometric intersection graphs by studying several classical computational problems on H-graphs: recognition, graph isomorphism, dominating set, clique, and colorability. We negatively answer the 25-year-old question of Bir√≥, Hujter, and Tuza which asks whether H-graphs can be recognized in polynomial time, for a fixed graph H. We prove that it is $$\textsf {NP}$$ -complete if H contains the diamond graph as a minor. On the positive side, we provide a polynomial-time algorithm recognizing T-graphs, for each fixed tree T. For the special case when T is a star $$S_d$$ of degree d, we have an $$\mathcal{O}(n^{3.5})$$ -time algorithm. We give $$\textsf {FPT}$$ - and $$\textsf {XP}$$ -time algorithms solving the minimum dominating set problem on $$S_d$$ -graphs and H-graphs, parametrized by d and the size of H, respectively. The algorithm for H-graphs adapts to an $$\textsf {XP}$$ -time algorithm for the independent set and the independent dominating set problems on H-graphs. If H contains the double-triangle as a minor, we prove that the graph isomorphism problem is GI-complete and that the clique problem is APX-hard. On the positive side, we show that the clique problem can be solved in polynomial time if H is a cactus graph. Also, when a graph has a Helly H-representation, the clique problem is polynomial-time solvable. Further, we show that both the k-clique and the list k-coloring problems are solvable in FPT-time on H-graphs, parameterized by k and the treewidth of H. In fact, these results apply to classes of graphs with treewidth bounded by a function of the clique number. We observe that H-graphs have at most $$n^{O(\Vert H\Vert )}$$ minimal separators which allows us to apply the meta-algorithmic framework of Fomin, Todinca, and Villanger (2015) to show that for each fixed t, finding a maximum induced subgraph of treewidth t can be done in polynomial time. In the case when H is a cactus, we improve the bound to $$O(\Vert H\Vert n^2)$$ .},
  archive      = {J_Alg},
  author       = {Chaplick, Steven and T√∂pfer, Martin and Voborn√≠k, Jan and Zeman, Peter},
  doi          = {10.1007/s00453-021-00846-3},
  journal      = {Algorithmica},
  number       = {11},
  pages        = {3281-3318},
  shortjournal = {Algorithmica},
  title        = {On H-topological intersection graphs},
  volume       = {83},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Runtime analyses of the population-based univariate
estimation of distribution algorithms on LeadingOnes. <em>Alg</em>,
<em>83</em>(10), 3238‚Äì3280. (<a
href="https://doi.org/10.1007/s00453-021-00862-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We perform rigorous runtime analyses for the univariate marginal distribution algorithm (UMDA) and the population-based incremental learning (PBIL) Algorithm on LeadingOnes. For the UMDA, the currently known expected runtime on the function is $${\mathcal {O}}\left( n\lambda \log \lambda +n^2\right)$$ under an offspring population size $$\lambda =\Omega (\log n)$$ and a parent population size $$\mu \le \lambda /(e(1+\delta ))$$ for any constant $$\delta &gt;0$$ (Dang and Lehre, GECCO 2015). There is no lower bound on the expected runtime under the same parameter settings. It also remains unknown whether the algorithm can still optimise the LeadingOnes function within a polynomial runtime when $$\mu \ge \lambda /(e(1+\delta ))$$ . In case of the PBIL, an expected runtime of $${\mathcal {O}}(n^{2+c})$$ holds for some constant $$c \in (0,1)$$ (Wu, Kolonko and M√∂hring, IEEE TEVC 2017). Despite being a generalisation of the UMDA, this upper bound is significantly asymptotically looser than the upper bound of $${\mathcal {O}}\left( n^2\right)$$ of the UMDA for $$\lambda =\Omega (\log n)\cap {\mathcal {O}}\left( n/\log n\right)$$ . Furthermore, the required population size is very large, i.e., $$\lambda =\Omega (n^{1+c})$$ . Our contributions are then threefold: (1) we show that the UMDA with $$\mu =\Omega (\log n)$$ and $$\lambda \le \mu e^{1-\varepsilon }/(1+\delta )$$ for any constants $$\varepsilon \in (0,1)$$ and $$0&lt;\delta \le e^{1-\varepsilon }-1$$ requires an expected runtime of $$e^{\Omega (\mu )}$$ on LeadingOnes, (2) an upper bound of $${\mathcal {O}}\left( n\lambda \log \lambda +n^2\right)$$ is shown for the PBIL, which improves the current bound $${\mathcal {O}}\left( n^{2+c}\right)$$ by a significant factor of $$\Theta (n^{c})$$ , and (3) we for the first time consider the two algorithms on the LeadingOnes function in a noisy environment and obtain an expected runtime of $${\mathcal {O}}\left( n^2\right)$$ for appropriate parameter settings. Our results emphasise that despite the independence assumption in the probabilistic models, the UMDA and the PBIL with fine-tuned parameter choices can still cope very well with variable interactions.},
  archive      = {J_Alg},
  author       = {Lehre, Per Kristian and Nguyen, Phan Trung Hai},
  doi          = {10.1007/s00453-021-00862-3},
  journal      = {Algorithmica},
  number       = {10},
  pages        = {3238-3280},
  shortjournal = {Algorithmica},
  title        = {Runtime analyses of the population-based univariate estimation of distribution algorithms on LeadingOnes},
  volume       = {83},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Improved runtime results for simple randomised search
heuristics on linear functions with a uniform constraint. <em>Alg</em>,
<em>83</em>(10), 3209‚Äì3237. (<a
href="https://doi.org/10.1007/s00453-020-00779-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the last decade remarkable progress has been made in development of suitable proof techniques for analysing randomised search heuristics. The theoretical investigation of these algorithms on classes of functions is essential to the understanding of the underlying stochastic process. Linear functions have been traditionally studied in this area resulting in tight bounds on the expected optimisation time of simple randomised search algorithms for this class of problems. Recently, the constrained version of this problem has gained attention and some theoretical results have also been obtained on this class of problems. In this paper we study the class of linear functions under uniform constraint and investigate the expected optimisation time of Randomised Local Search (RLS) and a simple evolutionary algorithm called (1+1)¬†EA. We prove a tight bound of $$\varTheta (n^2)$$ for RLS and improve the previously best known upper bound of (1+1)¬†EA from $$O(n^2 \log (Bw_{\max }))$$ to $$O(n^2\log B)$$ in expectation and to $$O(n^2 \log n)$$ with high probability, where $$w_{\max }$$ and B are the maximum weight of the linear objective function and the bound of the uniform constraint, respectively. Also, we obtain a tight bound of $$O(n^2)$$ for the (1+1)¬†EA on a special class of instances. We complement our theoretical studies by experimental investigations that consider different values of B and also higher mutation rates that reflect the fact that 2-bit flips are crucial for dealing with the uniform constraint.},
  archive      = {J_Alg},
  author       = {Neumann, Frank and Pourhassan, Mojgan and Witt, Carsten},
  doi          = {10.1007/s00453-020-00779-3},
  journal      = {Algorithmica},
  number       = {10},
  pages        = {3209-3237},
  shortjournal = {Algorithmica},
  title        = {Improved runtime results for simple randomised search heuristics on linear functions with a uniform constraint},
  volume       = {83},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Lower bounds on the runtime of crossover-based algorithms
via decoupling and family graphs. <em>Alg</em>, <em>83</em>(10),
3180‚Äì3208. (<a
href="https://doi.org/10.1007/s00453-020-00776-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The runtime analysis of evolutionary algorithms using crossover as search operator has recently produced remarkable results indicating benefits and drawbacks of crossover and illustrating its working principles. Virtually all these results are restricted to upper bounds on the running time of the crossover-based algorithms. This work addresses this lack of lower bounds and rigorously bounds the optimization time of simple algorithms using uniform crossover on the search space $${0,1}^n$$ from below via two novel techniques called decoupling and family graphs. First, a simple steady-state crossover-based evolutionary algorithm without selection pressure is analyzed and shown that after $$O(\mu \log \mu )$$ generations, bit positions are sampled almost independently with marginal probabilities corresponding to the fraction of one-bits at the corresponding position in the initial population. In the presence of weak selective pressure induced by the probabilistic application of tournament selection, it is demonstrated that the inheritance probability at an arbitrary locus quickly approaches a uniform distribution over the initial population up to additive factors that depend on the effect of selection. Afterwards, the algorithm is analyzed by a novel generalization of the family tree technique originally introduced for mutation-only EAs. Using these so-called family graphs, almost tight lower bounds on the optimization time on the OneMax benchmark function are shown.},
  archive      = {J_Alg},
  author       = {Sutton, Andrew M. and Witt, Carsten},
  doi          = {10.1007/s00453-020-00776-6},
  journal      = {Algorithmica},
  number       = {10},
  pages        = {3180-3208},
  shortjournal = {Algorithmica},
  title        = {Lower bounds on the runtime of crossover-based algorithms via decoupling and family graphs},
  volume       = {83},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Time complexity analysis of randomized search heuristics for
the dynamic graph coloring problem. <em>Alg</em>, <em>83</em>(10),
3148‚Äì3179. (<a
href="https://doi.org/10.1007/s00453-021-00838-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We contribute to the theoretical understanding of randomized search heuristics for dynamic problems. We consider the classical vertex coloring problem on graphs and investigate the dynamic setting where edges are added to the current graph. We then analyze the expected time for randomized search heuristics to recompute high quality solutions. The (1+1)¬†Evolutionary Algorithm and RLS operate in a setting where the number of colors is bounded and we are minimizing the number of conflicts. Iterated local search algorithms use an unbounded color palette and aim to use the smallest colors and, consequently, the smallest number of colors. We identify classes of bipartite graphs where reoptimization is as hard as or even harder than optimization from scratch, i.e., starting with a random initialization. Even adding a single edge can lead to hard symmetry problems. However, graph classes that are hard for one algorithm turn out to be easy for others. In most cases our bounds show that reoptimization is faster than optimizing from scratch. We further show that tailoring mutation operators to parts of the graph where changes have occurred can significantly reduce the expected reoptimization time. In most settings the expected reoptimization time for such tailored algorithms is linear in the number of added edges. However, tailored algorithms cannot prevent exponential times in settings where the original algorithm is inefficient.},
  archive      = {J_Alg},
  author       = {Bossek, Jakob and Neumann, Frank and Peng, Pan and Sudholt, Dirk},
  doi          = {10.1007/s00453-021-00838-3},
  journal      = {Algorithmica},
  number       = {10},
  pages        = {3148-3179},
  shortjournal = {Algorithmica},
  title        = {Time complexity analysis of randomized search heuristics for the dynamic graph coloring problem},
  volume       = {83},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Self-adjusting mutation rates with provably optimal success
rules. <em>Alg</em>, <em>83</em>(10), 3108‚Äì3147. (<a
href="https://doi.org/10.1007/s00453-021-00854-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The one-fifth success rule is one of the best-known and most widely accepted techniques to control the parameters of evolutionary algorithms. While it is often applied in the literal sense, a common interpretation sees the one-fifth success rule as a family of success-based updated rules that are determined by an update strength F and a success rate. We analyze in this work how the performance of the (1+1) Evolutionary Algorithm on Leading Ones depends on these two hyper-parameters. Our main result shows that the best performance is obtained for small update strengths $$F=1+o(1)$$ and success rate 1/e. We also prove that the running time obtained by this parameter setting is, apart from lower order terms, the same that is achieved with the best fitness-dependent mutation rate. We show similar results for the resampling variant of the (1+1) Evolutionary Algorithm, which enforces to flip at least one bit per iteration.},
  archive      = {J_Alg},
  author       = {Doerr, Benjamin and Doerr, Carola and Lengler, Johannes},
  doi          = {10.1007/s00453-021-00854-3},
  journal      = {Algorithmica},
  number       = {10},
  pages        = {3108-3147},
  shortjournal = {Algorithmica},
  title        = {Self-adjusting mutation rates with provably optimal success rules},
  volume       = {83},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The runtime of the compact genetic algorithm on jump
functions. <em>Alg</em>, <em>83</em>(10), 3059‚Äì3107. (<a
href="https://doi.org/10.1007/s00453-020-00780-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the first and so far only mathematical runtime analysis of an estimation-of-distribution algorithm (EDA) on a multimodal problem, Hasen√∂hrl and Sutton (GECCO 2018) showed for any $$k = o(n)$$ that the compact genetic algorithm (cGA) with any hypothetical population size $$\mu = \Omega (ne^{4k} + n^{3.5+\varepsilon })$$ with high probability finds the optimum of the n-dimensional jump function with jump size k in time $$O(\mu n^{1.5} \log n)$$ . We significantly improve this result for small jump sizes $$k \le \frac{1}{20} \ln n -1$$ . In this case, already for $$\mu = \Omega (\sqrt{n} \log n) \cap {{\,\mathrm{poly}\,}}(n)$$ the runtime of the cGA with high probability is only $$O(\mu \sqrt{n})$$ . For the smallest admissible values of $$\mu $$ , our result gives a runtime of $$O(n \log n)$$ , whereas the previous one only shows $$O(n^{5+\varepsilon })$$ . Since it is known that the cGA with high probability needs at least $$\Omega (\mu \sqrt{n})$$ iterations to optimize the unimodal $${\textsc {OneMax}} $$ function, our result shows that the cGA in contrast to most classic evolutionary algorithms here is able to cross moderate-sized valleys of low fitness at no extra cost. For large k, we show that the exponential (in k) runtime guarantee of Hasen√∂hrl and Sutton is tight and cannot be improved, also not by using a smaller hypothetical population size. We prove that any choice of the hypothetical population size leads to a runtime that, with high probability, is at least exponential in the jump size k. This result might be the first non-trivial exponential lower bound for EDAs that holds for arbitrary parameter settings. To complete the picture, we show that the cGA with hypothetical population size $$\mu = \Omega (\log n)$$ with high probability needs $$\Omega (\mu \sqrt{n} + n \log n)$$ iterations to optimize any n-dimensional jump function. This bound was known for OneMax, but, as we also show, the usual domination arguments do not allow to extend lower bounds on the performance of the cGA on OneMax to arbitrary functions with unique optimum. As a side result, we provide a simple general method based on parallel runs that, under mild conditions, (1)¬†overcomes the need to specify a suitable population size and still gives a performance close to the one stemming from the best-possible population size, and (2)¬†transforms EDAs with high-probability performance guarantees into EDAs with similar bounds on the expected runtime.},
  archive      = {J_Alg},
  author       = {Doerr, Benjamin},
  doi          = {10.1007/s00453-020-00780-w},
  journal      = {Algorithmica},
  number       = {10},
  pages        = {3059-3107},
  shortjournal = {Algorithmica},
  title        = {The runtime of the compact genetic algorithm on jump functions},
  volume       = {83},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multiplicative up-drift. <em>Alg</em>, <em>83</em>(10),
3017‚Äì3058. (<a
href="https://doi.org/10.1007/s00453-020-00775-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Drift analysis aims at translating the expected progress of an evolutionary algorithm (or more generally, a random process) into a probabilistic guarantee on its run time (hitting time). So far, drift arguments have been successfully employed in the rigorous analysis of evolutionary algorithms, however, only for the situation that the progress is constant or becomes weaker when approaching the target. Motivated by questions like how fast fit individuals take over a population, we analyze random processes exhibiting a $$(1+\delta )$$ -multiplicative growth in expectation. We prove a drift theorem translating this expected progress into a hitting time. This drift theorem gives a simple and insightful proof of the level-based theorem first proposed by Lehre (2011). Our version of this theorem has, for the first time, the best-possible near-linear dependence on $$1/\delta$$ (the previous results had an at least near-quadratic dependence), and it only requires a population size near-linear in $$\delta$$ (this was super-quadratic in previous results). These improvements immediately lead to stronger run time guarantees for a number of applications. We also discuss the case of large $$\delta$$ and show stronger results for this setting.},
  archive      = {J_Alg},
  author       = {Doerr, Benjamin and K√∂tzing, Timo},
  doi          = {10.1007/s00453-020-00775-7},
  journal      = {Algorithmica},
  number       = {10},
  pages        = {3017-3058},
  shortjournal = {Algorithmica},
  title        = {Multiplicative up-drift},
  volume       = {83},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Editor‚Äôs note: Special issue on genetic and evolutionary
computation. <em>Alg</em>, <em>83</em>(10), 3015‚Äì3016. (<a
href="https://doi.org/10.1007/s00453-021-00871-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_Alg},
  doi          = {10.1007/s00453-021-00871-2},
  journal      = {Algorithmica},
  number       = {10},
  pages        = {3015-3016},
  shortjournal = {Algorithmica},
  title        = {Editor‚Äôs note: Special issue on genetic and evolutionary computation},
  volume       = {83},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Online budgeted maximum coverage. <em>Alg</em>,
<em>83</em>(9), 2989‚Äì3014. (<a
href="https://doi.org/10.1007/s00453-021-00850-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the Online Budgeted Maximum Coverage problem. Subsets of a weighted ground set U arrive one by one, where each set has a cost. The online algorithm has to select a collection of sets, under the constraint that their cost is at most a given budget. Upon arrival of a set the algorithm must decide whether to accept or to irrevocably reject the arriving set, and it may also irrevocably drop previously accepted sets. The goal is to maximize the total weight of the elements covered by the sets in the chosen collection. We give a deterministic $$\frac{4}{1-r}$$ -competitive algorithm where r is the maximum ratio between the cost of a set and the total budget, and show that the competitive ratio of any deterministic online algorithm is $$\Omega (\frac{1}{1-r})$$ . We further give a randomized O(1)-competitive algorithm. We also give a deterministic $$O(\Delta )$$ -competitive algorithm, where $$\Delta $$ is the maximum weight of a set and a modified version of it with competitive ratio of $$O(\min {\Delta ,\sqrt{w(U)}})$$ for the case that the total weight of the elements, w(U), is known in advance. A matching lower bound of $$\Omega (\min {\Delta ,\sqrt{w(U)}})$$ is given. Finally, our results, including the lower bounds, apply also to Removable Online Knapsack.},
  archive      = {J_Alg},
  author       = {Rawitz, Dror and Ros√©n, Adi},
  doi          = {10.1007/s00453-021-00850-7},
  journal      = {Algorithmica},
  number       = {9},
  pages        = {2989-3014},
  shortjournal = {Algorithmica},
  title        = {Online budgeted maximum coverage},
  volume       = {83},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Selfish vector packing. <em>Alg</em>, <em>83</em>(9),
2952‚Äì2988. (<a
href="https://doi.org/10.1007/s00453-021-00849-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the multidimensional vector packing problem with selfish items. An item is a d-dimensional non-zero vector, whose rational components are in [0,¬†1]. A set of items can be packed into a bin if for every $$1 \le i \le d$$ , the sum of the ith components of all items of this set does not exceed 1. Items share costs of bins proportionally to the $$\ell _1$$ -norms of items, and each item corresponds to a selfish player in the sense that it prefers to be packed into a bin minimizing its resulting cost. This defines a class of games called vector packing games. We show that any game in this class has a packing that is a strong equilibrium, and that both the strong price of anarchy and the strong price of stability are logarithmic in d. We also provide an algorithm that constructs a packing that is a strong equilibrium. Furthermore, we show improved and nearly tight lower and upper bounds of $$d+0.657067$$ and $$d+0.657143$$ , respectively, for any $$d\ge 2$$ , on the price of anarchy. This exhibits a difference between the multidimensional problem and the one-dimensional problem, for which that price of anarchy is at most 1.6428.},
  archive      = {J_Alg},
  author       = {Epstein, Leah and Kleiman, Elena},
  doi          = {10.1007/s00453-021-00849-0},
  journal      = {Algorithmica},
  number       = {9},
  pages        = {2952-2988},
  shortjournal = {Algorithmica},
  title        = {Selfish vector packing},
  volume       = {83},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). On girth and the parameterized complexity of token sliding
and token jumping. <em>Alg</em>, <em>83</em>(9), 2914‚Äì2951. (<a
href="https://doi.org/10.1007/s00453-021-00848-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the Token Jumping problem we are given a graph $$G = (V,E)$$ and two independent sets S and T of G, each of size $$k \ge 1$$ . The goal is to determine whether there exists a sequence of k-sized independent sets in G, $$\langle S_0, S_1, \ldots , S_\ell \rangle$$ , such that for every i, $$|S_i| = k$$ , $$S_i$$ is an independent set, $$S = S_0$$ , $$S_\ell = T$$ , and $$|S_i \varDelta S_{i+1}| = 2$$ . In other words, if we view each independent set as a collection of tokens placed on a subset of the vertices of G, then the problem asks for a sequence of independent sets which transforms S to T by individual token jumps which maintain the independence of the sets. This problem is known to be PSPACE-complete on very restricted graph classes, e.g., planar bounded degree graphs and graphs of bounded bandwidth. A closely related problem is the Token Sliding problem, where instead of allowing a token to jump to any vertex of the graph we instead require that a token slides along an edge of the graph. Token Sliding is also known to be PSPACE-complete on the aforementioned graph classes. We investigate the parameterized complexity of both problems on several graph classes, focusing on the effect of excluding certain cycles from the input graph. In particular, we show that both Token Sliding and Token Jumping are fixed-parameter tractable on $$C_4$$ -free bipartite graphs when parameterized by k. For Token Jumping, we in fact show that the problem admits a polynomial kernel on $${C_3,C_4}$$ -free graphs. In the case of Token Sliding, we also show that the problem admits a polynomial kernel on bipartite graphs of bounded degree. We believe both of these results to be of independent interest. We complement these positive results by showing that, for any constant $$p \ge 4$$ , both problems are W[1]-hard on $${C_4, \dots , C_p}$$ -free graphs and Token Sliding remains W[1]-hard even on bipartite graphs.},
  archive      = {J_Alg},
  author       = {Bartier, Valentin and Bousquet, Nicolas and Dallard, Cl√©ment and Lomer, Kyle and Mouawad, Amer E.},
  doi          = {10.1007/s00453-021-00848-1},
  journal      = {Algorithmica},
  number       = {9},
  pages        = {2914-2951},
  shortjournal = {Algorithmica},
  title        = {On girth and the parameterized complexity of token sliding and token jumping},
  volume       = {83},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A new lower bound for deterministic truthful scheduling.
<em>Alg</em>, <em>83</em>(9), 2895‚Äì2913. (<a
href="https://doi.org/10.1007/s00453-021-00847-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the problem of truthfully scheduling m tasks to n selfish unrelated machines, under the objective of makespan minimization, as was introduced in the seminal work of Nisan and Ronen (in: The 31st Annual ACM symposium on Theory of Computing (STOC), 1999). Closing the current gap of [2.618,¬†n] on the approximation ratio of deterministic truthful mechanisms is a notorious open problem in the field of algorithmic mechanism design. We provide the first such improvement in more than a decade, since the lower bounds of 2.414 (for $$n=3$$ ) and 2.618 (for $$n\rightarrow \infty$$ ) by Christodoulou et al. (in: Proceedings of the 18th Annual ACM-SIAM Symposium on Discrete Algorithms (SODA), 2007) and Koutsoupias and Vidali (in: Proceedings of Mathematical Foundations of Computer Science (MFCS), 2007), respectively. More specifically, we show that the currently best lower bound of 2.618 can be achieved even for just $$n=4$$ machines; for $$n=5$$ we already get the first improvement, namely 2.711; and allowing the number of machines to grow arbitrarily large we can get a lower bound of 2.755.},
  archive      = {J_Alg},
  author       = {Giannakopoulos, Yiannis and Hammerl, Alexander and Po√ßas, Diogo},
  doi          = {10.1007/s00453-021-00847-2},
  journal      = {Algorithmica},
  number       = {9},
  pages        = {2895-2913},
  shortjournal = {Algorithmica},
  title        = {A new lower bound for deterministic truthful scheduling},
  volume       = {83},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A queueing network-based distributed laplacian solver.
<em>Alg</em>, <em>83</em>(9), 2859‚Äì2894. (<a
href="https://doi.org/10.1007/s00453-021-00845-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We use queueing networks to present a new approach to solving Laplacian systems. This marks a significant departure from the existing techniques, mostly based on graph-theoretic constructions and sampling. Our distributed solver works for a large and important class of Laplacian systems that we call ‚Äúone-sink‚Äù Laplacian systems. Specifically, our solver can produce solutions for systems of the form $$L\varvec{x} = \varvec{b}$$ where exactly one of the coordinates of $$\varvec{b}$$ is negative. Our solver is a distributed algorithm that takes $${\widetilde{O}}(t_{\text{ hit }}\hat{d}_{\max })$$ time (where $${\widetilde{O}}$$ hides $${\text {poly}}\log n$$ factors) to produce an approximate solution where $$t_{\text{ hit }}$$ is the worst-case hitting time of the random walk on the graph, which is $$\Theta (n)$$ for a large set of important graphs, and $$\hat{d}_{\max }$$ is the¬†maximum degree of the graph. The class of one-sink Laplacians includes the important voltage computation problem and allows us to compute the effective resistance between nodes in a distributed setting. As a result, our Laplacian solver can be used to adapt the approach by Kelner and MƒÖdry (2009) to give the first distributed algorithm to compute approximate random spanning trees efficiently.},
  archive      = {J_Alg},
  author       = {Gillani, Iqra Altaf and Bagchi, Amitabha},
  doi          = {10.1007/s00453-021-00845-4},
  journal      = {Algorithmica},
  number       = {9},
  pages        = {2859-2894},
  shortjournal = {Algorithmica},
  title        = {A queueing network-based distributed laplacian solver},
  volume       = {83},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Best fit bin packing with random order revisited.
<em>Alg</em>, <em>83</em>(9), 2833‚Äì2858. (<a
href="https://doi.org/10.1007/s00453-021-00844-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Best Fit is a well known online algorithm for the bin packing problem, where a collection of one-dimensional items has to be packed into a minimum number of unit-sized bins. In a seminal work, Kenyon [SODA 1996] introduced the (asymptotic) random order ratio as an alternative performance measure for online algorithms. Here, an adversary specifies the items, but the order of arrival is drawn uniformly at random. Kenyon‚Äôs result establishes lower and upper bounds of 1.08 and 1.5, respectively, for the random order ratio of Best Fit. Although this type of analysis model became increasingly popular in the field of online algorithms, no progress has been made for the Best Fit algorithm after the result of Kenyon. We study the random order ratio of Best Fit and tighten the long-standing gap by establishing an improved lower bound of 1.10. For the case where all items are larger than 1/3, we show that the random order ratio converges quickly to 1.25. It is the existence of such large items that crucially determines the performance of Best Fit in the general case. Moreover, this case is closely related to the classical maximum-cardinality matching problem in the fully online model. As a side product, we show that Best Fit satisfies a monotonicity property on such instances, unlike in the general case. In addition, we initiate the study of the absolute random order ratio for this problem. In contrast to asymptotic ratios, absolute ratios must hold even for instances that can be packed into a small number of bins. We show that the absolute random order ratio of Best Fit is at least 1.3. For the case where all items are larger than 1/3, we derive upper and lower bounds of 21/16 and 1.2, respectively.},
  archive      = {J_Alg},
  author       = {Albers, Susanne and Khan, Arindam and Ladewig, Leon},
  doi          = {10.1007/s00453-021-00844-5},
  journal      = {Algorithmica},
  number       = {9},
  pages        = {2833-2858},
  shortjournal = {Algorithmica},
  title        = {Best fit bin packing with random order revisited},
  volume       = {83},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Scheduling in the random-order model. <em>Alg</em>,
<em>83</em>(9), 2803‚Äì2832. (<a
href="https://doi.org/10.1007/s00453-021-00841-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Makespan minimization on identical machines is a fundamental problem in online scheduling. The goal is to assign a sequence of jobs to m identical parallel machines so as to minimize the maximum completion time of any job. Already in the 1960s, Graham showed that Greedy is $$(2-1/m)$$ -competitive. The best deterministic online algorithm currently known achieves a competitive ratio of 1.9201. No deterministic online strategy can obtain a competitiveness smaller than 1.88.¬†In this paper, we study online makespan minimization in the popular random-order model, where the jobs of a given input arrive as a random permutation. It is known that Greedy does not attain a competitive factor asymptotically smaller than¬†2 in this setting. We present the first improved performance guarantees. Specifically, we develop a deterministic online algorithm that achieves a competitive ratio of 1.8478. The result relies on a new analysis approach. We identify a set of properties that a random permutation of the input jobs satisfies with high probability. Then we conduct a worst-case analysis of our algorithm, for the respective class of permutations. The analysis implies that the stated competitiveness holds not only in expectation but with high probability. Moreover, it provides mathematical evidence that job sequences leading to higher performance ratios are extremely rare, pathological inputs. We complement the results by lower bounds, for the random-order model. We show that no deterministic online algorithm can achieve a competitive ratio smaller than 4/3. Moreover, no deterministic online algorithm can attain a competitiveness smaller than 3/2 with high probability.},
  archive      = {J_Alg},
  author       = {Albers, Susanne and Janke, Maximilian},
  doi          = {10.1007/s00453-021-00841-8},
  journal      = {Algorithmica},
  number       = {9},
  pages        = {2803-2832},
  shortjournal = {Algorithmica},
  title        = {Scheduling in the random-order model},
  volume       = {83},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Finding temporal paths under waiting time constraints.
<em>Alg</em>, <em>83</em>(9), 2754‚Äì2802. (<a
href="https://doi.org/10.1007/s00453-021-00831-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Computing a (short) path between two vertices is one of the most fundamental primitives in graph algorithmics. In recent years, the study of paths in temporal graphs, that is, graphs where the vertex set is fixed but the edge set changes over time, gained more and more attention. A path is time-respecting, or temporal, if it uses edges with non-decreasing time stamps. We investigate a basic constraint for temporal paths, where the time spent at each vertex must not exceed a given duration $$\varDelta $$ , referred to as $$\varDelta $$ -restless temporal paths. This constraint arises naturally in the modeling of real-world processes like packet routing in communication networks and infection transmission routes of diseases where recovery confers lasting resistance. While finding temporal paths without waiting time restrictions is known to be doable in polynomial time, we show that the ‚Äúrestless variant‚Äù of this problem becomes computationally hard even in very restrictive settings. For example, it is W[1]-hard when parameterized by the distance to disjoint path of the underlying graph, which implies W[1]-hardness for many other parameters like feedback vertex number and pathwidth. A natural question is thus whether the problem becomes tractable in some natural settings. We explore several natural parameterizations, presenting FPT algorithms for three kinds of parameters: (1) output-related parameters (here, the maximum length of the path), (2) classical parameters applied to the underlying graph (e.g., feedback edge number), and (3) a new parameter called timed feedback vertex number, which captures finer-grained temporal features of the input temporal graph, and which may be of interest beyond this work.},
  archive      = {J_Alg},
  author       = {Casteigts, Arnaud and Himmel, Anne-Sophie and Molter, Hendrik and Zschoche, Philipp},
  doi          = {10.1007/s00453-021-00831-w},
  journal      = {Algorithmica},
  number       = {9},
  pages        = {2754-2802},
  shortjournal = {Algorithmica},
  title        = {Finding temporal paths under waiting time constraints},
  volume       = {83},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Online node- and edge-deletion problems with advice.
<em>Alg</em>, <em>83</em>(9), 2719‚Äì2753. (<a
href="https://doi.org/10.1007/s00453-021-00840-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In online edge- and node-deletion problems the input arrives node by node and an algorithm has to delete nodes or edges in order to keep the input graph in a given graph class $$\Pi $$ at all times. We consider only hereditary properties $$\Pi $$ , for which optimal online algorithms exist and which can be characterized by a set of forbidden subgraphs $${{\mathcal{F}}}$$ and analyze the advice complexity of getting an optimal solution. We give almost tight bounds on the Delayed Connected $${{\mathcal{F}}}$$ -Node-Deletion Problem, where all graphs of the family $${\mathcal{F}}$$ have to be connected and almost tight lower and upper bounds for the Delayed $$H$$ -Node-Deletion Problem, where there is one forbidden induced subgraph H that may be connected or not. For the Delayed $$H$$ -Node-Deletion Problem the advice complexity is basically an easy function of the size of the biggest component in¬†H. Additionally, we give tight bounds on the Delayed Connected $${\mathcal{F}}$$ -Edge-Deletion Problem, where we have an arbitrary number of forbidden connected graphs. For the latter result we present an algorithm that computes the advice complexity directly from $${\mathcal{F}}$$ . We give a separate analysis for the Delayed Connected $$H$$ -Edge-Deletion Problem, which is less general but admits a bound that is easier to compute.},
  archive      = {J_Alg},
  author       = {Chen, Li-Hsuan and Hung, Ling-Ju and Lotze, Henri and Rossmanith, Peter},
  doi          = {10.1007/s00453-021-00840-9},
  journal      = {Algorithmica},
  number       = {9},
  pages        = {2719-2753},
  shortjournal = {Algorithmica},
  title        = {Online node- and edge-deletion problems with advice},
  volume       = {83},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Connectivity keeping trees in 2-connected graphs with girth
conditions. <em>Alg</em>, <em>83</em>(9), 2697‚Äì2718. (<a
href="https://doi.org/10.1007/s00453-021-00833-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mader conjectured in 2010 that for any tree T of order m, every k-connected graph G with minimum degree at least $$\lfloor \frac{3k}{2} \rfloor +m-1$$ contains a subtree $$T&#39; \cong T$$ such that $$G-V(T&#39;)$$ is k-connected. This conjecture has been proved for $$k = 1$$ ; however, it remains open for general $$k \ge 2$$ ; for $$k = 2$$ , partially affirmative answers have been shown, all of which restrict the class of trees to special subclasses such as trees with at most 5 internal vertices, trees of order at most 8, trees with diameter at most 4, caterpillars, and spiders. We first extend the previously known subclass of trees for which Mader‚Äôs conjecture for $$k = 2$$ holds; namely, we show that Mader‚Äôs conjecture for $$k = 2$$ is true for the class of bifurcate quasi-unimodal caterpillars which includes every caterpillar and every tree of order m with diameter at least $$m-4$$ . Instead of restricting the class of trees, we next consider 2-connected graphs with girth conditions. We then show that Mader‚Äôs conjecture is true for every 2-connected graph G with $$g(G) \ge \delta (G)-8$$ , where g(G) and $$\delta (G)$$ denote the girth of G and the minimum degree of a vertex in G, respectively. Besides, we show that for every 2-connected graph G with $$g(G) \ge \delta (G)-7$$ , the lower bound of $$m+2$$ on $$\delta (G)$$ in Mader‚Äôs conjecture can be improved to $$m+1$$ if $$m \ge 10$$ . Moreover, the lower bound of $$\delta (G)-8$$ (respectively, $$\delta (G)-7$$ ) on g(G) in these results can be improved to $$\delta (G)-9$$ (respectively, $$\delta (G) -8$$ with $$m \ge 11$$ ) if no six (respectively, four) cycles of length g(G) have a common path of length $$\left\lceil \frac{g(G)}{2} \right\rceil -1$$ in G. We also show that Mader‚Äôs conjecture holds for every 2-connected graph G with $$g^\circ (G) \ge \delta (G)-8$$ , where $$g^\circ (G)$$ is the overlapping girth of G. Mader‚Äôs conjecture is interesting not only from a theoretical point of view but also from a practical point of view, since it may be applied to fault-tolerant problems in communication networks. Our proofs lead to $$O(|V(G)|^4)$$ time algorithms for finding a desired subtree in a given 2-connected graph G satisfying the assumptions.},
  archive      = {J_Alg},
  author       = {Hasunuma, Toru},
  doi          = {10.1007/s00453-021-00833-8},
  journal      = {Algorithmica},
  number       = {9},
  pages        = {2697-2718},
  shortjournal = {Algorithmica},
  title        = {Connectivity keeping trees in 2-connected graphs with girth conditions},
  volume       = {83},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Strongly stable and maximum weakly stable noncrossing
matchings. <em>Alg</em>, <em>83</em>(9), 2678‚Äì2696. (<a
href="https://doi.org/10.1007/s00453-021-00832-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In IWOCA 2019, Ruangwises and Itoh introduced stable noncrossing matchings, where participants of each side are aligned on each of two parallel lines, and no two matching edges are allowed to cross each other. They defined two stability notions, strongly stable noncrossing matching (SSNM) and weakly stable noncrossing matching (WSNM), depending on the strength of blocking pairs. They proved that a WSNM always exists and presented an $$O(n^{2})$$ -time algorithm to find one for an instance with n men and n women. They also posed open questions of the complexities of determining existence of an SSNM and finding a largest WSNM. In this paper, we show that both problems are solvable in polynomial time. Our algorithms are applicable to extensions where preference lists may include ties, except for one case which we show to be NP-complete. This NP-completeness holds even if each person&#39;s preference list is of length at most two and ties appear in only men&#39;s preference lists. To complement this intractability, we show that the problem is solvable in polynomial time if the length of preference lists of one side is bounded by one (but that of the other side is unbounded).},
  archive      = {J_Alg},
  author       = {Hamada, Koki and Miyazaki, Shuichi and Okamoto, Kazuya},
  doi          = {10.1007/s00453-021-00832-9},
  journal      = {Algorithmica},
  number       = {9},
  pages        = {2678-2696},
  shortjournal = {Algorithmica},
  title        = {Strongly stable and maximum weakly stable noncrossing matchings},
  volume       = {83},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). On the complexity of broadcast domination and multipacking
in digraphs. <em>Alg</em>, <em>83</em>(9), 2651‚Äì2677. (<a
href="https://doi.org/10.1007/s00453-021-00828-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the complexity of the two dual covering and packing distance-based problems Broadcast Domination and Multipacking in digraphs. A dominating broadcast of a digraph D is a function $$f:V(D)\rightarrow {\mathbb {N}}$$ such that for each vertex v of D, there exists a vertex t with $$f(t)&gt;0$$ having a directed path to v of length at most f(t). The cost of f is the sum of f(v) over all vertices v. A multipacking is a set S of vertices of D such that for each vertex v of D and for every integer d, there are at most d vertices from S within directed distance at most d from v. The maximum size of a multipacking of D is a lower bound to the minimum cost of a dominating broadcast of D. Let Broadcast Domination denote the problem of deciding whether a given digraph D has a dominating broadcast of cost at most k, and Multipacking the problem of deciding whether D has a multipacking of size at least k. It is known that Broadcast Domination is polynomial-time solvable for the class of all undirected graphs (that is, symmetric digraphs), while polynomial-time algorithms for Multipacking are known only for a few classes of undirected graphs. We prove that Broadcast Domination and Multipacking are both NP-complete for digraphs, even for planar layered acyclic digraphs of small maximum degree. Moreover, when parameterized by the solution cost/solution size, we show that the problems are respectively W[2]-hard and W[1]-hard. We also show that Broadcast Domination is FPT on acyclic digraphs, and that it does not admit a polynomial kernel for such inputs, unless the polynomial hierarchy collapses to its third level. In addition, we show that both problems are FPT when parameterized by the solution cost/solution size together with the maximum (out-)degree, and as well, by the vertex cover number. Finally, we give for both problems polynomial-time algorithms for some subclasses of acyclic digraphs.},
  archive      = {J_Alg},
  author       = {Foucaud, Florent and Gras, Benjamin and Perez, Anthony and Sikora, Florian},
  doi          = {10.1007/s00453-021-00828-5},
  journal      = {Algorithmica},
  number       = {9},
  pages        = {2651-2677},
  shortjournal = {Algorithmica},
  title        = {On the complexity of broadcast domination and multipacking in digraphs},
  volume       = {83},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Subexponential-time algorithms for finding large induced
sparse subgraphs. <em>Alg</em>, <em>83</em>(8), 2634‚Äì2650. (<a
href="https://doi.org/10.1007/s00453-020-00745-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Let $${\mathcal {C}}$$ and $${\mathcal {D}}$$ be hereditary graph classes. Consider the following problem: given a graph $$G\in {\mathcal {D}}$$ , find a largest, in terms of the number of vertices, induced subgraph of G that belongs to $${\mathcal {C}}$$ . We prove that it can be solved in $$2^{o(n)}$$ time, where n is the number of vertices of G, if the following conditions are satisfied: This leads, for example, to the following corollaries for specific classes $${\mathcal {C}}$$ and $${\mathcal {D}}$$ :},
  archive      = {J_Alg},
  author       = {Novotn√°, Jana and Okrasa, Karolina and Pilipczuk, Micha≈Ç and RzƒÖ≈ºewski, Pawe≈Ç and van Leeuwen, Erik Jan and Walczak, Bartosz},
  doi          = {10.1007/s00453-020-00745-z},
  journal      = {Algorithmica},
  number       = {8},
  pages        = {2634-2650},
  shortjournal = {Algorithmica},
  title        = {Subexponential-time algorithms for finding large induced sparse subgraphs},
  volume       = {83},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Metric dimension parameterized by treewidth. <em>Alg</em>,
<em>83</em>(8), 2606‚Äì2633. (<a
href="https://doi.org/10.1007/s00453-021-00808-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A resolving set S of a graph G is a subset of its vertices such that no two vertices of G have the same distance vector to S. The Metric Dimension problem asks for a resolving set of minimum size, and in its decision form, a resolving set of size at most some specified integer. This problem is NP-complete, and remains so in very restricted classes of graphs. It is also W[2]-complete with respect to the size of the solution. Metric Dimension has proven elusive on graphs of bounded treewidth. On the algorithmic side, a polynomial time algorithm is known for trees, and even for outerplanar graphs, but the general case of treewidth at most two is open. On the complexity side, no parameterized hardness is known. This has led several papers on the topic to ask for the parameterized complexity of Metric Dimension with respect to treewidth. We provide a first answer to the question. We show that Metric Dimension parameterized by the treewidth of the input graph is W[1]-hard. More refinedly we prove that, unless the Exponential Time Hypothesis fails, there is no algorithm solving Metric Dimension in time $$f(\text {pw})n^{o(\text {pw})}$$ on n-vertex graphs of constant degree, with $$\text {pw}$$ the pathwidth of the input graph, and f any computable function. This is in stark contrast with an FPT algorithm of Belmonte et al. (SIAM J Discrete Math 31(2):1217‚Äì1243, 2017) with respect to the combined parameter $$\text {tl}+\Delta$$ , where $$\text {tl}$$ is the tree-length and $$\Delta$$ the maximum-degree of the input graph.},
  archive      = {J_Alg},
  author       = {Bonnet, √âdouard and Purohit, Nidhi},
  doi          = {10.1007/s00453-021-00808-9},
  journal      = {Algorithmica},
  number       = {8},
  pages        = {2606-2633},
  shortjournal = {Algorithmica},
  title        = {Metric dimension parameterized by treewidth},
  volume       = {83},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Faster algorithms for counting subgraphs in sparse graphs.
<em>Alg</em>, <em>83</em>(8), 2578‚Äì2605. (<a
href="https://doi.org/10.1007/s00453-021-00811-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given a k-node pattern graph H and an n-node host graph G, the subgraph counting problem asks to compute the number of copies of H in G. In this work we address the following question: can we count the copies of H faster if G is sparse? We answer in the affirmative by introducing a novel tree-like decomposition for directed acyclic graphs, inspired by the classic tree decomposition for undirected graphs. This decomposition gives a dynamic program for counting the homomorphisms of H in G by exploiting the degeneracy of G, which allows us to beat the state-of-the-art subgraph counting algorithms when G is sparse enough. For example, we can count the induced copies of any k-node pattern H in time $$2^{O(k^2)} O(n^{0.25k + 2} \log n)$$ if G has bounded degeneracy, and in time $$2^{O(k^2)} O(n^{0.625k + 2} \log n)$$ if G has bounded average degree. These bounds are instantiations of a more general result, parameterized by the degeneracy of G and the structure of H, which generalizes classic bounds on counting cliques and complete bipartite graphs. We also give lower bounds based on the Exponential Time Hypothesis, showing that our results are actually a characterization of the complexity of subgraph counting in bounded-degeneracy graphs.},
  archive      = {J_Alg},
  author       = {Bressan, Marco},
  doi          = {10.1007/s00453-021-00811-0},
  journal      = {Algorithmica},
  number       = {8},
  pages        = {2578-2605},
  shortjournal = {Algorithmica},
  title        = {Faster algorithms for counting subgraphs in sparse graphs},
  volume       = {83},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Finding and counting permutations via CSPs. <em>Alg</em>,
<em>83</em>(8), 2552‚Äì2577. (<a
href="https://doi.org/10.1007/s00453-021-00812-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Permutation patterns and pattern avoidance have been intensively studied in combinatorics and computer science, going back at least to the seminal work of Knuth on stack-sorting (1968). Perhaps the most natural algorithmic question in this area is deciding whether a given permutation of length n contains a given pattern of length k. In this work we give two new algorithms for this well-studied problem, one whose running time is $$n^{k/4 + o(k)}$$ , and a polynomial-space algorithm whose running time is the better of $$O(1.6181^n)$$ and $$O(n^{k/2 + 1})$$ . These results improve the earlier best bounds of $$n^{0.47k + o(k)}$$ and $$O(1.79^n)$$ due to Ahal and Rabinovich (2000) resp. Bruner and Lackner (2012) and are the fastest algorithms for the problem when $$k \in \varOmega (\log {n})$$ . We show that both our new algorithms and the previous exponential-time algorithms in the literature can be viewed through the unifying lens of constraint-satisfaction. Our algorithms can also count, within the same running time, the number of occurrences of a pattern. We show that this result is close to optimal: solving the counting problem in time $$f(k) \cdot n^{o(k/\log {k})}$$ would contradict the exponential-time hypothesis (ETH). For some special classes of patterns we obtain improved running times. We further prove that 3-increasing (4321-avoiding) and 3-decreasing (1234-avoiding) permutations can, in some sense, embed arbitrary permutations of almost linear length, which indicates that a sub-exponential running time is unlikely with the current techniques, even for patterns from these restricted classes.},
  archive      = {J_Alg},
  author       = {Berendsohn, Benjamin Aram and Kozma, L√°szl√≥ and Marx, D√°niel},
  doi          = {10.1007/s00453-021-00812-z},
  journal      = {Algorithmica},
  number       = {8},
  pages        = {2552-2577},
  shortjournal = {Algorithmica},
  title        = {Finding and counting permutations via CSPs},
  volume       = {83},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Beating treewidth for average-case subgraph isomorphism.
<em>Alg</em>, <em>83</em>(8), 2521‚Äì2551. (<a
href="https://doi.org/10.1007/s00453-021-00813-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For any fixed graph G, the subgraph isomorphism problem asks whether an n-vertex input graph has a subgraph isomorphic to G. A well-known algorithm of Alon et al. (J ACM 42(4):844‚Äì856, 1995. https://doi.org/10.1145/210332.210337 ) efficiently reduces this to the ‚Äúcolored‚Äù version of the problem, denoted $$G{\text{-}}{\mathsf {SUB}}$$ , and then solves $$G{\text{-}}{\mathsf {SUB}}$$ in time $$O(n^{{\textit{tw}}(G)+1})$$ where $${\textit{tw}}(G)$$ is the treewidth of G. Marx (Theory Comput 6(1):85‚Äì112, 2010. https://doi.org/10.4086/toc.2010.v006a005 ) conjectured that $$G{\text{-}}{\mathsf {SUB}}$$ requires time $$\varOmega (n^{{{\mathrm {const}}}\cdot {\textit{tw}}(G)})$$ and, assuming the Exponential Time Hypothesis, proved a lower bound of $$\varOmega (n^{{{\mathrm {const}}}\cdot {\textit{emb}}(G)})$$ for a certain graph parameter $${\textit{emb}}(G) \ge \varOmega ({\textit{tw}}(G)/\log {\textit{tw}}(G))$$ . With respect to the size of $${{\mathrm {AC}}}^0$$ circuits solving $$G{\text{-}}{\mathsf {SUB}}$$ in the average case, Li et al. (SIAM J Comput 46(3):936‚Äì971, 2017. https://doi.org/10.1137/14099721X ) proved (unconditional) upper and lower bounds of $$O(n^{2\kappa (G)+{{\mathrm {const}}}})$$ and $$\varOmega (n^{\kappa (G)})$$ for a different graph parameter $$\kappa (G) \ge \varOmega ({\textit{tw}}(G)/\log {\textit{tw}}(G))$$ . Our contributions are as follows. First, we prove that $${\textit{emb}}(G)$$ is $$O(\kappa (G))$$ for all graphs G. Next, we show that $$\kappa (G)$$ can be asymptotically less than $${\textit{tw}}(G)$$ ; for example, if G is a hypercube then $$\kappa (G)$$ is $$\varTheta \left( {\textit{tw}}(G)\big /\sqrt{\log {\textit{tw}}(G)}\right) $$ . This implies that the average-case complexity of $$G{\text{-}}{\mathsf {SUB}}$$ is $$n^{o({\textit{tw}}(G))}$$ when G is a hypercube. Finally, we construct $${{\mathrm {AC}}}^0$$ circuits of size $$O(n^{\kappa (G)+{{\mathrm {const}}}})$$ that solve $$G{\text{-}}{\mathsf {SUB}}$$ in the average case, closing the gap between the upper and lower bounds of Li et al.},
  archive      = {J_Alg},
  author       = {Rosenthal, Gregory},
  doi          = {10.1007/s00453-021-00813-y},
  journal      = {Algorithmica},
  number       = {8},
  pages        = {2521-2551},
  shortjournal = {Algorithmica},
  title        = {Beating treewidth for average-case subgraph isomorphism},
  volume       = {83},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Improved analysis of highest-degree branching for feedback
vertex set. <em>Alg</em>, <em>83</em>(8), 2503‚Äì2520. (<a
href="https://doi.org/10.1007/s00453-021-00815-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent empirical evaluations of exact algorithms for Feedback Vertex Set have demonstrated the efficiency of a highest-degree branching algorithm with a degree-based pruning. In this paper, we prove that this empirically fast algorithm runs in $$O(3.460^k n)$$ time, where k is the solution size. This improves the previous best $$O(3.619^k n)$$ -time deterministic algorithm obtained by Kociumaka and Pilipczuk (Inf Process Lett 114:556‚Äì560, 2014. https://doi.org/10.1016/j.ipl.2014.05.001 ).},
  archive      = {J_Alg},
  author       = {Iwata, Yoichi and Kobayashi, Yusuke},
  doi          = {10.1007/s00453-021-00815-w},
  journal      = {Algorithmica},
  number       = {8},
  pages        = {2503-2520},
  shortjournal = {Algorithmica},
  title        = {Improved analysis of highest-degree branching for feedback vertex set},
  volume       = {83},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). C-planarity testing of embedded clustered graphs with
bounded dual carving-width. <em>Alg</em>, <em>83</em>(8), 2471‚Äì2502. (<a
href="https://doi.org/10.1007/s00453-021-00839-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For a clustered graph, i.e, a graph whose vertex set is recursively partitioned into clusters, the C-Planarity Testing problem asks whether it is possible to find a planar embedding of the graph and a representation of each cluster as a region homeomorphic to a closed disk such that (1)¬†the subgraph induced by each cluster is drawn in the interior of the corresponding disk, (2)¬†each edge intersects any disk at most once, and (3)¬†the nesting between clusters is reflected by the representation, i.e., child clusters are properly contained in their parent cluster. The computational complexity of this problem, whose study has been central to the theory of graph visualization since its introduction in 1995 [Feng, Cohen, and Eades, Planarity for clustered graphs, ESA‚Äô95], has only been recently settled [Fulek and T√≥th, Atomic Embeddability, Clustered Planarity, and Thickenability, to appear at SODA‚Äô20]. Before such a breakthrough, the complexity question was still unsolved even when the graph has a prescribed planar embedding, i.e, for embedded clustered graphs. We show that the C-Planarity Testing problem admits a single-exponential single-parameter FPT (resp., XP) algorithm for embedded flat (resp., non-flat) clustered graphs, when parameterized by the carving-width of the dual graph of the input. These are the first FPT and XP algorithms for this long-standing open problem with respect to a single notable graph-width parameter. Moreover, the polynomial dependency of our FPT algorithm is smaller than the one of the algorithm by Fulek and T√≥th. In particular, our algorithm runs in quadratic time for flat instances of bounded treewidth and bounded face size. To further strengthen the relevance of this result, we show that an algorithm with running time O(r(n)) for flat instances whose underlying graph has pathwidth 1 would result in an algorithm with running time O(r(n)) for flat instances and with running time $$O(r(n^2) + n^2)$$ for general, possibly non-flat, instances.},
  archive      = {J_Alg},
  author       = {Da Lozzo, Giordano and Eppstein, David and Goodrich, Michael T. and Gupta, Siddharth},
  doi          = {10.1007/s00453-021-00839-2},
  journal      = {Algorithmica},
  number       = {8},
  pages        = {2471-2502},
  shortjournal = {Algorithmica},
  title        = {C-planarity testing of embedded clustered graphs with bounded dual carving-width},
  volume       = {83},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Special issue dedicated to the 14th international symposium
on parameterized and exact computation. <em>Alg</em>, <em>83</em>(8),
2469‚Äì2470. (<a
href="https://doi.org/10.1007/s00453-021-00853-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_Alg},
  author       = {Jansen, Bart M. P. and Telle, Jan Arne},
  doi          = {10.1007/s00453-021-00853-4},
  journal      = {Algorithmica},
  number       = {8},
  pages        = {2469-2470},
  shortjournal = {Algorithmica},
  title        = {Special issue dedicated to the 14th international symposium on parameterized and exact computation},
  volume       = {83},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The maximum binary tree problem. <em>Alg</em>,
<em>83</em>(8), 2427‚Äì2468. (<a
href="https://doi.org/10.1007/s00453-021-00836-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce and investigate the approximability of the maximum binary tree problem (MBT) in directed and undirected graphs. The goal in MBT is to find a maximum-sized binary tree in a given graph. MBT is a natural variant of the well-studied longest path problem, since both can be viewed as finding a maximum-sized tree of bounded degree in a given graph. The connection to longest path motivates the study of MBT in directed acyclic graphs (DAGs), since the longest path problem is solvable efficiently in DAGs. In contrast, we show that MBT in DAGs is hard: it has no efficient $$\exp (-O(\log n/ \log \log n))$$ -approximation under the exponential time hypothesis, where n is the number of vertices in the input graph. In undirected graphs, we show that MBT has no efficient $$\exp (-O(\log ^{0.63}{n}))$$ -approximation under the exponential time hypothesis. Our inapproximability results rely on self-improving reductions and structural properties of binary trees. We also show constant-factor inapproximability assuming $${\mathbf {P}}\ne \mathbf {NP}$$ . In addition to inapproximability results, we present algorithmic results along two different flavors: (1) We design a randomized algorithm to verify if a given directed graph on n vertices contains a binary tree of size k in $$2^k \mathsf {poly}(n)$$ time. (2) Motivated by the longest heapable subsequence problem, introduced by Byers, Heeringa, Mitzenmacher, and Zervas, ANALCO 2011, which is equivalent to MBT in permutation DAGs, we design efficient algorithms for MBT in bipartite permutation graphs.},
  archive      = {J_Alg},
  author       = {Chandrasekaran, Karthekeyan and Grigorescu, Elena and Istrate, Gabriel and Kulkarni, Shubhang and Lin, Young-San and Zhu, Minshen},
  doi          = {10.1007/s00453-021-00836-5},
  journal      = {Algorithmica},
  number       = {8},
  pages        = {2427-2468},
  shortjournal = {Algorithmica},
  title        = {The maximum binary tree problem},
  volume       = {83},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A new algorithm for the <span
class="math display"><sup><em>K</em></sup></span> DMDGP subclass of
distance geometry problems with exact distances. <em>Alg</em>,
<em>83</em>(8), 2400‚Äì2426. (<a
href="https://doi.org/10.1007/s00453-021-00835-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The fundamental inverse problem in distance geometry is the one of finding positions from inter-point distances. The Discretizable Molecular Distance Geometry Problem (DMDGP) is a subclass of the Distance Geometry Problem (DGP) whose search space can be discretized and represented by a binary tree, which can be explored by a Branch-and-Prune (BP) algorithm. It turns out that this combinatorial search space possesses many interesting symmetry properties that were studied in the last decade. In this paper, we present a new algorithm for this subclass of the DGP, which exploits DMDGP symmetries more effectively than its predecessors. Computational results show that the speedup, with respect to the classic BP algorithm, is considerable for sparse DMDGP instances related to protein conformation.},
  archive      = {J_Alg},
  author       = {Gon√ßalves, Douglas S. and Lavor, Carlile and Liberti, Leo and Souza, Michael},
  doi          = {10.1007/s00453-021-00835-6},
  journal      = {Algorithmica},
  number       = {8},
  pages        = {2400-2426},
  shortjournal = {Algorithmica},
  title        = {A new algorithm for the $$^K$$ DMDGP subclass of distance geometry problems with exact distances},
  volume       = {83},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Online multistage subset maximization problems.
<em>Alg</em>, <em>83</em>(8), 2374‚Äì2399. (<a
href="https://doi.org/10.1007/s00453-021-00834-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Numerous combinatorial optimization problems (knapsack, maximum-weight matching, etc.) can be expressed as subset maximization problems: One is given a ground set $$N={1,\dots ,n}$$ , a collection $$\mathcal {F}\subseteq 2^N$$ of subsets thereof such that $$\emptyset \in \mathcal {F}$$ , and an objective (profit) function $$p:\mathcal {F}\rightarrow \mathbb {R}_+$$ . The task is to choose a set $$S\in \mathcal {F}$$ that maximizes p(S). We consider the multistage version (Eisenstat et al., Gupta et al., both ICALP 2014) of such problems: The profit function $$p_t$$ (and possibly the set of feasible solutions $$\mathcal {F}_t$$ ) may change over time. Since in many applications changing the solution is costly, the task becomes to find a sequence of solutions that optimizes the trade-off between good per-time solutions and stable solutions taking into account an additional similarity bonus. As similarity measure for two consecutive solutions, we consider either the size of the intersection of the two solutions or the difference of n and the Hamming distance between the two characteristic vectors. We study multistage subset maximization problems in the online setting, that is, $$p_t$$ (along with possibly $$\mathcal {F}_t$$ ) only arrive one by one and, upon such an arrival, the online algorithm has to output the corresponding solution without knowledge of the future. We develop general techniques for online multistage subset maximization and thereby characterize those models (given by the type of data evolution and the type of similarity measure) that admit a constant-competitive online algorithm. When no constant competitive ratio is possible, we employ lookahead to circumvent this issue. When a constant competitive ratio is possible, we provide almost matching lower and upper bounds on the best achievable one.},
  archive      = {J_Alg},
  author       = {Bampis, Evripidis and Escoffier, Bruno and Schewior, Kevin and Teiller, Alexandre},
  doi          = {10.1007/s00453-021-00834-7},
  journal      = {Algorithmica},
  number       = {8},
  pages        = {2374-2399},
  shortjournal = {Algorithmica},
  title        = {Online multistage subset maximization problems},
  volume       = {83},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). On the complexity of finding large odd induced subgraphs and
odd colorings. <em>Alg</em>, <em>83</em>(8), 2351‚Äì2373. (<a
href="https://doi.org/10.1007/s00453-021-00830-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the complexity of the problems of finding, given a graph G, a largest induced subgraph of G with all degrees odd (called an odd subgraph), and the smallest number of odd subgraphs that partition V(G). We call these parameters $$\mathsf{mos}(G)$$ and $$\chi _{\mathsf{odd}}(G)$$ , respectively. We prove that deciding whether $$\chi _{\mathsf{odd}}(G) \le q$$ is polynomial-time solvable if $$q \le 2$$ , and NP-complete otherwise. We provide algorithms in time $$2^{{{\mathcal {O}}}(\mathsf{rw})} \cdot n^{{{\mathcal {O}}}(1)}$$ and $$2^{{{\mathcal {O}}}(q \cdot \mathsf{rw})} \cdot n^{{{\mathcal {O}}}(1)}$$ to compute $$\mathsf{mos}(G)$$ and to decide whether $$\chi _{\mathsf{odd}}(G) \le q$$ on n-vertex graphs of rank-width at most $$\mathsf{rw}$$ , respectively, and we prove that the dependency on rank-width is asymptotically optimal under the ETH. Finally, we give some tight bounds for these parameters on restricted graph classes or in relation to other parameters.},
  archive      = {J_Alg},
  author       = {Belmonte, R√©my and Sau, Ignasi},
  doi          = {10.1007/s00453-021-00830-x},
  journal      = {Algorithmica},
  number       = {8},
  pages        = {2351-2373},
  shortjournal = {Algorithmica},
  title        = {On the complexity of finding large odd induced subgraphs and odd colorings},
  volume       = {83},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The (2, k)-connectivity augmentation problem: Algorithmic
aspects. <em>Alg</em>, <em>83</em>(8), 2333‚Äì2350. (<a
href="https://doi.org/10.1007/s00453-021-00829-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Durand de Gevigney and Szigeti (J Gr Theory 91(4):305‚Äì325, 2019) have recently given a min‚Äìmax theorem for the (2,¬†k)-connectivity augmentation problem. This article provides an $$O(n^3(m+ n \text { }\log \text { }n))$$ time algorithm to find an optimal solution for this problem.},
  archive      = {J_Alg},
  author       = {H√∂rsch, Florian and Szigeti, Zolt√°n},
  doi          = {10.1007/s00453-021-00829-4},
  journal      = {Algorithmica},
  number       = {8},
  pages        = {2333-2350},
  shortjournal = {Algorithmica},
  title        = {The (2, k)-connectivity augmentation problem: Algorithmic aspects},
  volume       = {83},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Approximation in (poly-) logarithmic space. <em>Alg</em>,
<em>83</em>(7), 2303‚Äì2331. (<a
href="https://doi.org/10.1007/s00453-021-00826-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We develop new approximation algorithms for classical graph and set problems in the RAM model under space constraints. As one of our main results, we devise an algorithm for $$d\text {-}\textsc {Hitting Set}{}$$ that runs in time $$n^{{{\,\mathrm{O}\,}}{(d^2 + (d / \epsilon ))}}$$ , uses $${{\,\mathrm{O}\,}}{((d^2 + (d / \epsilon ))\log {n})}$$ bits of space, and achieves an approximation ratio of $${{\,\mathrm{O}\,}}{((d / \epsilon ) n^{\epsilon })}$$ for any positive $$\epsilon \le 1$$ and any $$d \in {\mathbb {N}}$$ . In particular, this yields a factor- $${{\,\mathrm{O}\,}}{(\log {n})}$$ approximation algorithm which runs in time $$n^{{{\,\mathrm{O}\,}}{(\log {n})}}$$ and uses $${{\,\mathrm{O}\,}}{(\log ^2{n})}$$ bits of space (for constant d). As a corollary, we obtain similar bounds for $$\textsc {Vertex Cover}{}$$ and several graph deletion problems. For bounded-multiplicity problem instances, one can do better. We devise a factor-2 approximation algorithm for $$\textsc {Vertex Cover}{}$$ on graphs with maximum degree $$\varDelta$$ , and an algorithm for computing maximal independent sets, both of which run in time $$n^{{{\,\mathrm{O}\,}}{(\varDelta )}}$$ and use $${{\,\mathrm{O}\,}}{(\varDelta \log {n})}$$ bits of space. For the more general $$d\text {-}\textsc {Hitting Set}{}$$ problem, we devise a factor-d approximation algorithm which runs in time $$n^{{{\,\mathrm{O}\,}}{(d{\delta }^2)}}$$ and uses $${{\,\mathrm{O}\,}}{(d {\delta }^2 \log {n})}$$ bits of space on set families where each element appears in at most $$\delta$$ sets. For $$\textsc {Independent Set}{}$$ restricted to graphs with average degree d, we give a factor-(2d) approximation algorithm which runs in polynomial time and uses $${{\,\mathrm{O}\,}}{(\log {n})}$$ bits of space. We also devise a factor- $${{\,\mathrm{O}\,}}{(d^2)}$$ approximation algorithm for $$\textsc {Dominating Set}{}$$ on d-degenerate graphs which runs in time $$n^{{{\,\mathrm{O}\,}}{(\log {n})}}$$ and uses $${{\,\mathrm{O}\,}}{(\log ^2{n})}$$ bits of space. For d-regular graphs, we show how a known randomized factor- $${{\,\mathrm{O}\,}}{(\log {d})}$$ approximation algorithm can be derandomized to run in time $$n^{{{\,\mathrm{O}\,}}{(1)}}$$ and use $${{\,\mathrm{O}\,}}{(\log n)}$$ bits of space. Our results use a combination of ideas from the theory of kernelization, distributed algorithms and randomized algorithms.},
  archive      = {J_Alg},
  author       = {Biswas, Arindam and Raman, Venkatesh and Saurabh, Saket},
  doi          = {10.1007/s00453-021-00826-7},
  journal      = {Algorithmica},
  number       = {7},
  pages        = {2303-2331},
  shortjournal = {Algorithmica},
  title        = {Approximation in (Poly-) logarithmic space},
  volume       = {83},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). On the minimum consistent subset problem. <em>Alg</em>,
<em>83</em>(7), 2273‚Äì2302. (<a
href="https://doi.org/10.1007/s00453-021-00825-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Let P be a set of n colored points in the d-dimensional Euclidean space. Introduced by Hart (1968), a consistent subset of P, is a set $$S\subseteq P$$ such that for every point p in $$P {\setminus } S$$ , the closest point of p in S has the same color as p. The consistent subset problem is to find a consistent subset of P with minimum cardinality. This problem is known to be NP-complete even for two-colored point sets. Since the initial presentation of this problem, aside from the hardness results, there has not been significant progress from the algorithmic point of view. In this paper we present the following algorithmic results for the consistent subset problem in the plane: (1) The first subexponential-time algorithm for the consistent subset problem. (2) An $$O(n\log n)$$ -time algorithm that finds a consistent subset of size two in two-colored point sets (if such a subset exists). Along the way we prove the following result which is of an independent interest: given n translations of a cone (defined as the intersection of n halfspaces) and n points in $$\mathbb {R}^3$$ , in $$O(n\log n)$$ time one can decide whether or not there is a point in a cone. (3) An $$O(n\log ^2 n)$$ -time algorithm that finds a minimum consistent subset in two-colored point sets where one color class contains exactly one point; this improves the previous best known $$O(n^2)$$ running time which is due to Wilfong (SoCG 1991). (4) An O(n)-time algorithm for the consistent subset problem on collinear points that are given from left to right; this improves the previous best known $$O(n^2)$$ running time. (5) A non-trivial $$O(n^6)$$ -time dynamic programming algorithm for the consistent subset problem on points arranged on two parallel lines. To obtain these results, we combine tools from planar separators, paraboloid lifting, additively-weighted Voronoi diagrams with respect to convex distance functions, point location in farthest-point Voronoi diagrams, range trees, minimum covering of a circle with arcs, and several geometric transformations.},
  archive      = {J_Alg},
  author       = {Biniaz, Ahmad and Cabello, Sergio and Carmi, Paz and De Carufel, Jean-Lou and Maheshwari, Anil and Mehrabi, Saeed and Smid, Michiel},
  doi          = {10.1007/s00453-021-00825-8},
  journal      = {Algorithmica},
  number       = {7},
  pages        = {2273-2302},
  shortjournal = {Algorithmica},
  title        = {On the minimum consistent subset problem},
  volume       = {83},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Convex-straight-skeleton voronoi diagrams for segments and
convex polygons. <em>Alg</em>, <em>83</em>(7), 2245‚Äì2272. (<a
href="https://doi.org/10.1007/s00453-021-00824-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study the convex-straight-skeleton Voronoi diagrams of line segments and convex polygons. We explore the combinatorial complexity of these diagrams, and provide efficient algorithms for computing compact representations of them.},
  archive      = {J_Alg},
  author       = {Barequet, Gill and De, Minati and Goodrich, Michael T.},
  doi          = {10.1007/s00453-021-00824-9},
  journal      = {Algorithmica},
  number       = {7},
  pages        = {2245-2272},
  shortjournal = {Algorithmica},
  title        = {Convex-straight-skeleton voronoi diagrams for segments and convex polygons},
  volume       = {83},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Compact distributed certification of planar graphs.
<em>Alg</em>, <em>83</em>(7), 2215‚Äì2244. (<a
href="https://doi.org/10.1007/s00453-021-00823-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Naor M., Parter M., Yogev E.: (The power of distributed verifiers in interactive proofs. In: 31st ACM-SIAM symposium on discrete algorithms (SODA), pp 1096‚Äì115, 2020. https://doi.org/10.1137/1.9781611975994.67 ) have recently demonstrated the existence of a distributed interactive proof for planarity (i.e., for certifying that a network is planar), using a sophisticated generic technique for constructing distributed IP protocols based on sequential IP protocols. The interactive proof for planarity is based on a distributed certification of the correct execution of any given sequential linear-time algorithm for planarity testing. It involves three interactions between the prover and the randomized distributed verifier (i.e., it is a dMAM protocol), and uses small certificates, on $$O(\log n)$$ bits in n-node networks. We show that a single interaction with the prover suffices, and randomization is unecessary, by providing an explicit description of a proof-labeling scheme for planarity, still using certificates on just $$O(\log n)$$ bits. We also show that there are no proof-labeling schemes‚Äîin fact, even no locally checkable proofs‚Äîfor planarity using certificates on $$o(\log n)$$ bits.},
  archive      = {J_Alg},
  author       = {Feuilloley, Laurent and Fraigniaud, Pierre and Montealegre, Pedro and Rapaport, Ivan and R√©mila, √âric and Todinca, Ioan},
  doi          = {10.1007/s00453-021-00823-w},
  journal      = {Algorithmica},
  number       = {7},
  pages        = {2215-2244},
  shortjournal = {Algorithmica},
  title        = {Compact distributed certification of planar graphs},
  volume       = {83},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Subexponential parameterized algorithms and kernelization on
almost chordal graphs. <em>Alg</em>, <em>83</em>(7), 2170‚Äì2214. (<a
href="https://doi.org/10.1007/s00453-021-00822-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study algorithmic properties of the graph class $${\textsc {Chordal}}{-ke}$$ , that is, graphs that can be turned into a chordal graph by adding at most k edges or, equivalently, the class of graphs of fill-in at most k. It appears that a number of fundamental intractable optimization problems being parameterized by k admit subexponential algorithms on graphs from $${\textsc {Chordal}}{-ke}$$ . More precisely, we identify a large class of optimization problems on $${\textsc {Chordal}}{-ke}$$ solvable in time $$2^{{\mathcal{O}}(\sqrt{k}\log k)}\cdot n^{{\mathcal{O}}(1)}$$ . Examples of the problems from this class are finding an independent set of maximum weight, finding a feedback vertex set or an odd cycle transversal of minimum weight, or the problem of finding a maximum induced planar subgraph. On the other hand, we show that for some fundamental optimization problems, like finding an optimal graph coloring or finding a maximum clique, are FPT on $${\textsc {Chordal}}{-ke}$$ when parameterized by k but do not admit subexponential in k algorithms unless ETH fails. Besides subexponential time algorithms, the class of $${\textsc {Chordal}}{-ke}$$ graphs appears to be appealing from the perspective of kernelization (with parameter k). While it is possible to show that most of the weighted variants of optimization problems do not admit polynomial in k kernels on $${\textsc {Chordal}}{-ke}$$ graphs, this does not exclude the existence of Turing kernelization and kernelization for unweighted graphs. In particular, we construct a polynomial Turing kernel for Weighted Clique on $${\textsc {Chordal}}{-ke}$$ graphs. For (unweighted) Independent Set we design polynomial kernels on two interesting subclasses of $${\textsc {Chordal}}{-ke}$$ , namely, $${\textsc {Interval}}{-ke}$$ and $${\textsc {Split}}{-ke}$$ graphs.},
  archive      = {J_Alg},
  author       = {Fomin, Fedor V. and Golovach, Petr A.},
  doi          = {10.1007/s00453-021-00822-x},
  journal      = {Algorithmica},
  number       = {7},
  pages        = {2170-2214},
  shortjournal = {Algorithmica},
  title        = {Subexponential parameterized algorithms and kernelization on almost chordal graphs},
  volume       = {83},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Internal dictionary matching. <em>Alg</em>, <em>83</em>(7),
2142‚Äì2169. (<a
href="https://doi.org/10.1007/s00453-021-00821-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce data structures answering queries concerning the occurrences of patterns from a given dictionary $$\mathsf {D}$$ in fragments of a given string T of length n. The dictionary is internal in the sense that each pattern in $$\mathsf {D}$$ is given as a fragment of T. This way, $$\mathsf {D}$$ takes space proportional to the number of patterns $$d=|\mathsf {D}|$$ rather than their total length, which could be $$\varTheta (n\cdot d)$$ . In particular, we consider the following types of queries: reporting and counting all occurrences of patterns from $$\mathsf {D}$$ in a fragment $$T[i \mathinner {.\,.}j]$$ and reporting distinct patterns from $$\mathsf {D}$$ that occur in $$T[i \mathinner {.\,.}j]$$ . We show how to construct, in $$O((n+d) \log ^{O(1)} n)$$ time, a data structure that answers each of these queries in time $$O(\log ^{O(1)} n+| output |)$$ . The case of counting patterns is much more involved and needs a combination of a locally consistent parsing with orthogonal range searching. Reporting distinct patterns, on the other hand, uses the structure of maximal repetitions in strings. Finally, we provide tight‚Äîup to subpolynomial factors‚Äîupper and lower bounds for the case of a dynamic dictionary.},
  archive      = {J_Alg},
  author       = {Charalampopoulos, Panagiotis and Kociumaka, Tomasz and Mohamed, Manal and Radoszewski, Jakub and Rytter, Wojciech and Wale≈Ñ, Tomasz},
  doi          = {10.1007/s00453-021-00821-y},
  journal      = {Algorithmica},
  number       = {7},
  pages        = {2142-2169},
  shortjournal = {Algorithmica},
  title        = {Internal dictionary matching},
  volume       = {83},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A polynomial kernel for distance-hereditary vertex deletion.
<em>Alg</em>, <em>83</em>(7), 2096‚Äì2141. (<a
href="https://doi.org/10.1007/s00453-021-00820-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A graph is distance-hereditary if for any pair of vertices, their distance in every connected induced subgraph containing both vertices is the same as their distance in the original graph. The Distance-Hereditary Vertex Deletion problem asks, given a graph G on n vertices and an integer k, whether there is a set S of at most k vertices in G such that $$G-S$$ is distance-hereditary. This problem is important due to its connection to the graph parameter rank-width because distance-hereditary graphs are exactly the graphs of rank-width at most 1. Eiben, Ganian, and Kwon (JCSS‚Äô 18) proved that Distance-Hereditary Vertex Deletion can be solved in time $$2^{{\mathcal {O}}(k)}n^{{\mathcal {O}}(1)}$$ , and asked whether it admits a polynomial kernelization. We show that this problem admits a polynomial kernel, answering this question positively. For this, we use a similar idea for obtaining an approximate solution for Chordal Vertex Deletion due to Jansen and Pilipczuk (SIDMA‚Äô 18) to obtain an approximate solution with $${\mathcal {O}}(k^3\log n+ k^2\log ^2 n)$$ vertices when the problem is a Yes-instance, and we exploit the structure of split decompositions of distance-hereditary graphs to reduce the total size.},
  archive      = {J_Alg},
  author       = {Kim, Eun Jung and Kwon, O-joung},
  doi          = {10.1007/s00453-021-00820-z},
  journal      = {Algorithmica},
  number       = {7},
  pages        = {2096-2141},
  shortjournal = {Algorithmica},
  title        = {A polynomial kernel for distance-hereditary vertex deletion},
  volume       = {83},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Producing genomic sequences after genome scaffolding with
ambiguous paths: Complexity, approximation and lower bounds.
<em>Alg</em>, <em>83</em>(7), 2063‚Äì2095. (<a
href="https://doi.org/10.1007/s00453-021-00819-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Scaffolding is the final step in assembling Next Generation Sequencing data, in which pre-assembled contiguous regions (‚Äùcontigs‚Äù) are oriented and ordered using information that links them (for example, mapping of paired-end reads). As the genome of some species is highly repetitive, we allow placing some contigs multiple times, thereby generalizing established computational models for this problem. We study the subsequent problems induced by the translation of solutions of the model back to actual sequences, proposing models and analyzing the complexity of the resulting computational problems. We find both polynomial-time and $$\mathcal {NP}$$ -hard special cases like planarity or bounded degree. Finally, we propose two polynomial-time approximation algorithms according to cut/weight score.},
  archive      = {J_Alg},
  author       = {Davot, Tom and Chateau, Annie and Giroudeau, Rodolphe and Weller, Mathias and Tabary, Dorine},
  doi          = {10.1007/s00453-021-00819-6},
  journal      = {Algorithmica},
  number       = {7},
  pages        = {2063-2095},
  shortjournal = {Algorithmica},
  title        = {Producing genomic sequences after genome scaffolding with ambiguous paths: Complexity, approximation and lower bounds},
  volume       = {83},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A new lower bound for classic online bin packing.
<em>Alg</em>, <em>83</em>(7), 2047‚Äì2062. (<a
href="https://doi.org/10.1007/s00453-021-00818-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We improve the lower bound on the asymptotic competitive ratio of any online algorithm for bin packing to above 1.54278. We demonstrate for the first time the advantage of branching and the applicability of full adaptivity in the design of lower bounds for the classic online bin packing problem. We apply a new method for weight based analysis, which is usually applied only in proofs of upper bounds. The values of previous lower bounds were approximately 1.5401 and 1.5403.},
  archive      = {J_Alg},
  author       = {Balogh, J√°nos and B√©k√©si, J√≥zsef and D√≥sa, Gy√∂rgy and Epstein, Leah and Levin, Asaf},
  doi          = {10.1007/s00453-021-00818-7},
  journal      = {Algorithmica},
  number       = {7},
  pages        = {2047-2062},
  shortjournal = {Algorithmica},
  title        = {A new lower bound for classic online bin packing},
  volume       = {83},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Cluster deletion on interval graphs and split related
graphs. <em>Alg</em>, <em>83</em>(7), 2018‚Äì2046. (<a
href="https://doi.org/10.1007/s00453-021-00817-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the Cluster Deletion problem the goal is to remove the minimum number of edges of a given graph, such that every connected component of the resulting graph constitutes a clique. It is known that the decision version of Cluster Deletion is NP-complete on ( $$P_5$$ -free) chordal graphs, whereas Cluster Deletion is solved in polynomial time on split graphs. However, the existence of a polynomial-time algorithm of Cluster Deletion on interval graphs, a proper subclass of chordal graphs, remained a well-known open problem. Our main contribution is that we settle this problem in the affirmative, by providing a polynomial-time algorithm for Cluster Deletion on interval graphs. Moreover, despite the simple formulation of a polynomial-time algorithm on split graphs, we show that Cluster Deletion remains NP-complete on a natural and slight generalization of split graphs that constitutes a proper subclass of $$P_5$$ -free chordal graphs. Although the later result arises from the already-known reduction for $$P_5$$ -free chordal graphs, we give an alternative proof showing an interesting connection between edge-weighted and vertex-weighted variations of the problem. To complement our results, we provide faster and simpler polynomial-time algorithms for Cluster Deletion on subclasses of such a generalization of split graphs.},
  archive      = {J_Alg},
  author       = {Konstantinidis, Athanasios L. and Papadopoulos, Charis},
  doi          = {10.1007/s00453-021-00817-8},
  journal      = {Algorithmica},
  number       = {7},
  pages        = {2018-2046},
  shortjournal = {Algorithmica},
  title        = {Cluster deletion on interval graphs and split related graphs},
  volume       = {83},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Correlation clustering in data streams. <em>Alg</em>,
<em>83</em>(7), 1980‚Äì2017. (<a
href="https://doi.org/10.1007/s00453-021-00816-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Clustering is a fundamental tool for analyzing large data sets. A rich body of work has been devoted to designing data-stream algorithms for the relevant optimization problems such as k-center, k-median, and k-means. Such algorithms need to be both time and and space efficient. In this paper, we address the problem of correlation clustering in the dynamic data stream model. The stream consists of updates to the edge weights of a graph on¬†n nodes and the goal is to find a node-partition such that the end-points of negative-weight edges are typically in different clusters whereas the end-points of positive-weight edges are typically in the same cluster. We present polynomial-time, $$O(n\cdot {{\,\mathrm{polylog}\,}}n)$$ -space approximation algorithms for natural problems that arise. We first develop data structures based on linear sketches that allow the ‚Äúquality‚Äù of a given node-partition to be measured. We then combine these data structures with convex programming and sampling techniques to solve the relevant approximation problem. Unfortunately, the standard LP and SDP formulations are not obviously solvable in $$O(n\cdot {{\,\mathrm{polylog}\,}}n)$$ -space. Our work presents space-efficient algorithms for the convex programming required, as well as approaches to reduce the adaptivity of the sampling.},
  archive      = {J_Alg},
  author       = {Ahn, Kook Jin and Cormode, Graham and Guha, Sudipto and McGregor, Andrew and Wirth, Anthony},
  doi          = {10.1007/s00453-021-00816-9},
  journal      = {Algorithmica},
  number       = {7},
  pages        = {1980-2017},
  shortjournal = {Algorithmica},
  title        = {Correlation clustering in data streams},
  volume       = {83},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Sorting a permutation by best short swaps. <em>Alg</em>,
<em>83</em>(7), 1953‚Äì1979. (<a
href="https://doi.org/10.1007/s00453-021-00814-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A permutation is happy, if it can be transformed into the identity permutation using as many short swaps as one third times the number of inversions in the permutation. The complexity of the decision version of sorting a permutation by short swaps, is still open. We present an O(n) time algorithm to decide whether it is true for a permutation to be happy, where n is the number of elements in the permutation. If a permutation is happy, we give an $$O(n^2)$$ time algorithm to find a sequence of as many short swaps as one third times the number of its inversions, to transform it into the identity permutation. A permutation is lucky, if it can be transformed into the identity permutation using as many short swaps as one fourth times the length sum of the permutation‚Äôs element vectors. We present an O(n) time algorithm to decide whether it is true for a permutation to be lucky, where n is the number of elements in the permutation. If a permutation is lucky, we give an $$O(n^2)$$ time algorithm to find a sequence of as many short swaps as one fourth times the length sum of its element vectors to transform it into the identity permutation. This improves upon the $$O(n^2)$$ time algorithm proposed by Heath and Vergara to decide whether a permutation is lucky. We show that there are at least $$2^{\lceil \frac{n}{2}\rceil -2}$$ happy permutations as well as $$2^{n-4}$$ lucky permutations of n elements.},
  archive      = {J_Alg},
  author       = {Zhang, Shu and Zhu, Daming and Jiang, Haitao and Guo, Jiong and Feng, Haodi and Liu, Xiaowen},
  doi          = {10.1007/s00453-021-00814-x},
  journal      = {Algorithmica},
  number       = {7},
  pages        = {1953-1979},
  shortjournal = {Algorithmica},
  title        = {Sorting a permutation by best short swaps},
  volume       = {83},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Independent sets and hitting sets of bicolored rectangular
families. <em>Alg</em>, <em>83</em>(6), 1918‚Äì1952. (<a
href="https://doi.org/10.1007/s00453-021-00810-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A bicolored rectangular family BRF is the collection of all axis-parallel rectangles formed by selecting a bottom-left corner from a finite set of points A and an upper-right corner from a finite set of points B. We devise a combinatorial algorithm to compute the maximum independent set and the minimum hitting set of a BRF that runs in $$O(n^{2.5}\sqrt{\log n})$$ -time, where $$n=|A |+|B |$$ . This result significantly reduces the gap between the $$\Omega (n^7)$$ -time algorithm by Bencz√∫r (Discrete Appl Math 129 (2‚Äì3):233‚Äì262, 2003) for the more general problem of finding directed covers of pairs of sets, and the $$O(n^2)$$ -time algorithms of Franzblau and Kleitman (Inf Control 63(3):164‚Äì189, 1984) and Knuth (ACM J Exp Algorithm 1:1, 1996) for BRFs where the points of A lie on an anti-diagonal line. Furthermore, when the bicolored rectangular family is weighted, we show that the problem of finding the maximum weight of an independent set is $$\mathbf {NP}$$ -hard, and provide efficient algorithms to solve it on important subclasses.},
  archive      = {J_Alg},
  author       = {Soto, Jos√© A. and Telha, Claudio},
  doi          = {10.1007/s00453-021-00810-1},
  journal      = {Algorithmica},
  number       = {6},
  pages        = {1918-1952},
  shortjournal = {Algorithmica},
  title        = {Independent sets and hitting sets of bicolored rectangular families},
  volume       = {83},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Active-learning a convex body in low dimensions.
<em>Alg</em>, <em>83</em>(6), 1885‚Äì1917. (<a
href="https://doi.org/10.1007/s00453-021-00807-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Consider a set $$P\subseteq \mathbb {R}^d$$ of n points, and a convex body $$C$$ provided via a separation oracle. The task at hand is to decide for each point of $$P$$ if it is in $$C$$ using the fewest number of oracle queries. We show that one can solve this problem in two and three dimensions using queries, where is the size of the largest subset of points of $$P$$ in convex position. In 2D, we provide an algorithm that efficiently generates these adaptive queries. Furthermore, we show that in two dimensions one can solve this problem using oracle queries, where is a lower bound on the minimum number of queries that any algorithm for this specific instance requires. Finally, we consider other variations on the problem, such as using the fewest number of queries to decide if $$C$$ contains all points of $$P$$ . As an application of the above, we show that the discrete geometric median of a point set P in $$\mathbb {R}^2$$ can be computed in expected time.},
  archive      = {J_Alg},
  author       = {Har-Peled, Sariel and Jones, Mitchell and Rahul, Saladi},
  doi          = {10.1007/s00453-021-00807-w},
  journal      = {Algorithmica},
  number       = {6},
  pages        = {1885-1917},
  shortjournal = {Algorithmica},
  title        = {Active-learning a convex body in low dimensions},
  volume       = {83},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A sub-exponential FPT algorithm and a polynomial kernel for
minimum directed bisection on semicomplete digraphs. <em>Alg</em>,
<em>83</em>(6), 1861‚Äì1884. (<a
href="https://doi.org/10.1007/s00453-021-00806-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given an n-vertex digraph D and a non-negative integer k, the Minimum Directed Bisection problem asks if the vertices of D can be partitioned into two parts, say L and R, such that $${\vert {L} \vert }$$ and $${\vert {R} \vert }$$ differ by at most 1 and the number of arcs from R to L is at most k. This problem is known to be NP-hard even when $$k = 0$$ . We investigate the parameterized complexity of this problem on semicomplete digraphs. We show that Minimum Directed Bisection admits a sub-exponential time fixed-parameter tractable algorithm on semicomplete digraphs. We also show that Minimum Directed Bisection admits a polynomial kernel on semicomplete digraphs. To design the kernel, we use $$(n,k,k^2)$$ -splitters, which, to the best of our knowledge, have never been used before in the design of kernels. We also prove that Minimum Directed Bisection is NP-hard on semicomplete digraphs, but polynomial time solvable on tournaments.},
  archive      = {J_Alg},
  author       = {Madathil, Jayakrishnan and Sharma, Roohani and Zehavi, Meirav},
  doi          = {10.1007/s00453-021-00806-x},
  journal      = {Algorithmica},
  number       = {6},
  pages        = {1861-1884},
  shortjournal = {Algorithmica},
  title        = {A sub-exponential FPT algorithm and a polynomial kernel for minimum directed bisection on semicomplete digraphs},
  volume       = {83},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Parameterized counting of partially injective homomorphisms.
<em>Alg</em>, <em>83</em>(6), 1829‚Äì1860. (<a
href="https://doi.org/10.1007/s00453-021-00805-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the parameterized complexity of the problem of counting graph homomorphisms with given partial injectivity constraints, i.e., inequalities between pairs of vertices, which subsumes counting of graph homomorphisms, subgraph counting and, more generally, counting of answers to equi-join queries with inequalities. Our main result presents an exhaustive complexity classification for the problem in fixed-parameter tractable and $$\#\mathsf {W[1]}$$ -complete cases. The proof relies on the framework of linear combinations of homomorphisms as independently discovered by Chen and Mengel (PODS¬†16) and by Curticapean, Dell and Marx in the recent breakthrough result regarding the exact complexity of the subgraph counting problem (STOC¬†17). Moreover, we invoke Rota‚Äôs NBC-Theorem to obtain an explicit criterion for fixed-parameter tractability based on treewidth. The abstract classification theorem is then applied to the problem of counting locally injective graph homomorphisms from small pattern graphs to large target graphs. As a consequence, we are able to fully classify its parameterized complexity depending on the class of allowed pattern graphs.},
  archive      = {J_Alg},
  author       = {Roth, Marc},
  doi          = {10.1007/s00453-021-00805-y},
  journal      = {Algorithmica},
  number       = {6},
  pages        = {1829-1860},
  shortjournal = {Algorithmica},
  title        = {Parameterized counting of partially injective homomorphisms},
  volume       = {83},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Computing the rooted triplet distance between phylogenetic
networks. <em>Alg</em>, <em>83</em>(6), 1786‚Äì1828. (<a
href="https://doi.org/10.1007/s00453-021-00802-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rooted triplet distance measures the structural dissimilarity of two phylogenetic trees or phylogenetic networks by counting the number of rooted phylogenetic trees with exactly three leaf labels (called rooted triplets, or triplets for short) that occur as embedded subtrees in one, but not both, of them. Suppose that $$N_1 = (V_1, E_1)$$ and $$N_2 = (V_2, E_2)$$ are phylogenetic networks over a common leaf label set of size¬†n, that $$N_i$$ has level $$k_i$$ and maximum in-degree $$d_i$$ for $$i \in {1,2}$$ , and that the networks‚Äô out-degrees are unbounded. Write $$N = \max (|V_1|, |V_2|)$$ , $$M = \max (|E_1|, |E_2|)$$ , $$k = \max (k_1, k_2)$$ , and $$d = \max (d_1, d_2)$$ . Previous work has shown how to compute the rooted triplet distance between $$N_1$$ and $$N_2$$ in $$\mathrm {O}(n \log n)$$ time in the special case $$k \le 1$$ . For $$k &gt; 1$$ , no efficient algorithms are known; applying a classic method from¬†1980 by Fortune¬†et al.¬†in a direct way leads to a running time of $${\Omega }(N^{6} n^{3})$$ and the only existing non-trivial algorithm imposes restrictions on the networks‚Äô in- and out-degrees (in particular, it does not work when non-binary vertices are allowed). In this article, we develop two new algorithms with no such restrictions. Their running times are $$\mathrm {O}(N^{2} M + n^{3})$$ and $$\mathrm {O}(M + N k^{2} d^{2} + n^{3})$$ , respectively. We also provide implementations of our algorithms, evaluate their performance on simulated and real datasets, and make some observations on the limitations of the current definition of the rooted triplet distance in practice. Our prototype implementations have been packaged into the first publicly available software for computing the rooted triplet distance between unrestricted networks of arbitrary levels.},
  archive      = {J_Alg},
  author       = {Jansson, Jesper and Mampentzidis, Konstantinos and Rajaby, Ramesh and Sung, Wing-Kin},
  doi          = {10.1007/s00453-021-00802-1},
  journal      = {Algorithmica},
  number       = {6},
  pages        = {1786-1828},
  shortjournal = {Algorithmica},
  title        = {Computing the rooted triplet distance between phylogenetic networks},
  volume       = {83},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Improved online algorithms for knapsack and GAP in the
random order model. <em>Alg</em>, <em>83</em>(6), 1750‚Äì1785. (<a
href="https://doi.org/10.1007/s00453-021-00801-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The knapsack problem is one of the classical problems in combinatorial optimization: Given a set of items, each specified by its size and profit, the goal is to find a maximum profit packing into a knapsack of bounded capacity. In the online setting, items are revealed one by one and the decision, if the current item is packed or discarded forever, must be done immediately and irrevocably upon arrival. We study the online variant in the random order model where the input sequence is a uniform random permutation of the item set. We develop a randomized (1/6.65)-competitive algorithm for this problem, outperforming the current best algorithm of competitive ratio 1/8.06 (Kesselheim et al. in SIAM J Comput 47(5):1939‚Äì1964, 2018). Our algorithm is based on two new insights: We introduce a novel algorithmic approach that employs two given algorithms, optimized for restricted item classes, sequentially on the input sequence. In addition, we study and exploit the relationship of the knapsack problem to the 2-secretary problem. The generalized assignment problem (GAP) includes, besides the knapsack problem, several important problems related to scheduling and matching. We show that in the same online setting, applying the proposed sequential approach yields a (1/6.99)-competitive randomized algorithm for GAP. Again, our proposed algorithm outperforms the current best result of competitive ratio 1/8.06 (Kesselheim et al. in SIAM J Comput 47(5):1939‚Äì1964, 2018).},
  archive      = {J_Alg},
  author       = {Albers, Susanne and Khan, Arindam and Ladewig, Leon},
  doi          = {10.1007/s00453-021-00801-2},
  journal      = {Algorithmica},
  number       = {6},
  pages        = {1750-1785},
  shortjournal = {Algorithmica},
  title        = {Improved online algorithms for knapsack and GAP in the random order model},
  volume       = {83},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Dispersing obnoxious facilities on a graph. <em>Alg</em>,
<em>83</em>(6), 1734‚Äì1749. (<a
href="https://doi.org/10.1007/s00453-021-00800-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study a continuous facility location problem on a graph where all edges have unit length and where the facilities may also be positioned in the interior of the edges. The goal is to position as many facilities as possible subject to the condition that any two facilities have at least distance $$\delta$$ from each other. We investigate the complexity of this problem in terms of the rational parameter $$\delta$$ . The problem is polynomially solvable, if the numerator of $$\delta$$ is 1 or 2, while all other cases turn out to be NP-hard.},
  archive      = {J_Alg},
  author       = {Grigoriev, Alexander and Hartmann, Tim A. and Lendl, Stefan and Woeginger, Gerhard J.},
  doi          = {10.1007/s00453-021-00800-3},
  journal      = {Algorithmica},
  number       = {6},
  pages        = {1734-1749},
  shortjournal = {Algorithmica},
  title        = {Dispersing obnoxious facilities on a graph},
  volume       = {83},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Range majorities and minorities in arrays. <em>Alg</em>,
<em>83</em>(6), 1707‚Äì1733. (<a
href="https://doi.org/10.1007/s00453-021-00799-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The problem of parameterized range majority asks us to preprocess a string of length n such that, given the endpoints of a range, one can quickly find all the distinct elements whose relative frequencies in that range are more than a threshold $$\tau$$ . This is a more tractable version of the classical problem of finding the range mode, which is unlikely to be solvable in polylogarithmic time and linear space. In this paper we give the first linear-space solution with optimal $$\mathcal {O}\!\left( {1 / \tau } \right)$$ query time, even when $$\tau$$ can be specified with the query. We then consider data structures whose space is bounded by the entropy of the distribution of the symbols in the sequence. For the case when the alphabet size $$\sigma$$ is polynomial on the computer word size, we retain the optimal time within optimally compressed space (i.e., with sublinear redundancy). Otherwise, either the compressed space is increased by an arbitrarily small constant factor or the time rises to any function in $$(1/\tau )\cdot \omega (1)$$ . We obtain the same results on the complementary problem of parameterized range minority.},
  archive      = {J_Alg},
  author       = {Belazzougui, Djamal and Gagie, Travis and Munro, J. Ian and Navarro, Gonzalo and Nekrich, Yakov},
  doi          = {10.1007/s00453-021-00799-7},
  journal      = {Algorithmica},
  number       = {6},
  pages        = {1707-1733},
  shortjournal = {Algorithmica},
  title        = {Range majorities and minorities in arrays},
  volume       = {83},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Finding cuts of bounded degree: Complexity, FPT and exact
algorithms, and kernelization. <em>Alg</em>, <em>83</em>(6), 1677‚Äì1706.
(<a href="https://doi.org/10.1007/s00453-021-00798-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A matching cut is a partition of the vertex set of a graph into two sets A and B such that each vertex has at most one neighbor in the other side of the cut. The Matching Cut problem asks whether a graph has a matching cut, and has been intensively studied in the literature. Motivated by a question posed by Komusiewicz et al.¬†[Discrete Applied Mathematics, 2020], we introduce a natural generalization of this problem, which we call d -Cut: for a positive integer d, a d-cut is a bipartition of the vertex set of a graph into two sets A and B such that each vertex has at most d neighbors across the cut. We generalize (and in some cases, improve) a number of results for the Matching Cut problem. Namely, we begin with an NP-hardness reduction for d -Cut on $$(2d+2)$$ -regular graphs and a polynomial algorithm for graphs of maximum degree at most $$d+2$$ . The degree bound in the hardness result is unlikely to be improved, as it would disprove a long-standing conjecture in the context of internal partitions. We then give FPT algorithms for several parameters: the maximum number of edges crossing the cut, treewidth, distance to cluster, and distance to co-cluster. In particular, the treewidth algorithm improves upon the running time of the best known algorithm for Matching Cut. Our main technical contribution, building on the techniques of Komusiewicz et al.¬†[DAM, 2020], is a polynomial kernel for d -Cut for every positive integer d, parameterized by the vertex deletion distance of the input graph to a cluster graph. We also rule out the existence of polynomial kernels when parameterizing simultaneously by the number of edges crossing the cut, the treewidth, and the maximum degree. Finally, we provide an exact exponential algorithm slightly faster than the naive brute force approach running in time $$\mathcal {O}^*\!\left( 2^n\right)$$ .},
  archive      = {J_Alg},
  author       = {Gomes, Guilherme C. M. and Sau, Ignasi},
  doi          = {10.1007/s00453-021-00798-8},
  journal      = {Algorithmica},
  number       = {6},
  pages        = {1677-1706},
  shortjournal = {Algorithmica},
  title        = {Finding cuts of bounded degree: Complexity, FPT and exact algorithms, and kernelization},
  volume       = {83},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Optimal matroid partitioning problems. <em>Alg</em>,
<em>83</em>(6), 1653‚Äì1676. (<a
href="https://doi.org/10.1007/s00453-021-00797-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies optimal matroid partitioning problems for various objective functions. In the problem, we are given k weighted-matroids on the same ground set. Our goal is to find a feasible partition that minimizes (maximizes) the value of an objective function. A typical objective is the maximum over all subsets of the total weights of the elements in a subset, which is extensively studied in the scheduling literature. Likewise, as an objective function, we handle the maximum/minimum/sum over all subsets of the maximum/minimum/total weight(s) of the elements in a subset. In this paper, we determine the computational complexity of the optimal partitioning problem with the above-described objective functions. Namely, for each objective function, we either provide a polynomial time algorithm or prove NP-hardness. We also discuss the approximability for the NP-hard cases.},
  archive      = {J_Alg},
  author       = {Kawase, Yasushi and Kimura, Kei and Makino, Kazuhisa and Sumita, Hanna},
  doi          = {10.1007/s00453-021-00797-9},
  journal      = {Algorithmica},
  number       = {6},
  pages        = {1653-1676},
  shortjournal = {Algorithmica},
  title        = {Optimal matroid partitioning problems},
  volume       = {83},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Average-case approximation ratio of scheduling without
payments. <em>Alg</em>, <em>83</em>(6), 1638‚Äì1652. (<a
href="https://doi.org/10.1007/s00453-020-00796-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Apart from the principles and methodologies inherited from Economics and Game Theory, the studies in Algorithmic Mechanism Design typically employ the worst-case analysis and design of approximation schemes of Theoretical Computer Science. For instance, the approximation ratio, which is the canonical measure of evaluating how well an incentive-compatible mechanism approximately optimizes the objective, is defined in the worst-case sense. It compares the performance of the optimal mechanism against the performance of a truthful mechanism, for all possible inputs. In this paper, we take the average-case analysis approach, and tackle one of the primary motivating problems in Algorithmic Mechanism Design‚Äîthe scheduling problem¬†(Nisan and Ronen, in: Proceedings of the 31st annual ACM symposium on theory of computing (STOC), 1999). One version of this problem, which includes a verification component, is studied by Koutsoupias (Theory Comput Syst 54(3):375‚Äì387, 2014). It was shown that the problem has a tight approximation ratio bound of $$(n+1)/2$$ for the single-task setting, where n is the number of machines. We show, however, when the costs of the machines to executing the task follow any independent and identical distribution, the average-case approximation ratio of the mechanism given by Koutsoupias (Theory Comput Syst 54(3):375‚Äì387, 2014) is upper bounded by a constant. This positive result asymptotically separates the average-case ratio from the worst-case ratio. It indicates that the optimal mechanism devised for a worst-case guarantee works well on average.},
  archive      = {J_Alg},
  author       = {Zhang, Jie},
  doi          = {10.1007/s00453-020-00796-2},
  journal      = {Algorithmica},
  number       = {6},
  pages        = {1638-1652},
  shortjournal = {Algorithmica},
  title        = {Average-case approximation ratio of scheduling without payments},
  volume       = {83},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). On structural parameterizations of the edge disjoint paths
problem. <em>Alg</em>, <em>83</em>(6), 1605‚Äì1637. (<a
href="https://doi.org/10.1007/s00453-020-00795-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we revisit the classical edge disjoint paths (EDP) problem, where one is given an undirected graph G and a set of terminal pairs P and asks whether G contains a set of pairwise edge-disjoint paths connecting every terminal pair in P. Our focus lies on structural parameterizations for the problem that allow for efficient (polynomial-time or FPT) algorithms. As our first result, we answer an open question stated in Fleszar et al. (Proceedings of the ESA, 2016), by showing that the problem can be solved in polynomial time if the input graph has a feedback vertex set of size one. We also show that EDP parameterized by the treewidth and the maximum degree of the input graph is fixed-parameter tractable. Having developed two novel algorithms for EDP using structural restrictions on the input graph, we then turn our attention towards the augmented graph, i.e., the graph obtained from the input graph after adding one edge between every terminal pair. In constrast to the input graph, where EDP is known to remain NP-hard even for treewidth two, a result by Zhou et al. (Algorithmica 26(1):3--30, 2000) shows that EDP can be solved in non-uniform polynomial time if the augmented graph has constant treewidth; we note that the possible improvement of this result to an FPT-algorithm has remained open since then. We show that this is highly unlikely by establishing the W[1]-hardness of the problem parameterized by the treewidth (and even feedback vertex set) of the augmented graph. Finally, we develop an FPT-algorithm for EDP by exploiting a novel structural parameter of the augmented graph.},
  archive      = {J_Alg},
  author       = {Ganian, Robert and Ordyniak, Sebastian and Ramanujan, M. S.},
  doi          = {10.1007/s00453-020-00795-3},
  journal      = {Algorithmica},
  number       = {6},
  pages        = {1605-1637},
  shortjournal = {Algorithmica},
  title        = {On structural parameterizations of the edge disjoint paths problem},
  volume       = {83},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Obtaining a proportional allocation by deleting items.
<em>Alg</em>, <em>83</em>(5), 1559‚Äì1603. (<a
href="https://doi.org/10.1007/s00453-020-00794-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the following control problem on fair allocation of indivisible goods. Given a set I of items and a set of agents, each having strict linear preferences over the items, we ask for a minimum subset of the items whose deletion guarantees the existence of a proportional allocation in the remaining instance; we call this problem Proportionality by Item Deletion (PID). Our main result is a polynomial-time algorithm that solves PID for three agents. By contrast, we prove that PID is computationally intractable when the number of agents is unbounded, even if the number k of item deletions allowed is small‚Äîwe show that the problem is $${\mathsf {W}}[3]$$ -hard with respect to the parameter k. Additionally, we provide some tight lower and upper bounds on the complexity of PID when regarded as a function of |I| and k. Considering the possibilities for approximation, we prove a strong inapproximability result for PID. Finally, we also study a variant of the problem where we are given an allocation $$\pi $$ in advance as part of the input, and our aim is to delete a minimum number of items such that $$\pi $$ is proportional in the remainder; this variant turns out to be $${{\mathsf {N}}}{{\mathsf {P}}}$$ -hard for six agents, but polynomial-time solvable for two agents, and we show that it is $$\mathsf {W[2]}$$ -hard when parameterized by the number k of},
  archive      = {J_Alg},
  author       = {Dorn, Britta and de Haan, Ronald and Schlotter, Ildik√≥},
  doi          = {10.1007/s00453-020-00794-4},
  journal      = {Algorithmica},
  number       = {5},
  pages        = {1559-1603},
  shortjournal = {Algorithmica},
  title        = {Obtaining a proportional allocation by deleting items},
  volume       = {83},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A fast algorithm for the product structure of planar graphs.
<em>Alg</em>, <em>83</em>(5), 1544‚Äì1558. (<a
href="https://doi.org/10.1007/s00453-020-00793-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dujmoviƒá et al. (FOCS2019) recently proved that every planar graph G is a subgraph of $$H\boxtimes P$$ , where $$\boxtimes$$ denotes the strong graph product, H is a graph of treewidth 8 and P is a path. This result has found numerous applications to linear graph layouts, graph colouring, and graph labelling. The proof given by Dujmoviƒá et al. is based on a similar decomposition of Pilipczuk and Siebertz (SODA2019) which is constructive and leads to an $$O(n^2)$$ time algorithm for finding H and the mapping from V(G) onto $$V(H\boxtimes P)$$ . In this note, we show that this algorithm can be made to run in $$O(n\log n)$$ time.},
  archive      = {J_Alg},
  author       = {Morin, Pat},
  doi          = {10.1007/s00453-020-00793-5},
  journal      = {Algorithmica},
  number       = {5},
  pages        = {1544-1558},
  shortjournal = {Algorithmica},
  title        = {A fast algorithm for the product structure of planar graphs},
  volume       = {83},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Approximating the canadian traveller problem with online
randomization. <em>Alg</em>, <em>83</em>(5), 1524‚Äì1543. (<a
href="https://doi.org/10.1007/s00453-020-00792-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study online algorithms for the Canadian Traveller Problem defined by Papadimitriou and Yannakakis in 1991. This problem involves a traveller who knows the entire road network in advance, and wishes to travel as quickly as possible from a source vertex s to a destination vertex t, but discovers online that some roads are blocked (e.g., by snow) once reaching them. Achieving a bounded competitive ratio for the problem is PSPACE-complete. Furthermore, if at most k roads can be blocked, the optimal competitive ratio for a deterministic online algorithm is $$2k+1$$ , while the only randomized result known so far is a lower bound of $$k+1$$ . We show, for the first time, that a polynomial time randomized algorithm can outperform the best deterministic algorithms when there are at least two blockages, and surpass the lower bound of $$2k+1$$ by an o(1) factor. Moreover, we prove that the randomized algorithm can achieve a competitive ratio of $$\big (1+ \frac{\sqrt{2}}{2} \big )k + \sqrt{2}$$ in pseudo-polynomial time. The proposed techniques can also be exploited to implicitly represent multiple near-shortest s-t paths.},
  archive      = {J_Alg},
  author       = {Demaine, Erik D. and Huang, Yamming and Liao, Chung-Shou and Sadakane, Kunihiko},
  doi          = {10.1007/s00453-020-00792-6},
  journal      = {Algorithmica},
  number       = {5},
  pages        = {1524-1543},
  shortjournal = {Algorithmica},
  title        = {Approximating the canadian traveller problem with online randomization},
  volume       = {83},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Popular matchings in complete graphs. <em>Alg</em>,
<em>83</em>(5), 1493‚Äì1523. (<a
href="https://doi.org/10.1007/s00453-020-00791-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Our input is a complete graph G on n vertices where each vertex has a strict ranking of all other vertices in G. The goal is to construct a matching in G that is popular. A matching M is popular if M does not lose a head-to-head election against any matching $$M&#39;$$ : here each vertex casts a vote for the matching in $${M,M&#39;}$$ in which it gets a better assignment. Popular matchings need not exist in the given instance G and the popular matching problem is to decide whether one exists or not. The popular matching problem in G is easy to solve for odd¬†n. Surprisingly, the problem becomes $$\texttt {NP}$$ -complete for even n, as we show here. This is one of the few graph theoretic problems efficiently solvable when n has one parity and $$\texttt {NP}$$ -complete when n has the other parity.},
  archive      = {J_Alg},
  author       = {Cseh, √Ågnes and Kavitha, Telikepalli},
  doi          = {10.1007/s00453-020-00791-7},
  journal      = {Algorithmica},
  number       = {5},
  pages        = {1493-1523},
  shortjournal = {Algorithmica},
  title        = {Popular matchings in complete graphs},
  volume       = {83},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Eternal domination: D-dimensional cartesian and strong grids
and everything in between. <em>Alg</em>, <em>83</em>(5), 1459‚Äì1492. (<a
href="https://doi.org/10.1007/s00453-020-00790-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the eternal domination game played on graphs, an attacker attacks a vertex at each turn and a team of guards must move a guard to the attacked vertex to defend it. The guards may only move to adjacent vertices on their turn. The goal is to determine the eternal domination number $$\gamma ^{\infty }_{all}$$ of a graph, which is the minimum number of guards required to defend against an infinite sequence of attacks. This paper first continues the study of the eternal domination game on strong grids $$P_n\boxtimes P_m$$ . Cartesian grids $$P_n \square P_m$$ have been vastly studied with tight bounds existing for small grids such as $$k\times n$$ grids for $$k\in {2,3,4,5}$$ . It was recently proven that $$\gamma ^{\infty }_{all}(P_n \square P_m)=\gamma (P_n \square P_m)+O(n+m)$$ where $$\gamma (P_n \square P_m)$$ is the domination number of $$P_n \square P_m$$ which lower bounds the eternal domination number [Lamprou et al. Eternally dominating large grids. Theoretical Computer Science, 794:27‚Äì46, 2019]. We prove that, for all $$n,m\in \mathbb {N^*}$$ such that $$m\ge n$$ , $$\lfloor \frac{n}{3} \rfloor \lfloor \frac{m}{3} \rfloor +\Omega (n+m)=\gamma _{all}^{\infty } (P_{n}\boxtimes P_{m})=\lceil \frac{n}{3} \rceil \lceil \frac{m}{3} \rceil + O(m\sqrt{n})$$ (note that $$\lceil \frac{n}{3} \rceil \lceil \frac{m}{3} \rceil$$ is the domination number of $$P_n\boxtimes P_m$$ ). We then generalise our technique to prove that $$\gamma _{all}^{\infty }(G)=\gamma (G)+o(\gamma (G))$$ for all graphs $$G\in {\mathcal {F}}$$ , where $${\mathcal {F}}$$ is a large family of D-dimensional grids which are supergraphs of the D-dimensional Cartesian grid and subgraphs of the D-dimensional strong grid. In particular, $${\mathcal {F}}$$ includes both the D-dimensional Cartesian grid and the D-dimensional strong grid.},
  archive      = {J_Alg},
  author       = {Mc Inerney, Fionn and Nisse, Nicolas and P√©rennes, St√©phane},
  doi          = {10.1007/s00453-020-00790-8},
  journal      = {Algorithmica},
  number       = {5},
  pages        = {1459-1492},
  shortjournal = {Algorithmica},
  title        = {Eternal domination: D-dimensional cartesian and strong grids and everything in between},
  volume       = {83},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Computing the largest bond and the maximum connected cut of
a graph. <em>Alg</em>, <em>83</em>(5), 1421‚Äì1458. (<a
href="https://doi.org/10.1007/s00453-020-00789-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The cut-set $$\partial (S)$$ of a graph $$G=(V,E)$$ is the set of edges that have one endpoint in $$S\subset V$$ and the other endpoint in $$V\setminus S$$ , and whenever G[S] is connected, the cut $$[S,V\setminus S]$$ of G is called a connected cut. A bond of a graph G is an inclusion-wise minimal disconnecting set of G, i.e., bonds are cut-sets that determine cuts $$[S,V\setminus S]$$ of G such that G[S] and $$G[V\setminus S]$$ are both connected. Contrasting with a large number of studies related to maximum cuts, there exist very few results regarding the largest bond of general graphs. In this paper, we aim to reduce this gap on the complexity of computing the largest bond, and the maximum connected cut of a graph. Although cuts and bonds are similar, we remark that computing the largest bond and the maximum connected cut of a graph tends to be harder than computing its maximum cut. We show that it does not exist a constant-factor approximation algorithm to compute the largest bond, unless $$\text{ P }= \text{ NP }$$ . Also, we show that Largest Bond and Maximum Connected Cut are NP-hard even for planar bipartite graphs, whereas Maximum Cut is trivial on bipartite graphs and polynomial-time solvable on planar graphs. In addition, we show that Largest Bond and Maximum Connected Cut are NP-hard on split graphs, and restricted to graphs of clique-width w they can not be solved in time $$f(w) n^{{o}(w)}$$ unless the Exponential Time Hypothesis fails, but they can be solved in time $$f(w) n^{{O}(w)}$$ . Finally, we show that both problems are fixed-parameter tractable when parameterized by the size of the solution, the treewidth, and the twin-cover number.},
  archive      = {J_Alg},
  author       = {Duarte, Gabriel L. and Eto, Hiroshi and Hanaka, Tesshu and Kobayashi, Yasuaki and Kobayashi, Yusuke and Lokshtanov, Daniel and Pedrosa, Lehilton L. C. and Schouery, Rafael C. S. and Souza, U√©verton S.},
  doi          = {10.1007/s00453-020-00789-1},
  journal      = {Algorithmica},
  number       = {5},
  pages        = {1421-1458},
  shortjournal = {Algorithmica},
  title        = {Computing the largest bond and the maximum connected cut of a graph},
  volume       = {83},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Packing arc-disjoint cycles in tournaments. <em>Alg</em>,
<em>83</em>(5), 1393‚Äì1420. (<a
href="https://doi.org/10.1007/s00453-020-00788-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A tournament is a directed graph in which there is a single arc between every pair of distinct vertices. Given a tournament T on n vertices, we explore the classical and parameterized complexity of the problems of determining if T has a cycle packing (a set of pairwise arc-disjoint cycles) of size k and a triangle packing (a set of pairwise arc-disjoint triangles) of size k. We refer to these problems as Arc-disjoint Cycles in Tournaments (ACT) and Arc-disjoint Triangles in Tournaments (ATT), respectively. Although the maximization version of ACT can be seen as the dual of the well-studied problem of finding a minimum feedback arc set (a set of arcs whose deletion results in an acyclic graph) in tournaments, surprisingly no algorithmic results seem to exist for ACT. We first show that ACT and ATT are both NP-complete. Then, we show that the problem of determining if a tournament has a cycle packing and a feedback arc set of the same size is NP-complete. Next, we prove that ACT is fixed-parameter tractable via a $$2^{\mathcal {O}(k \log k)} n^{\mathcal {O}(1)}$$ -time algorithm and admits a kernel with $$\mathcal {O}(k)$$ vertices. Then, we show that ATT too has a kernel with $$\mathcal {O}(k)$$ vertices and can be solved in $$2^{\mathcal {O}(k)} n^{\mathcal {O}(1)}$$ time. Afterwards, we describe polynomial-time algorithms for ACT and ATT when the input tournament has a feedback arc set that is a matching. We also prove that ACT and ATT cannot be solved in $$2^{o(\sqrt{n})} n^{\mathcal {O}(1)}$$ time under the exponential-time hypothesis.},
  archive      = {J_Alg},
  author       = {Bessy, St√©phane and Bougeret, Marin and Krithika, R. and Sahu, Abhishek and Saurabh, Saket and Thiebaut, Jocelyn and Zehavi, Meirav},
  doi          = {10.1007/s00453-020-00788-2},
  journal      = {Algorithmica},
  number       = {5},
  pages        = {1393-1420},
  shortjournal = {Algorithmica},
  title        = {Packing arc-disjoint cycles in tournaments},
  volume       = {83},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Polynomial time approximation schemes for all 1-center
problems on metric rational set similarities. <em>Alg</em>,
<em>83</em>(5), 1371‚Äì1392. (<a
href="https://doi.org/10.1007/s00453-020-00787-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we investigate algorithms for finding centers of a given collection $$\mathcal N$$ of sets. In particular, we focus on metric rational set similarities, a broad class of similarity measures including Jaccard and Hamming. A rational set similarity S is called metric if $$D=1-S$$ is a distance function. We study the 1-center problem on these metric spaces. The problem consists of finding a set C that minimizes the maximum distance of C to any set of $$\mathcal N$$ . We present a general framework that computes a $$(1+\varepsilon )$$ approximation for any metric rational set similarity.},
  archive      = {J_Alg},
  author       = {Bury, Marc and Gentili, Michele and Schwiegelshohn, Chris and Sorella, Mara},
  doi          = {10.1007/s00453-020-00787-3},
  journal      = {Algorithmica},
  number       = {5},
  pages        = {1371-1392},
  shortjournal = {Algorithmica},
  title        = {Polynomial time approximation schemes for all 1-center problems on metric rational set similarities},
  volume       = {83},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Travelling on graphs with small highway dimension.
<em>Alg</em>, <em>83</em>(5), 1352‚Äì1370. (<a
href="https://doi.org/10.1007/s00453-020-00785-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the Travelling Salesperson (TSP) and the Steiner Tree problem (STP) in graphs of low highway dimension. This graph parameter roughly measures how many central nodes are visited by all shortest paths of a certain length. It has been shown that transportation networks, on which TSP and STP naturally occur for various applications in logistics, typically have a small highway dimension. While it was previously shown that these problems admit a quasi-polynomial time approximation scheme on graphs of constant highway dimension, we demonstrate that a significant improvement is possible in the special case when the highway dimension is¬†1. Specifically, we present a fully-polynomial time approximation scheme (FPTAS). We also prove that both TSP and STP are weakly $${\mathsf {NP}}$$ -hard for these restricted graphs.},
  archive      = {J_Alg},
  author       = {Disser, Yann and Feldmann, Andreas Emil and Klimm, Max and K√∂nemann, Jochen},
  doi          = {10.1007/s00453-020-00785-5},
  journal      = {Algorithmica},
  number       = {5},
  pages        = {1352-1370},
  shortjournal = {Algorithmica},
  title        = {Travelling on graphs with small highway dimension},
  volume       = {83},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Universal reconfiguration of facet-connected modular robots
by pivots: The o(1) musketeers. <em>Alg</em>, <em>83</em>(5), 1316‚Äì1351.
(<a href="https://doi.org/10.1007/s00453-020-00784-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present the first universal reconfiguration algorithm for transforming a modular robot between any two facet-connected square-grid configurations using pivot moves. More precisely, we show that five extra ‚Äúhelper‚Äù modules (‚Äúmusketeers‚Äù) suffice to reconfigure the remaining n modules between any two given configurations. Our algorithm uses $$O(n^2)$$ pivot moves, which is worst-case optimal. Previous reconfiguration algorithms either require less restrictive ‚Äúsliding‚Äù moves, do not preserve facet-connectivity, or for the setting we consider, could only handle a small subset of configurations defined by a local forbidden pattern. Configurations with the forbidden pattern do have disconnected reconfiguration graphs (discrete configuration spaces), and indeed we show that they can have an exponential number of connected components. But forbidding the local pattern throughout the configuration is far from necessary, as we show that just a constant number of added modules (placed to be freely reconfigurable) suffice for universal reconfigurability. We also classify three different models of natural pivot moves that preserve facet-connectivity, and show separations between these models.},
  archive      = {J_Alg},
  author       = {Akitaya, Hugo A. and Arkin, Esther M. and Damian, Mirela and Demaine, Erik D. and Dujmoviƒá, Vida and Flatland, Robin and Korman, Matias and Palop, Belen and Parada, Irene and Renssen, Andr√© van and Sacrist√°n, Vera},
  doi          = {10.1007/s00453-020-00784-6},
  journal      = {Algorithmica},
  number       = {5},
  pages        = {1316-1351},
  shortjournal = {Algorithmica},
  title        = {Universal reconfiguration of facet-connected modular robots by pivots: The o(1) musketeers},
  volume       = {83},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The price of defense. <em>Alg</em>, <em>83</em>(5),
1256‚Äì1315. (<a
href="https://doi.org/10.1007/s00453-020-00783-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a game on a graph $$G=\langle V, E\rangle $$ with two confronting classes of randomized players: $$\nu $$ attackers, who choose vertices and seek to minimize the probability of getting caught, and a single defender, who chooses edges and seeks to maximize the expected number of attackers it catches. In a Nash equilibrium, no player has an incentive to unilaterally deviate from her randomized strategy. The Price of Defense is the worst-case ratio, over all Nash equilibria, of $$\nu $$ over the expected utility of the defender at a Nash equilibrium. We orchestrate a strong interplay of arguments from Game Theory and Graph Theory to obtain both general and specific results in the considered setting: (1) Via a reduction to a Two-Players, Constant-Sum game, we observe that an arbitrary Nash equilibrium is computable in polynomial time. Further, we prove a general lower bound of $$\frac{\textstyle |V|}{\textstyle 2}$$ on the Price of Defense. We derive a characterization of graphs with a Nash equilibrium attaining this lower bound, which reveals a promising connection to Fractional Graph Theory; thereby, it implies an efficient recognition algorithm for such Defense-Optimal graphs. (2) We study some specific classes of Nash equilibria, both for their computational complexity and for their incurred Price of Defense. The classes are defined by imposing structure on the players‚Äô randomized strategies: either graph-theoretic structure on the supports, or symmetry and uniformity structure on the probabilities. We develop novel graph-theoretic techniques to derive trade-offs between computational complexity and the Price of Defense for these classes. Some of the techniques touch upon classical milestones of Graph Theory; for example, we derive the first game-theoretic characterization of K√∂nig-Egerv√°ry graphs as graphs admitting a Matching Nash equilibrium.},
  archive      = {J_Alg},
  author       = {Mavronicolas, Marios and Michael, Loizos and Papadopoulou Lesta, Vicky and Persiano, Giuseppe and Philippou, Anna and Spirakis, Paul G.},
  doi          = {10.1007/s00453-020-00783-7},
  journal      = {Algorithmica},
  number       = {5},
  pages        = {1256-1315},
  shortjournal = {Algorithmica},
  title        = {The price of defense},
  volume       = {83},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Matching cut in graphs with large minimum degree.
<em>Alg</em>, <em>83</em>(5), 1238‚Äì1255. (<a
href="https://doi.org/10.1007/s00453-020-00782-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In a graph, a matching cut is an edge cut that is a matching. Matching Cut is the problem of deciding whether or not a given graph has a matching cut, which is known to be $${\mathsf {NP}}$$ -complete. While Matching Cut is trivial for graphs with minimum degree at most one, it is $${\mathsf {NP}}$$ -complete on graphs with minimum degree two. In this paper, we show that, for any given constant $$c&gt;1$$ , Matching Cut is $${\mathsf {NP}}$$ -complete in the class of graphs with minimum degree c and this restriction of Matching Cut has no subexponential-time algorithm in the number of vertices unless the Exponential-Time Hypothesis fails. We also show that, for any given constant $$\epsilon &gt;0$$ , Matching Cut remains $${\mathsf {NP}}$$ -complete in the class of n-vertex (bipartite) graphs with unbounded minimum degree $$\delta &gt;n^{1-\epsilon }$$ . We give an exact branching algorithm to solve Matching Cut for graphs with minimum degree $$\delta \ge 3$$ in $$O^*(\lambda ^n)$$ time, where $$\lambda$$ is the positive root of the polynomial $$x^{\delta +1}-x^{\delta }-1$$ . Despite the hardness results, this is a very fast exact exponential-time algorithm for Matching Cut on graphs with large minimum degree; for instance, the running time is $$O^*(1.0099^n)$$ on graphs with minimum degree $$\delta \ge 469$$ . Complementing our hardness results, we show that, for any two fixed constants $$1&lt; c &lt;4$$ and $$c^{\prime }\ge 0$$ , Matching Cut is solvable in polynomial time for graphs with large minimum degree $$\delta \ge \frac{1}{c}n-c^{\prime }$$ .},
  archive      = {J_Alg},
  author       = {Chen, Chi-Yeh and Hsieh, Sun-Yuan and Le, Hoang-Oanh and Le, Van Bang and Peng, Sheng-Lung},
  doi          = {10.1007/s00453-020-00782-8},
  journal      = {Algorithmica},
  number       = {5},
  pages        = {1238-1255},
  shortjournal = {Algorithmica},
  title        = {Matching cut in graphs with large minimum degree},
  volume       = {83},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Budget feasible mechanisms on matroids. <em>Alg</em>,
<em>83</em>(5), 1222‚Äì1237. (<a
href="https://doi.org/10.1007/s00453-020-00781-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Motivated by many practical applications, in this paper we study budget feasible mechanisms with the goal of procuring an independent set of a matroid. More specifically, we are given a matroid $${\mathcal {M}}=(E,{\mathcal {I}})$$ . Each element of the ground set E is controlled by a selfish agent and the cost of the element is private information of the agent itself. A budget limited buyer has additive valuations over the elements of E. The goal is to design an incentive compatible budget feasible mechanism which procures an independent set of the matroid of largest possible value. We also consider the more general case of the pair $${\mathcal {M}}=(E,{\mathcal {I}})$$ satisfying only the hereditary property. This includes matroids as well as matroid intersection. We show that, given a polynomial time deterministic algorithm that returns an $$\alpha $$ -approximation to the problem of finding a maximum-value independent set in $${\mathcal {M}}$$ , there exists an individually rational, truthful and budget feasible mechanism which is $$(3\alpha +1)$$ -approximated and runs in polynomial time, thus yielding also a 4-approximation for the special case of matroids.},
  archive      = {J_Alg},
  author       = {Leonardi, Stefano and Monaco, Gianpiero and Sankowski, Piotr and Zhang, Qiang},
  doi          = {10.1007/s00453-020-00781-9},
  journal      = {Algorithmica},
  number       = {5},
  pages        = {1222-1237},
  shortjournal = {Algorithmica},
  title        = {Budget feasible mechanisms on matroids},
  volume       = {83},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Towards a polynomial kernel for directed feedback vertex
set. <em>Alg</em>, <em>83</em>(5), 1201‚Äì1221. (<a
href="https://doi.org/10.1007/s00453-020-00777-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the Directed Feedback Vertex Set (DFVS) problem, the input is a directed graph D and an integer k. The objective is to determine whether there exists a set of at most k vertices intersecting every directed cycle of D. DFVS was shown to be fixed-parameter tractable when parameterized by solution size by Chen et al. (J ACM 55(5):177‚Äì186, 2008); since then, the existence of a polynomial kernel for this problem has become one of the largest open problems in the area of parameterized algorithmics. Since this problem has remained open in spite of the best efforts of a number of prominent researchers and pioneers in the field, a natural step forward is to study the kernelization complexity of DFVS parameterized by a natural larger parameter. In this paper, we study DFVS parameterized by the feedback vertex set number of the underlying undirected graph. We provide two main contributions: a polynomial kernel for this problem on general instances, and a linear kernel for the case where the input digraph is embeddable on a surface of bounded genus.},
  archive      = {J_Alg},
  author       = {Bergougnoux, Benjamin and Eiben, Eduard and Ganian, Robert and Ordyniak, Sebastian and Ramanujan, M. S.},
  doi          = {10.1007/s00453-020-00777-5},
  journal      = {Algorithmica},
  number       = {5},
  pages        = {1201-1221},
  shortjournal = {Algorithmica},
  title        = {Towards a polynomial kernel for directed feedback vertex set},
  volume       = {83},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The inverse voronoi problem in graphs II: trees.
<em>Alg</em>, <em>83</em>(5), 1165‚Äì1200. (<a
href="https://doi.org/10.1007/s00453-020-00774-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the inverse Voronoi diagram problem in trees: given a tree T with positive edge-lengths and a collection $$\mathbb {U}$$ of subsets of vertices of V(T), decide whether $${\mathbb {U}}$$ is a Voronoi diagram in T with respect to the shortest-path metric. We show that the problem can be solved in $$O(N+n \log ^2 n)$$ time, where n is the number of vertices in T and $$N=n+\sum _{U\in {\mathbb {U}}}|U|$$ is the size of the description of the input. We also provide a lower bound of $$\Omega (n \log n)$$ time for trees with n vertices.},
  archive      = {J_Alg},
  author       = {Bonnet, √âdouard and Cabello, Sergio and Mohar, Bojan and P√©rez-Ros√©s, Hebert},
  doi          = {10.1007/s00453-020-00774-8},
  journal      = {Algorithmica},
  number       = {5},
  pages        = {1165-1200},
  shortjournal = {Algorithmica},
  title        = {The inverse voronoi problem in graphs II: Trees},
  volume       = {83},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Fixed-parameter tractability of crossover: Steady-state GAs
on the closest string problem. <em>Alg</em>, <em>83</em>(4), 1138‚Äì1163.
(<a href="https://doi.org/10.1007/s00453-021-00809-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We investigate the effect of crossover in the context of parameterized complexity on a well-known fixed-parameter tractable combinatorial optimization problem known as the closest string problem. We prove that a multi-start ( $$\mu$$ +1)¬†GA solves arbitrary length-n instances of closest string in $$2^{O(d^2 + d \log k)} \cdot t(n)$$ steps in expectation. Here, k is the number of strings in the input set, d is the value of the optimal solution, and $$n \le t(n) \le {\text {poly}}(n)$$ is the number of iterations allocated to the ( $$\mu$$ +1)¬†GA before a restart, which can be an arbitrary polynomial in n. This confirms that the multi-start ( $$\mu$$ +1)¬†GA runs in randomized fixed-parameter tractable (FPT) time with respect to the above parameterization. On the other hand, if the crossover operation is disabled, we show there exist instances that require $$n^{\varOmega (\log (d+k))}$$ steps in expectation. The lower bound asserts that crossover is a necessary component in the FPT running time.},
  archive      = {J_Alg},
  author       = {Sutton, Andrew M.},
  doi          = {10.1007/s00453-021-00809-8},
  journal      = {Algorithmica},
  number       = {4},
  pages        = {1138-1163},
  shortjournal = {Algorithmica},
  title        = {Fixed-parameter tractability of crossover: Steady-state GAs on the closest string problem},
  volume       = {83},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The complex parameter landscape of the compact genetic
algorithm. <em>Alg</em>, <em>83</em>(4), 1096‚Äì1137. (<a
href="https://doi.org/10.1007/s00453-020-00778-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The compact Genetic Algorithm (cGA) evolves a probability distribution favoring optimal solutions in the underlying search space by repeatedly sampling from the distribution and updating it according to promising samples. We study the intricate dynamics of the cGA on the test function OneMax, and how its performance depends on the hypothetical population size K, which determines how quickly decisions about promising bit values are fixated in the probabilistic model. It is known that the cGA and the Univariate Marginal Distribution Algorithm (UMDA), a related algorithm whose population size is called $$\lambda$$ , run in expected time $$O(n \log n)$$ when the population size is just large enough ( $$K = \varTheta (\sqrt{n}\log n)$$ and $$\lambda = \varTheta (\sqrt{n}\log n)$$ , respectively) to avoid wrong decisions being fixated. The UMDA also shows the same performance in a very different regime ( $$\lambda =\varTheta (\log n)$$ , equivalent to $$K = \varTheta (\log n)$$ in the cGA) with much smaller population size, but for very different reasons: many wrong decisions are fixated initially, but then reverted efficiently. If the population size is even smaller ( $$o(\log n)$$ ), the time is exponential. We show that population sizes in between the two optimal regimes are worse as they yield larger runtimes: we prove a lower bound of $$\varOmega (K^{1/3}n + n \log n)$$ for the cGA on OneMax for $$K = O(\sqrt{n}/\log ^2 n)$$ . For $$K = \varOmega (\log ^3 n)$$ the runtime increases with growing¬†K before dropping again to $$O(K\sqrt{n} + n \log n)$$ for $$K = \varOmega (\sqrt{n} \log n)$$ . This suggests that the expected runtime for the cGA is a bimodal function in¬†K with two very different optimal regions and worse performance in between.},
  archive      = {J_Alg},
  author       = {Lengler, Johannes and Sudholt, Dirk and Witt, Carsten},
  doi          = {10.1007/s00453-020-00778-4},
  journal      = {Algorithmica},
  number       = {4},
  pages        = {1096-1137},
  shortjournal = {Algorithmica},
  title        = {The complex parameter landscape of the compact genetic algorithm},
  volume       = {83},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A tight runtime analysis for the <span
class="math display">(<em>Œº</em>‚ÄÖ+‚ÄÖ<em>Œª</em>)</span> EA. <em>Alg</em>,
<em>83</em>(4), 1054‚Äì1095. (<a
href="https://doi.org/10.1007/s00453-020-00731-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite significant progress in the theory of evolutionary algorithms, the theoretical understanding of evolutionary algorithms which use non-trivial populations remains challenging and only few rigorous results exist. Already for the most basic problem, the determination of the asymptotic runtime of the $$(\mu +\lambda )$$ evolutionary algorithm on the simple OneMax benchmark function, only the special cases $$\mu =1$$ and $$\lambda =1$$ have been solved. In this work, we analyze this long-standing problem and show the asymptotically tight result that the runtime T, the number of iterations until the optimum is found, satisfies $$E[T] = \Theta \bigg (\frac{n\log n}{\lambda }+\frac{n}{\lambda / \mu } + \frac{n\log ^+\log ^+ (\lambda / \mu )}{\log ^+ (\lambda / \mu )}\bigg )$$ , where $$\log ^+ x := \max {1, \log x}$$ for all $$x &gt; 0$$ . The same methods allow to improve the previous-best $$O(\frac{n \log n}{\lambda } + n \log \lambda )$$ runtime guarantee for the $$(\lambda +\lambda )$$ EA with fair parent selection to a tight $$\Theta (\frac{n \log n}{\lambda } + n)$$ runtime result.},
  archive      = {J_Alg},
  author       = {Antipov, Denis and Doerr, Benjamin},
  doi          = {10.1007/s00453-020-00731-5},
  journal      = {Algorithmica},
  number       = {4},
  pages        = {1054-1095},
  shortjournal = {Algorithmica},
  title        = {A tight runtime analysis for the $${(\mu + \lambda )}$$ EA},
  volume       = {83},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Runtime analysis for self-adaptive mutation rates.
<em>Alg</em>, <em>83</em>(4), 1012‚Äì1053. (<a
href="https://doi.org/10.1007/s00453-020-00726-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose and analyze a self-adaptive version of the $$(1,\lambda )$$ evolutionary algorithm in which the current mutation rate is encoded within the individual and thus also subject to mutation. A rigorous runtime analysis on the OneMax benchmark function reveals that a simple local mutation scheme for the rate leads to an expected optimization time (number of fitness evaluations) of $$O(n\lambda /\log \lambda +n\log n)$$ when $$\lambda$$ is at least $$C \ln n$$ for some constant $$C &gt; 0$$ . For all values of $$\lambda \ge C \ln n$$ , this performance is asymptotically best possible among all $$\lambda$$ -parallel mutation-based unbiased black-box algorithms. Our result rigorously proves for the first time that self-adaptation in evolutionary computation can find complex optimal parameter settings on the fly. In particular, it gives asymptotically the same performance as the relatively complicated self-adjusting scheme for the mutation rate proposed by Doerr, Gie√üen, Witt, and Yang (Algorithmica¬†2019). On the technical side, the paper contributes new tools for the analysis of two-dimensional drift processes arising in the analysis of dynamic parameter choices in EAs, including bounds on occupation probabilities in processes with non-constant drift.},
  archive      = {J_Alg},
  author       = {Doerr, Benjamin and Witt, Carsten and Yang, Jing},
  doi          = {10.1007/s00453-020-00726-2},
  journal      = {Algorithmica},
  number       = {4},
  pages        = {1012-1053},
  shortjournal = {Algorithmica},
  title        = {Runtime analysis for self-adaptive mutation rates},
  volume       = {83},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Analysing the robustness of evolutionary algorithms to
noise: Refined runtime bounds and an example where noise is beneficial.
<em>Alg</em>, <em>83</em>(4), 976‚Äì1011. (<a
href="https://doi.org/10.1007/s00453-020-00671-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We analyse the performance of well-known evolutionary algorithms, the $$(1+1)$$ EA and the $$(1+\lambda )$$ EA, in the prior noise model, where in each fitness evaluation the search point is altered before the evaluation with probability¬†p. We present refined results for the expected optimisation time of these algorithms on the function Leading-Ones, where bits have to be optimised in sequence. Previous work showed that the $$(1+1)$$ EA on Leading-Ones runs in polynomial expected time if $$p = O((\log n)/n^2)$$ and needs superpolynomial expected time if $$p = \omega ((\log n)/n)$$ , leaving a huge gap for which no results were known. We close this gap by showing that the expected optimisation time is $$\varTheta (n^2) \cdot \exp (\varTheta (\min {pn^2, n}))$$ for all $$p \le 1/2$$ , allowing for the first time to locate the threshold between polynomial and superpolynomial expected times at $$p = \varTheta ((\log n)/n^2)$$ . Hence the $$(1+1)$$ EA on Leading-Ones is surprisingly sensitive to noise. We also show that offspring populations of size $$\lambda \ge 3.42\log n$$ can effectively deal with much higher noise than known before. Finally, we present an example of a rugged landscape where prior noise can help to escape from local optima by blurring the landscape and allowing a hill climber to see the underlying gradient. We prove that in this particular setting noise can have a highly beneficial effect on performance.},
  archive      = {J_Alg},
  author       = {Sudholt, Dirk},
  doi          = {10.1007/s00453-020-00671-0},
  journal      = {Algorithmica},
  number       = {4},
  pages        = {976-1011},
  shortjournal = {Algorithmica},
  title        = {Analysing the robustness of evolutionary algorithms to noise: Refined runtime bounds and an example where noise is beneficial},
  volume       = {83},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Analysis of noisy evolutionary optimization when sampling
fails. <em>Alg</em>, <em>83</em>(4), 940‚Äì975. (<a
href="https://doi.org/10.1007/s00453-019-00666-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In noisy evolutionary optimization, sampling is a common strategy to deal with noise. By the sampling strategy, the fitness of a solution is evaluated multiple times (called sample size) independently, and its true fitness is then approximated by the average of these evaluations. Most previous studies on sampling are empirical, and the few theoretical studies mainly showed the effectiveness of sampling with a sufficiently large sample size. In this paper, we theoretically examine what strategies can work when sampling with any fixed sample size fails. By constructing a family of artificial noisy examples, we prove that sampling is always ineffective, while using parent or offspring populations can be helpful on some examples. We also construct an artificial noisy example to show that when using neither sampling nor populations is effective, a tailored adaptive sampling (i.e., sampling with an adaptive sample size) strategy can work. These findings may enhance our understanding of sampling to some extent, but future work is required to validate them in natural situations.},
  archive      = {J_Alg},
  author       = {Qian, Chao and Bian, Chao and Yu, Yang and Tang, Ke and Yao, Xin},
  doi          = {10.1007/s00453-019-00666-6},
  journal      = {Algorithmica},
  number       = {4},
  pages        = {940-975},
  shortjournal = {Algorithmica},
  title        = {Analysis of noisy evolutionary optimization when sampling fails},
  volume       = {83},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Runtime performances of randomized search heuristics for the
dynamic weighted vertex cover problem. <em>Alg</em>, <em>83</em>(4),
906‚Äì939. (<a href="https://doi.org/10.1007/s00453-019-00662-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Randomized search heuristics such as evolutionary algorithms are frequently applied to dynamic combinatorial optimization problems. Within this paper, we present a dynamic model of the classic weighted vertex cover problem and analyze the runtime performances of the well-studied algorithms randomized local search and (1¬†+¬†1) EA adapted to it, to contribute to the theoretical understanding of evolutionary computing for problems with dynamic changes. In our investigations, we use an edge-based representation based on the dual form of the Linear Programming formulation for the problem and study the expected runtime that the adapted algorithms require to maintain a 2-approximate solution when the given weighted graph is modified by an edge-editing or weight-editing operation. Considering the weights on the vertices may be exponentially large with respect to the size of the graph, the step size adaption strategy is incorporated, with or without the 1/5-th rule that is employed to control the increasing/decreasing rate of the step size. Our results show that three of the four algorithms presented in the paper can recompute 2-approximate solutions for the studied dynamic changes in polynomial expected runtime, but the (1¬†+¬†1) EA with 1/5-th rule requires pseudo-polynomial expected runtime.},
  archive      = {J_Alg},
  author       = {Shi, Feng and Neumann, Frank and Wang, Jianxin},
  doi          = {10.1007/s00453-019-00662-w},
  journal      = {Algorithmica},
  number       = {4},
  pages        = {906-939},
  shortjournal = {Algorithmica},
  title        = {Runtime performances of randomized search heuristics for the dynamic weighted vertex cover problem},
  volume       = {83},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Preface to the special issue on theory of genetic and
evolutionary computation. <em>Alg</em>, <em>83</em>(4), 903‚Äì905. (<a
href="https://doi.org/10.1007/s00453-021-00803-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_Alg},
  author       = {Auger, Anne and Lehre, Per Kristian},
  doi          = {10.1007/s00453-021-00803-0},
  journal      = {Algorithmica},
  number       = {4},
  pages        = {903-905},
  shortjournal = {Algorithmica},
  title        = {Preface to the special issue on theory of genetic and evolutionary computation},
  volume       = {83},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Improved streaming algorithms for maximizing monotone
submodular functions under a knapsack constraint. <em>Alg</em>,
<em>83</em>(3), 879‚Äì902. (<a
href="https://doi.org/10.1007/s00453-020-00786-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we consider the problem of maximizing a monotone submodular function subject to a knapsack constraint in a streaming setting. In such a setting, elements arrive sequentially and at any point in time, and the algorithm can store only a small fraction of the elements that have arrived so far. For the special case that all elements have unit sizes¬†(i.e., the cardinality-constraint case), one can find a $$(0.5-\varepsilon )$$ -approximate solution in $$O(K\varepsilon ^{-1})$$ space, where K is the knapsack capacity¬†(Badanidiyuru et al.¬†KDD 2014). The approximation ratio is recently shown to be optimal¬†(Feldman et al.¬†STOC 2020). In this work, we propose a $$(0.4-\varepsilon )$$ -approximation algorithm for the knapsack-constrained problem, using space that is a polynomial of K and $$\varepsilon $$ . This improves on the previous best ratio of $$0.363-\varepsilon $$ with space of the same order. Our algorithm is based on a careful combination of various ideas to transform multiple-pass streaming algorithms into a single-pass one.},
  archive      = {J_Alg},
  author       = {Huang, Chien-Chung and Kakimura, Naonori},
  doi          = {10.1007/s00453-020-00786-4},
  journal      = {Algorithmica},
  number       = {3},
  pages        = {879-902},
  shortjournal = {Algorithmica},
  title        = {Improved streaming algorithms for maximizing monotone submodular functions under a knapsack constraint},
  volume       = {83},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Guess free maximization of submodular and linear sums.
<em>Alg</em>, <em>83</em>(3), 853‚Äì878. (<a
href="https://doi.org/10.1007/s00453-020-00757-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the problem of maximizing the sum of a monotone submodular function and a linear function subject to a general solvable polytope constraint. Recently, Sviridenko et al.¬†(Math Oper Res 42(4):1197‚Äì1218, 2017) described an algorithm for this problem whose approximation guarantee is optimal in some intuitive and formal senses. Unfortunately, this algorithm involves a guessing step which makes it less clean and significantly affects its time complexity. In this work we describe a clean alternative algorithm that uses a novel weighting technique in order to avoid the problematic guessing step while keeping the same approximation guarantee as the algorithm of Sviridenko et al.¬†(2017). We also show that the guarantee of our algorithm becomes slightly better when the polytope is down-monotone, and that this better guarantee is tight for such polytopes.},
  archive      = {J_Alg},
  author       = {Feldman, Moran},
  doi          = {10.1007/s00453-020-00757-9},
  journal      = {Algorithmica},
  number       = {3},
  pages        = {853-878},
  shortjournal = {Algorithmica},
  title        = {Guess free maximization of submodular and linear sums},
  volume       = {83},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Graph isomorphism for <span
class="math display">(<em>H</em><sub>1</sub>,‚ÄÜ<em>H</em><sub>2</sub>)</span>
-free graphs: An almost complete dichotomy. <em>Alg</em>,
<em>83</em>(3), 822‚Äì852. (<a
href="https://doi.org/10.1007/s00453-020-00747-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We resolve the computational complexity of Graph Isomorphism for classes of graphs characterized by two forbidden induced subgraphs $$ H_{1} $$ and $$H_2$$ for all but six pairs $$(H_1,H_2)$$ . Schweitzer had previously shown that the number of open cases was finite, but without specifying the open cases. Grohe and Schweitzer proved that Graph Isomorphism is polynomial-time solvable on graph classes of bounded clique-width. Our work combines known results such as these with new results. By exploiting a relationship between Graph Isomorphism and clique-width, we simultaneously reduce the number of open cases for boundedness of clique-width for $$(H_1,H_2)$$ -free graphs to five.},
  archive      = {J_Alg},
  author       = {Bonamy, Marthe and Bousquet, Nicolas and Dabrowski, Konrad K. and Johnson, Matthew and Paulusma, Dani√´l and Pierron, Th√©o},
  doi          = {10.1007/s00453-020-00747-x},
  journal      = {Algorithmica},
  number       = {3},
  pages        = {822-852},
  shortjournal = {Algorithmica},
  title        = {Graph isomorphism for $$(H_1,H_2)$$ -free graphs: An almost complete dichotomy},
  volume       = {83},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Online bin covering with advice. <em>Alg</em>,
<em>83</em>(3), 795‚Äì821. (<a
href="https://doi.org/10.1007/s00453-020-00728-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The bin covering problem asks for covering a maximum number of bins with an online sequence of n items of different sizes in the range (0,¬†1]; a bin is said to be covered if it receives items of total size at least¬†1. We study this problem in the advice setting and provide asymptotically tight bounds of $$\Theta (n \log {\textsc {Opt}})$$ on the size of advice required to achieve optimal solutions. Moreover, we show that any algorithm with advice of size $$o(\log \log n)$$ has a competitive ratio of at most¬†0.5. In other words, advice of size $$o(\log \log n)$$ is useless for improving the competitive ratio of¬†0.5, attainable by an online algorithm without advice. This result highlights a difference between the bin covering and the bin packing problems in the advice model: for the bin packing problem, there are several algorithms with advice of constant size that outperform online algorithms without advice. Furthermore, we show that advice of size $$O(\log \log n)$$ is sufficient to achieve an asymptotic competitive ratio of $$0.5\bar{3}$$ which is strictly better than the best ratio¬†0.5 attainable by purely online algorithms. The technicalities involved in introducing and analyzing this algorithm are quite different from the existing results for the bin packing problem and confirm the different nature of these two problems. Finally, we show that a linear number of advice bits is necessary to achieve any competitive ratio better than 15/16 for the online bin covering problem.},
  archive      = {J_Alg},
  author       = {Boyar, Joan and Favrholdt, Lene M. and Kamali, Shahin and Larsen, Kim S.},
  doi          = {10.1007/s00453-020-00728-0},
  journal      = {Algorithmica},
  number       = {3},
  pages        = {795-821},
  shortjournal = {Algorithmica},
  title        = {Online bin covering with advice},
  volume       = {83},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Succinct encodings for families of interval graphs.
<em>Alg</em>, <em>83</em>(3), 776‚Äì794. (<a
href="https://doi.org/10.1007/s00453-020-00710-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the problem of designing succinct data structures for interval graphs with n vertices while supporting degree, adjacency, neighborhood and shortest path queries in optimal time. Towards showing succinctness, we first show that at least $$n\log _2{n} - 2n\log _2\log _2 n - O(n)$$ bits are necessary to represent any unlabeled interval graph G with n vertices, answering an open problem of Yang and Pippenger (Proc Am Math Soc Ser B 4(1):1‚Äì3, 2017). This is augmented by a data structure of size $$n\log _2{n} +O(n)$$ bits while supporting not only the above queries optimally but also capable of executing various combinatorial algorithms (like proper coloring, maximum independent set etc.) on interval graphs efficiently. Finally, we extend our ideas to other variants of interval graphs, for example, proper/unit interval graphs, k-improper interval graphs, and circular-arc graphs, and design succinct data structures for these graph classes as well along with supporting queries on them efficiently.},
  archive      = {J_Alg},
  author       = {Acan, H√ºseyin and Chakraborty, Sankardeep and Jo, Seungbum and Satti, Srinivasa Rao},
  doi          = {10.1007/s00453-020-00710-w},
  journal      = {Algorithmica},
  number       = {3},
  pages        = {776-794},
  shortjournal = {Algorithmica},
  title        = {Succinct encodings for families of interval graphs},
  volume       = {83},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Special issue on algorithms and data structures (WADS 2019).
<em>Alg</em>, <em>83</em>(3), 775. (<a
href="https://doi.org/10.1007/s00453-021-00804-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_Alg},
  author       = {Friggstad, Zachary and Sack, J√∂rg-R√ºdiger and Salavatipour, Mohammad R.},
  doi          = {10.1007/s00453-021-00804-z},
  journal      = {Algorithmica},
  number       = {3},
  pages        = {775},
  shortjournal = {Algorithmica},
  title        = {Special issue on algorithms and data structures (WADS 2019)},
  volume       = {83},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Simultaneous feedback edge set: A parameterized perspective.
<em>Alg</em>, <em>83</em>(2), 753‚Äì774. (<a
href="https://doi.org/10.1007/s00453-020-00773-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Agrawal et al.¬†(ACM Trans Comput Theory 10(4):18:1‚Äì18:25, 2018. https://doi.org/10.1145/3265027 ) studied a simultaneous variant of the classic Feedback Vertex Set problem, called Simultaneous Feedback Vertex Set (Sim-FVS). Here, we consider the edge variant of the problem, namely, Simultaneous Feedback Edge Set (Sim-FES). In this problem, the input is an n-vertex graph G, a positive integer k, and a coloring function col: $$E(G) \rightarrow 2^{[\alpha ]}$$ , and the objective is to check whether there is an edge subset S of cardinality k in G such that for each $$i \in [\alpha ]$$ , $$G_i - S$$ is acyclic. Unlike the vertex variant of the problem, when $$\alpha =1$$ , the problem is equivalent to finding a maximal spanning forest and hence it is polynomial time solvable. We show that for $$\alpha =3$$ , Sim-FES is NP-hard, and does not admit an algorithm of running time $$2^{o(k)}n^{{{\mathcal {O}}}(1)}$$ unless ETH fails. This hardness result is complimented by an FPT algorithm for Sim-FES running in time $$2^{\omega k \alpha +\alpha \log k} n^{{{\mathcal {O}}}(1)}$$ where $$\omega$$ is the exponent in the running time of matrix multiplication. The same algorithm gives a polynomial time algorithm for the case when $$\alpha =2$$ . We also give a kernel for Sim-FES with $$(k\alpha )^{{\mathcal {O}}(\alpha )}$$ vertices. Finally, we consider a ‚Äúdual‚Äù version of the problem called Maximum Simultaneous Acyclic Subgraph and give an FPT algorithm with running time $$2^{\omega q \alpha }n^{{\mathcal {O}}(1)}$$ , where q is the number of edges in the output subgraph.},
  archive      = {J_Alg},
  author       = {Agrawal, Akanksha and Panolan, Fahad and Saurabh, Saket and Zehavi, Meirav},
  doi          = {10.1007/s00453-020-00773-9},
  journal      = {Algorithmica},
  number       = {2},
  pages        = {753-774},
  shortjournal = {Algorithmica},
  title        = {Simultaneous feedback edge set: A parameterized perspective},
  volume       = {83},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The power of cut-based parameters for computing
edge-disjoint paths. <em>Alg</em>, <em>83</em>(2), 726‚Äì752. (<a
href="https://doi.org/10.1007/s00453-020-00772-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper revisits the classical edge-disjoint paths (EDP) problem, where one is given an undirected graph G and a set of terminal pairs P and asks whether G contains a set of pairwise edge-disjoint paths connecting every terminal pair in P. Our aim is to identify structural properties (parameters) of graphs which allow the efficient solution of EDP without restricting the placement of terminals in P in any way. In this setting, EDP is known to remain NP-hard even on extremely restricted graph classes, such as graphs with a vertex cover of size 3. We present three results which use edge-separator based parameters to chart new islands of tractability in the complexity landscape of EDP. Our first and main result utilizes the fairly recent structural parameter tree-cut width (a parameter with fundamental ties to graph immersions and graph cuts): we obtain a polynomial-time algorithm for EDP on every graph class of bounded tree-cut width. Our second result shows that EDP parameterized by tree-cut width is unlikely to be fixed-parameter tractable. Our final, third result is a polynomial kernel for EDP parameterized by the size of a minimum feedback edge set in the graph.},
  archive      = {J_Alg},
  author       = {Ganian, Robert and Ordyniak, Sebastian},
  doi          = {10.1007/s00453-020-00772-w},
  journal      = {Algorithmica},
  number       = {2},
  pages        = {726-752},
  shortjournal = {Algorithmica},
  title        = {The power of cut-based parameters for computing edge-disjoint paths},
  volume       = {83},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Approximation guarantee of OSP mechanisms: The case of
machine scheduling and facility location. <em>Alg</em>, <em>83</em>(2),
695‚Äì725. (<a href="https://doi.org/10.1007/s00453-020-00771-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Obvious strategyproofness (OSP) is an appealing concept as it allows to maintain incentive compatibility even in the presence of agents that are not fully rational, i.e., those who struggle with contingent reasoning (Li in Am Econ Rev 107(11):3257‚Äì3287, 2017). However, it has been shown to impose some limitations, e.g., no OSP mechanism can return a stable matching (Ashlagi and Gonczarowski in J Econ Theory 177:405‚Äì425, 2018). We here deepen the study of the limitations of OSP mechanisms by looking at their approximation guarantees for basic optimization problems paradigmatic of the area, i.e., machine scheduling and facility location. We prove a number of bounds on the approximation guarantee of OSP mechanisms, which show that OSP can come at a significant cost. However, rather surprisingly, we prove that OSP mechanisms can return optimal solutions when they use monitoring‚Äîa novel mechanism design paradigm that introduces a mild level of scrutiny on agents‚Äô declarations (Kov√°cs et al. in WINE 9470:398‚Äì412, 2015).},
  archive      = {J_Alg},
  author       = {Ferraioli, Diodato and Ventre, Carmine},
  doi          = {10.1007/s00453-020-00771-x},
  journal      = {Algorithmica},
  number       = {2},
  pages        = {695-725},
  shortjournal = {Algorithmica},
  title        = {Approximation guarantee of OSP mechanisms: The case of machine scheduling and facility location},
  volume       = {83},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). High entropy random selection protocols. <em>Alg</em>,
<em>83</em>(2), 667‚Äì694. (<a
href="https://doi.org/10.1007/s00453-020-00770-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the two party problem of randomly selecting a common string among all the strings of length n. We want the protocol to have the property that the output distribution has high Shannon entropy or high min entropy, even when one of the two parties is dishonest and deviates from the protocol. We develop protocols that achieve high, close to n, Shannon entropy and simultaneously min entropy close to n/2. In the literature the randomness guarantee is usually expressed in terms of ‚Äúresilience‚Äù. The notion of Shannon entropy is not directly comparable to that of resilience, but we establish a connection between the two that allows us to compare our protocols with the existing ones. We construct an explicit protocol that yields Shannon entropy $$n - O(1)$$ and has $$O(\log ^* n)$$ rounds, improving over the protocol of Goldreich et al. (SIAM J Comput 27: 506‚Äì544, 1998) that also achieves this entropy but needs O(n) rounds. Both these protocols need $$O(n^2)$$ bits of communication. Next we reduce the number of rounds and the length of communication in our protocols. We show the existence, non-explicitly, of a protocol that has 6 rounds, O(n) bits of communication and yields Shannon entropy $$n- O(\log n)$$ and min entropy $$n/2 - O(\log n)$$ . Our protocol achieves the same Shannon entropy bound as, also non-explicit, protocol of Gradwohl et al. (in: Dwork (ed) Advances in Cryptology‚ÄîCRYPTO ‚Äò06, 409‚Äì426, Technical Report , 2006), however achieves much higher min entropy: $$n/2 - O(\log n)$$ versus $$O(\log n)$$ . Finally we exhibit a very simple 3-round explicit ‚Äúgeometric‚Äù protocol with communication length O(n). We connect the security parameter of this protocol with the well studied Kakeya problem motivated by Harmonic Analysis and Analytic Number Theory. We prove that this protocol has Shannon entropy $$n-o(n)$$ . Its relation to the Kakeya problem follows a new and different approach to the random selection problem than any of the previously known protocols.},
  archive      = {J_Alg},
  author       = {Buhrman, Harry and Christandl, Matthias and Kouck√Ω, Michal and Lotker, Zvi and Patt-Shamir, Boaz and Vereshchagin, Nikolay},
  doi          = {10.1007/s00453-020-00770-y},
  journal      = {Algorithmica},
  number       = {2},
  pages        = {667-694},
  shortjournal = {Algorithmica},
  title        = {High entropy random selection protocols},
  volume       = {83},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). On orthogonally guarding orthogonal polygons with bounded
treewidth. <em>Alg</em>, <em>83</em>(2), 641‚Äì666. (<a
href="https://doi.org/10.1007/s00453-020-00769-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There exist many variants of guarding an orthogonal polygon in an orthogonal fashion: sometimes a guard can see within a rectangle, along a staircase, or along an orthogonal path with at most k bends. In this paper, we study all these guarding models for the special case of orthogonal polygons that have bounded treewidth in some sense. As our main result, we show that the problem of finding the minimum number of guards in all these models becomes linear-time solvable on polygons with bounded treewidth. We complement our main result by giving some hardness results.},
  archive      = {J_Alg},
  author       = {Biedl, Therese and Mehrabi, Saeed},
  doi          = {10.1007/s00453-020-00769-5},
  journal      = {Algorithmica},
  number       = {2},
  pages        = {641-666},
  shortjournal = {Algorithmica},
  title        = {On orthogonally guarding orthogonal polygons with bounded treewidth},
  volume       = {83},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Non-greedy online steiner trees on outerplanar graphs.
<em>Alg</em>, <em>83</em>(2), 613‚Äì640. (<a
href="https://doi.org/10.1007/s00453-020-00768-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the classic online Steiner tree problem on edge-weighted graphs. It is known that a greedy (nearest neighbor) online algorithm has a tight competitive ratio for wide classes of graphs, such as trees, rings, any class including series-parallel graphs, and unweighted graphs with bounded diameter. However, we do not know any greedy or non-greedy tight deterministic algorithm for other classes of graphs. In this paper, we observe that a greedy algorithm is $$\Omega (\log n)$$ -competitive on outerplanar graphs, where n is the number of vertices, and propose a 5.828-competitive deterministic algorithm on outerplanar graphs. Our algorithm connects a requested vertex and the tree constructed thus far using a path that is constant times longer than the distance between them. We also present a lower bound of 4 for arbitrary deterministic online Steiner tree algorithms on outerplanar graphs.},
  archive      = {J_Alg},
  author       = {Matsubayashi, Akira},
  doi          = {10.1007/s00453-020-00768-6},
  journal      = {Algorithmica},
  number       = {2},
  pages        = {613-640},
  shortjournal = {Algorithmica},
  title        = {Non-greedy online steiner trees on outerplanar graphs},
  volume       = {83},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). On the complexity of colouring antiprismatic graphs.
<em>Alg</em>, <em>83</em>(2), 589‚Äì612. (<a
href="https://doi.org/10.1007/s00453-020-00767-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A graph G is prismatic if for every triangle T of G, every vertex of G not in T has a unique neighbour in T. The complement of a prismatic graph is called antiprismatic. The complexity of colouring antiprismatic graphs is still unknown. Equivalently, the complexity of the clique cover problem in prismatic graphs is not known. Chudnovsky and Seymour gave a full structural description of prismatic graphs. They showed that the class can be divided into two subclasses: the orientable prismatic graphs, and the non-orientable prismatic graphs. We give a polynomial time algorithm that solves the clique cover problem in every non-orientable prismatic graph. It relies on the the structural description and on later work of Javadi and Hajebi. We give a polynomial time algorithm which solves the vertex-disjoint triangles problem for every prismatic graph. It does not rely on the structural description.},
  archive      = {J_Alg},
  author       = {Preissmann, Myriam and Robin, Cl√©oph√©e and Trotignon, Nicolas},
  doi          = {10.1007/s00453-020-00767-7},
  journal      = {Algorithmica},
  number       = {2},
  pages        = {589-612},
  shortjournal = {Algorithmica},
  title        = {On the complexity of colouring antiprismatic graphs},
  volume       = {83},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Constrained minimum passage time in random geometric graphs.
<em>Alg</em>, <em>83</em>(2), 576‚Äì588. (<a
href="https://doi.org/10.1007/s00453-020-00766-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Let $$G$$ be a random geometric graph formed by $$n$$ nodes with adjacency distance $$r_n$$ and let each edge of $$G$$ be assigned an independent exponential passage time with mean that depends on the graph size $$n.$$ We connect $$G$$ to two nodes source $$s_A$$ and destination $$s_B$$ at deterministic locations spaced $$d_n$$ apart in the unit square and find upper and lower bounds on the minimum passage time between $$s_A$$ and $$s_B$$ through paths in $$G$$ having constant stretch, i.e., whose length is constrained to be proportional to the Euclidean distance between $$s_A$$ and $$s_B.$$},
  archive      = {J_Alg},
  author       = {Ganesan, Ghurumuruhan},
  doi          = {10.1007/s00453-020-00766-8},
  journal      = {Algorithmica},
  number       = {2},
  pages        = {576-588},
  shortjournal = {Algorithmica},
  title        = {Constrained minimum passage time in random geometric graphs},
  volume       = {83},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). On the tree augmentation problem. <em>Alg</em>,
<em>83</em>(2), 553‚Äì575. (<a
href="https://doi.org/10.1007/s00453-020-00765-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the Tree Augmentation problem we are given a tree $$T=(V,F)$$ and a set $$E \subseteq V \times V$$ of edges with positive integer costs $${c_e:e \in E}$$ . The goal is to augment T by a minimum cost edge set $$J \subseteq E$$ such that $$T \cup J$$ is 2-edge-connected. We obtain the following results.},
  archive      = {J_Alg},
  author       = {Nutov, Zeev},
  doi          = {10.1007/s00453-020-00765-9},
  journal      = {Algorithmica},
  number       = {2},
  pages        = {553-575},
  shortjournal = {Algorithmica},
  title        = {On the tree augmentation problem},
  volume       = {83},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Covert computation in self-assembled circuits. <em>Alg</em>,
<em>83</em>(2), 531‚Äì552. (<a
href="https://doi.org/10.1007/s00453-020-00764-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditionally, computation within self-assembly models is hard to conceal because the self-assembly process generates a crystalline assembly whose computational history is inherently part of the structure itself. With no way to remove information from the computation, this computational model offers a unique problem: how can computational input and computation be hidden while still computing and reporting the final output? Designing such systems is inherently motivated by privacy concerns in biomedical computing and applications in cryptography. In this paper we propose the problem of performing ‚Äúcovert computation‚Äù within tile self-assembly that seeks to design self-assembly systems that ‚Äúconceal‚Äù both the input and computational history of performed computations. We achieve these results within the growth-only restricted abstract Tile Assembly Model (aTAM) with positive and negative interactions. We show that general-case covert computation is possible by implementing a set of basic covert logic gates capable of simulating any circuit (functionally complete). To further motivate the study of covert computation, we apply our new framework to resolve an outstanding complexity question; we use our covert circuitry to show that the unique assembly verification problem within the growth-only aTAM with negative interactions is coNP-complete.},
  archive      = {J_Alg},
  author       = {Cantu, Angel A. and Luchsinger, Austin and Schweller, Robert and Wylie, Tim},
  doi          = {10.1007/s00453-020-00764-w},
  journal      = {Algorithmica},
  number       = {2},
  pages        = {531-552},
  shortjournal = {Algorithmica},
  title        = {Covert computation in self-assembled circuits},
  volume       = {83},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The complexity of computational problems about nash
equilibria in symmetric win-lose games. <em>Alg</em>, <em>83</em>(2),
447‚Äì530. (<a href="https://doi.org/10.1007/s00453-020-00763-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We revisit the complexity of deciding, given a bimatrix game, whether it has a Nash equilibrium with certain natural properties; such decision problems were early known to be $${{\mathcal{N}}{\mathcal{P}}}$$ -hard (Gilboa and Zemel in Games Econ Behav 1(1):80‚Äì93, 1989). We show that $${{\mathcal{N}}{\mathcal{P}}}$$ -hardness still holds under two significant restrictions in simultaneity: the game is win-lose (that is, all utilities are 0 or 1) and symmetric. To address the former restriction, we design win-lose gadgets and a win-lose reduction; to accomodate the latter restriction, we employ and analyze the classical $${\mathsf{GHR}}$$ -symmetrization (Griesmer et al. in On symmetric bimatrix games, IBM research paper RC-959, IBM Corp., T.¬†J.¬†Watson Research Center, 1963) in the win-lose setting. Thus, symmetric win-lose bimatrix games are as complex as general bimatrix games with respect to such decision problems. As a byproduct of our techniques, we derive hardness results for search, counting and parity problems about Nash equilibria in symmetric win-lose bimatrix games.},
  archive      = {J_Alg},
  author       = {Bil√≤, Vittorio and Mavronicolas, Marios},
  doi          = {10.1007/s00453-020-00763-x},
  journal      = {Algorithmica},
  number       = {2},
  pages        = {447-530},
  shortjournal = {Algorithmica},
  title        = {The complexity of computational problems about nash equilibria in symmetric win-lose games},
  volume       = {83},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Fault-tolerant covering problems in metric spaces.
<em>Alg</em>, <em>83</em>(2), 413‚Äì446. (<a
href="https://doi.org/10.1007/s00453-020-00762-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we study some fault-tolerant covering problems in metric spaces. In the metric multi-cover problem (MMC), we are given two point sets Y (servers) and X (clients) in an arbitrary metric space $$(X \cup Y, d)$$ , a positive integer k that represents the coverage demand of each client, and a constant $$\alpha \ge 1$$ . Each server can host a single ball of arbitrary radius centered on it. Each client $$x \in X$$ needs to be covered by at least k such balls centered on servers. The objective function that we wish to minimize is the sum of the $$\alpha $$ -th powers of the radii of the balls. We also study some non-trivial generalizations of the MMC, such as (a) the non-uniform MMC, where we allow client-specific demands, and (b) the t-MMC, where we require the number of open servers to be at most some given integer t. We present the first constant approximations for these fault-tolerant covering problems. Our algorithms are based on the following paradigm: for each of the three problems, we present an efficient algorithm that reduces the problem to several instances of the corresponding 1-covering problem, where the coverage demand of each client is 1. The reductions preserve optimality up to a multiplicative constant factor. Applying known constant factor approximation algorithms for 1-covering, we obtain our results for the MMC and these generalizations.},
  archive      = {J_Alg},
  author       = {Bhowmick, Santanu and Inamdar, Tanmay and Varadarajan, Kasturi},
  doi          = {10.1007/s00453-020-00762-y},
  journal      = {Algorithmica},
  number       = {2},
  pages        = {413-446},
  shortjournal = {Algorithmica},
  title        = {Fault-tolerant covering problems in metric spaces},
  volume       = {83},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). CADbots: Algorithmic aspects of manipulating programmable
matter with finite automata. <em>Alg</em>, <em>83</em>(1), 387‚Äì412. (<a
href="https://doi.org/10.1007/s00453-020-00761-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We contribute results for a set of fundamental problems in the context of programmable matter by presenting algorithmic methods for evaluating and manipulating a collective of particles by a finite automaton that can neither store significant amounts of data, nor perform complex computations, and is limited to a handful of possible physical operations. We provide a toolbox for carrying out fundamental tasks on a given arrangement of particles, using the arrangement itself as a storage device, similar to a higher-dimensional Turing machine with geometric properties. Specific results include time- and space-efficient procedures for bounding, counting, copying, reflecting, rotating or scaling a complex given shape.},
  archive      = {J_Alg},
  author       = {Fekete, S√°ndor P. and Gmyr, Robert and Hugo, Sabrina and Keldenich, Phillip and Scheffer, Christian and Schmidt, Arne},
  doi          = {10.1007/s00453-020-00761-z},
  journal      = {Algorithmica},
  number       = {1},
  pages        = {387-412},
  shortjournal = {Algorithmica},
  title        = {CADbots: Algorithmic aspects of manipulating programmable matter with finite automata},
  volume       = {83},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Polynomial treedepth bounds in linear colorings.
<em>Alg</em>, <em>83</em>(1), 361‚Äì386. (<a
href="https://doi.org/10.1007/s00453-020-00760-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Low-treedepth colorings are an important tool for algorithms that exploit structure in classes of bounded expansion; they guarantee subgraphs that use few colors have bounded treedepth. These colorings have an implicit tradeoff between the total number of colors used and the treedepth bound, and prior empirical work suggests that the former dominates the run time of existing algorithms in practice. We introduce p-linear colorings as an alternative to the commonly used p-centered colorings. They can be efficiently computed in bounded expansion classes and use at most as many colors as p-centered colorings. Although a set of $$k&lt;p$$ colors from a p-centered coloring induces a subgraph of treedepth at most k, the same number of colors from a p-linear coloring may induce subgraphs of larger treedepth. We establish a polynomial upper bound on the treedepth in general graphs, and give tighter bounds in trees and interval graphs via constructive coloring algorithms. We also give a co-NP-completeness reduction for recognizing p-linear colorings and discuss ways to overcome this limitation in practice.},
  archive      = {J_Alg},
  author       = {Kun, Jeremy and O‚ÄôBrien, Michael P. and Pilipczuk, Marcin and Sullivan, Blair D.},
  doi          = {10.1007/s00453-020-00760-0},
  journal      = {Algorithmica},
  number       = {1},
  pages        = {361-386},
  shortjournal = {Algorithmica},
  title        = {Polynomial treedepth bounds in linear colorings},
  volume       = {83},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Tight bounds for online coloring of basic graph classes.
<em>Alg</em>, <em>83</em>(1), 337‚Äì360. (<a
href="https://doi.org/10.1007/s00453-020-00759-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We resolve a number of long-standing open problems in online graph coloring. More specifically, we develop tight lower bounds on the performance of online algorithms for fundamental graph classes. An important contribution is that our bounds also hold for randomized online algorithms, for which hardly any results were known. Technically, we construct lower bounds for chordal graphs. The constructions then allow us to derive results on the performance of randomized online algorithms for the following further graph classes: trees, planar, bipartite, inductive, bounded-treewidth and disk graphs. It shows that the best competitive ratio of both deterministic and randomized online algorithms is $$\Theta (\log n)$$ , where n is the number of vertices of a graph. Furthermore, we prove that this guarantee cannot be improved if an online algorithm has a lookahead of size $$O(n/\log n)$$ or access to a reordering buffer of size $$n^{1-\epsilon }$$ , for any $$0&lt;\epsilon \le 1$$ . A consequence of our results is that, for all of the above mentioned graph classes except bipartite graphs, the natural First Fit coloring algorithm achieves an optimal performance, up to constant factors, among deterministic and randomized online algorithms.},
  archive      = {J_Alg},
  author       = {Albers, Susanne and Schraink, Sebastian},
  doi          = {10.1007/s00453-020-00759-7},
  journal      = {Algorithmica},
  number       = {1},
  pages        = {337-360},
  shortjournal = {Algorithmica},
  title        = {Tight bounds for online coloring of basic graph classes},
  volume       = {83},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). On structural parameterizations of the bounded-degree vertex
deletion problem. <em>Alg</em>, <em>83</em>(1), 297‚Äì336. (<a
href="https://doi.org/10.1007/s00453-020-00758-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the parameterized complexity of the Bounded-Degree Vertex Deletion problem (BDD), where the aim is to find a maximum induced subgraph whose maximum degree is below a given degree bound. Our focus lies on parameters that measure the structural properties of the input instance. We first show that the problem is W[1]-hard parameterized by a wide range of fairly restrictive structural parameters such as the feedback vertex set number, pathwidth, treedepth, and even the size of a minimum vertex deletion set into graphs of pathwidth and treedepth at most three. We thereby resolve an open question stated in Betzler, Bredereck, Niedermeier and Uhlmann¬†(2012) concerning the complexity of BDD parameterized by the feedback vertex set number. On the positive side, we obtain fixed-parameter algorithms for the problem with respect to the decompositional parameter treecut width and a novel problem-specific parameter called the core fracture number.},
  archive      = {J_Alg},
  author       = {Ganian, Robert and Klute, Fabian and Ordyniak, Sebastian},
  doi          = {10.1007/s00453-020-00758-8},
  journal      = {Algorithmica},
  number       = {1},
  pages        = {297-336},
  shortjournal = {Algorithmica},
  title        = {On structural parameterizations of the bounded-degree vertex deletion problem},
  volume       = {83},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Distance and routing labeling schemes for cube-free median
graphs. <em>Alg</em>, <em>83</em>(1), 252‚Äì296. (<a
href="https://doi.org/10.1007/s00453-020-00756-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Distance labeling schemes are schemes that label the vertices of a graph with short labels in such a way that the distance between any two vertices u and v can be determined efficiently by merely inspecting the labels of u and v, without using any other information. Similarly, routing labeling schemes label the vertices of a graph in a such a way that given the labels of a source node and a destination node, it is possible to compute efficiently the port number of the edge from the source that heads in the direction of the destination. One of important problems is finding natural classes of graphs admitting distance and/or routing labeling schemes with labels of polylogarithmic size. In this paper, we show that the class of cube-free median graphs on n nodes enjoys distance and routing labeling schemes with labels of $$O(\log ^3 n)$$ bits.},
  archive      = {J_Alg},
  author       = {Chepoi, Victor and Labourel, Arnaud and Ratel, S√©bastien},
  doi          = {10.1007/s00453-020-00756-w},
  journal      = {Algorithmica},
  number       = {1},
  pages        = {252-296},
  shortjournal = {Algorithmica},
  title        = {Distance and routing labeling schemes for cube-free median graphs},
  volume       = {83},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). List 3-coloring graphs with no induced <span
class="math display"><em>P</em><sub>6</sub>‚ÄÖ+‚ÄÖ<em>r</em><em>P</em><sub>3</sub></span>.
<em>Alg</em>, <em>83</em>(1), 216‚Äì251. (<a
href="https://doi.org/10.1007/s00453-020-00754-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For an integer t, we let $$P_t$$ denote the t-vertex path. We write $$H+G$$ for the disjoint union of two graphs H and G, and for an integer r and a graph H, we write rH for the disjoint union of r copies of H. We say that a graph G is H-free if no induced subgraph of G is isomorphic to the graph H. In this paper, we study the complexity of k-coloring, for a fixed integer k, when restricted to the class of H-free graphs with a fixed graph H. We provide a polynomial-time algorithm to test if, for fixed r, a $$(P_6+rP_3)$$ -free is three-colorable, and find a coloring if one exists. We also solve the list version of this problem, where each vertex is assigned a list of possible colors, which is a subset of $${1,2,3}$$ . This generalizes results of Broersma, Golovach, Paulusma, and Song, and results of Klimo≈°ov√°, Malik, Masa≈ô√≠k, Novotn√°, Paulusma, and Sl√≠vov√°. Our proof uses a result of Ding, Seymour, and Winkler relating matchings and hitting sets in hypergraphs. We also prove that the problem of deciding if a $$(P_5+P_2)$$ -free graph has a k-coloring is NP-hard for every fixed $$k \ge 5$$ .},
  archive      = {J_Alg},
  author       = {Chudnovsky, Maria and Huang, Shenwei and Spirkl, Sophie and Zhong, Mingxian},
  doi          = {10.1007/s00453-020-00754-y},
  journal      = {Algorithmica},
  number       = {1},
  pages        = {216-251},
  shortjournal = {Algorithmica},
  title        = {List 3-coloring graphs with no induced $$P_6+rP_3$$},
  volume       = {83},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Learning privately with labeled and unlabeled examples.
<em>Alg</em>, <em>83</em>(1), 177‚Äì215. (<a
href="https://doi.org/10.1007/s00453-020-00753-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A private learner is an algorithm that given a sample of labeled individual examples outputs a generalizing hypothesis while preserving the privacy of each individual. In 2008, Kasiviswanathan et al. (FOCS 2008) gave a generic construction of private learners, in which the sample complexity is (generally) higher than what is needed for non-private learners. This gap in the sample complexity was then further studied in several followup papers, showing that (at least in some cases) this gap is unavoidable. Moreover, those papers considered ways to overcome the gap, by relaxing either the privacy or the learning guarantees of the learner. We suggest an alternative approach, inspired by the (non-private) models of semi-supervised learning and active-learning, where the focus is on the sample complexity of labeled examples whereas unlabeled examples are of a significantly lower cost. We consider private semi-supervised learners that operate on a random sample, where only a (hopefully small) portion of this sample is labeled. The learners have no control over which of the sample elements are labeled. Our main result is that the labeled sample complexity of private learners is characterized by the VC dimension. We present two generic constructions of private semi-supervised learners. The first construction is of learners where the labeled sample complexity is proportional to the VC dimension of the concept class, however, the unlabeled sample complexity of the algorithm is as big as the representation length of domain elements. Our second construction presents a new technique for decreasing the labeled sample complexity of a given private learner, while roughly maintaining its unlabeled sample complexity. In addition, we show that in some settings the labeled sample complexity does not depend on the privacy parameters of the learner.},
  archive      = {J_Alg},
  author       = {Beimel, Amos and Nissim, Kobbi and Stemmer, Uri},
  doi          = {10.1007/s00453-020-00753-z},
  journal      = {Algorithmica},
  number       = {1},
  pages        = {177-215},
  shortjournal = {Algorithmica},
  title        = {Learning privately with labeled and unlabeled examples},
  volume       = {83},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Building a nest by an automaton. <em>Alg</em>,
<em>83</em>(1), 144‚Äì176. (<a
href="https://doi.org/10.1007/s00453-020-00752-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A robot modeled as a deterministic finite automaton has to build a structure from material available to it. The robot navigates in the infinite oriented grid $${\mathbb {Z}} \times {\mathbb {Z}}$$ . Some cells of the grid are full (contain a brick) and others are empty. The subgraph of the grid induced by full cells, called the shape, is initially connected. The (Manhattan) distance between the furthest cells of the shape is called its span. The robot starts at a full cell. It can carry at most one brick at a time. At each step it can pick a brick from a full cell, move to an adjacent cell and drop a brick at an empty cell. The aim of the robot is to construct the most compact possible structure composed of all bricks, i.e., a nest. That is, the robot has to move all bricks in such a way that the span of the resulting shape be the smallest. Our main result is the design of a deterministic finite automaton that accomplishes this task and subsequently stops, for every initially connected shape, in time $$O(sn)$$ , where s is the span of the initial shape and $$n$$ is the number of bricks. We show that this complexity is optimal.},
  archive      = {J_Alg},
  author       = {Czyzowicz, Jurek and Dereniowski, Dariusz and Pelc, Andrzej},
  doi          = {10.1007/s00453-020-00752-0},
  journal      = {Algorithmica},
  number       = {1},
  pages        = {144-176},
  shortjournal = {Algorithmica},
  title        = {Building a nest by an automaton},
  volume       = {83},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Flip distances between graph orientations. <em>Alg</em>,
<em>83</em>(1), 116‚Äì143. (<a
href="https://doi.org/10.1007/s00453-020-00751-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Flip graphs are a ubiquitous class of graphs, which encode relations on a set of combinatorial objects by elementary, local changes. Skeletons of associahedra, for instance, are the graphs induced by quadrilateral flips in triangulations of a convex polygon. For some definition of a flip graph, a natural computational problem to consider is the flip distance: Given two objects, what is the minimum number of flips needed to transform one into the other? We consider flip graphs on orientations of simple graphs, where flips consist of reversing the direction of some edges. More precisely, we consider so-called $$\alpha$$ -orientations of a graph G, in which every vertex v has a specified outdegree $$\alpha (v)$$ , and a flip consists of reversing all edges of a directed cycle. We prove that deciding whether the flip distance between two $$\alpha$$ -orientations of a planar graph G is at most two is NP-complete. This also holds in the special case of perfect matchings, where flips involve alternating cycles. This problem amounts to finding geodesics on the common base polytope of two partition matroids, or, alternatively, on an alcoved polytope. It therefore provides an interesting example of a flip distance question that is computationally intractable despite having a natural interpretation as a geodesic on a nicely structured combinatorial polytope. We also consider the dual question of the flip distance between graph orientations in which every cycle has a specified number of forward edges, and a flip is the reversal of all edges in a minimal directed cut. In general, the problem remains hard. However, if we restrict to flips that only change sinks into sources, or vice-versa, then the problem can be solved in polynomial time. Here we exploit the fact that the flip graph is the cover graph of a distributive lattice. This generalizes a recent result from Zhang et al. (Acta Math Sin Engl Ser 35(4):569‚Äì576, 2019).},
  archive      = {J_Alg},
  author       = {Aichholzer, Oswin and Cardinal, Jean and Huynh, Tony and Knauer, Kolja and M√ºtze, Torsten and Steiner, Raphael and Vogtenhuber, Birgit},
  doi          = {10.1007/s00453-020-00751-1},
  journal      = {Algorithmica},
  number       = {1},
  pages        = {116-143},
  shortjournal = {Algorithmica},
  title        = {Flip distances between graph orientations},
  volume       = {83},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Privately outsourcing exponentiation to a single server:
Cryptanalysis and optimal constructions. <em>Alg</em>, <em>83</em>(1),
72‚Äì115. (<a href="https://doi.org/10.1007/s00453-020-00750-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We address the problem of speeding up group computations in cryptography using a single untrusted computational resource. We analyze the security of two efficient protocols for securely outsourcing (multi-)exponentiations. We show that the schemes do not achieve the claimed security guarantees and we present practical polynomial-time attacks on the delegation protocols which allow the untrusted helper to recover part (or the whole) of the device‚Äôs secret inputs. We then provide simple constructions for outsourcing group exponentiations in different settings (e.g. public/secret, fixed/variable bases and public/secret exponents). Finally, we prove that our attacks are unavoidable if one wants to use a single untrusted computational resource and to limit the computational cost of the limited device to a constant number of (generic) group operations. In particular, we show that our constructions are actually optimal in terms of operations in the underlying group.},
  archive      = {J_Alg},
  author       = {Chevalier, C√©line and Laguillaumie, Fabien and Vergnaud, Damien},
  doi          = {10.1007/s00453-020-00750-2},
  journal      = {Algorithmica},
  number       = {1},
  pages        = {72-115},
  shortjournal = {Algorithmica},
  title        = {Privately outsourcing exponentiation to a single server: Cryptanalysis and optimal constructions},
  volume       = {83},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Iterative partial rounding for vertex cover with hard
capacities. <em>Alg</em>, <em>83</em>(1), 45‚Äì71. (<a
href="https://doi.org/10.1007/s00453-020-00749-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We provide a simple and novel algorithmic design technique, for which we call iterative partial rounding, that gives a tight rounding-based approximation for vertex cover with hard capacities (VC-HC). In particular, we obtain an f-approximation for VC-HC on hypergraphs, improving over a previous results of Cheung et al. (In: SODA‚Äô14, 2014) to the tight extent. This also closes the gap of approximation since it was posted by Chuzhoy and Naor (Proceedings of the 43rd Symposium on Foundations of Computer Science (FOCS) 2002, pp. 481--489. IEEE Computer Society, 2002). Our main technical tool for establishing the approximation guarantee is a separation lemma that certifies the existence of a strong partition for solutions that are basic feasible in an extended version of the natural LP. We believe that our rounding technique is of independent interest when hard constraints are considered.},
  archive      = {J_Alg},
  author       = {Kao, Mong-Jen},
  doi          = {10.1007/s00453-020-00749-9},
  journal      = {Algorithmica},
  number       = {1},
  pages        = {45-71},
  shortjournal = {Algorithmica},
  title        = {Iterative partial rounding for vertex cover with hard capacities},
  volume       = {83},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Parameterized dynamic cluster editing. <em>Alg</em>,
<em>83</em>(1), 1‚Äì44. (<a
href="https://doi.org/10.1007/s00453-020-00746-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce a dynamic version of the NP-hard graph modification problem Cluster Editing. The essential point here is to take into account dynamically evolving input graphs: having a cluster graph (that is, a disjoint union of cliques) constituting a solution for a first input graph, can we cost-efficiently transform it into a ‚Äúsimilar‚Äù cluster graph that is a solution for a second (‚Äúsubsequent‚Äù) input graph? This model is motivated by several application scenarios, including incremental clustering, the search for compromise clusterings, or also local search in graph-based data clustering. We thoroughly study six problem variants (three modification scenarios edge editing, edge deletion, edge insertion; each combined with two distance measures between cluster graphs). We obtain both fixed-parameter tractability as well as (parameterized) hardness results, thus (except for three open questions) providing a fairly complete picture of the parameterized computational complexity landscape under the two perhaps most natural parameterizations: the distances of the new ‚Äúsimilar‚Äù cluster graph to (1)¬†the second input graph and to (2)¬†the input cluster graph.},
  archive      = {J_Alg},
  author       = {Luo, Junjie and Molter, Hendrik and Nichterlein, Andr√© and Niedermeier, Rolf},
  doi          = {10.1007/s00453-020-00746-y},
  journal      = {Algorithmica},
  number       = {1},
  pages        = {1-44},
  shortjournal = {Algorithmica},
  title        = {Parameterized dynamic cluster editing},
  volume       = {83},
  year         = {2021},
}
</textarea>
</details></li>
</ul>

</body>
</html>
