<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>PAAA_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="paaa---125">PAAA - 125</h2>
<ul>
<li><details>
<summary>
(2021a). Correction to: Outlier removal in biomaterial image
segmentations using a non-stationary bayesian learning. <em>PAAA</em>,
<em>24</em>(4), 1873. (<a
href="https://doi.org/10.1007/s10044-021-01015-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_PAAA},
  author       = {Syam, Wahyudin P. and Benardos, Panorios and Britchford, Emily and Hopkinson, Andrew and Branson , David T.},
  doi          = {10.1007/s10044-021-01015-6},
  journal      = {Pattern Analysis and Applications},
  month        = {11},
  number       = {4},
  pages        = {1873},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Correction to: Outlier removal in biomaterial image segmentations using a non-stationary bayesian learning},
  volume       = {24},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Proposing a new local density estimation outlier detection
algorithm: An empirical case study on flow pattern experiments.
<em>PAAA</em>, <em>24</em>(4), 1859–1872. (<a
href="https://doi.org/10.1007/s10044-021-01019-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Outlier or anomaly detection is an important branch of data analysis that becomes a crucial task in many application domains. Data objects which significantly dissimilar and inconsistent from the rest of the data objects are referred to as an outlier. In this paper, a new approach, called LDBAD (Local Density-Based Abnormal Detector), is proposed to discover useful irregular patterns hidden in the collected data sets. This method aims to find local abnormal data objects, which are characterized through three proposed measurements: local distance, local density, and Influenced outlierness degree. The performance of the proposed approach is evaluated on flow pattern experiments along a 180 degrees sharp bend channel with and without a T-shaped spur dike. Flow velocity components are collected using 3D velocimeter Vectrino. The analysis shows that the novel outlier detection method is effective and applicable to find outlier objects. Moreover, some feed-forward neural network velocity prediction models are created to demonstrate the necessity and advantages of outlier detection in flow pattern experiments. The results show that the accuracy of created models has been increased by removing outliers from the measurements.},
  archive      = {J_PAAA},
  author       = {Mahmoodi, Kumars and Ketabdari, Mohammad Javad and Vaghefi, Mohammad},
  doi          = {10.1007/s10044-021-01019-2},
  journal      = {Pattern Analysis and Applications},
  month        = {11},
  number       = {4},
  pages        = {1859-1872},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Proposing a new local density estimation outlier detection algorithm: An empirical case study on flow pattern experiments},
  volume       = {24},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A robust method for image stitching. <em>PAAA</em>,
<em>24</em>(4), 1847–1858. (<a
href="https://doi.org/10.1007/s10044-021-01005-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a novel method for large-scale image stitching that is robust against repetitive patterns and featureless regions in the imagery. In such cases, state-of-the-art image stitching methods easily produce image alignment artifacts, since they may produce false pairwise image registrations that are in conflict within the global connectivity graph. Our method augments the current methods by collecting all the plausible pairwise image registration candidates, among which globally consistent candidates are chosen. This enables the stitching process to determine the correct pairwise registrations by utilizing all the available information from the whole imagery, such as unambiguous registrations outside the repeating pattern and featureless regions. We formalize the method as a weighted multigraph whose nodes represent the individual image transformations from the composite image, and whose sets of multiple edges between two nodes represent all the plausible transformations between the pixel coordinates of the two images. The edge weights represent the plausibility of the transformations. The image transformations and the edge weights are solved from a non-linear minimization problem with linear constraints, for which a projection method is used. As an example, we apply the method in a large-scale scanning application where the transformations are primarily translations with only slight rotation and scaling component. Despite these simplifications, the state-of-the-art methods do not produce adequate results in such applications, since the image overlap is small, which can be featureless or repetitive, and misalignment artifacts and their concealment are unacceptable.},
  archive      = {J_PAAA},
  author       = {Pellikka, Matti and Lahtinen, Valtteri},
  doi          = {10.1007/s10044-021-01005-8},
  journal      = {Pattern Analysis and Applications},
  month        = {11},
  number       = {4},
  pages        = {1847-1858},
  shortjournal = {Pattern Anal. Appl.},
  title        = {A robust method for image stitching},
  volume       = {24},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). KAGO: An approximate adaptive grid-based outlier detection
approach using kernel density estimate. <em>PAAA</em>, <em>24</em>(4),
1825–1846. (<a
href="https://doi.org/10.1007/s10044-021-00998-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Outlier detection approaches show their efficacy while extracting unforeseen knowledge in domains such as intrusion detection, e-commerce, and fraudulent transactions. A prominent method like the K-Nearest Neighbor (KNN)-based outlier detection (KNNOD) technique relies on distance measures to extract the anomalies from the dataset. However, KNNOD is ill-equipped to deal with dynamic data environment efficiently due to its quadratic time complexity and sensitivity to changes in the dataset. As a result, any form of redundant computation due to frequent updates may lead to inefficiency while detecting outliers. In order to address these challenges, we propose an approximate adaptive g﻿rid-based outlier detection technique by finding point density using kernel density estimate (KAGO) instead of any distance measure. The proposed technique prunes the inlier grids and filters the candidate grids with local outliers upon a new point insertion. The grids containing potential outliers are aggregated to converge on to at most top-N global outliers incrementally. Experimental evaluation showed that KAGO outperformed KNNOD by more than an order of $$\approx$$ 3.9 across large relevant datasets at about half the memory consumption.},
  archive      = {J_PAAA},
  author       = {Bhattacharjee, Panthadeep and Garg, Ankur and Mitra, Pinaki},
  doi          = {10.1007/s10044-021-00998-6},
  journal      = {Pattern Analysis and Applications},
  month        = {11},
  number       = {4},
  pages        = {1825-1846},
  shortjournal = {Pattern Anal. Appl.},
  title        = {KAGO: An approximate adaptive grid-based outlier detection approach using kernel density estimate},
  volume       = {24},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Outlier removal in biomaterial image segmentations using a
non-stationary bayesian learning. <em>PAAA</em>, <em>24</em>(4),
1805–1824. (<a
href="https://doi.org/10.1007/s10044-021-00979-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Segmentation of dried amnion biomaterial tends to produce invalid (outlier) contour point detections due to texture and colour inhomogeneity of the biomaterial. In this paper, a novel implementation of a non-stationary Bayesian learning process for outlier contour point removal of amnion segmentations is presented. This outlier removal method is independent to algorithms used for the contour detection. The Bayesian process uses a non-stationary kernel to learn a function with complex shape that maps image features in a region-of-interest around each contour point to a discrete output. Based on this output, a contour point can be determined as valid or invalid (outlier). The hyper-parameters of the non-stationary kernel are learned by maximising the marginal likelihood of the combined likelihood of data and the prior of the kernel parameters. Moreover, a novel combination of gradient-ascend and harmonic heuristic search methods is presented to find the optimal hyper-parameters. To validate the method, experiments are conducted to detect and ignore invalid contour points on amnion biomaterial images. A comparison of the proposed method with a logistic regression classification as the baseline is performed. The results show that the proposed method can significantly improve the contour detection by removing outliers and, hence, can reduce waste of uncut biomaterials.},
  archive      = {J_PAAA},
  author       = {Syam, Wahyudin P. and Benardos, Panorios and Britchford, Emily and Hopkinson, Andrew and Branson , David T.},
  doi          = {10.1007/s10044-021-00979-9},
  journal      = {Pattern Analysis and Applications},
  month        = {11},
  number       = {4},
  pages        = {1805-1824},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Outlier removal in biomaterial image segmentations using a non-stationary bayesian learning},
  volume       = {24},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-resolution dictionary collaborative representation for
face recognition. <em>PAAA</em>, <em>24</em>(4), 1793–1803. (<a
href="https://doi.org/10.1007/s10044-021-00987-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a multi-resolution dictionary collaborative representation(MRDCR) method for face recognition is proposed. Unlike most of the traditional sparse learning methods, such as sparse representation-based classification(SRC) methods and dictionary learning(DL)-based methods, which concentrate only on a single resolution, we consider the fact that the resolutions of real-world face images are variable. We use multiple dictionaries each being related with a resolution to collaboratively represent the test image. Main advantages of this work are summarized as follows. First, we extend the traditional collaborative representation-based classification(CRC) method to the multi-resolution dictionary case, which obtains better recognition accuracy than traditional SRC/CRC methods. Second, comparing with conventional DL methods and recently proposed multi-resolution dictionary learning(MRDL) method, MRDCR still shows superior performance, even in the case of random baboon block occlusion. Third, on the small-scale face databases, our method has achieved better results than some deep learning methods. Last, MRDCR has a closed-form solution, which makes it more efficient than most of the traditional sparse learning methods. The experimental results on five benchmark face databases and a Virus database demonstrate that our proposed MRDCR method outperforms many state-of-the-art dictionary learning and sparse representation methods. The MATLAB code will be available at https://github.com/masterliuhzen/ .},
  archive      = {J_PAAA},
  author       = {Liu, Zhen and Wu, Xiao-Jun and Shu, Zhenqiu},
  doi          = {10.1007/s10044-021-00987-9},
  journal      = {Pattern Analysis and Applications},
  month        = {11},
  number       = {4},
  pages        = {1793-1803},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Multi-resolution dictionary collaborative representation for face recognition},
  volume       = {24},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Depth and edge auxiliary learning for still image crowd
density estimation. <em>PAAA</em>, <em>24</em>(4), 1777–1792. (<a
href="https://doi.org/10.1007/s10044-021-01017-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Crowd counting plays a significant role in crowd monitoring and management, which suffers from various challenges, especially in crowd-scale variations and background interference issues. Therefore, we propose a method named depth and edge auxiliary learning for still image crowd density estimation to cope with crowd-scale variations and background interference problems simultaneously. The proposed multi-task framework contains three sub-tasks including the crowd head edge regression, the crowd density map regression and the relative depth map regression. The crowd head edge regression task outputs distinctive crowd head edge features to distinguish crowd from complex background. The relative depth map regression task perceives crowd-scale variations and outputs multi-scale crowd features. Moreover, we design an efficient fusion strategy to fuse the above information and make the crowd density map regression generate high-quality crowd density maps. Various experiments were conducted on four main-stream datasets to verify the effectiveness and portability of our method. Experimental results indicate that our method can achieve competitive performance compared with other superior approaches. In addition, our proposed method improves the counting accuracy of the baseline network by $$15.6\%$$ .},
  archive      = {J_PAAA},
  author       = {Peng, Sifan and Yin, Baoqun and Hao, Xiaoliang and Yang, Qianqian and Kumar, Aakash and Wang, Luyang},
  doi          = {10.1007/s10044-021-01017-4},
  journal      = {Pattern Analysis and Applications},
  month        = {11},
  number       = {4},
  pages        = {1777-1792},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Depth and edge auxiliary learning for still image crowd density estimation},
  volume       = {24},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Video-based person re-identification by semi-supervised
adaptive stepwise learning. <em>PAAA</em>, <em>24</em>(4), 1769–1776.
(<a href="https://doi.org/10.1007/s10044-021-01016-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Person re-identification (ReID) is mainly aimed at establishing correct identity correspondence among moving person collected by multiple cameras. Extending labeled data sets with pseudo-labels is one of the common methods of ReID. However, single evaluation standards and fixed screening pseudo-label methods make pseudo-labels gradually weaken their update rate. Based on that, we propose a semi-supervised adaptive stepwise learning (SSAS) method for accelerating the update of pseudo-labels. Using the concept of Kullback–Leibler divergence, a more global pseudo-label update idea (GPLU) is proposed, an evaluation criterion of pseudo-labels is designed to satisfy two conditions: The first is to use simple tracklets as pseudo-label data in the early stage, and the second is to gradually add complex and diverse tracklets as pseudo-label data in the iterative process. Our proposed adaptive pseudo-label screening strategy steadily improves the recognition accuracy of ReID. In addition, we conduct extensive experiments on canonical data sets and the evaluation results suggest the superiority of our method.},
  archive      = {J_PAAA},
  author       = {Ma, Ding and Zhou, Yong and Zhao, Jiaqi and Chen, Ying and Yao, Rui and Chen, Hao},
  doi          = {10.1007/s10044-021-01016-5},
  journal      = {Pattern Analysis and Applications},
  month        = {11},
  number       = {4},
  pages        = {1769-1776},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Video-based person re-identification by semi-supervised adaptive stepwise learning},
  volume       = {24},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). ChoiceNet: CNN learning through choice of multiple feature
map representations. <em>PAAA</em>, <em>24</em>(4), 1757–1767. (<a
href="https://doi.org/10.1007/s10044-021-01004-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce a new architecture called ChoiceNet where each layer of the network is highly connected with skip connections and channelwise concatenations. This enables the network to alleviate the problem of vanishing gradients, reduces the number of parameters without sacrificing performance and encourages feature reuse. We evaluate our proposed architecture on three independent tasks: classification, segmentation and facial landmark localisation. For this, we use benchmark datasets such as ImageNet, CIFAR-10, CIFAR-100, SVHN CamVid and 300W.},
  archive      = {J_PAAA},
  author       = {Rayhan, Farshid and Galata, Aphrodite and Cootes, Tim F.},
  doi          = {10.1007/s10044-021-01004-9},
  journal      = {Pattern Analysis and Applications},
  month        = {11},
  number       = {4},
  pages        = {1757-1767},
  shortjournal = {Pattern Anal. Appl.},
  title        = {ChoiceNet: CNN learning through choice of multiple feature map representations},
  volume       = {24},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). TRFH: Towards real-time face detection and head pose
estimation. <em>PAAA</em>, <em>24</em>(4), 1745–1755. (<a
href="https://doi.org/10.1007/s10044-021-01026-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, face detection and head pose estimation have a lot of application such as face recognition, aiding in gaze estimation and modeling attention. For these two tasks, it is usually to design two different models. However, the head pose estimation model often depends on the region of interest (ROI) detected in advance, which means that a serial face detector is needed. Even the lightest face detector will slow down the whole forward inference time and cannot achieve real-time performance when detecting the head pose of multiple people. We can see that both face detection and head pose estimation need face features, so a shared face feature map can be used between them. In this paper, a multi-task learning model is proposed that can solve both problems simultaneously. We directly detect the location of the center point of the bounding box of face; at this location, we calculate the size of the bounding box of face and the head attitude. We evaluate our model’s performance on the AFLW. The proposed model has great competitiveness with the multi-stage face attribute analysis model, and our model can achieve real-time performance.},
  archive      = {J_PAAA},
  author       = {Chen, Shicun and Zhang, Yong and Yin, Baocai and Wang, Boyue},
  doi          = {10.1007/s10044-021-01026-3},
  journal      = {Pattern Analysis and Applications},
  month        = {11},
  number       = {4},
  pages        = {1745-1755},
  shortjournal = {Pattern Anal. Appl.},
  title        = {TRFH: Towards real-time face detection and head pose estimation},
  volume       = {24},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Batch and online variational learning of hierarchical
dirichlet process mixtures of multivariate beta distributions in medical
applications. <em>PAAA</em>, <em>24</em>(4), 1731–1744. (<a
href="https://doi.org/10.1007/s10044-021-01023-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Thanks to the significant developments in healthcare industries, various types of medical data are generated. Analysing such valuable resources aid healthcare experts to understand the illnesses more precisely and provide better clinical services. Machine learning as one of the capable tools could assist healthcare experts in achieving expressive interpretation and making proper decisions. As annotation of medical data is a costly and sensitive task that can be performed just by healthcare professionals, label-free methods could be significantly promising. Interpretability and evidence-based decision are other concerns in medicine. These needs were our motivators to propose a novel clustering method based on hierarchical Dirichlet process mixtures of multivariate Beta distributions. To learn it, we applied batch and online variational methods for finding the proper number of clusters as well as estimating model parameters at the same time. The effectiveness of the proposed models is evaluated on three medical real applications, namely oropharyngeal carcinoma diagnosis, osteosarcoma analysis, and white blood cell counting.},
  archive      = {J_PAAA},
  author       = {Manouchehri, Narges and Bouguila, Nizar and Fan, Wentao},
  doi          = {10.1007/s10044-021-01023-6},
  journal      = {Pattern Analysis and Applications},
  month        = {11},
  number       = {4},
  pages        = {1731-1744},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Batch and online variational learning of hierarchical dirichlet process mixtures of multivariate beta distributions in medical applications},
  volume       = {24},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Dimensionality reduction based on multi-local linear
regression and global subspace projection distance minimum.
<em>PAAA</em>, <em>24</em>(4), 1713–1730. (<a
href="https://doi.org/10.1007/s10044-021-01022-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dimensionality reduction is vital in many fields, such as computer vision and pattern recognition. This paper proposes an unsupervised dimensionality reduction algorithm based on multi-local linear regression. The algorithm first divides the high-dimensional data into many localities. Under the criterion of local homeomorphism, the continuous dependency relationship of the high-dimensional data is maintained in each locality in the low-dimensional space. At the same time, due to the overlap of locality divisions, that is, each data may belong to multiple localities. Therefore, the algorithm performs a multi-local linear prediction on each target data point, to better capture the internal geometric structure of the data. Finally, to coordinate the predictions of the target data points by each locality, we require that the variance between the predictions of each locality to the same target point should be as small as possible. We perform experiments on synthetic and real datasets. Compared with the existing advanced algorithms, the experimental results show that the proposed algorithm has good feasibility.},
  archive      = {J_PAAA},
  author       = {Huang, Haidong and Ma, Zhengming and Zhang, Guokai and Wu, Huibin},
  doi          = {10.1007/s10044-021-01022-7},
  journal      = {Pattern Analysis and Applications},
  month        = {11},
  number       = {4},
  pages        = {1713-1730},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Dimensionality reduction based on multi-local linear regression and global subspace projection distance minimum},
  volume       = {24},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Unrestricted deep metric learning using neural networks
interaction. <em>PAAA</em>, <em>24</em>(4), 1699–1711. (<a
href="https://doi.org/10.1007/s10044-021-01018-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In many machine learning applications and algorithms, the algorithm performance and accuracy are highly dependent on the metric used to measure the distance between different samples. Therefore, learning a distance metric specific to the data can improve these algorithms’ performance. This paper proposes an unrestricted deep metric learning framework based on neural networks’ interaction for learning metrics in latent space. The proposed method is inspired by generative neural nets (GANs), in which two neural nets are working together to learn true data distribution. In our method, one network plays the role of a supervisor for another network, a feature learning auto-encoder. Its task is to learn transformation to latent space in which data have more meaningful distance and separability. i.e., the supervisor gets the output of the auto-encoder and sends feedback to modify its weights. They interact with each other interleavingly. Several experiments were conducted on four datasets, such as MNIST, GISETTE, Winnipeg Cropland Classification (WCC), and swarm behavior, from different application domains, to evaluate the proposed method’s performance. The results show that we can force auto-encoder to learn label information to project data into a latent space with better separability by using our approach. In addition to better class discrimination, the proposed method is far faster than normal auto-encoders during feature learning and has much less training time in the classification phase.},
  archive      = {J_PAAA},
  author       = {Mehralian, Soheil and Teshnehlab, Mohammad and Nasersharif, Babak},
  doi          = {10.1007/s10044-021-01018-3},
  journal      = {Pattern Analysis and Applications},
  month        = {11},
  number       = {4},
  pages        = {1699-1711},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Unrestricted deep metric learning using neural networks interaction},
  volume       = {24},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Superpixel/voxel medical image segmentation algorithm based
on the regional interlinked value. <em>PAAA</em>, <em>24</em>(4),
1685–1698. (<a
href="https://doi.org/10.1007/s10044-021-01021-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Medical image segmentation can effectively overcome human perception with strong personal limitations. The superpixel/voxel segmentation method has strong adaptability and computational efficiency. It can effectively separate the diseased tissue from normal cells or bone and muscle, which is widely used. This paper proposes a superpixel/voxel medical image segmentation algorithm based on regional interlinked value and block (region) merging, which can segment the two-dimensional bone image and three-dimensional brain image. By computing the regional interlinked value, the proposed method can overcome the problem of the initial setting block size in the traditional superpixel/voxel segmentation method. Next, the blocks with the same features are merged. To segment the superpixel/voxel medical image, the final distance with the intensity feature, the location feature, and the gradient feature is considered. Compared with most state-of-the-art algorithms, the proposed method has strong robustness and efficiency, which provides a solid foundation for further image segmentation.},
  archive      = {J_PAAA},
  author       = {Fang, Lingling and Wang, Xin and Wang, Mengyi},
  doi          = {10.1007/s10044-021-01021-8},
  journal      = {Pattern Analysis and Applications},
  month        = {11},
  number       = {4},
  pages        = {1685-1698},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Superpixel/voxel medical image segmentation algorithm based on the regional interlinked value},
  volume       = {24},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). HSIC-based affinity measure for learning on graphs.
<em>PAAA</em>, <em>24</em>(4), 1667–1683. (<a
href="https://doi.org/10.1007/s10044-021-01014-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The performance of graph-based learning techniques largely relies on the edges defined between the vertices of the graph. These edges that represent the affinity between vertices must be learned from data. In this paper, we propose statistical dependence as a measure of affinity for learning the structure of graphs from data. It is assumed that the data lies on a high-dimensional Riemannian manifold, but the neighborhood is not known. Due to unknown characteristics of the underlying manifold, Euclidean distance (ED) does not capture the affinity between the data points accurately and cannot be used to construct the adjacency matrix. A scalable Hilbert–Schmidt independence criterion (HSIC)-based affinity technique is proposed to learn the nonlinear dependence between the data points. The pairwise affinities are captured by dividing the data into small chunks, which also makes the technique scalable. Once the pairwise affinity between data points is computed using HSIC-based dependence, $$\mu$$ nearest neighboring points are determined to construct the graph. The data points represented by the graph lie on a high-dimensional Riemannian manifold with every data point having $$\mu$$ neighbors. Dimensionality reduction is performed, followed by classification. Experiments on both synthetic and real-world dataset give accurate low-dimensional representation with preservation of maximum local linear structures. The random walk illustration of both ED and proposed HSIC-based affinity shows that the proposed affinity measure is able to identify and link similar data points. The increase in kNN, SVM and decision tree classifiers’ accuracies on low-dimensional data achieved using graph Laplacian on HSIC-based affinity matrix proves the efficiency of the proposed affinity metric for graph-based learning.},
  archive      = {J_PAAA},
  author       = {Yadav, Rakesh Kumar and Abhishek and Yadav, Vijay Kumar and Verma, Shekhar and Venkatesan, S.},
  doi          = {10.1007/s10044-021-01014-7},
  journal      = {Pattern Analysis and Applications},
  month        = {11},
  number       = {4},
  pages        = {1667-1683},
  shortjournal = {Pattern Anal. Appl.},
  title        = {HSIC-based affinity measure for learning on graphs},
  volume       = {24},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). On measuring and employing texture directionality for image
classification. <em>PAAA</em>, <em>24</em>(4), 1649–1665. (<a
href="https://doi.org/10.1007/s10044-021-01013-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Directionality is useful in many computer vision, pattern recognition, visualization, and multimedia applications since it is considered as an important pre-attentive attribute in human vision. To support using directionality (i.e., orientedness) for texture discrimination, a new measure that uses both local and global aspects of texture, with such use, to our knowledge, novel vis-à-vis prior state-of-the-art, to determine the directionality status for a texture is described and validated in this paper. This paper has four major elements. Element one is the measure we have developed that examines both local and global aspects of directionality to signal if a texture is directional or not. The local aspect is provided mostly from local pixel intensity differences, while a frequency domain analysis provides most of the global aspect. Element two is a comparison study of the measure (which exhibits the best outcomes) versus the known alternatives for determining texture directionality. Element three considers the measure relative to human experience. Element four considers applications of the measure to image classification. The second element (i.e., the study) is a comprehensive comparison study of existing texture directionality measures, based on the full set of Brodatz textures and human sentiment, which is the first such study.},
  archive      = {J_PAAA},
  author       = {Maskey, Manil and Newman, Timothy S.},
  doi          = {10.1007/s10044-021-01013-8},
  journal      = {Pattern Analysis and Applications},
  month        = {11},
  number       = {4},
  pages        = {1649-1665},
  shortjournal = {Pattern Anal. Appl.},
  title        = {On measuring and employing texture directionality for image classification},
  volume       = {24},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Vehicle object detection method based on candidate region
aggregation. <em>PAAA</em>, <em>24</em>(4), 1635–1647. (<a
href="https://doi.org/10.1007/s10044-021-01009-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-scale vehicle detection is an important application in the field of object detection, and Feature Pyramid Network (FPN) is an important means to deal with multi-scale object detection tasks. However, baseline method is the common method used in most of the existing network structure, which represents the input image information by selecting one from the output layer of FPN, and discard other layers. This not only limits the performance of the network structure, but also performs poorly when dealing with the problem of excessive scale differences. To solve this problem, a novelty candidate region aggregation network (CRAN) is proposed in this paper. The candidate regions of different feature layers are effectively aggregated to improve the network generalization performance. Specifically, calculate the similarity between different feature layers through a feature quality score module, and use this as a quantity factor to determine the number of candidate regions reserved for the corresponding feature layer. Finally, they are aggregated into a more comprehensive candidate region group. Further, in order to improve the detection efficiency of small objects, an area cross entropy loss function is proposed. It makes the model pay more attention to small targets by adding a monotonic decrease based on the area. Finally, the proposed CRAN and the area cross entropy loss function are applied to the advanced detectors. The experimental results in the KITTI and UA-DETRAC datasets show that this method has good performance on vehicle objects in different scenarios, and can meet the requirements of practical application.},
  archive      = {J_PAAA},
  author       = {Zhang, Luyang and Wang, Haitao and Wang, Xinyao and Liu, Qiang and Wang, Huaibin and Wang, Hailong},
  doi          = {10.1007/s10044-021-01009-4},
  journal      = {Pattern Analysis and Applications},
  month        = {11},
  number       = {4},
  pages        = {1635-1647},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Vehicle object detection method based on candidate region aggregation},
  volume       = {24},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Iterative feature refinement with network-driven prior for
image restoration. <em>PAAA</em>, <em>24</em>(4), 1623–1634. (<a
href="https://doi.org/10.1007/s10044-021-01006-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image restoration (IR) has been extensively studied with lots of excellent strategies accumulated over the years. However, most existing methods still have large room for improvement. In this paper, we boost an unsupervised iterative feature refinement model (IFR) with the enhanced high-dimensional deep mean-shift prior (EDMSP), termed IFR-EDMSP. The proposed model inherits the fantastic noise suppression characteristic of embedded network and the fine detail preservation ability of IFR model. Moreover, based on the fact that multiple implementations of artificial noise in prior learning improve underlying representation capability, three-sigma rule is adopted in IFR-EDMSP for accurate and robust results. Extensive experiments demonstrated that IFR-EDMSP outperforms the typical methods in compressed sensing, image deblurring and super-resolution.},
  archive      = {J_PAAA},
  author       = {Zhou, Jinjie and Meng, Miaomiao and Xing, Jinglong and Xiong, Yuchen and Xu, Xiaoling and Zhang, Yinghong},
  doi          = {10.1007/s10044-021-01006-7},
  journal      = {Pattern Analysis and Applications},
  month        = {11},
  number       = {4},
  pages        = {1623-1634},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Iterative feature refinement with network-driven prior for image restoration},
  volume       = {24},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Clustering and classification with inertia weight and
elitism-based particle swarm optimization. <em>PAAA</em>,
<em>24</em>(4), 1605–1621. (<a
href="https://doi.org/10.1007/s10044-021-01010-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Clustering and classification-based pattern recognition techniques are widely used in various domains. While many approaches exist to perform these tasks, it remains a difficult process to perform clustering and classification simultaneously for particular datasets. In this paper, a method based on k-nearest neighbor (KNN) is presented to classify the dataset with PSO optimized k-medoids clustering. Initial clustering with k-medoids algorithm divides the dataset into smaller and disjoint clusters featuring similarity within clusters and dissimilarity with members of other clusters. Particle swarm optimization (PSO) is an evolutionary algorithm mainly used to optimize the issues in several research areas including data analytics. The fitness function of the PSO approach mentioned in this paper is based on inertia weights that identify the particles with the best positions and velocities for optimization. Additionally, PSO uses a novel elitism concept that allows massive searching capability between the swarm of particles to achieve a better convergence rate. Because of this property, it can be applied throughout different machine learning fields. Moreover, the KNN classifier outperforms the classification task in terms of classifying the optimized particles with high accuracy. The performance of the proposed technique is evaluated by experimenting with datasets taken from open sources. The simulation results revealed that the performance of the proposed method is better than the existing methods in terms of effective clustering as well as accurate classification.},
  archive      = {J_PAAA},
  author       = {Murugan, T. Mathi and Baburaj, E.},
  doi          = {10.1007/s10044-021-01010-x},
  journal      = {Pattern Analysis and Applications},
  month        = {11},
  number       = {4},
  pages        = {1605-1621},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Clustering and classification with inertia weight and elitism-based particle swarm optimization},
  volume       = {24},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multiple circle detection in images: A simple evolutionary
algorithm approach and a new benchmark of images. <em>PAAA</em>,
<em>24</em>(4), 1583–1603. (<a
href="https://doi.org/10.1007/s10044-021-01007-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The circle detection problem focuses on finding all circle shapes within a given image. In fact, circle detection has several applications in real-life problems arising in agriculture, ophthalmology, and oceanography, among others. Despite many approaches having been proposed to deal with this problem, our work is motivated by two main issues: (1) the limitation of a recently proposed evolutionary algorithm and (2) the lack of benchmark images to fairly compare current approaches. To address the first issue, we introduce an effective evolutionary algorithm with a pre-processing noise reduction step. The proposed evolutionary algorithm’s goal is to match several randomly generated circles with a point cloud extracted from an edge map of the original image. These circles are individuals in the population where the fittest one in the last generation is a detected circle. Henceforth, by removing the points corresponding to such circle and repeating the process, all circles within the image can be detected. We propose and make publicly available a set of synthetic, hand-drawn, and real images with different features to address the second issue. To assess our approach’s performance, we apply it to the set of proposed images that include challenging features. Experimental results show that our method is competitive compared with the well-known Circle Hough Transform and as well as with EDCircles.},
  archive      = {J_PAAA},
  author       = {González, Miguel R. and Martínez, Miguel E. and Cosío-León, María and Cervantes, Humberto and Brizuela, Carlos A.},
  doi          = {10.1007/s10044-021-01007-6},
  journal      = {Pattern Analysis and Applications},
  month        = {11},
  number       = {4},
  pages        = {1583-1603},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Multiple circle detection in images: A simple evolutionary algorithm approach and a new benchmark of images},
  volume       = {24},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Enhancing performance and user convenience of
multi-biometric verification systems. <em>PAAA</em>, <em>24</em>(4),
1569–1582. (<a
href="https://doi.org/10.1007/s10044-021-01008-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A multi-biometric verification system lowers the verification errors by fusing information from multiple biometric sources. Information can be fused in parallel or serial modes. While parallel fusion gives a higher accuracy, it may suffer from a serious problem of taking a longer verification time. Serial fusion can alleviate this problem by allowing the users to submit a subset of the available biometric characteristics. Unfortunately, several studies show that serial fusion may not reach the level of accuracy of parallel fusion. In this paper, we propose a fusion framework which combines the advantages of both parallel and serial fusion. The core of the framework is a new concept of “confident reject region” which incurs nearly zero verification error. We evaluate our framework by performing experiments on two multi-biometric verification systems built with NIST biometric scores set release 1. The experimental results show that our framework achieves a lower equal error rate and takes a shorter verification time than standard parallel fusion.},
  archive      = {J_PAAA},
  author       = {Hossain, Md S. and Phoha, Vir V.},
  doi          = {10.1007/s10044-021-01008-5},
  journal      = {Pattern Analysis and Applications},
  month        = {11},
  number       = {4},
  pages        = {1569-1582},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Enhancing performance and user convenience of multi-biometric verification systems},
  volume       = {24},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). DroneRTEF: Development of a novel adaptive framework for
railroad track extraction in drone images. <em>PAAA</em>,
<em>24</em>(4), 1549–1568. (<a
href="https://doi.org/10.1007/s10044-021-00994-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Railroad track health monitoring is a challenging yet important task as it affects the safety of railroad systems. Railroad track extraction presents an immediate advantage during railroad inspections in an efficient and cost-effective manner. At present, human inspectors, inspection trains, and rail-mounted vehicles equipped with cameras are prevalent image acquisition systems(IAS) in the track extraction module. However, these IAS face various challenges such as high operability cost, railroad closed for normal traffic, and inaccessibility to certain geographical locations. In such scenarios, drones act as effective IAS. Therefore, this paper presents a novel and adaptive railroad track extraction framework for drone images (DI) captured under uneven illumination, at different drone flight heights, with varying rail line orientations, and in complex railroad environments. We termed this framework as DroneRTEF. This work primarily focuses on two aspects of drone-based railroad track images: image enhancement and image analysis. With regard to the first aspect, a global image enhancement algorithm named adaptive colour space-based masking (ACSM) is developed to enhance railroad track images and identify rail lines. The rail lines and background can be highlighted and homogenized, respectively, in DI captured under various sunlight intensity using ACSM due to its illuminance independence. With regard to the second aspect, the Hough parameter space analysis-based novel Hough transform-ground sample distance(HT-GSD) method is presented in this paper. The proposed HT-GSD method emphasizes on rail line detections at varying line orientations and different flight heights. The track extraction is then performed by a coordinate transformation technique. The approach has been successfully tested and validated on various DI. The efficacy of our framework for rail line detection is identified by comparing it with other line detection model. Performances of these methods are tested using metrics such as precision, recall and accuracies of the detections. Results obtained show that our method is superior to another model. Therefore, DroneRTEF is an efficient and feasible method for railroad track extraction in DI.},
  archive      = {J_PAAA},
  author       = {Saini, Aradhya and Singh, Dharmendra},
  doi          = {10.1007/s10044-021-00994-w},
  journal      = {Pattern Analysis and Applications},
  month        = {11},
  number       = {4},
  pages        = {1549-1568},
  shortjournal = {Pattern Anal. Appl.},
  title        = {DroneRTEF: Development of a novel adaptive framework for railroad track extraction in drone images},
  volume       = {24},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Chinese font migration combining local and global features
learning. <em>PAAA</em>, <em>24</em>(4), 1533–1547. (<a
href="https://doi.org/10.1007/s10044-021-01003-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {At present, deep learning has made great progress in the field of glyph modeling. However, existing methods of font generation have some problems, such as missing stroke, structural deformation, artifact and blur. To solve these problems, this paper proposes Chinese font style migration combining local and global feature learning (FTFNet). The model uses skipping connection and dense connection mechanism to enhance the information transfer between the network layers. At the same time, feature attention layer is introduced to capture the dependency relationship between local and global features. So as to achieve the purpose of strengthening local feature learning and global feature fusion. Experiments show that the method in this paper has better performance in the details of font generation, which simplifies the font generation process and improves the quality of generated fonts.},
  archive      = {J_PAAA},
  author       = {Miao, Yalin and Jia, Huanhuan and Tang, Kaixu},
  doi          = {10.1007/s10044-021-01003-w},
  journal      = {Pattern Analysis and Applications},
  month        = {11},
  number       = {4},
  pages        = {1533-1547},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Chinese font migration combining local and global features learning},
  volume       = {24},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Domain adaption based on source dictionary regularized RKHS
subspace learning. <em>PAAA</em>, <em>24</em>(4), 1513–1532. (<a
href="https://doi.org/10.1007/s10044-021-01002-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Domain adaption is to transform the source and target domain data into a certain space through a certain transformation, so that the probability distribution of the transformed data is as close as possible. The domain adaption algorithm based on Maximum Mean Difference (MMD) Maximization and Reproducing Kernel Hilbert Space (RKHS) subspace transformation is the current main algorithm for domain adaption, in which the RKHS subspace transformation is determined by MMD of the transformed source and target domain data. However, MMD has inherent defects in theory. The probability distributions of two different random variables will not change after subtracting their respective mean values, but their MMD becomes zero. A reasonable method should be that the MMD of the source and target domain data with the same label should be as small as possible after RKHS subspace transformation. However, the labels of target domain data are unknown and there is no way to model according to this criterion. In this paper, a domain adaption algorithm based on source dictionary regularized RKHS subspace learning is proposed, in which the source domain data are used as a dictionary, and the target domain data are approximated by the sparse coding of the dictionary. That is to say, in the process of RKHS subspace transformation, the target domain data are distributed around the mostly relevant source domain data. In this way, the proposed algorithm indirectly achieves the MMD of the source and target domain data with the same label after RKHS subspace transformation. So far there has been no similar work reported in the published academic papers. The experimental results presented in this paper show that the proposed algorithm outperforms 5 other state-of-the-art domain adaption algorithms on 5 commonly used datasets.},
  archive      = {J_PAAA},
  author       = {Lei, Wenjie and Ma, Zhengming and Lin, Yuanping and Gao, Wenxu},
  doi          = {10.1007/s10044-021-01002-x},
  journal      = {Pattern Analysis and Applications},
  month        = {11},
  number       = {4},
  pages        = {1513-1532},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Domain adaption based on source dictionary regularized RKHS subspace learning},
  volume       = {24},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Hybrid domain adaptation for sensor-based human activity
recognition in a heterogeneous setup with feature commonalities.
<em>PAAA</em>, <em>24</em>(4), 1501–1511. (<a
href="https://doi.org/10.1007/s10044-021-00995-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Common approaches in the cross-domain sensor-based human activity recognition are based on the homogeneous domain adaptation which relies on the assumption that the training and testing data are of homogeneous feature space. In reality, such an assumption does not always hold. For example, although two devices may share common sensors, it is possible that each of them has its own specific sensors. In this case, the homogeneous domain adaptation approaches cannot be used directly. Although heterogeneous domain adaptation approaches have been proposed to handle such feature space heterogeneity, most of them require some label information in the target domain, which is often difficult to obtain. As a compromise, the hybrid domain adaptation has been recently proposed to address feature space heterogeneity. Instead of using the target domain label information, it exploits the common features between domains as additional information, so the adaptation can be performed in an unsupervised manner. However, it still neglects the possibility of the common features between domains having different distribution, which may lead to the negative transfer of the domain-specific features. In this work, we introduce a domain-invariant latent representation of the common features to enhance the specific feature transfer in the hybrid domain adaptation approach. The latent representation learning and the domain-specific feature transfer are performed jointly using an autoencoder-based framework. The experimental result shows that the performance improves when the common features are furthermore aligned in the latent space. It is also shown that, in overall, our model outperforms existing approaches, yielding up to 9.48% accuracy improvement.},
  archive      = {J_PAAA},
  author       = {Prabono, Aria Ghora and Yahya, Bernardo Nugroho and Lee, Seok-Lyong},
  doi          = {10.1007/s10044-021-00995-9},
  journal      = {Pattern Analysis and Applications},
  month        = {11},
  number       = {4},
  pages        = {1501-1511},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Hybrid domain adaptation for sensor-based human activity recognition in a heterogeneous setup with feature commonalities},
  volume       = {24},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Assessing task understanding in remote ultrasound diagnosis
via gesture analysis. <em>PAAA</em>, <em>24</em>(4), 1489–1500. (<a
href="https://doi.org/10.1007/s10044-021-01027-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work presents a gesture-based approach to estimate task understanding and performance during remote ultrasound tasks. Our approach is comprised of two main components. The first component uses the Multi-Agent Gestural Instruction Comparer (MAGIC) framework to represent and compare the gestures performed by collaborators. Through MAGIC, gestures can be compared based in their morphology, semantics, and pragmatics. The second component computes the Physical Instructions Assimilation (PIA) metric, a score representing how well are gestures being used to communicate and execute physical instructions. To evaluate our hypothesis, 20 participants performed a remote ultrasound task consisting of three subtasks: vessel detection, blood extraction, and foreign body detection. MAGIC’s gesture comparison approaches were compared against two other approaches based on how well they replicated human-annotated gestures matchings. Our approach outperformed the others, agreeing with the human baseline over 76% of the times. Subsequently, a correlation analysis was performed to compare PIA’s task understanding insights with those of three other metrics: error rate, idle time rate, and task completion percentage. Significant correlations ( $$p\,\le \,0.04$$ ) were found between PIA and all the other metrics, positioning PIA as an effective metric for task understanding estimation. Finally, post-experiment questionnaires were used to subjectively evaluate the participants’ perceived understanding. The PIA score was found to be significantly correlated with the participants’ overall task understanding ( $$p\le 0.05$$ ), hinting to the relation between the assimilation of physical instructions and self-perceived understanding. These results demonstrate that gestures an be used to estimate task understanding in remote ultrasound tasks, which can improve how these tasks are performed and assessed.},
  archive      = {J_PAAA},
  author       = {Rojas-Muñoz, Edgar and Wachs, Juan P.},
  doi          = {10.1007/s10044-021-01027-2},
  journal      = {Pattern Analysis and Applications},
  month        = {11},
  number       = {4},
  pages        = {1489-1500},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Assessing task understanding in remote ultrasound diagnosis via gesture analysis},
  volume       = {24},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Testing the randomness of shares in color visual
cryptography. <em>PAAA</em>, <em>24</em>(4), 1475–1487. (<a
href="https://doi.org/10.1007/s10044-021-00999-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The concept of black-and-white visual cryptography with two truly random shares, previously applied to color images, was improved by mixing the contents of the segments of each coding image and by randomly changing a specified number of black pixels into color ones. This was done in such a way that the changes of the contents of the decoded image were as small as possible. These modifications made the numbers of color pixels in the shares close to balanced, which potentially made it possible for the shares to be truly random. The true randomness was understood as that the data pass the suitably designed randomness tests. The randomness of the shares was tested with the NIST randomness tests. Part of the tests passed successfully, while some failed. The target of coding a color image in truly random shares was approached, but not yet reached. In visual cryptography, the decoding with the unarmed human eye is of primary importance, but besides this, simple numerical processing of the decoded image makes it possible to greatly improve the quality of the reconstructed image, so that it becomes close to that of the dithered original image.},
  archive      = {J_PAAA},
  author       = {Chmielewski, Leszek J. and Nieniewski, Mariusz and Orłowski, Arkadiusz},
  doi          = {10.1007/s10044-021-00999-5},
  journal      = {Pattern Analysis and Applications},
  month        = {11},
  number       = {4},
  pages        = {1475-1487},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Testing the randomness of shares in color visual cryptography},
  volume       = {24},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Savitzky–golay filter energy features-based approach to face
recognition using symbolic modeling. <em>PAAA</em>, <em>24</em>(4),
1451–1473. (<a
href="https://doi.org/10.1007/s10044-021-00991-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Face recognition is a well-researched domain however many issues for instance expression changes, illumination variations, and presence of occlusion in the face images seriously affect the performance of such systems. A recent survey shows that COVID-19 will also have a considerable and long-term impact on biometric face recognition systems. The work has presented two novel Savitzky–Golay differentiator (SGD) and gradient-based Savitzky–Golay differentiator (GSGD) feature extraction techniques to elevate issues related to face recognition systems. The SGD and GSGD feature descriptors are able to extract discriminative information present in different parts of the face image. In this paper, an efficient and robust person identification using symbolic data modeling approach and similarity analysis measure is devised and employed for feature representation and classification tasks to address the aforementioned issues of face recognition. Extensive experiments and comparisons of the proposed descriptors experimental results indicated that the proposed approaches can achieve optimal performance of 96–97, 92–96, 100, 84–93, and 87–96% on LFW, ORL, AR, IJB-A datasets, and newly devised VISA database, respectively.},
  archive      = {J_PAAA},
  author       = {Kagawade, Vishwanath C. and Angadi, Shanmukhappa A.},
  doi          = {10.1007/s10044-021-00991-z},
  journal      = {Pattern Analysis and Applications},
  month        = {11},
  number       = {4},
  pages        = {1451-1473},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Savitzky–Golay filter energy features-based approach to face recognition using symbolic modeling},
  volume       = {24},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A new method of hybrid time window embedding with
transformer-based traffic data classification in IoT-networked
environment. <em>PAAA</em>, <em>24</em>(4), 1441–1449. (<a
href="https://doi.org/10.1007/s10044-021-00980-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Internet of Things (IoT) appliances often expose sensitive data, either directly or indirectly. They may, for instance, tell whether you are at home right now or what your long or short-term habits are. Therefore, it is crucial to protect such devices against adversaries and has in place an early warning system which indicates compromised devices in a quick and efficient manner. In this paper, we propose time window embedding solutions that efficiently process a massive amount of data and have a low-memory-footprint at the same time. On top of the proposed embedding vectors, we use the core anomaly detection unit. It is a classifier that is based on the transformer’s encoder component followed by a feed-forward neural network. We have compared the proposed method with other classical machine-learning algorithms. Therefore, in the paper, we formally evaluate various machine-learning schemes and discuss their effectiveness in the IoT-related context. Our proposal is supported by detailed experiments that have been conducted on the recently published Aposemat IoT-23 dataset.},
  archive      = {J_PAAA},
  author       = {Kozik, Rafał and Pawlicki, Marek and Choraś, Michał},
  doi          = {10.1007/s10044-021-00980-2},
  journal      = {Pattern Analysis and Applications},
  month        = {11},
  number       = {4},
  pages        = {1441-1449},
  shortjournal = {Pattern Anal. Appl.},
  title        = {A new method of hybrid time window embedding with transformer-based traffic data classification in IoT-networked environment},
  volume       = {24},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A real-time two-stage and dual-check template matching
algorithm based on normalized cross-correlation for industrial vision
positioning. <em>PAAA</em>, <em>24</em>(3), 1427–1439. (<a
href="https://doi.org/10.1007/s10044-021-00997-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a fast template matching algorithm of two-stage and dual-check bounded partial correlation (TDBPC) based on normalized cross-correlation (NCC) of single-check bounded partial correlation is proposed. According to the principle of continuous rows, the template and the sub-image under matching are divided into three subregions to obtain two upper boundary terms of NCC and get two checking conditions then. In this way, it is possible to quickly eliminate matching points that cannot provide a better cross-correlation score regarding the current best candidate. Generally, to get the highest cross-correlation score, the sub-image has to traverse through the whole image. In addition, the two-stage search strategy of coarse–fine proposed in this paper can further reduce the calculation and improve matching efficiency. The initialization parameters are selected experimentally or automatically. Experimental results show that the TDBPC algorithm proposed in this paper can solve high computational complexity and long matching time of NCC template matching and make it possible to achieve real-time template matching in industrial vision positioning fields. The feasibility of this algorithm in practical application is proved.},
  archive      = {J_PAAA},
  author       = {Chen, Fengjun and Liao, Jinqi and Lu, Zejin and Lv, Jiyang},
  doi          = {10.1007/s10044-021-00997-7},
  journal      = {Pattern Analysis and Applications},
  month        = {8},
  number       = {3},
  pages        = {1427-1439},
  shortjournal = {Pattern Anal. Appl.},
  title        = {A real-time two-stage and dual-check template matching algorithm based on normalized cross-correlation for industrial vision positioning},
  volume       = {24},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Analysing the patterns of spatial contrast discontinuities
in natural images for robust edge detection. <em>PAAA</em>,
<em>24</em>(3), 1403–1425. (<a
href="https://doi.org/10.1007/s10044-021-00976-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The pattern of spatial contrast discontinuities in natural images has been analysed in the present work, and based on it, a new adaptive model of the bio-inspired Difference of Gaussian (DOG)-based edge detector has been designed. The distinguishing feature of the proposed filter is that the magnitude of surround suppression in receptive field of the DOG is adaptively adjusted depending on the nature of discontinuity of the edge profile. The model is based on the biological evidences indicating the possibility that human brain may be endowed with the ability to perform Fourier decomposition of visual images into its various components of spatial frequencies. It may be shown that information obtained from such a Fourier decomposition may help to measure the strength of contrast (sharpness of discontinuity) in the intensity profile across any possible edge in the natural image. In the present model, it is assumed that the magnitude of surround suppression in an excitatory–inhibitory receptive field is dependent on the sharpness of discontinuity. The suppression is strong when the edge contrast is poor, while it becomes weaker as the edge contrast is high. At a biphasic edge, the surround suppression is vanishingly small. Natural images collected from benchmark databases are used to evaluate the efficiency and robustness of the proposed model for the detection of edges. The result shows that the edge maps generated through the proposed model are at par, if not more effective as compared to the classical edge detectors like Canny. The performance of the proposed model is also compared with a number of recently proposed alternative adaptive models for edge detection.},
  archive      = {J_PAAA},
  author       = {Mazumdar, Debasis and Mitra, Soma and Ghosh, Kuntal and Bhaumik, Kamales},
  doi          = {10.1007/s10044-021-00976-y},
  journal      = {Pattern Analysis and Applications},
  month        = {8},
  number       = {3},
  pages        = {1403-1425},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Analysing the patterns of spatial contrast discontinuities in natural images for robust edge detection},
  volume       = {24},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A hybrid reciprocal model of PCA and k-means with an
innovative approach of considering sub-datasets for the improvement of
k-means initialization and step-by-step labeling to create clusters with
high interpretability. <em>PAAA</em>, <em>24</em>(3), 1387–1402. (<a
href="https://doi.org/10.1007/s10044-021-00977-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The K-means algorithm is a popular clustering method, which is sensitive to the initialization of samples and selecting the number of clusters. Its performance on high-dimensional datasets is considerably influenced. Principal component analysis (PCA) is a linear dimensionless reduction method that is closely related to the K-means algorithm. Dimension reduction leads to the selection of initial centers in a smaller space, which is a solution to solve initialization problems. The present study investigates the reciprocal relationship between K-means and PCA and adopts an innovative approach of creating sub-datasets and applying step-by-step labeling in the hybrid execution of both algorithms to propose two methods, namely K-P and P-K. The clusters that are obtained from the two proposed methods are of high interpretability. This was verified by the step-by-step labeling results of a human resource dataset. Interpretability was evaluated via the distribution of features of interest (FoI), suggesting improved results for both datasets. In addition to the improvement of the qualitative results, the outcome of the present study showed the sum of squared estimate of errors (SSE)/N (total number of data) and silhouette improvement of 10 datasets with eight initialization methods in previous studies. The P-K results and run time were better than the K-P ones.},
  archive      = {J_PAAA},
  author       = {Mousavian Anaraki, Seyed Alireza and Haeri, Abdorrahman and Moslehi, Fateme},
  doi          = {10.1007/s10044-021-00977-x},
  journal      = {Pattern Analysis and Applications},
  month        = {8},
  number       = {3},
  pages        = {1387-1402},
  shortjournal = {Pattern Anal. Appl.},
  title        = {A hybrid reciprocal model of PCA and K-means with an innovative approach of considering sub-datasets for the improvement of K-means initialization and step-by-step labeling to create clusters with high interpretability},
  volume       = {24},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A study on intelligent diagnosis model of shortwave
receiving system based on improved KFCM and LapSVM. <em>PAAA</em>,
<em>24</em>(3), 1377–1386. (<a
href="https://doi.org/10.1007/s10044-021-00957-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aiming at the difficulty of obtaining a large number of labeled samples of the shortwave receiving system, an intelligent diagnosis method for the shortwave receiving system based on the improved Laplacian SVM algorithm is proposed. By introducing the idea of neighborhood density into the adjacency graph construction of Laplacian SVM, the manifold structure information of samples is more fully mined, thus improving the performance of Laplacian SVM classifier and realizing the optimization of traditional Laplacian SVM. KFCM clustering algorithm was used to select unlabeled boundary samples and labeled samples to form the reduction training set. The method of the KFCM pre-selection sample was combined with the improved Laplacian SVM algorithm to enhance the learning efficiency. The simulation results using the UCI data set and the experimental verification results of shortwave receiving system sample data indicate that the proposed algorithm could more fully mine the manifold structure information of samples and improve the performance of the Laplacian SVM classifier.},
  archive      = {J_PAAA},
  author       = {Luo, Yong and Xiang, Yixue and Zhong, Shouyang},
  doi          = {10.1007/s10044-021-00957-1},
  journal      = {Pattern Analysis and Applications},
  month        = {8},
  number       = {3},
  pages        = {1377-1386},
  shortjournal = {Pattern Anal. Appl.},
  title        = {A study on intelligent diagnosis model of shortwave receiving system based on improved KFCM and LapSVM},
  volume       = {24},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Ridgelet moment invariants for robust pattern recognition.
<em>PAAA</em>, <em>24</em>(3), 1367–1376. (<a
href="https://doi.org/10.1007/s10044-021-00996-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Moment invariants are an especially important research topic in pattern recognition. There are many kinds of moment invariants published in the literature already. However, there is a need to further improve them, especially under the noisy environments. In this article, we develop a new set of moment invariants by means of ridgelet function. The ridgelet function is capable of capturing line features in an image, which is a particularly important property in pattern recognition. It is well-known that every curve can be approximated by short line segments, so ridgelet moment invariants should be good at robust pattern recognition. We can prove that this set of moments is invariant to the rotation of 2D images. Experiments show that our proposed ridgelet moment invariants are better than the Gaussian–Hermite moments, the Fourier–wavelet descriptor, and Zernike’s moment invariants for one Chinese character database and one 2D shape database. Furthermore, our proposed ridgelet moment invariants can do an excellent job for noise-robust pattern recognition.},
  archive      = {J_PAAA},
  author       = {Chen, Guang Yi and Li, Changjun},
  doi          = {10.1007/s10044-021-00996-8},
  journal      = {Pattern Analysis and Applications},
  month        = {8},
  number       = {3},
  pages        = {1367-1376},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Ridgelet moment invariants for robust pattern recognition},
  volume       = {24},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An approach to improve SSD through mask prediction of
multi-scale feature maps. <em>PAAA</em>, <em>24</em>(3), 1357–1366. (<a
href="https://doi.org/10.1007/s10044-021-00993-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a novel single shot object detection network with a mask prediction branch. Our motivation is to enhance object detection features with semantic information extracted from deeper layers. The proposed mask prediction branch enriches important features in shallower layers with pixel-wise probability distribution of semantic information. Meanwhile, an improved receptive field block is adopted to increase the scale of receptive field of backbone network without too much extra computing burden. Our network improves the performance significantly over SSD and FSSD (Feature Fusion Single Shot Multi-box Detector) with just a little speed drop. In addition, we discuss the relationship between effective receptive fields and theoretical receptive fields on VGG16 backbone network. Comprehensive experimental results on PASCAL VOC 2007 demonstrate the effectiveness of the proposed method. We achieve a mAP of 79.8 with 300 × 300 input images (81.2 mAP by 512 × 512 inputs) at the speed of 58.4 FPS on a single Nvidia 1080Ti GPU. Experimental results demonstrate that the proposed network achieves a comparable performance with the state-of-the-arts.},
  archive      = {J_PAAA},
  author       = {Sun, Peng and Zhao, Yaqin and Zhu, Songhao},
  doi          = {10.1007/s10044-021-00993-x},
  journal      = {Pattern Analysis and Applications},
  month        = {8},
  number       = {3},
  pages        = {1357-1366},
  shortjournal = {Pattern Anal. Appl.},
  title        = {An approach to improve SSD through mask prediction of multi-scale feature maps},
  volume       = {24},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An improved small object detection method based on yolo v3.
<em>PAAA</em>, <em>24</em>(3), 1347–1355. (<a
href="https://doi.org/10.1007/s10044-021-00989-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, an improved algorithm based on Yolo V3 is proposed, which can effectively improve the accuracy of small target detection. First of all, the feature map acquisition network is improved. The image double-segmentation and bilinear upsampling network are used to replace the 2-step downsampling convolution network in the original network architecture, and the feature values of large and small objects are amplified. Secondly, a size recognition module is added to the input image to reduce the loss of morpheme features caused by no-feature value filling and enhance the recognition ability of small objects. Thirdly, in order to avoid the gradient fading of the network, the residual network element of the output network layer is added to enhance the feature channel of small object detection. Compared with Yolo V3, our algorithm improves the detection accuracy of small objects from 82.4 to 88.5%, the recall rate from 84.6 to 91.3%, and the average accuracy from 95.5 to 97.3%, respectively.},
  archive      = {J_PAAA},
  author       = {Xianbao, Cheng and Guihua, Qiu and Yu, Jiang and Zhaomin, Zhu},
  doi          = {10.1007/s10044-021-00989-7},
  journal      = {Pattern Analysis and Applications},
  month        = {8},
  number       = {3},
  pages        = {1347-1355},
  shortjournal = {Pattern Anal. Appl.},
  title        = {An improved small object detection method based on yolo v3},
  volume       = {24},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Advanced skeleton-based action recognition via
spatial–temporal rotation descriptors. <em>PAAA</em>, <em>24</em>(3),
1335–1346. (<a
href="https://doi.org/10.1007/s10044-020-00952-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As human action is a spatial–temporal process, modern action recognition research has focused on exploring more effective motion representations, rather than only taking human poses as input. To better model a motion pattern, in this paper, we exploit the rotation information to depict the spatial–temporal variation, thus enhancing the dynamic appearance, as well as forming a complementary component with the static coordinates of the joints. Specifically, we design to represent the movement of human body with joint units, consisting of performing regrouping human joints together with the adjacent two bones. Therefore, the rotation descriptors reduce the impact from the static values while focus on the dynamic movement. The proposed general features can be simply applied to existing CNN-based action recognition methods. The experimental results performed on NTU-RGB+D and ICL First Person Handpose datasets demonstrate the advantages of the proposed method.},
  archive      = {J_PAAA},
  author       = {Shen, Zhongwei and Wu, Xiao-Jun and Kittler, Josef},
  doi          = {10.1007/s10044-020-00952-y},
  journal      = {Pattern Analysis and Applications},
  month        = {8},
  number       = {3},
  pages        = {1335-1346},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Advanced skeleton-based action recognition via spatial–temporal rotation descriptors},
  volume       = {24},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Learning occlusion-aware view synthesis for light fields.
<em>PAAA</em>, <em>24</em>(3), 1319–1334. (<a
href="https://doi.org/10.1007/s10044-021-00956-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a novel learning-based approach to synthesize new views of a light field image. In particular, given the four corner views of a light field, the presented method estimates any in-between view. We use three sequential convolutional neural networks for feature extraction, scene geometry estimation and view selection. Compared to state-of-the-art approaches, in order to handle occlusions we propose to estimate a different disparity map per view. Jointly with the view selection network, this strategy shows to be the most important to have proper reconstructions near object boundaries. Ablation studies and comparison against the state of the art on Lytro light fields show the superior performance of the proposed method. Furthermore, the method is adapted and tested on light fields with wide baselines acquired with a camera array and, in spite of having to deal with large occluded areas, the proposed approach yields very promising results.},
  archive      = {J_PAAA},
  author       = {Navarro, J. and Sabater, N.},
  doi          = {10.1007/s10044-021-00956-2},
  journal      = {Pattern Analysis and Applications},
  month        = {8},
  number       = {3},
  pages        = {1319-1334},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Learning occlusion-aware view synthesis for light fields},
  volume       = {24},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Chaotic sequence and opposition learning guided approach for
data clustering. <em>PAAA</em>, <em>24</em>(3), 1303–1317. (<a
href="https://doi.org/10.1007/s10044-021-00964-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data clustering is a prevalent problem that belongs to the data mining domain. It aims to partition the given data objects into some specified number of clusters based on the sum of the intra-cluster distances. It is an NP-hard problem, and many heuristic approaches have already been proposed to target the desired objective. However, during the search process, the problem of local entrapment is prevalent due to nonlinear objective functions and a large range of search domains. In this paper, an opposition learning and chaotic sequence guided approaches are incorporated in a fast converging evolutionary algorithm called improved environmental adaptation method with real parameter (IEAM-R) for solving the data clustering problem. A chaotic sequence generated by a sinusoidal chaotic map has been utilized to target promising solutions in the search domain. On the other hand, the inclusion of the opposition learning-based approach allows the solutions to explore more appropriate locations in the search domain. The performance of the proposed approach is compared against some well-known algorithms using fitness values, statistical values, convergence curves, and box plots. These comparisons justify the efficacy of the suggested approach.},
  archive      = {J_PAAA},
  author       = {Singh, Tribhuvan and Saxena, Nitin},
  doi          = {10.1007/s10044-021-00964-2},
  journal      = {Pattern Analysis and Applications},
  month        = {8},
  number       = {3},
  pages        = {1303-1317},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Chaotic sequence and opposition learning guided approach for data clustering},
  volume       = {24},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Fuzzy kernel k-medoids clustering algorithm for uncertain
data objects. <em>PAAA</em>, <em>24</em>(3), 1287–1302. (<a
href="https://doi.org/10.1007/s10044-021-00983-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most data mining algorithms are designed for traditional type of data objects which are referred to as certain data objects. Certain data objects contain no uncertainty information and are represented by a single point. Capturing uncertainty can result in better performance of algorithms as they might generate more accurate results. There are different ways of modeling uncertainty for data objects, two of the most popular ones are: (1) considering a group of points for each object and (2) considering a probability density function (pdf) for each object. Objects modeled in these ways are referred to as uncertain data objects. Fuzzy clustering is a well-established field of research for certain data. When fuzzy clustering algorithms are used, degrees of membership are generated for assignment of objects to clusters which gives the flexibility to express that objects can belong to more than one cluster. To the best of our knowledge, for uncertain data, there is only one existing fuzzy clustering algorithm in the literature. The existing uncertain fuzzy clustering algorithm, however, cannot properly create non-convex shaped clusters, and therefore, its performance is not that well on uncertain data sets with arbitrary-shaped clusters—clusters that are non-convex, unconventional, and possibly nonlinearly separable. In this paper, we propose a novel fuzzy kernel K-medoids clustering algorithm for uncertain objects which works well on data sets with arbitrary-shaped clusters. We show through several experiments on synthetic and real data that the proposed algorithm outperforms the competitor algorithms: certain fuzzy K-medoids and the uncertain fuzzy K-medoids.},
  archive      = {J_PAAA},
  author       = {Tavakkol, Behnam and Son, Youngdoo},
  doi          = {10.1007/s10044-021-00983-z},
  journal      = {Pattern Analysis and Applications},
  month        = {8},
  number       = {3},
  pages        = {1287-1302},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Fuzzy kernel K-medoids clustering algorithm for uncertain data objects},
  volume       = {24},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Target re-aware deep tracking based on correlation filters
updated online. <em>PAAA</em>, <em>24</em>(3), 1275–1286. (<a
href="https://doi.org/10.1007/s10044-021-00982-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep trackers often use convolutional neural networks (CNNs) pre-trained to extract features. The training dataset always does not contain the tracking objects. Even the objects appearing in the training dataset may always be in arbitrary forms. Therefore, the pre-trained convolutional neural networks extract features with less effectiveness in describing the tracking object. Target-aware deep tracking (TADT) algorithm proposes a scheme to acquire target-aware deep features by an improved regression loss and a ranking loss. Target awareness is achieved by calculating the back-propagation gradients at each pixel in the regression. Multi-channel deep features gradients captured in the first frame affect the efficiency of the tracking in subsequent frames. If the target-aware scheme is updated online, the tracking efficiency can be further improved. In this work, we present a target-aware scheme updated online to re-select deep features generalizing the object appearance more effectively. The base deep features are extracted by the pre-trained VGG16 and further processed to acquire the target awareness deep features. The awareness deep features are re-selected as re-awareness deep features in the framework of correlation filters with parameters updated online. Correlation filters updated online replace improved regression loss to re-identify the importance of features by global average pooling deep features weights. The re-awareness deep features are integrated with a Siamese matching network to determine the target&#39;s location and scale in the subsequent frame. Experimental results demonstrate the effectiveness of our presented algorithm compared with TADT in terms of accuracy and speed.},
  archive      = {J_PAAA},
  author       = {Zhao, Yunji and Fan, Cunliang and Zhang, Xinliang and Chen, Xiangjun},
  doi          = {10.1007/s10044-021-00982-0},
  journal      = {Pattern Analysis and Applications},
  month        = {8},
  number       = {3},
  pages        = {1275-1286},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Target re-aware deep tracking based on correlation filters updated online},
  volume       = {24},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Improved barnacles mating optimizer algorithm for feature
selection and support vector machine optimization. <em>PAAA</em>,
<em>24</em>(3), 1249–1274. (<a
href="https://doi.org/10.1007/s10044-021-00985-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of computer technology, data collection becomes easier, and data object presents more complex. Data analysis method based on machine learning is an important, active, and multi-disciplinarily research field. Support vector machine (SVM) is one of the most powerful and fast classification models. The main challenges SVM faces are the selection of feature subset and the setting of kernel parameters. To improve the performance of SVM, a metaheuristic algorithm is used to optimize them simultaneously. This paper first proposes a novel classification model called IBMO-SVM, which hybridizes an improved barnacle mating optimizer (IBMO) with SVM. Three strategies, including Gaussian mutation, logistic model, and refraction-learning, are used to improve the performance of BMO from different perspectives. Through 23 classical benchmark functions, the impact of control parameters and the effectiveness of introduced strategies are analyzed. The convergence accuracy and stability are the main gains, and exploration and exploitation phases are more properly balanced. We apply IBMO-SVM to 20 real-world datasets, including 4 extremely high-dimensional datasets. Experimental results are compared with 6 state-of-the-art methods in the literature. The final statistical results show that the proposed IBMO-SVM achieves a better performance than the standard BMO-SVM and other compared methods, especially on high-dimensional datasets. In addition, the proposed model also shows significant superiority compared with 4 other classifiers.},
  archive      = {J_PAAA},
  author       = {Jia, Heming and Sun, Kangjian},
  doi          = {10.1007/s10044-021-00985-x},
  journal      = {Pattern Analysis and Applications},
  month        = {8},
  number       = {3},
  pages        = {1249-1274},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Improved barnacles mating optimizer algorithm for feature selection and support vector machine optimization},
  volume       = {24},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A novel clustering algorithm by adaptively merging
sub-clusters based on the normal-neighbor and merging force.
<em>PAAA</em>, <em>24</em>(3), 1231–1248. (<a
href="https://doi.org/10.1007/s10044-021-00981-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Clustering by fast search and find of density peaks (DPC) is a popular clustering method based on density and distance. In DPC, each non-center point’s cluster label is led by its nearest point with higher density, which may cause some misclassifications of non-center points and interfere with the choice of correct cluster centers in the decision graph. To avoid these defects, we propose a novel clustering algorithm that automatically generates clusters without using the decision graph based on the Normal-neighbor and Merging force (NM-DPC). We conduct a series of experiments on various challenging synthetic datasets. Experimental results demonstrate that NM-DPC can better identify clusters of complex shapes and automatically recognize the number of clusters.},
  archive      = {J_PAAA},
  author       = {Junyi , Guan and li, Sheng and Xiongxiong, He and Jiajia, Chen},
  doi          = {10.1007/s10044-021-00981-1},
  journal      = {Pattern Analysis and Applications},
  month        = {8},
  number       = {3},
  pages        = {1231-1248},
  shortjournal = {Pattern Anal. Appl.},
  title        = {A novel clustering algorithm by adaptively merging sub-clusters based on the normal-neighbor and merging force},
  volume       = {24},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). SSD based on contour–material level for domain adaptation.
<em>PAAA</em>, <em>24</em>(3), 1221–1229. (<a
href="https://doi.org/10.1007/s10044-021-00986-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the field of object detection, domain migration has gradually become a hot issue. We hope that the model trained in the domain with label-rich can be applied to other domains with label-poor or without labels, which can save a lot of time and energy for annotation, but different domain distributions are always mismatched; such a distribution mismatch will lead to a sharp decline in domain transfer performance. In this work, to improve the performance of object detection for domain transfer, we tackle the domain shift on two levels: (1) the contour-level shift, such as appearance, shape, and size, and (2) the material-level shift, such as texture, shade, and color. We apply different alignments to the aforementioned levels, specifically contour-level adaptation with full alignment and material-level adaptation with selective alignment. We construct a domain adaptation framework based on the recent state-of-the-art SSD model, and SSD is the abbreviation of single shot multibox detector, which is preeminent above most of the other approaches proposed in large numbers due to its real-time performance and effectiveness. We design two domain adapters on contour level and material level, respectively, to alleviate the domain discrepancy. Recently, approaches that align distributions of source and target images employing an adversarial loss have been proven effective, so the two domain adapters are implemented by learning a domain classifier in adversarial training manner, and the domain classifiers on different levels are further reinforced with a consistency regularization in the SSD model. We empirically verify the effectiveness of our method, which outperforms the other three state-of-the-art methods by a large margin of 5–10% in terms of mean average precision (mAP) on various datasets in both similar and dissimilar domain shift scenarios.},
  archive      = {J_PAAA},
  author       = {Jiang, Ning and Fang, Jinglong and Xu, Jihui and Shao, Yanli},
  doi          = {10.1007/s10044-021-00986-w},
  journal      = {Pattern Analysis and Applications},
  month        = {8},
  number       = {3},
  pages        = {1221-1229},
  shortjournal = {Pattern Anal. Appl.},
  title        = {SSD based on contour–material level for domain adaptation},
  volume       = {24},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Automatic detection of coronavirus disease (COVID-19) using
x-ray images and deep convolutional neural networks. <em>PAAA</em>,
<em>24</em>(3), 1207–1220. (<a
href="https://doi.org/10.1007/s10044-021-00984-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The 2019 novel coronavirus disease (COVID-19), with a starting point in China, has spread rapidly among people living in other countries and is approaching approximately 101,917,147 cases worldwide according to the statistics of World Health Organization. There are a limited number of COVID-19 test kits available in hospitals due to the increasing cases daily. Therefore, it is necessary to implement an automatic detection system as a quick alternative diagnosis option to prevent COVID-19 spreading among people. In this study, five pre-trained convolutional neural network-based models (ResNet50, ResNet101, ResNet152, InceptionV3 and Inception-ResNetV2) have been proposed for the detection of coronavirus pneumonia-infected patient using chest X-ray radiographs. We have implemented three different binary classifications with four classes (COVID-19, normal (healthy), viral pneumonia and bacterial pneumonia) by using five-fold cross-validation. Considering the performance results obtained, it has been seen that the pre-trained ResNet50 model provides the highest classification performance (96.1% accuracy for Dataset-1, 99.5% accuracy for Dataset-2 and 99.7% accuracy for Dataset-3) among other four used models.},
  archive      = {J_PAAA},
  author       = {Narin, Ali and Kaya, Ceren and Pamuk, Ziynet},
  doi          = {10.1007/s10044-021-00984-y},
  journal      = {Pattern Analysis and Applications},
  month        = {8},
  number       = {3},
  pages        = {1207-1220},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Automatic detection of coronavirus disease (COVID-19) using X-ray images and deep convolutional neural networks},
  volume       = {24},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Recognition of overlapping elliptical objects in a binary
image. <em>PAAA</em>, <em>24</em>(3), 1193–1206. (<a
href="https://doi.org/10.1007/s10044-020-00951-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recognition of overlapping objects is required in many applications in the field of computer vision. Examples include cell segmentation, bubble detection and bloodstain pattern analysis. This paper presents a method to identify overlapping objects by approximating them with ellipses. The method is intended to be applied to complex-shaped regions which are believed to be composed of one or more overlapping objects. The method has two primary steps. First, a pool of candidate ellipses are generated by applying the Euclidean distance transform on a compressed image and the pool is filtered by an overlaying method. Second, the concave points on the contour of the region of interest are extracted by polygon approximation to divide the contour into segments. Then, the optimal ellipses are selected from among the candidates by choosing a minimal subset that best fits the identified segments. We propose the use of the adjusted Rand index, commonly applied in clustering, to compare the fitting result with ground truth. Through a set of computational and optimization efficiencies, we are able to apply our approach in complex images comprised of a number of overlapped regions. Experimental results on a synthetic data set, two types of cell images and bloodstain patterns show superior accuracy and flexibility of our method in ellipse recognition, relative to other methods.},
  archive      = {J_PAAA},
  author       = {Zou, Tong and Pan, Tianyu and Taylor, Michael and Stern, Hal},
  doi          = {10.1007/s10044-020-00951-z},
  journal      = {Pattern Analysis and Applications},
  month        = {8},
  number       = {3},
  pages        = {1193-1206},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Recognition of overlapping elliptical objects in a binary image},
  volume       = {24},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Real-time one-shot learning gesture recognition based on
lightweight 3D inception-ResNet with separable convolutions.
<em>PAAA</em>, <em>24</em>(3), 1173–1192. (<a
href="https://doi.org/10.1007/s10044-021-00965-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gesture recognition is a popular research field in computer vision and the application of deep neural networks greatly improves its performance. However, the general deep learning method has a large number of parameters preventing the practical application on resource-limited devices. Meanwhile, collecting large number of training samples is usually time-consuming and difficult. To this end, we propose a lightweight 3D Inception-ResNet to extract discriminative features for real-time one-shot learning gesture recognition which aims to recognize gestures successfully given only one training sample for each new class. For efficient extraction of gesture features, we firstly extend the original 2D Inception-ResNet to the 3D version and then apply two kinds of separable convolutions as well as some other design strategies to reduce the number of parameters and computation complexity making it running in real-time even on CPU for feature extraction. Moreover, the consumption of storage space is also greatly reduced. In order to obtain robust performance for one-shot learning recognition, we employ an evolution mechanism by updating the root sample with innovation of new samples to enhance and improve the performance of the nearest neighbor classifier. Meanwhile, we propose an update strategy of the dynamic threshold to deal with the problem of threshold selection in real-world applications. In order to improve the robustness of recognition performance, we conduct artificial data synthesis to augment our collected dataset. A series of experiments conducted on public datasets and our collected dataset demonstrate the effectiveness of our approach to one-shot learning gesture recognition.},
  archive      = {J_PAAA},
  author       = {Li, Lianwei and Qin, Shiyin and Lu, Zhi and Zhang, Dinghao and Xu, Kuanhong and Hu, Zhongying},
  doi          = {10.1007/s10044-021-00965-1},
  journal      = {Pattern Analysis and Applications},
  month        = {8},
  number       = {3},
  pages        = {1173-1192},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Real-time one-shot learning gesture recognition based on lightweight 3D inception-ResNet with separable convolutions},
  volume       = {24},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Customizable HMM-based measures to accurately compare tree
sets. <em>PAAA</em>, <em>24</em>(3), 1149–1171. (<a
href="https://doi.org/10.1007/s10044-021-00971-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Trees have been topics of much interest since many decades due to various emerging applications using data represented as trees. Several techniques have been developed to compare two trees. But there is a serious lack of metrics to compare weighted trees. Existing approaches do not also allow to explicitly specify the targeted nodes properties on which the comparison should be performed. Furthermore, the problem of comparing two tree sets is not specifically addressed by existing techniques. This paper attempts to solve these problems by first proposing a distance and a similarity for the comparison of two finite sets of rooted ordered trees which can be labeled or not, as well as weighted or unweighted. To achieve this goal, a hidden Markov model is associated with each tree set for each targeted nodes property. The model associated with a tree set T for the targeted nodes property p learns how much the nodes of the trees in T verify property p. The resulting models are finally compared to derive a distance and similarity between the two sets of trees. The previous measures are then generalized for the comparison of unrooted and unordered trees. Flat classification experiments were carried out on two synthetic databases named FirstLast-L and FirstLast-LW available online. They both contain four classes of 100 rooted ordered trees whose specific and non-trivial nodes properties are clearly defined. When the distance proposed in this paper is selected as metric for the Nearest Neighbor classifier, a perfect accuracy of $$100\%$$ is obtained for these two databases. This performance is $$41\%$$ higher than the accuracy exhibited when the widespread tree Edit distance is selected for FirstLast-L.},
  archive      = {J_PAAA},
  author       = {Iloga, Sylvain},
  doi          = {10.1007/s10044-021-00971-3},
  journal      = {Pattern Analysis and Applications},
  month        = {8},
  number       = {3},
  pages        = {1149-1171},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Customizable HMM-based measures to accurately compare tree sets},
  volume       = {24},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A 2D and 3D discrete bisector function based on annulus.
<em>PAAA</em>, <em>24</em>(3), 1135–1148. (<a
href="https://doi.org/10.1007/s10044-021-00973-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The bisector function is an important tool for analyzing and filtering Euclidean skeletons. In this paper, we are proposing a new way to compute 2D and 3D discrete bisector function based on annuli. From a continuous point of view, a point that belongs to the medial axis is the center of a maximal ball that hits the background in more than one point. The maximal angle between those points is expected to be high for most of the object points and corresponds to the bisector angle. This logic is not really applicable in the discrete space since we may miss some background points that can lead to small bisector angles. In this work we use annuli to find the background points in order to compute the bisector angle. Our approach offers the possibility to change the thickness of the annulus at a given point and is thus flexible when computing skeletons. Our work can be extended to nD and we propose the nD algorithm.},
  archive      = {J_PAAA},
  author       = {Zrour, Rita and Andres, Eric and Sidibe, Sangbé and Lenain, Raphael and Largeteau-Skapin, Gaelle},
  doi          = {10.1007/s10044-021-00973-1},
  journal      = {Pattern Analysis and Applications},
  month        = {8},
  number       = {3},
  pages        = {1135-1148},
  shortjournal = {Pattern Anal. Appl.},
  title        = {A 2D and 3D discrete bisector function based on annulus},
  volume       = {24},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Blocking sparse method for image denoising. <em>PAAA</em>,
<em>24</em>(3), 1125–1133. (<a
href="https://doi.org/10.1007/s10044-021-00974-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, compressive sensing has been one promising technique for denoising images. This paper presents a new denoising model based on blocking sparsity. First, an image is blocked. Second, the split-Bregman method is used to solve for each block image. Finally, all denoised block images are combined into one image. Compared with the latest HTV, GHNS, FastATV, CSR and BM3D models, experimental results demonstrate that the proposed method is efficient, and has better denoising capability.},
  archive      = {J_PAAA},
  author       = {Yuan, Jianjun and He, Jiao},
  doi          = {10.1007/s10044-021-00974-0},
  journal      = {Pattern Analysis and Applications},
  month        = {8},
  number       = {3},
  pages        = {1125-1133},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Blocking sparse method for image denoising},
  volume       = {24},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Automatic COVID-19 detection from x-ray images using
ensemble learning with convolutional neural network. <em>PAAA</em>,
<em>24</em>(3), 1111–1124. (<a
href="https://doi.org/10.1007/s10044-021-00970-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {COVID-19 continues to have catastrophic effects on the lives of human beings throughout the world. To combat this disease it is necessary to screen the affected patients in a fast and inexpensive way. One of the most viable steps towards achieving this goal is through radiological examination, Chest X-Ray being the most easily available and least expensive option. In this paper, we have proposed a Deep Convolutional Neural Network-based solution which can detect the COVID-19 +ve patients using chest X-Ray images. Multiple state-of-the-art CNN models—DenseNet201, Resnet50V2 and Inceptionv3, have been adopted in the proposed work. They have been trained individually to make independent predictions. Then the models are combined, using a new method of weighted average ensembling technique, to predict a class value. To test the efficacy of the solution we have used publicly available chest X-ray images of COVID +ve and –ve cases. 538 images of COVID +ve patients and 468 images of COVID –ve patients have been divided into training, test and validation sets. The proposed approach gave a classification accuracy of 91.62% which is higher than the state-of-the-art CNN models as well the compared benchmark algorithm. We have developed a GUI-based application for public use. This application can be used on any computer by any medical personnel to detect COVID +ve patients using Chest X-Ray images within a few seconds.},
  archive      = {J_PAAA},
  author       = {Das, Amit Kumar and Ghosh, Sayantani and Thunder, Samiruddin and Dutta, Rohit and Agarwal, Sachin and Chakrabarti, Amlan},
  doi          = {10.1007/s10044-021-00970-4},
  journal      = {Pattern Analysis and Applications},
  month        = {8},
  number       = {3},
  pages        = {1111-1124},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Automatic COVID-19 detection from X-ray images using ensemble learning with convolutional neural network},
  volume       = {24},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). HDG and HDGG: An extensible feature extraction descriptor
for effective face and facial expressions recognition. <em>PAAA</em>,
<em>24</em>(3), 1095–1110. (<a
href="https://doi.org/10.1007/s10044-021-00972-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The potential of facial and facial expression recognitions has gained increased interest in social interactions and biometric identification. Earlier facial identification methods suffer from drawbacks due to the lower identification accuracy under difficult lighting conditions. This paper presents two novel new descriptors called Histogram of Directional Gradient (HDG) and Histogram of Directional Gradient Generalized (HDGG) to extracting discriminant facial expression features for better classification accuracy with good efficiency than existing classifiers. The proposed descriptors are based on the directional local gradients combined with SVM (Support Vector Machine) linear classification. To build an efficient face and facial expression recognition, features with reduced dimension are used to boost the performance of the classification. Experiments are conducted on two public-domain datasets: JAFFE for facial expression recognition and YALE for face recognition. The experiment results show the best overall accuracy of 92.12% compared to other existing works. It demonstrates a fast execution time for face recognition ranging from 0.4 to 0.7 s in all evaluated databases.},
  archive      = {J_PAAA},
  author       = {Ayeche, Farid and Alti, Adel},
  doi          = {10.1007/s10044-021-00972-2},
  journal      = {Pattern Analysis and Applications},
  month        = {8},
  number       = {3},
  pages        = {1095-1110},
  shortjournal = {Pattern Anal. Appl.},
  title        = {HDG and HDGG: An extensible feature extraction descriptor for effective face and facial expressions recognition},
  volume       = {24},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Text classification based on the word subspace
representation. <em>PAAA</em>, <em>24</em>(3), 1075–1093. (<a
href="https://doi.org/10.1007/s10044-021-00960-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a novel framework for text classification based on subspace-based methods. Recent studies showed the advantages of modeling texts as linear subspaces in a high-dimensional word vector space, to which we refer as word subspace. Therefore, we propose solving topic classification and sentiment analysis by using the word subspace along with different subspace-based methods. We explore the word embeddings geometry to decide which subspace-based method is more suitable for each task. We empirically demonstrate that a word subspace generated from sets of texts is a unique representation of a semantic topic that can be spanned by basis vectors derived from different texts. Therefore, texts can be classified by comparing their word subspace with the topic class subspaces. We achieve this framework by using the mutual subspace method that effectively handles multiple subspaces for classification. For sentiment analysis, as word embeddings do not necessarily consider sentiment information (i.e., opposite sentiment words have similar word vectors), we introduce the orthogonal mutual subspace method, to push opposite sentiment words apart. Furthermore, as there may be overlap between the sentiment class subspaces due to overlapping topics, we propose modeling a sentiment class by a set of multiple word subspaces, generated from each text belonging to the class. We further model the sentiment classes on a Grassmann manifold by using the Grassmann subspace method and its discriminative extension, the Grassmann orthogonal subspace method. We show the validity of each framework through experiments on four widely used datasets.},
  archive      = {J_PAAA},
  author       = {Shimomoto, Erica K. and Portet, François and Fukui, Kazuhiro},
  doi          = {10.1007/s10044-021-00960-6},
  journal      = {Pattern Analysis and Applications},
  month        = {8},
  number       = {3},
  pages        = {1075-1093},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Text classification based on the word subspace representation},
  volume       = {24},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Adjacent LBP and LTP based background modeling with
mixed-mode learning for foreground detection. <em>PAAA</em>,
<em>24</em>(3), 1047–1074. (<a
href="https://doi.org/10.1007/s10044-021-00967-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Detection of video objects under bad weather and poor illumination condition is a challenging task. We address this issue using the notion of background modeling. LBP-based background modeling and model learning has been used to detect the video objects but performance degrades in the above complex background. We propose the adjacency- and reinforced adjacency-based variants of LBP for complex real-world background modeling and model learning for object detection. In this regard, we have proposed the four variants; (1) enhanced adjacent local binary pattern, (2) enhanced reinforced adjacent local binary pattern, (3) enhanced adjacent local ternary pattern, and (4) enhanced reinforced adjacent local ternary pattern. Besides, we have embedded the Gabor and LBP features to obtain an embedded feature, which is subsequently used with the notions of adjacency. Unlike the background learning approach where the model learns only the background, our model learning algorithm learns the background together with the foreground objects and hence named as mixed-mode learning strategy. These models together with the new learning strategy are tested with CD2014 (snowfall and blizzard) and PETS (2014 and 2016) data sets, and the performance of the proposed models has been compared with LBP-based methods and other state-of-the-art methods.},
  archive      = {J_PAAA},
  author       = {Acharya, Subhabrata and Nanda, Pradipta Kumar},
  doi          = {10.1007/s10044-021-00967-z},
  journal      = {Pattern Analysis and Applications},
  month        = {8},
  number       = {3},
  pages        = {1047-1074},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Adjacent LBP and LTP based background modeling with mixed-mode learning for foreground detection},
  volume       = {24},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Robust and effective multiple copy-move forgeries detection
and localization. <em>PAAA</em>, <em>24</em>(3), 1025–1046. (<a
href="https://doi.org/10.1007/s10044-021-00968-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Copy-move (or copy-paste or cloning) is one of the most common image forgeries, wherein one or more region are copied and pasted within the same image. The motivations of such forgery include hiding an element in the image or emphasizing a particular object. Copy-move image forgery is more challenging to detect than other types, such as splicing and retouching. In recent years, keypoint based copy-move forgery detection, which extracts image keypoints and uses local visual features to identify duplicated regions, exhibits remarkable performance with respect to memory requirement and robustness against various attacks. However, these approaches usually have poor detection ability when copy-move forgeries only involve small or smooth regions. Moreover, they cannot always effectively deal with multiple copy-move forgeries. To tackle these challenges, we propose a robust and effective multiple copy-move forgeries detection and localization method through adaptive keypoint extraction, robust local feature representation, and offsets clustering based post-processing. Firstly, we develop a new image keypoint detector, named generic features from accelerated segment test, and extract adaptively the uniform distribution keypoints from the forged image by employing the adaptive-thresholding and non-maximum suppression. Then, we introduce fast quaternion polar complex exponential transform to describe the image keypoints compactly and distinctively, and utilize the KD tree based K-nearest neighbor matching to find possible correspondences. Finally, the falsely matched pairs are removed by employing the offsets information based candidate clustering, and the duplicated regions are localized using RANSAC and ZNCC algorithm. We conduct extensive experiments to evaluate the performance of the proposed approach, in which encouraging results validate the effectiveness of the proposed technique, especially for plain/multiple copy-move forgeries, in comparison with the state-of-the-art approaches recently proposed in the literature.},
  archive      = {J_PAAA},
  author       = {Wang, Xiang-yang and Wang, Chao and Wang, Li and Yang, Hong-ying and Niu, Pan-pan},
  doi          = {10.1007/s10044-021-00968-y},
  journal      = {Pattern Analysis and Applications},
  month        = {8},
  number       = {3},
  pages        = {1025-1046},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Robust and effective multiple copy-move forgeries detection and localization},
  volume       = {24},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A new approach for generation of generalized basic
probability assignment in the evidence theory. <em>PAAA</em>,
<em>24</em>(3), 1007–1023. (<a
href="https://doi.org/10.1007/s10044-021-00966-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The process of information fusion needs to deal with a large number of uncertain information with multi-source, heterogeneity, inaccuracy, unreliability, and incompleteness. In practical engineering applications, Dempster–Shafer evidence theory is widely used in multi-source information fusion owing to its effectiveness in data fusion. Information sources have an important impact on multi-source information fusion in an environment with the characteristics of complex, unstable, uncertain, and incomplete. To address multi-source information fusion problem, this paper considers the situation of uncertain information modeling from the closed-world to the open-world assumption and studies the generation of basic probability assignment with incomplete information. A new method is proposed to generate the generalized basic probability assignment (GBPA) based on the triangular fuzzy number model under the open-world assumption. First, the maximum, minimum, and mean values for the triangular membership function of each attribute in classification problem can be obtained to construct a triangular fuzzy number representation model. Then, by calculating the length of the intersection points between the sample and the triangular fuzzy number model, a GBPA set with an assignment for the empty set can be determined. The proposed method can not only be used in different complex environments simply and flexibly, but also have less information loss in information processing. Finally, a series of comprehensive experiments basing on the UCI data sets is used to verify the rationality and superiority of the proposed method.},
  archive      = {J_PAAA},
  author       = {Tang, Yongchuan and Wu, Dongdong and Liu, Zijing},
  doi          = {10.1007/s10044-021-00966-0},
  journal      = {Pattern Analysis and Applications},
  month        = {8},
  number       = {3},
  pages        = {1007-1023},
  shortjournal = {Pattern Anal. Appl.},
  title        = {A new approach for generation of generalized basic probability assignment in the evidence theory},
  volume       = {24},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Coronavirus disease 2019 (COVID-19): Survival analysis using
deep learning and cox regression model. <em>PAAA</em>, <em>24</em>(3),
993–1005. (<a href="https://doi.org/10.1007/s10044-021-00958-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Coronavirus (COVID-19) is one of the most serious problems that has caused stopping the wheel of life all over the world. It is widely spread to the extent that hospital places are not available for all patients. Therefore, most hospitals accept patients whose recovery rate is high. Machine learning techniques and artificial intelligence have been deployed for computing infection risks, performing survival analysis and classification. Survival analysis (time-to-event analysis) is widely used in many areas such as engineering and medicine. This paper presents two systems, Cox_COVID_19 and Deep_ Cox_COVID_19 that are based on Cox regression to study the survival analysis for COVID-19 and help hospitals to choose patients with better chances of survival and predict the most important symptoms (features) affecting survival probability. Cox_COVID_19 is based on Cox regression and Deep_Cox_COVID_19 is a combination of autoencoder deep neural network and Cox regression to enhance prediction accuracy. A clinical dataset for COVID-19 patients is used. This dataset consists of 1085 patients. The results show that applying an autoencoder on the data to reconstruct features, before applying Cox regression algorithm, would improve the results by increasing concordance, accuracy and precision. For Deep_ Cox_COVID_19 system, it has a concordance of 0.983 for training and 0.999 for testing, but for Cox_COVID_19 system, it has a concordance of 0.923 for training and 0.896 for testing. The most important features affecting mortality are, age, muscle pain, pneumonia and throat pain. Both Cox_COVID_19 and Deep_ Cox_COVID_19 prediction systems can predict the survival probability and present significant symptoms (features) that differentiate severe cases and death cases. But the accuracy of Deep_Cox_Covid_19 outperforms that of Cox_Covid_19. Both systems can provide definite information for doctors about detection and intervention to be taken, which can reduce mortality.},
  archive      = {J_PAAA},
  author       = {Atlam, Mostafa and Torkey, Hanaa and El-Fishawy, Nawal and Salem, Hanaa},
  doi          = {10.1007/s10044-021-00958-0},
  journal      = {Pattern Analysis and Applications},
  month        = {8},
  number       = {3},
  pages        = {993-1005},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Coronavirus disease 2019 (COVID-19): Survival analysis using deep learning and cox regression model},
  volume       = {24},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Medical imaging technique using curvelet transform and
machine learning for the automated diagnosis of breast cancer from
thermal image. <em>PAAA</em>, <em>24</em>(3), 981–991. (<a
href="https://doi.org/10.1007/s10044-021-00963-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Thermography is a useful imaging tool using infrared for the early diagnosis of breast cancer. Screening cancer aims to outstrip prognosis by seeing the precancerous stage to give a prominent prescription. Early diagnosis is essential to avoid the fatality rate in abnormal cases. In this article, a novel approach is proposed using image analysis and machine learning techniques. In the present work, thermal images were collected from the visual laboratory. In the pre-processing stage, the contrast of the image is improved by combining top-hat and bottom-hat transforms. The ROI extraction method is the preliminary process to select the right and left breast region and remove the neck and armpit region. Then, the imperfection in the structure of the image has been eliminated by using morphological operations. Statistical, geometrical, and intensity features are extracted from the pre-processed and segmented images. Texture features using a Gray-Level Co-Occurrence matrix are obtained both in the spatial domain and curvelet domain. The curvelet transform is used in the feature extraction stage, and this can be used to find an explanation of the curve discontinuity. The curvelet wrapping is applied, followed by the application of GLCM to extract texture features. In the proposed method, 16 features are used for the automated classification of input thermal images. Different machine learning techniques are explored, and the cubic SVM renders the highest accuracy of 93.3%. A combination of statistical, intensity, geometry features, and texture features extracted from curvelet coefficients provides the highest accuracy.},
  archive      = {J_PAAA},
  author       = {Karthiga, R. and Narasimhan, K.},
  doi          = {10.1007/s10044-021-00963-3},
  journal      = {Pattern Analysis and Applications},
  month        = {8},
  number       = {3},
  pages        = {981-991},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Medical imaging technique using curvelet transform and machine learning for the automated diagnosis of breast cancer from thermal image},
  volume       = {24},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). BFCNet: A CNN for diagnosis of ductal carcinoma in breast
from cytology images. <em>PAAA</em>, <em>24</em>(3), 967–980. (<a
href="https://doi.org/10.1007/s10044-021-00962-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fine Needle Aspiration Cytology (FNAC) is a quick and minimally invasive technique used to diagnose breast cancer, specifically ductal carcinoma. The incidence of breast cancer (ductal carcinoma) is high among Indian women. Consequently, there is a volume burden on laboratories, primarily regional centers, for diagnosis. The pressure on laboratories and doctors to make a timely and correct diagnosis can be resolved by automating the process to an extent, especially where expertise is limited. Recent advances in Artificial Intelligence techniques on large and complex data have enabled better understanding in the domain of Computer-Aided Diagnosis, which helps both automate and digitize diagnosis. In this study, we have leveraged Convolutional Neural Networks (CNNs) to automate the diagnosis of ductal carcinoma in breast from images produced after FNAC is performed on breast tissue. We created a data set of FNAC images of breast lesions and extracted 1020 Region of Interest (RoI) patches from Giemsa-stained lesions and 631 RoI patches from H&amp;E-stained lesions. The performance of various CNNs was tested on these patches. Three networks performed very well and have the potential to assist doctors in diagnosis. One of them was a light network we built—BFCNet (Breast FNAC Classification Network). It produced the highest average accuracies in the binary classification of Giemsa-stained patches (97.53%) and H&amp;E-stained patches (96.59%). This network fits the data properly and performs well in other parameters.},
  archive      = {J_PAAA},
  author       = {Bal, Ananya and Das, Meenakshi and Satapathy, Shashank Mouli and Jena, Madhusmita and Das, Subha Kanta},
  doi          = {10.1007/s10044-021-00962-4},
  journal      = {Pattern Analysis and Applications},
  month        = {8},
  number       = {3},
  pages        = {967-980},
  shortjournal = {Pattern Anal. Appl.},
  title        = {BFCNet: A CNN for diagnosis of ductal carcinoma in breast from cytology images},
  volume       = {24},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Correction to a novel framework for rapid diagnosis of
COVID-19 on computed tomography scans. <em>PAAA</em>, <em>24</em>(3),
965. (<a href="https://doi.org/10.1007/s10044-021-00969-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A correction to this paper has been published: https://doi.org/10.1007/s10044-021-00969-x},
  archive      = {J_PAAA},
  author       = {Akram, Tallha and Attique, Muhammad and Gul, Salma and Shahzad, Aamir and Altaf, Muhammad and Naqvi, S. Syed Rameez and Damaševičius, Robertas and Maskeliūnas, Rytis},
  doi          = {10.1007/s10044-021-00969-x},
  journal      = {Pattern Analysis and Applications},
  month        = {8},
  number       = {3},
  pages        = {965},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Correction to a novel framework for rapid diagnosis of COVID-19 on computed tomography scans},
  volume       = {24},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). A novel framework for rapid diagnosis of COVID-19 on
computed tomography scans. <em>PAAA</em>, <em>24</em>(3), 951–964. (<a
href="https://doi.org/10.1007/s10044-020-00950-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Since the emergence of COVID-19, thousands of people undergo chest X-ray and computed tomography scan for its screening on everyday basis. This has increased the workload on radiologists, and a number of cases are in backlog. This is not only the case for COVID-19, but for the other abnormalities needing radiological diagnosis as well. In this work, we present an automated technique for rapid diagnosis of COVID-19 on computed tomography images. The proposed technique consists of four primary steps: (1) data collection and normalization, (2) extraction of the relevant features, (3) selection of the most optimal features and (4) feature classification. In the data collection step, we collect data for several patients from a public domain website, and perform preprocessing, which includes image resizing. In the successive step, we apply discrete wavelet transform and extended segmentation-based fractal texture analysis methods for extracting the relevant features. This is followed by application of an entropy controlled genetic algorithm for selection of the best features from each feature type, which are combined using a serial approach. In the final phase, the best features are subjected to various classifiers for the diagnosis. The proposed framework, when augmented with the Naive Bayes classifier, yields the best accuracy of 92.6%. The simulation results are supported by a detailed statistical analysis as a proof of concept.},
  archive      = {J_PAAA},
  author       = {Akram, Tallha and Attique, Muhammad and Gul, Salma and Shahzad, Aamir and Altaf, Muhammad and Naqvi, S. Syed Rameez and Damaševičius, Robertas and Maskeliūnas, Rytis},
  doi          = {10.1007/s10044-020-00950-0},
  journal      = {Pattern Analysis and Applications},
  month        = {8},
  number       = {3},
  pages        = {951-964},
  shortjournal = {Pattern Anal. Appl.},
  title        = {A novel framework for rapid diagnosis of COVID-19 on computed tomography scans},
  volume       = {24},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Unsupervised change detection driven by floating references:
A pattern analysis approach. <em>PAAA</em>, <em>24</em>(3), 933–949. (<a
href="https://doi.org/10.1007/s10044-020-00954-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Earth’s environment is continually changing due to both human and natural factors. Timely identification of the location and kind of change is of paramount importance in several areas of application. Because of that, remote sensing change detection is a topic of great interest. The development of precise change detection methods is a constant challenge. This study introduces a novel unsupervised change detection method based on data clustering and optimization. The proposal is less dependent on radiometric normalization than classical approaches. We carried experiments with remote sensing images and simulated datasets to compare the proposed method with other unsupervised well-known techniques. At its best, the proposal improves by 50% the accuracy concerning the second best technique. Such improvement is most noticeable with uncalibrated data. Experiments with simulated data reveal that the proposal is better than all other compared methods at any practical significance level. The results show the potential of the proposed method.},
  archive      = {J_PAAA},
  author       = {Negri, Rogério G. and Frery, Alejandro C.},
  doi          = {10.1007/s10044-020-00954-w},
  journal      = {Pattern Analysis and Applications},
  month        = {8},
  number       = {3},
  pages        = {933-949},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Unsupervised change detection driven by floating references: A pattern analysis approach},
  volume       = {24},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Human activity recognition using robust adaptive privileged
probabilistic learning. <em>PAAA</em>, <em>24</em>(3), 915–932. (<a
href="https://doi.org/10.1007/s10044-020-00953-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, a supervised probabilistic approach is proposed that integrates the learning using privileged information (LUPI) paradigm into a hidden conditional random field (HCRF) model, called HCRF+, for human action recognition. The proposed model employs a self-training technique for automatic estimation of the regularization parameters of the objective function. Moreover, the method provides robustness to outliers by modeling the conditional distribution of the privileged information by a Student’s t-density function, which is naturally integrated into the HCRF+ framework. The proposed method was evaluated using different forms of privileged information on four publicly available datasets. The experimental results demonstrate its effectiveness concerning the state of the art in the LUPI framework using both hand-crafted and deep learning-based features extracted from a convolutional neural network.},
  archive      = {J_PAAA},
  author       = {Vrigkas, Michalis and Kazakos, Evangelos and Nikou, Christophoros and Kakadiaris, Ioannis A.},
  doi          = {10.1007/s10044-020-00953-x},
  journal      = {Pattern Analysis and Applications},
  month        = {8},
  number       = {3},
  pages        = {915-932},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Human activity recognition using robust adaptive privileged probabilistic learning},
  volume       = {24},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Twin-image suppression in digital in-line holography based
on wave-front filtering. <em>PAAA</em>, <em>24</em>(3), 907–914. (<a
href="https://doi.org/10.1007/s10044-020-00949-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Digital holography is an imaging process able to recreate three-dimensional representations of objects from recording pattern interference among distinct waves. The in-line configuration setup is a variant considered the simplest physical implementation, providing a feasible manner for acquisition and the same time higher resolution for free-living microscopy imaging using a single illumination system. However, the well-known twin-image problem is bounded to the technique, since there is no separation among reference and objects beams in this configuration. As a result, computational numerical diffraction routines present the twin-image effect intrinsically, imposing several difficulties in terms of post-processing requirements. In this context, this paper aims to present a numerical approach able to provide consistent suppression of twin-image problem for in-line holography, during the numerical diffraction procedure for phase retrieval, combining image subtraction and edge detection techniques. The proposed solution was implemented in Python language, and metrics defined to assess it were both qualitative and quantitative, based on edge detection and some image comparison metrics. The obtained results of the proposed approach present a significant reduction in the twin-image artifacts in the reconstructions of both experimental and simulated holograms, considering a spherical reference wave, regardless of the shapes and sizes of objects.},
  archive      = {J_PAAA},
  author       = {de Almeida, Jhony Luiz and Comunello, Eros and Sobieranski, Antonio and da Rocha Fernandes, Anita Maria and Cardoso, Gabriel Schade},
  doi          = {10.1007/s10044-020-00949-7},
  journal      = {Pattern Analysis and Applications},
  month        = {8},
  number       = {3},
  pages        = {907-914},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Twin-image suppression in digital in-line holography based on wave-front filtering},
  volume       = {24},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A rotation based regularization method for semi-supervised
learning. <em>PAAA</em>, <em>24</em>(3), 887–905. (<a
href="https://doi.org/10.1007/s10044-020-00947-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In manifold learning, the intrinsic geometry of the manifold is explored and preserved by identifying the optimal local neighborhood around each observation. It is well known that when a Riemannian manifold is unfolded correctly, the observations lying spatially near to the manifold, should remain near on the lower dimension as well. Due to the nonlinear properties of manifold around each observation, finding such optimal neighborhood on the manifold is a challenge. Thus, a sub-optimal neighborhood may lead to erroneous representation and incorrect inferences. In this paper, we propose a rotation-based affinity metric for accurate graph Laplacian approximation. It exploits the property of aligned tangent spaces of observations in an optimal neighborhood to approximate correct affinity between them. Extensive experiments on both synthetic and real world datasets have been performed. It is observed that proposed method outperforms existing nonlinear dimensionality reduction techniques in low-dimensional representation for synthetic datasets. The results on real world datasets like COVID-19 prove that our approach increases the accuracy of classification by enhancing Laplacian regularization.},
  archive      = {J_PAAA},
  author       = {Shukla, Prashant and Abhishek and Verma, Shekhar and Kumar, Manish},
  doi          = {10.1007/s10044-020-00947-9},
  journal      = {Pattern Analysis and Applications},
  month        = {8},
  number       = {3},
  pages        = {887-905},
  shortjournal = {Pattern Anal. Appl.},
  title        = {A rotation based regularization method for semi-supervised learning},
  volume       = {24},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Tracklet style transfer and part-level feature description
for person reidentification in a camera network. <em>PAAA</em>,
<em>24</em>(3), 875–886. (<a
href="https://doi.org/10.1007/s10044-021-00990-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reidentifying multiple objects in a camera network are a difficult problem, especially when determining whether the same object appears in a different place at a different time, captured by another camera. In this paper, we propose a novel tracklet-based approach for reidentifying objects despite the illumination condition differences that occur at various times of day. A similarity search is performed by comparing part-level object feature descriptions. Tracking in each camera is made by a recurrent neural network, and the matching between cameras is done by using a similarity neural network to obtain an output in the form of a similarity score. Our approach consists of two main phases. In the first phase, preprocessing is performed through the transfer of tracklets from several cameras. This process generates more samples from each camera, which is beneficial for training. In the second phase, the object definition is applied, which considers appearance information, temporal information and the similarity calculation, hence making object reidentification easier. We have analyzed the proposed strategy when applied to pedestrian reidentification databases in comparison with state-of-the-art work to prove its robustness.},
  archive      = {J_PAAA},
  author       = {Dorai, Yosra and Gazzah, Sami and Chausse, Frederic and Amara, Najoua Essoukri Ben},
  doi          = {10.1007/s10044-021-00990-0},
  journal      = {Pattern Analysis and Applications},
  month        = {8},
  number       = {3},
  pages        = {875-886},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Tracklet style transfer and part-level feature description for person reidentification in a camera network},
  volume       = {24},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Approaches on crowd counting and density estimation: A
review. <em>PAAA</em>, <em>24</em>(3), 853–874. (<a
href="https://doi.org/10.1007/s10044-021-00959-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, urgent needs for counting crowds and vehicles have greatly promoted research of crowd counting and density estimation. Benefiting from the rapid development of deep learning, the counting performance has been greatly improved, and the application scenarios have been further expanded. Aiming to deeply understand the development status of crowd counting and density estimation, we introduce and analyze the typical methods in this field and especially focus on elaborating deep learning-based counting methods. We summarize the existing approaches into four categories, i.e., detection-based, regression-based, convolutional neural network based and video-based. Each category is explicated in great detail. To provide more concrete reference, we compare the performance of typical methods on the popular benchmarks. We further elaborate on the datasets and metrics for the crowd counting community and discuss the work of solving the problem of small-sample-based counting, dataset annotation methods and so on. Finally, we summarize various challenges facing crowd counting and their corresponding solutions and propose a set of development trends in the future.},
  archive      = {J_PAAA},
  author       = {Li, Bo and Huang, Hongbo and Zhang, Ang and Liu, Peiwen and Liu, Cheng},
  doi          = {10.1007/s10044-021-00959-z},
  journal      = {Pattern Analysis and Applications},
  month        = {8},
  number       = {3},
  pages        = {853-874},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Approaches on crowd counting and density estimation: A review},
  volume       = {24},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Space-time flexible kernel for recognizing activities from
wearable cameras. <em>PAAA</em>, <em>24</em>(2), 843–852. (<a
href="https://doi.org/10.1007/s10044-020-00942-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recognizing activities of daily living is useful for ambient assisted living. In this regard, the use of wearable cameras is a promising technology. In this paper, we propose a novel approach for recognizing activities of daily living using egocentric viewpoint video clips. First, in every frame, the appearing objects are detected and labelled depending if they are being used or not by the subject. Later, the video clip is divided into spatiotemporal bins created with an object-centric cut. Finally, a support vector machine classifier is computed using a spatiotemporal flexible kernel between video clips. The validity of the proposed method has been proved by conducting experiments in the ADL dataset. Results confirm the suitability of using the space-time location of objects as information for the classification of activities using an egocentric viewpoint.},
  archive      = {J_PAAA},
  author       = {Rodriguez, Mario and Orrite, Carlos and Medrano, Carlos},
  doi          = {10.1007/s10044-020-00942-0},
  journal      = {Pattern Analysis and Applications},
  month        = {5},
  number       = {2},
  pages        = {843-852},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Space-time flexible kernel for recognizing activities from wearable cameras},
  volume       = {24},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Pedestrian tracking in thermal videos using TFM (tri-feature
matrix). <em>PAAA</em>, <em>24</em>(2), 831–842. (<a
href="https://doi.org/10.1007/s10044-020-00926-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, thermal cameras play a major role because of its temperature-based photography in many applications such as video surveillance, monitoring electronics/electrical machines, forest monitoring, monitoring babies/adult patients, and suspicious object detection. Tracking pedestrians in thermal video is a major task for such applications. Thermal cameras usually create images based on temperature emitted by the object only and not on the lighting conditions and outdoor environment conditions. But still thermal images have constraints like no texture or colour information, more number of dead pixels, low resolution, and noticeable visual colour patterns in case of any temperature variations. So the challenge in tracking pedestrians in thermal videos is tracking objects/pedestrians throughout the video without an identity switch by overcoming these constraints which may mislead the tracking process. To overcome these constraints, the proposed system uses tri feature matrix (TFM) as an object descriptor which is used to uniquely identify and represent objects in thermal images. TFM is represented in more compact way as a triple matrix. It is a simple and accurate descriptor suitable for tracking objects in thermal video sequences without an identity switch. The proposed Pedestrian tracking system uses most of the advantages of thermal cameras by overcoming challenges in thermal videos effectively based on a novel descriptor TFM. The proposed system is evaluated with various data sets, and the results are analysed using true positive, true negative, false negative, false positive, accuracy, precision, recall, F-score, global identity mismatch (GMME) and track matching error (TME). The performance metrics such as accuracy, precision, recall, F-score, GMME and TME are computed as 99%, 100%, 99%, 99%, 2.3%, and 2.1%, respectively. From the observation, it is found that the performance of proposed TFM-based system is significantly improved. The experimental result shows that the proposed system achieved more accurate tracking compared to the conventional methods.},
  archive      = {J_PAAA},
  author       = {Sasireka, D. and Juliet, S. Ebenezer},
  doi          = {10.1007/s10044-020-00926-0},
  journal      = {Pattern Analysis and Applications},
  month        = {5},
  number       = {2},
  pages        = {831-842},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Pedestrian tracking in thermal videos using TFM (tri-feature matrix)},
  volume       = {24},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Improving the accuracy of pruned network using knowledge
distillation. <em>PAAA</em>, <em>24</em>(2), 819–830. (<a
href="https://doi.org/10.1007/s10044-020-00940-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The introduction of convolutional neural networks (CNN) in image processing field has attracted researchers to explore the applications of CNN itself. Some network designs have been proposed to reach the state-of-the-art capability. However, the current design of neural network remains an issue related to the size of the model. Thus, some researchers introduce to reduce or compress the model size. The compression technique might affect the accuracy of the compressed model compared to the original one. In addition, it may influence the performance of the new model. Furthermore, we need to exploit a new scheme to enhance the accuracy of compressed network. In this study, we explore that knowledge distillation (KD) can be integrated to one of pruning methodologies, namely pruning filters, as the compression technique, to enhance the accuracy of pruned model. From all experimental results, we conclude that incorporating KD to create a MobileNets model can enhance the accuracy of pruned network without elongating the inference time. We measured the inference time of model trained with KD is just 0.1 s longer than that of without KD. Furthermore, by reducing 26.08% of the model size, the accuracy without KD is 63.65% and by incorporating KD, we can enhance to 65.37%.},
  archive      = {J_PAAA},
  author       = {Prakosa, Setya Widyawan and Leu, Jenq-Shiou and Chen, Zhao-Hong},
  doi          = {10.1007/s10044-020-00940-2},
  journal      = {Pattern Analysis and Applications},
  month        = {5},
  number       = {2},
  pages        = {819-830},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Improving the accuracy of pruned network using knowledge distillation},
  volume       = {24},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Adaptive weighted crowd receptive field network for crowd
counting. <em>PAAA</em>, <em>24</em>(2), 805–817. (<a
href="https://doi.org/10.1007/s10044-020-00934-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Crowd counting plays an important role in crowd analysis and monitoring. To this end, we propose a novel method called Adaptive Weighted Crowd Receptive Field Network (AWRFN) for crowd counting to estimate the number of people and the spatial distribution of input crowd images. The proposed AWRFN is composed of four modules: backbone, crowd receptive field block (CRFB), recurrent block (RB), and channel attention block (CAB). Backbone utilizes the first ten layers of VGG16 to extract base features of input images. CRFB is a multi-branch architecture simulating a real human visual system for further obtaining refined and discriminative crowd features. RB generates strong semantic and global information by recurrently stacking convolutional layers with the same parameters. CAB outputs appropriate weights to supervise each channel of the feature maps output from CRFB, which uses the outputs of RB as guidance. Different from previous works using Euclidean Loss, we employ L1_Smooth Loss to train our network in an end-to-end fashion. To demonstrate the effectiveness of our proposed method, we implement AWRFN on two representative datasets including the ShanghaiTech dataset and the UCF_CC_50 dataset. The experimental results prove that our method is both effective and robust compared with the state-of-the-art approaches.},
  archive      = {J_PAAA},
  author       = {Peng, Sifan and Wang, Luyang and Yin, Baoqun and Li, Yun and Xia, Yinfeng and Hao, Xiaoliang},
  doi          = {10.1007/s10044-020-00934-0},
  journal      = {Pattern Analysis and Applications},
  month        = {5},
  number       = {2},
  pages        = {805-817},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Adaptive weighted crowd receptive field network for crowd counting},
  volume       = {24},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A note on “new aggregation operators of single-valued
neutrosophic hesitant fuzzy set and their application in multi-attribute
decision making.” <em>PAAA</em>, <em>24</em>(2), 801–803. (<a
href="https://doi.org/10.1007/s10044-020-00928-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Single-valued neutrosophic hesitant fuzzy elements (SVNHFEs) can be used to characterize incomplete, uncertain and inconsistent information effectively, which result in great significance of the aggregation of SVNHFEs. However, some existing aggregation operators for SVNHFEs may not be rigorous enough. In this paper, We show that an assertion (Theorem  1) in a previous paper by Liu and Guo [C.F. Liu, Y.S. Luo, New aggregation operators of single-valued neutrosophic hesitant fuzzy set and their application in multi-attribute decision making, Pattern Analysis Application (2019) 22:417–427] is not correct, i.e., the single-valued neutrosophic hesitant fuzzy ordered weighted aggregation (SVNHFOWA) operator does not satisfy idempotency actually. Thus it is not reasonable to adopt the SVNHFOWA operator in many practical applications. The present paper can effectively prevent many researchers from using the SVNHFOWA operator to aggregate SVNHFEs.},
  archive      = {J_PAAA},
  author       = {Wang, Li and Bao, Yan-Ling},
  doi          = {10.1007/s10044-020-00928-y},
  journal      = {Pattern Analysis and Applications},
  month        = {5},
  number       = {2},
  pages        = {801-803},
  shortjournal = {Pattern Anal. Appl.},
  title        = {A note on “New aggregation operators of single-valued neutrosophic hesitant fuzzy set and their application in multi-attribute decision making”},
  volume       = {24},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). CED-net: Context-aware ear detection network for
unconstrained images. <em>PAAA</em>, <em>24</em>(2), 779–800. (<a
href="https://doi.org/10.1007/s10044-020-00914-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Personal authentication systems based on biometric have seen a strong demand mainly due to the increasing concern in various privacy and security applications. Although the use of each biometric trait is problem dependent, the human ear has been found to have enough discriminating characteristics to allow its use as a strong biometric measure. To locate an ear in a face image is a strenuous task, numerous existing approaches have achieved significant performance, but the majority of studies are based on the constrained environment. However, ear biometrics possess a great level of difficulties in the unconstrained environment, where pose, scale, occlusion, illuminations, background clutter, etc., vary to a great extent. To address the problem of ear detection in the wild, we have proposed two high-performance ear detection models: CED-Net-1 and CED-Net-2, which are fundamentally based on deep convolutional neural networks and primarily use contextual information to detect ear in the unconstrained environment. To compare the performance of proposed models, we have implemented state-of-the-art deep learning models, viz. FRCNN (faster region convolutional neural network) and SSD (single shot multibox detector) for ear detection task. To test the model’s generalization, these are evaluated on six different benchmark datasets, viz. IITD, IITK, USTB-DB3, UND-E, UND-J2 and UBEAR, and each one of the databases has different challenging images. The models are compared based on performance measure parameters such as IOU (intersection over union), accuracy, precision, recall and F1-score. It is observed that our proposed models CED-Net-1 and CED-Net-2 outperformed the FRCNN and SSD at higher values of IOUs. An accuracy of 99% is achieved at IOU 0.5 on majority of the databases. This performance signifies the importance and effectiveness of the models and indicates that the models are resilient to environmental conditions.},
  archive      = {J_PAAA},
  author       = {Kamboj, Aman and Rani, Rajneesh and Nigam, Aditya and Jha, Ranjeet Ranjan},
  doi          = {10.1007/s10044-020-00914-4},
  journal      = {Pattern Analysis and Applications},
  month        = {5},
  number       = {2},
  pages        = {779-800},
  shortjournal = {Pattern Anal. Appl.},
  title        = {CED-net: Context-aware ear detection network for unconstrained images},
  volume       = {24},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A scalable solution to the nearest neighbor search problem
through local-search methods on neighbor graphs. <em>PAAA</em>,
<em>24</em>(2), 763–777. (<a
href="https://doi.org/10.1007/s10044-020-00946-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nearest neighbor search is a powerful abstraction for data access; however, data indexing is troublesome even for approximate indexes. For intrinsically high-dimensional data, high-quality fast searches demand either indexes with impractically large memory usage or preprocessing time. In this paper, we introduce an algorithm to solve a nearest-neighbor query q by minimizing a kernel function defined by the distance from q to each object in the database. The minimization is performed using metaheuristics to solve the problem rapidly; even when some methods in the literature use this strategy behind the scenes, our approach is the first one using it explicitly. We also provide two approaches to select edges in the graph’s construction stage that limit memory footprint and reduce the number of free parameters simultaneously. We carry out a thorough experimental comparison with state-of-the-art indexes through synthetic and real-world datasets; we found out that our contributions achieve competitive performances regarding speed, accuracy, and memory in almost any of our benchmarks.},
  archive      = {J_PAAA},
  author       = {Tellez, Eric S. and Ruiz, Guillermo and Chavez, Edgar and Graff, Mario},
  doi          = {10.1007/s10044-020-00946-w},
  journal      = {Pattern Analysis and Applications},
  month        = {5},
  number       = {2},
  pages        = {763-777},
  shortjournal = {Pattern Anal. Appl.},
  title        = {A scalable solution to the nearest neighbor search problem through local-search methods on neighbor graphs},
  volume       = {24},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Neighborhood and center difference-based-LBP for face
recognition. <em>PAAA</em>, <em>24</em>(2), 741–761. (<a
href="https://doi.org/10.1007/s10044-020-00948-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This research paper introduces the novel local binary pattern (LBP) variant for face recognition (FR) called as neighborhood and center difference-based-LBP (NCDB-LBP). In NCDB-LBP, the 4 labeled function is proposed to capture the robust features from 3 × 3 pixel window. For each neighborhood position , 2 first-order derivatives are computed, first computed between the adjacent neighborhood and the current neighborhood and the second computed between the center pixel and the current neighborhood. Employing the proposed function between the 2 first-order derivatives (produced from each neighborhood position) eventually results in 4 labeled window. All 8 neighborhoods are then placed in the 1 × 8 pixel window from which the 4 different binary patterns are produced. This concept is performed in both anticlockwise (ac) and clockwise (c) directions, termed as NCDB-LBPac and NCDB-LBPc descriptors. After binary patterns are encoded for each pixel position, the 4 transformed images are produced from ac direction and 4 from the c direction. All the respective directional transformed images are then divided into 3 × 3 subregions for histogram extraction. The combined histograms from all the respective subregions are the entire feature size of the NCDB-LBPac and NCDB-LBPc descriptors. To reduce the feature size, PCA and FLDA are utilized. Finally, classification is performed by SVMs and NN. The proposed FR approach is tested on ORL, GT, JAFFE, Yale, YB and EYB databases. The proposed FR approach achieves encouraging results.},
  archive      = {J_PAAA},
  author       = {Karanwal, Shekhar and Diwakar, Manoj},
  doi          = {10.1007/s10044-020-00948-8},
  journal      = {Pattern Analysis and Applications},
  month        = {5},
  number       = {2},
  pages        = {741-761},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Neighborhood and center difference-based-LBP for face recognition},
  volume       = {24},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The framework of learnable kernel function and its
application to dictionary learning of SPD data. <em>PAAA</em>,
<em>24</em>(2), 723–739. (<a
href="https://doi.org/10.1007/s10044-020-00941-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The kernel method of machine learning is to transform data from data space to reproducing kernel Hilbert space (RKHS) and then perform machine learning in RKHS, while kernel learning is to select the best RKHS for specific applications and given learning samples. Since RKHS can be generated from kernel functions, kernel learning is to learn kernel functions. At present, the dilemma of kernel learning is that there are few kinds of kernel functions available for learning. The first contribution of this paper is to propose a new framework of kernel functions, in which the given learning samples can be embedded. Moreover, the framework contains a learnable part which can be optimized for specific applications. Symmetric positive definite (SPD) matrix data are more and more common in machine learning. However, SPD data space does not constitute a linear space and dictionary learning involves a lot of linear operations. Therefore, dictionary learning cannot be performed directly on SPD data space. The second contribution of this paper is to apply the proposed framework of kernel functions to dictionary learning of SPD data, in which SPD data are first transformed to the RKHS produced by the proposed framework, and then, both dictionary and the learnable part of the framework are learned simultaneously in RKHS. The experimental results on 4 landmark datasets show that the proposed algorithm performs better than 6 other algorithms published recently in top academic journals.},
  archive      = {J_PAAA},
  author       = {Feng, Weijia and Ma, Zhengming and Zhuang, Rixin and Che, Hangjian},
  doi          = {10.1007/s10044-020-00941-1},
  journal      = {Pattern Analysis and Applications},
  month        = {5},
  number       = {2},
  pages        = {723-739},
  shortjournal = {Pattern Anal. Appl.},
  title        = {The framework of learnable kernel function and its application to dictionary learning of SPD data},
  volume       = {24},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). OCR error correction using correction patterns and
self-organizing migrating algorithm. <em>PAAA</em>, <em>24</em>(2),
701–721. (<a href="https://doi.org/10.1007/s10044-020-00936-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optical character recognition (OCR) systems help to digitize paper-based historical achieves. However, poor quality of scanned documents and limitations of text recognition techniques result in different kinds of errors in OCR outputs. Post-processing is an essential step in improving the output quality of OCR systems by detecting and cleaning the errors. In this paper, we present an automatic model consisting of both error detection and error correction phases for OCR post-processing. We propose a novel approach of OCR post-processing error correction using correction pattern edits and evolutionary algorithm which has been mainly used for solving optimization problems. Our model adopts a variant of the self-organizing migrating algorithm along with a fitness function based on modifications of important linguistic features. We illustrate how to construct the table of correction pattern edits involving all types of edit operations and being directly learned from the training dataset. Through efficient settings of the algorithm parameters, our model can be performed with high-quality candidate generation and error correction. The experimental results show that our proposed approach outperforms various baseline approaches as evaluated on the benchmark dataset of ICDAR 2017 Post-OCR text correction competition.},
  archive      = {J_PAAA},
  author       = {Nguyen, Quoc-Dung and Le, Duc-Anh and Phan, Nguyet-Minh and Zelinka, Ivan},
  doi          = {10.1007/s10044-020-00936-y},
  journal      = {Pattern Analysis and Applications},
  month        = {5},
  number       = {2},
  pages        = {701-721},
  shortjournal = {Pattern Anal. Appl.},
  title        = {OCR error correction using correction patterns and self-organizing migrating algorithm},
  volume       = {24},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A multi-class structured dictionary learning method using
discriminant atom selection. <em>PAAA</em>, <em>24</em>(2), 685–700. (<a
href="https://doi.org/10.1007/s10044-020-00939-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the last decade, traditional dictionary learning methods have been successfully applied to various pattern classification tasks. Although these methods produce sparse representations of signals which are robust against distortions and missing data, such representations quite often turn out to be unsuitable if the final objective is signal classification. In order to overcome, or at least to attenuate, such a weakness, several new methods which incorporate discriminant information into sparse-inducing models have emerged in recent years. In particular, methods for discriminant dictionary learning have shown to be more accurate than the traditional ones, which are only focused on minimizing the total representation error. In this work, we present both a novel multi-class discriminant measure and an innovative dictionary learning method. For a given dictionary, this new measure, which takes into account not only when a particular atom is used for representing signals coming from a certain class and the magnitude of its corresponding representation coefficient, but also the effect that such an atom has in the total representation error, is capable of efficiently quantifying the degree of discriminability of each one of the atoms. On the other hand, the new dictionary construction method yields dictionaries which are highly suitable for multi-class classification tasks. Our method was tested with two widely used databases for handwritten digit recognition and for object recognition, and compared with three state-of-the-art classification methods. The results show that our method significantly outperforms the other three achieving good recognition rates and additionally, reducing the computational cost of the classifier.},
  archive      = {J_PAAA},
  author       = {Rolon, Roman E. and Di Persia, Leandro E. and Spies, Ruben D. and Rufiner, Hugo L.},
  doi          = {10.1007/s10044-020-00939-9},
  journal      = {Pattern Analysis and Applications},
  month        = {5},
  number       = {2},
  pages        = {685-700},
  shortjournal = {Pattern Anal. Appl.},
  title        = {A multi-class structured dictionary learning method using discriminant atom selection},
  volume       = {24},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Image matching based on the adaptive redundant keypoint
elimination method in the SIFT algorithm. <em>PAAA</em>, <em>24</em>(2),
669–683. (<a href="https://doi.org/10.1007/s10044-020-00938-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Scale invariant feature transform (SIFT) is one of the most effective techniques in image matching applications. However, it has a main drawback: existing numerous redundant keypoints located very close to each other in the image. These redundant keypoints increase the computational complexity while they decrease the image matching performance. Redundant keypoint elimination method (RKEM)–SIFT are incorporated to eliminate these points by comparing their distances with a fixed experimental threshold value. However, this value has a great impact on the matching results. In this paper, an adaptive RKEM is presented which considers type of the images and distortion thereof, while adjusting the threshold value. Moreover, this value is found separately for the reference and sensed images. In an image, the adaptive RKEM finds the histogram of the keypoints distances, for which the number and the width of the bins are determined based on the number of keypoints and the distances distribution metrics. Then, a maximum value for searching the optimal threshold value is determined. Finally, for each integer value smaller than the mentioned maximum, a set containing distances smaller than that value is created and the one with the smallest variance is selected. The integer value corresponding to that set is chosen as the adaptive threshold for that image. This approach can improve the efficiency of the RKEM-SIFT in eliminating redundant keypoints. Simulation results validated that the proposed method outperforms the SIFT, A2 SIFT and RKEM-SIFT in terms of the matching performance indices.},
  archive      = {J_PAAA},
  author       = {Hossein-Nejad, Zahra and Agahi, Hamed and Mahmoodzadeh, Azar},
  doi          = {10.1007/s10044-020-00938-w},
  journal      = {Pattern Analysis and Applications},
  month        = {5},
  number       = {2},
  pages        = {669-683},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Image matching based on the adaptive redundant keypoint elimination method in the SIFT algorithm},
  volume       = {24},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Forensic image analysis using inconsistent noise pattern.
<em>PAAA</em>, <em>24</em>(2), 655–667. (<a
href="https://doi.org/10.1007/s10044-020-00930-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the advancement of image acquisition devices and social networking services, a huge volume of image data is generated. Using different image and video processing applications, these image data are manipulated, and thus, original images get tampered. These tampered images are the prime source of spreading fake news, defaming the personalities and in some cases (when used as evidence) misleading the law bodies. Hence before relying totally on the image data, the authenticity of the image must be verified. Works of the literature are reported for the verification of the authenticity of an image based on noise inconsistency. However, these works suffer from limitations of confusion between edges and noise, post-processing operation for localization and need of prior knowledge about an image. To handle these limitations, a noise inconsistency-based technique has been presented here to detect and localize a false region in an image. This work consists of three major steps of pre-processing, noise estimation and post-processing. For the experimental purpose two, publicly available datasets are used. The result is discussed in terms of precision, recall, accuracy and f1-score on the pixel level. The result of the presented work is also compared with the recent state-of-the-art techniques. The average accuracy of the proposed work on datasets is 91.70%, which is highest among state-of-the-art techniques.},
  archive      = {J_PAAA},
  author       = {Jaiswal, Ankit Kumar and Srivastava, Rajeev},
  doi          = {10.1007/s10044-020-00930-4},
  journal      = {Pattern Analysis and Applications},
  month        = {5},
  number       = {2},
  pages        = {655-667},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Forensic image analysis using inconsistent noise pattern},
  volume       = {24},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). RFCL: A new under-sampling method of reducing the degree of
imbalance and overlap. <em>PAAA</em>, <em>24</em>(2), 641–654. (<a
href="https://doi.org/10.1007/s10044-020-00929-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Imbalanced data are often encountered in every aspect of our lives, such as medical science, Internet, finance, and surveillance. Learning from imbalanced data which is also called the imbalanced learning problem is still a big challenge and deserves more attention. In this paper, we focus on overlap, which is one of the most important inherent factors that hinder learning from imbalanced data well. We put forward the overlapping degree (OD), and grouped data sets into two types, high OD (HOD) and low OD (LOD). The experimental results found that LOD data sets can achieve good results without any under-sampling algorithm, though some of them have high degree of imbalance, and the under-sampling algorithm does not improve the results very much. A new under-sampling algorithm, random forest cleaning rule (RFCL), was proposed to remove the majority class instances that cross the given new classification boundary which is a margin’s threshold. The degree of overlap and imbalance will be decreased in this way. This threshold is searched by maximizing the F1-score of the final classifier. Experimental results show that RFCL outperforms seven classic and two latest under-sampling methods in terms of F1-score and area under the curve, whether using random forest or support vector machine as the final classifier.},
  archive      = {J_PAAA},
  author       = {Zhang, Rui and Zhang, Zuoquan and Wang, Di},
  doi          = {10.1007/s10044-020-00929-x},
  journal      = {Pattern Analysis and Applications},
  month        = {5},
  number       = {2},
  pages        = {641-654},
  shortjournal = {Pattern Anal. Appl.},
  title        = {RFCL: A new under-sampling method of reducing the degree of imbalance and overlap},
  volume       = {24},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). AWkS: Adaptive, weighted k-means-based superpixels for
improved saliency detection. <em>PAAA</em>, <em>24</em>(2), 625–639. (<a
href="https://doi.org/10.1007/s10044-020-00925-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Clustering inspired superpixel algorithms perform a restricted partitioning of an image, where each visually coherent region containing perceptually similar pixels serves as a primitive in subsequent processing stages. Simple linear iterative clustering (SLIC) has emerged as a standard superpixel generation tool due to its exceptional performance in terms of segmentation accuracy and speed. However, SLIC applies a manually adjusted distance measure for dis-similarity computation which directly affects the quality of superpixels. In this work, self-adjustable distance measures are adapted from the weighted k-means clustering (W-k-means) for generating superpixel segmentation. In the proposed distance measures, an adaptive weight associated with each variable reflects its relevance in the clustering process. Intuitively, the variable weights correspond to the normalization terms in SLIC that affect the trade-off between superpixels boundary adherence and compactness. Weights that influence consistency in superpixel generation are automatically updated. The variable weights update is accomplished during optimization with a closed-form solution based on the current image partition. The proposed adaptive, W-k-means-based superpixels (AWkS) experimented on three benchmarks under different distance measure outperform the conventional SLIC algorithm with respect to various boundary adherence metrics. Finally, the effectiveness of the AWkS over SLIC is demonstrated for saliency detection.},
  archive      = {J_PAAA},
  author       = {Gupta, Ashish Kumar and Seal, Ayan and Khanna, Pritee and Krejcar, Ondrej and Yazidi, Anis},
  doi          = {10.1007/s10044-020-00925-1},
  journal      = {Pattern Analysis and Applications},
  month        = {5},
  number       = {2},
  pages        = {625-639},
  shortjournal = {Pattern Anal. Appl.},
  title        = {AWkS: Adaptive, weighted k-means-based superpixels for improved saliency detection},
  volume       = {24},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). IM-c-means: A new clustering algorithm for clusters with
skewed distributions. <em>PAAA</em>, <em>24</em>(2), 611–623. (<a
href="https://doi.org/10.1007/s10044-020-00932-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a new clustering algorithm, IM-c-means, is proposed for clusters with skewed distributions. C-means algorithm is a well-known and widely used strategy for data clustering, but at the same time prone to poor performance if the data set is not distributed uniformly, which is called “uniform effect” in studies. We first analyze the cause of this effect and find that it occurs only when clusters sizes are varied, whereas different object densities inter-clusters have no effect on c-means algorithm. According to this finding, we propose to form a new objective function by considering volumes and object densities of all clusters, which creates a new effective clustering algorithm with respect to the clusters with varied sizes or densities, while at the same time inheriting the good performance of traditional c-means algorithm for balanced data set. The experiments using both synthetic and real data sets have provided promising results of the proposed clustering algorithm. In addition, the nonparametric test has showed that the proposed algorithm could offer a significant improvement over other clustering methods for imbalanced data sets.},
  archive      = {J_PAAA},
  author       = {Liu, Yun and Hou, Tao and Miao, Yan and Liu, Meihe and Liu, Fu},
  doi          = {10.1007/s10044-020-00932-2},
  journal      = {Pattern Analysis and Applications},
  month        = {5},
  number       = {2},
  pages        = {611-623},
  shortjournal = {Pattern Anal. Appl.},
  title        = {IM-c-means: A new clustering algorithm for clusters with skewed distributions},
  volume       = {24},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A three-stage shearlet-based algorithm for vessel
segmentation in medical imaging. <em>PAAA</em>, <em>24</em>(2), 591–610.
(<a href="https://doi.org/10.1007/s10044-020-00915-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dictionaries are known tools used in different branches of image processing like edge detection, inpainting and, etc. Segmentation is the task of extracting an object as the part of a particular image. The common drawback of different segmentation methods is that they perform the extraction task incompletely. Tasks like edge detection, denoising and smoothing, as the parts of segmentation, can be done through applying the dictionaries. In this paper, we propose three new contrast stretching function. Based on one of the stretching functions and shearlets as a dictionary, we improved the previous version of a method that has been used in binary segmentation for magnetic resonance angiography images (MRI). We also introduce a three-stage binary image segmentation algorithm for vessel segmentation in MRI images. There are some disadvantages in recent proposed methods when dealing with extracting vessels of medical images. Our algorithm does the task with a more accurate extraction in detecting vessels having low intensity and weak edges in MRI.},
  archive      = {J_PAAA},
  author       = {Mirzafam, Mahdi and Aghazadeh, Nasser},
  doi          = {10.1007/s10044-020-00915-3},
  journal      = {Pattern Analysis and Applications},
  month        = {5},
  number       = {2},
  pages        = {591-610},
  shortjournal = {Pattern Anal. Appl.},
  title        = {A three-stage shearlet-based algorithm for vessel segmentation in medical imaging},
  volume       = {24},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Infrared and visible image fusion using modified spatial
frequency-based clustered dictionary. <em>PAAA</em>, <em>24</em>(2),
575–589. (<a href="https://doi.org/10.1007/s10044-020-00919-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Infrared and visible image fusion is an active area of research as it provides fused image with better scene information and sharp features. An efficient fusion of images from multisensory sources is always a challenge for researchers. In this paper, an efficient image fusion method based on sparse representation with clustered dictionary is proposed for infrared and visible images. Firstly, the edge information of visible image is enhanced by using a guided filter. To extract more edge information from the source images, modified spatial frequency is used to generate a clustered dictionary from the source images. Then, non-subsampled contourlet transform (NSCT) is used to obtain low-frequency and high-frequency sub-bands of the source images. The low-frequency sub-bands are fused using sparse coding, and the high-frequency sub-bands are fused using max-absolute rule. The final fused image is obtained by using inverse NSCT. The subjective and objective evaluations show that the proposed method is able to outperform other conventional image fusion methods.},
  archive      = {J_PAAA},
  author       = {Budhiraja, Sumit and Sharma, Rajat and Agrawal, Sunil and Sohi, Balwinder S.},
  doi          = {10.1007/s10044-020-00919-z},
  journal      = {Pattern Analysis and Applications},
  month        = {5},
  number       = {2},
  pages        = {575-589},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Infrared and visible image fusion using modified spatial frequency-based clustered dictionary},
  volume       = {24},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Representing and analyzing relief patterns using LBP
variants on mesh manifold. <em>PAAA</em>, <em>24</em>(2), 557–573. (<a
href="https://doi.org/10.1007/s10044-020-00920-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Extending the concept of texture to the geometry of a mesh manifold surface is an emerging topic in computer vision. This concept is different from gluing images to the surface, but rather indicates the presence of relief patterns that locally change the surface geometry, showing some regular and repetitive patterns. The representation and the analysis of such relief patterns have several potential applications. In this paper, we propose an original and comprehensive framework to address this novel task, which redefines a large variety of local binary patterns on the mesh manifold domain. We also propose an efficient mesh re-sampling technique that enables uniform surface tessellation. We assess the different descriptive variants derived with this framework in terms of uniformity, repeatability and discriminative power. Afterward, we conduct an extensive experimentation on different datasets showcasing the competitiveness of our framework in classification and retrieval tasks, in terms of both accuracy and computational complexity, with respect to state-of-the-art methods.},
  archive      = {J_PAAA},
  author       = {Tortorici, Claudio and Werghi, Naoufel and Berretti, Stefano},
  doi          = {10.1007/s10044-020-00920-6},
  journal      = {Pattern Analysis and Applications},
  month        = {5},
  number       = {2},
  pages        = {557-573},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Representing and analyzing relief patterns using LBP variants on mesh manifold},
  volume       = {24},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Deep kernel machines: A survey. <em>PAAA</em>,
<em>24</em>(2), 537–556. (<a
href="https://doi.org/10.1007/s10044-020-00933-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The emergence of deep learning frameworks paves the way for achieving higher-level data abstractions and possess the potential in consolidating both supervised and unsupervised learning paradigms. Researchers have made many successful explorations in the field of deep learning, with applications in the fields of face recognition, text mining, language translation, image prediction, and action recognition. Kernel machines act as a bridge between the linearity and nonlinearity for many machine learning algorithms such as support vector machines, extreme learning machines, and core vector machines. These Kernel machines play a vital role in mapping the data in the input space to a Kernel-induced high-dimensional feature space to obtain a better distribution of the data. In this Kernel-induced high-dimensional feature space, the distribution of data points will be more amenable to the classification problem under consideration. The Kernel trick facilitates in transforming the machine learning algorithms that require only inner product computations between the data vectors into a Kernel-based approach by selecting an appropriate Kernel function. In Kernel-based approaches, the Kernel functions can thus be utilized for accomplishing the inner product computations between the transformed data vectors in an implicitly defined Kernel-induced feature space. Unlike neural networks, the Kernel machines guarantee structural risk minimization and global optimal solutions. Also, the Kernel machines exhibit capabilities such as theoretical tractability and excellent performance in practical applications. These attempts motivated the researchers towards utilizing the emerging trends of deep learning with Kernel methods for building deep Kernel machines. Researchers integrate Kernel methods and deep learning networks for maintaining their advantages and make up their limitations, then apply the deep Kernel learning approaches for improving the performance of the learning algorithm in different applications. Different ways of building deep Kernel machines by integrating the Kernel methods and deep learning architectures include utilizing Kernel machines as the final classifier of deep learning networks, Kernelization in deep neural networks for better feature enrichment, and building deep Kernel machines by utilizing deep or multiple Kernels in different tasks. This survey attempts to provide an overview of different approaches in building several deep Kernel learning architectures for enhancing the learning algorithm properties and their performance in practical applications.},
  archive      = {J_PAAA},
  author       = {Nikhitha, Nair K. and Afzal, A. L. and Asharaf, S.},
  doi          = {10.1007/s10044-020-00933-1},
  journal      = {Pattern Analysis and Applications},
  month        = {5},
  number       = {2},
  pages        = {537-556},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Deep kernel machines: A survey},
  volume       = {24},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A hermite polynomial algorithm for detection of lesions in
lymphoma images. <em>PAAA</em>, <em>24</em>(2), 523–535. (<a
href="https://doi.org/10.1007/s10044-020-00927-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There are different types of lesions that can be investigated with the hematoxylin–eosin staining protocol. Lymphoma is a type of malignant disease which affects one of the highest white blood cell populations responsible for the immunological defence system. There are lymphoma sub-types that can have similar features, which make their diagnoses a difficult task. In this study, we investigated algorithms based on multiscale and multidimensional fractal geometry with colour models for classification of lymphoma images. Fractal features were extracted from the colour models and separate channels from these models. These features were concatenated to form feature vectors. Finally, we investigated the Hermite polynomial classifier and machine learning algorithms in order to evaluate the performance of the proposed approach. We employed the tenfold cross-validation method and evaluated the lesion sub-types with the binary and multiclass classifications. The separated colour channels obtained from histological images achieved relevant values for the binary and multiclass classifications, with an accuracy rating between 91 and 97%. These results can contribute to the detection and classification of the lesions by supporting specialists in clinical practices.},
  archive      = {J_PAAA},
  author       = {Martins, Alessandro S. and Neves, Leandro A. and de Faria, Paulo R. and Tosta, Thaína A. A. and Longo, Leonardo C. and Silva, Adriano B. and Roberto, Guilherme Freire and do Nascimento, Marcelo Z.},
  doi          = {10.1007/s10044-020-00927-z},
  journal      = {Pattern Analysis and Applications},
  month        = {5},
  number       = {2},
  pages        = {523-535},
  shortjournal = {Pattern Anal. Appl.},
  title        = {A hermite polynomial algorithm for detection of lesions in lymphoma images},
  volume       = {24},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Face spoofing detection via ensemble of classifiers toward
low-power devices. <em>PAAA</em>, <em>24</em>(2), 511–521. (<a
href="https://doi.org/10.1007/s10044-020-00937-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Facial biometrics tend to be spontaneous, instinctive and less human intrusive. It is regularly employed in the authentication of authorized users and personnel to protect data from violation attacks. A face spoofing attack usually comprises the illegal attempt to access valuable undisclosed information as a trespasser attempts to impersonate an individual holding desirable authentication clearance. In search of such violations, many investigators have devoted their efforts to studying either visual liveness detection or patterns generated during media recapture as predominant indicators to block spoofing violations. This work contemplates low-power devices through the aggregation of Fourier transforms, different classification methods and handcrafted descriptors to estimate whether face samples correspond to falsification attacks. To the best of our knowledge, the proposed method consists of low computational cost and is one of the few methods associating features derived from both spatial and frequency image domains. We conduct experiments on recent and well-known datasets under same and cross-database settings with artificial neural networks, support vector machines and partial least squares ensembles. Results show that although our methodology is geared for resource-limited single-board computers, it can produce significant results, outperforming state-of-the-art approaches.},
  archive      = {J_PAAA},
  author       = {Vareto, Rafael Henrique and Schwartz, William Robson},
  doi          = {10.1007/s10044-020-00937-x},
  journal      = {Pattern Analysis and Applications},
  month        = {5},
  number       = {2},
  pages        = {511-521},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Face spoofing detection via ensemble of classifiers toward low-power devices},
  volume       = {24},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Correction to: Simple and efficient pose-based gait
recognition method for challenging environments. <em>PAAA</em>,
<em>24</em>(2), 509. (<a
href="https://doi.org/10.1007/s10044-020-00945-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the original publication of the article, the Acknowledgements section was missed unfortunately. The correct Acknowledgements section is given in this correction.},
  archive      = {J_PAAA},
  author       = {Lima, Vítor C. de and Melo, Victor H. C. and Schwartz, William Robson},
  doi          = {10.1007/s10044-020-00945-x},
  journal      = {Pattern Analysis and Applications},
  month        = {5},
  number       = {2},
  pages        = {509},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Correction to: Simple and efficient pose-based gait recognition method for challenging environments},
  volume       = {24},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Simple and efficient pose-based gait recognition method for
challenging environments. <em>PAAA</em>, <em>24</em>(2), 497–507. (<a
href="https://doi.org/10.1007/s10044-020-00935-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gait is a biometry characterized by the identification of individuals by the way they walk. It is recently gaining evidence because it can be collected at distance and does not require subject cooperation, which is desirable on surveillance scenarios. Despite these advantages, the literature reports challenging situations where gait recognition is not accurate and although exist works that try to address these problems, most of them uses silhoettes, which carry appearance information that confounds with gait. Because of this limitation, a pose estimation method that use information of frames is employed for gait recognition and a multilayer perception, called PoseFrame, is created. As the focus of gait is the classification of a whole walking sequence, the results based on the frames are temporally aggregated for final classification. The method is tested on CASIA Dataset A, having accuracy above other pose-based works; and on CASIA Dataset B, achieving the best results in some situations. An ablation study is also performed, finding that the arms and feet are the most important body parts for gait recognition.},
  archive      = {J_PAAA},
  author       = {Lima, Vítor C. de and Melo, Victor H. C. and Schwartz, William R.},
  doi          = {10.1007/s10044-020-00935-z},
  journal      = {Pattern Analysis and Applications},
  month        = {5},
  number       = {2},
  pages        = {497-507},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Simple and efficient pose-based gait recognition method for challenging environments},
  volume       = {24},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Analysis of cancer in histological images: Employing an
approach based on genetic algorithm. <em>PAAA</em>, <em>24</em>(2),
483–496. (<a href="https://doi.org/10.1007/s10044-020-00931-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The analysis of histological images is based on visual assessment of tissues by specialists using an optical microscopy. This task can be time-consuming and challenging, mainly due to the complexity of the structures and diseases under investigation. These facts have motivated the development of computational methods to support specialists in research and decision-making. Despite the different computational strategies available in the literature, the solutions based on genetic algorithm have not been fully explored to provide the best combination of features, selection algorithms and classifiers. In this paper, we describe an approach based on genetic algorithm able to evaluate a significant number of features, selection methods and classifiers in order to provide an acceptable association for the diagnosis and pattern recognition of non-Hodgkin lymphomas and colorectal cancer. The chromosomal structure was represented with four genes. The evaluation and selection of individuals, as well as the crossover and mutation processes, were defined to distinguish the groups under investigation, with the highest AUC value and the smallest number of features. The tests were performed considering 1512 features from histological images, different population sizes and number of iterations. An initial population of 50 individuals and 50 iterations provided the best result (AUC value of 0.984) for the colorectal histological images. For non-Hodgkin lymphoma images, the best result (AUC value of 0.947) was obtained with a population of 500 individuals and 50 iterations. The proposed methodology with detailed information regarding the methods, features and best associations are relevant contributions for the community interested in the study of pattern recognition of colorectal cancer and lymphomas.},
  archive      = {J_PAAA},
  author       = {Taino, Daniela F. and Ribeiro, Matheus G. and Roberto, Guilherme F. and Zafalon, Geraldo F. D. and do Nascimento, Marcelo Z. and Tosta, Thaína A. A. and Martins, Alessandro S. and Neves, Leandro A.},
  doi          = {10.1007/s10044-020-00931-3},
  journal      = {Pattern Analysis and Applications},
  month        = {5},
  number       = {2},
  pages        = {483-496},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Analysis of cancer in histological images: Employing an approach based on genetic algorithm},
  volume       = {24},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Second-order motion descriptors for efficient action
recognition. <em>PAAA</em>, <em>24</em>(2), 473–482. (<a
href="https://doi.org/10.1007/s10044-020-00924-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human action recognition from realistic video data constitutes a challenging and relevant research area. Leading the state of the art we can find those methods based on convolutional neural networks (CNNs), and specially two-stream CNNs. In this family of deep architectures, the appearance channel learns from the RGB images and the motion channel learns from a motion representation, usually, the optical flow. Given that action recognition requires the extraction of complex motion patterns descriptors in image sequences, we introduce a new set of second-order motion representations capable of capturing both: geometrical and kinematic properties of the motion (curl, div, curvature, and acceleration). Besides, we present a new and effective strategy capable of reducing training times without sacrificing the performance when using the I3D two-stream CNN and robust to the weakness of a single channel. The experiments presented in this paper were carried out over two of the most challenging datasets for action recognition: UCF101 and HMDB51. Reported results show an improvement in accuracy over the UCF101 dataset where an accuracy of 98.45% is achieved when the curvature and acceleration are combined as a motion representation. For the HMDB51, our approach shows a competitive performance, achieving an accuracy of 80.19%. In both datasets, our approach shows a considerable reduction in time for the preprocessing and training phases. Preprocessing time is reduced to a sixth of the time while the training procedure for the motion stream can be performed in a third of the time usually employed.},
  archive      = {J_PAAA},
  author       = {Oves García, Reinier and Morales, Eduardo F. and Sucar, L. Enrique},
  doi          = {10.1007/s10044-020-00924-2},
  journal      = {Pattern Analysis and Applications},
  month        = {5},
  number       = {2},
  pages        = {473-482},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Second-order motion descriptors for efficient action recognition},
  volume       = {24},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Document scanners for minutiae-based palmprint recognition:
A feasibility study. <em>PAAA</em>, <em>24</em>(2), 459–472. (<a
href="https://doi.org/10.1007/s10044-020-00923-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Highly expensive capturing devices and barely existent high-resolution palmprint datasets have slowed the development of forensic palmprint biometric systems in comparison with civilian systems. These issues are addressed in this work. The feasibility of using document scanners as a cheaper option to acquire palmprints for minutiae-based matching systems is explored. A new high-resolution palmprint dataset was established using an industry-standard Green Bit MC517 scanner and an HP Scanjet G4010 document scanner. Furthermore, a new enhancement algorithm to attenuate the negative effect of creases in the process of minutiae extraction is proposed. Experimental results highlight the potentialities of document scanners for forensic applications. Advantages and disadvantages of both technologies are discussed in this context as well.},
  archive      = {J_PAAA},
  author       = {Aguado-Martínez, Manuel and Hernández-Palancar, José and Castillo-Rosado, Katy and Cupull-Gómez, Rodobaldo and Kauba, Christof and Kirchgasser, Simon and Uhl, Andreas},
  doi          = {10.1007/s10044-020-00923-3},
  journal      = {Pattern Analysis and Applications},
  month        = {5},
  number       = {2},
  pages        = {459-472},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Document scanners for minutiae-based palmprint recognition: A feasibility study},
  volume       = {24},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A convolutional oculomotor representation to model
parkinsonian fixational patterns from magnified videos. <em>PAAA</em>,
<em>24</em>(2), 445–457. (<a
href="https://doi.org/10.1007/s10044-020-00922-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Oculomotor alterations are a promising biomarker to detect and characterize Parkinson’s disease (PD), even in prodromal stages. Nowadays, however, only global and simplified gaze trajectories are used to approximate the complex interactions between neuromotor commands and ocular muscles. Besides, the acquisition of such signals often requires sophisticated calibration and invasive settings. This work presents a novel imaging biomarker for PD assessment that models ocular fixational movements, recorded with conventional cameras. Firstly, a video acceleration magnification is performed to enhance small relevant fixation patterns on standard gaze video recordings. Hence, from each video are extracted a set of spatio-temporal slices, which thereafter are represented as convolutional feature maps, recovered as the first-layer responses of pre-trained CNN architectures. The feature maps are then efficiently encoded by means of covariance matrices to train a support vector machine and perform the disease classification. From a set of 130 recordings of 13 PD patients and 13 age-matched controls, the proposed approach achieved an average accuracy of 95.4% and an AUC of 0.984, following a leave-one-patient-out cross-validation scheme. The proposed imaging-based descriptor properly captures known disease tremor patterns, since PD classification performance is outstanding when augmented motion frequencies were fixed within tremor-related ranges. These results suggest a successful PD characterization from fixational eye motion patterns using ordinary videos.},
  archive      = {J_PAAA},
  author       = {Salazar, Isail and Pertuz, Said and Contreras, William and Martínez, Fabio},
  doi          = {10.1007/s10044-020-00922-4},
  journal      = {Pattern Analysis and Applications},
  month        = {5},
  number       = {2},
  pages        = {445-457},
  shortjournal = {Pattern Anal. Appl.},
  title        = {A convolutional oculomotor representation to model parkinsonian fixational patterns from magnified videos},
  volume       = {24},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An ensemble of fingerprint matching algorithms based on
cylinder codes and mtriplets for latent fingerprint identification.
<em>PAAA</em>, <em>24</em>(2), 433–444. (<a
href="https://doi.org/10.1007/s10044-020-00911-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic latent fingerprint identification is beneficial during forensic investigations. Usually, latent fingerprint identification algorithms are used to find a subset of similar fingerprints from those previously captured on databases, which are finally examined by latent examiners. Yet, the identification rate achieved by latent fingerprint identification algorithms is far from those obtained by latent examiners. One approach for improving identification rates is the fusion of the match scores computed with fingerprint matching algorithms using a supervised classification algorithm. This approach fuses the results provided by different lower-level algorithms to improve them. Thus, we propose a fusion of fingerprint matching algorithms using a supervised classifier. Our proposal starts with two different local matching algorithms. We substitute their global matching algorithms with another independent of the local matching, creating two lower-level algorithms for fingerprint matching. Then, we combine the output of these lower-level algorithms using a supervised classifier. Our proposal achieves higher identification rates than each lower-level algorithm and their fusion using traditional approaches for most of the rank values and reference databases. Moreover, our fusion algorithm reaches a Rank-1 identification rate of $$74.03\%$$ and $$71.32\%$$ matching the 258 samples in the NIST SD27 database against 29,257 and 100,000 references, the two largest reference databases employed in our experiments.},
  archive      = {J_PAAA},
  author       = {Valdes-Ramirez, Danilo and Medina-Pérez, Miguel A. and Monroy, Raúl},
  doi          = {10.1007/s10044-020-00911-7},
  journal      = {Pattern Analysis and Applications},
  month        = {5},
  number       = {2},
  pages        = {433-444},
  shortjournal = {Pattern Anal. Appl.},
  title        = {An ensemble of fingerprint matching algorithms based on cylinder codes and mtriplets for latent fingerprint identification},
  volume       = {24},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-channel spectrograms for speech processing
applications using deep learning methods. <em>PAAA</em>, <em>24</em>(2),
423–431. (<a href="https://doi.org/10.1007/s10044-020-00921-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time–frequency representations of the speech signals provide dynamic information about how the frequency component changes with time. In order to process this information, deep learning models with convolution layers can be used to obtain feature maps. In many speech processing applications, the time–frequency representations are obtained by applying the short-time Fourier transform and using single-channel input tensors to feed the models. However, this may limit the potential of convolutional networks to learn different representations of the audio signal. In this paper, we propose a methodology to combine three different time–frequency representations of the signals by computing continuous wavelet transform, Mel-spectrograms, and Gammatone spectrograms and combining then into 3D-channel spectrograms to analyze speech in two different applications: (1) automatic detection of speech deficits in cochlear implant users and (2) phoneme class recognition to extract phone-attribute features. For this, two different deep learning-based models are considered: convolutional neural networks and recurrent neural networks with convolution layers.},
  archive      = {J_PAAA},
  author       = {Arias-Vergara, T. and Klumpp, P. and Vasquez-Correa, J. C. and Nöth, E. and Orozco-Arroyave, J. R. and Schuster, M.},
  doi          = {10.1007/s10044-020-00921-5},
  journal      = {Pattern Analysis and Applications},
  month        = {5},
  number       = {2},
  pages        = {423-431},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Multi-channel spectrograms for speech processing applications using deep learning methods},
  volume       = {24},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Classification among healthy, mild cognitive impairment and
alzheimer’s disease subjects based on wavelet entropy and relative beta
and theta power. <em>PAAA</em>, <em>24</em>(2), 413–422. (<a
href="https://doi.org/10.1007/s10044-020-00910-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Diagnosis of Alzheimer’s disease (AD), mild cognitive impairment (MCI), and healthy subjects (Healthy) is currently lacking an automated tool. It requires experience of neuropsychologists and has sensibilities of 80% when separating between Healthy and MCI. The aim of this work is to evaluate the performance of a method for classification among the three groups using a database of 17 Healthy, 9 MCI and 15 AD. The method uses wavelet decomposition of the EEG signal (Haar mother wavelet and 5 decomposition levels) to calculate the wavelet entropy and theta and beta relative power of the EEG signal. These features are used as inputs to a three-way classifier consisting in a support vector machine with polynomial kernel and a two-layer neural network. The last implements a vote procedure. Wavelet entropy was evaluated together with the sample entropy and approximated entropy to choose the one that best detected changes in the complexity of the EEG signal. The results show that it is possible to automatically classify a subject of a particular group with an overall accuracy of 92.6%, close to the best result found in the literature that is 97.9%. The method could be the basis for the implementation of a diagnosis-support quantitative tool oriented to aid in clinical diagnosis, especially when the classification between the three groups is not one of the more represented researches in the consulted literature.},
  archive      = {J_PAAA},
  author       = {Santos Toural, Jorge Esteban and Montoya Pedrón, Arquímedes and Marañón Reyes, Enrique Juan},
  doi          = {10.1007/s10044-020-00910-8},
  journal      = {Pattern Analysis and Applications},
  month        = {5},
  number       = {2},
  pages        = {413-422},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Classification among healthy, mild cognitive impairment and alzheimer’s disease subjects based on wavelet entropy and relative beta and theta power},
  volume       = {24},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Special issue of PAAA devoted to CIARP 2019. <em>PAAA</em>,
<em>24</em>(2), 409–411. (<a
href="https://doi.org/10.1007/s10044-020-00943-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_PAAA},
  author       = {Méndez-Vázquez, Heydi and Ruiz-Shulcloper, José},
  doi          = {10.1007/s10044-020-00943-z},
  journal      = {Pattern Analysis and Applications},
  month        = {5},
  number       = {2},
  pages        = {409-411},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Special issue of PAAA devoted to CIARP 2019},
  volume       = {24},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Wavelet domain majority coupled binary pattern: A new
descriptor for texture classification. <em>PAAA</em>, <em>24</em>(1),
393–408. (<a href="https://doi.org/10.1007/s10044-020-00907-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a new approach for texture classification called wavelet domain majority coupled binary pattern is proposed. Here, the single-level wavelet transform is applied which decomposes the image, resulting in wavelet coefficients. The wavelet coefficients present in all the four sub-bands are taken for further processing. The relationship of wavelet coefficients present at distances one, two and three is utilized. The average wavelet coefficients present at various distances are compared with the center wavelet coefficient of the local region, resulting in binary value. For each distance,  eight bit binary pattern is generated. Altogether, three distances yield three eight bit binary pattern. Then, the rule of majority is applied to the three  eight bit binary pattern and results in generation of proposed label. The proposed labels together contribute for the construction of histogram. Finally, the distance measure is used to identify the similarity between query and database images. Experimental results show that the proposed method achieves the average retrieval rate of 88.92% on Brodatz, 93.95% on Outex and 90.53% on Virus databases. This shows that the proposed method achieves good performance and outperforms other existing methods.},
  archive      = {J_PAAA},
  author       = {Nithya, S. and Ramakrishnan, S.},
  doi          = {10.1007/s10044-020-00907-3},
  journal      = {Pattern Analysis and Applications},
  month        = {2},
  number       = {1},
  pages        = {393-408},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Wavelet domain majority coupled binary pattern: A new descriptor for texture classification},
  volume       = {24},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Spatio-temporal adversarial learning for detecting unseen
falls. <em>PAAA</em>, <em>24</em>(1), 381–391. (<a
href="https://doi.org/10.1007/s10044-020-00901-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fall detection is an important problem from both the health and machine learning perspective. A fall can lead to severe injuries, long-term impairments or even death in some cases. In terms of machine learning, it presents a severely class imbalance problem with very few or no training data for falls owing to the fact that falls occur rarely. In this paper, we take an alternate philosophy to detect falls in the absence of their training data, by training the classifier on only the normal activities (that are available in abundance) and identifying a fall as an anomaly. To realize such a classifier, we use an adversarial learning framework, which comprises of a spatio-temporal autoencoder for reconstructing input video frames and a spatio-temporal convolution network to discriminate them against original video frames. 3D convolutions are used to learn spatial and temporal features from the input video frames. The adversarial learning of the spatio-temporal autoencoder will enable reconstructing the normal activities of daily living efficiently, thus rendering detecting unseen falls plausible within this framework. We tested the performance of the proposed framework on camera-sensing modalities that may preserve an individual’s privacy (fully or partially), such as thermal and depth camera. Our results on three publicly available datasets show that the proposed spatio-temporal adversarial framework performed better than other baseline frame-based (or spatial) adversarial learning methods.},
  archive      = {J_PAAA},
  author       = {Khan, Shehroz S. and Nogas, Jacob and Mihailidis, Alex},
  doi          = {10.1007/s10044-020-00901-9},
  journal      = {Pattern Analysis and Applications},
  month        = {2},
  number       = {1},
  pages        = {381-391},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Spatio-temporal adversarial learning for detecting unseen falls},
  volume       = {24},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An efficient global representation constrained by angular
triplet loss for vehicle re-identification. <em>PAAA</em>,
<em>24</em>(1), 367–379. (<a
href="https://doi.org/10.1007/s10044-020-00900-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vehicle re-identification is becoming an increasingly important problem in modern intelligent transportation systems. Substantial results have been achieved with methods based on deep metric learning. Most of the previous works tend to design complicated neural network models or utilize extra information. In this work, we introduce a simple Angular Triplet loss on the basis of analysis of different feature representations constrained by softmax loss and triplet loss. A batch normalization layer with zero bias is adopted to pass through the embedded feature before loss calculation. Then, triplet loss is calculated in cosine metric space instead of Euclidean space. In this way, triplet loss can cooperate with softmax consistently. By unifying the metric space of these two types of losses, the proposed method achieves 77.3% and 95.9% in rank-1 on VehicleID and VeRi-776 datasets, respectively. With only global features utilized, the proposed model can be seen as an effective baseline for vehicle re-identification task.},
  archive      = {J_PAAA},
  author       = {Gu, Jianyang and Jiang, Wei and Luo, Hao and Yu, Hongyan},
  doi          = {10.1007/s10044-020-00900-w},
  journal      = {Pattern Analysis and Applications},
  month        = {2},
  number       = {1},
  pages        = {367-379},
  shortjournal = {Pattern Anal. Appl.},
  title        = {An efficient global representation constrained by angular triplet loss for vehicle re-identification},
  volume       = {24},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Deep learning-based effective fine-grained weather
forecasting model. <em>PAAA</em>, <em>24</em>(1), 343–366. (<a
href="https://doi.org/10.1007/s10044-020-00898-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is well-known that numerical weather prediction (NWP) models require considerable computer power to solve complex mathematical equations to obtain a forecast based on current weather conditions. In this article, we propose a novel lightweight data-driven weather forecasting model by exploring temporal modelling approaches of long short-term memory (LSTM) and temporal convolutional networks (TCN) and compare its performance with the existing classical machine learning approaches, statistical forecasting approaches, and a dynamic ensemble method, as well as the well-established weather research and forecasting (WRF) NWP model. More specifically Standard Regression (SR), Support Vector Regression (SVR), and Random Forest (RF) are implemented as the classical machine learning approaches, and Autoregressive Integrated Moving Average (ARIMA), Vector Auto Regression (VAR), and Vector Error Correction Model (VECM) are implemented as the statistical forecasting approaches. Furthermore, Arbitrage of Forecasting Expert (AFE) is implemented as the dynamic ensemble method in this article. Weather information is captured by time-series data and thus, we explore the state-of-art LSTM and TCN models, which is a specialised form of neural network for weather prediction. The proposed deep model consists of a number of layers that use surface weather parameters over a given period of time for weather forecasting. The proposed deep learning networks with LSTM and TCN layers are assessed in two different regressions, namely multi-input multi-output and multi-input single-output. Our experiment shows that the proposed lightweight model produces better results compared to the well-known and complex WRF model, demonstrating its potential for efficient and accurate weather forecasting up to 12 h.},
  archive      = {J_PAAA},
  author       = {Hewage, Pradeep and Trovati, Marcello and Pereira, Ella and Behera, Ardhendu},
  doi          = {10.1007/s10044-020-00898-1},
  journal      = {Pattern Analysis and Applications},
  month        = {2},
  number       = {1},
  pages        = {343-366},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Deep learning-based effective fine-grained weather forecasting model},
  volume       = {24},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Simultaneous identification of points and circles: Structure
from motion system in industry scenes. <em>PAAA</em>, <em>24</em>(1),
333–342. (<a href="https://doi.org/10.1007/s10044-020-00889-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To address the issue of dynamic 3D circular features recognition in robot arm grasping, we propose a feature-based and incremental simultaneous points and circles structure from motion system. First, we represent the 3D target scene with sparse point cloud from multiple observations. The fundamental points construction pipeline combines the benefits of feature-based mapping and probabilistic depth estimation, which reduce the computational cost of generating practical 3D structures. Second, accurate 3D circles are extracted from the keyframes and are optimized in the backend. The circles construction pipeline attempts to find potential circles in the produced sparse point cloud and apply an adjusted level set method to do a novel 3D circle optimization process, which can work on keyframes smoothly. The integrated system is compared with other real-time construction systems and outperforms in industry scenes with more stable land-marks. Meanwhile the experimental results illustrate the ability of capturing circular features in target scenes.},
  archive      = {J_PAAA},
  author       = {Ni, Tao and Shi, Yukun and Sun, Anyu and Ju, Bingfeng},
  doi          = {10.1007/s10044-020-00889-2},
  journal      = {Pattern Analysis and Applications},
  month        = {2},
  number       = {1},
  pages        = {333-342},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Simultaneous identification of points and circles: Structure from motion system in industry scenes},
  volume       = {24},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Low-light enhancement based on an improved simplified
retinex model via fast illumination map refinement. <em>PAAA</em>,
<em>24</em>(1), 321–332. (<a
href="https://doi.org/10.1007/s10044-020-00908-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Low-light enhancement is an important post-image-processing technique, as it helps to reveal hidden details from dark image regions. In this paper, we propose a fast low-light enhancement model, which is robust to various lighting conditions and imaging noise, and is computationally efficient. By using a fusion-based simplified Retinex model, our model caters to different lighting conditions. In the model, we propose an edge-preserving filter to efficiently refine the estimated illumination map. We also extend our model by equipping it with a very simple denoising step, which effectively prevents the over-boosting of imaging noise in the dark regions. We conduct the experiments on public available images as well as the ones collected by ourselves. Visual and quantitative results validate the effectiveness of our model.},
  archive      = {J_PAAA},
  author       = {Hao, Shijie and Han, Xu and Zhang, Youming and Xu, Lei},
  doi          = {10.1007/s10044-020-00908-2},
  journal      = {Pattern Analysis and Applications},
  month        = {2},
  number       = {1},
  pages        = {321-332},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Low-light enhancement based on an improved simplified retinex model via fast illumination map refinement},
  volume       = {24},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Component-based face recognition using statistical pattern
matching analysis. <em>PAAA</em>, <em>24</em>(1), 299–319. (<a
href="https://doi.org/10.1007/s10044-020-00895-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The aim of this research is to develop a fusion concept to component-based face recognition algorithms for features analysis of binary facial components (BFCs), which are invariant to illumination, expression, pose variations and partial occlusion. To analyze the features, using statistical pattern matching concepts, which are the combination of Chi-square (CSQ), Hu moment invariants (HuMIs), absolute difference probability of white pixels (AbsDifPWPs) and geometric distance values (GDVs) have been proposed for face recognition. The individual grayscale face image is cropped by applying the Viola–Jones face detection algorithm from a face database having variations in illumination, appearance, pose and partial occlusion with complex backgrounds. Doing illumination correction through histogram linearization technique, the grayscale face components such as eyes, nose and mouth regions are extracted using the 2D geometric positions. The binary face image is created by applying cumulative probability distribution function with Otsu adaptive thresholding method and then extracted BFCs such as eyes, nose and mouth regions. Five statistical pattern matching tools such as the standard deviation of CSQ values with probability of white pixels (PWPs), standard deviation of HuMIs with Hu’s seven moment invariants, AbsDifPWPs and GDVs are developed for recognition purpose. GDVs are determined between two similar facial corner points (FCPs) and nine FCPs are extracted from binary whole face and BFCs. Pixel Intensity Values (PIVs) which are determined using L2 norms from grayscale values of the whole face and grayscale values of the face components. Experiment is performed using BioID Face Database on the basis of these pattern matching tools and appropriate threshold values with logical and conditional operators and gives the best expected results from true positive rate perspective.},
  archive      = {J_PAAA},
  author       = {Paul, Sushil Kumar and Bouakaz, Saida and Rahman, Chowdhury Mofizur and Uddin, Mohammad Shorif},
  doi          = {10.1007/s10044-020-00895-4},
  journal      = {Pattern Analysis and Applications},
  month        = {2},
  number       = {1},
  pages        = {299-319},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Component-based face recognition using statistical pattern matching analysis},
  volume       = {24},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Learning latent hash codes with discriminative structure
preserving for cross-modal retrieval. <em>PAAA</em>, <em>24</em>(1),
283–297. (<a href="https://doi.org/10.1007/s10044-020-00893-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the low storage cost and computational efficiency, hashing approaches have drawn considerable interest and gained great success in multimodal retrieval. However, most existing works study the local geometric structure in the original space, which suffers from intra- and inter-modality ambiguity, resulting in low discriminative hash codes. To address this issue, we propose a novel cross-modal hashing approach by taking inter- and intra-modality structure preserving into consideration, dubbed discriminative structure preserving hashing (DSPH). Specifically, DSPH explores the intra- and inter-modality in the latent structure of the constructed common space. In addition, the local geometric consistency is improved by a supervised shrinking scheme. DSPH learns the hash codes and latent features based on factorization coding scheme. The objective function includes common latent subspace learning and inter- &amp; intra-modality structure embedding. We devise an alternative optimization scheme, where the hash codes are solved by a bitwise scheme, and the large quantization error can be avoided. Owing to the merit of DSPH, more discriminative hash codes can be generated. The extensive experimental results on several widely used databases demonstrate that the proposed algorithm outperforms several state-of-art cross-media retrieval methods.},
  archive      = {J_PAAA},
  author       = {Zhang, Donglin and Wu, Xiao-Jun and Yu, Jun},
  doi          = {10.1007/s10044-020-00893-6},
  journal      = {Pattern Analysis and Applications},
  month        = {2},
  number       = {1},
  pages        = {283-297},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Learning latent hash codes with discriminative structure preserving for cross-modal retrieval},
  volume       = {24},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). PKM3: An optimal markov model for predicting future
navigation sequences of the web surfers. <em>PAAA</em>, <em>24</em>(1),
263–281. (<a href="https://doi.org/10.1007/s10044-020-00892-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predicting the browsing behavior of the user on the web has gained significant importance, as it improves the productivity of the website owners and also raises the interest of web users. The Markov model has been used immensely for user’s web navigation prediction. To enhance the coverage and accuracy of the Markov model, higher order Markov models are integrated with lower order models. However, this integration results in large state-space complexity. To reduce the state-space complexity, this paper proposes a novel technique, namely Pruned all-Kth modified Markov model (PKM3). PKM3 eliminates the irrelevant states from a higher order model, which have a negligible contribution toward prediction. The proposed model is evaluated on four standard weblogs: BMS, MSWEB, CTI and MSNBC. PKM3 performance was optimal for the website in which pages were closely placed and share high interlinking. This pruning-based optimal model achieves a significant reduction in state-space complexity while maintaining comparable accuracy.},
  archive      = {J_PAAA},
  author       = {Jindal, Honey and Sardana, Neetu},
  doi          = {10.1007/s10044-020-00892-7},
  journal      = {Pattern Analysis and Applications},
  month        = {2},
  number       = {1},
  pages        = {263-281},
  shortjournal = {Pattern Anal. Appl.},
  title        = {PKM3: An optimal markov model for predicting future navigation sequences of the web surfers},
  volume       = {24},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An efficient generic approach for automatic taxonomy
generation using HMMs. <em>PAAA</em>, <em>24</em>(1), 243–262. (<a
href="https://doi.org/10.1007/s10044-020-00918-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Taxonomies are essential tools for fast information retrieval and classification of knowledge. Many existing techniques for automatic taxonomy generation strongly depend on the specific properties of a particular domain and are consequently hard to apply to other domains. Some attempts have been made to design taxonomies for multiple domains. Unfortunately, they induce high hierarchical classification error rates for some datasets. The automatic design of a taxonomy requires the capability of measuring the similarity between classes. More precisely, the fact that two classes are near intuitively implies that some elements of one class are scattered in the neighborhood of some elements of the other class. This observation is used in this paper to propose a new generic technique for automatic taxonomy generation. A topological analysis of the neighborhood of each instance is first performed. The results of this analysis are used to initialize and train a hidden Markov model for each class. The model of a given class c captures the frequencies of the classes found in the neighborhood of the instances of c, from the most dominant class to the least dominant. The similarities between these models are finally used to derive a taxonomy. Hierarchical classification experiments realized on 20 datasets from various domains showed an average accuracy of $$97.22\%$$ and a standard deviation of $$4.11\%$$ . Comparison results revealed that the proposed approach outperforms existing work with accuracy gains reaching $$38.62\%$$ for one dataset.},
  archive      = {J_PAAA},
  author       = {Iloga, Sylvain and Romain, Olivier and Tchuenté, Maurice},
  doi          = {10.1007/s10044-020-00918-0},
  journal      = {Pattern Analysis and Applications},
  month        = {2},
  number       = {1},
  pages        = {243-262},
  shortjournal = {Pattern Anal. Appl.},
  title        = {An efficient generic approach for automatic taxonomy generation using HMMs},
  volume       = {24},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Efficient integration of generative topic models into
discriminative classifiers using robust probabilistic kernels.
<em>PAAA</em>, <em>24</em>(1), 217–241. (<a
href="https://doi.org/10.1007/s10044-020-00917-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose an alternative to the generative classifier that usually models both the class conditionals and class priors separately, and then uses the Bayes theorem to compute the posterior distribution of classes given the training set as a decision boundary. Because SVM (support vector machine) is not a probabilistic framework, it is really difficult to implement a direct posterior distribution-based discriminative classifier. As SVM lacks in full Bayesian analysis, we propose a hybrid (generative–discriminative) technique where the generative topic features from a Bayesian learning are fed to the SVM. The standard latent Dirichlet allocation topic model with its Dirichlet (Dir) prior could be defined as Dir–Dir topic model to characterize the Dirichlet placed on the document and corpus parameters. With very flexible conjugate priors to the multinomials such as generalized Dirichlet (GD) and Beta-Liouville (BL) in our proposed approach, we define two new topic models: the BL–GD and GD–BL. We take advantage of the geometric interpretation of our generative topic (latent) models that associate a K-dimensional manifold (K is the size of the topics) embedded into a V-dimensional feature space (word simplex) where V is the vocabulary size. Under this structure, the low-dimensional topic simplex (the subspace) defines a document as a single point on its manifold and associates each document with a single probability. The SVM, with its kernel trick, performs on these document probabilities in classification where it utilizes the maximum margin learning approach as a decision boundary. The key note is that points or documents that are close to each other on the manifold must belong to the same class. Experimental results with text documents and images show the merits of the proposed framework.},
  archive      = {J_PAAA},
  author       = {Ihou, Koffi Eddy and Bouguila, Nizar and Bouachir, Wassim},
  doi          = {10.1007/s10044-020-00917-1},
  journal      = {Pattern Analysis and Applications},
  month        = {2},
  number       = {1},
  pages        = {217-241},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Efficient integration of generative topic models into discriminative classifiers using robust probabilistic kernels},
  volume       = {24},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A new feature selection using dynamic interaction.
<em>PAAA</em>, <em>24</em>(1), 203–215. (<a
href="https://doi.org/10.1007/s10044-020-00916-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the continuous development of Internet technology, data gradually present a complicated and high-dimensional trend. These high-dimensional data have a large number of redundant features and irrelevant features, which bring great challenges to the existing machine learning algorithms. Feature selection is one of the important research topics in the fields of machine learning, pattern recognition and data mining, and it is also an important means in the data preprocessing stage. Feature selection is to look for the optimal feature subset from the original feature set, which would improve the classification accuracy and reduce the machine learning time. The traditional feature selection algorithm tends to ignore the kind of feature which has a weak distinguishing capacity as a monomer, whereas the feature group’s distinguishing capacity is strong. Therefore, a new dynamic interaction feature selection (DIFS) algorithm is proposed in this paper. Initially, under the theoretical framework of interactive information, it redefines the relevance, irrelevance and redundancy of the features. Secondly, it offers the computational formulas for calculating interactive information. Finally, under the eleven data sets of UCI and three different classifiers, namely, KNN, SVM and C4.5, the DIFS algorithm increases the classification accuracy of the FullSet by 3.2848% and averagely decreases the number of features selected by 15.137. Hence, the DIFS algorithm can not only identify the relevance feature effectively, but also identify the irrelevant and redundant features. Moreover, it can effectively improve the classification accuracy of the data sets and reduce the feature dimensions of the data sets.},
  archive      = {J_PAAA},
  author       = {Li, Zhang},
  doi          = {10.1007/s10044-020-00916-2},
  journal      = {Pattern Analysis and Applications},
  month        = {2},
  number       = {1},
  pages        = {203-215},
  shortjournal = {Pattern Anal. Appl.},
  title        = {A new feature selection using dynamic interaction},
  volume       = {24},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Seismicity analysis using space-time density peak clustering
method. <em>PAAA</em>, <em>24</em>(1), 181–201. (<a
href="https://doi.org/10.1007/s10044-020-00913-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents two-stage clustering approach for accurate analysis of earthquake catalogs where aim is to categorize events in terms of aftershock (AF) clusters or independent backgrounds (BGs). In stage I, the Gaussian kernel-based temporal density estimation is used for grouping of events based on their occurrence time. From the graph, local peak (maxima), local minima and their timing information are utilized to group the events into significant time zones. In stage II, on events of each time zone, coordinate and magnitude information is combined together (weighted mechanism) to determine effective local weighted spatial density ( $$\rho ^{\mathrm{w}}$$ ). Based on $$\rho ^{\mathrm{w}}$$ and event distance ( $$\delta$$ ), a decision graph is drawn to find out the spatial cluster centroids for each time zone. Event’s assignment to the centroid is carried out based on its nearest neighbor of higher density. Outliers (non-clustered) are also detected in stage II which is considered as independent backgrounds. The experimental analysis is carried out on historical seismicity of California, Himalaya, Japan and Sumatra–Andaman region. The results indicate that obtained AFs and total number of events follow a similar cumulative and $$\lambda$$ rate, whereas BGs have linear cumulative and consistent $$\lambda$$ rate. It is also observed that AFs and total events have similar ergodic behavior, quantified from the inverse TM metric plot. The competitive performance of the proposed approach is obtained over state-of-the-art declustering methods.},
  archive      = {J_PAAA},
  author       = {Vijay, Rahul Kumar and Nanda, Satyasai Jagannath},
  doi          = {10.1007/s10044-020-00913-5},
  journal      = {Pattern Analysis and Applications},
  month        = {2},
  number       = {1},
  pages        = {181-201},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Seismicity analysis using space-time density peak clustering method},
  volume       = {24},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Deep learning-based data augmentation method and signature
verification system for offline handwritten signature. <em>PAAA</em>,
<em>24</em>(1), 165–179. (<a
href="https://doi.org/10.1007/s10044-020-00912-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Offline handwritten signature verification is a challenging pattern recognition task. One of the most significant limitations of the handwritten signature verification problem is inadequate data for training phases. Due to this limitation, deep learning methods that have obtained the state-of-the-art results in many areas achieve quite unsuccessful results when applied to signature verification. In this study, a new use of Cycle-GAN is proposed as a data augmentation method to address the inadequate data problem on signature verification. We also propose a novel signature verification system based on Caps-Net. The proposed data augmentation method is tested on four different convolutional neural network (CNN) methods, VGG16, VGG19, ResNet50, and DenseNet121, which are widely used in the literature. The method has provided a significant contribution to all mentioned CNN methods’ success. The proposed data augmentation method has the best effect on the DenseNet121. We also tested our data augmentation method with the proposed signature verification system on two widely used databases: GPDS and MCYT. Compared to other studies, our verification system achieved the state-of-the-art results on MCYT database, while it reached the second-best verification result on GPDS.},
  archive      = {J_PAAA},
  author       = {Yapıcı, Muhammed Mutlu and Tekerek, Adem and Topaloğlu, Nurettin},
  doi          = {10.1007/s10044-020-00912-6},
  journal      = {Pattern Analysis and Applications},
  month        = {2},
  number       = {1},
  pages        = {165-179},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Deep learning-based data augmentation method and signature verification system for offline handwritten signature},
  volume       = {24},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). AFDL: A new adaptive fuzzy dictionary learning for medical
image classification. <em>PAAA</em>, <em>24</em>(1), 145–164. (<a
href="https://doi.org/10.1007/s10044-020-00909-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sparse coding allows the representation of complex data as a linear combination of basis sparse vectors (alternatively called atoms or codewords), a collection of which constitutes a dictionary. Dictionary learning is a learning process aimed at finding a small number of optimal basis vectors for a more accurate representation of the original data. The existing dictionary learning methods do not address the inherent uncertainty of the input data in their learning processes. To compensate for the uncertainty, and to obtain a flexible and effective learning system, we introduce a new adaptive fuzzy dictionary learning (AFDL) method for image classification purposes. The new method iteratively alternates between sparse coding based on a given dictionary and an adaptive fuzzy dictionary learning approach to learn (improve) dictionary atoms. The adjustability of the dictionary and coefficients vectors, in this method, provide us a more accurate and straight representation of input data. AFDL was applied on magnetic resonance images from the cancer image archive datasets, for medical image classification of cancer tumors. Finally, the overall experimental results clearly show that our approach outperforms its rival techniques in terms of accuracy, sensitivity, and specificity. Convergence speed in the experimental results shows that AFDL can achieve its acceptable precision in a reasonable time.},
  archive      = {J_PAAA},
  author       = {Ghasemi, Majid and Kelarestaghi, Manoochehr and Eshghi, Farshad and Sharifi, Arash},
  doi          = {10.1007/s10044-020-00909-1},
  journal      = {Pattern Analysis and Applications},
  month        = {2},
  number       = {1},
  pages        = {145-164},
  shortjournal = {Pattern Anal. Appl.},
  title        = {AFDL: A new adaptive fuzzy dictionary learning for medical image classification},
  volume       = {24},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Eccentricity based kinship verification from facial images
in the wild. <em>PAAA</em>, <em>24</em>(1), 119–144. (<a
href="https://doi.org/10.1007/s10044-020-00906-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Kinship verification from facial images in the wild is a promising research aiming to identify whether a facial image pair shares kinship relation by analyzing face structures. This paper proposes a novel eccentricity-based kinship verification (EKV) method to demonstrate efficacy of dominant facial sections for kinship verification. The proposed EKV method uses eccentricity of ellipse-approximated dominant facial sections as discriminative parameter to perform kinship verification. It presents two different schemes, namely single eccentricity (SE) and fused eccentricity (FE). SE scheme for EKV method employs single formulation by considering single facial section. Each selected facial section is approximated as an ellipse to compute eccentricity parameter and perform verification. Next, FE scheme for EKV method employs multiview formulation by analyzing two or more facial sections. Eccentricity of different ellipse-approximated facial sections is computed and fused to form a transformed parameter and perform verification. The proposed EKV method is demonstrated on different available kinship databases. Experimental results showcase effectiveness of EKV method with the best and competitive accuracy obtained for FE scheme on different databases.},
  archive      = {J_PAAA},
  author       = {Goyal, Aarti and Meenpal, Toshanlal},
  doi          = {10.1007/s10044-020-00906-4},
  journal      = {Pattern Analysis and Applications},
  month        = {2},
  number       = {1},
  pages        = {119-144},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Eccentricity based kinship verification from facial images in the wild},
  volume       = {24},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Two-dimensional subclass discriminant analysis for face
recognition. <em>PAAA</em>, <em>24</em>(1), 109–117. (<a
href="https://doi.org/10.1007/s10044-020-00905-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dimensionality reduction plays a major role in face recognition. Discriminant analysis (DA) and principal component analysis (PCA) are two of the most important approaches in this field. In particular, subclass discriminant analysis (SDA) is a well-known scheme for feature extraction and dimensionality reduction. It is widely used in many high-dimensional data-driven applications, namely face recognition and image retrieval. It is also found to be applicable under various scenarios. However, it has high cost in time and space given the need for an eigendecomposition involving the scatter matrices, known as the singularity problem. This limitation is caused by the high-dimensional space of data, particularly when dimensions exceed the number of observations. Recent advances widely reported that 2D methods with matrix-based representation perform better than the traditional 1D vector-based ones. In this paper, we propose a novel 2D-SDA algorithm to avoid the “curse of dimensionality” and address the singularity issue. The performance of the proposed algorithm is evaluated for face recognition in terms of recognition performance and computational cost. Experiments are conducted on four benchmark face databases and compared to several competitive 1D and 2D methods based on PCA and DA. Results show that 2DSVD achieves the best recognition performance at low dimensions. In particular, 2D-SDA works significantly better on large-sized data sets where intra-class variation is the most important.},
  archive      = {J_PAAA},
  author       = {Nakouri, Haïfa},
  doi          = {10.1007/s10044-020-00905-5},
  journal      = {Pattern Analysis and Applications},
  month        = {2},
  number       = {1},
  pages        = {109-117},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Two-dimensional subclass discriminant analysis for face recognition},
  volume       = {24},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Gestalt descriptions for deep image understanding.
<em>PAAA</em>, <em>24</em>(1), 89–107. (<a
href="https://doi.org/10.1007/s10044-020-00904-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we present a novel visual perception-inspired local description approach as a preprocessing step for deep learning. With the ongoing growth of visual data, efficient image descriptor methods are becoming more and more important. Several local point-based description methods were defined in the past decades before the highly accurate and popular deep learning methods such as convolutional neural networks (CNNs) emerged. The method presented in this work combines a novel local description approach inspired by the Gestalt laws with deep learning, and thereby, it benefits from both worlds. To test our method, we conducted several experiments on different datasets of various forensic application domains, e.g., makeup-robust face recognition. Our results show that the proposed approach is robust against overfitting and only little image information is necessary to classify the image content with high accuracy. Furthermore, we compared our experimental results to state-of-the-art description methods and found that our method is highly competitive. For example it outperforms a conventional CNN in terms of accuracy in the domain of makeup-robust face recognition.},
  archive      = {J_PAAA},
  author       = {Hörhan, Markus and Eidenberger, Horst},
  doi          = {10.1007/s10044-020-00904-6},
  journal      = {Pattern Analysis and Applications},
  month        = {2},
  number       = {1},
  pages        = {89-107},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Gestalt descriptions for deep image understanding},
  volume       = {24},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Nonparametric “anti-bayesian” quantile-based pattern
classification. <em>PAAA</em>, <em>24</em>(1), 75–87. (<a
href="https://doi.org/10.1007/s10044-020-00903-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Parametric and nonparametric pattern recognition have been studied for almost a century based on a Bayesian paradigm, which is, in turn, founded on the principles of Bayes theorem. It is well known that the accuracy of the Bayes classifier cannot be exceeded. Typically, this reduces to comparing the testing sample to mean or median of the respective distributions. Recently, Oommen and his co-authors have presented a pioneering and non-intuitive paradigm, namely that of achieving the classification by comparing the testing sample with another descriptor, which could also be quite distant from the mean. This paradigm has been termed as being “anti-Bayesian,” and it essentially uses the quantiles of the distributions to achieve the pattern recognition. Such classifiers attain the optimal Bayesian accuracy for symmetric distributions even though they operate with a non-intuitive philosophy. While this paradigm has been applied in a number of domains (briefly explained in the body of this paper), its application for nonparametric domains has been limited. This paper explains, in detail, how such quantile-based classification can be extended to the nonparametric world, using both traditional and kernel-based strategies. The paper analyzes the methodology of such nonparametric schemes and their robustness. From a fundamental perspective, the paper utilizes the so-called large sample theory to derive strong asymptotic results that pertain to the equivalence between the parametric and nonparametric schemes for large samples. Apart from the new theoretical results, the paper also presents experimental results demonstrating their power. These results pertain to artificial data sets and also involve a real-life breast cancer data set obtained from the University Hospital Centre of Coimbra. The experimental results clearly confirm the power of the proposed “anti-Bayesian” procedure, especially when approached from a nonparametric perspective.},
  archive      = {J_PAAA},
  author       = {Mahmoudi, Fatemeh and Razmkhah, Mostafa and Oommen, B. John},
  doi          = {10.1007/s10044-020-00903-7},
  journal      = {Pattern Analysis and Applications},
  month        = {2},
  number       = {1},
  pages        = {75-87},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Nonparametric “anti-bayesian” quantile-based pattern classification},
  volume       = {24},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Ternary tree-based structural twin support tensor machine
for clustering. <em>PAAA</em>, <em>24</em>(1), 61–74. (<a
href="https://doi.org/10.1007/s10044-020-00902-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most of the real-life applications usually involve complex data, e.g., grayscale images, where information is distributed spatially in the form of two-dimensional matrices (elements of second-order tensor space). Traditional vector-based clustering models such as k-means and support vector clustering rely on low-dimensional features representations for identifying patterns and are prone to loss of useful information which is present in spatial structure of the data. To overcome this limitation, tensor-based clustering models can be utilized for identifying relevant patterns in matrix data as they take advantage of structural information present in multi-dimensional framework and reduce computational overheads as well. However, despite these numerous advantages, tensor clustering has still remained relatively unexplored research area. In this paper, we propose a novel clustering framework, termed as Ternary Tree-based Structural Least Squares Support Tensor Clustering (TT-SLSTWSTC), that builds a cluster model as a hierarchical ternary tree, where at each node non-ambiguous data are dealt separately from ambiguous data points using the proposed Ternary Structural Least Squares Support Tensor Machine (TS-LSTWSTM). The TS-LSTWSTM classifier considers the structural risk minimization of data alongside a symmetrical L2-norm loss function. Also, initialization framework based on tensor k-means has been used in order to overcome the instability disseminated by random initialization. To validate the efficacy of the proposed framework, computational experiments have been performed on human activity recognition and image recognition problems. Experimental results show that our method is not only fast but yields significantly better generalization performance and is comparatively more robust in order to handle heteroscedastic noise and outliers when compared to related methods.},
  archive      = {J_PAAA},
  author       = {Rastogi, Reshma and Sharma, Sweta},
  doi          = {10.1007/s10044-020-00902-8},
  journal      = {Pattern Analysis and Applications},
  month        = {2},
  number       = {1},
  pages        = {61-74},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Ternary tree-based structural twin support tensor machine for clustering},
  volume       = {24},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Effectiveness of symmetric rejection for a secure and user
convenient multistage biometric system. <em>PAAA</em>, <em>24</em>(1),
49–60. (<a href="https://doi.org/10.1007/s10044-020-00899-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A multistage biometric verification system uses multiple biometrics and/or multiple biometric verifiers to generate a verification decision. The core of a multistage biometric verification system is reject option which allows a stage not to give a genuine/impostor decision when it is not confident enough. This paper studies the effectiveness of symmetric rejection for multistage biometric verification systems. The symmetric rejection method determines the reject region by symmetrically rejecting equal proportion of genuine and impostor scores. The applicability of a multistage biometric verification system depends on how secure and user convenient it is, which is measured by the performance–cost trade-off. This paper analyzes the performance–cost trade-off of symmetric rejection method by conducting extensive experiments. Experiments are performed on two biometric databases: (1) publicly available NIST database and (2) a keystroke database. In addition, the symmetric rejection method is empirically compared with two existing rejection methods: (1) sequential probability ratio test-based method, which uses score-fusion and (2) Marcialis et al.’s method, which does not use score fusion. Results demonstrate strong effect of symmetric rejection method on creating a secure and user convenient multistage biometric verification system.},
  archive      = {J_PAAA},
  author       = {Hossain, Md S. and Balagani, Kiran S. and Phoha, Vir V.},
  doi          = {10.1007/s10044-020-00899-0},
  journal      = {Pattern Analysis and Applications},
  month        = {2},
  number       = {1},
  pages        = {49-60},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Effectiveness of symmetric rejection for a secure and user convenient multistage biometric system},
  volume       = {24},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). High-dimensional cluster boundary detection using directed
markov tree. <em>PAAA</em>, <em>24</em>(1), 35–47. (<a
href="https://doi.org/10.1007/s10044-020-00897-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hypersurface of an inscribed geometry decides the distribution of an embedded cluster, in which its boundary points approximately fit this surface. To detect these points, capturing the implicit features of a local space is used to distinguish whether the data is an inner or outer feature. However, this approximation on the boundary is coarse-grained and may be ineffective in a high-dimensional space due to unbalanced feature distribution. In this paper, we introduce a directed Markov tree in high-dimensional cluster boundary detection. The key idea is to project each one-dimensional subspace of a local high-dimensional feature space into a layer of a directed Markov tree, covering absorptive and reflective walls. We then derive a fine-grained detection coefficient against on the Markov process of knight’s tour over each layer of the tree. In this fine-grained view, the local feature space centered with a cluster boundary point has lower estimate on the tour cost than the internal data of the cluster. Based on this observation, we propose a knight algorithm to detect the boundary points of a high-dimensional feature space. Experiments on gene expression and video retrieval datasets demonstrate that the proposed algorithm can achieve a higher F-measure score than the other boundary detection baselines.},
  archive      = {J_PAAA},
  author       = {Cao, Xiaofeng},
  doi          = {10.1007/s10044-020-00897-2},
  journal      = {Pattern Analysis and Applications},
  month        = {2},
  number       = {1},
  pages        = {35-47},
  shortjournal = {Pattern Anal. Appl.},
  title        = {High-dimensional cluster boundary detection using directed markov tree},
  volume       = {24},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Substep active deep learning framework for image
classification. <em>PAAA</em>, <em>24</em>(1), 23–34. (<a
href="https://doi.org/10.1007/s10044-020-00894-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In image classification, the acquisition of images labels is often expensive and time-consuming. To reduce this labeling cost, active learning is introduced into this field. Although some active learning algorithms have been proposed, they are all single-sampling strategies or combined with multiple-sampling strategies simultaneously (i.e., correlation, uncertainty and label-based measure), without considering the relationship between substep sampling strategies. To this end, we designed a new active learning scheme called substep active deep learning (SADL) for image classification. In SADL, samples were selected by correlation strategy and then determined by the uncertainty and label-based measurement. Finally, it is fed to CNN model training. Experiments were performed with three data sets (i.e., MNIST, Fashion-MNIST and CIFAR-10) to compare against state-of-the-art active learning algorithms, and it can be verified that our substep active deep learning is rational and effective.},
  archive      = {J_PAAA},
  author       = {Li, Guoqiang and Gong, Ning},
  doi          = {10.1007/s10044-020-00894-5},
  journal      = {Pattern Analysis and Applications},
  month        = {2},
  number       = {1},
  pages        = {23-34},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Substep active deep learning framework for image classification},
  volume       = {24},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Correction to: Deep kernel learning in extreme learning
machines. <em>PAAA</em>, <em>24</em>(1), 21. (<a
href="https://doi.org/10.1007/s10044-020-00944-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the original publication of the article, the Acknowledgements section was missed unfortunately. The correct Acknowledgements section is given in this correction.},
  archive      = {J_PAAA},
  author       = {Afzal, A. L. and Nair, Nikhitha K. and Asharaf, S.},
  doi          = {10.1007/s10044-020-00944-y},
  journal      = {Pattern Analysis and Applications},
  month        = {2},
  number       = {1},
  pages        = {21},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Correction to: Deep kernel learning in extreme learning machines},
  volume       = {24},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Deep kernel learning in extreme learning machines.
<em>PAAA</em>, <em>24</em>(1), 11–19. (<a
href="https://doi.org/10.1007/s10044-020-00891-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Emergence of extreme learning machine as a breakneck learning algorithm has marked its prominence in solitary hidden layer feed-forward networks. Kernel-based extreme learning machine (KELM) reflected its efficiency in diverse applications where feature mapping functions of hidden nodes are concealed from users. The conventional KELM algorithms involve only solitary layer of kernels, thereby emulating shallow learning architectures for its feature transformation. Trend in migrating shallow-based learning models into deep learning architectures opens up a new outlook for machine learning domains. This paper attempts to bestow deep kernel learning approach in a conventional shallow architecture. The emerging arc-cosine kernels possess the potential to mimic the prevailing deep layered frameworks to a greater extent. Unlike other kernels such as linear, polynomial and Gaussian, arc-cosine kernels have a recursive nature by itself and have the potential to express multilayer computation in learning models. This paper explores the possibility of building a new deep kernel machine with extreme learning machine and multilayer arc-cosine kernels. This framework outperforms conventional KELM and deep support vector machine in terms of training time and accuracy.},
  archive      = {J_PAAA},
  author       = {Afzal, A. L. and Nair, Nikhitha K. and Asharaf, S.},
  doi          = {10.1007/s10044-020-00891-8},
  journal      = {Pattern Analysis and Applications},
  month        = {2},
  number       = {1},
  pages        = {11-19},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Deep kernel learning in extreme learning machines},
  volume       = {24},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Content-based image retrieval using feature weighting and
c-means clustering in a multi-label classification framework.
<em>PAAA</em>, <em>24</em>(1), 1–10. (<a
href="https://doi.org/10.1007/s10044-020-00887-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a novel learning algorithm based on feature weighting is proposed to improve the performance of image classification or retrieval systems in a multi-label framework. The goal is to exploit maximally the beneficial properties of each feature in the system. Since each feature can separate more effectively some of the image classes, it is hypothesized that the weights of various features at some states can be traded off against each other. The training phase of the suggested algorithm is performed in two stages: (1) The input images are clustered using a supervised C-means method iteratively; (2) image features are weighted using a local feature weighting method in each cluster. These weights are determined by considering the importance of each feature in minimizing the classification error on each cluster. In the testing phase, the cluster corresponding to the query is found first. Then, the most similar images are retrieved in the multi-label framework using the feature weights assigned to that cluster. Experimental results on three well-known, public and international image datasets demonstrate that our proposed method leads to significant performance gains over existing methods.},
  archive      = {J_PAAA},
  author       = {Ghodratnama, Samaneh and Abrishami Moghaddam, Hamid},
  doi          = {10.1007/s10044-020-00887-4},
  journal      = {Pattern Analysis and Applications},
  month        = {2},
  number       = {1},
  pages        = {1-10},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Content-based image retrieval using feature weighting and C-means clustering in a multi-label classification framework},
  volume       = {24},
  year         = {2021},
}
</textarea>
</details></li>
</ul>

</body>
</html>
