<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>FoCM_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="focm---40">FoCM - 40</h2>
<ul>
<li><details>
<summary>
(2021). Complexes from complexes. <em>FoCM</em>, <em>21</em>(6),
1739–1774. (<a
href="https://doi.org/10.1007/s10208-021-09498-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is concerned with the derivation and properties of differential complexes arising from a variety of problems in differential equations, with applications in continuum mechanics, relativity, and other fields. We present a systematic procedure which, starting from well-understood differential complexes such as the de Rham complex, derives new complexes and deduces the properties of the new complexes from the old. We relate the cohomology of the output complex to that of the input complexes and show that the new complex has closed ranges, and, consequently, satisfies a Hodge decomposition, Poincaré-type inequalities, well-posed Hodge–Laplacian boundary value problems, regular decomposition, and compactness properties on general Lipschitz domains.},
  archive      = {J_FoCM},
  author       = {Arnold, Douglas N. and Hu, Kaibo},
  doi          = {10.1007/s10208-021-09498-9},
  journal      = {Foundations of Computational Mathematics},
  number       = {6},
  pages        = {1739-1774},
  shortjournal = {Found. Comput. Math.},
  title        = {Complexes from complexes},
  volume       = {21},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Newton polytopes and relative entropy optimization.
<em>FoCM</em>, <em>21</em>(6), 1703–1737. (<a
href="https://doi.org/10.1007/s10208-021-09497-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Certifying function nonnegativity is a ubiquitous problem in computational mathematics, with especially notable applications in optimization. We study the question of certifying nonnegativity of signomials based on the recently proposed approach of Sums-of-AM/GM-Exponentials (SAGE) decomposition due to the second author and Shah. The existence of a SAGE decomposition is a sufficient condition for nonnegativity of a signomial, and it can be verified by solving a tractable convex relative entropy program. We present new structural properties of SAGE certificates such as a characterization of the extreme rays of the cones associated to these decompositions as well as an appealing form of sparsity preservation. These lead to a number of important consequences such as conditions under which signomial nonnegativity is equivalent to the existence of a SAGE decomposition; our results represent the broadest-known class of nonconvex signomial optimization problems that can be solved efficiently via convex relaxation. The analysis in this paper proceeds by leveraging the interaction between the convex duality underlying SAGE certificates and the face structure of Newton polytopes. After proving our main signomial results, we direct our machinery toward the topic of globally nonnegative polynomials. This leads to (among other things) efficient methods for certifying polynomial nonnegativity, with complexity independent of the degree of a polynomial.},
  archive      = {J_FoCM},
  author       = {Murray, Riley and Chandrasekaran, Venkat and Wierman, Adam},
  doi          = {10.1007/s10208-021-09497-w},
  journal      = {Foundations of Computational Mathematics},
  number       = {6},
  pages        = {1703-1737},
  shortjournal = {Found. Comput. Math.},
  title        = {Newton polytopes and relative entropy optimization},
  volume       = {21},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Optimal artificial boundary condition for random elliptic
media. <em>FoCM</em>, <em>21</em>(6), 1643–1702. (<a
href="https://doi.org/10.1007/s10208-021-09492-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We are given a uniformly elliptic coefficient field that we regard as a realization of a stationary and finite-range ensemble of coefficient fields. Given a right-hand side supported in a ball of size $$\ell \gg 1$$ and of vanishing average, we are interested in an algorithm to compute the solution near the origin, just using the knowledge of the given realization of the coefficient field in some large box of size $$L\gg \ell $$ . More precisely, we are interested in the most seamless artificial boundary condition on the boundary of the computational domain of size L. Motivated by the recently introduced multipole expansion in random media, we propose an algorithm. We rigorously establish an error estimate on the level of the gradient in terms of $$L\gg \ell \gg 1$$ , using recent results in quantitative stochastic homogenization. More precisely, our error estimate has an a priori and an a posteriori aspect: with a priori overwhelming probability, the prefactor can be bounded by a constant that is computable without much further effort, on the basis of the given realization in the box of size L. We also rigorously establish that the order of the error estimate in both L and $$\ell $$ is optimal, where in this paper we focus on the case of $$d=2$$ . This amounts to a lower bound on the variance of the quantity of interest when conditioned on the coefficients inside the computational domain, and relies on the deterministic insight that a sensitivity analysis with respect to a defect commutes with stochastic homogenization. Finally, we carry out numerical experiments that show that this optimal convergence rate already sets in at only moderately large L, and that more naive boundary conditions perform worse both in terms of rate and prefactor.},
  archive      = {J_FoCM},
  author       = {Lu, Jianfeng and Otto, Felix},
  doi          = {10.1007/s10208-021-09492-1},
  journal      = {Foundations of Computational Mathematics},
  number       = {6},
  pages        = {1643-1702},
  shortjournal = {Found. Comput. Math.},
  title        = {Optimal artificial boundary condition for random elliptic media},
  volume       = {21},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Curve based approximation of measures on manifolds by
discrepancy minimization. <em>FoCM</em>, <em>21</em>(6), 1595–1642. (<a
href="https://doi.org/10.1007/s10208-021-09491-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The approximation of probability measures on compact metric spaces and in particular on Riemannian manifolds by atomic or empirical ones is a classical task in approximation and complexity theory with a wide range of applications. Instead of point measures we are concerned with the approximation by measures supported on Lipschitz curves. Special attention is paid to push-forward measures of Lebesgue measures on the unit interval by such curves. Using the discrepancy as distance between measures, we prove optimal approximation rates in terms of the curve’s length and Lipschitz constant. Having established the theoretical convergence rates, we are interested in the numerical minimization of the discrepancy between a given probability measure and the set of push-forward measures of Lebesgue measures on the unit interval by Lipschitz curves. We present numerical examples for measures on the 2- and 3-dimensional torus, the 2-sphere, the rotation group on $$\mathbb R^3$$ and the Grassmannian of all 2-dimensional linear subspaces of $${\mathbb {R}}^4$$ . Our algorithm of choice is a conjugate gradient method on these manifolds, which incorporates second-order information. For efficient gradient and Hessian evaluations within the algorithm, we approximate the given measures by truncated Fourier series and use fast Fourier transform techniques on these manifolds.},
  archive      = {J_FoCM},
  author       = {Ehler, Martin and Gräf, Manuel and Neumayer, Sebastian and Steidl, Gabriele},
  doi          = {10.1007/s10208-021-09491-2},
  journal      = {Foundations of Computational Mathematics},
  number       = {6},
  pages        = {1595-1642},
  shortjournal = {Found. Comput. Math.},
  title        = {Curve based approximation of measures on manifolds by discrepancy minimization},
  volume       = {21},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Low-rank matrix recovery with composite optimization: Good
conditioning and rapid convergence. <em>FoCM</em>, <em>21</em>(6),
1505–1593. (<a
href="https://doi.org/10.1007/s10208-020-09490-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The task of recovering a low-rank matrix from its noisy linear measurements plays a central role in computational science. Smooth formulations of the problem often exhibit an undesirable phenomenon: the condition number, classically defined, scales poorly with the dimension of the ambient space. In contrast, we here show that in a variety of concrete circumstances, nonsmooth penalty formulations do not suffer from the same type of ill-conditioning. Consequently, standard algorithms for nonsmooth optimization, such as subgradient and prox-linear methods, converge at a rapid dimension-independent rate when initialized within constant relative error of the solution. Moreover, nonsmooth formulations are naturally robust against outliers. Our framework subsumes such important computational tasks as phase retrieval, blind deconvolution, quadratic sensing, matrix completion, and robust PCA. Numerical experiments on these problems illustrate the benefits of the proposed approach.},
  archive      = {J_FoCM},
  author       = {Charisopoulos, Vasileios and Chen, Yudong and Davis, Damek and Díaz, Mateo and Ding, Lijun and Drusvyatskiy, Dmitriy},
  doi          = {10.1007/s10208-020-09490-9},
  journal      = {Foundations of Computational Mathematics},
  number       = {6},
  pages        = {1505-1593},
  shortjournal = {Found. Comput. Math.},
  title        = {Low-rank matrix recovery with composite optimization: Good conditioning and rapid convergence},
  volume       = {21},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Fenchel duality theory and a primal-dual algorithm on
riemannian manifolds. <em>FoCM</em>, <em>21</em>(6), 1465–1504. (<a
href="https://doi.org/10.1007/s10208-020-09486-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a new notion of a Fenchel conjugate, which generalizes the classical Fenchel conjugation to functions defined on Riemannian manifolds. We investigate its properties, e.g., the Fenchel–Young inequality and the characterization of the convex subdifferential using the analogue of the Fenchel–Moreau Theorem. These properties of the Fenchel conjugate are employed to derive a Riemannian primal-dual optimization algorithm and to prove its convergence for the case of Hadamard manifolds under appropriate assumptions. Numerical results illustrate the performance of the algorithm, which competes with the recently derived Douglas–Rachford algorithm on manifolds of nonpositive curvature. Furthermore, we show numerically that our novel algorithm may even converge on manifolds of positive curvature.},
  archive      = {J_FoCM},
  author       = {Bergmann, Ronny and Herzog, Roland and Silva Louzeiro, Maurício and Tenbrinck, Daniel and Vidal-Núñez, José},
  doi          = {10.1007/s10208-020-09486-5},
  journal      = {Foundations of Computational Mathematics},
  number       = {6},
  pages        = {1465-1504},
  shortjournal = {Found. Comput. Math.},
  title        = {Fenchel duality theory and a primal-dual algorithm on riemannian manifolds},
  volume       = {21},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The reeb graph edit distance is universal. <em>FoCM</em>,
<em>21</em>(5), 1441–1464. (<a
href="https://doi.org/10.1007/s10208-020-09488-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the setting of Reeb graphs of piecewise linear functions and study distances between them that are stable, meaning that functions which are similar in the supremum norm ought to have similar Reeb graphs. We define an edit distance for Reeb graphs and prove that it is stable and universal, meaning that it provides an upper bound to any other stable distance. In contrast, via a specific construction, we show that the interleaving distance and the functional distortion distance on Reeb graphs are not universal.},
  archive      = {J_FoCM},
  author       = {Bauer, Ulrich and Landi, Claudia and Mémoli, Facundo},
  doi          = {10.1007/s10208-020-09488-3},
  journal      = {Foundations of Computational Mathematics},
  number       = {5},
  pages        = {1441-1464},
  shortjournal = {Found. Comput. Math.},
  title        = {The reeb graph edit distance is universal},
  volume       = {21},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Exact splitting methods for semigroups generated by
inhomogeneous quadratic differential operators. <em>FoCM</em>,
<em>21</em>(5), 1401–1439. (<a
href="https://doi.org/10.1007/s10208-020-09487-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce some general tools to design exact splitting methods to compute numerically semigroups generated by inhomogeneous quadratic differential operators. More precisely, we factorize these semigroups as products of semigroups that can be approximated efficiently, using, for example, pseudo-spectral methods. We highlight the efficiency of these new methods on the examples of the magnetic linear Schrödinger equations with quadratic potentials, some transport equations and some Fokker–Planck equations.},
  archive      = {J_FoCM},
  author       = {Bernier, Joackim},
  doi          = {10.1007/s10208-020-09487-4},
  journal      = {Foundations of Computational Mathematics},
  number       = {5},
  pages        = {1401-1439},
  shortjournal = {Found. Comput. Math.},
  title        = {Exact splitting methods for semigroups generated by inhomogeneous quadratic differential operators},
  volume       = {21},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Primary ideals and their differential equations.
<em>FoCM</em>, <em>21</em>(5), 1363–1399. (<a
href="https://doi.org/10.1007/s10208-020-09485-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An ideal in a polynomial ring encodes a system of linear partial differential equations with constant coefficients. Primary decomposition organizes the solutions to the PDE. This paper develops a novel structure theory for primary ideals in a polynomial ring. We characterize primary ideals in terms of PDE, punctual Hilbert schemes, relative Weyl algebras, and the join construction. Solving the PDE described by a primary ideal amounts to computing Noetherian operators in the sense of Ehrenpreis and Palamodov. We develop new algorithms for this task, and we present efficient implementations.},
  archive      = {J_FoCM},
  author       = {Cid-Ruiz, Yairon and Homs, Roser and Sturmfels, Bernd},
  doi          = {10.1007/s10208-020-09485-6},
  journal      = {Foundations of Computational Mathematics},
  number       = {5},
  pages        = {1363-1399},
  shortjournal = {Found. Comput. Math.},
  title        = {Primary ideals and their differential equations},
  volume       = {21},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Metrics, quantization and registration in varifold spaces.
<em>FoCM</em>, <em>21</em>(5), 1317–1361. (<a
href="https://doi.org/10.1007/s10208-020-09484-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is concerned with the theory and applications of varifolds to the representation, approximation and diffeomorphic registration of shapes. One of its purpose is to synthesize and extend several prior works which, so far, have made use of this framework mainly in the context of submanifold comparison and matching. In this work, we instead consider deformation models acting on general varifold spaces, which allow to formulate and tackle diffeomorphic registration problems for a much wider class of geometric objects and lead to a more versatile algorithmic pipeline. We study in detail the construction of kernel metrics on varifold spaces and the resulting topological properties of those metrics and then propose a mathematical model for diffeomorphic registration of varifolds under a specific group action which we formulate in the framework of optimal control theory. A second important part of the paper focuses on the discrete aspects. Specifically, we address the problem of optimal finite approximations (quantization) for those metrics and show a $$\varGamma $$ -convergence property for the corresponding registration functionals. Finally, we develop numerical pipelines for quantization and registration before showing a few preliminary results for one- and two-dimensional varifolds.},
  archive      = {J_FoCM},
  author       = {Hsieh, Hsi-Wei and Charon, Nicolas},
  doi          = {10.1007/s10208-020-09484-7},
  journal      = {Foundations of Computational Mathematics},
  number       = {5},
  pages        = {1317-1361},
  shortjournal = {Found. Comput. Math.},
  title        = {Metrics, quantization and registration in varifold spaces},
  volume       = {21},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Computing the homology of semialgebraic sets. II: General
formulas. <em>FoCM</em>, <em>21</em>(5), 1279–1316. (<a
href="https://doi.org/10.1007/s10208-020-09483-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We describe and analyze a numerical algorithm for computing the homology (Betti numbers and torsion coefficients) of semialgebraic sets given by Boolean formulas. The algorithm works in weak exponential time. This means that outside a subset of data having exponentially small measure, the cost of the algorithm is single exponential in the size of the data. This extends the work in Part I to arbitrary semialgebraic sets. All previous algorithms proposed for this problem have doubly exponential complexity.},
  archive      = {J_FoCM},
  author       = {Bürgisser, Peter and Cucker, Felipe and Tonelli-Cueto, Josué},
  doi          = {10.1007/s10208-020-09483-8},
  journal      = {Foundations of Computational Mathematics},
  number       = {5},
  pages        = {1279-1316},
  shortjournal = {Found. Comput. Math.},
  title        = {Computing the homology of semialgebraic sets. II: General formulas},
  volume       = {21},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Homological algebra for persistence modules. <em>FoCM</em>,
<em>21</em>(5), 1233–1278. (<a
href="https://doi.org/10.1007/s10208-020-09482-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We develop some aspects of the homological algebra of persistence modules, in both the one-parameter and multi-parameter settings, considered as either sheaves or graded modules. The two theories are different. We consider the graded module and sheaf tensor product and Hom bifunctors as well as their derived functors, Tor and Ext, and give explicit computations for interval modules. We give a classification of injective, projective, and flat interval modules. We state Künneth theorems and universal coefficient theorems for the homology and cohomology of chain complexes of persistence modules in both the sheaf and graded module settings and show how these theorems can be applied to persistence modules arising from filtered cell complexes. We also give a Gabriel–Popescu theorem for persistence modules. Finally, we examine categories enriched over persistence modules. We show that the graded module point of view produces a closed symmetric monoidal category that is enriched over itself.},
  archive      = {J_FoCM},
  author       = {Bubenik, Peter and Milićević, Nikola},
  doi          = {10.1007/s10208-020-09482-9},
  journal      = {Foundations of Computational Mathematics},
  number       = {5},
  pages        = {1233-1278},
  shortjournal = {Found. Comput. Math.},
  title        = {Homological algebra for persistence modules},
  volume       = {21},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Tensor-free proximal methods for lifted bilinear/quadratic
inverse problems with applications to phase retrieval. <em>FoCM</em>,
<em>21</em>(5), 1181–1232. (<a
href="https://doi.org/10.1007/s10208-020-09479-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose and study a class of novel algorithms that aim at solving bilinear and quadratic inverse problems. Using a convex relaxation based on tensorial lifting, and applying first-order proximal algorithms, these problems could be solved numerically by singular value thresholding methods. However, a direct realization of these algorithms for, e.g., image recovery problems is often impracticable, since computations have to be performed on the tensor-product space, whose dimension is usually tremendous. To overcome this limitation, we derive tensor-free versions of common singular value thresholding methods by exploiting low-rank representations and incorporating an augmented Lanczos process. Using a novel reweighting technique, we further improve the convergence behavior and rank evolution of the iterative algorithms. Applying the method to the two-dimensional masked Fourier phase retrieval problem, we obtain an efficient recovery method. Moreover, the tensor-free algorithms are flexible enough to incorporate a priori smoothness constraints that greatly improve the recovery results.},
  archive      = {J_FoCM},
  author       = {Beinert, Robert and Bredies, Kristian},
  doi          = {10.1007/s10208-020-09479-4},
  journal      = {Foundations of Computational Mathematics},
  number       = {5},
  pages        = {1181-1232},
  shortjournal = {Found. Comput. Math.},
  title        = {Tensor-free proximal methods for lifted Bilinear/Quadratic inverse problems with applications to phase retrieval},
  volume       = {21},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Duality in finite element exterior calculus and hodge
duality on the sphere. <em>FoCM</em>, <em>21</em>(5), 1153–1180. (<a
href="https://doi.org/10.1007/s10208-020-09478-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Finite element exterior calculus refers to the development of finite element methods for differential forms, generalizing several earlier finite element spaces of scalar fields and vector fields to arbitrary dimension n, arbitrary polynomial degree r, and arbitrary differential form degree k. The study of finite element exterior calculus began with the $${\mathcal {P}}_r\varLambda ^k$$ and $${\mathcal {P}}_r^-\varLambda ^k$$ families of finite element spaces on simplicial triangulations. In their development of these spaces, Arnold, Falk, and Winther rely on a duality relationship between $${\mathcal {P}}_r\varLambda ^k$$ and $$\mathring{{\mathcal {P}}}_{r+k+1}^-\varLambda ^{n-k}$$ and between $${\mathcal {P}}_r^-\varLambda ^k$$ and $$\mathring{{\mathcal {P}}}_{r+k}\varLambda ^{n-k}$$ . In this article, we show that this duality relationship is, in essence, Hodge duality of differential forms on the standard n-sphere, disguised by a change of coordinates. We remove the disguise, giving explicit correspondences between the $${\mathcal {P}}_r\varLambda ^k$$ , $${\mathcal {P}}_r^-\varLambda ^k$$ , $$\mathring{{\mathcal {P}}}_r\varLambda ^k$$ and $$\mathring{{\mathcal {P}}}_r^-\varLambda ^k$$ spaces and spaces of differential forms on the sphere. As a direct corollary, we obtain new pointwise duality isomorphisms between $${\mathcal {P}}_r \varLambda ^k$$ and $$\mathring{{\mathcal {P}}}_{r+k+1}^-\varLambda ^{n-k}$$ and between $${\mathcal {P}}_r^-\varLambda ^k$$ and $$\mathring{{\mathcal {P}}}_{r+k} \varLambda ^{n-k}$$ . These isomorphisms can be implemented via a simple computation, which we illustrate with examples.},
  archive      = {J_FoCM},
  author       = {Berchenko-Kogan, Yakov},
  doi          = {10.1007/s10208-020-09478-5},
  journal      = {Foundations of Computational Mathematics},
  number       = {5},
  pages        = {1153-1180},
  shortjournal = {Found. Comput. Math.},
  title        = {Duality in finite element exterior calculus and hodge duality on the sphere},
  volume       = {21},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Function values are enough for <span
class="math display"><em>L</em><sub>2</sub></span> -approximation.
<em>FoCM</em>, <em>21</em>(4), 1141–1151. (<a
href="https://doi.org/10.1007/s10208-020-09481-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the $$L_2$$ -approximation of functions from a Hilbert space and compare the sampling numbers with the approximation numbers. The sampling number $$e_n$$ is the minimal worst-case error that can be achieved with n function values, whereas the approximation number $$a_n$$ is the minimal worst-case error that can be achieved with n pieces of arbitrary linear information (like derivatives or Fourier coefficients). We show that $$\begin{aligned} e_n \,\lesssim \, \sqrt{\frac{1}{k_n} \sum _{j\ge k_n} a_j^2}, \end{aligned}$$ where $$k_n \asymp n/\log (n)$$ . This proves that the sampling numbers decay with the same polynomial rate as the approximation numbers and therefore that function values are basically as powerful as arbitrary linear information if the approximation numbers are square-summable. Our result applies, in particular, to Sobolev spaces $$H^s_\mathrm{mix}(\mathbb {T}^d)$$ with dominating mixed smoothness $$s&gt;1/2$$ and dimension $$d\in \mathbb {N}$$ , and we obtain $$\begin{aligned} e_n \,\lesssim \, n^{-s} \log ^{sd}(n). \end{aligned}$$ For $$d&gt;2s+1$$ , this improves upon all previous bounds and disproves the prevalent conjecture that Smolyak’s (sparse grid) algorithm is optimal.},
  archive      = {J_FoCM},
  author       = {Krieg, David and Ullrich, Mario},
  doi          = {10.1007/s10208-020-09481-w},
  journal      = {Foundations of Computational Mathematics},
  number       = {4},
  pages        = {1141-1151},
  shortjournal = {Found. Comput. Math.},
  title        = {Function values are enough for $$L_2$$ -approximation},
  volume       = {21},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Convergence rates for discretized monge–ampère equations and
quantitative stability of optimal transport. <em>FoCM</em>,
<em>21</em>(4), 1099–1140. (<a
href="https://doi.org/10.1007/s10208-020-09480-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent works—both experimental and theoretical—it has been shown how to use computational geometry to efficiently construct approximations to the optimal transport map between two given probability measures on Euclidean space, by discretizing one of the measures. Here we provide a quantitative convergence analysis for the solutions of the corresponding discretized Monge–Ampère equations. This yields $$H^{1}$$ -converge rates, in terms of the corresponding spatial resolution h, of the discrete approximations of the optimal transport map, when the source measure is discretized and the target measure has bounded convex support. Periodic variants of the results are also established. The proofs are based on new quantitative stability results for optimal transport maps, shown using complex geometry.},
  archive      = {J_FoCM},
  author       = {Berman, Robert J.},
  doi          = {10.1007/s10208-020-09480-x},
  journal      = {Foundations of Computational Mathematics},
  number       = {4},
  pages        = {1099-1140},
  shortjournal = {Found. Comput. Math.},
  title        = {Convergence rates for discretized Monge–Ampère equations and quantitative stability of optimal transport},
  volume       = {21},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Constraint-preserving hybrid finite element methods for
maxwell’s equations. <em>FoCM</em>, <em>21</em>(4), 1075–1098. (<a
href="https://doi.org/10.1007/s10208-020-09476-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Maxwell’s equations describe the evolution of electromagnetic fields, together with constraints on the divergence of the magnetic and electric flux densities. These constraints correspond to fundamental physical laws: the nonexistence of magnetic monopoles and the conservation of charge, respectively. However, one or both of these constraints may be violated when one applies a finite element method to discretize in space. This is a well-known and long-standing problem in computational electromagnetics. We use domain decomposition to construct a family of primal hybrid finite element methods for Maxwell’s equations, where the Lagrange multipliers are shown to correspond to a numerical trace of the magnetic field and a numerical flux of the electric flux density. Expressing the charge conservation constraint in terms of this numerical flux, we show that both constraints are strongly preserved. As a special case, these methods include a hybridized version of Nédélec’s method, implying that it preserves the constraints more strongly than previously recognized. These constraint-preserving properties are illustrated using numerical experiments in both the time domain and frequency domain. In 2-D, we also observe a superconvergence phenomenon, where hybrid post-processing yields an improved estimate of the magnetic field.},
  archive      = {J_FoCM},
  author       = {Berchenko-Kogan, Yakov and Stern, Ari},
  doi          = {10.1007/s10208-020-09476-7},
  journal      = {Foundations of Computational Mathematics},
  number       = {4},
  pages        = {1075-1098},
  shortjournal = {Found. Comput. Math.},
  title        = {Constraint-preserving hybrid finite element methods for maxwell’s equations},
  volume       = {21},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Computing higher leray–serre spectral sequences of towers of
fibrations. <em>FoCM</em>, <em>21</em>(4), 1023–1074. (<a
href="https://doi.org/10.1007/s10208-020-09475-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The higher Leray–Serre spectral sequence associated with a tower of fibrations represents a generalization of the classical Leray–Serre spectral sequence of a fibration. In this work, we present algorithms to compute higher Leray–Serre spectral sequences leveraging the effective homology technique, which allows to perform computations involving chain complexes of infinite type associated with interesting objects in algebraic topology. In order to develop the programs, implemented as a new module for the Computer Algebra system Kenzo, we translated the original construction of the higher Leray–Serre spectral sequence in a simplicial framework and studied some of its fundamental properties.},
  archive      = {J_FoCM},
  author       = {Guidolin, Andrea and Romero, Ana},
  doi          = {10.1007/s10208-020-09475-8},
  journal      = {Foundations of Computational Mathematics},
  number       = {4},
  pages        = {1023-1074},
  shortjournal = {Found. Comput. Math.},
  title        = {Computing higher Leray–Serre spectral sequences of towers of fibrations},
  volume       = {21},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Algebraic boundaries among typical ranks for real binary
forms of arbitrary degree. <em>FoCM</em>, <em>21</em>(4), 1003–1022. (<a
href="https://doi.org/10.1007/s10208-020-09474-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We show that the algebraic boundaries of the regions of real binary forms with fixed typical rank are always unions of dual varieties to suitable coincident root loci.},
  archive      = {J_FoCM},
  author       = {Brambilla, Maria Chiara and Staglianò, Giovanni},
  doi          = {10.1007/s10208-020-09474-9},
  journal      = {Foundations of Computational Mathematics},
  number       = {4},
  pages        = {1003-1022},
  shortjournal = {Found. Comput. Math.},
  title        = {Algebraic boundaries among typical ranks for real binary forms of arbitrary degree},
  volume       = {21},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A variational finite element discretization of compressible
flow. <em>FoCM</em>, <em>21</em>(4), 961–1001. (<a
href="https://doi.org/10.1007/s10208-020-09473-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a finite element variational integrator for compressible flows. The numerical scheme is derived by discretizing, in a structure-preserving way, the Lie group formulation of fluid dynamics on diffeomorphism groups and the associated variational principles. Given a triangulation on the fluid domain, the discrete group of diffeomorphisms is defined as a certain subgroup of the group of linear isomorphisms of a finite element space of functions. In this setting, discrete vector fields correspond to a certain subspace of the Lie algebra of this group. This subspace is shown to be isomorphic to a Raviart–Thomas finite element space. The resulting finite element discretization corresponds to a weak form of the compressible fluid equation that does not seem to have been used in the finite element literature. It extends previous work done on incompressible flows and at the lowest order on compressible flows. We illustrate the conservation properties of the scheme with some numerical simulations.},
  archive      = {J_FoCM},
  author       = {Gawlik, Evan S. and Gay-Balmaz, François},
  doi          = {10.1007/s10208-020-09473-w},
  journal      = {Foundations of Computational Mathematics},
  number       = {4},
  pages        = {961-1001},
  shortjournal = {Found. Comput. Math.},
  title        = {A variational finite element discretization of compressible flow},
  volume       = {21},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A unifying representer theorem for inverse problems and
machine learning. <em>FoCM</em>, <em>21</em>(4), 941–960. (<a
href="https://doi.org/10.1007/s10208-020-09472-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Regularization addresses the ill-posedness of the training problem in machine learning or the reconstruction of a signal from a limited number of measurements. The method is applicable whenever the problem is formulated as an optimization task. The standard strategy consists in augmenting the original cost functional by an energy that penalizes solutions with undesirable behavior. The effect of regularization is very well understood when the penalty involves a Hilbertian norm. Another popular configuration is the use of an $$\ell _1$$ -norm (or some variant thereof) that favors sparse solutions. In this paper, we propose a higher-level formulation of regularization within the context of Banach spaces. We present a general representer theorem that characterizes the solutions of a remarkably broad class of optimization problems. We then use our theorem to retrieve a number of known results in the literature such as the celebrated representer theorem of machine leaning for RKHS, Tikhonov regularization, representer theorems for sparsity promoting functionals, the recovery of spikes, as well as a few new ones.},
  archive      = {J_FoCM},
  author       = {Unser, Michael},
  doi          = {10.1007/s10208-020-09472-x},
  journal      = {Foundations of Computational Mathematics},
  number       = {4},
  pages        = {941-960},
  shortjournal = {Found. Comput. Math.},
  title        = {A unifying representer theorem for inverse problems and machine learning},
  volume       = {21},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Stable rank-one matrix completion is solved by the level 2
lasserre relaxation. <em>FoCM</em>, <em>21</em>(4), 891–940. (<a
href="https://doi.org/10.1007/s10208-020-09471-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the problem of deterministic rank-one matrix completion. It is known that the simplest semidefinite programming relaxation, involving minimization of the nuclear norm, does not in general return the solution for this problem. In this paper, we show that in every instance where the problem has a unique solution, one can provably recover the original matrix through the level 2 Lasserre relaxation with minimization of the trace norm. We further show that the solution of the proposed semidefinite program is Lipschitz stable with respect to perturbations of the observed entries, unlike more basic algorithms such as nonlinear propagation or ridge regression. Our proof is based on recursively building a certificate of optimality corresponding to a dual sum-of-squares (SoS) polynomial. This SoS polynomial is built from the polynomial ideal generated by the completion constraints and the monomials provided by the minimization of the trace. The proposed relaxation fits in the framework of the Lasserre hierarchy, albeit with the key addition of the trace objective function. Finally, we show how to represent and manipulate the moment tensor in favorable complexity by means of a hierarchical low-rank factorization.},
  archive      = {J_FoCM},
  author       = {Cosse, Augustin and Demanet, Laurent},
  doi          = {10.1007/s10208-020-09471-y},
  journal      = {Foundations of Computational Mathematics},
  number       = {4},
  pages        = {891-940},
  shortjournal = {Found. Comput. Math.},
  title        = {Stable rank-one matrix completion is solved by the level 2 lasserre relaxation},
  volume       = {21},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Numerical performance of optimized frolov lattices in tensor
product reproducing kernel sobolev spaces. <em>FoCM</em>,
<em>21</em>(3), 849–889. (<a
href="https://doi.org/10.1007/s10208-020-09463-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we deal with several aspects of the universal Frolov cubature method, which is known to achieve optimal asymptotic convergence rates in a broad range of function spaces. Even though every admissible lattice has this favorable asymptotic behavior, there are significant differences concerning the precise numerical behavior of the worst-case error. To this end, we propose new generating polynomials that promise a significant reduction in the integration error compared to the classical polynomials. Moreover, we develop a new algorithm to enumerate the Frolov points from non-orthogonal lattices for numerical cubature in the d-dimensional unit cube $$[0,1]^d$$ . Finally, we study Sobolev spaces with anisotropic mixed smoothness and compact support in $$[0,1]^d$$ and derive explicit formulas for their reproducing kernels. This allows for the simulation of exact worst-case errors which numerically validate our theoretical results.},
  archive      = {J_FoCM},
  author       = {Kacwin, Christopher and Oettershagen, Jens and Ullrich, Mario and Ullrich, Tino},
  doi          = {10.1007/s10208-020-09463-y},
  journal      = {Foundations of Computational Mathematics},
  number       = {3},
  pages        = {849-889},
  shortjournal = {Found. Comput. Math.},
  title        = {Numerical performance of optimized frolov lattices in tensor product reproducing kernel sobolev spaces},
  volume       = {21},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Local approximation from spline spaces on box meshes.
<em>FoCM</em>, <em>21</em>(3), 807–848. (<a
href="https://doi.org/10.1007/s10208-020-09467-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper analyzes the approximation properties of spaces of piecewise tensor product polynomials over box meshes with a focus on application to isogeometric analysis. Local and global error bounds with respect to Sobolev or reduced seminorms are provided. Attention is also paid to the dependence on the degree, and exponential convergence is proved for the approximation of analytic functions in the absence of non-convex extended supports.},
  archive      = {J_FoCM},
  author       = {Bressan, Andrea and Lyche, Tom},
  doi          = {10.1007/s10208-020-09467-8},
  journal      = {Foundations of Computational Mathematics},
  number       = {3},
  pages        = {807-848},
  shortjournal = {Found. Comput. Math.},
  title        = {Local approximation from spline spaces on box meshes},
  volume       = {21},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Towards massively parallel computations in algebraic
geometry. <em>FoCM</em>, <em>21</em>(3), 767–806. (<a
href="https://doi.org/10.1007/s10208-020-09464-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Introducing parallelism and exploring its use is still a fundamental challenge for the computer algebra community. In high-performance numerical simulation, on the other hand, transparent environments for distributed computing which follow the principle of separating coordination and computation have been a success story for many years. In this paper, we explore the potential of using this principle in the context of computer algebra. More precisely, we combine two well-established systems: The mathematics we are interested in is implemented in the computer algebra system Singular, whose focus is on polynomial computations, while the coordination is left to the workflow management system GPI-Space, which relies on Petri nets as its mathematical modeling language and has been successfully used for coordinating the parallel execution (autoparallelization) of academic codes as well as for commercial software in application areas such as seismic data processing. The result of our efforts is a major step towards a framework for massively parallel computations in the application areas of Singular, specifically in commutative algebra and algebraic geometry. As a first test case for this framework, we have modeled and implemented a hybrid smoothness test for algebraic varieties which combines ideas from Hironaka’s celebrated desingularization proof with the classical Jacobian criterion. Applying our implementation to two examples originating from current research in algebraic geometry, one of which cannot be handled by other means, we illustrate the behavior of the smoothness test within our framework and investigate how the computations scale up to 256 cores.},
  archive      = {J_FoCM},
  author       = {Böhm, Janko and Decker, Wolfram and Frühbis-Krüger, Anne and Pfreundt, Franz-Josef and Rahn, Mirko and Ristau, Lukas},
  doi          = {10.1007/s10208-020-09464-x},
  journal      = {Foundations of Computational Mathematics},
  number       = {3},
  pages        = {767-806},
  shortjournal = {Found. Comput. Math.},
  title        = {Towards massively parallel computations in algebraic geometry},
  volume       = {21},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Error estimates of a fourier integrator for the cubic
schrödinger equation at low regularity. <em>FoCM</em>, <em>21</em>(3),
725–765. (<a href="https://doi.org/10.1007/s10208-020-09468-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a new filtered low-regularity Fourier integrator for the cubic nonlinear Schrödinger equation based on recent time discretization and filtering techniques. For this new scheme, we perform a rigorous error analysis and establish better convergence rates at low regularity than known for classical schemes in the literature so far. In our error estimates, we combine the better local error properties of the new scheme with a stability analysis based on general discrete Strichartz-type estimates. The latter allow us to handle a much rougher class of solutions as the error analysis can be carried out directly at the level of $$L^2$$ compared to classical results in dimension d, which are limited to higher-order (sufficiently smooth) Sobolev spaces $$H^s$$ with $$s&gt;d/2$$ . In particular, we are able to establish a global error estimate in $$L^2$$ for $$H^1$$ solutions which is roughly of order $$\tau ^{ {1\over 2} + { 5-d \over 12} }$$ in dimension $$d \le 3$$ ( $$\tau $$ denoting the time discretization parameter). This breaks the “natural order barrier” of $$\tau ^{1/2}$$ for $$H^1$$ solutions which holds for classical numerical schemes (even in combination with suitable filter functions).},
  archive      = {J_FoCM},
  author       = {Ostermann, Alexander and Rousset, Frédéric and Schratz, Katharina},
  doi          = {10.1007/s10208-020-09468-7},
  journal      = {Foundations of Computational Mathematics},
  number       = {3},
  pages        = {725-765},
  shortjournal = {Found. Comput. Math.},
  title        = {Error estimates of a fourier integrator for the cubic schrödinger equation at low regularity},
  volume       = {21},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Moment identifiability of homoscedastic gaussian mixtures.
<em>FoCM</em>, <em>21</em>(3), 695–724. (<a
href="https://doi.org/10.1007/s10208-020-09469-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the problem of identifying a mixture of Gaussian distributions with the same unknown covariance matrix by their sequence of moments up to certain order. Our approach rests on studying the moment varieties obtained by taking special secants to the Gaussian moment varieties, defined by their natural polynomial parametrization in terms of the model parameters. When the order of the moments is at most three, we prove an analogue of the Alexander–Hirschowitz theorem classifying all cases of homoscedastic Gaussian mixtures that produce defective moment varieties. As a consequence, identifiability is determined when the number of mixed distributions is smaller than the dimension of the space. In the two-component setting, we provide a closed form solution for parameter recovery based on moments up to order four, while in the one-dimensional case we interpret the rank estimation problem in terms of secant varieties of rational normal curves.},
  archive      = {J_FoCM},
  author       = {Agostini, Daniele and Améndola, Carlos and Ranestad, Kristian},
  doi          = {10.1007/s10208-020-09469-6},
  journal      = {Foundations of Computational Mathematics},
  number       = {3},
  pages        = {695-724},
  shortjournal = {Found. Comput. Math.},
  title        = {Moment identifiability of homoscedastic gaussian mixtures},
  volume       = {21},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Iterative potts minimization for the recovery of signals
with discontinuities from indirect measurements: The multivariate case.
<em>FoCM</em>, <em>21</em>(3), 649–694. (<a
href="https://doi.org/10.1007/s10208-020-09466-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Signals and images with discontinuities appear in many problems in such diverse areas as biology, medicine, mechanics and electrical engineering. The concrete data are often discrete, indirect and noisy measurements of some quantities describing the signal under consideration. A frequent task is to find the segments of the signal or image which corresponds to finding the discontinuities or jumps in the data. Methods based on minimizing the piecewise constant Mumford–Shah functional—whose discretized version is known as Potts energy—are advantageous in this scenario, in particular, in connection with segmentation. However, due to their non-convexity, minimization of such energies is challenging. In this paper, we propose a new iterative minimization strategy for the multivariate Potts energy dealing with indirect, noisy measurements. We provide a convergence analysis and underpin our findings with numerical experiments.},
  archive      = {J_FoCM},
  author       = {Kiefer, Lukas and Storath, Martin and Weinmann, Andreas},
  doi          = {10.1007/s10208-020-09466-9},
  journal      = {Foundations of Computational Mathematics},
  number       = {3},
  pages        = {649-694},
  shortjournal = {Found. Comput. Math.},
  title        = {Iterative potts minimization for the recovery of signals with discontinuities from indirect measurements: The multivariate case},
  volume       = {21},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). On the convergence of time splitting methods for quantum
dynamics in the semiclassical regime. <em>FoCM</em>, <em>21</em>(3),
613–647. (<a href="https://doi.org/10.1007/s10208-020-09470-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {By using the pseudo-metric introduced in Golse and Paul (Arch Ration Mech Anal 223:57–94, 2017), which is an analogue of the Wasserstein distance of exponent 2 between a quantum density operator and a classical (phase-space) density, we prove that the convergence of time splitting algorithms for the von Neumann equation of quantum dynamics is uniform in the Planck constant $$\hbar $$ . We obtain explicit uniform in $$\hbar $$ error estimates for the first-order Lie–Trotter, and the second-order Strang splitting methods.},
  archive      = {J_FoCM},
  author       = {Golse, François and Jin, Shi and Paul, Thierry},
  doi          = {10.1007/s10208-020-09470-z},
  journal      = {Foundations of Computational Mathematics},
  number       = {3},
  pages        = {613-647},
  shortjournal = {Found. Comput. Math.},
  title        = {On the convergence of time splitting methods for quantum dynamics in the semiclassical regime},
  volume       = {21},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Noncommutative polynomials describing convex sets.
<em>FoCM</em>, <em>21</em>(2), 575–611. (<a
href="https://doi.org/10.1007/s10208-020-09465-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The free closed semialgebraic set $${\mathcal {D}}_f$$ determined by a hermitian noncommutative polynomial $$f\in {\text {M}}_{{\delta }}({\mathbb {C}}\mathop {})$$ is the closure of the connected component of $${(X,X^*)\mid f(X,X^*)\succ 0}$$ containing the origin. When L is a hermitian monic linear pencil, the free closed semialgebraic set $${\mathcal {D}}_L$$ is the feasible set of the linear matrix inequality $$L(X,X^*)\succeq 0$$ and is known as a free spectrahedron. Evidently these are convex and it is well known that a free closed semialgebraic set is convex if and only it is a free spectrahedron. The main result of this paper solves the basic problem of determining those f for which $${\mathcal {D}}_f$$ is convex. The solution leads to an efficient algorithm that not only determines if $${\mathcal {D}}_f$$ is convex, but if so, produces a minimal hermitian monic pencil L such that $${\mathcal {D}}_f={\mathcal {D}}_L$$ . Of independent interest is a subalgorithm based on a Nichtsingulärstellensatz presented here: given a linear pencil $${\widetilde{L}}$$ and a hermitian monic pencil L, it determines if $${\widetilde{L}}$$ takes invertible values on the interior of $${\mathcal {D}}_L$$ . Finally, it is shown that if $${\mathcal {D}}_f$$ is convex for an irreducible hermitian $$f\in {\mathbb {C}}\mathop {}$$ , then f has degree at most two, and arises as the Schur complement of an L such that $${\mathcal {D}}_f={\mathcal {D}}_L$$ .},
  archive      = {J_FoCM},
  author       = {Helton, J. William and Klep, Igor and McCullough, Scott and Volčič, Jurij},
  doi          = {10.1007/s10208-020-09465-w},
  journal      = {Foundations of Computational Mathematics},
  number       = {2},
  pages        = {575-611},
  shortjournal = {Found. Comput. Math.},
  title        = {Noncommutative polynomials describing convex sets},
  volume       = {21},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The grassmannian of affine subspaces. <em>FoCM</em>,
<em>21</em>(2), 537–574. (<a
href="https://doi.org/10.1007/s10208-020-09459-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Grassmannian of affine subspaces is a natural generalization of both the Euclidean space, points being 0-dimensional affine subspaces, and the usual Grassmannian, linear subspaces being special cases of affine subspaces. We show that, like the Grassmannian, the affine Grassmannian has rich geometrical and topological properties: It has the structure of a homogeneous space, a differential manifold, an algebraic variety, a vector bundle, a classifying space, among many more structures; furthermore, it affords an analogue of Schubert calculus and its (co)homology and homotopy groups may be readily determined. On the other hand, like the Euclidean space, the affine Grassmannian serves as a concrete computational platform on which various distances, metrics, probability densities may be explicitly defined and computed via numerical linear algebra. Moreover, many standard problems in machine learning and statistics—linear regression, errors-in-variables regression, principal components analysis, support vector machines, or more generally any problem that seeks linear relations among variables that either best represent them or separate them into components—may be naturally formulated as problems on the affine Grassmannian.},
  archive      = {J_FoCM},
  author       = {Lim, Lek-Heng and Wong, Ken Sze-Wai and Ye, Ke},
  doi          = {10.1007/s10208-020-09459-8},
  journal      = {Foundations of Computational Mathematics},
  number       = {2},
  pages        = {537-574},
  shortjournal = {Found. Comput. Math.},
  title        = {The grassmannian of affine subspaces},
  volume       = {21},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Weak convergence rates for euler-type approximations of
semilinear stochastic evolution equations with nonlinear diffusion
coefficients. <em>FoCM</em>, <em>21</em>(2), 445–536. (<a
href="https://doi.org/10.1007/s10208-020-09448-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Strong convergence rates for time-discrete numerical approximations of semilinear stochastic evolution equations (SEEs) with smooth and regular nonlinearities are well understood in the literature. Weak convergence rates for time-discrete numerical approximations of such SEEs have, loosely speaking, been investigated since 2003 and are far away from being well understood: roughly speaking, no essentially sharp weak convergence rates are known for time-discrete numerical approximations of parabolic SEEs with nonlinear diffusion coefficient functions. In the recent article (Conus et al. in Ann Appl Probab 29(2):653–716, 2019) this weak convergence problem has been solved in the case of spatial spectral Galerkin approximations for semilinear SEEs with nonlinear diffusion coefficient functions. In this article we overcome this weak convergence problem in the case of a class of time-discrete Euler-type approximation methods (including exponential and linear-implicit Euler approximations as special cases) and, in particular, we establish essentially sharp weak convergence rates for linear-implicit Euler approximations of semilinear SEEs with nonlinear diffusion coefficient functions. Key ingredients of our approach are applications of a mild Itô-type formula and the use of suitable semilinear integrated counterparts of the time-discrete numerical approximation processes.},
  archive      = {J_FoCM},
  author       = {Jentzen, Arnulf and Kurniawan, Ryan},
  doi          = {10.1007/s10208-020-09448-x},
  journal      = {Foundations of Computational Mathematics},
  number       = {2},
  pages        = {445-536},
  shortjournal = {Found. Comput. Math.},
  title        = {Weak convergence rates for euler-type approximations of semilinear stochastic evolution equations with nonlinear diffusion coefficients},
  volume       = {21},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Topological properties of the set of functions generated by
neural networks of fixed size. <em>FoCM</em>, <em>21</em>(2), 375–444.
(<a href="https://doi.org/10.1007/s10208-020-09461-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We analyze the topological properties of the set of functions that can be implemented by neural networks of a fixed size. Surprisingly, this set has many undesirable properties. It is highly non-convex, except possibly for a few exotic activation functions. Moreover, the set is not closed with respect to $$L^p$$ -norms, $$0 0$$ , it is, regardless of the size of $$\varepsilon $$ , usually not possible to find weights $$w_1, w_2$$ close together such that each $$f_i$$ is realized by a neural network with weights $$w_i$$ . Overall, our findings identify potential causes for issues in the training procedure of deep learning such as no guaranteed convergence, explosion of parameters, and slow convergence.},
  archive      = {J_FoCM},
  author       = {Petersen, Philipp and Raslan, Mones and Voigtlaender, Felix},
  doi          = {10.1007/s10208-020-09461-0},
  journal      = {Foundations of Computational Mathematics},
  number       = {2},
  pages        = {375-444},
  shortjournal = {Found. Comput. Math.},
  title        = {Topological properties of the set of functions generated by neural networks of fixed size},
  volume       = {21},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A neural network-based policy iteration algorithm with
global <span class="math display"><em>H</em><sup>2</sup></span>
-superlinear convergence for stochastic games on domains. <em>FoCM</em>,
<em>21</em>(2), 331–374. (<a
href="https://doi.org/10.1007/s10208-020-09460-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we propose a class of numerical schemes for solving semilinear Hamilton–Jacobi–Bellman–Isaacs (HJBI) boundary value problems which arise naturally from exit time problems of diffusion processes with controlled drift. We exploit policy iteration to reduce the semilinear problem into a sequence of linear Dirichlet problems, which are subsequently approximated by a multilayer feedforward neural network ansatz. We establish that the numerical solutions converge globally in the $$H^2$$ -norm and further demonstrate that this convergence is superlinear, by interpreting the algorithm as an inexact Newton iteration for the HJBI equation. Moreover, we construct the optimal feedback controls from the numerical value functions and deduce convergence. The numerical schemes and convergence results are then extended to oblique derivative boundary conditions. Numerical experiments on the stochastic Zermelo navigation problem are presented to illustrate the theoretical results and to demonstrate the effectiveness of the method.},
  archive      = {J_FoCM},
  author       = {Ito, Kazufumi and Reisinger, Christoph and Zhang, Yufei},
  doi          = {10.1007/s10208-020-09460-1},
  journal      = {Foundations of Computational Mathematics},
  number       = {2},
  pages        = {331-374},
  shortjournal = {Found. Comput. Math.},
  title        = {A neural network-based policy iteration algorithm with global $$H^2$$ -superlinear convergence for stochastic games on domains},
  volume       = {21},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Sparse harmonic transforms: A new class of sublinear-time
algorithms for learning functions of many variables. <em>FoCM</em>,
<em>21</em>(2), 275–329. (<a
href="https://doi.org/10.1007/s10208-020-09462-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we develop fast and memory efficient numerical methods for learning functions of many variables that admit sparse representations in terms of general bounded orthonormal tensor product bases. Such functions appear in many applications including, e.g., various Uncertainty Quantification (UQ) problems involving the solution of parametric PDE that are approximately sparse in Chebyshev or Legendre product bases (Chkifa et al. in Polynomial approximation via compressed sensing of high-dimensional functions on lower sets. arXiv:1602.05823 , 2016; Rauhut and Schwab in Math Comput 86(304):661–700, 2017). We expect that our results provide a starting point for a new line of research on sublinear-time solution techniques for UQ applications of the type above which will eventually be able to scale to significantly higher-dimensional problems than what are currently computationally feasible. More concretely, let $${\mathcal {B}}$$ be a finite Bounded Orthonormal Product Basis (BOPB) of cardinality $$|{\mathcal {B}}| = N$$ . Herein we will develop methods that rapidly approximate any function f that is sparse in the BOPB, that is, $$f: {\mathcal {D}} \subset {\mathbb {R}}^D \rightarrow {\mathbb {C}}$$ of the form $$\begin{aligned} f(\varvec{x}) = \sum _{b \in {\mathcal {S}}} c_b \cdot b(\varvec{x}) \end{aligned}$$ with $${\mathcal {S}} \subset {\mathcal {B}}$$ of cardinality $$|{\mathcal {S}}| = s \ll N$$ . Our method adapts the CoSaMP algorithm (Needell and Tropp in Appl Comput Harmon Anal 26(3):301–321, 2009) to use additional function samples from f along a randomly constructed grid $${\mathcal {G}} \subset {\mathbb {R}}^D$$ with universal approximation properties in order to rapidly identify the multi-indices of the most dominant basis functions in $${\mathcal {S}}$$ component by component during each CoSaMP iteration. It has a runtime of just $$(s \log N)^{{\mathcal {O}}(1)}$$ , uses only $$(s \log N)^{{\mathcal {O}}(1)}$$ function evaluations on the fixed and nonadaptive grid $${\mathcal {G}}$$ , and requires not more than $$(s \log N)^{{\mathcal {O}}(1)}$$ bits of memory. We emphasize that nothing about $${\mathcal {S}}$$ or any of the coefficients $$c_b \in {\mathbb {C}}$$ is assumed in advance other than that $${\mathcal {S}} \subset {\mathcal {B}}$$ has $$|{\mathcal {S}}| \le s$$ . Both $${\mathcal {S}}$$ and its related coefficients $$c_b$$ will be learned from the given function evaluations by the developed method. For $$s\ll N$$ , the runtime $$(s \log N)^{{\mathcal {O}}(1)}$$ will be less than what is required to simply enumerate the elements of the basis $${\mathcal {B}}$$ ; thus our method is the first approach applicable in a general BOPB framework that falls into the class referred to as sublinear-time. This and the similarly reduced sample and memory requirements set our algorithm apart from previous works based on standard compressive sensing algorithms such as basis pursuit which typically store and utilize full intermediate basis representations of size $$\varOmega (N)$$ during the solution process.},
  archive      = {J_FoCM},
  author       = {Choi, Bosu and Iwen, Mark A. and Krahmer, Felix},
  doi          = {10.1007/s10208-020-09462-z},
  journal      = {Foundations of Computational Mathematics},
  number       = {2},
  pages        = {275-329},
  shortjournal = {Found. Comput. Math.},
  title        = {Sparse harmonic transforms: A new class of sublinear-time algorithms for learning functions of many variables},
  volume       = {21},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Data analysis from empirical moments and the christoffel
function. <em>FoCM</em>, <em>21</em>(1), 243–273. (<a
href="https://doi.org/10.1007/s10208-020-09451-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spectral features of the empirical moment matrix constitute a resourceful tool for unveiling properties of a cloud of points, among which, density, support and latent structures. This matrix is readily computed from an input dataset, and its eigen decomposition can then be used to identify algebraic properties of the support or density/support estimates with the Christoffel function. It is already well known that the empirical moment matrix encodes a great deal of subtle attributes of the underlying measure. Starting from this object as base of observations, we combine ideas from statistics, real algebraic geometry, orthogonal polynomials and approximation theory for opening new insights relevant for machine learning problems with data supported on algebraic sets. Refined concepts and results from real algebraic geometry and approximation theory are empowering a simple tool (the empirical moment matrix) for the task of solving non-trivial questions in data analysis. We provide (1) theoretical support, (2) numerical experiments and (3) connections to real-world data as a validation of the stamina of the empirical moment matrix approach.},
  archive      = {J_FoCM},
  author       = {Pauwels, Edouard and Putinar, Mihai and Lasserre, Jean-Bernard},
  doi          = {10.1007/s10208-020-09451-2},
  journal      = {Foundations of Computational Mathematics},
  number       = {1},
  pages        = {243-273},
  shortjournal = {Found. Comput. Math.},
  title        = {Data analysis from empirical moments and the christoffel function},
  volume       = {21},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Wavenumber-explicit hp-FEM analysis for maxwell’s equations
with transparent boundary conditions. <em>FoCM</em>, <em>21</em>(1),
125–241. (<a href="https://doi.org/10.1007/s10208-020-09452-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The time-harmonic Maxwell equations at high wavenumber k are discretized by edge elements of degree p on a mesh of width h. For the case of a ball as the computational domain and exact, transparent boundary conditions, we show quasi-optimality of the Galerkin method under the k-explicit scale resolution condition that (a) kh/p is sufficient small and (b) $$p/\ln k$$ is bounded from below.},
  archive      = {J_FoCM},
  author       = {Melenk, Jens M. and Sauter, Stefan A.},
  doi          = {10.1007/s10208-020-09452-1},
  journal      = {Foundations of Computational Mathematics},
  number       = {1},
  pages        = {125-241},
  shortjournal = {Found. Comput. Math.},
  title        = {Wavenumber-explicit hp-FEM analysis for maxwell’s equations with transparent boundary conditions},
  volume       = {21},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Perturbations of christoffel–darboux kernels: Detection of
outliers. <em>FoCM</em>, <em>21</em>(1), 71–124. (<a
href="https://doi.org/10.1007/s10208-020-09458-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Two central objects in constructive approximation, the Christoffel–Darboux kernel and the Christoffel function, encode ample information about the associated moment data and ultimately about the possible generating measures. We develop a multivariate theory of the Christoffel–Darboux kernel in $$\mathbb {C}^d$$ , with emphasis on the perturbation of Christoffel functions and their level sets with respect to perturbations of small norm or low rank. The statistical notion of leverage score provides a quantitative criterion for the detection of outliers in large data. Using the refined theory of Bergman orthogonal polynomials, we illustrate the main results, including some numerical simulations, in the case of finite atomic perturbations of area measure of a 2D region. Methods of function theory of a complex variable and (pluri) potential theory are widely used in the derivation of our perturbation formulas.},
  archive      = {J_FoCM},
  author       = {Beckermann, Bernhard and Putinar, Mihai and Saff, Edward B. and Stylianopoulos, Nikos},
  doi          = {10.1007/s10208-020-09458-9},
  journal      = {Foundations of Computational Mathematics},
  number       = {1},
  pages        = {71-124},
  shortjournal = {Found. Comput. Math.},
  title        = {Perturbations of Christoffel–Darboux kernels: Detection of outliers},
  volume       = {21},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Real quadratic julia sets can have arbitrarily high
complexity. <em>FoCM</em>, <em>21</em>(1), 59–69. (<a
href="https://doi.org/10.1007/s10208-020-09457-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We show that there exist real parameters $$c\in (-2,0)$$ for which the Julia set $$J_{c}$$ of the quadratic map $$z^{2} + c$$ has arbitrarily high computational complexity. More precisely, we show that for any given complexity threshold T(n), there exist a real parameter c such that the computational complexity of computing $$J_{c}$$ with n bits of precision is higher than T(n). This is the first known class of real parameters with a non-poly-time computable Julia set.},
  archive      = {J_FoCM},
  author       = {Rojas, Cristobal and Yampolsky, Michael},
  doi          = {10.1007/s10208-020-09457-w},
  journal      = {Foundations of Computational Mathematics},
  number       = {1},
  pages        = {59-69},
  shortjournal = {Found. Comput. Math.},
  title        = {Real quadratic julia sets can have arbitrarily high complexity},
  volume       = {21},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). On the complexity exponent of polynomial system solving.
<em>FoCM</em>, <em>21</em>(1), 1–57. (<a
href="https://doi.org/10.1007/s10208-020-09453-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a probabilistic Las Vegas algorithm for solving sufficiently generic square polynomial systems over finite fields. We achieve a nearly quadratic running time in the number of solutions, for densely represented input polynomials. We also prove a nearly linear bit complexity bound for polynomial systems with rational coefficients. Our results are obtained using the combination of the Kronecker solver and a new improved algorithm for fast multivariate modular composition.},
  archive      = {J_FoCM},
  author       = {van der Hoeven, Joris and Lecerf, Grégoire},
  doi          = {10.1007/s10208-020-09453-0},
  journal      = {Foundations of Computational Mathematics},
  number       = {1},
  pages        = {1-57},
  shortjournal = {Found. Comput. Math.},
  title        = {On the complexity exponent of polynomial system solving},
  volume       = {21},
  year         = {2021},
}
</textarea>
</details></li>
</ul>

</body>
</html>
