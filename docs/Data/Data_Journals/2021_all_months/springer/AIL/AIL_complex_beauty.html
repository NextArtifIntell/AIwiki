<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>AIL_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="ail---21">AIL - 21</h2>
<ul>
<li><details>
<summary>
(2021). Compliance-aware engineering process plans: The case of
space software engineering processes. <em>AIL</em>, <em>29</em>(4),
587–627. (<a href="https://doi.org/10.1007/s10506-021-09285-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Safety-critical systems manufacturers have the duty of care, i.e., they should take correct steps while performing acts that could foreseeably harm others. Commonly, industry standards prescribe reasonable steps in their process requirements, which regulatory bodies trust. Manufacturers perform careful documentation of compliance with each requirement to show that they act under acceptable criteria. To facilitate this task, a safety-centered planning-time framework, called ACCEPT, has been proposed. Based on compliance-by-design, ACCEPT capabilities (i.e., processes and standards modeling, and automatic compliance checking) permit to design Compliance-aware Engineering Process Plans (CaEPP), which are able to show the planning-time allocation of standard demands, i.e., if the elements set down by the standard requirements are present at given points in the engineering process plan. In this paper, we perform a case study to understand if the ACCEPT produced models could support the planning of space software engineering processes. Space software is safety and mission-critical, and it is often the result of industrial cooperation. Such cooperation is coordinated through compliance with relevant standards. In the European context, ECSS-E-ST-40C is the de-facto standard for space software production. The planning of processes in compliance with project-specific ECSS-E-ST-40C applicable requirements is mandatory during contractual agreements. Our analysis is based on qualitative criteria targeting the effort dictated by task demands required to create a CaEPP for software development with ACCEPT. Initial observations show that the effort required to model compliance and processes artifacts is significant. However, such an effort pays off in the long term since models are, to some extend, reusable and flexible. The coverage level of the models is also analyzed based on design decisions. In our opinion, such a level is adequate since it responds to the information needs required by the ECSS-E-ST-40C framework.},
  archive      = {J_AIL},
  author       = {Castellanos-Ardila, Julieth Patricia and Gallina, Barbara and Governatori, Guido},
  doi          = {10.1007/s10506-021-09285-5},
  journal      = {Artificial Intelligence and Law},
  month        = {12},
  number       = {4},
  pages        = {587-627},
  shortjournal = {Artif. Intell. Law},
  title        = {Compliance-aware engineering process plans: The case of space software engineering processes},
  volume       = {29},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A formal analysis of some factor- and precedent-based
accounts of precedential constraint. <em>AIL</em>, <em>29</em>(4),
559–585. (<a href="https://doi.org/10.1007/s10506-021-09284-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper several recent factor- and dimension-based models of precedential constraint are formally investigated and an alternative dimension-based model is proposed. Simple factor- and dimension-based syntactic criteria are identified for checking whether a decision in a new case is forced, in terms of the relevant differences between a precedent and a new case, and the difference between absence of factors and negated factors in factor-based models is investigated. Then Horty’s and Rigoni’s recent dimension-based models of precedential constraint are critically examined. An alternative to their reason models is proposed which is less expressive but arguably easier to apply in practice.},
  archive      = {J_AIL},
  author       = {Prakken, Henry},
  doi          = {10.1007/s10506-021-09284-6},
  journal      = {Artificial Intelligence and Law},
  month        = {12},
  number       = {4},
  pages        = {559-585},
  shortjournal = {Artif. Intell. Law},
  title        = {A formal analysis of some factor- and precedent-based accounts of precedential constraint},
  volume       = {29},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Resolving counterintuitive consequences in law using legal
debugging. <em>AIL</em>, <em>29</em>(4), 541–557. (<a
href="https://doi.org/10.1007/s10506-021-09283-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There are cases in which the literal interpretation of statutes may lead to counterintuitive consequences. When such cases go to high courts, judges may handle these counterintuitive consequences by identifying problematic rule conditions. Given that the law consists of a large number of rule conditions, it is demanding and exhaustive to figure out which condition is problematic. For solving this problem, our work aims to assist judges in civil law systems to resolve counterintuitive consequences using logic program representation of statutes and Legal Debugging. The core principle of Legal Debugging is to cooperate with a user to find a culprit, a root cause of counterintuitive consequences. This article proposes an algorithm to resolve a culprit. Since the statutes are represented by logic rules but changes in law are initiated by cases, we adopt a prototypical case with judgement specified by a set of rules. Then, to resolve a culprit, we reconstruct a program so that it provides reasons as if we applied case-based reasoning to a new set of prototypical cases with judgement, which include a new set of facts relevant to a considering case.},
  archive      = {J_AIL},
  author       = {Fungwacharakorn, Wachara and Tsushima, Kanae and Satoh, Ken},
  doi          = {10.1007/s10506-021-09283-7},
  journal      = {Artificial Intelligence and Law},
  month        = {12},
  number       = {4},
  pages        = {541-557},
  shortjournal = {Artif. Intell. Law},
  title        = {Resolving counterintuitive consequences in law using legal debugging},
  volume       = {29},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The linked legal data landscape: Linking legal data across
different countries. <em>AIL</em>, <em>29</em>(4), 485–539. (<a
href="https://doi.org/10.1007/s10506-021-09282-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The European Union is working towards harmonizing legislation across Europe, in order to improve cross-border interchange of legal information. This goal is supported for instance via standards such as the European Law Identifier (ELI) and the European Case Law Identifier (ECLI), which provide technical specifications for Web identifiers and suggestions for vocabularies to be used to describe metadata pertaining to legal documents in a machine readable format. Notably, these ECLI and ELI metadata standards adhere to the RDF data format which forms the basis of Linked Data, and therefore have the potential to form a basis for a pan-European legal Knowledge Graph. Unfortunately, to date said specifications have only been partially adopted by EU member states. In this paper we describe a methodology to transform the existing legal information system used in Austria to such a legal knowledge graph covering different steps from modeling national specific aspects, to population, and finally the integration of legal data from other countries through linked data. We demonstrate the usefulness of this approach by exemplifying practical use cases from legal information search, which are not possible in an automated fashion so far.},
  archive      = {J_AIL},
  author       = {Filtz, Erwin and Kirrane, Sabrina and Polleres, Axel},
  doi          = {10.1007/s10506-021-09282-8},
  journal      = {Artificial Intelligence and Law},
  month        = {12},
  number       = {4},
  pages        = {485-539},
  shortjournal = {Artif. Intell. Law},
  title        = {The linked legal data landscape: Linking legal data across different countries},
  volume       = {29},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Two-layered fuzzy logic-based model for predicting court
decisions in construction contract disputes. <em>AIL</em>,
<em>29</em>(4), 453–484. (<a
href="https://doi.org/10.1007/s10506-021-09281-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The dynamic nature and increasing complexity of the construction industry have led to increased conflicts in construction projects. An accurate prediction of the outcome of a dispute resolution in courts could effectively reduce the number of disputes that would otherwise conclude by spending more money through litigation. This study aims to introduce a two-layered fuzzy logic model for predicting court decisions in construction contract disputes. 100 cases of construction contract disputes are selected from the courts of Iran. A questionnaire survey is then conducted to extract a set of fuzzy rules for identifying important decision parameters and expert knowledge. Accordingly, a two-layered fuzzy logic-based decision-making architecture is proposed for the prediction model. Furthermore, the fuzzy system is trained based on 10-fold cross-validation. Analysis of results indicates that 51 out of the 100 cases are filed after the dissolution and termination of the contract show a significant impact of these clauses as the root cause in construction contract disputes. Our results present a proposed hierarchical fuzzy system that can correctly predict nearly 60% of the test data. Also, we demonstrate a methodology of using argument before ML to establish interpretable AI models. Based on our findings, a fuzzy model with a hierarchical structure may be used as a simple and efficient method for predicting court decisions in construction contract disputes.},
  archive      = {J_AIL},
  author       = {Bagherian-Marandi, Navid and Ravanshadnia, Mehdi and Akbarzadeh-T, Mohammad-R.},
  doi          = {10.1007/s10506-021-09281-9},
  journal      = {Artificial Intelligence and Law},
  month        = {12},
  number       = {4},
  pages        = {453-484},
  shortjournal = {Artif. Intell. Law},
  title        = {Two-layered fuzzy logic-based model for predicting court decisions in construction contract disputes},
  volume       = {29},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Unsupervised approaches for measuring textual similarity
between legal court case reports. <em>AIL</em>, <em>29</em>(3), 417–451.
(<a href="https://doi.org/10.1007/s10506-020-09280-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the domain of legal information retrieval, an important challenge is to compute similarity between two legal documents. Precedents (statements from prior cases) play an important role in The Common Law system, where lawyers need to frequently refer to relevant prior cases. Measuring document similarity is one of the most crucial aspects of any document retrieval system which decides the speed, scalability and accuracy of the system. Text-based and network-based methods for computing similarity among case reports have already been proposed in prior works but not without a few pitfalls. Since legal citation networks are generally highly disconnected, network based metrics are not suited for them. Till date, only a few text-based and predominant embedding based methods have been employed, for instance, TF-IDF based approaches, Word2Vec (Mikolov et al. 2013) and Doc2Vec (Le and Mikolov 2014) based approaches. We investigate the performance of 56 different methodologies for computing textual similarity across court case statements when applied on a dataset of Indian Supreme Court Cases. Among the 56 different methods, thirty are adaptations of existing methods and twenty-six are our proposed methods. The methods studied include models such as BERT (Devlin et al. 2018) and Law2Vec (Ilias 2019). It is observed that the more traditional methods (such as the TF-IDF and LDA) that rely on a bag-of-words representation performs better than the more advanced context-aware methods (like BERT and Law2Vec) for computing document-level similarity. Finally we nominate, via empirical validation, five of our best performing methods as appropriate for measuring similarity between case reports. Among these five, two are adaptations of existing methods and the other three are our proposed methods.},
  archive      = {J_AIL},
  author       = {Mandal, Arpan and Ghosh, Kripabandhu and Ghosh, Saptarshi and Mandal, Sekhar},
  doi          = {10.1007/s10506-020-09280-2},
  journal      = {Artificial Intelligence and Law},
  month        = {9},
  number       = {3},
  pages        = {417-451},
  shortjournal = {Artif. Intell. Law},
  title        = {Unsupervised approaches for measuring textual similarity between legal court case reports},
  volume       = {29},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Who is obliged when many are involved? Labelled transition
system modelling of how obligation arises. <em>AIL</em>, <em>29</em>(3),
395–415. (<a href="https://doi.org/10.1007/s10506-020-09279-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paper tackles the problem of the relation between rights and obligations. Two examples of situations in which such a relation occurs are discussed. One concerns the abortion regulations in Polish law, the other one—a clash between freedom of expression and freedom of enterprise occurring in the context of discrimination. The examples are analysed and formalised using labelled transition systems in the $$n\mathcal {C}+$$ framework. Rights are introduced to the system as procedures allowing for their fulfilment. Obligations are based on the requirement of cooperation in the realisation of the goals of the agent that has a right. If the right of an agent cannot be fulfilled without an action of another agent, then that action is obligatory for that agent. If there are many potential contributors who are individually allowed to refuse, then the last of them is obliged to help when all the others have already refused. By means of formalisation this account of the relation under consideration is precisely expressed and shown consistent.},
  archive      = {J_AIL},
  author       = {Kulicki, Piotr and Trypuz, Robert and Sergot, Marek},
  doi          = {10.1007/s10506-020-09279-9},
  journal      = {Artificial Intelligence and Law},
  month        = {9},
  number       = {3},
  pages        = {395-415},
  shortjournal = {Artif. Intell. Law},
  title        = {Who is obliged when many are involved? labelled transition system modelling of how obligation arises},
  volume       = {29},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Mīmāṃsā deontic reasoning using specificity: A proof
theoretic approach. <em>AIL</em>, <em>29</em>(3), 351–394. (<a
href="https://doi.org/10.1007/s10506-020-09278-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Over the course of more than two millennia the philosophical school of Mīmāṃsā has thoroughly analyzed normative statements. In this paper we approach a formalization of the deontic system which is applied but never explicitly discussed in Mīmāṃsā to resolve conflicts between deontic statements by giving preference to the more specific ones. We first extend with prohibitions and recommendations the non-normal deontic logic extracted in Ciabattoni et al. (in: TABLEAUX 2015, volume 9323 of LNCS, Springer, 2015) from Mīmāṃsā texts, obtaining a multimodal dyadic version of the deontic logic $$\mathsf {MD}$$ . Sequent calculus is then used to close a set of prima-facie injunctions under a restricted form of monotonicity, using specificity to avoid conflicts. We establish decidability and complexity results, and investigate the potential use of the resulting system for Mīmāṃsā philosophy and, more generally, for the formal interpretation of normative statements.},
  archive      = {J_AIL},
  author       = {Lellmann, Björn and Gulisano, Francesca and Ciabattoni, Agata},
  doi          = {10.1007/s10506-020-09278-w},
  journal      = {Artificial Intelligence and Law},
  month        = {9},
  number       = {3},
  pages        = {351-394},
  shortjournal = {Artif. Intell. Law},
  title        = {Mīmāṃsā deontic reasoning using specificity: A proof theoretic approach},
  volume       = {29},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). On argument acceptability change towards legal
interpretation dynamics. <em>AIL</em>, <em>29</em>(3), 311–350. (<a
href="https://doi.org/10.1007/s10506-020-09277-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a formal theory built upon an abstract argumentation framework for handling argumentation dynamics. To that end, we analyze the acceptability dynamics of arguments through the proposal of two different kinds of sets of arguments which are somehow responsible for the acceptability/rejection of a given argument. We develop a study of the consequences of breaking the construction of such sets towards the acceptance of an analyzed argument. This brings about the proposal of a novel change operation which allows to determine which arguments should be removed from the framework so that another particular argument becomes accepted. Finally, the proposed model is formalized in the light of the theory of belief revision by characterizing the corresponding operations through constructive definition and an axiomatic characterization, connecting them through the corresponding representation theorem. The theoretical proposal constitutes the fundamentals for a system implementation in many dynamic domains of application. In particular, we show its application for handling the dynamics of legal interpretation. In that sense, this proposal constitutes a fundamental approach and theoretical justification to handle the dynamics of legal arguments through changes of interpretative canons. We show a possible concretisation of our abstract theory for the legal domain by analysing a real legal case from the Argentinean jurisprudence. Such a system would be capable of suggesting alternative critical points in the current state of affairs of a legal case towards pursuing a specific goal for which the case is being investigated.},
  archive      = {J_AIL},
  author       = {Moguillansky, Martín O. and Tamargo, Luciano H.},
  doi          = {10.1007/s10506-020-09277-x},
  journal      = {Artificial Intelligence and Law},
  month        = {9},
  number       = {3},
  pages        = {311-350},
  shortjournal = {Artif. Intell. Law},
  title        = {On argument acceptability change towards legal interpretation dynamics},
  volume       = {29},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Automatically running experiments on checking multi-party
contracts. <em>AIL</em>, <em>29</em>(3), 287–310. (<a
href="https://doi.org/10.1007/s10506-020-09276-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Contracts play an important role in business management where relationships among different parties are dictated by legal rules. Electronic contracts have emerged mostly due to technological advances and electronic trading between companies and customers. New challenges have then arisen to guarantee reliability among the stakeholders in electronic negotiations. In this scenario, automatic verification of electronic contracts appeared as an imperative support, specially the conflict detection task of multi-party contracts. The problem of checking contracts has been largely addressed in the literature, but there are few, if any, methods and practical tools that can deal with multi-party contracts using a contract language with deontic and dynamic aspects as well as relativizations, over the same formalism. In this work we present an automatic checker for finding conflicts on multi-party contracts modeled by an extended contract language with deontic operators and relativizations. Moreover a well-known case study of sales contract is modeled and automatically verified by our tool. Further, we performed practical experiments in order to evaluate the efficiency of our method and the practical tool.},
  archive      = {J_AIL},
  author       = {Bonifacio, Adilson Luiz and Della Mura, Wellington Aparecido},
  doi          = {10.1007/s10506-020-09276-y},
  journal      = {Artificial Intelligence and Law},
  month        = {9},
  number       = {3},
  pages        = {287-310},
  shortjournal = {Artif. Intell. Law},
  title        = {Automatically running experiments on checking multi-party contracts},
  volume       = {29},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Modifying the reason model. <em>AIL</em>, <em>29</em>(2),
271–285. (<a href="https://doi.org/10.1007/s10506-020-09275-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In previous work, I showed how the “reason model” of precedential constraint could naturally be generalized from the standard setting in which it was first developed to a richer setting in which dimensional information is represented as well. Surprisingly, it then turned out that, in this new dimensional setting, the reason model of constraint collapsed into the “result model,” which supports only a fortiori reasoning. The purpose of this note is to suggest a modification of the reason model of constraint that distinguishes it from the result model even in the dimensional setting.},
  archive      = {J_AIL},
  author       = {Horty, John},
  doi          = {10.1007/s10506-020-09275-z},
  journal      = {Artificial Intelligence and Law},
  month        = {6},
  number       = {2},
  pages        = {271-285},
  shortjournal = {Artif. Intell. Law},
  title        = {Modifying the reason model},
  volume       = {29},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The promise and pitfall of automated text-scaling techniques
for the analysis of jurisprudential change. <em>AIL</em>,
<em>29</em>(2), 239–269. (<a
href="https://doi.org/10.1007/s10506-020-09274-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {I consider the potential of eight text-scaling methods for the analysis of jurisprudential change. I use a small corpus of well-documented German Federal Constitutional Court opinions on European integration to compare the machine-generated scores to scholarly accounts of the case law and legal expert ratings. Naive Bayes, Word2Vec, Correspondence Analysis and Latent Semantic Analysis appear to perform well. Less convincing are the performance of Wordscores, ML Affinity and lexicon-based sentiment analysis. While both the high-dimensionality of judicial texts and the validation of computer-based jurisprudential estimates pose major methodological challenges, I conclude that automated text-scaling methods hold out great promise for legal research.},
  archive      = {J_AIL},
  author       = {Dyevre, Arthur},
  doi          = {10.1007/s10506-020-09274-0},
  journal      = {Artificial Intelligence and Law},
  month        = {6},
  number       = {2},
  pages        = {239-269},
  shortjournal = {Artif. Intell. Law},
  title        = {The promise and pitfall of automated text-scaling techniques for the analysis of jurisprudential change},
  volume       = {29},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Scalable and explainable legal prediction. <em>AIL</em>,
<em>29</em>(2), 213–238. (<a
href="https://doi.org/10.1007/s10506-020-09273-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Legal decision-support systems have the potential to improve access to justice, administrative efficiency, and judicial consistency, but broad adoption of such systems is contingent on development of technologies with low knowledge-engineering, validation, and maintenance costs. This paper describes two approaches to an important form of legal decision support—explainable outcome prediction—that obviate both annotation of an entire decision corpus and manual processing of new cases. The first approach, which uses an attention network for prediction and attention weights to highlight salient case text, was shown to be capable of predicting decisions, but attention-weight-based text highlighting did not demonstrably improve human decision speed or accuracy in an evaluation with 61 human subjects. The second approach, termed semi-supervised case annotation for legal explanations, exploits structural and semantic regularities in case corpora to identify textual patterns that have both predictable relationships to case decisions and explanatory value.},
  archive      = {J_AIL},
  author       = {Branting, L. Karl and Pfeifer, Craig and Brown, Bradford and Ferro, Lisa and Aberdeen, John and Weiss, Brandy and Pfaff, Mark and Liao, Bill},
  doi          = {10.1007/s10506-020-09273-1},
  journal      = {Artificial Intelligence and Law},
  month        = {6},
  number       = {2},
  pages        = {213-238},
  shortjournal = {Artif. Intell. Law},
  title        = {Scalable and explainable legal prediction},
  volume       = {29},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Populating legal ontologies using semantic role labeling.
<em>AIL</em>, <em>29</em>(2), 171–211. (<a
href="https://doi.org/10.1007/s10506-020-09271-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article seeks to address the problem of the ‘resource consumption bottleneck’ of creating legal semantic technologies manually. It describes a semantic role labeling based information extraction system to extract definitions and norms from legislation and represent them as structured norms in legal ontologies. The output is intended to help make laws more accessible, understandable, and searchable in a legal document management system.},
  archive      = {J_AIL},
  author       = {Humphreys, Llio and Boella, Guido and van der Torre, Leendert and Robaldo, Livio and Di Caro, Luigi and Ghanavati, Sepideh and Muthuri, Robert},
  doi          = {10.1007/s10506-020-09271-3},
  journal      = {Artificial Intelligence and Law},
  month        = {6},
  number       = {2},
  pages        = {171-211},
  shortjournal = {Artif. Intell. Law},
  title        = {Populating legal ontologies using semantic role labeling},
  volume       = {29},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Legal requirements on explainability in machine learning.
<em>AIL</em>, <em>29</em>(2), 149–169. (<a
href="https://doi.org/10.1007/s10506-020-09270-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning and other black-box models are becoming more and more popular today. Despite their high performance, they may not be accepted ethically or legally because of their lack of explainability. This paper presents the increasing number of legal requirements on machine learning model interpretability and explainability in the context of private and public decision making. It then explains how those legal requirements can be implemented into machine-learning models and concludes with a call for more inter-disciplinary research on explainability.},
  archive      = {J_AIL},
  author       = {Bibal, Adrien and Lognoul, Michael and de Streel, Alexandre and Frénay, Benoît},
  doi          = {10.1007/s10506-020-09270-4},
  journal      = {Artificial Intelligence and Law},
  month        = {6},
  number       = {2},
  pages        = {149-169},
  shortjournal = {Artif. Intell. Law},
  title        = {Legal requirements on explainability in machine learning},
  volume       = {29},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Evaluating causes of algorithmic bias in juvenile criminal
recidivism. <em>AIL</em>, <em>29</em>(2), 111–147. (<a
href="https://doi.org/10.1007/s10506-020-09268-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we investigate risk prediction of criminal re-offense among juvenile defendants using general-purpose machine learning (ML) algorithms. We show that in our dataset, containing hundreds of cases, ML models achieve better predictive power than a structured professional risk assessment tool, the Structured Assessment of Violence Risk in Youth (SAVRY), at the expense of not satisfying relevant group fairness metrics that SAVRY does satisfy. We explore in more detail two possible causes of this algorithmic bias that are related to biases in the data with respect to two protected groups, foreigners and women. In particular, we look at (1) the differences in the prevalence of re-offense between protected groups and (2) the influence of protected group or correlated features in the prediction. Our experiments show that both can lead to disparity between groups on the considered group fairness metrics. We observe that methods to mitigate the influence of either cause do not guarantee fair outcomes. An analysis of feature importance using LIME, a machine learning interpretability method, shows that some mitigation methods can shift the set of features that ML techniques rely on away from demographics and criminal history which are highly correlated with sensitive features.},
  archive      = {J_AIL},
  author       = {Miron, Marius and Tolan, Songül and Gómez, Emilia and Castillo, Carlos},
  doi          = {10.1007/s10506-020-09268-y},
  journal      = {Artificial Intelligence and Law},
  month        = {6},
  number       = {2},
  pages        = {111-147},
  shortjournal = {Artif. Intell. Law},
  title        = {Evaluating causes of algorithmic bias in juvenile criminal recidivism},
  volume       = {29},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Administrative due process when using automated
decision-making in public administration: Some notes from a finnish
perspective. <em>AIL</em>, <em>29</em>(1), 87–110. (<a
href="https://doi.org/10.1007/s10506-020-09269-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Various due process provisions designed for use by civil servants in administrative decision-making may become redundant when automated decision-making is taken into use in public administration. Problems with mechanisms of good government, responsibility and liability for automated decisions and the rule of law require attention of the law-maker in adapting legal provisions to this new form of decision-making. Although the general data protection regulation of the European Union is important in acknowledging automated decision-making, most of the legal safeguards within administrative due process have to be provided for by the national law-maker. It is suggested that all countries have a need to review their rules of administrative due process with a view to bringing them up to date regarding the requirements of automated decision-making. In whichever way the legislation is framed, the key issues are that persons who develop the algorithm and the code as well as persons who run or deal with the software within public authorities are aware of the preventive safeguards of legality in the context of automated decision-making, not only of the reactive safeguards constituted by the complaint procedures, and that legal mechanisms exist under which these persons can be held accountable and liable for decisions produced by automated decision-making. It is also argued that only rule-based systems of automatized decision-making are compatible with the rule of law and that there is a general interest in preventing a development into a rule of algorithm.},
  archive      = {J_AIL},
  author       = {Suksi, Markku},
  doi          = {10.1007/s10506-020-09269-x},
  journal      = {Artificial Intelligence and Law},
  month        = {3},
  number       = {1},
  pages        = {87-110},
  shortjournal = {Artif. Intell. Law},
  title        = {Administrative due process when using automated decision-making in public administration: Some notes from a finnish perspective},
  volume       = {29},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Law and software agents: Are they “agents” by the way?
<em>AIL</em>, <em>29</em>(1), 59–86. (<a
href="https://doi.org/10.1007/s10506-020-09265-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Using intelligent software agents in the world of e-commerce may give rise to many difficulties especially with regard to the validity of agent-based contracts and the attribution of liability for the actions of such agents. This paper thus critically examines the main approaches that have been advanced to deal with software agents, and proposes the gradual approach as a way of overcoming the difficulties of such agents by adopting different standards of responsibility depending whether the action is done autonomously by an unattended software, or whether it is done automatically by an attended software. Throughout this paper, it is argued that the introduction of “one size” regulation without sufficient consideration of the nature of software agents or the environments in which they communicate might lead to a divorce between the legal theory and technological practice. It is also concluded that it is incorrect to deal with software agents as if they were either legal persons or nothing without in any way accounting for the fact that there are various kinds of such agents endowed with different levels of autonomy, mobility, intelligence, and sophistication. However, this paper is not intended to provide the final answer to all problematic questions posed by the emergence of intelligent software agents, but is designed to provide some kind of temporary relief until such agents reach a more reliable and autonomous level whereby law begins to regard them, rather than their users, as the source of the relevant action.},
  archive      = {J_AIL},
  author       = {Dahiyat, Emad Abdel Rahim},
  doi          = {10.1007/s10506-020-09265-1},
  journal      = {Artificial Intelligence and Law},
  month        = {3},
  number       = {1},
  pages        = {59-86},
  shortjournal = {Artif. Intell. Law},
  title        = {Law and software agents: Are they “Agents” by the way?},
  volume       = {29},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Information extraction framework to build legislation
network. <em>AIL</em>, <em>29</em>(1), 35–58. (<a
href="https://doi.org/10.1007/s10506-020-09263-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper concerns an information extraction process for building a dynamic legislation network from legal documents. Unlike supervised learning approaches which require additional calculations, the idea here is to apply information extraction methodologies by identifying distinct expressions in legal text in order to extract network information. The study highlights the importance of data accuracy in network analysis and improves approximate string matching techniques to produce reliable network data-sets with more than 98% precision and recall. The applications and the complexity of the created dynamic legislation network are also discussed and challenged.},
  archive      = {J_AIL},
  author       = {Sakhaee, Neda and Wilson, Mark C.},
  doi          = {10.1007/s10506-020-09263-3},
  journal      = {Artificial Intelligence and Law},
  month        = {3},
  number       = {1},
  pages        = {35-58},
  shortjournal = {Artif. Intell. Law},
  title        = {Information extraction framework to build legislation network},
  volume       = {29},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Modeling law search as prediction. <em>AIL</em>,
<em>29</em>(1), 3–34. (<a
href="https://doi.org/10.1007/s10506-020-09261-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Law search is fundamental to legal reasoning and its articulation is an important challenge and open problem in the ongoing efforts to investigate legal reasoning as a formal process. This Article formulates a mathematical model that frames the behavioral and cognitive framework of law search as a sequential decision process. The model has two components: first, a model of the legal corpus as a search space and second, a model of the search process (or search strategy) that is compatible with that environment. The search space has the structure of a “multi-network”—an interleaved structure of distinct networks—developed in earlier work. In this Article, we develop and formally describe three related models of the search process. We then implement these models on a subset of the corpus of U.S. Supreme Court opinions and assess their performance against two benchmark prediction tasks. The first is to predict the citations in a document from its semantic content. The second is to predict the search results generated by human users. For both benchmarks, all search models outperform a null model with the learning-based model outperforming the other approaches. Our results indicate that through additional work and refinement, there may be the potential for machine law search to achieve human or near-human levels of performance.},
  archive      = {J_AIL},
  author       = {Dadgostari, Faraz and Guim, Mauricio and Beling, Peter A. and Livermore, Michael A. and Rockmore, Daniel N.},
  doi          = {10.1007/s10506-020-09261-5},
  journal      = {Artificial Intelligence and Law},
  month        = {3},
  number       = {1},
  pages        = {3-34},
  shortjournal = {Artif. Intell. Law},
  title        = {Modeling law search as prediction},
  volume       = {29},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Correction to: Modeling law search as prediction.
<em>AIL</em>, <em>29</em>(1), 1. (<a
href="https://doi.org/10.1007/s10506-020-09264-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the original publication of the article},
  archive      = {J_AIL},
  author       = {Dadgostari, Faraz and Guim, Mauricio and Beling, Peter A. and Livermore, Michael A. and Rockmore, Daniel N.},
  doi          = {10.1007/s10506-020-09264-2},
  journal      = {Artificial Intelligence and Law},
  month        = {3},
  number       = {1},
  pages        = {1},
  shortjournal = {Artif. Intell. Law},
  title        = {Correction to: Modeling law search as prediction},
  volume       = {29},
  year         = {2021},
}
</textarea>
</details></li>
</ul>

</body>
</html>
