<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>AAMAS_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="aamas---47">AAMAS - 47</h2>
<ul>
<li><details>
<summary>
(2021). Modelling and verification of reconfigurable multi-agent
systems. <em>AAMAS</em>, <em>35</em>(2), 1–36. (<a
href="https://doi.org/10.1007/s10458-021-09521-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a formalism to model and reason about reconfigurable multi-agent systems. In our formalism, agents interact and communicate in different modes so that they can pursue joint tasks; agents may dynamically synchronize, exchange data, adapt their behaviour, and reconfigure their communication interfaces. Inspired by existing multi-robot systems, we represent a system as a set of agents (each with local state), executing independently and only influence each other by means of message exchange. Agents are able to sense their local states and partially their surroundings. We extend ltl to be able to reason explicitly about the intentions of agents in the interaction and their communication protocols. We also study the complexity of satisfiability and model-checking of this extension.},
  archive      = {J_AAMAS},
  author       = {Abd Alrahman, Yehia and Piterman, Nir},
  doi          = {10.1007/s10458-021-09521-x},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  number       = {2},
  pages        = {1-36},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {Modelling and verification of reconfigurable multi-agent systems},
  volume       = {35},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Automatic calibration of dynamic and heterogeneous
parameters in agent-based models. <em>AAMAS</em>, <em>35</em>(2), 1–66.
(<a href="https://doi.org/10.1007/s10458-021-09528-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Simulation has been applied to diverse domains such as urban growth modeling and market dynamics modeling. Some of these applications may require validations, based on some real-world observations modeled in the simulation. This validation can be conducted as either qualitative face-validation or quantitative empirical validation; however, as the importance and accumulation of data grows, the importance of quantitative validation has been highlighted in recent studies. The key component of quantitative validation is finding a calibrated set of parameters to regenerate the real-world observations in the simulation models. While the parameter of interest to be calibrated has hitherto been fixed throughout simulation executions, we expand the static parameter calibration in two dimensions in this study, dynamically and heterogeneously. The dynamic calibration changes the parameter values over the simulation period by reflecting the simulation output trend, and the heterogeneous calibration changes the parameter values per simulated entity clusters by considering the similarities of the entity states. We experimented with the proposed calibrations on a hypothetical case and a real-world case. For the hypothetical scenario, we used the wealth distribution model to illustrate how our calibration works. For the real-world scenario, we selected the real estate market model. The models were selected, because of two reasons. First, they have heterogeneous entities, being agent-based models. Second, they are agent-based models exhibiting real-world trends over time.},
  archive      = {J_AAMAS},
  author       = {Kim, Dongjun and Yun, Tae-Sub and Moon, Il-Chul and Bae, Jang Won},
  doi          = {10.1007/s10458-021-09528-4},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  number       = {2},
  pages        = {1-66},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {Automatic calibration of dynamic and heterogeneous parameters in agent-based models},
  volume       = {35},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Enabling BDI group plans with coordination middleware:
Semantics and implementation. <em>AAMAS</em>, <em>35</em>(2), 1–40. (<a
href="https://doi.org/10.1007/s10458-021-09525-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the use of group goals and plans as programming abstractions that provide explicit constructs for goals and plans involving coordinated action by groups of agents, with a focus on the BDI agent model. We define a group goal construct, which specifies subgoals that the group members must satisfy for the group goal to succeed, subject to timeouts on the members beginning work on the goal, and then completing their subgoals. A group plan containing one or more group goals can be dynamically distributed amongst a set of agents and jointly executed without a need for explicit coordinating communication between agents. We define formal semantics that model the coordination needed to determine a group goal’s success or failure as updates to a shared state machine for the group goal. We implement the semantics directly as rewrite rules in Maude, and verify using LTL model checking that the intended coordination behaviour is achieved. An implementation of group plans and goals for the Jason agent platform is also described, based on an integration of Jason with the ZooKeeper coordination middleware via a set of generic Jason plans supporting group goals, and the Apache Camel integration framework. A evaluation of the performance of this implementation is presented, showing that the approach is scalable.},
  archive      = {J_AAMAS},
  author       = {Cranefield, Stephen},
  doi          = {10.1007/s10458-021-09525-7},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  number       = {2},
  pages        = {1-40},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {Enabling BDI group plans with coordination middleware: Semantics and implementation},
  volume       = {35},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Utility distribution matters: Enabling fast belief
propagation for multi-agent optimization with dense local utility
function. <em>AAMAS</em>, <em>35</em>(2), 1–40. (<a
href="https://doi.org/10.1007/s10458-021-09511-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Belief propagation algorithms including Max-sum and its variants are important methods for multi-agent optimization. However, they face a significant scalability challenge as the computational overhead grows exponentially with respect to the arity of each utility function. To date, a number of acceleration algorithms for belief propagation algorithms were proposed. These algorithms maintain a lower bound on total utility and employ either a domain pruning technique or branch and bound to reduce the search space. However, these algorithms still suffer from low-quality bounds and the inability of filtering out suboptimal tied entries. In this paper, we first show that these issues are exacerbated and can considerably degenerate the performance of the state-of-the-art methods when dealing with the problems with dense utility functions, which widely exist in many real-world domains. Built on this observation, we then develop several novel acceleration algorithms that alleviate the effect of densely distributed local utility values from the perspectives of both bound quality and search space organization. Specifically, we build a search tree for each distinct local utility value to enable efficient branch and bound on tied entries and tighten a running lower bound to perform dynamic domain pruning. That is, we integrate both search and pruning to iteratively reduce the search space. Besides, we propose a discretization mechanism to offer a tradeoff between the reconstruction overhead and the pruning efficiency. Finally, a K-depth partial tree-sorting scheme with different sorting criteria is proposed to reduce the memory consumption. We demonstrate the superiorities of our algorithms over the state-of-the-art acceleration algorithms from both theoretical and experimental perspectives.},
  archive      = {J_AAMAS},
  author       = {Deng, Yanchen and An, Bo},
  doi          = {10.1007/s10458-021-09511-z},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  number       = {2},
  pages        = {1-40},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {Utility distribution matters: Enabling fast belief propagation for multi-agent optimization with dense local utility function},
  volume       = {35},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Arguing and negotiating using incomplete negotiators
profiles. <em>AAMAS</em>, <em>35</em>(2), 1–40. (<a
href="https://doi.org/10.1007/s10458-021-09493-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Computational argumentation has taken a predominant place in the modeling of negotiation dialogues over the last years. A competent agent participating in a negotiation process is expected to decide its next move taking into account an, often incomplete, model of its opponent. This work provides a complete computational account of argumentation-based negotiation under incomplete opponent profiles. After the agent identifies its best option, in any state of a negotiation, it looks for suitable arguments that support this option in the theory of its opponent. As the knowledge on the opponent is uncertain, the challenge is to find arguments that, ideally, support the selected option despite the uncertainty. We present a negotiation framework based on these ideas, along with experimental evidence that highlights the advantages of our approach.},
  archive      = {J_AAMAS},
  author       = {Dimopoulos, Yannis and Mailly, Jean-Guy and Moraitis, Pavlos},
  doi          = {10.1007/s10458-021-09493-y},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  number       = {2},
  pages        = {1-40},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {Arguing and negotiating using incomplete negotiators profiles},
  volume       = {35},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Goal-driven active learning. <em>AAMAS</em>, <em>35</em>(2),
1–29. (<a href="https://doi.org/10.1007/s10458-021-09527-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep reinforcement learning methods have achieved significant successes in complex decision-making problems. In fact, they traditionally rely on well-designed extrinsic rewards, which limits their applicability to many real-world tasks where rewards are naturally sparse. While cloning behaviors provided by an expert is a promising approach to the exploration problem, learning from a fixed set of demonstrations may be impracticable due to lack of state coverage or distribution mismatch—when the learner’s goal deviates from the demonstrated behaviors. Besides, we are interested in learning how to reach a wide range of goals from the same set of demonstrations. In this work we propose a novel goal-conditioned method that leverages very small sets of goal-driven demonstrations to massively accelerate the learning process. Crucially, we introduce the concept of active goal-driven demonstrations to query the demonstrator only in hard-to-learn and uncertain regions of the state space. We further present a strategy for prioritizing sampling of goals where the disagreement between the expert and the policy is maximized. We evaluate our method on a variety of benchmark environments from the Mujoco domain. Experimental results show that our method outperforms prior imitation learning approaches in most of the tasks in terms of exploration efficiency and average scores.},
  archive      = {J_AAMAS},
  author       = {Bougie, Nicolas and Ichise, Ryutaro},
  doi          = {10.1007/s10458-021-09527-5},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  number       = {2},
  pages        = {1-29},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {Goal-driven active learning},
  volume       = {35},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Revenue maximizing markets for zero-day exploits.
<em>AAMAS</em>, <em>35</em>(2), 1–29. (<a
href="https://doi.org/10.1007/s10458-021-09522-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Markets for zero-day exploits (software vulnerabilities unknown to the software vendor) have a long history and a growing popularity. We study these markets from a revenue-maximizing mechanism design perspective. We first propose a theoretical model for zero-day exploits markets. In our model, one exploit is being sold to multiple buyers. There are two kinds of buyers, which we call the defenders and the offenders. The defenders are buyers who buy vulnerabilities in order to fix them (e.g., software vendors). The offenders, on the other hand, are buyers who intend to utilize the exploits (e.g., national security agencies and police). We study the problem of selling one zero-day exploit to multiple defenders and offenders. Our model has a few unique features that make it different from single-item auctions. First, an exploit is a piece of information, so one exploit can be sold to multiple buyers. Second, buyers have externalities. If any defender wins, then the exploit becomes worthless to the offenders. Third, if the auctioneer discloses the details of the exploit to the buyers before the auction, then they may leave with the information without paying. On the other hand, if the auctioneer does not disclose enough details, then the buyers cannot determine how valuable the exploit is. Considering the above, our proposed mechanism discloses the details of the exploit to all offenders at the beginning of the auction. The defenders will receive the information slightly delayed. The offenders bid to prolong the delay and the defenders bid to shorten the delay. We derive the optimal mechanism for single-parameter valuations. For general valuations, we propose three numerical solution techniques. One is based on iterative linear programming and the other two are based on neural networks and evolutionary computation.},
  archive      = {J_AAMAS},
  author       = {Guo, Mingyu and Wang, Guanhua and Hata, Hideaki and Babar, Muhammad Ali},
  doi          = {10.1007/s10458-021-09522-w},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  number       = {2},
  pages        = {1-29},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {Revenue maximizing markets for zero-day exploits},
  volume       = {35},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Automated narrative planning model extension.
<em>AAMAS</em>, <em>35</em>(2), 1–29. (<a
href="https://doi.org/10.1007/s10458-021-09501-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Interactive Narrative is an emerging application of automated planning, in which a planning domain is used to generate a consistent chain of narrative actions that constitute a plot structure. The task of creating narrative planning domains has been identified as a bottleneck which is hampering further development of the field. This stems from the difficulties faced by humans authoring such planning domains due to the need to provide the range of alternative content, such as actions, which are required to support the important properties of diversity and robustness. Narrative planning domains must be capable of generating diverse sets of narratives to ensure system replayability, and they must also be able to respond robustly in the face of narrative execution failure due to user interaction. In this paper, we introduce a novel approach to the development of narrative planning domains based on the automatic expansion of a baseline planning domain through application of principled operations applied to both operators and predicates. We overview two such operations in this paper. The first of these, anton for antonymic operators, is based on the generation of contrary operators that can be invoked in the face of action failure, and whose structure is derived from a model of state transitions triggered by the original operator. Since the intention is for additional operators to be incorporated to the baseline, human-authored, domain model, the generated contents should be human-readable. This is achieved by using combined linguistic resources to access antonyms of predicates occurring inside operators, and parsing them from and into hyphenated units. The second operation, part of the same approach, referred to as thype, generates variants of operators by exploring type hierarchies for the main concepts associated with individual operators; the resulting concepts being fully integrated into a new operator’s structure. Our evaluation procedures are directly derived from the target properties of narrative planning domains, which are diversity and robustness, the former being measured through plot diversity and the latter, plot continuation following planned action execution failure. We used published narrative domains as datasets for these evaluations. Results demonstrated strong generative ability, and even more significant plan completion following action failure. Moreover, our evaluation demonstrates the synergic nature of anton and thype when applied simultaneously. Future work will focus on improving the integration of anton and thype operations through better balance between linguistic and conceptual hierarchies.},
  archive      = {J_AAMAS},
  author       = {Porteous, Julie and Ferreira, João F. and Lindsay, Alan and Cavazza, Marc},
  doi          = {10.1007/s10458-021-09501-1},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  number       = {2},
  pages        = {1-29},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {Automated narrative planning model extension},
  volume       = {35},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). AGNT SI: Agents and multiagent systems for social good.
<em>AAMAS</em>, <em>35</em>(2), 1–2. (<a
href="https://doi.org/10.1007/s10458-021-09496-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_AAMAS},
  author       = {Fang, Fei},
  doi          = {10.1007/s10458-021-09496-9},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  number       = {2},
  pages        = {1-2},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {AGNT SI: Agents and multiagent systems for social good},
  volume       = {35},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). On the dominant set selection problem and its application to
value alignment. <em>AAMAS</em>, <em>35</em>(2), 1–38. (<a
href="https://doi.org/10.1007/s10458-021-09519-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Decision makers can often be confronted with the need to select a subset of objects from a set of candidate objects by just counting on preferences regarding the objects’ features. Here we formalise this problem as the dominant set selection problem. Solving this problem amounts to finding the preferences over all possible sets of objects. We accomplish so by: (i) grounding the preferences over features to preferences over the objects themselves; and (ii) lifting these preferences to preferences over all possible sets of objects. This is achieved by combining lex-cel –a method from the literature—with our novel anti-lex-cel method, which we formally (and thoroughly) study. Furthermore, we provide a binary integer program encoding to solve the problem. Finally, we illustrate our overall approach by applying it to the selection of value-aligned norm systems.},
  archive      = {J_AAMAS},
  author       = {Serramia, Marc and López-Sánchez, Maite and Moretti, Stefano and Rodríguez-Aguilar, Juan Antonio},
  doi          = {10.1007/s10458-021-09519-5},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  number       = {2},
  pages        = {1-38},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {On the dominant set selection problem and its application to value alignment},
  volume       = {35},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Towards completing the puzzle: Complexity of control by
replacing, adding, and deleting candidates or voters. <em>AAMAS</em>,
<em>35</em>(2), 1–48. (<a
href="https://doi.org/10.1007/s10458-021-09523-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We investigate the computational complexity of electoral control in elections. Electoral control describes the scenario where the election chair seeks to alter the outcome of the election by structural changes such as adding, deleting, or replacing either candidates or voters. Such control actions have been studied in the literature for a lot of prominent voting rules. We complement those results by solving several open cases for Copeland $$^{\alpha }$$ , maximin, k-veto, plurality with runoff, veto with runoff, Condorcet, fallback, range voting, and normalized range voting.},
  archive      = {J_AAMAS},
  author       = {Erdélyi, Gábor and Neveling, Marc and Reger, Christian and Rothe, Jörg and Yang, Yongjie and Zorn, Roman},
  doi          = {10.1007/s10458-021-09523-9},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  number       = {2},
  pages        = {1-48},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {Towards completing the puzzle: Complexity of control by replacing, adding, and deleting candidates or voters},
  volume       = {35},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An asymptotically optimal VCG redistribution mechanism for
the public project problem. <em>AAMAS</em>, <em>35</em>(2), 1–27. (<a
href="https://doi.org/10.1007/s10458-021-09526-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the classic public project problem, where the agents decide whether or not to build a non-excludable public project. We focus on efficient, strategy-proof, and weakly budget-balanced mechanisms (VCG redistribution mechanisms). Our aim is to maximize the worst-case efficiency ratio—the worst-case ratio between the achieved total utility and the first-best maximum total utility. Previous studies have identified an optimal mechanism for 3 agents. Unfortunately, no optimal mechanisms have been identified for more than 3 agents. We propose an automated mechanism design approach that is capable of handling worst-case objectives. With its help, we identify a different optimal mechanism for 3 agents. For more agents, we identify mechanisms with better worst-case efficiency ratios than previous results. Using a dimension reduction technique, we extend the newly identified optimal mechanism for 3 agents to n agents. The resulting mechanism’s worst-case efficiency ratio equals $$\frac{n+1}{2n}$$ . In comparison, the best previously known worst-case efficiency ratio equals 0.102 asymptotically. We then derive an asymptotically optimal mechanism under a minor technical assumption: we assume the agents’ valuations are rational numbers with bounded denominators. Previous studies conjectured that the optimal asymptotic worst-case efficiency ratio equals 1. We confirm this conjecture.},
  archive      = {J_AAMAS},
  author       = {Guo, Mingyu},
  doi          = {10.1007/s10458-021-09526-6},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  number       = {2},
  pages        = {1-27},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {An asymptotically optimal VCG redistribution mechanism for the public project problem},
  volume       = {35},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Fair cake-cutting algorithms with real land-value data.
<em>AAMAS</em>, <em>35</em>(2), 1–28. (<a
href="https://doi.org/10.1007/s10458-021-09524-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fair division of land is an important practical problem that is commonly handled either by hiring assessors or by selling and dividing the proceeds. A third way to divide land fairly is via algorithms for fair cake-cutting. Such un-intermediated methods are not only cheaper than an assessor but also theoretically fairer since they guarantee each agent a fair share according to his/her value function. However, the current theory of fair cake-cutting is not yet ready to optimally share a plot of land, and such algorithms are seldom used in practical land division. We attempt to narrow the gap between theory and practice by presenting several heuristic adaptations of famous algorithms for one-dimensional cake-cutting to two-dimensional land-division. The heuristics are evaluated using extensive simulations on real land-value data maps from three different data sets and a fourth (control) map of random values. The simulations compare the performance of cake-cutting algorithms to sale and assessor division in various performance metrics, such as utilitarian welfare, egalitarian welfare, Nash social welfare, envy, and geometric shape. The cake-cutting algorithms perform better in most metrics. However, their performance is greatly influenced by technical implementation details and heuristics that are often overlooked by theorists. We also propose a new protocol for practical cake-cutting using a dynamic programming approach and discuss its run-time complexity versus performance trade-off. Our new protocol performs better than the examined classic cake-cutting algorithms on most metrics. Experiments to assess the amount that a strategic agent can gain from reporting false preferences are also presented. The results show that the problem of strategic manipulation is much less severe than the worst-case predicted by theory.},
  archive      = {J_AAMAS},
  author       = {Shtechman, Itay and Gonen, Rica and Segal-HaLevi, Erel},
  doi          = {10.1007/s10458-021-09524-8},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  number       = {2},
  pages        = {1-28},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {Fair cake-cutting algorithms with real land-value data},
  volume       = {35},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). ANEGMA: An automated negotiation model for e-markets.
<em>AAMAS</em>, <em>35</em>(2), 1–28. (<a
href="https://doi.org/10.1007/s10458-021-09513-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a novel negotiation model that allows an agent to learn how to negotiate during concurrent bilateral negotiations in unknown and dynamic e-markets. The agent uses an actor-critic architecture with model-free reinforcement learning to learn a strategy expressed as a deep neural network. We pre-train the strategy by supervision from synthetic market data, thereby decreasing the exploration time required for learning during negotiation. As a result, we can build automated agents for concurrent negotiations that can adapt to different e-market settings without the need to be pre-programmed. Our experimental evaluation shows that our deep reinforcement learning based agents outperform two existing well-known negotiation strategies in one-to-many concurrent bilateral negotiations for a range of e-market settings.},
  archive      = {J_AAMAS},
  author       = {Bagga, Pallavi and Paoletti, Nicola and Alrayes, Bedour and Stathis, Kostas},
  doi          = {10.1007/s10458-021-09513-x},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  number       = {2},
  pages        = {1-28},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {ANEGMA: An automated negotiation model for e-markets},
  volume       = {35},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Information design in affiliate marketing. <em>AAMAS</em>,
<em>35</em>(2), 1–28. (<a
href="https://doi.org/10.1007/s10458-021-09509-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The recent massive proliferation of affiliate marketing suggests a new e-commerce paradigm which involves sellers, affiliates and the platforms that connect them. In particular, the fact that prospective buyers may become acquainted with the promotion through more than one affiliate to whom they are connected calls for new mechanisms for compensating affiliates for their promotional efforts. In this paper, we study the problem of a platform that needs to decide on the commission to be awarded to affiliates for promoting a given product or service. Our equilibrium-based analysis, which applies to the case where affiliates are a priori homogeneous and self-interested, enables showing that a minor change in the way the platform discloses information to the affiliates results in a tremendous (positive) effect on the platform’s expected profit. In particular, we show that with the revised mechanism the platform can overcome the multi-equilibria problem that arises in the traditional mechanism and obtain a profit which is at least as high as the maximum profit in any of the equilibria that hold in the latter.},
  archive      = {J_AAMAS},
  author       = {Suryanarayana, Sharadhi Alape and Sarne, David and Kraus, Sarit},
  doi          = {10.1007/s10458-021-09509-7},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  number       = {2},
  pages        = {1-28},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {Information design in affiliate marketing},
  volume       = {35},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). On coalitional manipulation for multiwinner elections:
shortlisting. <em>AAMAS</em>, <em>35</em>(2), 1–41. (<a
href="https://doi.org/10.1007/s10458-021-09507-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Shortlisting of candidates—selecting a group of “best” candidates—is a special case of multiwinner elections. We provide the first in-depth study of the computational complexity of strategic voting for shortlisting based on the perhaps most basic voting rule in this scenario, $$\ell $$ -Bloc (every voter approves $$\ell $$ candidates). In particular, we investigate the influence of several different group evaluation functions (e.g., egalitarian versus utilitarian) and tie-breaking mechanisms modeling pessimistic and optimistic manipulators. Among other things, we conclude that in an egalitarian setting strategic voting may indeed be computationally intractable regardless of the tie-breaking rule. Altogether, we provide a fairly comprehensive picture of the computational complexity landscape of this scenario.},
  archive      = {J_AAMAS},
  author       = {Bredereck, Robert and Kaczmarczyk, Andrzej and Niedermeier, Rolf},
  doi          = {10.1007/s10458-021-09507-9},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  number       = {2},
  pages        = {1-41},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {On coalitional manipulation for multiwinner elections: Shortlisting},
  volume       = {35},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Preface to the special issue on engineering reliable
multi-agent systems. <em>AAMAS</em>, <em>35</em>(2), 1–3. (<a
href="https://doi.org/10.1007/s10458-021-09520-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_AAMAS},
  author       = {Dix, Jürgen and Logan, Brian and Winikoff, Michael},
  doi          = {10.1007/s10458-021-09520-y},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  number       = {2},
  pages        = {1-3},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {Preface to the special issue on engineering reliable multi-agent systems},
  volume       = {35},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A contract-based incentive mechanism for distributed meeting
scheduling: Can agents who value privacy tell the truth? <em>AAMAS</em>,
<em>35</em>(2), 1–58. (<a
href="https://doi.org/10.1007/s10458-021-09516-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a distributed meeting scheduling problem where agents negotiate with each other to reach a consensus over the starting time of the meeting. Each agent has a private preference over a set of time slots, and aims to select its own preferred slot while revealing as little information about its preference as possible. A key challenge in this canonical setting is whether it is possible to design a distributed mechanism where agents that value their privacy are motivated to tell the truth about their preferences. In this paper, we give a positive answer by proposing a novel incentive mechanism based on economic contract theory. A set of contracts are carefully designed for agents of different types, consisting of the required actions, corresponding rewards and the privacy leakage level. By selecting the contract that maximises its own utility, each agent will not deviate from the required actions and can avoid unnecessary privacy leakage. Other properties of the mechanism such as budget balance, no need for a central authority, and near-optimal social welfare are also theoretically proved. Our empirical evaluations show that our proposed mechanism reduces privacy leakage by 58\% compared to a standard calendar-sharing scheme. The social welfare of the proposed mechanism reaches over 88\% of the optimal centralized method, and is higher than the social welfare of the state-of-the-art schemes by between 16 and 82\%. A better trade-off between the privacy leakage and the number of rounds for convergence is also achieved compared to a typical negotiation mechanism.},
  archive      = {J_AAMAS},
  author       = {Di, Boya and Jennings, Nicholas R.},
  doi          = {10.1007/s10458-021-09516-8},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  number       = {2},
  pages        = {1-58},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {A contract-based incentive mechanism for distributed meeting scheduling: Can agents who value privacy tell the truth?},
  volume       = {35},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Maximin fairness with mixed divisible and indivisible goods.
<em>AAMAS</em>, <em>35</em>(2), 1–21. (<a
href="https://doi.org/10.1007/s10458-021-09517-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study fair resource allocation when the resources contain a mixture of divisible and indivisible goods, focusing on the well-studied fairness notion of maximin share fairness (MMS). With only indivisible goods, a full MMS allocation may not exist, but a constant multiplicative approximate allocation always does. We analyze how the MMS approximation guarantee would be affected when the resources to be allocated also contain divisible goods. In particular, we show that the worst-case MMS approximation guarantee with mixed goods is no worse than that with only indivisible goods. However, there exist problem instances to which adding some divisible resources would strictly decrease the MMS approximation ratios of the instances. On the algorithmic front, we propose a constructive algorithm that will always produce an $$\alpha$$ -MMS allocation for any number of agents, where $$\alpha$$ takes values between 1/2 and 1 and is a monotonically increasing function determined by how agents value the divisible goods relative to their MMS values.},
  archive      = {J_AAMAS},
  author       = {Bei, Xiaohui and Liu, Shengxin and Lu, Xinhang and Wang, Hongao},
  doi          = {10.1007/s10458-021-09517-7},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  number       = {2},
  pages        = {1-21},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {Maximin fairness with mixed divisible and indivisible goods},
  volume       = {35},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Exploration in policy optimization through multiple paths.
<em>AAMAS</em>, <em>35</em>(2), 1–26. (<a
href="https://doi.org/10.1007/s10458-021-09518-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent years have witnessed a tremendous improvement of deep reinforcement learning. However, a challenging problem is that an agent may suffer from inefficient exploration, particularly for on-policy methods. Previous exploration methods either rely on complex structure to estimate the novelty of states, or incur sensitive hyper-parameters causing instability. We propose an efficient exploration method, Multi-Path Policy Optimization (MP-PO), which does not incur high computation cost and ensures stability. MP-PO maintains an efficient mechanism that effectively utilizes a population of diverse policies to enable better exploration, especially in sparse environments. We also give a theoretical guarantee of the stable performance. We build our scheme upon two widely-adopted on-policy methods, the Trust-Region Policy Optimization algorithm and Proximal Policy Optimization algorithm. We conduct extensive experiments on several MuJoCo tasks and their sparsified variants to fairly evaluate the proposed method. Results show that MP-PO significantly outperforms state-of-the-art exploration methods in terms of both sample efficiency and final performance.},
  archive      = {J_AAMAS},
  author       = {Pan, Ling and Cai, Qingpeng and Huang, Longbo},
  doi          = {10.1007/s10458-021-09518-6},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  number       = {2},
  pages        = {1-26},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {Exploration in policy optimization through multiple paths},
  volume       = {35},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Testing stability prop﻿erties in graphical hedonic games.
<em>AAMAS</em>, <em>35</em>(2), 1–26. (<a
href="https://doi.org/10.1007/s10458-021-09505-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In hedonic games, players form coalitions based on individual preferences over the group of players they could belong to. Several concepts to describe the stability of coalition structures in a game have been proposed and analysed in the literature. However, prior research focuses on algorithms with time complexity that is at least linear in the input size. In the light of very large games that arise from, e.g., social networks and advertising, we initiate the study of sublinear time property testing algorithms for existence and verification problems under several notions of coalition stability in a model of hedonic games represented by graphs with bounded degree. In graph property testing, one shall decide whether a given input has a property (e.g., a game admits a stable coalition structure) or is far from it, i.e., one has to modify at least an $$\epsilon$$ -fraction of the input (e.g., the game’s preferences) to make it have the property. In particular, we consider verification of perfection, individual rationality, Nash stability, (contractual) individual stability, and core stability. While there is always a Nash-stable coalition structure (which also implies individually stable coalitions), we show that the existence of a perfect coalition structure is not tautological but can be tested. All our testers have one-sided error and time complexity that is independent of the input size.},
  archive      = {J_AAMAS},
  author       = {Fichtenberger, Hendrik and Rey, Anja},
  doi          = {10.1007/s10458-021-09505-x},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  number       = {2},
  pages        = {1-26},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {Testing stability prop﻿erties in graphical hedonic games},
  volume       = {35},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A logical model for the ontology alignment repair game.
<em>AAMAS</em>, <em>35</em>(2), 1–34. (<a
href="https://doi.org/10.1007/s10458-021-09508-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ontology alignments enable agents to communicate while preserving heterogeneity in their knowledge. Alignments may not be provided as input and should be able to evolve when communication fails or when new information contradicting the alignment is acquired. The Alignment Repair Game (ARG) has been proposed for agents to simultaneously communicate and repair their alignments through adaptation operators when communication failures occur. ARG has been evaluated experimentally and the experiments showed that agents converge towards successful communication and improve their alignments. However, whether the adaptation operators are formally correct, complete or redundant could not be established by experiments. We introduce a logical model, Dynamic Epistemic Ontology Logic (DEOL), that enables us to answer these questions. This framework allows us (1) to express the ontologies and alignments used via a faithful translation from ARG to DEOL, (2) to model the ARG adaptation operators as dynamic modalities and (3) to formally define and establish the correctness, partial redundancy and incompleteness of the adaptation operators in ARG.},
  archive      = {J_AAMAS},
  author       = {van den Berg, Line and Atencia, Manuel and Euzenat, Jérôme},
  doi          = {10.1007/s10458-021-09508-8},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  number       = {2},
  pages        = {1-34},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {A logical model for the ontology alignment repair game},
  volume       = {35},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Recent advances in leveraging human guidance for sequential
decision-making tasks. <em>AAMAS</em>, <em>35</em>(2), 1–39. (<a
href="https://doi.org/10.1007/s10458-021-09514-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A longstanding goal of artificial intelligence is to create artificial agents capable of learning to perform tasks that require sequential decision making. Importantly, while it is the artificial agent that learns and acts, it is still up to humans to specify the particular task to be performed. Classical task-specification approaches typically involve humans providing stationary reward functions or explicit demonstrations of the desired tasks. However, there has recently been a great deal of research energy invested in exploring alternative ways in which humans may guide learning agents that may, e.g., be more suitable for certain tasks or require less human effort. This survey provides a high-level overview of five recent machine learning frameworks that primarily rely on human guidance apart from pre-specified reward functions or conventional, step-by-step action demonstrations. We review the motivation, assumptions, and implementation of each framework, and we discuss possible future research directions.},
  archive      = {J_AAMAS},
  author       = {Zhang, Ruohan and Torabi, Faraz and Warnell, Garrett and Stone, Peter},
  doi          = {10.1007/s10458-021-09514-w},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  number       = {2},
  pages        = {1-39},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {Recent advances in leveraging human guidance for sequential decision-making tasks},
  volume       = {35},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Trust repair in human-agent teams: The effectiveness of
explanations and expressing regret. <em>AAMAS</em>, <em>35</em>(2),
1–20. (<a href="https://doi.org/10.1007/s10458-021-09515-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The role of intelligent agents becomes more social as they are expected to act in direct interaction, involvement and/or interdependency with humans and other artificial entities, as in Human-Agent Teams (HAT). The highly interdependent and dynamic nature of teamwork demands correctly calibrated trust among team members. Trust violations are an inevitable aspect of the cycle of trust and since repairing damaged trust proves to be more difficult than building trust initially, effective trust repair strategies are needed to ensure durable and successful team performance. The aim of this study was to explore the effectiveness of different trust repair strategies from an intelligent agent by measuring the development of human trust and advice taking in a Human-Agent Teaming task. Data for this study were obtained using a task environment resembling a first-person shooter game. Participants carried out a mission in collaboration with their artificial team member. A trust violation was provoked when the agent failed to detect an approaching enemy. After this, the agent offered one of four trust repair strategies, composed of the apology components explanation and expression of regret (either one alone, both or neither). Our results indicated that expressing regret was crucial for effective trust repair. After trust declined due to the violation by the agent, trust only significantly recovered when an expression of regret was included in the apology. This effect was stronger when an explanation was added. In this context, the intelligent agent was the most effective in its attempt of rebuilding trust when it provided an apology that was both affective, and informational. Finally, the implications of our findings for the design and study of Human-Agent trust repair are discussed.},
  archive      = {J_AAMAS},
  author       = {Kox, E. S. and Kerstholt, J. H. and Hueting, T. F. and de Vries, P. W.},
  doi          = {10.1007/s10458-021-09515-9},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  number       = {2},
  pages        = {1-20},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {Trust repair in human-agent teams: The effectiveness of explanations and expressing regret},
  volume       = {35},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Special issue on current trends in research on software
agents and agent-based software systems. <em>AAMAS</em>, <em>35</em>(2),
1–4. (<a href="https://doi.org/10.1007/s10458-021-09510-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This special issue of autonomous agents and multi-agent systems sought research articles that discuss relevant topics for the current trends in research on software agents and agent-based software systems. Topics of interest included techniques and technologies to engineer agent-based software systems, as well as languages, frameworks, and infrastructures broadly related to software agents and agent-based software systems.},
  archive      = {J_AAMAS},
  author       = {Baldoni, Matteo and Bergenti, Federico and El Fallah Seghrouchni, Amal and Winikoff, Michael},
  doi          = {10.1007/s10458-021-09510-0},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  number       = {2},
  pages        = {1-4},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {Special issue on current trends in research on software agents and agent-based software systems},
  volume       = {35},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Concurrent local negotiations with a global utility
function: A greedy approach. <em>AAMAS</em>, <em>35</em>(2), 1–31. (<a
href="https://doi.org/10.1007/s10458-021-09512-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automated Negotiation is a growing area of research in recent years as it provides a mechanism for intelligent agents representing people and institutions to coordinate their behavior in a complex environment under rational selfish assumptions. Most research in this area assumes either a single negotiation thread with a well-defined utility function for each agent involved or a set of concurrent negotiations with an ordering of outcomes in each local negotiation. In this paper, we consider an agent engaged in a set of concurrent negotiations with a utility function defined only for the complete set of agreements in all of them and no locally defined ordering of outcomes in any negotiation. The paper presents an algorithm that allows such agent to maximize its expected global utility by orchestrating its behavior in all negotiation threads. The performance of the proposed method is analyzed theoretically and empirically using simulation in the context of a trading market.},
  archive      = {J_AAMAS},
  author       = {Mohammad, Yasser},
  doi          = {10.1007/s10458-021-09512-y},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  number       = {2},
  pages        = {1-31},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {Concurrent local negotiations with a global utility function: A greedy approach},
  volume       = {35},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Voting with random classifiers (VORACE): Theoretical and
experimental analysis. <em>AAMAS</em>, <em>35</em>(2), 1–31. (<a
href="https://doi.org/10.1007/s10458-021-09504-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In many machine learning scenarios, looking for the best classifier that fits a particular dataset can be very costly in terms of time and resources. Moreover, it can require deep knowledge of the specific domain. We propose a new technique which does not require profound expertise in the domain and avoids the commonly used strategy of hyper-parameter tuning and model selection. Our method is an innovative ensemble technique that uses voting rules over a set of randomly-generated classifiers. Given a new input sample, we interpret the output of each classifier as a ranking over the set of possible classes. We then aggregate these output rankings using a voting rule, which treats them as preferences over the classes. We show that our approach obtains good results compared to the state-of-the-art, both providing a theoretical analysis and an empirical evaluation of the approach on several datasets.},
  archive      = {J_AAMAS},
  author       = {Cornelio, Cristina and Donini, Michele and Loreggia, Andrea and Pini, Maria Silvia and Rossi, Francesca},
  doi          = {10.1007/s10458-021-09504-y},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  number       = {2},
  pages        = {1-31},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {Voting with random classifiers (VORACE): Theoretical and experimental analysis},
  volume       = {35},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Analysing factorizations of action-value networks for
cooperative multi-agent reinforcement learning. <em>AAMAS</em>,
<em>35</em>(2), 1–53. (<a
href="https://doi.org/10.1007/s10458-021-09506-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent years have seen the application of deep reinforcement learning techniques to cooperative multi-agent systems, with great empirical success. However, given the lack of theoretical insight, it remains unclear what the employed neural networks are learning, or how we should enhance their learning power to address the problems on which they fail. In this work, we empirically investigate the learning power of various network architectures on a series of one-shot games. Despite their simplicity, these games capture many of the crucial problems that arise in the multi-agent setting, such as an exponential number of joint actions or the lack of an explicit coordination mechanism. Our results extend those in Castellini et al. (Proceedings of the 18th International Conference on Autonomous Agents and MultiAgent Systems, AAMAS’19.International Foundation for Autonomous Agents and Multiagent Systems, pp 1862–1864, 2019) and quantify how well various approaches can represent the requisite value functions, and help us identify the reasons that can impede good performance, like sparsity of the values or too tight coordination requirements.},
  archive      = {J_AAMAS},
  author       = {Castellini, Jacopo and Oliehoek, Frans A. and Savani, Rahul and Whiteson, Shimon},
  doi          = {10.1007/s10458-021-09506-w},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  number       = {2},
  pages        = {1-53},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {Analysing factorizations of action-value networks for cooperative multi-agent reinforcement learning},
  volume       = {35},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The effect of strategic noise in linear regression.
<em>AAMAS</em>, <em>35</em>(2), 1–24. (<a
href="https://doi.org/10.1007/s10458-021-09502-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We build on an emerging line of work which studies strategic manipulations in training data provided to machine learning algorithms. Specifically, we focus on the ubiquitous task of linear regression. Prior work focused on the design of strategyproof algorithms, which aim to prevent such manipulations altogether by aligning the incentives of data sources. However, algorithms used in practice are often not strategyproof, which induces a strategic game among the agents. We focus on a broad class of non-strategyproof algorithms for linear regression, namely $$\ell _p$$ norm minimization ( $$p &gt; 1$$ ) with convex regularization. We show that when manipulations are bounded, every algorithm in this class admits a unique pure Nash equilibrium outcome. We also shed light on the structure of this equilibrium by uncovering a surprising connection between strategyproof algorithms and pure Nash equilibria of non-strategyproof algorithms in a broader setting, which may be of independent interest. Finally, we analyze the quality of equilibria under these algorithms in terms of the price of anarchy.},
  archive      = {J_AAMAS},
  author       = {Hossain, Safwan and Shah, Nisarg},
  doi          = {10.1007/s10458-021-09502-0},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  number       = {2},
  pages        = {1-24},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {The effect of strategic noise in linear regression},
  volume       = {35},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Swap dynamics in single-peaked housing markets.
<em>AAMAS</em>, <em>35</em>(2), 1–37. (<a
href="https://doi.org/10.1007/s10458-021-09503-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper focuses on the problem of fairly and efficiently allocating resources to agents. We consider a specific setting, usually referred to as a housing market, where each agent must receive exactly one resource (and initially owns one). In this framework, in the domain of linear preferences, the Top Trading Cycle (TTC) algorithm is the only procedure satisfying Pareto-optimality, individual rationality and strategy-proofness. Under the restriction of single-peaked preferences, Crawler enjoys the same properties. These two centralized procedures might however involve long trading cycles. In this paper we focus instead on procedures involving the shortest cycles: bilateral swap-deals. In such swap dynamics, the agents perform pairwise mutually improving deals until reaching a swap-stable allocation (no improving swap-deal is possible). We prove that in the single-peaked domain every swap-stable allocation is Pareto-optimal, showing the efficiency of the swap dynamics. In fact, this domain turns out to be maximal when it comes to guaranteeing this property. Besides, both the outcome of TTC and Crawler can always be reached by sequences of swaps. However, some Pareto-optimal allocations are not reachable through improving swap-deals. We further analyze the outcome of swap dynamics through social welfare notions, in our context the average or minimum rank of the resources obtained by agents in the final allocation. We start by providing a worst-case analysis of these procedures. Finally, we present an extensive experimental study in which different versions of swap dynamics are compared to other existing allocation procedures. We show that they exhibit good results on average in this domain, under different cultures for generating synthetic data.},
  archive      = {J_AAMAS},
  author       = {Beynier, Aurélie and Maudet, Nicolas and Rey, Simon and Shams, Parham},
  doi          = {10.1007/s10458-021-09503-z},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  number       = {2},
  pages        = {1-37},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {Swap dynamics in single-peaked housing markets},
  volume       = {35},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Playing atari with few neurons. <em>AAMAS</em>,
<em>35</em>(2), 1–23. (<a
href="https://doi.org/10.1007/s10458-021-09497-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a new method for learning compact state representations and policies separately but simultaneously for policy approximation in vision-based applications such as Atari games. Approaches based on deep reinforcement learning typically map pixels directly to actions to enable end-to-end training. Internally, however, the deep neural network bears the responsibility of both extracting useful information and making decisions based on it, two objectives which can be addressed independently. Separating the image processing from the action selection allows for a better understanding of either task individually, as well as potentially finding smaller policy representations which is inherently interesting. Our approach learns state representations using a compact encoder based on two novel algorithms: (i) Increasing Dictionary Vector Quantization builds a dictionary of state representations which grows in size over time, allowing our method to address new observations as they appear in an open-ended online-learning context; and (ii) Direct Residuals Sparse Coding encodes observations in function of the dictionary, aiming for highest information inclusion by disregarding reconstruction error and maximizing code sparsity. As the dictionary size increases, however, the encoder produces increasingly larger inputs for the neural network; this issue is addressed with a new variant of the Exponential Natural Evolution Strategies algorithm which adapts the dimensionality of its probability distribution along the run. We test our system on a selection of Atari games using tiny neural networks of only 6 to 18 neurons (depending on each game’s controls). These are still capable of achieving results that are not much worse, and occasionally superior, to the state-of-the-art in direct policy search which uses two orders of magnitude more neurons.},
  archive      = {J_AAMAS},
  author       = {Cuccu, Giuseppe and Togelius, Julian and Cudré-Mauroux, Philippe},
  doi          = {10.1007/s10458-021-09497-8},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  number       = {2},
  pages        = {1-23},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {Playing atari with few neurons},
  volume       = {35},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). AVDM: A hierarchical command-and-control system architecture
for cooperative autonomous vehicles in highways scenario using
microscopic simulations. <em>AAMAS</em>, <em>35</em>(1), 1–30. (<a
href="https://doi.org/10.1007/s10458-021-09499-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Microscopic agent-based traffic simulation is an important tool for the efficient and safe resolution of various traffic challenges accompanying the introduction of autonomous vehicles on the roads. Both the variety of questions that can be asked and the quality of answers provided by simulations, however, depend on the underlying models. In mixed traffic, the two most critical models are the models describing the driving behaviour of humans and AVs, respectively. This paper presents AVDM (Autonomous Vehicle Driving Model), a hierarchical AV behaviour model that allows the holistic evaluation of autonomous and mixed traffic by unifying a wide spectrum of AV functionality, including long-term planning, path planning, complex platooning manoeuvres, and low-level longitudinal and lateral control. The model consists of hierarchically layered modules bidirectionally connected by messages and commands. On top, a high-level planning module makes decisions whether to join/form platoons and how to follow the vehicle’s route. A platooning manoeuvres layer guides involved AVs through the manoeuvres chosen to be executed, assisted by the trajectory planning layer, which, after finding viable paths through complex traffic conditions, sends simple commands to the low-level control layer to execute those paths. The model has been implemented in the BEHAVE mixed traffic simulation tool and achieved a 92\% success rate for platoon joining manoeuvres in mixed traffic conditions. As a proof of concept, we conducted a mixed traffic simulation study showing that enabling platooning on a highway scenario shifts the velocity-density curve upwards despite the additional lane changing and manoeuvring it induces.},
  archive      = {J_AAMAS},
  author       = {Braud, Thomas and Ivanchev, Jordan and Deboeser, Corvin and Knoll, Alois and Eckhoff, David and Sangiovanni-Vincentelli, Alberto},
  doi          = {10.1007/s10458-021-09499-6},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  number       = {1},
  pages        = {1-30},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {AVDM: A hierarchical command-and-control system architecture for cooperative autonomous vehicles in highways scenario using microscopic simulations},
  volume       = {35},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Probabilistic serial mechanism for multi-type resource
allocation. <em>AAMAS</em>, <em>35</em>(1), 1–48. (<a
href="https://doi.org/10.1007/s10458-021-09495-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In multi-type resource allocation (MTRA) problems, there are $$d\ge 2$$ types of items, and n agents who each demand one unit of items of each type and have strict linear preferences over bundles consisting of one item of each type. For MTRAs with indivisible items, our first result is an impossibility theorem that is in direct contrast to the single type ( $$d=1$$ ) setting: no mechanism, the output of which is always decomposable into a probability distribution over discrete assignments (where no item is split between agents), can satisfy both sd-efficiency and sd-envy-freeness. We show that this impossibility result is circumvented under the natural assumption of lexicographic preferences. We provide lexicographic probabilistic serial (LexiPS) as an extension of the probabilistic serial (PS) mechanism for MTRAs with lexicographic preferences, and prove that LexiPS satisfies sd-efficiency and sd-envy-freeness, retaining the desirable properties of PS. Moreover, LexiPS satisfies sd-weak-strategyproofness when agents are not allowed to misreport their importance orders. For MTRAs with divisible items, we show that the existing multi-type probabilistic serial (MPS) mechanism satisfies the stronger efficiency notion of lexi-efficiency, and is sd-envy-free under strict linear preferences and sd-weak-strategyproof under lexicographic preferences. We also prove that MPS can be characterized both by leximin-optimality and by item-wise ordinal fairness, and the family of eating algorithms which MPS belongs to can be characterized by lexi-efficiency.},
  archive      = {J_AAMAS},
  author       = {Guo, Xiaoxi and Sikdar, Sujoy and Wang, Haibin and Xia, Lirong and Cao, Yongzhi and Wang, Hanpin},
  doi          = {10.1007/s10458-021-09495-w},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  number       = {1},
  pages        = {1-48},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {Probabilistic serial mechanism for multi-type resource allocation},
  volume       = {35},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). GDL as a unifying domain description language for
declarative automated negotiation. <em>AAMAS</em>, <em>35</em>(1), 1–48.
(<a href="https://doi.org/10.1007/s10458-020-09491-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, it has been proposed that Game Description Language (GDL) could be used to define negotiation domains. This would open up an entirely new, declarative, approach to Automated Negotiations in which a single algorithm could negotiate over any domain, as long as that domain is expressible in GDL. However, until now, the feasibility of this approach has only been demonstrated on a few toy-world problems. Therefore, in this paper we show that GDL is a truly unifying language that can also be used to define more general and more complex negotiation domains. We demonstrate this by showing that some of the most commonly used test-beds in the Automated Negotiations literature, namely Genius and Colored Trails, can be described in GDL. More specifically, we formally prove that the set of possible agreements of any negotiation domain from Genius (either linear or non-linear) can be modeled as a set of strategies over a deterministic extensive-form game. Furthermore, we show that this game can be effectively described in GDL and we show experimentally that, given only this GDL description, we can explore the agreement space efficiently using entirely generic domain-independent algorithms. In addition, we show that the same holds for negotiation domains in the Colored Trails framework. This means that one could indeed implement a single negotiating agent that is capable of negotiating over a broad class of negotiation domains, including Genius and Colored Trails.},
  archive      = {J_AAMAS},
  author       = {de Jonge, Dave and Zhang, Dongmo},
  doi          = {10.1007/s10458-020-09491-6},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  number       = {1},
  pages        = {1-48},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {GDL as a unifying domain description language for declarative automated negotiation},
  volume       = {35},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). On the computation of probabilistic coalition structures.
<em>AAMAS</em>, <em>35</em>(1), 1–38. (<a
href="https://doi.org/10.1007/s10458-021-09498-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In Coalition Structure Generation (CSG), one seeks to form a partition of a given set of agents into coalitions such that the sum of the values of each coalition is maximized. This paper introduces a model for Probabilistic CSG (PCSG), which extends the standard CSG model to account for the stochastic nature of the environment, i.e., when some of the agents considered at start may be finally defective. In PCSG, the goal is to maximize the expected utility of a coalition structure. We show that the problem is $${\mathsf{NP}}^{\mathsf {PP}}$$ -hard in the general case, but remains in $${\mathsf{NP}}$$ for two natural subclasses of PCSG instances, when the characteristic function that gives the utility of every coalition is represented using a marginal contribution network (MC-net). Two encoding schemes are presented for these subclasses and empirical results are reported, showing that computing a coalition structure with maximal expected utility can be done efficiently for PCSG instances of reasonable size. This is an extended and revised version of the paper entitled “Probabilistic Coalition Structure Generation” published in the proceedings of KR’18, pages 663–664 [33].},
  archive      = {J_AAMAS},
  author       = {Schwind, Nicolas and Okimoto, Tenda and Inoue, Katsumi and Hirayama, Katsutoshi and Lagniez, Jean-Marie and Marquis, Pierre},
  doi          = {10.1007/s10458-021-09498-7},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  number       = {1},
  pages        = {1-38},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {On the computation of probabilistic coalition structures},
  volume       = {35},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Real-time multi-agent systems: Rationality, formal model,
and empirical results. <em>AAMAS</em>, <em>35</em>(1), 1–37. (<a
href="https://doi.org/10.1007/s10458-020-09492-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Since its dawn as a discipline, Artificial Intelligence (AI) has focused on mimicking the human mental processes. As AI applications matured, the interest for employing them into real-world complex systems (i.e., coupling AI with Cyber-Physical Systems—CPS) kept increasing. In the last decades, the multi-agent systems (MAS) paradigm has been among the most relevant approaches fostering the development of intelligent systems. In numerous scenarios, MAS boosted distributed autonomous reasoning and behaviors. However, many real-world applications (e.g., CPS) demand the respect of strict timing constraints. Unfortunately, current AI/MAS theories and applications only reason “about time” and are incapable of acting “in time” guaranteeing any timing predictability. This paper analyzes the MAS compliance with strict timing constraints (real-time compliance)—crucial for safety-critical applications such as healthcare, industry 4.0, and automotive. Moreover, it elicits the main reasons for the lack of real-time satisfiability in MAS (originated from current theories, standards, and implementations). In particular, traditional internal agent schedulers (general-purpose-like), communication middlewares, and negotiation protocols have been identified as co-factors inhibiting real-time compliance. To pave the road towards reliable and predictable MAS, this paper postulates a formal definition and mathematical model of real-time multi-agent systems (RT-MAS). Furthermore, this paper presents the results obtained by testing the dynamics characterizing the RT-MAS model within the simulator MAXIM-GPRT. Thus, it has been possible to analyze the deadline miss ratio between the algorithms employed in the most popular frameworks and the proposed ones. Finally, discussing the obtained results, the ongoing and future steps are outlined.},
  archive      = {J_AAMAS},
  author       = {Calvaresi, Davide and Dicente Cid, Yashin and Marinoni, Mauro and Dragoni, Aldo Franco and Najjar, Amro and Schumacher, Michael},
  doi          = {10.1007/s10458-020-09492-5},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  number       = {1},
  pages        = {1-37},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {Real-time multi-agent systems: Rationality, formal model, and empirical results},
  volume       = {35},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Towards addressing dynamic multi-agent task allocation in
law enforcement. <em>AAMAS</em>, <em>35</em>(1), 1–18. (<a
href="https://doi.org/10.1007/s10458-021-09494-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Police officers conduct routine patrols and perform tasks in response to reported incidents. The importance of each task varies from low (e.g. noise complaint) to high (e.g. murder). The workload associated with each task, indicating the amount of work to be completed for the incident to be processed, may vary as well. Multiple officers with heterogeneous skills may work together on important tasks to share the workload and improve response time. To deal with the underlying law enforcement problem (LEPH), one needs to allocate police officers to dynamic tasks whose locations, arrival times, and importance levels are unknown a priori. Addressing this challenge and inspired by real police logs, this research aims to solve the LEPH problem by using and comparing three methods: Fisher market-based FMC_TAH+, swarm intelligence HDBA, and Simulated Annealing SA algorithms. FMC_TAH+ is implemented, using agents as buyers and tasks as goods, to compute fair allocations (i.e. envy-free), and efficient (i.e. Pareto-optimal) in a polynomial or pseudo-polynomial time. FMC_TAH+ allocations are heuristically scheduled, considering inter-agent constraints on shared tasks. HDBA, a probabilistic swarm intelligence algorithm inspired by the emergent behavior of social bees, was previously implemented to allocate agents to tasks based on agent performance, task priorities, and distances between agents and task-execution locations. SA is a meta-heuristic for approximating the global optimums in large optimization problems. The three methods were compared in this study for five different performance measures that are commonly used by law enforcement authorities. The results indicate an advantage for FMC_TAH+ both in total utility and in the average arrival time to tasks. Also, compared respectively to HDBA and SA, FMC_TAH+ leads to 34\% and 32\% higher team utility in the highest shift workload.},
  archive      = {J_AAMAS},
  author       = {Tkach, Itshak and Amador, Sofia},
  doi          = {10.1007/s10458-021-09494-x},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  number       = {1},
  pages        = {1-18},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {Towards addressing dynamic multi-agent task allocation in law enforcement},
  volume       = {35},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Enabling scalable and fault-tolerant multi-agent systems by
utilizing cloud-native computing. <em>AAMAS</em>, <em>35</em>(1), 1–27.
(<a href="https://doi.org/10.1007/s10458-020-09489-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-agent systems (MAS) represent a distributed computing paradigm well suited to tackle today’s challenges in the field of the Internet of Things (IoT). Both share many similarities such as the interconnection of distributed devices and their cooperation. The combination of MAS and IoT would allow the transfer of the experience gained in MAS research to the broader range of IoT applications. The key enabler for utilizing MAS in the IoT is the ability to build large-scale and fault-tolerant MASs since IoT concepts comprise possibly thousands or even millions of devices. However, well known multi-agent platforms (MAP), e. g., Java Agent DE-velopment Framework (JADE), are not able to deal with these challenges. To this aim, we present a cloud-native Multi-Agent Platform (cloneMAP) as a modern MAP based on cloud-computing techniques to enable scalability and fault-tolerance. A microservice architecture is used to implement it in a distributed way utilizing the open-source container orchestration system Kubernetes. Thereby, bottlenecks and single-points of failure are conceptually avoided. A comparison with JADE via relevant performance metrics indicates the massively improved scalability. Furthermore, the implementation of a large-scale use case verifies cloneMAP’s suitability for IoT applications. This leads to the conclusion that cloneMAP extends the range of possible MAS applications and enables the integration with IoT concepts.},
  archive      = {J_AAMAS},
  author       = {Dähling, Stefan and Razik, Lukas and Monti, Antonello},
  doi          = {10.1007/s10458-020-09489-0},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  number       = {1},
  pages        = {1-27},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {Enabling scalable and fault-tolerant multi-agent systems by utilizing cloud-native computing},
  volume       = {35},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Reaching consensus under a deadline. <em>AAMAS</em>,
<em>35</em>(1), 1–42. (<a
href="https://doi.org/10.1007/s10458-020-09490-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Group decisions are often complicated by a deadline. For example, in committee hiring decisions the deadline might be the next start of a budget, or the beginning of a semester. It may be that if no candidate is supported by a strong majority, the default is to hire no one - an option that may cost dearly. As a result, committee members might prefer to agree on a reasonable, if not necessarily the best, candidate, to avoid unfilled positions. In this paper we propose a model for the above scenario—Consensus Under a Deadline (CUD)—based on a time-bounded iterative voting process. We provide convergence guarantees and an analysis of the quality of the final decision. An extensive experimental study demonstrates more subtle features of CUDs, e.g., the difference between two simple types of committee member behavior, lazy vs. proactive voters. Finally, a user study examines the differences between the behavior of rational voting bots and real voters, concluding that it may often be best to have bots play on the voters’ behalf.},
  archive      = {J_AAMAS},
  author       = {Bannikova, Marina and Dery, Lihi and Obraztsova, Svetlana and Rabinovich, Zinovi and Rosenschein, Jeffrey S.},
  doi          = {10.1007/s10458-020-09490-7},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  number       = {1},
  pages        = {1-42},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {Reaching consensus under a deadline},
  volume       = {35},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Towards a framework for certification of reliable autonomous
systems. <em>AAMAS</em>, <em>35</em>(1), 1–65. (<a
href="https://doi.org/10.1007/s10458-020-09487-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A computational system is called autonomous if it is able to make its own decisions, or take its own actions, without human supervision or control. The capability and spread of such systems have reached the point where they are beginning to touch much of everyday life. However, regulators grapple with how to deal with autonomous systems, for example how could we certify an Unmanned Aerial System for autonomous use in civilian airspace? We here analyse what is needed in order to provide verified reliable behaviour of an autonomous system, analyse what can be done as the state-of-the-art in automated verification, and propose a roadmap towards developing regulatory guidelines, including articulating challenges to researchers, to engineers, and to regulators. Case studies in seven distinct domains illustrate the article.},
  archive      = {J_AAMAS},
  author       = {Fisher, Michael and Mascardi, Viviana and Rozier, Kristin Yvonne and Schlingloff, Bernd-Holger and Winikoff, Michael and Yorke-Smith, Neil},
  doi          = {10.1007/s10458-020-09487-2},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  number       = {1},
  pages        = {1-65},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {Towards a framework for certification of reliable autonomous systems},
  volume       = {35},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Assisting humans in privacy management: An agent-based
approach. <em>AAMAS</em>, <em>35</em>(1), 1–33. (<a
href="https://doi.org/10.1007/s10458-020-09488-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image sharing is a service offered by many online social networks. In order to preserve privacy of images, users need to think through and specify a privacy setting for each image that they upload. This is difficult for two main reasons: first, research shows that many times users do not know their own privacy preferences, but only become aware of them over time. Second, even when users know their privacy preferences, editing these privacy settings is cumbersome and requires too much effort, interfering with the quick sharing behavior expected on an online social network. Accordingly, this paper proposes a privacy recommendation model for images using tags and an agent that implements this, namely pelte. Each user agent makes use of the privacy settings that its user have set for previous images to predict automatically the privacy setting for an image that is uploaded to be shared. When in doubt, the agent analyzes the sharing behavior of other users in the user’s network to be able to recommend to its user about what should be considered as private. Contrary to existing approaches that assume all the images are available to a centralized model, pelte is compatible to distributed environments since each agent accesses only the privacy settings of the images that the agent owner has shared or those that have been shared with the user. Our simulations on a real-life dataset shows that pelte can accurately predict privacy settings even when a user has shared a few images with others, the images have only a few tags or the user’s friends have varying privacy preferences.},
  archive      = {J_AAMAS},
  author       = {Kurtan, A. Can and Yolum, Pınar},
  doi          = {10.1007/s10458-020-09488-1},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  number       = {1},
  pages        = {1-33},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {Assisting humans in privacy management: An agent-based approach},
  volume       = {35},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). I2RL: Online inverse reinforcement learning under occlusion.
<em>AAMAS</em>, <em>35</em>(1), 1–33. (<a
href="https://doi.org/10.1007/s10458-020-09485-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inverse reinforcement learning (IRL) is the problem of learning the preferences of an agent from observing its behavior on a task. It inverts RL which focuses on learning an agent’s behavior on a task based on the reward signals received. IRL is witnessing sustained attention due to promising applications in robotics, computer games, and finance, as well as in other sectors. Methods for IRL have, for the most part, focused on batch settings where the observed agent’s behavioral data has already been collected. However, the related problem of online IRL—where observations are incrementally accrued, yet the real-time demands of the application often prohibit a full rerun of an IRL method—has received significantly less attention. We introduce the first formal framework for online IRL, called incremental IRL (I2RL), which can serve as a common ground for online IRL methods. We demonstrate the usefulness of this framework by casting existing online IRL techniques into this framework. Importantly, we present a new method that advances maximum entropy IRL with hidden variables to the online setting. Our analysis shows that the new method has monotonically improving performance with more demonstration data as well as probabilistically bounded error, both under full and partial observability. Simulated and physical robot experiments in a multi-robot patrolling application situated in varied-sized worlds, which involves learning under high levels of occlusion, show a significantly improved performance of I2RL as compared to both batch IRL and an online imitation learning method.},
  archive      = {J_AAMAS},
  author       = {Arora, Saurabh and Doshi, Prashant and Banerjee, Bikramjit},
  doi          = {10.1007/s10458-020-09485-4},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  number       = {1},
  pages        = {1-33},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {I2RL: Online inverse reinforcement learning under occlusion},
  volume       = {35},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A decentralised self-healing approach for network topology
maintenance. <em>AAMAS</em>, <em>35</em>(1), 1–36. (<a
href="https://doi.org/10.1007/s10458-020-09486-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In many distributed systems, from cloud to sensor networks, different configurations impact system performance, while strongly depending on the network topology. Hence, topological changes may entail costly reconfiguration and optimisation processes. This paper proposes a multi-agent solution for recovering networks from node failures. To preserve the network topology, the proposed approach relies on local information about the network’s structure, which is collected and disseminated at runtime. The paper studies two strategies for distributing topological data: one based on mobile agents (our proposal) and the other based on Trickle (a reference gossiping protocol from the literature). These two strategies were adapted for our self-healing approach—to collect topological information for recovering the network; and were evaluated in terms of resource overheads. Experimental results show that both variants can recover the network topology, up to a certain node failure rate, which depends on the network topology. At the same time, mobile agents collect less information, focusing on local dissemination, which suffices for network recovery. This entails less bandwidth overheads than when Trickle is used. Still, mobile agents utilise more memory and exchange more messages, during data-collection, than Trickle does. These results validate the viability of the proposed self-healing solution, offering two variant implementations with diverse performance characteristics, which may suit different application domains.},
  archive      = {J_AAMAS},
  author       = {Rodríguez, Arles and Gómez, Jonatan and Diaconescu, Ada},
  doi          = {10.1007/s10458-020-09486-3},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  number       = {1},
  pages        = {1-36},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {A decentralised self-healing approach for network topology maintenance},
  volume       = {35},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Irrelevant matches in round-robin tournaments.
<em>AAMAS</em>, <em>35</em>(1), 1–34. (<a
href="https://doi.org/10.1007/s10458-020-09483-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider tournaments played by a set of players in order to establish a ranking among them. We introduce the notion of irrelevant match, as a match that does not influence the ultimate ranking of the involved parties. After discussing the basic properties of this notion, we seek out tournaments that have no irrelevant matches, focusing on the class of tournaments where each player challenges each other exactly once. We prove that tournaments with a static schedule and at least five players always include irrelevant matches. Conversely, dynamic schedules for an arbitrary number of players can be devised that avoid irrelevant matches, at least for one of the players involved in each match. Finally, we prove by computational means that there exist tournaments where all matches are relevant to both players, at least up to eight players.},
  archive      = {J_AAMAS},
  author       = {Faella, Marco and Sauro, Luigi},
  doi          = {10.1007/s10458-020-09483-6},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  number       = {1},
  pages        = {1-34},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {Irrelevant matches in round-robin tournaments},
  volume       = {35},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Electric vehicle charging strategy study and the application
on charging station placement. <em>AAMAS</em>, <em>35</em>(1), 1–19. (<a
href="https://doi.org/10.1007/s10458-020-09484-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optimal placement of charging stations for electric vehicles (EVs) is critical for providing convenient charging service to EV owners and promoting public acceptance of EVs. There has been a lot of work on EV charging station placement, yet EV drivers’ charging strategy, which plays an important role in deciding charging stations’ performance, is missing. EV drivers make choice among charging stations according to various factors, including the distance, the charging fare and queuing condition in different stations etc. In turn, some factors, like queuing condition, is greatly influenced by EV drivers’ choices. As more EVs visit the same station, longer queuing duration should be expected. This work first proposes a behavior model to capture the decision making of EV drivers in choosing charging stations, based on which an optimal charging station placement model is presented to minimize the social cost (defined as the congestion in charging stations suffered by all EV drivers). Through analyzing EV drivers’ decision-making in the charging process, we propose a k-Level nested Quantal Response Equilibrium charging behavior model inspired by Quantal Response Equilibrium model and level-k thinking model. We then design a set of user studies to simulate charging scenarios and collect data from human players to learn the parameters of different behavior models. Experimental results show that our charging behavior model can better capture the bounded rationality of human players in the charging activity compared with state-of-the-art behavior models. Furthermore, to evaluate the proposed charging behavior model, we formulate the charging station placement problem with it and design an algorithm to solve the problem. It is shown that our approach obtains placement with a significantly better performance to different extent, especially when the budget is limited and relatively low.},
  archive      = {J_AAMAS},
  author       = {Xiong, Yanhai and An, Bo and Kraus, Sarit},
  doi          = {10.1007/s10458-020-09484-5},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  number       = {1},
  pages        = {1-19},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {Electric vehicle charging strategy study and the application on charging station placement},
  volume       = {35},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Efficient policy detecting and reusing for non-stationarity
in markov games. <em>AAMAS</em>, <em>35</em>(1), 1–29. (<a
href="https://doi.org/10.1007/s10458-020-09480-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One challenging problem in multiagent systems is to cooperate or compete with non-stationary agents that change behavior from time to time. An agent in such a non-stationary environment is usually supposed to be able to quickly detect the other agents’ policy during online interaction, and then adapt its own policy accordingly. This article studies efficient policy detecting and reusing techniques when playing against non-stationary agents in cooperative or competitive Markov games. We propose a new deep Bayesian policy reuse algorithm, a.k.a. DPN-BPR+, by extending the recent BPR+ algorithm with a neural network as the value-function approximator. To detect policy accurately, we propose the rectified belief model taking advantage of the opponent model to infer the other agents’ policy from reward signals and its behavior. Instead of directly storing individual policies as BPR+, we introduce distilled policy network that serves as the policy library, and policy distillation to achieve efficient online policy learning and reuse. DPN-BPR+ inherits all the advantages of BPR+. In experiments, we evaluate DPN-BPR+ in terms of detection accuracy, cumulative reward and speed of convergence in four complex Markov games with raw visual inputs, including two cooperative games and two competitive games. Empirical results show that our proposed DPN-BPR+ approach has better performance than existing algorithms in all these Markov games.},
  archive      = {J_AAMAS},
  author       = {Zheng, Yan and Hao, Jianye and Zhang, Zongzhang and Meng, Zhaopeng and Yang, Tianpei and Li, Yanran and Fan, Changjie},
  doi          = {10.1007/s10458-020-09480-9},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  number       = {1},
  pages        = {1-29},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {Efficient policy detecting and reusing for non-stationarity in markov games},
  volume       = {35},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Logic-based technologies for multi-agent systems: A
systematic literature review. <em>AAMAS</em>, <em>35</em>(1), 1–67. (<a
href="https://doi.org/10.1007/s10458-020-09478-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Precisely when the success of artificial intelligence (AI) sub-symbolic techniques makes them be identified with the whole AI by many non-computer-scientists and non-technical media, symbolic approaches are getting more and more attention as those that could make AI amenable to human understanding. Given the recurring cycles in the AI history, we expect that a revamp of technologies often tagged as “classical AI”—in particular, logic-based ones—will take place in the next few years. On the other hand, agents and multi-agent systems (MAS) have been at the core of the design of intelligent systems since their very beginning, and their long-term connection with logic-based technologies, which characterised their early days, might open new ways to engineer explainable intelligent systems. This is why understanding the current status of logic-based technologies for MAS is nowadays of paramount importance. Accordingly, this paper aims at providing a comprehensive view of those technologies by making them the subject of a systematic literature review (SLR). The resulting technologies are discussed and evaluated from two different perspectives: the MAS and the logic-based ones.},
  archive      = {J_AAMAS},
  author       = {Calegari, Roberta and Ciatto, Giovanni and Mascardi, Viviana and Omicini, Andrea},
  doi          = {10.1007/s10458-020-09478-3},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  number       = {1},
  pages        = {1-67},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {Logic-based technologies for multi-agent systems: A systematic literature review},
  volume       = {35},
  year         = {2021},
}
</textarea>
</details></li>
</ul>

</body>
</html>
