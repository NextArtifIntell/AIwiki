<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>JOH_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="joh---35">JOH - 35</h2>
<ul>
<li><details>
<summary>
(2021). Constraint-guided evolutionary algorithm for solving the
winner determination problem. <em>JOH</em>, <em>27</em>(6), 1111–1150.
(<a href="https://doi.org/10.1007/s10732-021-09485-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Combinatorial Auctions (CAs) allow the participants to bid on a bundle of items and can result in more cost-effective deals than traditional auctions if the goods are complementary. However, solving the Winner Determination Problem (WDP) in CAs is an NP-hard problem. Since Evolutionary Algorithms (EAs) can find good solutions in polynomial time within a huge search space, the use of EAs has become quite suitable for solving this type of problem. In this paper, we introduce a new Constraint-Guided Evolutionary Algorithm (CGEA) for the WDP. It employs a penalty component to represent each constraint in the fitness function and introduces new variation operators that consider each package value and each type of violated constraint to induce the generation of feasible solutions. CGEA also presents a survivor selection operator that maintains the exploration versus exploitation balance in the evolutionary process. The performance of CGEA is compared with that of three other evolutionary algorithms to solve a WDP in a Combinatorial Reverse Auction (CRA) of electricity generation and transmission line assets. Each of the algorithms compared employs different methods to deal with constraints. They are tested and compared on several problem instances. The results show that CGEA is competitive and results in better performance in most cases.},
  archive      = {J_JOH},
  author       = {Kazama, Fernanda Nakano and Araujo, Aluizio Fausto Ribeiro and de Barros Correia, Paulo and Guerrero-Peña, Elaine},
  doi          = {10.1007/s10732-021-09485-x},
  journal      = {Journal of Heuristics},
  month        = {12},
  number       = {6},
  pages        = {1111-1150},
  shortjournal = {J. Heuristics},
  title        = {Constraint-guided evolutionary algorithm for solving the winner determination problem},
  volume       = {27},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Randomized rounding algorithms for large scale unsplittable
flow problems. <em>JOH</em>, <em>27</em>(6), 1081–1110. (<a
href="https://doi.org/10.1007/s10732-021-09478-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unsplittable flow problems cover a wide range of telecommunication and transportation problems and their efficient resolution is key to a number of applications. In this work, we study algorithms that can scale up to large graphs and important numbers of commodities. We present and analyze in detail a heuristic based on the linear relaxation of the problem and randomized rounding. We provide empirical evidence that this approach is competitive with state-of-the-art resolution methods either by its scaling performance or by the quality of its solutions. We provide a variation of the heuristic which has the same approximation factor as the state-of-the-art approximation algorithm. We also derive a tighter analysis for the approximation factor of both the variation and the state-of-the-art algorithm. We introduce a new objective function for the unsplittable flow problem and discuss its differences with the classical congestion objective function. Finally, we discuss the gap in practical performance and theoretical guarantees between all the aforementioned algorithms.},
  archive      = {J_JOH},
  author       = {Lamothe, François and Rachelson, Emmanuel and Haït, Alain and Baudoin, Cedric and Dupé, Jean-Baptiste},
  doi          = {10.1007/s10732-021-09478-w},
  journal      = {Journal of Heuristics},
  month        = {12},
  number       = {6},
  pages        = {1081-1110},
  shortjournal = {J. Heuristics},
  title        = {Randomized rounding algorithms for large scale unsplittable flow problems},
  volume       = {27},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A probabilistic analysis of neighborhoods for combinatorial
optimization problems and its application. <em>JOH</em>, <em>27</em>(6),
1057–1079. (<a
href="https://doi.org/10.1007/s10732-021-09484-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Metaheuristics are a class of approximate methods, which are designed to attack hard combinatorial optimization problems. In metaheuristics, a neighborhood is defined by the specified move operation for a solution. The neighborhood plays an essential role in the performance of its algorithms. It is important to capture the statistical properties of neighborhoods. In this paper, we present a theoretical analysis of neighborhoods for a wide class of combinatorial optimization problems, instead of just for restricted instances. First, we give a probabilistic model which allows us to compute statistics for various types of neighborhoods. Here we introduce an approach in which the solution space (the landscape) for a wide class of combinatorial optimization problems can be approximated to AR(1), which can be used to capture the statistics of the solution space. The theoretical results obtained from our proposed model closely match empirically observed behavior. Second, we present an application in which we use our probabilistic model of neighborhoods.},
  archive      = {J_JOH},
  author       = {Kaji, Taichi},
  doi          = {10.1007/s10732-021-09484-y},
  journal      = {Journal of Heuristics},
  month        = {12},
  number       = {6},
  pages        = {1057-1079},
  shortjournal = {J. Heuristics},
  title        = {A probabilistic analysis of neighborhoods for combinatorial optimization problems and its application},
  volume       = {27},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-level evolution strategies for high-resolution
black-box control. <em>JOH</em>, <em>27</em>(6), 1021–1055. (<a
href="https://doi.org/10.1007/s10732-021-09483-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a multi-level (m-lev) mechanism into Evolution Strategies (ESs) in order to address a class of global optimization problems that could benefit from fine discretization of their decision variables. Such problems arise in engineering and scientific applications, which possess a multi-resolution control nature, and thus may be formulated either by means of low-resolution variants (providing coarser approximations with presumably lower accuracy for the general problem) or by high-resolution controls. A particular scientific application concerns practical Quantum Control (QC) problems, whose targeted optimal controls may be discretized to increasingly higher resolution, which in turn carries the potential to obtain better control yields. However, state-of-the-art derivative-free optimization heuristics for high-resolution formulations nominally call for an impractically large number of objective function calls. Therefore, an effective algorithmic treatment for such problems is needed. We introduce a framework with an automated scheme to facilitate guided-search over increasingly finer levels of control resolution for the optimization problem, whose on-the-fly learned parameters require careful adaptation. We instantiate the proposed m-lev self-adaptive ES framework by two specific strategies, namely the classical elitist single-child (1+1)-ES and the non-elitist multi-child derandomized $$(\mu _W,\lambda )$$ -sep-CMA-ES. We first show that the approach is suitable by simulation-based optimization of QC systems which were heretofore viewed as too complex to address. We also present a laboratory proof-of-concept for the proposed approach on a basic experimental QC system objective.},
  archive      = {J_JOH},
  author       = {Shir, Ofer M. and Xing, Xi. and Rabitz, Herschel.},
  doi          = {10.1007/s10732-021-09483-z},
  journal      = {Journal of Heuristics},
  month        = {12},
  number       = {6},
  pages        = {1021-1055},
  shortjournal = {J. Heuristics},
  title        = {Multi-level evolution strategies for high-resolution black-box control},
  volume       = {27},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A two-phase approach for integrating preventive maintenance
with production and delivery in an unreliable coal mine. <em>JOH</em>,
<em>27</em>(6), 991–1020. (<a
href="https://doi.org/10.1007/s10732-021-09482-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a coal mine that extracts raw coal by a set of coal mining equipment (CME), separates out multiple products by a set of coal washing equipment, and delivers the products through a fleet of trains over a multi-period horizon. The equipment requires a daily preventive maintenance (PM) and each CME is subject to random failures and repairs. We study a joint PM, production, and delivery problem that determines when to perform the PM and how to manage coal production and delivery in each period, to minimize the expected total cost. We formulate a multi-period stochastic optimization model that delicately integrates the static PM decisions with the adaptive production-delivery decisions, which is extremely difficult to solve due to CME’s decision-dependent operating status. We propose a novel two-phase solution approach to overcome this difficulty. Phase 1 firstly determines the PM decisions using a scenario-based variable neighborhood search algorithm. Using the PM solution and the resultant set of scenarios as input parameters, Phase 2 adaptively determines the production-delivery decisions using a forward-looking algorithm in a rolling horizon manner. We show numerically that our approach consistently produces good-quality and robust solutions while preserving tractability for varying problem instances.},
  archive      = {J_JOH},
  author       = {Jiu, Song},
  doi          = {10.1007/s10732-021-09482-0},
  journal      = {Journal of Heuristics},
  month        = {12},
  number       = {6},
  pages        = {991-1020},
  shortjournal = {J. Heuristics},
  title        = {A two-phase approach for integrating preventive maintenance with production and delivery in an unreliable coal mine},
  volume       = {27},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Conflict history based heuristic for constraint satisfaction
problem solving. <em>JOH</em>, <em>27</em>(6), 951–990. (<a
href="https://doi.org/10.1007/s10732-021-09475-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The variable ordering heuristic is an important module in algorithms dedicated to solve Constraint Satisfaction Problems (CSP), while it impacts the efficiency of exploring the search space and the size of the search tree. It also exploits, often implicitly, the structure of the instances. In this paper, we propose Conflict-History Search (CHS), a dynamic and adaptive variable ordering heuristic for CSP solving. It is based on the search failures and considers the temporality of these failures throughout the solving steps. The exponential recency weighted average is used to estimate the evolution of the hardness of constraints throughout the search. The experimental evaluation on XCSP3 instances shows that integrating CHS to solvers based on MAC (Maintaining Arc Consistency) and BTD (Backtracking with Tree Decomposition) achieves competitive results and improvements compared to the state-of-the-art heuristics. Beyond the decision problem, we show empirically that the solving of the constraint optimization problem (COP) can also take advantage of this heuristic.},
  archive      = {J_JOH},
  author       = {Habet, Djamal and Terrioux, Cyril},
  doi          = {10.1007/s10732-021-09475-z},
  journal      = {Journal of Heuristics},
  month        = {12},
  number       = {6},
  pages        = {951-990},
  shortjournal = {J. Heuristics},
  title        = {Conflict history based heuristic for constraint satisfaction problem solving},
  volume       = {27},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Delayed improvement local search. <em>JOH</em>,
<em>27</em>(5), 923–950. (<a
href="https://doi.org/10.1007/s10732-021-09479-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Local search is a fundamental tool in the development of heuristic algorithms. A neighborhood operator takes a current solution and returns a set of similar solutions, denoted as neighbors. In best improvement local search, the best of the neighboring solutions replaces the current solution in each iteration. On the other hand, in first improvement local search, the neighborhood is only explored until any improving solution is found, which then replaces the current solution. In this work we propose a new strategy for local search that attempts to avoid low-quality local optima by selecting in each iteration the improving neighbor that has the fewest possible attributes in common with local optima. To this end, it uses inequalities previously used as optimality cuts in the context of integer linear programming. The novel method, referred to as delayed improvement local search, is implemented and evaluated using the travelling salesman problem with the 2-opt neighborhood and the max-cut problem with the 1-flip neighborhood as test cases. Computational results show that the new strategy, while slower, obtains better local optima compared to the traditional local search strategies. The comparison is favourable to the new strategy in experiments with fixed computation time or with a fixed target.},
  archive      = {J_JOH},
  author       = {Amaral, Heber F. and Urrutia, Sebastián and Hvattum, Lars M.},
  doi          = {10.1007/s10732-021-09479-9},
  journal      = {Journal of Heuristics},
  month        = {10},
  number       = {5},
  pages        = {923-950},
  shortjournal = {J. Heuristics},
  title        = {Delayed improvement local search},
  volume       = {27},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An adaptive large neighbourhood search algorithm for
diameter bounded network design problems. <em>JOH</em>, <em>27</em>(5),
887–922. (<a href="https://doi.org/10.1007/s10732-021-09481-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper focuses on designing a diameter - constrained network where the maximum distance between any pair of nodes is bounded. The objective considered is to minimise a weighted sum of the total length of the links followed by the total length of the paths between the pairs of nodes. First, the problem is formulated in terms of Mixed Integer Linear Programming and Constraint Programming to provide two alternative exact approaches. Then, an adaptive large neighbourhood search (LNS) to overcome memory and runtime limitations of the exact methods in large size instances is proposed. Such approach is based on computing an initial solution and repeatedly improve it by solving relatively small subproblems. We investigate various alternatives for finding an initial solution and propose two different heuristics for selecting subproblems. We have introduced a tighter lower bound, which demonstrates the quality of the solution obtained by the proposed approach. The performance of the proposed approach is assessed using three real-world network topologies from Ireland, UK and Italy, which are taken from national telecommunication operators and are used to design a transparent optical core network. Our results demonstrate that the LNS approach is scalable to large networks and it can compute very high quality solutions that are close to being optimal.},
  archive      = {J_JOH},
  author       = {Garraffa, Michele and Mehta, Deepak and O’Sullivan, Barry and Ozturk, Cemalettin and Quesada, Luis},
  doi          = {10.1007/s10732-021-09481-1},
  journal      = {Journal of Heuristics},
  month        = {10},
  number       = {5},
  pages        = {887-922},
  shortjournal = {J. Heuristics},
  title        = {An adaptive large neighbourhood search algorithm for diameter bounded network design problems},
  volume       = {27},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Dynamic pricing with demand disaggregation for hotel revenue
management. <em>JOH</em>, <em>27</em>(5), 869–885. (<a
href="https://doi.org/10.1007/s10732-021-09480-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we present a novel approach to the dynamic pricing problem for hotel businesses. It includes disaggregation of the demand into several categories, forecasting, elastic demand simulation, and a mathematical programming model with concave quadratic objective function and linear constraints for dynamic price optimization. The approach is computationally efficient and easy to implement. In computer experiments with a hotel data set, the hotel revenue is increased by about 6% on average in comparison with the actual revenue gained in a past period, where the fixed price policy was employed, subject to an assumption that the demand can deviate from the suggested elastic model. The approach and the developed software can be a useful tool for small hotels recovering from the economic consequences of the COVID-19 pandemic.},
  archive      = {J_JOH},
  author       = {Bandalouski, Andrei M. and Egorova, Natalja G. and Kovalyov, Mikhail Y. and Pesch, Erwin and Tarim, S. Armagan},
  doi          = {10.1007/s10732-021-09480-2},
  journal      = {Journal of Heuristics},
  month        = {10},
  number       = {5},
  pages        = {869-885},
  shortjournal = {J. Heuristics},
  title        = {Dynamic pricing with demand disaggregation for hotel revenue management},
  volume       = {27},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A simple hyper-heuristic approach for a variant of
many-to-many hub location-routing problem. <em>JOH</em>, <em>27</em>(5),
791–868. (<a href="https://doi.org/10.1007/s10732-021-09477-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses a variant of the many-to-many hub location-routing problem. Given an undirected edge-weighted complete graph $$G = (V, E)$$ , this problem consists in finding a subset of V designated as hub nodes, partitioning all the nodes of V into cycles such that each cycle has exactly one hub node, and determining a Hamiltonian cycle on the subgraph induced by hub nodes. The objective is to minimize the total cost resulting from all these cycles. This problem is referred to as Many-to-Many p-Location-Hamiltonian Cycle Problem (MMpLHP) in this paper. To solve this problem, one has to deal with aspects of subset selection, grouping, and permutation. The characteristics of MMpLHP change according to the values of its constituent parameters. Hence, this problem can be regarded as a general problem which encompasses a diverse set of problems originating from different combinations of values of its constituent parameters. Such a general problem can be tackled effectively by suitably selecting and combining several different heuristics each of which cater to a different characteristic of the problem. Keeping this in mind, we have developed a simple multi-start hyper-heuristic approach for MMpLHP. Further, we have investigated two different selection mechanisms within the proposed approach. Experimental results and their analysis clearly demonstrate the superiority of our approach over best approaches known so far for this problem.},
  archive      = {J_JOH},
  author       = {Pandiri, Venkatesh and Singh, Alok},
  doi          = {10.1007/s10732-021-09477-x},
  journal      = {Journal of Heuristics},
  month        = {10},
  number       = {5},
  pages        = {791-868},
  shortjournal = {J. Heuristics},
  title        = {A simple hyper-heuristic approach for a variant of many-to-many hub location-routing problem},
  volume       = {27},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Bi-criteria multiple knapsack problem with grouped items.
<em>JOH</em>, <em>27</em>(5), 747–789. (<a
href="https://doi.org/10.1007/s10732-021-09476-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The multiple knapsack problem with grouped items aims to maximize rewards by assigning groups of items among multiple knapsacks, without exceeding knapsack capacities. Either all items in a group are assigned or none at all. We study the bi-criteria variation of the problem, where capacities can be exceeded and the second objective is to minimize the maximum exceeded knapsack capacity. We propose approximation algorithms that run in pseudo-polynomial time and guarantee that rewards are not less than the optimal solution of the capacity-feasible problem, with a bound on exceeded knapsack capacities. The algorithms have different approximation factors, where no knapsack capacity is exceeded by more than 2, 1, and $$1/2$$ times the maximum knapsack capacity. The approximation guarantee can be improved to $$1/3$$ when all knapsack capacities are equal. We also prove that for certain cases, solutions obtained by the approximation algorithms are always optimal—they never exceed knapsack capacities. To obtain capacity-feasible solutions, we propose a binary-search heuristic combined with the approximation algorithms. We test the performance of the algorithms and heuristics in an extensive set of experiments on randomly generated instances and show they are efficient and effective, i.e., they run reasonably fast and generate good quality solutions.},
  archive      = {J_JOH},
  author       = {Castillo-Zunino, Francisco and Keskinocak, Pinar},
  doi          = {10.1007/s10732-021-09476-y},
  journal      = {Journal of Heuristics},
  month        = {10},
  number       = {5},
  pages        = {747-789},
  shortjournal = {J. Heuristics},
  title        = {Bi-criteria multiple knapsack problem with grouped items},
  volume       = {27},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Heuristic-based allocation of supply constrained blood
platelets in emerging economies. <em>JOH</em>, <em>27</em>(5), 719–745.
(<a href="https://doi.org/10.1007/s10732-021-09474-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Platelets are valuable, but highly perishable, blood components used in the treatment of, among others, viral dengue fever, blood-related illness, and post-chemotherapy following cancer. Given the short shelf-life of 3–5 days and a highly volatile supply and demand pattern, platelet inventory allocation is a challenging task. This is especially prevalent in emerging economies where demand variability is more pronounced due to neglected tropical diseases, and a perpetual shortage of supply. The consequences of which have given rise to an illegal ‘red market’. Motivated by experience at a regional hospital in India, we investigate the problem of platelet allocation among three priority-differentiated demand streams. Specifically we consider a central hospital which, in addition to internal emergency and non-emergency requests, faces external demand from local clinics. We analyze the platelet allocation decision from a social planner’s perspective and propose an allocation heuristic based on revenue management (RM) principles. The objective is to maximize total social benefit in a highly supply-constrained environment. Using data from the aforementioned Indian hospital as a case study, we conduct a numerical simulation and sensitivity analysis to evaluate the allocation heuristic. The performance of the RM-based policy is evaluated against the current sequential first come, first serve policy and two fixed proportion-based rationing policies. It is shown that the RM-based policy overall dominates, serves patients with the highest medical urgency better, and can curtail patients’ need to procure platelets from commercial sources.},
  archive      = {J_JOH},
  author       = {Ødegaard, Fredrik and Roy, Sudipendra Nath},
  doi          = {10.1007/s10732-021-09474-0},
  journal      = {Journal of Heuristics},
  month        = {10},
  number       = {5},
  pages        = {719-745},
  shortjournal = {J. Heuristics},
  title        = {Heuristic-based allocation of supply constrained blood platelets in emerging economies},
  volume       = {27},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Qfold: A new modeling paradigm for the RNA folding problem.
<em>JOH</em>, <em>27</em>(4), 695–717. (<a
href="https://doi.org/10.1007/s10732-021-09471-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ribonucleic acid (RNA) molecules play informational, structural, and metabolic roles in all living cells. RNAs are chains of nucleotides containing bases {A, C, G, U} that interact via base pairings to determine higher order structure and functionality. The RNA folding problem is to predict one or more secondary RNA structures from a given primary sequence of bases. From a mathematical modeling perspective, solutions to the RNA folding problem come from minimizing the thermodynamic free energy of a structure by selecting which bases will be paired, subject to a set of constraints. Here we report on a Quadratic Unconstrained Binary Optimization (QUBO) modeling paradigm that fits naturally with the parameters and constraints required for RNA folding prediction. Three QUBO models are presented along with a hybrid metaheuristic algorithm. Extensive testing results show a strong positive correlation with benchmark results.},
  archive      = {J_JOH},
  author       = {Lewis, Mark W. and Verma, Amit and Eckdahl, Todd T.},
  doi          = {10.1007/s10732-021-09471-3},
  journal      = {Journal of Heuristics},
  month        = {8},
  number       = {4},
  pages        = {695-717},
  shortjournal = {J. Heuristics},
  title        = {Qfold: A new modeling paradigm for the RNA folding problem},
  volume       = {27},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A matheuristic for the stochastic facility location problem.
<em>JOH</em>, <em>27</em>(4), 649–694. (<a
href="https://doi.org/10.1007/s10732-021-09468-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we describe a matheuristic to solve the stochastic facility location problem which determines the location and size of storage facilities, the quantities of various types of supplies stored in each facility, and the assignment of demand locations to the open facilities, which minimize unmet demand and response time in lexicographic order. We assume uncertainties about demands, inventory spoilage, and transportation network availability. A good example where such a formulation makes sense is the the problem of pre-positioning emergency supplies, which aims to increase disaster preparedness by making the relief items readily available to people in need. The matheuristic employs iterated local search techniques to look for good location and inventory configurations, and uses CPLEX to optimize the assignments. Numerical experiments on a number of case studies and random instances for the pre-positioning problem demonstrate the effectiveness and efficiency of the matheuristic, which is shown to be particularly useful for tackling larger instances that are intractable for exact solvers. The matheuristic is therefore a contribution to the literature on heuristic approaches to solving facility location under uncertainties, can be used to further study the particular variant of the facility location problem, and can also support humanitarian logisticians in their planning of pre-positioning strategies.},
  archive      = {J_JOH},
  author       = {Turkeš, Renata and Sörensen, Kenneth and Cuervo, Daniel Palhazi},
  doi          = {10.1007/s10732-021-09468-y},
  journal      = {Journal of Heuristics},
  month        = {8},
  number       = {4},
  pages        = {649-694},
  shortjournal = {J. Heuristics},
  title        = {A matheuristic for the stochastic facility location problem},
  volume       = {27},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Enhancing large neighbourhood search heuristics for benders’
decomposition. <em>JOH</em>, <em>27</em>(4), 615–648. (<a
href="https://doi.org/10.1007/s10732-021-09467-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A general enhancement of the Benders’ decomposition (BD) algorithm can be achieved through the improved use of large neighbourhood search heuristics within mixed-integer programming solvers. While mixed-integer programming solvers are endowed with an array of large neighbourhood search heuristics, few, if any, have been designed for BD. Further, typically the use of large neighbourhood search heuristics is limited to finding solutions to the BD master problem. Given the lack of general frameworks for BD, only ad hoc approaches have been developed to enhance the ability of BD to find high quality primal feasible solutions through the use of large neighbourhood search heuristics. The general BD framework of SCIP has been extended with a trust region based heuristic and a general enhancement for large neighbourhood search heuristics. The general enhancement employs BD to solve the auxiliary problems of all large neighbourhood search heuristics to improve the quality of the identified solutions. The computational results demonstrate that the trust region heuristic and a general large neighbourhood search enhancement technique accelerate the improvement in the primal bound when applying BD.},
  archive      = {J_JOH},
  author       = {Maher, Stephen J.},
  doi          = {10.1007/s10732-021-09467-z},
  journal      = {Journal of Heuristics},
  month        = {8},
  number       = {4},
  pages        = {615-648},
  shortjournal = {J. Heuristics},
  title        = {Enhancing large neighbourhood search heuristics for benders’ decomposition},
  volume       = {27},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Reference point based evolutionary multi-objective
optimization algorithms with convergence properties using KKTPM and ASF
metrics. <em>JOH</em>, <em>27</em>(4), 575–614. (<a
href="https://doi.org/10.1007/s10732-021-09470-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In a preference-based multi-objective optimization task, the goal is to find a subset of the Pareto-optimal set close to a supplied set of aspiration points. The reference point based non-dominated sorting genetic algorithm (R-NSGA-II) was proposed for such problem-solving tasks. R-NSGA-II aims to finding Pareto-optimal points close, in the sense of Euclidean distance in the objective space, to the supplied aspiration points, instead of finding the entire Pareto-optimal set. In this paper, R-NSGA-II method is modified using recently proposed Karush–Kuhn–Tucker proximity measure (KKTPM) and achievement scalarization function (ASF) metrics, instead of Euclidean distance metric. While a distance measure may not produce desired solutions, KKTPM-based distance measure allows a theoretically-convergent local or global Pareto solutions satisfying KKT optimality conditions and the ASF measure allows Pareto-compliant solutions to be found. A new technique for calculating KKTPM measure of a solution in the presence of an aspiration point is developed in this paper. The proposed modified R-NSGA-II methods are able to solve as many as 10-objective problems as effectively or better than the existing R-NSGA-II algorithm.},
  archive      = {J_JOH},
  author       = {Abouhawwash, Mohamed and Deb, Kalyanmoy},
  doi          = {10.1007/s10732-021-09470-4},
  journal      = {Journal of Heuristics},
  month        = {8},
  number       = {4},
  pages        = {575-614},
  shortjournal = {J. Heuristics},
  title        = {Reference point based evolutionary multi-objective optimization algorithms with convergence properties using KKTPM and ASF metrics},
  volume       = {27},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Analysis of bayesian network learning techniques for a
hybrid multi-objective bayesian estimation of distribution algorithm: A
case study on MNK landscape. <em>JOH</em>, <em>27</em>(4), 549–573. (<a
href="https://doi.org/10.1007/s10732-021-09469-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work investigates different Bayesian network structure learning techniques by thoroughly studying several variants of Hybrid Multi-objective Bayesian Estimation of Distribution Algorithm (HMOBEDA), applied to the MNK Landscape combinatorial problem. In the experiments, we evaluate the performance considering three different aspects: optimization abilities, robustness and learning efficiency. Results for instances of multi- and many-objective MNK-landscape show that, score-based structure learning algorithms appear to be the best choice. In particular, HMOBEDA $$_{k2}$$ was capable of producing results comparable with the other variants in terms of the runtime of convergence and the coverage of the final Pareto front, with the additional advantage of providing solutions that are less sensible to noise while the variability of the corresponding Bayesian network models is reduced.},
  archive      = {J_JOH},
  author       = {Martins, Marcella S. R. and Yafrani, Mohamed El and Delgado, Myriam and Lüders, Ricardo and Santana, Roberto and Siqueira, Hugo V. and Akcay, Huseyin G. and Ahiod, Belaïd},
  doi          = {10.1007/s10732-021-09469-x},
  journal      = {Journal of Heuristics},
  month        = {8},
  number       = {4},
  pages        = {549-573},
  shortjournal = {J. Heuristics},
  title        = {Analysis of bayesian network learning techniques for a hybrid multi-objective bayesian estimation of distribution algorithm: A case study on MNK landscape},
  volume       = {27},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Augmented intuition: A bridge between theory and practice.
<em>JOH</em>, <em>27</em>(4), 497–547. (<a
href="https://doi.org/10.1007/s10732-020-09465-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Motivated by the celebrated paper of Hooker (J Heuristics 1(1): 33–42, 1995) published in the first issue of this journal, and by the relative lack of progress of both approximation algorithms and fixed-parameter algorithms for the classical decision and optimization problems related to covering edges by vertices, we aimed at developing an approach centered in augmenting our intuition about what is indeed needed. We present a case study of a novel design methodology by which algorithm weaknesses will be identified by computer-based and fixed-parameter tractable algorithmic challenges on their performance. Comprehensive benchmarkings on all instances of small size then become an integral part of the design process. Subsequent analyses of cases where human intuition “fails”, supported by computational testing, will then lead to the development of new methods by avoiding the traps of relying only on human perspicacity and ultimately will improve the quality of the results. Consequently, the computer-aided design process is seen as a tool to augment human intuition. It aims at accelerating and foster theory development in areas such as graph theory and combinatorial optimization since some safe reduction rules for pre-processing can be mathematically proved via theorems. This approach can also lead to the generation of new interesting heuristics. We test our ideas with a fundamental problem in graph theory that has attracted the attention of many researchers over decades, but for which seems it seems to be that a certain stagnation has occurred. The lessons learned are certainly beneficial, suggesting that we can bridge the increasing gap between theory and practice by a more concerted approach that would fuel human imagination from a data-driven discovery perspective.},
  archive      = {J_JOH},
  author       = {Moscato, Pablo and Mathieson, Luke and Haque, Mohammad Nazmul},
  doi          = {10.1007/s10732-020-09465-7},
  journal      = {Journal of Heuristics},
  month        = {8},
  number       = {4},
  pages        = {497-547},
  shortjournal = {J. Heuristics},
  title        = {Augmented intuition: A bridge between theory and practice},
  volume       = {27},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Weighted proximity search. <em>JOH</em>, <em>27</em>(3),
459–496. (<a href="https://doi.org/10.1007/s10732-021-09466-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Proximity search is an iterative method to solve complex mathematical programming problems. At each iteration, the objective function of the problem at hand is replaced by the Hamming distance function to a given solution, and a cutoff constraint is added to impose that any new obtained solution improves the objective function value. A mixed integer programming solver is used to find a feasible solution to this modified problem, yielding an improved solution to the original problem. This paper introduces the concept of weighted Hamming distance that allows to design a new method called weighted proximity search. In this new distance function, low weights are associated with the variables whose value in the current solution is promising to change in order to find an improved solution, while high weights are assigned to variables that are expected to remain unchanged. The weights help to distinguish between alternative solutions in the neighborhood of the current solution, and provide guidance to the solver when trying to locate an improved solution. Several strategies to determine weights are presented, including both static and dynamic strategies. The proposed weighted proximity search is compared with the classic proximity search on instances from three optimization problems: the p-median problem, the set covering problem, and the stochastic lot-sizing problem. The obtained results show that a suitable choice of weights allows the weighted proximity search to obtain better solutions, for 75 $$\%$$ of the cases, than the ones obtained by using proximity search and for 96 $$\%$$ of the cases the solutions are better than the ones obtained by running a commercial solver with a time limit.},
  archive      = {J_JOH},
  author       = {Rodrigues, Filipe and Agra, Agostinho and Hvattum, Lars Magnus and Requejo, Cristina},
  doi          = {10.1007/s10732-021-09466-0},
  journal      = {Journal of Heuristics},
  month        = {6},
  number       = {3},
  pages        = {459-496},
  shortjournal = {J. Heuristics},
  title        = {Weighted proximity search},
  volume       = {27},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A max-conflicts based heuristic search for the stable
marriage problem with ties and incomplete lists. <em>JOH</em>,
<em>27</em>(3), 439–458. (<a
href="https://doi.org/10.1007/s10732-020-09464-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a heuristic search algorithm based on maximum conflicts to find a weakly stable matching of maximum size for the stable marriage problem with ties and incomplete lists. The key idea of our approach is to define a heuristic function based on the information extracted from undominated blocking pairs from the men’s point of view. By choosing a man corresponding to the maximum value of the heuristic function, we aim to not only remove all the blocking pairs formed by the man but also reject as many blocking pairs as possible for an unstable matching from the women’s point of view to obtain a solution of the problem as quickly as possible. Experiments show that our algorithm is efficient in terms of both execution time and solution quality for solving the problem.},
  archive      = {J_JOH},
  author       = {Viet, Hoang Huu and Uyen, Nguyen Thi and Lee, SeungGwan and Chung, TaeChoong and Trang, Le Hong},
  doi          = {10.1007/s10732-020-09464-8},
  journal      = {Journal of Heuristics},
  month        = {6},
  number       = {3},
  pages        = {439-458},
  shortjournal = {J. Heuristics},
  title        = {A max-conflicts based heuristic search for the stable marriage problem with ties and incomplete lists},
  volume       = {27},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Iterated local search for single machine total weighted
tardiness batch scheduling. <em>JOH</em>, <em>27</em>(3), 353–438. (<a
href="https://doi.org/10.1007/s10732-020-09461-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents an iterated local search (ILS) algorithm for the single machine total weighted tardiness batch scheduling problem. To our knowledge, this is one of the first attempts to apply ILS to solve a batching scheduling problem. The proposed algorithm contains a local search procedure that explores five neighborhood structures, and we show how to efficiently implement them. Moreover, we compare the performance of our algorithm with dynamic programming-based implementations for the problem, including one from the literature and two other ones inspired in biased random-key genetic algorithms and ILS. We also demonstrate that finding the optimal batching for the problem given a fixed sequence of jobs is $$\mathcal {NP}$$ -hard, and provide an exact pseudo-polynomial time dynamic programming algorithm for solving such problem. Extensive computational experiments were conducted on newly proposed benchmark instances, and the results indicate that our algorithm yields highly competitive results when compared to other strategies. Finally, it was also observed that the methods that rely on dynamic programming tend to be time-consuming, even for small size instances.},
  archive      = {J_JOH},
  author       = {Queiroga, Eduardo and Pinheiro, Rian G. S. and Christ, Quentin and Subramanian, Anand and Pessoa, Artur A.},
  doi          = {10.1007/s10732-020-09461-x},
  journal      = {Journal of Heuristics},
  month        = {6},
  number       = {3},
  pages        = {353-438},
  shortjournal = {J. Heuristics},
  title        = {Iterated local search for single machine total weighted tardiness batch scheduling},
  volume       = {27},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A reduced cost-based restriction and refinement matheuristic
for stochastic network design problem. <em>JOH</em>, <em>27</em>(3),
325–351. (<a href="https://doi.org/10.1007/s10732-020-09460-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a solution approach for stochastic network design problems with uncertain demands. We investigate how to efficiently use reduced cost information as a means of guiding variable fixing to define a restriction that reduces the complexity of solving the stochastic model without sacrificing the quality of the solution obtained. We then propose a matheuristic approach that iteratively defines and explores restricted regions of the global solution space that have a high potential of containing good solutions. Extensive computational experiments show the effectiveness of the proposed approach in obtaining high-quality solutions, while reducing the computational effort to obtain them.},
  archive      = {J_JOH},
  author       = {Sarayloo, Fatemeh and Crainic, Teodor Gabriel and Rei, Walter},
  doi          = {10.1007/s10732-020-09460-y},
  journal      = {Journal of Heuristics},
  month        = {6},
  number       = {3},
  pages        = {325-351},
  shortjournal = {J. Heuristics},
  title        = {A reduced cost-based restriction and refinement matheuristic for stochastic network design problem},
  volume       = {27},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Local search for the maximum k-plex problem. <em>JOH</em>,
<em>27</em>(3), 303–324. (<a
href="https://doi.org/10.1007/s10732-020-09459-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The maximum k-plex problem is an important, computationally complex graph based problem. In this study an effective k-plex local search (KLS) is presented for solving this problem on a wide range of graph types. KLS uses data structures suitable for the graph being analysed and has mechanisms for preventing search cycling and promoting search diversity. State of the art results were obtained on 121 dense graphs and 61 large real-life (sparse) graphs. Comparisons with three recent algorithms on the more difficult graphs show that KLS performed better or as well as in 93% of 332 significant k-plex problem instances investigated achieving either larger average k-plex sizes (including some new results) or, when these were equivalent, lower CPU requirements.},
  archive      = {J_JOH},
  author       = {Pullan, Wayne},
  doi          = {10.1007/s10732-020-09459-5},
  journal      = {Journal of Heuristics},
  month        = {6},
  number       = {3},
  pages        = {303-324},
  shortjournal = {J. Heuristics},
  title        = {Local search for the maximum k-plex problem},
  volume       = {27},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A non-dominated sorting based customized random-key genetic
algorithm for the bi-objective traveling thief problem. <em>JOH</em>,
<em>27</em>(3), 267–301. (<a
href="https://doi.org/10.1007/s10732-020-09457-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a method to solve a bi-objective variant of the well-studied traveling thief problem (TTP). The TTP is a multi-component problem that combines two classic combinatorial problems: traveling salesman problem and knapsack problem. We address the BI-TTP, a bi-objective version of the TTP, where the goal is to minimize the overall traveling time and to maximize the profit of the collected items. Our proposed method is based on a biased-random key genetic algorithm with customizations addressing problem-specific characteristics. We incorporate domain knowledge through a combination of near-optimal solutions of each subproblem in the initial population and use a custom repair operator to avoid the evaluation of infeasible solutions. The bi-objective aspect of the problem is addressed through an elite population extracted based on the non-dominated rank and crowding distance. Furthermore, we provide a comprehensive study showing the influence of each parameter on the performance. Finally, we discuss the results of the BI-TTP competitions at EMO-2019 and GECCO-2019 conferences where our method has won first and second places, respectively, thus proving its ability to find high-quality solutions consistently.},
  archive      = {J_JOH},
  author       = {Chagas, Jonatas B. C. and Blank, Julian and Wagner, Markus and Souza, Marcone J. F. and Deb, Kalyanmoy},
  doi          = {10.1007/s10732-020-09457-7},
  journal      = {Journal of Heuristics},
  month        = {6},
  number       = {3},
  pages        = {267-301},
  shortjournal = {J. Heuristics},
  title        = {A non-dominated sorting based customized random-key genetic algorithm for the bi-objective traveling thief problem},
  volume       = {27},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The convex hull heuristic for nonlinear integer programming
problems with linear constraints and application to quadratic 0–1
problems. <em>JOH</em>, <em>27</em>(1), 251–265. (<a
href="https://doi.org/10.1007/s10732-019-09433-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The convex hull heuristic is a heuristic for mixed-integer programming problems with a nonlinear objective function and linear constraints. It is a matheuristic in two ways: it is based on the mathematical programming algorithm called simplicial decomposition, or SD (von Hohenbalken in Math Program 13:49–68, 1977), and at each iteration, one solves a mixed-integer programming problem with a linear objective function and the original constraints, and a continuous problem with a nonlinear objective function and a single linear constraint. Its purpose is to produce quickly feasible and often near optimal or optimal solutions for convex and nonconvex problems. It is usually multi-start. We have tested it on a number of hard quadratic 0–1 optimization problems and present numerical results for generalized quadratic assignment problems, cross-dock door assignment problems, quadratic assignment problems and quadratic knapsack problems. We compare solution quality and solution times with results from the literature, when possible.},
  archive      = {J_JOH},
  author       = {Guignard, Monique and Ahlatcioglu, Aykut},
  doi          = {10.1007/s10732-019-09433-w},
  journal      = {Journal of Heuristics},
  month        = {4},
  number       = {1},
  pages        = {251-265},
  shortjournal = {J. Heuristics},
  title        = {The convex hull heuristic for nonlinear integer programming problems with linear constraints and application to quadratic 0–1 problems},
  volume       = {27},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). CMSA algorithm for solving the prioritized pairwise test
data generation problem in software product lines. <em>JOH</em>,
<em>27</em>(1), 229–249. (<a
href="https://doi.org/10.1007/s10732-020-09462-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In Software Product Lines, it may be difficult or even impossible to test all the products of the family because of the large number of valid feature combinations that may exist (Ferrer et al. in: Squillero, Sim (eds) EvoApps 2017, LNCS 10200, Springer, The Netherlands, pp 3–19, 2017). Thus, we want to find a minimal subset of the product family that allows us to test all these possible combinations (pairwise). Furthermore, when testing a single product is a great effort, it is desirable to first test products composed of a set of priority features. This problem is called Prioritized Pairwise Test Data Generation Problem. State-of-the-art algorithms based on Integer Linear Programming for this problem are faster enough for small and medium instances. However, there exists some real instances that are too large to be computed with these algorithms in a reasonable time because of the exponential growth of the number of candidate solutions. Also, these heuristics not always lead us to the best solutions. In this work we propose a new approach based on a hybrid metaheuristic algorithm called Construct, Merge, Solve &amp; Adapt. We compare this matheuristic with four algorithms: a Hybrid algorithm based on Integer Linear Programming, a Hybrid algorithm based on Integer Nonlinear Programming, the Parallel Prioritized Genetic Solver, and a greedy algorithm called prioritized-ICPL. The analysis reveals that CMSA is statistically significantly better in terms of quality of solutions in most of the instances and for most levels of weighted coverage, although it requires more execution time.},
  archive      = {J_JOH},
  author       = {Ferrer, Javier and Chicano, Francisco and Ortega-Toro, José Antonio},
  doi          = {10.1007/s10732-020-09462-w},
  journal      = {Journal of Heuristics},
  month        = {4},
  number       = {1},
  pages        = {229-249},
  shortjournal = {J. Heuristics},
  title        = {CMSA algorithm for solving the prioritized pairwise test data generation problem in software product lines},
  volume       = {27},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An automatic constructive matheuristic for the shift
minimization personnel task scheduling problem. <em>JOH</em>,
<em>27</em>(1), 205–227. (<a
href="https://doi.org/10.1007/s10732-020-09439-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The shift minimization personnel task scheduling problem is an NP-complete optimization problem that concerns the assignment of tasks to multi-skilled employees with a view to minimize the total number of assigned employees. Recent literature indicates that hybrid methods which combine exact and heuristic techniques such as matheuristics are efficient as regards to generating high quality solutions. The present work employs a constructive matheuristic (CMH): a decomposition-based method where sub-problems are solved to optimality using exact techniques. The optimal solutions of sub-problems are subsequently utilized to construct a feasible solution for the entire problem. Based on the study, a time-based CMH has been developed which, for the first time, solves all the difficult instances introduced by Smet et al. (Omega 46:64–73, 2014) to optimality. In addition, an automated CMH algorithm that utilizes instance-specific problem features has also been developed that produces high quality solutions over all current benchmark instances.},
  archive      = {J_JOH},
  author       = {Chirayil Chandrasekharan, Reshma and Smet, Pieter and Wauters, Tony},
  doi          = {10.1007/s10732-020-09439-9},
  journal      = {Journal of Heuristics},
  month        = {4},
  number       = {1},
  pages        = {205-227},
  shortjournal = {J. Heuristics},
  title        = {An automatic constructive matheuristic for the shift minimization personnel task scheduling problem},
  volume       = {27},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The just-in-time job-shop scheduling problem with distinct
due-dates for operations. <em>JOH</em>, <em>27</em>(1), 175–204. (<a
href="https://doi.org/10.1007/s10732-020-09458-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the just-in-time job-shop scheduling (JIT–JSS) problem every operation has a distinct due-date, and earliness and tardiness penalties. Any deviation from the due-date incurs penalties. The objective of JIT–JSS is to obtain a schedule, i.e., the completion time for performing the operations, with the smallest total (weighted) earliness and tardiness penalties. This paper presents a matheuristic algorithm for the JIT–JSS problem, which operates by decomposing the problem into smaller sub-problems, optimizing the sub-problems and delivering the optimal schedule for the problem. By solving a set of 72 benchmark instances ranging from 10 to 20 jobs and 20 to 200 operations we show that the proposed algorithm outperforms the state-of-the-art methods and the solver CPLEX, and obtains new best solutions for nearly 56% of the instances, including for 79% of the large instances with 20 jobs.},
  archive      = {J_JOH},
  author       = {Ahmadian, Mohammad Mahdi and Salehipour, Amir},
  doi          = {10.1007/s10732-020-09458-6},
  journal      = {Journal of Heuristics},
  month        = {4},
  number       = {1},
  pages        = {175-204},
  shortjournal = {J. Heuristics},
  title        = {The just-in-time job-shop scheduling problem with distinct due-dates for operations},
  volume       = {27},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Minimizing total completion time in the two-machine no-idle
no-wait flow shop problem. <em>JOH</em>, <em>27</em>(1), 159–173. (<a
href="https://doi.org/10.1007/s10732-019-09430-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the two-machine total completion time flow shop problem with additional requirements. These requirements are the so-called no-idle constraint where the machines must operate with no inserted idle time and the so-called no-wait constraint where jobs cannot wait between the end of an operation and the start of the following one. We propose a matheuristic approach that uses an ILP formulation based on positional completion times variables and exploits the structural properties of the problem. The proposed approach shows very competitive performances on instances with up to 500 jobs in size.},
  archive      = {J_JOH},
  author       = {Della Croce, Federico and Grosso, Andrea and Salassa, Fabio},
  doi          = {10.1007/s10732-019-09430-z},
  journal      = {Journal of Heuristics},
  month        = {4},
  number       = {1},
  pages        = {159-173},
  shortjournal = {J. Heuristics},
  title        = {Minimizing total completion time in the two-machine no-idle no-wait flow shop problem},
  volume       = {27},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Scheduling hybrid flow shops with time windows.
<em>JOH</em>, <em>27</em>(1), 133–158. (<a
href="https://doi.org/10.1007/s10732-019-09425-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hybrid flow shops can be encountered in various industrial settings. In this paper we develop methods for scheduling hybrid flow shops with hard time windows. Specifically, we study a two-stage hybrid flow shop scheduling problem with time windows to minimize the total weighted completion times. Each stage consists of one or more identical parallel machines, and each job visits two processing stages in series. Finding a feasible schedule with hard time windows is a challenging task in this setting, because it is NP-complete in the strong sense even for a single machine in a single stage. We propose two matheuristics to find an initial feasible solution by local branching. We also develop two schedule improvement procedures, one based on stage-by-stage decomposition, and one using adapted local branching. The performance of our methods is validated via extensive computational experiments.},
  archive      = {J_JOH},
  author       = {Yang, Fan and Leus, Roel},
  doi          = {10.1007/s10732-019-09425-w},
  journal      = {Journal of Heuristics},
  month        = {4},
  number       = {1},
  pages        = {133-158},
  shortjournal = {J. Heuristics},
  title        = {Scheduling hybrid flow shops with time windows},
  volume       = {27},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A balance-first sequence-last algorithm to design RMS: A
matheuristic with performance guaranty to balance reconfigurable
manufacturing systems. <em>JOH</em>, <em>27</em>(1), 107–132. (<a
href="https://doi.org/10.1007/s10732-021-09473-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Reconfigurable Transfer Line Balancing Problem (RTLB) is considered in this paper. This problem is quite recent and motivated by the growing need of reconfigurability in the new industry 4.0 context. The problem consists into allocating a set of operations necessary to machine a single part to different workstations placed into a serial line. Each workstation can contain multiple machines operating in parallel and the tasks allocated to a workstation should be sequenced since sequence-dependent setup times between operations are needed to perform tool changes. Besides, precedence constraints, inclusion, exclusion and accessibility constraints between operations are considered. In this article we propose an efficient matheuristic of type Balance First, Sequence Last (BFSL). This method is a two-step heuristic with a constructive phase and an improvement phase. It contains several components from exact methods (linear programming, constraint generation and dynamic programming) and metaheuristics (simulated annealing). In addition, we show that the constructive algorithm approximates the optimal solution when the setup times are bounded by the processing times and give an approximation ratio. The obtained results show the effectiveness of the proposed approach. The matheuristic clearly outperforms a genetic algorithm from literature on quite large benchmark instances.},
  archive      = {J_JOH},
  author       = {Lahrichi, Youssef and Deroussi, Laurent and Grangeon, Nathalie and Norre, Sylvie},
  doi          = {10.1007/s10732-021-09473-1},
  journal      = {Journal of Heuristics},
  month        = {4},
  number       = {1},
  pages        = {107-132},
  shortjournal = {J. Heuristics},
  title        = {A balance-first sequence-last algorithm to design RMS: A matheuristic with performance guaranty to balance reconfigurable manufacturing systems},
  volume       = {27},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Matheuristics to optimize refueling and maintenance planning
of nuclear power plants. <em>JOH</em>, <em>27</em>(1), 63–105. (<a
href="https://doi.org/10.1007/s10732-020-09450-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Planning the maintenance of nuclear power plants is a complex optimization problem, involving a joint optimization of maintenance dates, fuel constraints and power production decisions. This paper investigates Mixed Integer Linear Programming (MILP) matheuristics for this problem, to tackle large size instances used in operations with a time scope of 5 years, and few restrictions with time window constraints for the latest maintenance operations. Several constructive matheuristics and a Variable Neighborhood Descent local search are designed. The matheuristics are shown to be accurately effective for medium and large size instances. The matheuristics give also results on the design of MILP formulations and neighborhoods for the problem. Contributions for the operational applications are also discussed. It is shown that the restriction of time windows, which was used to ease computations, induces large over-costs and that this restriction is not required anymore with the capabilities of matheuristics or local searches to solve such size of instances. Our matheuristics can be extended to a bi-objective optimization extension with stability costs, for the monthly re-optimization of the maintenance planning in the real-life application.},
  archive      = {J_JOH},
  author       = {Dupin, Nicolas and Talbi, El-Ghazali},
  doi          = {10.1007/s10732-020-09450-0},
  journal      = {Journal of Heuristics},
  month        = {4},
  number       = {1},
  pages        = {63-105},
  shortjournal = {J. Heuristics},
  title        = {Matheuristics to optimize refueling and maintenance planning of nuclear power plants},
  volume       = {27},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The vehicle routing problem with cross-docking and resource
constraints. <em>JOH</em>, <em>27</em>(1), 31–61. (<a
href="https://doi.org/10.1007/s10732-019-09423-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose an extension of the vehicle routing problem with cross-docking that takes into account resource constraints at the cross-dock. These constraints limit the number of docks that can be used simultaneously. To solve this new problem, we adapt a recently proposed matheuristic based on large neighborhood search. In particular, we focus on the feasibility tests for insertions and compare heuristics and constraint programming strategies. Finally, computational experiments on instances adapted from the vehicle routing problem with cross-docking are reported. They give insights on the impact of a limited cross-dock capacity on the routing cost.},
  archive      = {J_JOH},
  author       = {Grangier, Philippe and Gendreau, Michel and Lehuédé, Fabien and Rousseau, Louis-Martin},
  doi          = {10.1007/s10732-019-09423-y},
  journal      = {Journal of Heuristics},
  month        = {4},
  number       = {1},
  pages        = {31-61},
  shortjournal = {J. Heuristics},
  title        = {The vehicle routing problem with cross-docking and resource constraints},
  volume       = {27},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Focus distance-aware lifetime maximization of video
camera-based wireless sensor networks. <em>JOH</em>, <em>27</em>(1),
5–30. (<a href="https://doi.org/10.1007/s10732-019-09428-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The problem of maximizing the lifetime of a wireless sensor network which uses video cameras to monitor targets is considered. These video cameras can rotate and have a fixed monitoring angle. For a target to be covered by a video camera mounted on a sensor node, three conditions must be satisfied. First, the distance between the sensor and the target should be less than the sensing range. Second, the direction of the camera sensor should face the target, and third, the focus of the video camera should be such that the picture of the target is sharp. Basic elements on optics are recalled, then some properties are shown to efficiently address the problem of setting the direction and focal distance of a video camera for target coverage. Then, a column generation algorithm based on these properties is proposed for solving three lifetime maximization problems. Targets are considered as points in the first problem, they are considered as discs in the second problem (which allows for considering occlusion) and in the last problem, focal distance is also dealt with for taking image sharpness into account. All of these problems are compared on a testbed of 180 instances and numerical results show the effectiveness of the proposed approach.},
  archive      = {J_JOH},
  author       = {Rossi, André and Singh, Alok and Sevaux, Marc},
  doi          = {10.1007/s10732-019-09428-7},
  journal      = {Journal of Heuristics},
  month        = {4},
  number       = {1},
  pages        = {5-30},
  shortjournal = {J. Heuristics},
  title        = {Focus distance-aware lifetime maximization of video camera-based wireless sensor networks},
  volume       = {27},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Special issue on matheuristics. <em>JOH</em>,
<em>27</em>(1), 1–3. (<a
href="https://doi.org/10.1007/s10732-021-09472-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JOH},
  author       = {Kergosien, Yannick and Mendoza, Jorge E. and T’kindt, Vincent},
  doi          = {10.1007/s10732-021-09472-2},
  journal      = {Journal of Heuristics},
  month        = {4},
  number       = {1},
  pages        = {1-3},
  shortjournal = {J. Heuristics},
  title        = {Special issue on matheuristics},
  volume       = {27},
  year         = {2021},
}
</textarea>
</details></li>
</ul>

</body>
</html>
