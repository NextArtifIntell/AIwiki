<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>AIR_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="air---155">AIR - 155</h2>
<ul>
<li><details>
<summary>
(2021). A systematic review on overfitting control in shallow and
deep neural networks. <em>AIR</em>, <em>54</em>(8), 6391–6438. (<a
href="https://doi.org/10.1007/s10462-021-09975-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Shallow neural networks process the features directly, while deep networks extract features automatically along with the training. Both models suffer from overfitting or poor generalization in many cases. Deep networks include more hyper-parameters than shallow ones that increase the overfitting probability. This paper states a systematic review of the overfit controlling methods and categorizes them into passive, active, and semi-active subsets. A passive method designs a neural network before training, while an active method adapts a neural network along with the training process. A semi-active method redesigns a neural network when the training performance is poor. This review includes the theoretical and experimental backgrounds of these methods, their strengths and weaknesses, and the emerging techniques for overfitting detection. The adaptation of model complexity to the data complexity is another point in this review. The relation between overfitting control, regularization, network compression, and network simplification is also stated. The paper ends with some concluding lessons from the literature.},
  archive      = {J_AIR},
  author       = {Bejani, Mohammad Mahdi and Ghatee, Mehdi},
  doi          = {10.1007/s10462-021-09975-1},
  journal      = {Artificial Intelligence Review},
  number       = {8},
  pages        = {6391-6438},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A systematic review on overfitting control in shallow and deep neural networks},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Mining and classifying customer reviews: A survey.
<em>AIR</em>, <em>54</em>(8), 6343–6389. (<a
href="https://doi.org/10.1007/s10462-021-09955-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the increasing number of customer reviews on the Web, there is a growing need for effective methods to retrieve valuable information hidden in these reviews, as sellers need to gain a deep understanding of customers’ preferences in a timely manner. With the continuous enhancement of opinion mining or sentiment analysis research, researchers have proposed many automatic mining and classification methods. However, how to choose a trusted method is a difficult problem for companies, because customer reviews (or opinions) contain a lot of uncertain information and noise. This article reports on a detailed survey of recent opinion mining literature. It also reviews how to extract text features in opinions that may contain noise or uncertainties, how to express knowledge in opinions, and how to classify them. Through this extensive study, this paper discusses open questions and recommends future research directions for building the next generation of opinion mining systems.},
  archive      = {J_AIR},
  author       = {Subhashini, L. D. C. S. and Li, Yuefeng and Zhang, Jinglan and Atukorale, Ajantha S. and Wu, Yutong},
  doi          = {10.1007/s10462-021-09955-5},
  journal      = {Artificial Intelligence Review},
  number       = {8},
  pages        = {6343-6389},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Mining and classifying customer reviews: A survey},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Scientometric analysis of literature on distributed
vehicular networks: VOSViewer visualization techniques. <em>AIR</em>,
<em>54</em>(8), 6309–6341. (<a
href="https://doi.org/10.1007/s10462-021-09980-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The idea of vehicular communication has evolved dramatically over the past two decades apparently with technological advancements that accord low power and memory consumption devices, and yet providing low latency and high performing abilities. In the 20th century, vehicular communications were primarily done through singling blinkers, tail lights, and hazard lamps, essentially serving rudimentary purposes. In the early 2000s, the term “VANET” was first introduced for demonstrating road safety and navigation. By the end of 2012, the term vehicle-to-everything(V2X) was coined with IEEE 802.11p as the supporting standard for underneath technology. The adequately increasing publications and development of VANET simulators like SUMO acknowledge the fact that there has been an intriguing interest in vehicular research. While publications are increasing massively in numbers, perhaps, we identified a lack of comprehensive scientometric analysis for this field. This paper aims at analyzing the researches carried out between 2009 and 2020 using Scopus data with a scientometric approach thereby highlighting the citation patterns and indulging journals, authors, institutes, countries in the field of vehicular communication. Furthermore, keywords analysis is also staged using VOSViewer to visualize the research patterns. This paper also tries to classify the publications into distinct clusters so formed in VOSViewer using classifying techniques, hence, to make the voluminous data acumen for the publication stride.},
  archive      = {J_AIR},
  author       = {Sood, Sandeep Kumar and Kumar, Navin and Saini, Munish},
  doi          = {10.1007/s10462-021-09980-4},
  journal      = {Artificial Intelligence Review},
  number       = {8},
  pages        = {6309-6341},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Scientometric analysis of literature on distributed vehicular networks: VOSViewer visualization techniques},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A data-driven missing value imputation approach for
longitudinal datasets. <em>AIR</em>, <em>54</em>(8), 6277–6307. (<a
href="https://doi.org/10.1007/s10462-021-09963-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Longitudinal datasets of human ageing studies usually have a high volume of missing data, and one way to handle missing values in a dataset is to replace them with estimations. However, there are many methods to estimate missing values, and no single method is the best for all datasets. In this article, we propose a data-driven missing value imputation approach that performs a feature-wise selection of the best imputation method, using known information in the dataset to rank the five methods we selected, based on their estimation error rates. We evaluated the proposed approach in two sets of experiments: a classifier-independent scenario, where we compared the applicabilities and error rates of each imputation method; and a classifier-dependent scenario, where we compared the predictive accuracy of Random Forest classifiers generated with datasets prepared using each imputation method and a baseline approach of doing no imputation (letting the classification algorithm handle the missing values internally). Based on our results from both sets of experiments, we concluded that the proposed data-driven missing value imputation approach generally resulted in models with more accurate estimations for missing data and better performing classifiers, in longitudinal datasets of human ageing. We also observed that imputation methods devised specifically for longitudinal data had very accurate estimations. This reinforces the idea that using the temporal information intrinsic to longitudinal data is a worthwhile endeavour for machine learning applications, and that can be achieved through the proposed data-driven approach.},
  archive      = {J_AIR},
  author       = {Ribeiro, Caio and Freitas, Alex A.},
  doi          = {10.1007/s10462-021-09963-5},
  journal      = {Artificial Intelligence Review},
  number       = {8},
  pages        = {6277-6307},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A data-driven missing value imputation approach for longitudinal datasets},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Recent developments in computational color image denoising
with PDEs to deep learning: A review. <em>AIR</em>, <em>54</em>(8),
6245–6276. (<a
href="https://doi.org/10.1007/s10462-021-09977-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image denoising methods are of fundamental importance in image processing and artificial intelligence systems. In this review, we analyze the traditional and state of the art mathematical models for computational color image denoising. These algorithms are divided into methods that are based on the partial differential equations, low rank, sparse representation and recent developments based on deep learning models. These algorithms also compared in terms of image quality measures. Our analysis and review of the computational color image denoising filters indicate that the convolutional neural networks from the deep learning domain obtain high quality restorations in terms of image quality despite the higher computational complexity.},
  archive      = {J_AIR},
  author       = {Salamat, Nadeem and Missen, Malik Muhammad Saad and Surya Prasath, V. B.},
  doi          = {10.1007/s10462-021-09977-z},
  journal      = {Artificial Intelligence Review},
  number       = {8},
  pages        = {6245-6276},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Recent developments in computational color image denoising with PDEs to deep learning: A review},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Benchmarking lightweight face architectures on specific face
recognition scenarios. <em>AIR</em>, <em>54</em>(8), 6201–6244. (<a
href="https://doi.org/10.1007/s10462-021-09974-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the impact of lightweight face models on real applications. Lightweight architectures proposed for face recognition are analyzed and evaluated on different scenarios. In particular, we evaluate the performance of five recent lightweight architectures on five face recognition scenarios: image and video based face recognition, cross-factor and heterogeneous face recognition, as well as active authentication on mobile devices. In addition, we show the lacks of using common lightweight models unchanged for specific face recognition tasks, by assessing the performance of the original lightweight versions of the lightweight face models considered in our study. We also show that the inference time on different devices and the computational requirements of the lightweight architectures allows their use on real-time applications or computationally limited platforms. In summary, this paper can serve as a baseline in order to select lightweight face architectures depending on the practical application at hand. Besides, it provides some insights about the remaining challenges and possible future research topics.},
  archive      = {J_AIR},
  author       = {Martínez-Díaz, Yoanna and Nicolás-Díaz, Miguel and Méndez-Vázquez, Heydi and Luevano, Luis S. and Chang, Leonardo and Gonzalez-Mendoza, Miguel and Sucar, Luis Enrique},
  doi          = {10.1007/s10462-021-09974-2},
  journal      = {Artificial Intelligence Review},
  number       = {8},
  pages        = {6201-6244},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Benchmarking lightweight face architectures on specific face recognition scenarios},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Feature selection methods for text classification: A
systematic literature review. <em>AIR</em>, <em>54</em>(8), 6149–6200.
(<a href="https://doi.org/10.1007/s10462-021-09970-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature Selection (FS) methods alleviate key problems in classification procedures as they are used to improve classification accuracy, reduce data dimensionality, and remove irrelevant data. FS methods have received a great deal of attention from the text classification community. However, only a few literature surveys include them focusing on text classification, and the ones available are either a superficial analysis or present a very small set of work in the subject. For this reason, we conducted a Systematic Literature Review (SLR) that asses 1376 unique papers from journals and conferences published in the past eight years (2013–2020). After abstract screening and full-text eligibility analysis, 175 studies were included in our SLR. Our contribution is twofold. We have considered several aspects of each proposed method and mapped them into a new categorization schema. Additionally, we mapped the main characteristics of the experiments, identifying which datasets, languages, machine learning algorithms, and validation methods have been used to evaluate new and existing techniques. By following the SLR protocol, we allow the replication of our revision process and minimize the chances of bias while classifying the included studies. By mapping issues and experiment settings, our SLR helps researchers to develop and position new studies with respect to the existing literature.},
  archive      = {J_AIR},
  author       = {Pintas, Julliano Trindade and Fernandes, Leandro A. F. and Garcia, Ana Cristina Bicharra},
  doi          = {10.1007/s10462-021-09970-6},
  journal      = {Artificial Intelligence Review},
  number       = {8},
  pages        = {6149-6200},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Feature selection methods for text classification: A systematic literature review},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). On selection of optimal cuts in complete multi-scale
decision tables. <em>AIR</em>, <em>54</em>(8), 6125–6148. (<a
href="https://doi.org/10.1007/s10462-021-09965-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a novel optimal scale selection method in complete multi-scale decision tables has been proposed. Unlike the existing approaches in the literature, we employ the tools of granularity trees and cuts for each attribute. Each granularity tree has many different local cuts, which represent various scale selection methods under a specific attribute. Different local cuts collectively forms a global cut of a multi-scale information table, which in turn induces an information table with a mixed scale. One distinct feature of such tables is that the attribute values of different objects may be obtained at different scales for the same attribute. By keeping maximal consistency of the derived mixed-scale decision table, we introduce the notions of optimal cuts in multi-scale decision tables. Then, a comparative study between different types of optimal scale selection methods is performed. Finally, an algorithm is designed to verify the validity of the proposed approach.},
  archive      = {J_AIR},
  author       = {She, Yanhong and Zhao, Zhuojun and Hu, Mengting and Zheng, Wenli and He, Xiaoli},
  doi          = {10.1007/s10462-021-09965-3},
  journal      = {Artificial Intelligence Review},
  number       = {8},
  pages        = {6125-6148},
  shortjournal = {Artif. Intell. Rev.},
  title        = {On selection of optimal cuts in complete multi-scale decision tables},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Pseudo-relevance feedback based query expansion using
boosting algorithm. <em>AIR</em>, <em>54</em>(8), 6101–6124. (<a
href="https://doi.org/10.1007/s10462-021-09972-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Retrieving relevant documents from a large set using the original query is a formidable challenge. A generic approach to improve the retrieval process is realized using pseudo-relevance feedback techniques. This technique allows the expansion of original queries with conducive keywords that returns the most relevant documents corresponding to the original query. In this paper, five different hybrid techniques were tested utilizing traditional query expansion methods. Later, the boosting query term method was proposed to reweigh and strengthen the original query. The query-wise analysis revealed that the proposed approach effectively identified the most relevant keywords, and that was true even for short queries. All the proposed methods’ potency was evaluated on three different datasets; Roshni, Hamshahri1, and FIRE2011. Compared to the traditional query expansion methods, the proposed methods improved the mean average precision values of Urdu, Persian, and English datasets by 14.02\%, 9.93\%, and 6.60\%, respectively. The obtained results were also established using analysis of variance and post-hoc analysis.},
  archive      = {J_AIR},
  author       = {Rasheed, Imran and Banka, Haider and Khan, Hamaid Mahmood},
  doi          = {10.1007/s10462-021-09972-4},
  journal      = {Artificial Intelligence Review},
  number       = {8},
  pages        = {6101-6124},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Pseudo-relevance feedback based query expansion using boosting algorithm},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Detection of heart valve disorders from PCG signals using
TQWT, FA-MVEMD, shannon energy envelope and deterministic learning.
<em>AIR</em>, <em>54</em>(8), 6063–6100. (<a
href="https://doi.org/10.1007/s10462-021-09969-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Heart valve disorders (HVDs) are the major causes of cardiovascular diseases (CVD), which may be detected at the early stage using routine auscultation examination. The phonocardiogram (PCG) is a graphical representation of the physiological condition of the heart, which differs with respect to heart diseases. It is closely related to valve functionality which provides vital information for the diagnosis of CVD. However, visual inspection of PCG is tedious and error-prone, which makes it necessary and urgent to develop an automated system for the detection of HVDs with PCG recordings. In the present study we propose a novel method for the identification and classification of normal and abnormal non-segmented PCG recordings based on hybrid signal processing tools and deterministic learning theory. First, PCG signal and its first derivative are decomposed into a set of frequency subbands with a number of decomposition levels by using the tunable Q-factor wavelet transform method. Second, fast and adaptive multivariate empirical mode decomposition decomposes the subbands of the PCG signal and its derivative into scale-aligned intrinsic mode components (IMFs). The first two IMFs are extracted, which contain most of the energy of the PCG signal and its derivative and are considered to be the predominant IMFs. Third, Shannon energy is used to extract the characteristic envelope of predominant IMFs. The properties associated with the nonlinear PCG system dynamics are preserved. They are utilized to derive features, which demonstrate significant difference in PCG system dynamics between normal versus abnormal individual heartbeats. Fourth, neural networks are then used to model, identify and classify PCG system dynamics between normal and abnormal PCG signals based on deterministic learning theory. Finally, experiments have been carried out on a publicly available PCG database to verify the effectiveness of the proposed method, which include two types of classification, one for binary classification (normal vs. abnormal) and the other for multi-class classification (normal vs. aortic stenosis vs. mitral regurgitation vs. mitral stenosis vs. mitral valve prolapse). The overall average accuracy for binary, four-class and five-class classification are reported to be 97.75, 98.69 and 98.48\%, respectively. The proposed method has obtained the highest overall accuracy in comparison to other state-of-the-art approaches using the same database, which can serve as an assistant diagnostic tool for the automated detection of HVDs in clinical applications.},
  archive      = {J_AIR},
  author       = {Zeng, Wei and Lin, Zixiang and Yuan, Chengzhi and Wang, Qinghui and Liu, Fenglin and Wang, Ying},
  doi          = {10.1007/s10462-021-09969-z},
  journal      = {Artificial Intelligence Review},
  number       = {8},
  pages        = {6063-6100},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Detection of heart valve disorders from PCG signals using TQWT, FA-MVEMD, shannon energy envelope and deterministic learning},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Algorithm for t-spherical fuzzy MADM based on associated
immediate probability interactive geometric aggregation operators.
<em>AIR</em>, <em>54</em>(8), 6033–6061. (<a
href="https://doi.org/10.1007/s10462-021-09959-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The purpose of writing this manuscript is to point out some limitations of existing associated immediate probability intuitionistic fuzzy geometric aggregation operators as these existing operators fail under some conditions such as the existing operators cannot handle the information given in Pythagorean fuzzy sets, picture fuzzy sets, spherical fuzzy sets, and T-spherical fuzzy sets and the existing aggregation operators also cannot aggregate the membership value when membership value of anyone intuitionistic fuzzy number become zero. To overcome these shortcomings associated immediate probability geometric aggregation operators have been developed for T-spherical fuzzy sets and associated immediate probability interactive geometric aggregation operators are proposed. Then a comparison between these operators is developed with the help of an example. The existing score function for T-spherical fuzzy sets does not involve abstinence so a new score function is developed which provides a better comparison between any two T-spherical fuzzy numbers. To demonstrate the presented algorithm, a decision-making process algorithm is presented with T-SFS features. The advantages of the proposed work are also discussed in which it is shown that under some conditions the proposed operators can be reduced to other tools of uncertainty. The comparison between existing and proposed work is also developed with the help of an example.},
  archive      = {J_AIR},
  author       = {Munir, Muhammad and Mahmood, Tahir and Hussain, Azmat},
  doi          = {10.1007/s10462-021-09959-1},
  journal      = {Artificial Intelligence Review},
  number       = {8},
  pages        = {6033-6061},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Algorithm for T-spherical fuzzy MADM based on associated immediate probability interactive geometric aggregation operators},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Mean-variance-skewness portfolio optimization under
uncertain environment using improved genetic algorithm. <em>AIR</em>,
<em>54</em>(8), 6011–6032. (<a
href="https://doi.org/10.1007/s10462-021-09966-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An indeterminacy economic environment includes uncertainty during adopting experts knowledge for the analysis of stock returns. The main goal in this paper is to discuss the problem of portfolio selection with uncertain environment; because, the experts alone has the ability to evaluate the security returns and not with the historical data. However, the uncertain variables considered have shown the stock returns. Uncertainty programming is used to formulate mean-variance skewness indicating the problem of portfolio selection in uncertain environment based on different decision criteria. At different conditions, some significant crisp equivalents are explained for the ease of solving models within the uncertainty theory framework. Furthermore, this paper has solved the new models included in general cases using a general method developed through designing a novel hybrid intelligent algorithm. Ultimately, the developed algorithm and models applications and performance was evidently proved using a numerical example.},
  archive      = {J_AIR},
  author       = {Mittal, Sunil Kumar and Srivastava, Namita},
  doi          = {10.1007/s10462-021-09966-2},
  journal      = {Artificial Intelligence Review},
  number       = {8},
  pages        = {6011-6032},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Mean-variance-skewness portfolio optimization under uncertain environment using improved genetic algorithm},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Design and applications of an advanced hybrid meta-heuristic
algorithm for optimization problems. <em>AIR</em>, <em>54</em>(8),
5931–6010. (<a
href="https://doi.org/10.1007/s10462-021-09962-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper designed an advanced hybrid algorithm (haDEPSO) to solve the optimization problems, based on multi-population approach. It integrated with suggested advanced DE (aDE) and PSO (aPSO). Where in aDE a novel mutation strategy and crossover probability along with the slightly changed selection scheme are introduced, to avoid premature convergence. And aPSO consists of the novel gradually varying inertia weight and acceleration coefficient parameters, to escape stagnation. So, convergence characteristic of aDE and aPSO provides different approximation to the solution space. Thus, haDEPSO achieve better solutions due to integrating merits of aDE and aPSO. Also in haDEPSO individual population is merged with other in a pre-defined manner, to balance between global and local search capability. The algorithms efficiency is verified through 23 basic, 30 CEC 2014 and 30 CEC 2017 test suite and comparing the results with various state-of-the-art algorithms. The numerical, statistical and graphical analysis shows the effectiveness of these algorithms in terms of accuracy and convergence speed. Finally, three real world problems have been solved to confirm problem-solving capability of proposed algorithms. All these analyses confirm the superiority of the proposed algorithms over the compared algorithms.},
  archive      = {J_AIR},
  author       = {Parouha, Raghav Prasad and Verma, Pooja},
  doi          = {10.1007/s10462-021-09962-6},
  journal      = {Artificial Intelligence Review},
  number       = {8},
  pages        = {5931-6010},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Design and applications of an advanced hybrid meta-heuristic algorithm for optimization problems},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Study of automatic text summarization approaches in
different languages. <em>AIR</em>, <em>54</em>(8), 5897–5929. (<a
href="https://doi.org/10.1007/s10462-021-09964-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays we see huge amount of information is available on both, online and offline sources. For single topic we see hundreds of articles are available, containing vast amount of information about it. It is really a difficult task to manually extract the useful information from them. To solve this problem, automatic text summarization systems are developed. Text summarization is a process of extracting useful information from large documents and compressing them into short summary preserving all important content. This survey paper hand out a broad overview on the work done in the field of automatic text summarization in different languages using various text summarization approaches. The focal centre of this survey paper is to present the research done on text summarization on Indian languages such as, Hindi, Punjabi, Bengali, Malayalam, Kannada, Tamil, Marathi, Assamese, Konkani, Nepali, Odia, Sanskrit, Sindhi, Telugu and Gujarati and foreign languages such as Arabic, Chinese, Greek, Persian, Turkish, Spanish, Czeh, Rome, Urdu, Indonesia Bhasha and many more. This paper provides the knowledge and useful support to the beginner scientists in this research area by giving a concise view on various feature extraction methods and classification techniques required for different types of text summarization approaches applied on both Indian and non-Indian languages.},
  archive      = {J_AIR},
  author       = {Kumar, Yogesh and Kaur, Komalpreet and Kaur, Sukhpreet},
  doi          = {10.1007/s10462-021-09964-4},
  journal      = {Artificial Intelligence Review},
  number       = {8},
  pages        = {5897-5929},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Study of automatic text summarization approaches in different languages},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A survey on information hiding using video steganography.
<em>AIR</em>, <em>54</em>(8), 5831–5895. (<a
href="https://doi.org/10.1007/s10462-021-09968-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the last few decades, information security has gained huge importance owing to the massive growth in digital communication; hence, driving steganography to the forefront for secure communication. Steganography is a practice of concealing information or message in covert communication which involves hiding the information in any multimedia file such as text, image, or video. Many contributions have been made in the domain of image steganography; however, due to the low embedding capacity and robustness of images; videos are gaining more attention of academic researchers. This paper aims to provide a qualitative as well as quantitative analysis of various video steganography techniques by highlighting their properties, challenges, pros, and cons. Moreover, different quality metrics for the evaluation of distinct steganography techniques have also been discussed. The paper also provides an overview of steganalysis attacks which are commonly employed to test the security of the steganography techniques. The experimental analysis of some of the prominent techniques using different quality metrics has also been done. This paper also presented a critical analysis driven from the literature and the experimental results. The primary objective of this paper is to help the beginners to understand the basic concepts of this research domain to initiate their research in this field. Further, the paper highlighted the real-life applications of video steganography and also suggested some future directions which require the attention of the research community.},
  archive      = {J_AIR},
  author       = {Dalal, Mukesh and Juneja, Mamta},
  doi          = {10.1007/s10462-021-09968-0},
  journal      = {Artificial Intelligence Review},
  number       = {8},
  pages        = {5831-5895},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A survey on information hiding using video steganography},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Transformer models for text-based emotion detection: A
review of BERT-based approaches. <em>AIR</em>, <em>54</em>(8),
5789–5829. (<a
href="https://doi.org/10.1007/s10462-021-09958-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We cannot overemphasize the essence of contextual information in most natural language processing (NLP) applications. The extraction of context yields significant improvements in many NLP tasks, including emotion recognition from texts. The paper discusses transformer-based models for NLP tasks. It highlights the pros and cons of the identified models. The models discussed include the Generative Pre-training (GPT) and its variants, Transformer-XL, Cross-lingual Language Models (XLM), and the Bidirectional Encoder Representations from Transformers (BERT). Considering BERT’s strength and popularity in text-based emotion detection, the paper discusses recent works in which researchers proposed various BERT-based models. The survey presents its contributions, results, limitations, and datasets used. We have also provided future research directions to encourage research in text-based emotion detection using these models.},
  archive      = {J_AIR},
  author       = {Acheampong, Francisca Adoma and Nunoo-Mensah, Henry and Chen, Wenyu},
  doi          = {10.1007/s10462-021-09958-2},
  journal      = {Artificial Intelligence Review},
  number       = {8},
  pages        = {5789-5829},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Transformer models for text-based emotion detection: A review of BERT-based approaches},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-focus image fusion techniques: A survey. <em>AIR</em>,
<em>54</em>(8), 5735–5787. (<a
href="https://doi.org/10.1007/s10462-021-09961-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-Focus Image Fusion (MFIF) is a method that combines two or more source images to obtain a single image which is focused, has improved quality and more information than the source images. Due to limited Depth-of-Field of the imagining system, extracting all the useful information from a single image is challenging. Thus two or more defocused source images are fused together to obtain a composite image. This paper provides a comprehensive overview of existing MFIF methods. A new classification scheme is developed for categorizing the existing MFIF methods. These methods are classified into four major categories: spatial domain, transform domain, deep leaning and their hybrids and have been discussed well along with their drawbacks and challenges. In addition to this, both the parametric evaluation metrics i.e. &quot;with reference&quot; and &quot;without reference&quot; have also discussed. Then, a comparative analysis for nine image fusion methods is performed based on 30 pairs of publicly available images. Finally, various challenges that remain unaddressed and future work is also discussed in this work.},
  archive      = {J_AIR},
  author       = {Bhat, Shiveta and Koundal, Deepika},
  doi          = {10.1007/s10462-021-09961-7},
  journal      = {Artificial Intelligence Review},
  number       = {8},
  pages        = {5735-5787},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Multi-focus image fusion techniques: A survey},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A novel hybrid assessment model to evaluate e-services
websites of iranian municipalities. <em>AIR</em>, <em>54</em>(8),
5699–5733. (<a
href="https://doi.org/10.1007/s10462-021-09956-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Since municipalities are an essential part of urban management and are considered as the most important hub for offering urban services, they are expected to develop e-services rapidly and offer high-quality services to citizens. As the websites are the main infrastructure of e-services, therefore constant assessment of the websites assists to provide high-quality services. In this paper, a model was proposed for assessing the e-services websites of municipalities. Firstly, the most effective assessment indices and indicators were extracted from previous studies such as website design, responsiveness quality, security, content and information quality, citizen participation, trust, supporting and maintenance, services and usability including 73 indicators. The indices and indicators were assigned weight and raked using Analytical Hierarchy Process and PROMETHEE methods respectively. Owing to existed ambiguity in some of the extracted indices, fuzzy sets theory was applied to model existed uncertainty in the problem. Finally, the proposed model was used for evaluating the e-services websites of 10 Iranian metropolitan municipalities. Final results showed that Qom and Kermanshah cities received the highest and lowest readiness of e-services websites respectively.},
  archive      = {J_AIR},
  author       = {Shayganmehr, Masoud and Montazer, Gholam Ali},
  doi          = {10.1007/s10462-021-09956-4},
  journal      = {Artificial Intelligence Review},
  number       = {8},
  pages        = {5699-5733},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A novel hybrid assessment model to evaluate e-services websites of iranian municipalities},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Decision-making model for china’s stock market bubble
warning: The CoCoSo with picture fuzzy information. <em>AIR</em>,
<em>54</em>(8), 5675–5697. (<a
href="https://doi.org/10.1007/s10462-021-09954-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the financial liberalization and globalization, China’s financial system has been deepening, the scale of the stock market has been expanding, and the stock market bubble problem has gradually emerged. The overinflated stock market bubble will undoubtedly increase the risk of the stock market, seriously threaten the stability of the financial system, and even bring disastrous consequences to the economic system. Therefore, the stock market bubble warning evaluation is very important. In the case of considering stock market bubble warning evaluation, the fundamental issues involve strong fuzziness. Picture fuzzy set, depicted by three memberships (positive membership, neutral membership and negative membership), is a more resultful means for capturing fuzziness. In this paper, the novel picture fuzzy score function is given for dealing the comparison problem. Then, the objective weights are calculated by Renyi entropy method. Meanwhile, we develop combined weights, which can reflect both subjective preference and objective preference. Moreover, the picture fuzzy decision making algorithm based on Combined Compromise Solution is presented. Finally, the feasibility of algorithm is stated by the stock market bubble warning evaluation issue. The salient features of the proposed algorithm are that they have no counter-intuitive cases and antilogarithm or division by zero issues.},
  archive      = {J_AIR},
  author       = {Peng, Xindong and Luo, Zhigang},
  doi          = {10.1007/s10462-021-09954-6},
  journal      = {Artificial Intelligence Review},
  number       = {8},
  pages        = {5675-5697},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Decision-making model for china’s stock market bubble warning: The CoCoSo with picture fuzzy information},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Application of deep learning algorithms in geotechnical
engineering: A short critical review. <em>AIR</em>, <em>54</em>(8),
5633–5673. (<a
href="https://doi.org/10.1007/s10462-021-09967-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the advent of big data era, deep learning (DL) has become an essential research subject in the field of artificial intelligence (AI). DL algorithms are characterized with powerful feature learning and expression capabilities compared with the traditional machine learning (ML) methods, which attracts worldwide researchers from different fields to its increasingly wide applications. Furthermore, in the field of geochnical engineering, DL has been widely adopted in various research topics, a comprehensive review summarizing its application is desirable. Consequently, this study presented the state of practice of DL in geotechnical engineering, and depicted the statistical trend of the published papers. Four major algorithms, including feedforward neural (FNN), recurrent neural network (RNN), convolutional neural network (CNN) and generative adversarial network (GAN) along with their geotechnical applications were elaborated. In addition, a thorough summary containing pubilished literatures, the corresponding reference cases, the adopted DL algorithms as well as the related geotechnical topics was compiled. Furthermore, the challenges and perspectives of future development of DL in geotechnical engineering were presented and discussed.},
  archive      = {J_AIR},
  author       = {Zhang, Wengang and Li, Hongrui and Li, Yongqin and Liu, Hanlong and Chen, Yumin and Ding, Xuanming},
  doi          = {10.1007/s10462-021-09967-1},
  journal      = {Artificial Intelligence Review},
  number       = {8},
  pages        = {5633-5673},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Application of deep learning algorithms in geotechnical engineering: A short critical review},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Comparison between SSA and SSO algorithm inspired in the
behavior of the social spider for constrained optimization.
<em>AIR</em>, <em>54</em>(7), 5583–5631. (<a
href="https://doi.org/10.1007/s10462-021-10035-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The heuristic algorithms are often used to find solutions to real complex world problems. In this paper, the Social Spider Algorithm (SSA) and Social Spider Optimization (SSO) which are heuristic algorithms created upon spider behaviors are considered. Performances of both algorithms are compared with each other from six different items. These are; fitness values of spider population which are obtained in different dimensions, number of candidate solution obtained in each iteration, the best value of candidate solutions obtained in each iteration, the worst value of candidate solutions obtained in each iteration, average fitness value of candidate solutions obtained in each iteration and running time of each iteration. Obtained results of SSA and SSO are applied to the Wilcoxon signed-rank test. Various unimodal, multimodal, and hybrid standard benchmark functions are studied to compare each other with the performance of SSO and SSA. Using these benchmark functions, performances of SSO and SSA are compared with well-known evolutionary and recently developed methods in the literature. Obtained results show that both heuristic algorithms have advantages to another from different aspects. Also, according to other algorithms have good performance.},
  archive      = {J_AIR},
  author       = {Baş, Emine and Ülker, Erkan},
  doi          = {10.1007/s10462-021-10035-x},
  journal      = {Artificial Intelligence Review},
  number       = {7},
  pages        = {5583-5631},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Comparison between SSA and SSO algorithm inspired in the behavior of the social spider for constrained optimization},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Parameter reduction analysis under interval-valued m-polar
fuzzy soft information. <em>AIR</em>, <em>54</em>(7), 5541–5582. (<a
href="https://doi.org/10.1007/s10462-021-10027-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper formalizes a novel model that is able to use both interval representations, parameterizations, partial memberships and multi-polarity. These are differing modalities of uncertain knowledge that are supported by many models in the literature. The new structure that embraces all these features simultaneously is called interval-valued multi-polar fuzzy soft set (IVmFSS, for short). An enhanced combination of interval-valued m-polar fuzzy (IVmF) sets and soft sets produces this model. As such, the theory of IVmFSSs constitutes both an interval-valued multipolar-fuzzy generalization of soft set theory; a multipolar generalization of interval-valued fuzzy soft set theory; and an interval-valued generalization of multi-polar fuzzy set theory. Some fundamental operations for IVmFSSs, including intersection, union, complement, “OR”, “AND”, are explored and investigated through examples. An algorithm is developed to solve decision-making problems having data in interval-valued m-polar fuzzy soft form. It is applied to two numerical examples. In addition, three parameter reduction approaches and their algorithmic formulation are proposed for IVmFSSs. They are respectively called parameter reduction based on optimal choice, rank based parameter reduction, and normal parameter reduction. Moreover, these outcomes are compared with existing interval-valued fuzzy methods; relatedly, a comparative analysis among reduction approaches is investigated. Two real case studies for the selection of best site for an airport construction and best rotavator are studied.},
  archive      = {J_AIR},
  author       = {Akram, Muhammad and Ali, Ghous and Alcantud, José Carlos R.},
  doi          = {10.1007/s10462-021-10027-x},
  journal      = {Artificial Intelligence Review},
  number       = {7},
  pages        = {5541-5582},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Parameter reduction analysis under interval-valued m-polar fuzzy soft information},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A comprehensive survey of sine cosine algorithm: Variants
and applications. <em>AIR</em>, <em>54</em>(7), 5469–5540. (<a
href="https://doi.org/10.1007/s10462-021-10026-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sine Cosine Algorithm (SCA) is a recent meta-heuristic algorithm inspired by the proprieties of trigonometric sine and cosine functions. Since its introduction by Mirjalili in 2016, SCA has attracted great attention from researchers and has been widely used to solve different optimization problems in several fields. This attention is due to its reasonable execution time, good convergence acceleration rate, and high efficiency compared to several well-regarded optimization algorithms available in the literature. This paper presents a brief overview of the basic SCA and its variants divided into modified, multi-objective, and hybridized versions. Furthermore, the applications of SCA in several domains such as classification, image processing, robot path planning, scheduling, radial distribution networks, and other engineering problems are described. Finally, the paper recommended some potential future research directions for SCA.},
  archive      = {J_AIR},
  author       = {Gabis, Asma Benmessaoud and Meraihi, Yassine and Mirjalili, Seyedali and Ramdane-Cherif, Amar},
  doi          = {10.1007/s10462-021-10026-y},
  journal      = {Artificial Intelligence Review},
  number       = {7},
  pages        = {5469-5540},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A comprehensive survey of sine cosine algorithm: Variants and applications},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Underwater image enhancement: A comprehensive review, recent
trends, challenges and applications. <em>AIR</em>, <em>54</em>(7),
5413–5467. (<a
href="https://doi.org/10.1007/s10462-021-10025-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The mysteries of deep-sea ecosystems can be unlocked to reveal new sources, for developing medical drugs, food and energy resources, and products of renewable energy. Research in the area of underwater image processing has increased significantly in the last decade. This is primarily due to the dependence of human beings on the valuable resources existing underwater. Effective work of exploring the underwater environment is achievable by having excellent methods for underwater image enhancement. The work presented in this article highlights the survey of underwater image enhancement algorithms. This work presents an overview of various underwater image enhancement techniques and their broad classifications. The methods under each classification are briefly discussed. Underwater datasets required for performing experiments are summarized from the available literature. Attention is also drawn towards various evaluation metrics required for the quantitative assessment of underwater images and recent areas of application in the domain.},
  archive      = {J_AIR},
  author       = {Raveendran, Smitha and Patil, Mukesh D. and Birajdar, Gajanan K.},
  doi          = {10.1007/s10462-021-10025-z},
  journal      = {Artificial Intelligence Review},
  number       = {7},
  pages        = {5413-5467},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Underwater image enhancement: A comprehensive review, recent trends, challenges and applications},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Evaluating logic gate constraints in local search for
structured satisfiability problems. <em>AIR</em>, <em>54</em>(7),
5347–5411. (<a
href="https://doi.org/10.1007/s10462-021-10024-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conjunctive normal forms (CNF) of structured satisfiability problems contain logic gate patterns. So Boolean circuits (BC) by and large can be obtained from them and thus structural information that is lost in the CNF can be recovered. However, it is not known which logic gates are useful for local search on BCs or which logic gates in particular help local search the most and why. In this article, we empirically show that exploitation of xor, xnor, eq, and not gates is a key factor behind the performance of local search algorithms using single variable flips when adapted to logic gate constraints. Moreover, controlled experiments and investigations into the variables selected for flipping further elucidates these findings. To achieve these conclusions, we have adapted the AdaptNovelty+ and CCANr algorithms to cope with logic gate-based constraint models. These are two prominent families of local search algorithms for satisfiability. We performed our experiments using a large set of benchmark instances from SATLib, SAT2014, and SAT2020. We have also presented techniques to eliminate cycles among logic gates that are detected from CNF and to propagate equivalence of variables statically through the logic gate dependency relationships.},
  archive      = {J_AIR},
  author       = {Newton, M. A. H. and Polash, M. M. A. and Pham, D. N. and Thornton, J. and Su, K. and Sattar, A.},
  doi          = {10.1007/s10462-021-10024-0},
  journal      = {Artificial Intelligence Review},
  number       = {7},
  pages        = {5347-5411},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Evaluating logic gate constraints in local search for structured satisfiability problems},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Six application scenarios of artificial intelligence in the
precise diagnosis and treatment of liver cancer. <em>AIR</em>,
<em>54</em>(7), 5307–5346. (<a
href="https://doi.org/10.1007/s10462-021-10023-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The establishment of the precision diagnosis and treatment system and the advent of the digital intelligence era have not only deepened people&#39;s understanding of liver cancer but also continuously improved the diagnosis and treatment methods of liver cancer. Cutting-edge computer technology represented by artificial intelligence (AI) has been used in the prediction, screening, diagnosis, treatment, and rehabilitation of liver cancer. The rise of AI has given new vitality to liver surgery, as well as individualized treatment experience and greater healing opportunities for patients. We focus on summarizing the latest applications and developments of AI in liver cancer diagnosis and treatment from six aspects: virtual assistants, medical imaging diagnosis, adjuvant therapy, risk and treatment response prediction, drug development and testing, and postoperative rehabilitation management. Especially in the two major aspects of medical imaging diagnosis and adjuvant therapy, the development and achievements of AI are gratifying. Finally, we put forward a view on the current challenges of AI in the precise diagnosis and treatment of liver cancer and how to promote its development, and we have a prospect for the future development direction.},
  archive      = {J_AIR},
  author       = {Lang, Qi and Zhong, Chongli and Liang, Zhiyun and Zhang, Yizhou and Wu, Baokang and Xu, Feng and Cong, Ling and Wu, Shuodong and Tian, Yu},
  doi          = {10.1007/s10462-021-10023-1},
  journal      = {Artificial Intelligence Review},
  number       = {7},
  pages        = {5307-5346},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Six application scenarios of artificial intelligence in the precise diagnosis and treatment of liver cancer},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A review and experimental analysis of active learning over
crowdsourced data. <em>AIR</em>, <em>54</em>(7), 5283–5305. (<a
href="https://doi.org/10.1007/s10462-021-10021-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Training data creation is increasingly a key bottleneck for developing machine learning, especially for deep learning systems. Active learning provides a cost-effective means for creating training data by selecting the most informative instances for labeling. Labels in real applications are often collected from crowdsourcing, which engages online crowds for data labeling at scale. Despite the importance of using crowdsourced data in the active learning process, an analysis of how the existing active learning approaches behave over crowdsourced data is currently missing. This paper aims to fill this gap by reviewing the existing active learning approaches and then testing a set of benchmarking ones on crowdsourced datasets. We provide a comprehensive and systematic survey of the recent research on active learning in the hybrid human–machine classification setting, where crowd workers contribute labels (often noisy) to either directly classify data instances or to train machine learning models. We identify three categories of state of the art active learning methods according to whether and how predefined queries employed for data sampling, namely fixed-strategy approaches, dynamic-strategy approaches, and strategy-free approaches. We then conduct an empirical study on their cost-effectiveness, showing that the performance of the existing active learning approaches is affected by many factors in hybrid classification contexts, such as the noise level of data, label fusion technique used, and the specific characteristics of the task. Finally, we discuss challenges and identify potential directions to design active learning strategies for hybrid classification problems.},
  archive      = {J_AIR},
  author       = {Sayin, Burcu and Krivosheev, Evgeny and Yang, Jie and Passerini, Andrea and Casati, Fabio},
  doi          = {10.1007/s10462-021-10021-3},
  journal      = {Artificial Intelligence Review},
  number       = {7},
  pages        = {5283-5305},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A review and experimental analysis of active learning over crowdsourced data},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Balanced picture fuzzy graph with application. <em>AIR</em>,
<em>54</em>(7), 5255–5281. (<a
href="https://doi.org/10.1007/s10462-021-10020-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Picture fuzzy graphs are an extension of intuitionistic fuzzy graphs. Balanced picture fuzzy graph is a special type of picture fuzzy graph (PFG). In this study, the definition and important properties of PFG like, average PFG, balanced PFG, size, order, density of a PFG, isomorphism, the direct product of two PFG, etc have been studied. The necessary and sufficient conditions for balanced picture fuzzy graphs have also been studied in this article. Beside this, we proposed an algorithm to test whether a PFG is balanced or not. The proof of correctness and an illustration of the proposed algorithm is presented in this article. Lastly, an application of balanced PFG to business alliance is presented.},
  archive      = {J_AIR},
  author       = {Amanathulla, Sk and Bera, Biswajit and Pal, Madhumangal},
  doi          = {10.1007/s10462-021-10020-4},
  journal      = {Artificial Intelligence Review},
  number       = {7},
  pages        = {5255-5281},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Balanced picture fuzzy graph with application},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A review of deep learning used in the hyperspectral image
analysis for agriculture. <em>AIR</em>, <em>54</em>(7), 5205–5253. (<a
href="https://doi.org/10.1007/s10462-021-10018-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hyperspectral imaging is a non-destructive, nonpolluting, and fast technology, which can capture up to several hundred images of different wavelengths and offer relevant spectral signatures. Hyperspectral imaging technology has achieved breakthroughs in the acquisition of agricultural information and the detection of external or internal quality attributes of the agricultural product. Deep learning techniques have boosted the performance of hyperspectral image analysis. Compared with traditional machine learning, deep learning architectures exploit both spatial and spectral information of hyperspectral image analysis. To scrutinize thoroughly the current efforts, provide insights, and identify potential research directions on deep learning for hyperspectral image analysis in agriculture, this paper presents a systematic and comprehensive review. Firstly, its applications in agriculture are summarized, include ripeness and component prediction, different classification themes, and plant disease detection. Then, the recent achievements are reviewed in hyperspectral image analysis from the aspects of the deep learning models and the feature networks. Finally, the existing challenges of hyperspectral image analysis based on deep learning are summarized and the prospects of future works are put forward.},
  archive      = {J_AIR},
  author       = {Wang, Chunying and Liu, Baohua and Liu, Lipeng and Zhu, Yanjun and Hou, Jialin and Liu, Ping and Li, Xiang},
  doi          = {10.1007/s10462-021-10018-y},
  journal      = {Artificial Intelligence Review},
  number       = {7},
  pages        = {5205-5253},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A review of deep learning used in the hyperspectral image analysis for agriculture},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Improved q-rung orthopair fuzzy line integral aggregation
operators and their applications for multiple attribute decision making.
<em>AIR</em>, <em>54</em>(7), 5163–5204. (<a
href="https://doi.org/10.1007/s10462-021-10017-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The q-rung orthopair fuzzy line integral (q-ROFLI) operator is a potent mathematical tool to aggregate non-standard fuzzy information in the process of Decision Making. To overcome some disadvantages of the q-rung orthopair fuzzy integral curves (q-ROFICs) which was proposed by Gao et al. (IEEE Trans Cybern, https://doi.org/10.1109/TCYB.2019.290865 , 2019), in this paper, we present a novel definition of q-ROFICs. Based on this notion, we give a completed definition for q-ROFLI. Furthermore, we give a Newton–Leibniz formula through the q-rung orthopair fuzzy function with the variable upper limit (VUL-q-ROFF), and investigate the intermediate value theorem which can be utilized to solve generalized mean value theorem. Moreover, we propose the q-rung orthopair fuzzy line integral aggregation (q-ROFLIA) operator, and an improved q-ROFLIA with reliability (R-q-ROFLIA) operator. As their applications, we give several examples to show the process for aggregating q-rung orthopair fuzzy data by these operators. At last, the validity and flexibility of the above operators are verified through a practical example, especially the superiority of R-q-ROFLIA can avoid losing important extreme data, and make the results more suitable for the practical Decision Making.},
  archive      = {J_AIR},
  author       = {Shao, Yabin and Zhuo, Junle},
  doi          = {10.1007/s10462-021-10017-z},
  journal      = {Artificial Intelligence Review},
  number       = {7},
  pages        = {5163-5204},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Improved q-rung orthopair fuzzy line integral aggregation operators and their applications for multiple attribute decision making},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Matrix games with linguistic intuitionistic fuzzy payoffs:
Basic results and solution methods. <em>AIR</em>, <em>54</em>(7),
5127–5162. (<a
href="https://doi.org/10.1007/s10462-021-10014-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Game theory has found successful applications in different areas to handle competitive situations among different persons or organizations. Several extensions of ordinary game theory have been studied by the researchers to accommodate the uncertainty and vagueness in terms of payoffs and goals. Matrix games with payoffs represented by interval numbers, fuzzy numbers, and intuitionistic fuzzy numbers have considered only the quantitative aspects of the problems. But in many situations, qualitative information plays a crucial role in representing the payoffs of a game problem. This work presents a valuable study on matrix games with payoff represented by linguistic intuitionistic fuzzy numbers (LIFNs). First, the paper defines some new operational-laws for LIFNs based on linguistic scale function (LSF) and studies their properties in detail. Next, we define a new aggregation operator called ‘generalized linguistic intuitionistic fuzzy weighted average (GLIFWA)’operator for aggregating LIFNs. Several properties and special cases of GLIFWA operator are also discussed. The LSF provides an ability to consider the different semantic situations in a single formulation during the aggregation process. Further, the paper introduces some basic results of matrix games with payoffs represented by LIFNs. We develop solution methods using a pair of auxiliary linear/nonlinear-programming models derived from a pair of nonlinear bi-objective programming models. Finally, a real-life numerical example is considered to demonstrate the validity and applicability of the developed methods.},
  archive      = {J_AIR},
  author       = {Verma, Rajkumar and Aggarwal, Abha},
  doi          = {10.1007/s10462-021-10014-2},
  journal      = {Artificial Intelligence Review},
  number       = {7},
  pages        = {5127-5162},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Matrix games with linguistic intuitionistic fuzzy payoffs: Basic results and solution methods},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An in-ad contents-based viewability prediction framework
using artificial intelligence for web ads. <em>AIR</em>, <em>54</em>(7),
5095–5125. (<a
href="https://doi.org/10.1007/s10462-021-10013-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the current competitive corporate world, organizations rely on their products’ advertisements for surpassing competitors in reaching out to a larger pool of customers. This forces companies to focus on advertisement quality. This work presents a content-based advertisement viewability prediction framework using Artificial Intelligence (AI) methods. The primary focus here is on the web-advertisements available on various online shopping websites. Most of the past work in this domain emphasizes on the scroll depth and dwell time of an ad. However, the features that directly influence the viewability of an ad have been overlooked in the past. Unlike other approaches, this work considers multiple in-ad features that directly influence its viewability. Some of these include color, urgency, language, offers, discount, type, and prominent gender. This work presents an AI-based framework for identifying the features attributing towards increased viewability of ads. Feature selection techniques are executed on the dataset to extract important attributes. Afterward, clustering is applied to confirm the number of class labels assigned to the instances. To validate the clustering results, three validation indices are used here, namely Davies Bouldin Index, Dunn Index, and Silhouette Coefficient. Five classifiers, i.e., Support Vector Machine, k- Nearest Neighbors, Artificial Neural Network, Random Forest, and Gradient Regression Boosting Trees are trained using multiple features and viewability of an ad is predicted. The obtained results confirm that various in-content ad features, i.e., gender, type, discount, layout, and crowdedness play a vital role in predicting an ad’s viewability.},
  archive      = {J_AIR},
  author       = {Asad, Muhammad and Halim, Zahid and Waqas, Muhammad and Tu, Shanshan},
  doi          = {10.1007/s10462-021-10013-3},
  journal      = {Artificial Intelligence Review},
  number       = {7},
  pages        = {5095-5125},
  shortjournal = {Artif. Intell. Rev.},
  title        = {An in-ad contents-based viewability prediction framework using artificial intelligence for web ads},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Adaptive constraint propagation in constraint satisfaction:
Review and evaluation. <em>AIR</em>, <em>54</em>(7), 5055–5093. (<a
href="https://doi.org/10.1007/s10462-021-10012-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Several methods for dynamically adapting the local consistency property applied by a CP solver during search have been put forward in recent and older literature. We propose the classification of such methods in three categories depending on the level of granularity where decisions about which local consistency property to apply are taken: node, variable, and value oriented. We then present a detailed review of existing methods from each category, and evaluate them theoretically according to several criteria. Taking one recent representative method from each class, we then perform an experimental study. Results show that simple variable and value oriented methods are quite efficient when the older dom/ddeg heuristic is used for variable ordering, while a carefully tuned node oriented method does not seem to offer notable improvement compared to standard arc consistency propagation. In contrast, under the more realistic setting of dom/wdeg, the variable and value oriented methods cannot compete with standard propagation, while the node oriented method is very efficient. Finally, we obtain a new adaptive propagation method by integrating the variable and value oriented approaches and adding an amount of randomization The resulting method is simple, competitive, and almost parameter-free.},
  archive      = {J_AIR},
  author       = {Stergiou, Kostas},
  doi          = {10.1007/s10462-021-10012-4},
  journal      = {Artificial Intelligence Review},
  number       = {7},
  pages        = {5055-5093},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Adaptive constraint propagation in constraint satisfaction: Review and evaluation},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Systematic reviews in sentiment analysis: A tertiary study.
<em>AIR</em>, <em>54</em>(7), 4997–5053. (<a
href="https://doi.org/10.1007/s10462-021-09973-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With advanced digitalisation, we can observe a massive increase of user-generated content on the web that provides opinions of people on different subjects. Sentiment analysis is the computational study of analysing people&#39;s feelings and opinions for an entity. The field of sentiment analysis has been the topic of extensive research in the past decades. In this paper, we present the results of a tertiary study, which aims to investigate the current state of the research in this field by synthesizing the results of published secondary studies (i.e., systematic literature review and systematic mapping study) on sentiment analysis. This tertiary study follows the guidelines of systematic literature reviews (SLR) and covers only secondary studies. The outcome of this tertiary study provides a comprehensive overview of the key topics and the different approaches for a variety of tasks in sentiment analysis. Different features, algorithms, and datasets used in sentiment analysis models are mapped. Challenges and open problems are identified that can help to identify points that require research efforts in sentiment analysis. In addition to the tertiary study, we also identified recent 112 deep learning-based sentiment analysis papers and categorized them based on the applied deep learning algorithms. According to this analysis, LSTM and CNN algorithms are the most used deep learning algorithms for sentiment analysis.},
  archive      = {J_AIR},
  author       = {Ligthart, Alexander and Catal, Cagatay and Tekinerdogan, Bedir},
  doi          = {10.1007/s10462-021-09973-3},
  journal      = {Artificial Intelligence Review},
  number       = {7},
  pages        = {4997-5053},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Systematic reviews in sentiment analysis: A tertiary study},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Bee-inspired metaheuristics for global optimization: A
performance comparison. <em>AIR</em>, <em>54</em>(7), 4967–4996. (<a
href="https://doi.org/10.1007/s10462-021-10015-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Metaheuristics are widely applied to solve optimization problems. Numerous metaheuristic algorithms inspired by natural processes have been introduced in the past years. Studying and comparing the convergence of metaheuristics is helpful in future algorithmic development and applications. This study focuses on bee-inspired metaheuristics and identifies seven basic or root algorithms applied to solve continuous optimization problems. They are the bee system, mating bee optimization (MBO), bee colony optimization, bee evolution for genetic algorithms (BEGA), bee algorithm, artificial bee colony (ABC), and bee swarm optimization. The algorithms’ performances are evaluated with several benchmark problems. This study’s results rank the cited algorithms according to their convergence efficiency. The strengths and shortcomings of each algorithm are discussed. The ABC, BEGA, and MBO are the most efficient algorithms. This study’s results show the convergence rate among different algorithms varies, and evaluates the causes of such variation.},
  archive      = {J_AIR},
  author       = {Solgi, Ryan and Loáiciga, Hugo A.},
  doi          = {10.1007/s10462-021-10015-1},
  journal      = {Artificial Intelligence Review},
  number       = {7},
  pages        = {4967-4996},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Bee-inspired metaheuristics for global optimization: A performance comparison},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Over a decade of social opinion mining: A systematic review.
<em>AIR</em>, <em>54</em>(7), 4873–4965. (<a
href="https://doi.org/10.1007/s10462-021-10030-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Social media popularity and importance is on the increase due to people using it for various types of social interaction across multiple channels. This systematic review focuses on the evolving research area of Social Opinion Mining, tasked with the identification of multiple opinion dimensions, such as subjectivity, sentiment polarity, emotion, affect, sarcasm and irony, from user-generated content represented across multiple social media platforms and in various media formats, like text, image, video and audio. Through Social Opinion Mining, natural language can be understood in terms of the different opinion dimensions, as expressed by humans. This contributes towards the evolution of Artificial Intelligence which in turn helps the advancement of several real-world use cases, such as customer service and decision making. A thorough systematic review was carried out on Social Opinion Mining research which totals 485 published studies and spans a period of twelve years between 2007 and 2018. The in-depth analysis focuses on the social media platforms, techniques, social datasets, language, modality, tools and technologies, and other aspects derived. Social Opinion Mining can be utilised in many application areas, ranging from marketing, advertising and sales for product/service management, and in multiple domains and industries, such as politics, technology, finance, healthcare, sports and government. The latest developments in Social Opinion Mining beyond 2018 are also presented together with future research directions, with the aim of leaving a wider academic and societal impact in several real-world applications.},
  archive      = {J_AIR},
  author       = {Cortis, Keith and Davis, Brian},
  doi          = {10.1007/s10462-021-10030-2},
  journal      = {Artificial Intelligence Review},
  number       = {7},
  pages        = {4873-4965},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Over a decade of social opinion mining: A systematic review},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Deep learning for alzheimer prediction using brain
biomarkers. <em>AIR</em>, <em>54</em>(7), 4827–4871. (<a
href="https://doi.org/10.1007/s10462-021-10016-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Alzheimer disease is a neurodegenerative brain disorder leading to gradual loss of memory. Multiple biomarkers have been accepted for identifying the Alzheimer’s disease namely Neuroimaging, Cerebrospinal fluid proteins, blood and urine tests, genetic risk profilers. In this study, an extensive review has been done for Alzheimer disease prediction using diverse brain-imaging biomarkers through varied deep learning frameworks. A closer look revealed that taking into account multiple modalities of neuroimaging biomarkers always lead to better prediction accuracy for multi-class classification of Alzheimer disease. The paper further discusses about multiple open areas that need to be drilled down for establishing a model that can be accepted by medical community for Alzheimer prediction. This review work explores the different dimensions of neuroanatomical approach on which different deep learning frameworks that can be applied since the performance of designed model using 3-D subject-level, 3-D ROI-based and 3-D patch-level approaches varies. There is a need of extensive analysis for suitability of these methods for particular type of model.},
  archive      = {J_AIR},
  author       = {Goenka, Nitika and Tiwari, Shamik},
  doi          = {10.1007/s10462-021-10016-0},
  journal      = {Artificial Intelligence Review},
  number       = {7},
  pages        = {4827-4871},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Deep learning for alzheimer prediction using brain biomarkers},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Study on modeling implicit learning based on MAM framework.
<em>AIR</em>, <em>54</em>(6), 4799–4825. (<a
href="https://doi.org/10.1007/s10462-021-10019-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Implicit Learning (IL) involves the fundamental problem of human potential development, and it has been a hot and difficult topic for many years. Traditional artificial neural networks can simulate IL, but there are some shortcomings. A few years ago, people used a morphological neural network (MNN) to simulate IL, but the support in theory and practice is weak. The contribution of this study is threefold. Firstly, based on the theory of unified framework of morphological associative memories (UFMAM), this paper makes a deep exploration for simulating IL by MNNs. Since both MNN and UFMAM are based on strict mathematical morphology, the research is established on a solid theoretical basis. Secondly, three experiments were designed, and the results were analyzed and discussed according to the theory of UFMAM. Thus, the depth and breadth of this research of IL were further expanded, new simulation methods and research examples were provided, and the MNN model of IL was established. Thirdly, it provides an example for the coordinated development of artificial neural networks, artificial intelligence, cognitive psychology, neural science and brain science. The research shows that the IL model based on MNN is superior to the traditional IL model in automation, comprehension, abstraction and anti-interference. Therefore, it will play an important role in the future study of IL and bring new inspiration to reveal the neural mechanism of IL. There is an inseparable relationship between MNN and IL, i.e. the former provides new research tools and means for the latter, while the latter provides psychological and neuroscientific supports for the former, which will make both of them have a more solid scientific foundation. It is reasonable to believe that computer simulation of IL and other cognitive phenomena will have an important impact on promoting the coordinated development of multidisciplinary.},
  archive      = {J_AIR},
  author       = {Feng, Naiqin and Geng, Xiuqin and Sun, Bin},
  doi          = {10.1007/s10462-021-10019-x},
  journal      = {Artificial Intelligence Review},
  number       = {6},
  pages        = {4799-4825},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Study on modeling implicit learning based on MAM framework},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). How to tune the RBF SVM hyperparameters? An empirical
evaluation of 18 search algorithms. <em>AIR</em>, <em>54</em>(6),
4771–4797. (<a
href="https://doi.org/10.1007/s10462-021-10011-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {SVM with an RBF kernel is usually one of the best classification algorithms for most data sets, but it is important to tune the two hyperparameters C and $$\gamma $$ to the data itself. In general, the selection of the hyperparameters is a non-convex optimization problem and thus many algorithms have been proposed to solve it, among them: grid search, random search, Bayesian optimization, simulated annealing, particle swarm optimization, Nelder Mead, and others. There have also been proposals to decouple the selection of $$\gamma $$ and C. We empirically compare 18 of these proposed search algorithms (with different parameterizations for a total of 47 combinations) on 115 real-life binary data sets. We find (among other things) that trees of Parzen estimators and particle swarm optimization select better hyperparameters with only a slight increase in computation time with respect to a grid search with the same number of evaluations. We also find that spending too much computational effort searching the hyperparameters will not likely result in better performance for future data and that there are no significant differences among the different procedures to select the best set of hyperparameters when more than one is found by the search algorithms.},
  archive      = {J_AIR},
  author       = {Wainer, Jacques and Fonseca, Pablo},
  doi          = {10.1007/s10462-021-10011-5},
  journal      = {Artificial Intelligence Review},
  number       = {6},
  pages        = {4771-4797},
  shortjournal = {Artif. Intell. Rev.},
  title        = {How to tune the RBF SVM hyperparameters? an empirical evaluation of 18 search algorithms},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A survey on different dimensions for graphical keyword
extraction techniques. <em>AIR</em>, <em>54</em>(6), 4731–4770. (<a
href="https://doi.org/10.1007/s10462-021-10010-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The transmission from offline activities to online activities due to the social disorder evolved from COVID-19 pandemic lockdown has led to increase in the online economic and social activities. In this regard, the Automatic Keyword Extraction (AKE) from textual data has become even more interesting due to its application over different domains of Natural Language Processing (NLP). It is observed that the Graphical Keyword Extraction Techniques (GKET) use Graph of Words (GoW) in literature for analysis in different dimensions. In this article, efforts have been made to study these different dimensions for GKET, namely, the GoW representation, the statistical properties of GoW, the stability of the structure of GoW, the diversity in approaches over GoW for GKET, and the ranking of nodes in GoW. To elucidate these different dimensions, a comprehensive survey of GKET is carried in different domains to make some inferences out of the existing literature. These inferences are used to lay down possible research directions for interdisciplinary studies of network science and NLP. In addition, the experimental results are analysed to compare and contrast the existing GKET over 21 different dataset, to analyse the Word Co-occurrence Networks (WCN) for 15 different languages, and to study the structure of WCN for different genres. In this article, some strong correspondences in different disciplinary approaches are identified for different dimensions, namely, GoW representation: ’Line Graphs’ and ’Bigram Words Graphs’; Feature extraction and selection using eigenvalues: ’Random Walk’ and ’Spectral Clustering’. Different observations over the need to integrate multiple dimensions has open new research directions in the inter-disciplinary field of network science and NLP, applicable to handle streaming data and language-independent NLP.},
  archive      = {J_AIR},
  author       = {Garg, Muskan},
  doi          = {10.1007/s10462-021-10010-6},
  journal      = {Artificial Intelligence Review},
  number       = {6},
  pages        = {4731-4770},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A survey on different dimensions for graphical keyword extraction techniques},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Automatic selection of heavy-tailed distributions-based
synergy henry gas solubility and harris hawk optimizer for feature
selection: Case study drug design and discovery. <em>AIR</em>,
<em>54</em>(6), 4685–4730. (<a
href="https://doi.org/10.1007/s10462-021-10009-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Features Selection (FS) approaches have more attention since they have been applied to several fields primarily to deal with high dimensional data. An increase in the dimension of data can lead to degradation of the accuracy of the machine learning method. Therefore, there are several FS methods based on meta-heuristic (MH) techniques that have been developed to tackle the FS problem and avoid the limitations of traditional FS approaches. However, those MH methods still need improvements that suffer from some drawbacks that affect the quality of the final output. So, this paper proposed a modified Henry Gas Solubility Optimization (HGSO) using enhanced Harris hawks optimization (HHO) based on Heavy-tailed distributions (HTDs). In this study, a dynamical exchange between five HTDs is used to boost the HHO that modifies, in turn, the exploitation phase in HGSO. As a result, we proposed a dynamic modified HGSO based on enhanced HHO (DHGHHD). To assess the efficiency of the proposed DHGHHD, a set of eighteen UCI datasets are used. Furthermore, it applied to improve the prediction of two real-world datasets in the drug design and discovery field. The DHGHHD is compared with eight well-known MH methods. Comparison results illustrate the high quality of DHGHHD according to the values of accuracy, fitness value, and the number of selected features.},
  archive      = {J_AIR},
  author       = {Abd Elaziz, Mohamed and Yousri, Dalia},
  doi          = {10.1007/s10462-021-10009-z},
  journal      = {Artificial Intelligence Review},
  number       = {6},
  pages        = {4685-4730},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Automatic selection of heavy-tailed distributions-based synergy henry gas solubility and harris hawk optimizer for feature selection: Case study drug design and discovery},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A hybrid data envelopment analysis—artificial neural network
prediction model for COVID-19 severity in transplant recipients.
<em>AIR</em>, <em>54</em>(6), 4653–4684. (<a
href="https://doi.org/10.1007/s10462-021-10008-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In an overwhelming demand scenario, such as the SARS-CoV-2 pandemic, pressure over health systems may outburst their predicted capacity to deal with such extreme situations. Therefore, in order to successfully face a health emergency, scientific evidence and validated models are needed to provide real-time information that could be applied by any health center, especially for high-risk populations, such as transplant recipients. We have developed a hybrid prediction model whose accuracy relative to several alternative configurations has been validated through a battery of clustering techniques. Using hospital admission data from a cohort of hospitalized transplant patients, our hybrid Data Envelopment Analysis (DEA)—Artificial Neural Network (ANN) model extrapolates the progression towards severe COVID-19 disease with an accuracy of 96.3\%, outperforming any competing model, such as logistic regression (65.5\%) and random forest (44.8\%). In this regard, DEA-ANN allows us to categorize the evolution of patients through the values of the analyses performed at hospital admission. Our prediction model may help guiding COVID-19 management through the identification of key predictors that permit a sustainable management of resources in a patient-centered model.},
  archive      = {J_AIR},
  author       = {Revuelta, Ignacio and Santos-Arteaga, Francisco J. and Montagud-Marrahi, Enrique and Ventura-Aguiar, Pedro and Di Caprio, Debora and Cofan, Frederic and Cucchiari, David and Torregrosa, Vicens and Piñeiro, Gaston Julio and Esforzado, Nuria and Bodro, Marta and Ugalde-Altamirano, Jessica and Moreno, Asuncion and Campistol, Josep M. and Alcaraz, Antonio and Bayès, Beatriu and Poch, Esteban and Oppenheimer, Federico and Diekmann, Fritz},
  doi          = {10.1007/s10462-021-10008-0},
  journal      = {Artificial Intelligence Review},
  number       = {6},
  pages        = {4653-4684},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A hybrid data envelopment analysis—artificial neural network prediction model for COVID-19 severity in transplant recipients},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Reliability assessment of water quality index based on
guidelines of national sanitation foundation in natural streams:
Integration of remote sensing and data-driven models. <em>AIR</em>,
<em>54</em>(6), 4619–4651. (<a
href="https://doi.org/10.1007/s10462-021-10007-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rivers, as one of the freshwater resources, are generally put in the state of jeopardy in terms of quantity and quality due to the development in industry, agriculture, and urbanization. Management of water quality is inextricably bound up with a reliable prediction of the Water Quality Index (WQI) for various purposes. In this way, an accurate estimation of WQI is one of the most challenging issues in the water quality studies of surface water resources. There is a board range of traditional methodologies for the WQI evaluation. Due to the intrinsic limitations of conventional models, Data-Driven Models (DDMs) have been frequently employed to assess the WQI for natural streams. In the present research, WQI values and their typical classifications were obtained by guidelines of the National Sanitation Foundation (NSF). Hence, four well-known DDMs such as Evolutionary Polynomial Regression (EPR), M5 Model Tree (MT), Gene-Expression Programming (GEP), and Multivariate Adaptive Regression Spline (MARS) are employed to predict WQI in Karun River. In this way, 12 Water Quality Parameters (i.e., Dissolved Oxygen, Chemical Oxygen Demand, Biochemical Oxygen Demand, Electrical Conductivity, Nitrate, Nitrite, Phosphate, Turbidity, pH, Calcium, Magnesium, and Sodium) were accumulated from nine hydrometry stations and additionally missing values of water temperature were extracted from images analysis of Landsat-7 ETM+. Furthermore, the Gamma Test (GT), Forward Selection (FS), Polynomial Chaotic Expression (PCE), and Principle Component Analysis (PCA) were used to reduce the volume of DDMs-feeding-input variables. Results of DDMs demonstrated that FS-M5 MT had the best performance for the estimation of WQI classification. WQI values for Karun River were assessed in the reliability-based probabilistic framework to consider the effect of any uncertainty and randomness in the input parameters. To this end, the Monte-Carlo scenario sampling technique was conducted to evaluate the limit state function from the DDMs-based-WQI formulation. Based on the qualitative description of the WQI, it was observed that the WQI of Karun River is classified into “Relatively Bad” quality. Moreover, based on the reliability analysis, there is only a 19\% chance exists for a specimen from Karun River to have a better quality index.},
  archive      = {J_AIR},
  author       = {Najafzadeh, Mohammad and Homaei, Farshad and Farhadi, Hadi},
  doi          = {10.1007/s10462-021-10007-1},
  journal      = {Artificial Intelligence Review},
  number       = {6},
  pages        = {4619-4651},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Reliability assessment of water quality index based on guidelines of national sanitation foundation in natural streams: Integration of remote sensing and data-driven models},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Application of an improved discrete crow search algorithm
with local search and elitism on a humanitarian relief case.
<em>AIR</em>, <em>54</em>(6), 4591–4617. (<a
href="https://doi.org/10.1007/s10462-021-10006-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper demonstrates an application of the improved crow search algorithm (I-CSA), which is a modified version of the crow search algorithm (CSA). CSA is a recent, nature-inspired meta-heuristic optimization algorithm. I-CSA differs from CSA by allowing application on a discrete problem, which is P-median and fortifying faster convergence to an optimal or near-optimal solution. Improvements are provided by local searches which support escaping from local optima or convergence to the optimal solution, elitism enhances the intensification through the utilization of nodes by selecting the most frequent centers that appeared in hiding better locations for local search, on the P-median problem. The application of the I-CSA is structured in three phases. In the first phase, parameters of I-CSA are analyzed and optimized using well-known data tests. The test datasets for the application of I-CSA on the P-median problem were retrieved from the OR-library to present the effectiveness and applicability of I-CSA. In the second phase, 40-pmed test problems from the library are solved using I-CSA and the results are compared with known optimal results and recorded results of other meta-heuristic approaches. In addition, Wilcoxon signed-rank test is applied in order to demonstrate the performance of I-CSA compared to well-known algorithms. The results of the proposed method demonstrated a faster convergence rate and better solution in most cases when compared with the standard CSA and other well-known meta-heuristic approaches. Finally, the proposed I-CSA approach is tested on a real-life case problem including 2121 nodes in Tunceli, Turkey. Obtaining the optimal results in a reasonable time indicates that the potential of the I-CSA is high and promising. In nutshell, this paper presents an improvement to CSA and evaluates its performance in a three-phase test procedure.},
  archive      = {J_AIR},
  author       = {Eligüzel, İbrahim Miraç and Özceylan, Eren},
  doi          = {10.1007/s10462-021-10006-2},
  journal      = {Artificial Intelligence Review},
  number       = {6},
  pages        = {4591-4617},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Application of an improved discrete crow search algorithm with local search and elitism on a humanitarian relief case},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Approximate reasoning with fuzzy rule interpolation:
Background and recent advances. <em>AIR</em>, <em>54</em>(6), 4543–4590.
(<a href="https://doi.org/10.1007/s10462-021-10005-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Approximate reasoning systems facilitate fuzzy inference through activating fuzzy if–then rules in which attribute values are imprecisely described. Fuzzy rule interpolation (FRI) supports such reasoning with sparse rule bases where certain observations may not match any existing fuzzy rules, through manipulation of rules that bear similarity with an unmatched observation. This differs from classical rule-based inference that requires direct pattern matching between observations and the given rules. FRI techniques have been continuously investigated for decades, resulting in various types of approach. Traditionally, it is typically assumed that all antecedent attributes in the rules are of equal significance in deriving the consequents. Recent studies have shown significant interest in developing enhanced FRI mechanisms where the rule antecedent attributes are associated with relative weights, signifying their different importance levels in influencing the generation of the conclusion, thereby improving the interpolation performance. This survey presents a systematic review of both traditional and recently developed FRI methodologies, categorised accordingly into two major groups: FRI with non-weighted rules and FRI with weighted rules. It introduces, and analyses, a range of commonly used representatives chosen from each of the two categories, offering a comprehensive tutorial for this important soft computing approach to rule-based inference. A comparative analysis of different FRI techniques is provided both within each category and between the two, highlighting the main strengths and limitations while applying such FRI mechanisms to different problems. Furthermore, commonly adopted criteria for FRI algorithm evaluation are outlined, and recent developments on weighted FRI methods are presented in a unified pseudo-code form, easing their understanding and facilitating their comparisons.},
  archive      = {J_AIR},
  author       = {Li, Fangyi and Shang, Changjing and Li, Ying and Yang, Jing and Shen, Qiang},
  doi          = {10.1007/s10462-021-10005-3},
  journal      = {Artificial Intelligence Review},
  number       = {6},
  pages        = {4543-4590},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Approximate reasoning with fuzzy rule interpolation: Background and recent advances},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A survey of deep meta-learning. <em>AIR</em>,
<em>54</em>(6), 4483–4541. (<a
href="https://doi.org/10.1007/s10462-021-10004-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neural networks can achieve great successes when presented with large data sets and sufficient computational resources. However, their ability to learn new concepts quickly is limited. Meta-learning is one approach to address this issue, by enabling the network to learn how to learn. The field of Deep Meta-Learning advances at great speed, but lacks a unified, in-depth overview of current techniques. With this work, we aim to bridge this gap. After providing the reader with a theoretical foundation, we investigate and summarize key methods, which are categorized into (i) metric-, (ii) model-, and (iii) optimization-based techniques. In addition, we identify the main open challenges, such as performance evaluations on heterogeneous benchmarks, and reduction of the computational costs of meta-learning.},
  archive      = {J_AIR},
  author       = {Huisman, Mike and van Rijn, Jan N. and Plaat, Aske},
  doi          = {10.1007/s10462-021-10004-4},
  journal      = {Artificial Intelligence Review},
  number       = {6},
  pages        = {4483-4541},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A survey of deep meta-learning},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An integrated rough ELECTRE II approach for risk evaluation
and effects analysis in automatic manufacturing process. <em>AIR</em>,
<em>54</em>(6), 4449–4481. (<a
href="https://doi.org/10.1007/s10462-021-10003-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Smart manufacturing is an essential part of fourth industrial revolution in which robotic machines can control and perceive automatically to provide effectiveness and convenience in production process. However, the existence of potential failures and defects not only influence the manufacturing process but also damages the resources and cause negative impacts on environment. Failure modes and effects analysis (FMEA) is a key approach to identify and eliminate possible failures and evaluate the risks from design, system and process. This research paper provides a novel FMEA approach for risk evaluation by integrating rough set theory and ELimination and Choice Translating REality (ELECTRE) II method to handle the subjectivity and uncertainty in experts’ judgements without much prior information, membership functions and additional adjustments. Rough numbers are used to study uncertainty in linguistic terms using intervals instead of single fixed values. The proposed approach is formulated by defining different types of concordance and discordance sets using optimization techniques based on statistical dispersion and maximum deviation method. The presented technique shows the strong, weak and neutral pairwise relations among failure modes by systemically comparing them from each risk component. The distance functions and averaging methods are applied to check the similarities and differences among error modes which improves the accuracy of the results. The developed rough FMEA approach is applied to identify the potential failures of robot working in optical cable industry and evaluate the risk components of manufacturing and production process. Rough ELECTRE II approach can be effectively applied to enhance the efficiency of working conditions and prevent the loss of crude materials and energy.},
  archive      = {J_AIR},
  author       = {Sarwar, Musavarah and Akram, Muhammad and Liu, Peide},
  doi          = {10.1007/s10462-021-10003-5},
  journal      = {Artificial Intelligence Review},
  number       = {6},
  pages        = {4449-4481},
  shortjournal = {Artif. Intell. Rev.},
  title        = {An integrated rough ELECTRE II approach for risk evaluation and effects analysis in automatic manufacturing process},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Sine trigonometric operational laws and its based
pythagorean fuzzy aggregation operators for group decision-making
process. <em>AIR</em>, <em>54</em>(6), 4421–4447. (<a
href="https://doi.org/10.1007/s10462-021-10002-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paper aims are to impersonate some robust sine-trigonometric operations laws to determine the group decision-making process under the Pythagorean fuzzy set (PFS) situation. The PFS has a notable feature to trade with the dubious information with a broader membership representation space than the intuitionistic fuzzy set. Based on it, the present paper is classified into three phases. The first phase is to introduce new operational laws for PFS. The main idea behind these proposed operations is to incorporate the qualities of the sine function, namely periodicity and symmetric about the origin towards the decisions of the objects. Secondly, based on these laws, numerous operators to aggregate the information are acquired along with their requisite properties and relations. Finally, an algorithm to interpret the multiattribute group decision making problem is outlined based on the stated operators and manifest it with an illustrative example. A detailed comparative interpretation is achieved with some of the existing methods to reveal their influences.},
  archive      = {J_AIR},
  author       = {Garg, Harish},
  doi          = {10.1007/s10462-021-10002-6},
  journal      = {Artificial Intelligence Review},
  number       = {6},
  pages        = {4421-4447},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Sine trigonometric operational laws and its based pythagorean fuzzy aggregation operators for group decision-making process},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Facial asymmetry-based feature extraction for different
applications: A review complemented by new advances. <em>AIR</em>,
<em>54</em>(6), 4379–4419. (<a
href="https://doi.org/10.1007/s10462-021-10001-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Facial feature extraction (FFE) is considered as a challenging area for computer vision and artificial intelligence research community. There are numerous application domains of face recognition such as demographic classification and facial disease classification. In last few years, numerous feature extraction approaches are proposed. This review focuses on studies that exclusively use facial asymmetry as one of the main subject-specific facial characteristics for FFE. This paper provides a review about the related research conducted in the past two decades. First, we summarize the conventional FFE approaches and their main algorithms. Application of deep networks to facial asymmetry based FFE approaches is then presented. Multi-network deep models suitable for asymmetry-based FFE for different applications are also focused in this review. We presented the details about the publicly available face datasets, evaluation metrics, and comparison of the state-of-the-art results is also presented. The directions of asymmetry-based FFE for future research is also presented to provide an awareness about the existing and future trends. This review is presented to provide directions and ideas for future research in the field of facial asymmetry.},
  archive      = {J_AIR},
  author       = {Sajid, Muhammad and Ali, Nouman and Ratyal, Naeem Iqbal and Dar, Saadat Hanif and Zafar, Bushra},
  doi          = {10.1007/s10462-021-10001-7},
  journal      = {Artificial Intelligence Review},
  number       = {6},
  pages        = {4379-4419},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Facial asymmetry-based feature extraction for different applications: A review complemented by new advances},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Text detection and localization in scene images: A broad
review. <em>AIR</em>, <em>54</em>(6), 4317–4377. (<a
href="https://doi.org/10.1007/s10462-021-10000-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, text detection and localization have gained much popularity in the field of text analysis systems as they pave the way for the number of real-time based applications like mobile transliteration technologies, assistive methods for visually impaired persons, etc. Text detection and localization techniques are used to find the position of text area in the image.This paper intends to present a broad review in this field as five-fold: (1) comparison of document images with scene images and applications of natural scene images, (2) significant and up-to-date traditional machine learning and deep learning-based approaches for the text detection and localization for different languages, (3) various publicly available benchmarked datasets, (4) comparative analysis for other benchmarked datasets and, (5) related challenges and future scope on the field. The paper summarises some of the potential ways in this field, which can serve as a useful reference for the researchers for future exploration of the area.},
  archive      = {J_AIR},
  author       = {Mahajan, Shilpa and Rani, Rajneesh},
  doi          = {10.1007/s10462-021-10000-8},
  journal      = {Artificial Intelligence Review},
  number       = {6},
  pages        = {4317-4377},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Text detection and localization in scene images: A broad review},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Metaheuristics: A comprehensive overview and classification
along with bibliometric analysis. <em>AIR</em>, <em>54</em>(6),
4237–4316. (<a
href="https://doi.org/10.1007/s10462-020-09952-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Research in metaheuristics for global optimization problems are currently experiencing an overload of wide range of available metaheuristic-based solution approaches. Since the commencement of the first set of classical metaheuristic algorithms namely genetic, particle swarm optimization, ant colony optimization, simulated annealing and tabu search in the early 70s to late 90s, several new advancements have been recorded with an exponential growth in the novel proposals of new generation metaheuristic algorithms. Because these algorithms are neither entirely judged based on their performance values nor according to the useful insight they may provide, but rather the attention is given to the novelty of the processes they purportedly models, these area of study will continue to periodically see the arrival of several new similar techniques in the future. However, there is an obvious reason to keep track of the progressions of these algorithms by collating their general algorithmic profiles in terms of design inspirational source, classification based on swarm or evolutionary search concept, existing variation from the original design, and application areas. In this paper, we present a relatively new taxonomic classification list of both classical and new generation sets of metaheuristic algorithms available in the literature, with the aim of providing an easily accessible collection of popular optimization tools for the global optimization research community who are at the forefront in utilizing these tools for solving complex and difficult real-world problems. Furthermore, we also examined the bibliometric analysis of this field of metaheuristic for the last 30 years.},
  archive      = {J_AIR},
  author       = {Ezugwu, Absalom E. and Shukla, Amit K. and Nath, Rahul and Akinyelu, Andronicus A. and Agushaka, Jeffery O. and Chiroma, Haruna and Muhuri, Pranab K.},
  doi          = {10.1007/s10462-020-09952-0},
  journal      = {Artificial Intelligence Review},
  number       = {6},
  pages        = {4237-4316},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Metaheuristics: A comprehensive overview and classification along with bibliometric analysis},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Biological computation and computational biology: Survey,
challenges, and discussion. <em>AIR</em>, <em>54</em>(6), 4169–4235. (<a
href="https://doi.org/10.1007/s10462-020-09951-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Biological computation involves the design and development of computational techniques inspired by natural biota. On the other hand, computational biology involves the development and application of computational techniques to study biological systems. We present a comprehensive review showcasing how biology and computer science can guide and benefit each other, resulting in improved understanding of biological processes and at the same time advances in the design of algorithms. Unfortunately, integration between biology and computer science is often challenging, especially due to the cultural idiosyncrasies of these two communities. In this study, we aim at highlighting how nature has inspired the development of various algorithms and techniques in computer science, and how computational techniques and mathematical modeling have helped to better understand various fields in biology. We identified existing gaps between biological computation and computational biology and advocate for bridging this gap between “wet” and “dry” research.},
  archive      = {J_AIR},
  author       = {Chelly Dagdia, Zaineb and Avdeyev, Pavel and Bayzid, Md. Shamsuzzoha},
  doi          = {10.1007/s10462-020-09951-1},
  journal      = {Artificial Intelligence Review},
  number       = {6},
  pages        = {4169-4235},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Biological computation and computational biology: Survey, challenges, and discussion},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Probabilistic linguistic multiple attribute group decision
making for location planning of electric vehicle charging stations based
on the generalized dice similarity measures. <em>AIR</em>,
<em>54</em>(6), 4137–4167. (<a
href="https://doi.org/10.1007/s10462-020-09950-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The location of the electric vehicle charging station is deemed to be a multiple attribute group decision making (MAGDM) issue involving many experts and many conflicting attributes. In practical MAGDM issues, the information of uncertain and fuzzy cognitive decision is well-depicted by linguistic term sets (LTSs). These LTSs could be simply shifted into the probabilistic linguistic sets (PLTSs). In such paper, we design some novel probabilistic linguistic weighted Dice similarity measures (PLWDSM) and the probabilistic linguistic weighted generalized Dice similarity measures (PLWGDSM). Subsequently, the PLWGDSM-based MAGDM methods are presented under PLTSs. In the end, a practical case which concerns about the location planning of electric vehicle charging stations is offered to demonstrate the proposed PLWGDSM’s applicability and advantages.},
  archive      = {J_AIR},
  author       = {Wei, Guiwu and Wei, Cun and Wu, Jiang and Guo, Yanfeng},
  doi          = {10.1007/s10462-020-09950-2},
  journal      = {Artificial Intelligence Review},
  number       = {6},
  pages        = {4137-4167},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Probabilistic linguistic multiple attribute group decision making for location planning of electric vehicle charging stations based on the generalized dice similarity measures},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Grammar-based automatic programming for medical data
classification: An experimental study. <em>AIR</em>, <em>54</em>(6),
4097–4135. (<a
href="https://doi.org/10.1007/s10462-020-09949-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In a computational medical model, diagnosis is the classification of disease status in the terms of abnormal or positive, normal or negative or intermediate stages. Different Machine learning techniques such as artificial neural networks (ANNs) are extensively and successfully used in disease diagnosis. However, there is no single classifier that can solve all classification problems. Selecting an optimal classifier for a problem is difficult, and it has become a relevant subject in the area. This paper focuses on grammar-based automatic programming (GAP) to build optimized discriminant functions for medical data classification in any arbitrary language. These techniques have an implicit power of automatic feature selection and feature extraction. This work carries out an in-depth investigation of the use of different GAP algorithms in the medical data classification problem. The objective is to identify the benefits and limitations of algorithms of this nature in the current problem. Classical classifiers were also considered for comparison purposes. Fourteen medical data sets were used in the experiments, and seven performance measures such as accuracy, sensitivity, specificity, precision, geometric-mean, F-measure, and false-positive rate are used to evaluate the performance of the produced classifier. The multiple criteria decision analysis (MCDA) demonstrates that GAP approaches are able to produce suitable classifiers for a given problem, and the GS performs better than other classical classifiers in medical data classification.},
  archive      = {J_AIR},
  author       = {Si, Tapas and Miranda, Péricles and Galdino, João Victor and Nascimento, André},
  doi          = {10.1007/s10462-020-09949-9},
  journal      = {Artificial Intelligence Review},
  number       = {6},
  pages        = {4097-4135},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Grammar-based automatic programming for medical data classification: An experimental study},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A new interval type-2 trapezoid fuzzy multi-attribute group
decision-making method and its application to the evaluation of sponge
city construction. <em>AIR</em>, <em>54</em>(6), 4063–4096. (<a
href="https://doi.org/10.1007/s10462-021-10022-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The concept of sponge city receives more and more attention by Chinese government, and the evaluation of sponge city construction is an important aspect. To cope with the complexity and uncertainty of the evaluation process, this paper adopts interval type-2 trapezoidal fuzzy numbers (IT2TFNs) to express decision-making information and develops an approach for evaluating sponge city construction. To do these, two prioritized-guided interval type-2 trapezoidal fuzzy Hamacher operators are first defined to infuse IT2TFNs offered by experts, which can cope with the situation where there is prioritization among experts/attributes. In order to further consider the interactions among experts/attributes, two generalized-Shapley interval type-2 trapezoidal fuzzy prioritized Hamacher Choquet integral operators are presented. To measure the discrimination degree between IT2TFNs, a new interval type-2 trapezoidal fuzzy cross-entropy is defined. After that, cross-entropy based models for obtaining the optimal fuzzy measure on the expert/attribute set are constructed to handle the situation where the weighting information is interactive and partly known. Furthermore, an interval type-2 trapezoidal fuzzy multi-attribute group decision-making approach is developed. Finally, a practical example about the evaluation of residential land design plans in sponge city is provided to illustrate the utilization of the new method, and comparison analysis is provided.},
  archive      = {J_AIR},
  author       = {Meng, Fanyong and Li, Shutian and Tang, Jie},
  doi          = {10.1007/s10462-021-10022-2},
  journal      = {Artificial Intelligence Review},
  number       = {6},
  pages        = {4063-4096},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A new interval type-2 trapezoid fuzzy multi-attribute group decision-making method and its application to the evaluation of sponge city construction},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Artificial intelligence-based techniques for analysis of
body cavity fluids: A review. <em>AIR</em>, <em>54</em>(6), 4019–4061.
(<a href="https://doi.org/10.1007/s10462-020-09946-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper tends to present a systematic review of the applications of Artificial Intelligence (AI) in the field of medical diagnosis vis-a-vis fluid cytology. The study is based on the research articles published in various reputed international and national journals and the conference proceedings from 1990 to till date. AI-based systems are becoming useful as alternative approaches to conventional techniques and are also becoming integral components of many diagnostic systems. Artificial intelligence is being increasingly used to solve complex practical problems in various areas and is becoming more and more popular nowadays. The use of AI for tackling various problems in medical science has diversified significantly during this period. It emerges as a dominant technique for addressing various difficult research problems. This paper follows the trend and evolution of application-based research during the last three decades. It also presents a technical comparison of novel methodologies developed by the researchers to deal with diagnostic problems in the analysis of body cavity fluids. Abnormalities in body cavity fluids lead to various serious disorders like meningitis, subarachnoid hemorrhage, CNS malignancy, demyelinating disease, heart failure, pulmonary embolism, cirrhosis, pneumonia, pleurisy, and pericarditis, arthritis, joint Infection and joint hemorrhage. Moreover, the paper includes recent research articles published during 2018 and 2019 to present the recent progress in this domain.},
  archive      = {J_AIR},
  author       = {Mir, Aftab Ahmad and Sarwar, Abid},
  doi          = {10.1007/s10462-020-09946-y},
  journal      = {Artificial Intelligence Review},
  number       = {6},
  pages        = {4019-4061},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Artificial intelligence-based techniques for analysis of body cavity fluids: A review},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A possibilistic approach for interval type-2 fuzzy
linguistic summarization of time series. <em>AIR</em>, <em>54</em>(5),
3991–4018. (<a
href="https://doi.org/10.1007/s10462-020-09945-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Linguistic summarization with fuzzy sets, extracting explicit and concise knowledge from data, has received a great attention because of its compatibility with human cognitive mechanism. The most crucial step in linguistic summarization is certainly the evaluation of linguistic summaries. In this study, a new fuzzy cardinality based possibilistic approach is proposed for evaluating linguistic summaries in interval type-2 fuzzy environment. It is proved that the proposed possibilistic approach satisfies the desired properties defined in the literature. An application of the proposed possibilistic approach is presented on financial time series including the three stocks in Borsa İstanbul (BIST) covering the period for the last 10 years. It is noticed that the proposed possibilistic approach generates more stable results than the probabilistic approach of Boran and Akay (IEEE Trans Cybern 44:1632–1645, 2014).},
  archive      = {J_AIR},
  author       = {Özdoğan, İlyas and Boran, Fatih Emre and Akay, Diyar},
  doi          = {10.1007/s10462-020-09945-z},
  journal      = {Artificial Intelligence Review},
  number       = {5},
  pages        = {3991-4018},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A possibilistic approach for interval type-2 fuzzy linguistic summarization of time series},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A quantum-based sine cosine algorithm for solving general
systems of nonlinear equations. <em>AIR</em>, <em>54</em>(5), 3939–3990.
(<a href="https://doi.org/10.1007/s10462-020-09944-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a quantum-based sine cosine algorithm, named as Q-SCA, is proposed for solving general systems of nonlinear equations. The Q-SCA hybridizes the sine cosine algorithm (SCA) with quantum local search (QLS) for enhancing the diversity of solutions and preventing local optima entrapment. The essence of the proposed Q-SCA is to speed up the optimum searching operation and to accelerate the convergence characteristic. The proposed Q-SCA works in twofold: firstly, an improved version of SCA based on tuning the search space around the destination solution dynamically, so that the search space is shrunken gradually as the optima are attained. In addition, a new mechanism to update the solutions is introduced using bidirectional equations. Secondly, QLS is incorporated to improve the quality of the obtained solutions by the SCA phase. By this methodology, the proposed Q-SCA can achieve high levels of exploration/exploitation and precise stable convergence to high-quality solutions. The performance of the proposed algorithm is assessed by adopting twelve systems of nonlinear equations and two electrical applications. Furthermore, the proposed Q-SCA algorithm is applied on expensive large-scale problems including CEC 2017 benchmark and realistic optimal power dispatch (OPD) to confirm its scalability. Experimental results affirm that the Q-SCA is performs steadily, and it has a promising overall performance among several compared algorithms.},
  archive      = {J_AIR},
  author       = {Rizk-Allah, Rizk M.},
  doi          = {10.1007/s10462-020-09944-0},
  journal      = {Artificial Intelligence Review},
  number       = {5},
  pages        = {3939-3990},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A quantum-based sine cosine algorithm for solving general systems of nonlinear equations},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Applications, databases and open computer vision research
from drone videos and images: A survey. <em>AIR</em>, <em>54</em>(5),
3887–3938. (<a
href="https://doi.org/10.1007/s10462-020-09943-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Analyzing videos and images captured by unmanned aerial vehicles or aerial drones is an emerging application attracting significant attention from researchers in various areas of computer vision. Currently, the major challenge is the development of autonomous operations to complete missions and replace human operators. In this paper, based on the type of analyzing videos and images captured by drones in computer vision, we have reviewed these applications by categorizing them into three groups. The first group is related to remote sensing with challenges such as camera calibration, image matching, and aerial triangulation. The second group is related to drone-autonomous navigation, in which computer vision methods are designed to explore challenges such as flight control, visual localization and mapping, and target tracking and obstacle detection. The third group is dedicated to using images and videos captured by drones in various applications, such as surveillance, agriculture and forestry, animal detection, disaster detection, and face recognition. Since most of the computer vision methods related to the three categories have been designed for real-world conditions, providing real conditions based on drones is impossible. We aim to explore papers that provide a database for these purposes. In the first two groups, some survey papers presented are current. However, the surveys have not been aimed at exploring any databases. This paper presents a complete review of databases in the first two groups and works that used the databases to apply their methods. Vision-based intelligent applications and their databases are explored in the third group, and we discuss open problems and avenues for future research.},
  archive      = {J_AIR},
  author       = {Akbari, Younes and Almaadeed, Noor and Al-maadeed, Somaya and Elharrouss, Omar},
  doi          = {10.1007/s10462-020-09943-1},
  journal      = {Artificial Intelligence Review},
  number       = {5},
  pages        = {3887-3938},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Applications, databases and open computer vision research from drone videos and images: A survey},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Artificial intelligence, cyber-threats and industry 4.0:
Challenges and opportunities. <em>AIR</em>, <em>54</em>(5), 3849–3886.
(<a href="https://doi.org/10.1007/s10462-020-09942-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This survey paper discusses opportunities and threats of using artificial intelligence (AI) technology in the manufacturing sector with consideration for offensive and defensive uses of such technology. It starts with an introduction of Industry 4.0 concept and an understanding of AI use in this context. Then provides elements of security principles and detection techniques applied to operational technology (OT) which forms the main attack surface of manufacturing systems. As some intrusion detection systems (IDS) already involve some AI-based techniques, we focus on existing machine-learning and data-mining based techniques in use for intrusion detection. This article presents the major strengths and weaknesses of the main techniques in use. We also discuss an assessment of their relevance for application to OT, from the manufacturer point of view. Another part of the paper introduces the essential drivers and principles of Industry 4.0, providing insights on the advent of AI in manufacturing systems as well as an understanding of the new set of challenges it implies. AI-based techniques for production monitoring, optimisation and control are proposed with insights on several application cases. The related technical, operational and security challenges are discussed and an understanding of the impact of such transition on current security practices is then provided in more details. The final part of the report further develops a vision of security challenges for Industry 4.0. It addresses aspects of orchestration of distributed detection techniques, introduces an approach to adversarial/robust AI development and concludes with human–machine behaviour monitoring requirements.},
  archive      = {J_AIR},
  author       = {Bécue, Adrien and Praça, Isabel and Gama, João},
  doi          = {10.1007/s10462-020-09942-2},
  journal      = {Artificial Intelligence Review},
  number       = {5},
  pages        = {3849-3886},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Artificial intelligence, cyber-threats and industry 4.0: Challenges and opportunities},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Implicit and hybrid methods for attribute weighting in
multi-attribute decision-making: A review study. <em>AIR</em>,
<em>54</em>(5), 3817–3847. (<a
href="https://doi.org/10.1007/s10462-020-09941-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Attribute weighting is a task of paramount relevance in multi-attribute decision-making (MADM). Over the years, different approaches have been developed to face this problem. Despite the effort of the community, there is a lack of consensus on which method is the most suitable one for a given problem instance. This paper is the second part of a two-part survey on attribute weighting methods in MADM scenarios. The first part introduced a categorization in five classes while focusing on explicit weighting methods. The current paper addresses implicit and hybrid approaches. A total of 20 methods are analyzed in order to identify their strengths and limitations. Toward the end, we discuss possible alternatives to address the detected drawbacks, thus paving the road for further research directions. The implicit weighting with additional information category resulted in the most coherent approach to give effective solutions. Consequently, we encourage the development of future methods with additional preference information.},
  archive      = {J_AIR},
  author       = {Pena, Julio and Nápoles, Gonzalo and Salgueiro, Yamisleydi},
  doi          = {10.1007/s10462-020-09941-3},
  journal      = {Artificial Intelligence Review},
  number       = {5},
  pages        = {3817-3847},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Implicit and hybrid methods for attribute weighting in multi-attribute decision-making: A review study},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). QoS-driven metaheuristic service composition schemes: A
comprehensive overview. <em>AIR</em>, <em>54</em>(5), 3749–3816. (<a
href="https://doi.org/10.1007/s10462-020-09940-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Services Oriented Architecture provides Web Services (WSs) as reusable software components that can be applied to create more complicate composite services for users according to the specified QoS limitations. However, considering many WSs that may be appropriate for each task of a user-submitted workflow, finding the optimal WSs for a composite WS to maximize the overall QoS is an NP-hard problem. As a result, numerous composition schemes have been suggested in the literature to untangle this problem by using various metaheuristic algorithms. This paper presents a comprehensive survey and taxonomy of such QoS-oriented metaheuristic WS composition schemes provided in the literature. It investigates how metaheuristic algorithms are adapted for the WS composition problem and highlight their main features, advantages, and limitations. Also, in each category of the studied composition schemes, a comparison of their applied QoS factors, evaluated metrics, exploited simulators, and properties of the applied metaheuristic algorithms are explained. Finally, the concluding remarks and future research directions are summarized to help researchers in working in this area.},
  archive      = {J_AIR},
  author       = {Masdari, Mohammad and Nozad Bonab, Mehdi and Ozdemir, Suat},
  doi          = {10.1007/s10462-020-09940-4},
  journal      = {Artificial Intelligence Review},
  number       = {5},
  pages        = {3749-3816},
  shortjournal = {Artif. Intell. Rev.},
  title        = {QoS-driven metaheuristic service composition schemes: A comprehensive overview},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Concept learning using one-class classifiers for implicit
drift detection in evolving data streams. <em>AIR</em>, <em>54</em>(5),
3725–3747. (<a
href="https://doi.org/10.1007/s10462-020-09939-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data stream mining has become an important research area over the past decade due to the increasing amount of data available today. Sources from various domains generate a near-limitless volume of data in temporal order. Such data are referred to as data streams, and are generally nonstationary as the characteristics of data evolves over time. This phenomenon is called concept drift, and is an issue of great importance in the literature, since it makes models obsolete by decreasing their predictive performance. In the presence of concept drift, it is necessary to adapt to change in data to build more robust and effective classifiers. Drift detectors are designed to run jointly with classification models, updating them when a significant change in data distribution is observed. In this paper, we present an implicit (unsupervised) algorithm called One-Class Drift Detector (OCDD), which uses a one-class learner with a sliding window to detect concept drift. We perform a comprehensive evaluation on mostly recent 17 prevalent concept drift detection methods and an adaptive classifier using 13 datasets. The results show that OCDD outperforms the other methods by producing models with better predictive performance on both real-world and synthetic datasets.},
  archive      = {J_AIR},
  author       = {Gözüaçık, Ömer and Can, Fazli},
  doi          = {10.1007/s10462-020-09939-x},
  journal      = {Artificial Intelligence Review},
  number       = {5},
  pages        = {3725-3747},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Concept learning using one-class classifiers for implicit drift detection in evolving data streams},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-criteria decision making approach based on SVTrN dombi
aggregation functions. <em>AIR</em>, <em>54</em>(5), 3685–3723. (<a
href="https://doi.org/10.1007/s10462-020-09936-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The neutrosophic set is constructed for modelling of situations specifically with incomplete, indeterminate and inconsistent information. In the study, Dombi operations have been introduced on two single-valued trapezoidal neutrosophic numbers (SVTrNNs). Here, Dombi operation on SVTrNNs, some new averaging and geometric averaging operators namely SVTrN Domi weighted averaging (SVTrNDWA) operator, SVTrN Dombi ordered weighted averaging (SVTrNDOWA) operator, SVTrN Dombi hybrid weighted averaging (SVTrNDHWA) operator, SVTrN Dombi weighted geometric (SVTrNDWGA) operator, SVTrN Dombi ordered weighted geometric (SVTrNDOWGA) operator and SVTrN Dombi hybrid weighted geometric (SVTrNDHWGA) operator have been proposed. Further, some properties of these operators such as idempotency, boundedness, monotonicity and commutativity have been investigated. Next, we have constructed a multi-criteria decision-making (MCDM) method in SVTrN environment based on SVTrNDWA and SVTrNDWGA operators. We have given an application of the present MCDM method for selecting the best contractor for a road construction company. We have also compared the current approach with the existing procedure and have given the sensitivity analysis of the proposed plan.},
  archive      = {J_AIR},
  author       = {Jana, Chiranjibe and Muhiuddin, G. and Pal, Madhumangal},
  doi          = {10.1007/s10462-020-09936-0},
  journal      = {Artificial Intelligence Review},
  number       = {5},
  pages        = {3685-3723},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Multi-criteria decision making approach based on SVTrN dombi aggregation functions},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Artificial intelligence techniques and their application in
oil and gas industry. <em>AIR</em>, <em>54</em>(5), 3665–3683. (<a
href="https://doi.org/10.1007/s10462-020-09935-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data are being continuously generated from various operational steps in the oil and gas industry. The recordings of these data and their proper utilization have become a major concern for the oil and gas industry. Decision making based on predictive as well as inferential data analytics helps in making accurate decisions within a short period of time. In spite of many challenges, the use of data analytics for decision making is increasing on a large-scale in the oil and gas industry. An appreciable amount of development has been done in the above area of research. Many complex problems may now be easily solved using Artificial Intelligence (AI) and Machine Learning (ML) techniques. Historical, as well as real-time data, can be assimilated to achieve higher production by gathering data from the gas/oil wells. Various analytical modeling techniques are now widely being used by the oil and gas sector to make a decision based on data analytics. This paper reviews the recent developments via applications of AI and ML techniques for efficient exploitation of the data obtained, starting from the exploration for crude oil to the distribution of its end products. A brief account of the acceptance and future of these techniques in the oil and gas industry is also discussed. Present work may provide a technical framework for choosing relevant technologies for effectively gaining the information from the large volume of data generated by the oil and gas industry.},
  archive      = {J_AIR},
  author       = {Choubey, Sachin and Karmakar, G. P.},
  doi          = {10.1007/s10462-020-09935-1},
  journal      = {Artificial Intelligence Review},
  number       = {5},
  pages        = {3665-3683},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Artificial intelligence techniques and their application in oil and gas industry},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A review on fault detection and diagnosis techniques: Basics
and beyond. <em>AIR</em>, <em>54</em>(5), 3639–3664. (<a
href="https://doi.org/10.1007/s10462-020-09934-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Safety and reliability are absolutely important for modern sophisticated systems and technologies. Therefore, malfunction monitoring capabilities are instilled in the system for detection of the incipient faults and anticipation of their impact on the future behavior of the system using fault diagnosis techniques. In particular, state-of-the-art applications rely on the quick and efficient treatment of malfunctions within the equipment/system, resulting in increased production and reduced downtimes. This paper presents developments within Fault Detection and Diagnosis (FDD) methods and reviews of research work in this area. The review presents both traditional model-based and relatively new signal processing-based FDD approaches, with a special consideration paid to artificial intelligence-based FDD methods. Typical steps involved in the design and development of automatic FDD system, including system knowledge representation, data-acquisition and signal processing, fault classification, and maintenance related decision actions, are systematically presented to outline the present status of FDD. Future research trends, challenges and prospective solutions are also highlighted.},
  archive      = {J_AIR},
  author       = {Abid, Anam and Khan, Muhammad Tahir and Iqbal, Javaid},
  doi          = {10.1007/s10462-020-09934-2},
  journal      = {Artificial Intelligence Review},
  number       = {5},
  pages        = {3639-3664},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A review on fault detection and diagnosis techniques: Basics and beyond},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An improved henry gas solubility optimization algorithm for
task scheduling in cloud computing. <em>AIR</em>, <em>54</em>(5),
3599–3637. (<a
href="https://doi.org/10.1007/s10462-020-09933-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In cloud computing, task scheduling plays a major role and the efficient schedule of tasks can increase the cloud system efficiency. To successfully meet the dynamic requirements of end-users’ applications, advanced scheduling techniques should be in place to ensure optimal mapping of tasks to cloud resources. In this paper, a modified Henry gas solubility optimization (HGSO) is presented which is based on the whale optimization algorithm (WOA) and a comprehensive opposition-based learning (COBL) for optimum task scheduling. The proposed method is named HGSWC. In the proposed HGSWC, WOA is utilized as a local search procedure in order to improve the quality of solutions, whereas COBL is employed to improve the worst solutions by computing their opposite solutions and then selecting the best among them. HGSWC is validated on a set of thirty-six optimization benchmark functions, and it is contrasted with conventional HGSO and WOA. The proposed HGSWC has been proved to perform better than the comparison algorithms. Moreover, the performance of HGSWC has also been tested on a set of synthetic and real workloads including fifteen different task scheduling problems. The results obtained through simulation experiments demonstrate that HGSWC finds near optimal solutions with no computational overhead as well as outperforms six well-known metaheuristic algorithms.},
  archive      = {J_AIR},
  author       = {Abd Elaziz, Mohamed and Attiya, Ibrahim},
  doi          = {10.1007/s10462-020-09933-3},
  journal      = {Artificial Intelligence Review},
  number       = {5},
  pages        = {3599-3637},
  shortjournal = {Artif. Intell. Rev.},
  title        = {An improved henry gas solubility optimization algorithm for task scheduling in cloud computing},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Bioacoustic signal denoising: A review. <em>AIR</em>,
<em>54</em>(5), 3575–3597. (<a
href="https://doi.org/10.1007/s10462-020-09932-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Animal biodiversity has been experiencing rapid decline due to various reasons such as habitat loss and degradation, invasive species, and environment pollution. Recent advances in acoustic sensors provide a novel way to monitor animals through investigating collected bioacoustic recordings. To accurately monitor animals, the precondition is the high performance of developed bioacoustic signal recognition model. However, since bioacoustic recordings are often obtained in an open environment, various sources of noise will affect the audio quality, which causes problems for automated analysis of animal sound recordings. Although various methods have been developed for addressing the noise in different bioacoustic recordings, to the best of our knowledge, there is still no paper that reviews and summarizes those methods. The main aim of this paper is to provide a systematic survey of the existing literature related to bioacoustic signal denoising. By investigating the existing denoising methods for bioacoustic recordings, current challenges, possible opportunities, and future research directions are discussed and concluded.},
  archive      = {J_AIR},
  author       = {Xie, Jie and Colonna, Juan G. and Zhang, Jinglan},
  doi          = {10.1007/s10462-020-09932-4},
  journal      = {Artificial Intelligence Review},
  number       = {5},
  pages        = {3575-3597},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Bioacoustic signal denoising: A review},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Improved social spider algorithm for large scale
optimization. <em>AIR</em>, <em>54</em>(5), 3539–3574. (<a
href="https://doi.org/10.1007/s10462-020-09931-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Heuristic algorithms can give optimal solutions for low, middle, and large scale optimization problems in an acceptable time. The social spider algorithm (SSA) is one of the recent meta-heuristic algorithms that imitate the behaviors of the spider to perform global optimization. The original study of this algorithm was proposed to solve low scale continuous problems, and it is not be solved to middle and large scale continuous problems. In this paper, we have improved the SSA and have solved middle and large scale continuous problems, too. By adding two new techniques to the original SSA, the performance of the original SSA has been improved and it is named as an improved SSA (ISSA). In this paper, various unimodal and multimodal standard benchmark functions for low, middle, and large-scale optimization are studied for displaying the performance of ISSA. ISSA’s performance is also compared with the well-known and new evolutionary methods in the literature. Test results show that ISSA displays good performance and can be used as an alternative method for large scale optimization.},
  archive      = {J_AIR},
  author       = {Baş, Emine and Ülker, Erkan},
  doi          = {10.1007/s10462-020-09931-5},
  journal      = {Artificial Intelligence Review},
  number       = {5},
  pages        = {3539-3574},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Improved social spider algorithm for large scale optimization},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Incremental bayesian broad learning system and its
industrial application. <em>AIR</em>, <em>54</em>(5), 3517–3537. (<a
href="https://doi.org/10.1007/s10462-020-09929-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Broad learning system (BLS) is viewed as a class of neural networks with a broad structure, which exhibits an efficient training process through incremental learning. An incremental Bayesian framework broad learning system is proposed in this study, where the posterior mean and covariance over the output weights are both derived and updated in an incremental manner for the increment of feature nodes, enhancement nodes, and input data, respectively, and the hyper-parameters are simultaneously updated by maximizing the evidence function. In such a way, the scale of matrix operations is capable of being effectively reduced. To verify the performance of this proposed approach, a number of experiments by using four benchmark datasets and an industrial case are carried out. The experimental results demonstrate that the proposed method can not only achieve a better outcome compared to the classical BLS and other comparative algorithms but also incrementally remodel the system.},
  archive      = {J_AIR},
  author       = {Liu, Ying and Wang, Yifei and Chen, Long and Zhao, Jun and Wang, Wei and Liu, Quanli},
  doi          = {10.1007/s10462-020-09929-z},
  journal      = {Artificial Intelligence Review},
  number       = {5},
  pages        = {3517-3537},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Incremental bayesian broad learning system and its industrial application},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Various dimension reduction techniques for high dimensional
data analysis: A review. <em>AIR</em>, <em>54</em>(5), 3473–3515. (<a
href="https://doi.org/10.1007/s10462-020-09928-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the era of healthcare, and its related research fields, the dimensionality problem of high dimensional data is a massive challenge as it contains a huge number of variables forming complex data matrices. The demand for dimension reduction of complex data is growing immensely to improvise data prediction, analysis and visualization. In general, dimension reduction techniques are defined as a compression of dataset from higher dimensional matrix to lower dimensional matrix. Several computational techniques have been implemented for data dimension reduction, which is further segregated into two categories such as feature extraction and feature selection. In this review, a detailed investigation of various feature extraction and feature selection methods has been carried out with a systematic comparison of several dimension reduction techniques for the analysis of high dimensional data and to overcome the problem of data loss. Then, some case studies are also cited to verify the better approach for data dimension reduction by considering few advances described in the technical literature. This review paper may guide researchers to choose the most effective method for satisfactory analysis of high dimensional data.},
  archive      = {J_AIR},
  author       = {Ray, Papia and Reddy, S. Surender and Banerjee, Tuhina},
  doi          = {10.1007/s10462-020-09928-0},
  journal      = {Artificial Intelligence Review},
  number       = {5},
  pages        = {3473-3515},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Various dimension reduction techniques for high dimensional data analysis: A review},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Unbalanced probabilistic linguistic decision-making method
for multi-attribute group decision-making problems with heterogeneous
relationships and incomplete information. <em>AIR</em>, <em>54</em>(5),
3431–3471. (<a
href="https://doi.org/10.1007/s10462-020-09927-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In group decision-making problems, decision makers prefer to use several linguistic terms to describe their own perception and knowledge, and give their preference intensity of each possible linguistic terms based on their own understanding and interpretation. Due to the nonlinearity of decision maker’s cognition, the gaps between adjacent linguistic terms are unbalanced. The unbalanced probabilistic linguistic term set (UPLTS) is proposed to present such situation. To this phenomenon, a resolution framework is constructed to analyze multiple attribute group decision-making problems under unbalanced probabilistic linguistic environment. Firstly, the integration model based on evidential reasoning theory is proposed to aggregate UPLTSs from different groups in view of incomplete probabilistic distributions in UPLTS. Secondly, the transformation function based on proportional 2 tuple is developed to transform UPLTS into probabilistic linguistic term set, making it easier for subsequent analysis and processing. Thirdly, Based on the multiple types of partitioned structure relationship among attributes, partitioned fuzzy measure is developed to globally capture these interactions among attributes. Then the probabilistic linguistic Choquet integral operator with partitioned fuzzy measure is proposed to obtain the comprehensive performances of alternatives. Lastly, the effectiveness and practicability of the proposed method is demonstrated using three numerical examples and comparing with other methods.},
  archive      = {J_AIR},
  author       = {Teng, Fei and Liu, Peide and Liang, Xia},
  doi          = {10.1007/s10462-020-09927-1},
  journal      = {Artificial Intelligence Review},
  number       = {5},
  pages        = {3431-3471},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Unbalanced probabilistic linguistic decision-making method for multi-attribute group decision-making problems with heterogeneous relationships and incomplete information},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). A review of q-rung orthopair fuzzy information:
Bibliometrics and future directions. <em>AIR</em>, <em>54</em>(5),
3361–3430. (<a
href="https://doi.org/10.1007/s10462-020-09926-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The q-rung orthopair fuzzy set (q-ROFS), initiated by Yager, is a novel tool to dispose of indeterminacy that considers the membership $$\mu$$ and non-membership $$\nu$$ , which satisfy the limited condition $$0\le \mu ^q+\nu ^q\le 1$$ . It can be employed in characterizing the vague preference more precisely and flexibly than intuitionistic fuzzy set and Pythagorean fuzzy set. q-ROFS has attracted deep concern of numerous researchers, which is mainly distributed in diverse research points such as comparison methods, aggregation operators, decision making methods, calculus, information measure, preference relation, graph and application scenarios. As a result of this growth, we give an overview of q-ROFS for offering a clear perspective on novel trends. A total of 80 q-ROFS related publications of Web of Science are in-depth analysis. Some significant results related to annual trends, country level, institutional level, journal level, highly cited papers, and research landscape are generated and illustrated. Eighteen future research directions or challenges related to the q-ROFS theory are indicated. Finally, the co-authorship analysis, the co-citation analysis, the co-occurrence analysis and the bibliographic coupling analysis are derived by VOSviewer software.},
  archive      = {J_AIR},
  author       = {Peng, Xindong and Luo, Zhigang},
  doi          = {10.1007/s10462-020-09926-2},
  journal      = {Artificial Intelligence Review},
  number       = {5},
  pages        = {3361-3430},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A review of q-rung orthopair fuzzy information: Bibliometrics and future directions},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Visual tracking using convolutional features with sparse
coding. <em>AIR</em>, <em>54</em>(5), 3349–3360. (<a
href="https://doi.org/10.1007/s10462-020-09905-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visual object tracking has become one of the most active research topics in computer vision, and it has been applied in several commercial applications. Several visual trackers have been presented in the last two decades. They target different tracking objectives. Object tracking from a real-time video is a challenging problem. Therefore, a robust tracker is required to consider many aspects of videos such as camera motion, occlusion, illumination effect, clutter, and similar appearance. In this paper, we propose an efficient object tracking algorithm that adaptively represents the object appearance using CNN-based features. A sparse measurement matrix is proposed to extract the compressed features for the appearance model without sacrificing the performance. We compress sample images of the foreground object and the background by the sparse matrix. When re-detection is needed, the tracking algorithm conducts an SVM classifier on the extracted features with online update in the compressed domain. A search strategy is proposed to reduce the computational burden in the detection step. Extensive simulations with a challenging video dataset demonstrate that the proposed tracking algorithm provides real-time tracking, while delivering substantially better tracking performance than those of the state-of-the-art techniques in terms of robustness, accuracy, and efficiency.},
  archive      = {J_AIR},
  author       = {Abbass, Mohammed Y. and Kwon, Ki-Chul and Kim, Nam and Abdelwahab, Safey A. and El-Samie, Fathi E. Abd and Khalaf, Ashraf A. M.},
  doi          = {10.1007/s10462-020-09905-7},
  journal      = {Artificial Intelligence Review},
  number       = {5},
  pages        = {3349-3360},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Visual tracking using convolutional features with sparse coding},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Machine learning towards intelligent systems: Applications,
challenges, and opportunities. <em>AIR</em>, <em>54</em>(5), 3299–3348.
(<a href="https://doi.org/10.1007/s10462-020-09948-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The emergence and continued reliance on the Internet and related technologies has resulted in the generation of large amounts of data that can be made available for analyses. However, humans do not possess the cognitive capabilities to understand such large amounts of data. Machine learning (ML) provides a mechanism for humans to process large amounts of data, gain insights about the behavior of the data, and make more informed decision based on the resulting analysis. ML has applications in various fields. This review focuses on some of the fields and applications such as education, healthcare, network security, banking and finance, and social media. Within these fields, there are multiple unique challenges that exist. However, ML can provide solutions to these challenges, as well as create further research opportunities. Accordingly, this work surveys some of the challenges facing the aforementioned fields and presents some of the previous literature works that tackled them. Moreover, it suggests several research opportunities that benefit from the use of ML to address these challenges.},
  archive      = {J_AIR},
  author       = {Injadat, MohammadNoor and Moubayed, Abdallah and Nassif, Ali Bou and Shami, Abdallah},
  doi          = {10.1007/s10462-020-09948-w},
  journal      = {Artificial Intelligence Review},
  number       = {5},
  pages        = {3299-3348},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Machine learning towards intelligent systems: Applications, challenges, and opportunities},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Deep learning approaches to scene text detection: A
comprehensive review. <em>AIR</em>, <em>54</em>(5), 3239–3298. (<a
href="https://doi.org/10.1007/s10462-020-09930-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent times, text detection in the wild has significantly raised its ability due to tremendous success of deep learning models. Applications of computer vision have emerged and got reshaped in a new way in this booming era of deep learning. In the last decade, research community has witnessed drastic changes in the area of text detection from natural scene images in terms of approach, coverage and performance due to huge advancement of deep neural network based models. In this paper, we present (1) a comprehensive review of deep learning approaches towards scene text detection, (2) suitable deep frameworks for this task followed by critical analysis, (3) a categorical study of publicly available scene image datasets and applicable standard evaluation protocols with their pros and cons, and (4) comparative results and analysis of reported methods. Moreover, based on this review and analysis, we precisely mention possible future scopes and thrust areas of deep learning approaches towards text detection from natural scene images on which upcoming researchers may focus.},
  archive      = {J_AIR},
  author       = {Khan, Tauseef and Sarkar, Ram and Mollah, Ayatullah Faruk},
  doi          = {10.1007/s10462-020-09930-6},
  journal      = {Artificial Intelligence Review},
  number       = {5},
  pages        = {3239-3298},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Deep learning approaches to scene text detection: A comprehensive review},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A survey on multi-agent deep reinforcement learning: From
the perspective of challenges and applications. <em>AIR</em>,
<em>54</em>(5), 3215–3238. (<a
href="https://doi.org/10.1007/s10462-020-09938-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep reinforcement learning has proved to be a fruitful method in various tasks in the field of artificial intelligence during the last several years. Recent works have focused on deep reinforcement learning beyond single-agent scenarios, with more consideration of multi-agent settings. The main goal of this paper is to provide a detailed and systematic overview of multi-agent deep reinforcement learning methods in views of challenges and applications. Specifically, the preliminary knowledge is introduced first for a better understanding of this field. Then, a taxonomy of challenges is proposed and the corresponding structures and representative methods are introduced. Finally, some applications and interesting future opportunities for multi-agent deep reinforcement learning are given.},
  archive      = {J_AIR},
  author       = {Du, Wei and Ding, Shifei},
  doi          = {10.1007/s10462-020-09938-y},
  journal      = {Artificial Intelligence Review},
  number       = {5},
  pages        = {3215-3238},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A survey on multi-agent deep reinforcement learning: From the perspective of challenges and applications},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Generalized maclaurin symmetric mean aggregation operators
based on archimedean t-norm of the intuitionistic fuzzy soft set
information. <em>AIR</em>, <em>54</em>(4), 3173–3213. (<a
href="https://doi.org/10.1007/s10462-020-09925-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intuitionistic fuzzy soft set (IFSS) accommodates more uncertainties within the information by considering the parameterization feature than the intuitionistic fuzzy sets and hence its applications are more extensive. Archimedean T-conorm and T-norm (ATT), consists of T-norm and T-conorm classes, is as an essential source to make the comprehensive operational laws. Meanwhile, the Maclaurin symmetric mean (MSM) has a prominent characteristic and the advantage that it can take into account the interrelation between multi-input arguments, including different attributes or different experts. Motivated by these chief characteristics, in this article, we extend the MSM operators to the IFSS based on ATT. In this paper, a method is exploited to solve the multi-criteria decision-making (MCDM) problems under the IFSS environment. To it, firstly, some generalized intuitionistic fuzzy soft operational laws are introduced based on ATT. Secondly, we reveal some averaging and geometric aggregation operators based on MSM operator. Further, some desirable features and particular cases of it are tested and build up with a new technique for illustrating MCDM problems. Finally, an illustration is given to exhibit the methodology and approach’s supremacy is shown through a comparative study with prevailing techniques.},
  archive      = {J_AIR},
  author       = {Garg, Harish and Arora, Rishu},
  doi          = {10.1007/s10462-020-09925-3},
  journal      = {Artificial Intelligence Review},
  number       = {4},
  pages        = {3173-3213},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Generalized maclaurin symmetric mean aggregation operators based on archimedean t-norm of the intuitionistic fuzzy soft set information},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Certain competition graphs based on picture fuzzy
environment with applications. <em>AIR</em>, <em>54</em>(4), 3141–3171.
(<a href="https://doi.org/10.1007/s10462-020-09923-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the notion of picture fuzzy competition graph along with its few generalizations such as m-step picture fuzzy competition graphs, picture fuzzy economic competition graphs and picture fuzzy competition hypergraphs are introduced. Some related picture fuzzy graphs including picture fuzzy m-step neighborhood graph, picture fuzzy m-step economic competition graph and picture fuzzy k-competition hypergraphs are introduced. Some properties of these graphs have been investigated. Finally, applications of m-step picture fuzzy competition graphs and picture fuzzy competition hypergraphs are presented in several fields such as in education system, ecosystem, business market and job competition.},
  archive      = {J_AIR},
  author       = {Das, Sankar and Ghorai, Ganesh and Pal, Madhumangal},
  doi          = {10.1007/s10462-020-09923-5},
  journal      = {Artificial Intelligence Review},
  number       = {4},
  pages        = {3141-3171},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Certain competition graphs based on picture fuzzy environment with applications},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Ensemble learning based on random super-reduct and
resampling. <em>AIR</em>, <em>54</em>(4), 3115–3140. (<a
href="https://doi.org/10.1007/s10462-020-09922-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ensemble learning has been widely used for improving the performance of base classifiers. Diversity among base classifiers is considered as a key issue in ensemble learning. Recently, to promote the diversity of base classifiers, ensemble methods through multi-modal perturbation have been proposed. These methods simultaneously use two or more perturbation techniques when generating base classifiers. In this paper, from the perspective of multi-modal perturbation, we propose an ensemble approach (called ‘E $$\_$$ RSRR’) based on random super-reduct and resampling. To generate a set of accurate and diverse base classifiers, E $$\_$$ RSRR adopts a new multi-modal perturbation strategy. This strategy combines two perturbation techniques together, that is, resampling and random super-reduct. First, it perturbs the sample space via the resampling technique; Second, it perturbs the feature space via the random super-reduct technique, which is a combination of RSS (random subspace selection) technique and ADEFS (approximate decision entropy-based feature selection) method in rough sets. Experimental results show that E $$\_$$ RSRR can provide competitive solutions for ensemble learning.},
  archive      = {J_AIR},
  author       = {Jiang, Feng and Yu, Xu and Zhao, Hongbo and Gong, Dunwei and Du, Junwei},
  doi          = {10.1007/s10462-020-09922-6},
  journal      = {Artificial Intelligence Review},
  number       = {4},
  pages        = {3115-3140},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Ensemble learning based on random super-reduct and resampling},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Relative-distance-based approaches for ranking
intuitionistic fuzzy values. <em>AIR</em>, <em>54</em>(4), 3089–3114.
(<a href="https://doi.org/10.1007/s10462-020-09921-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {During the uncertain information processing on Atanassov’s intuitionistic fuzzy sets, the ranking for intuitionistic fuzzy values (IFVs) is an important and omnipresent issue. Even though many orders used to compare any two IFVs have been proposed, some shortcomings, such as inadmissibility, nonrobustness, and nondeterminacy, may exist when these orders are utilized. Inspired by the Euclidean approach for ranking IFVs, we present a novel order that can overcome the aforementioned shortcomings using the notion of relative geometric distance. With the help of graphic representation of an IFV, we analyze the existing popular approaches for ranking IFVs and point out their drawbacks. Taking into account these three distances between an IFV and the ideal negative point, ideal positive point and most uncertain point, respectively, we present a relative-distance-based mensuration for describing the favorable degree of the IFV. Accordingly, the boundaries used in the existing ranking approaches for IFVs are replaced by a novel curve. We prove that the proposed method satisfies the admissibility, robustness, and determinacy requirements. Finally, we extend the presented ranking method for IFVs by introducing human attitudes and compare the proposed approach with the existing ones, which indicates its availability and rationality. We then can obtain the conclusion that the relative distance is an effective and reasonable approach for ranking IFVs.},
  archive      = {J_AIR},
  author       = {Huang, Bing and Liu, Jiubing and Guo, Chunxiang and Li, Huaxiong and Feng, Guofu},
  doi          = {10.1007/s10462-020-09921-7},
  journal      = {Artificial Intelligence Review},
  number       = {4},
  pages        = {3089-3114},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Relative-distance-based approaches for ranking intuitionistic fuzzy values},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Ultrasound tissue classification: A review. <em>AIR</em>,
<em>54</em>(4), 3055–3088. (<a
href="https://doi.org/10.1007/s10462-020-09920-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ultrasound imaging is the most widespread medical imaging modality for creating images of the human body in clinical practice. Tissue classification in ultrasound has been established as one of the most active research areas, driven by many important clinical applications. In this paper, we present a survey on ultrasound tissue classification, focusing on recent advances in this area. We start with a brief review on the main clinical applications. We then introduce the traditional approaches, where the existing research on feature extraction and classifier design are reviewed. As deep learning approaches becoming popular for medical image analysis, the recent deep learning methods for tissue classification are also introduced. We briefly discuss the FDA-cleared techniques being used clinically. We conclude with the discussion on the challenges and research focus in future.},
  archive      = {J_AIR},
  author       = {Shan, Caifeng and Tan, Tao and Han, Jungong and Huang, Di},
  doi          = {10.1007/s10462-020-09920-8},
  journal      = {Artificial Intelligence Review},
  number       = {4},
  pages        = {3055-3088},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Ultrasound tissue classification: A review},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Text categorization: Past and present. <em>AIR</em>,
<em>54</em>(4), 3007–3054. (<a
href="https://doi.org/10.1007/s10462-020-09919-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic text categorization is the operation of sorting out the text documents into pre-defined text categories using some machine learning algorithms. Normally, it defines the most important approaches to organizing and making the use of a large volume of information exists in unstructured form. Nowadays, text categorization is becoming an extensively researched field of text mining and processing of languages. Word sense, semantic relationships among terms, text documents and categories are quite essential in order of enhancing the performances of categorization. Various surveys on text categorization have already been available which involve techniques of various text representation schemes to such extent but do not include several approaches that have been explored in text categorization over the standard techniques. Here, an exhaustive analysis of different text categorization approaches over the conventional approaches has been undertaken. This survey paper explores a wide variety of algorithms used for categorizing text documents and tries to assemble the existing works into three basic fields: conventional methods, fuzzy logic-based methods, deep learning-based methods. Further, conventional methods have been categorized into three fields: text categorization using handcrafted features, text categorization using nature-inspired algorithms and text categorization using graph-based methods. Furthermore, this survey provides a clear idea about the available libraries used for different algorithms, availability of datasets, categorization technologies explored in various non-Indian and Indian languages as well.},
  archive      = {J_AIR},
  author       = {Dhar, Ankita and Mukherjee, Himadri and Dash, Niladri Sekhar and Roy, Kaushik},
  doi          = {10.1007/s10462-020-09919-1},
  journal      = {Artificial Intelligence Review},
  number       = {4},
  pages        = {3007-3054},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Text categorization: Past and present},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A comprehensive review on feature set used for anaphora
resolution. <em>AIR</em>, <em>54</em>(4), 2917–3006. (<a
href="https://doi.org/10.1007/s10462-020-09917-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In linguistics, the Anaphora Resolution (AR) is the method of identifying the antecedent for anaphora. In simple terms, this is the problem that helps to solve what the expression referring to a referent refers to. It is considered to be one of the tedious tasks in Natural Language Processing (NLP). AR’s burgeoning popularity among researchers is attributable to its strong relevance to machine translation, text summarization, chatbot, question answering, and many others. This paper presents a review of AR approaches based on significant features utilized to perform this task and presents the evaluation metrics for this field. The feature is a relevant term related to AR that provides vital information regarding anaphor, antecedent, and relation between them. In this context, features represent the lexical, syntactical, semantical, and positional relationship between anaphor and its possible candidate antecedent. The performance of the Anaphora resolution system is profoundly dependent on the features used in the AR system. Hence, the selection of features for the AR system is highly significant. The main emphasis is to provide an overview of the various features needed to extract both the Anaphora and the Antecedent, respectively, used in different AR systems, present in literature. It is observed that syntactical information enhances the correctness of determining the properties for the existence of an anaphor and antecedent identification. Nowadays the trend is changing from hand-crafted feature dependent methods to deep learning approaches which try to learn feature representation. The performance of deep learning is progressing due to the accessibility of additional data and more powerful computing resources. This survey will provide the state-of art for the better understanding of solving AR problem from the feature selection perspective. The findings of this survey are useful to provide valuable insight into present trends and are helpful for researchers who are looking for developing AR system within given constraints.},
  archive      = {J_AIR},
  author       = {Lata, Kusum and Singh, Pardeep and Dutta, Kamlesh},
  doi          = {10.1007/s10462-020-09917-3},
  journal      = {Artificial Intelligence Review},
  number       = {4},
  pages        = {2917-3006},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A comprehensive review on feature set used for anaphora resolution},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Tensor decomposition for analysing time-evolving social
networks: An overview. <em>AIR</em>, <em>54</em>(4), 2891–2916. (<a
href="https://doi.org/10.1007/s10462-020-09916-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Social networks are becoming larger and more complex as new ways of collecting social interaction data arise (namely from online social networks, mobile devices sensors, ...). These networks are often large-scale and of high dimensionality. Therefore, dealing with such networks became a challenging task. An intuitive way to deal with this complexity is to resort to tensors. In this context, the application of tensor decomposition has proven its usefulness in modelling and mining these networks: it has not only been applied for exploratory analysis (thus allowing the discovery of interaction patterns), but also for more demanding and elaborated tasks such as community detection and link prediction. In this work, we provide an overview of the methods based on tensor decomposition for the purpose of analysing time-evolving social networks from various perspectives: from community detection, link prediction and anomaly/event detection to network summarization and visualization. In more detail, we discuss the ideas exploited to carry out each social network analysis task as well as its limitations in order to give a complete coverage of the topic.},
  archive      = {J_AIR},
  author       = {Fernandes, Sofia and Fanaee-T, Hadi and Gama, João},
  doi          = {10.1007/s10462-020-09916-4},
  journal      = {Artificial Intelligence Review},
  number       = {4},
  pages        = {2891-2916},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Tensor decomposition for analysing time-evolving social networks: An overview},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Modelling daily soil temperature by hydro-meteorological
data at different depths using a novel data-intelligence model: Deep
echo state network model. <em>AIR</em>, <em>54</em>(4), 2863–2890. (<a
href="https://doi.org/10.1007/s10462-020-09915-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Soil temperature (Ts) is an essential regulator of a plant’s root growth, evapotranspiration rates, and hence soil water content. Over the last few years, in response to the climatic change, significant amount of research has been conducted worldwide to understand the quantitative link between soil temperature and the climatic factors, and it was highlighted that the hydrothermal conditions in the soil are continuously changing in response to the change of the hydro-meteorological factors. A large amount of the models have been developed and used in the past for the analysis and modelling of soil temperature, however, none of them has investigated the robustness and feasibilities of the deep echo state network (Deep ESN) model. A more accurate model for forecasting Ts presents many worldwide opportunities in improving irrigation efficiency in arid climates and help attain sustainable water resources management. This research compares the application of the novel Deep ESN model versus three conventional machine learning models for soil temperature forecasting at 10 and 20 cm depths. We combined several critical daily hydro-meteorological data into six different input combinations for constructing the Deep ESN model. The accuracy of the developed soil temperature models is evaluated using three deterministic indices. The results of the evaluation indicate that the Deep ESN model outperformed conventional machine learning methods and can reduce the root mean square error (RMSE) accuracy of the traditional models between 30 and 60\% in both stations. In the test phase, the most accurate estimation was obtained by Deep ESN at depths of 10 cm by RMSE = 2.41 °C and 20 cm by RMSE = 1.28 °C in Champaign station and RMSE = 2.17 °C (10 cm) and RMSE = 1.52 °C (20 cm) in Springfield station. The superior performance of the Deep ESN model confirmed that this model can be successfully applied for modelling Ts based on meteorological paarameters.},
  archive      = {J_AIR},
  author       = {Alizamir, Meysam and Kim, Sungwon and Zounemat-Kermani, Mohammad and Heddam, Salim and Shahrabadi, Amin Hasanalipour and Gharabaghi, Bahram},
  doi          = {10.1007/s10462-020-09915-5},
  journal      = {Artificial Intelligence Review},
  number       = {4},
  pages        = {2863-2890},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Modelling daily soil temperature by hydro-meteorological data at different depths using a novel data-intelligence model: Deep echo state network model},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A systematic mapping study for ensemble classification
methods in cardiovascular disease. <em>AIR</em>, <em>54</em>(4),
2827–2861. (<a
href="https://doi.org/10.1007/s10462-020-09914-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ensemble methods overcome the limitations of single machine learning techniques by combining different techniques, and are employed in the quest to achieve a high level of accuracy. This approach has been investigated in various fields, one of them being that of bioinformatics. One of the most frequent applications of ensemble techniques involves research into cardiovascular diseases, which are considered the leading cause of death worldwide. The purpose of this research work is to identify the papers that investigate ensemble classification techniques applied to cardiology diseases, and to analyse them according to nine aspects: their publication venues, the medical tasks tackled, the empirical and research types adopted, the types of ensembles proposed, the single techniques used to construct the ensembles, the validation frameworks adopted to evaluate the proposed ensembles, the tools used to build the ensembles, and the optimization methods employed for the single techniques. This paper reports the carrying out of a systematic mapping study. An extensive automatic search in four digital libraries: IEEE Xplore, ACM Digital Library, PubMed, and Scopus, followed by a study selection process, resulted in the identification of 351 papers that were used to address our mapping questions. This study found that the papers selected had been published in a large number of different resources. The medical task addressed most frequently by the selected studies was diagnosis. In addition, the experiment-based empirical type and evaluation-based research type were the most dominant approaches adopted by the selected studies. Homogeneous ensembles were the ensemble type that was developed most often in literature, while decision trees, artificial neural networks and Bayesian classifiers were the single techniques used most frequently to develop ensemble classification methods. The weighted majority and majority voting rules were adopted to obtain the final decision of the ensembles developed. With regard to evaluation frameworks, the datasets obtained from the UCI and PhysioBank repositories were those used most often to evaluate the ensemble methods, while the k-fold cross-validation method was the most frequently-employed validation technique. Several tools with which to build ensemble classifiers were identified, and the type of software adopted with the greatest frequency was open source. Finally, only a few researchers took into account the optimization of the parameter settings of either single or meta ensemble classifiers. This mapping study attempts to provide a greater insight into the application of ensemble classification methods in cardiovascular diseases. The majority of the selected papers reported positive feedback as regards the ability of ensemble methods to perform better than single methods. Further analysis is required to aggregate the evidence reported in literature.},
  archive      = {J_AIR},
  author       = {Hosni, Mohamed and Carrillo de Gea, Juan M. and Idri, Ali and El Bajta, Manal and Fernández Alemán, José Luis and García-Mateos, Ginés and Abnane, Ibtissam},
  doi          = {10.1007/s10462-020-09914-6},
  journal      = {Artificial Intelligence Review},
  number       = {4},
  pages        = {2827-2861},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A systematic mapping study for ensemble classification methods in cardiovascular disease},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Interactive clustering: A scoping review. <em>AIR</em>,
<em>54</em>(4), 2765–2826. (<a
href="https://doi.org/10.1007/s10462-020-09913-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present in this paper a scoping review conducted in the interactive clustering area. Interactive clustering has been applied to leverage the strengths of both unsupervised and supervised learning. In interactive clustering, supervised learning is represented by inserting the knowledge of human experts in an originally unsupervised data analysis process. This scoping review aimed to organize the knowledge on (i) the applicability of interactive clustering methods, (ii) clustering algorithms being used to support interactive clustering, (iii) how to model the expert supervision and (iv) the effects brought by the expert supervision in the results produced. A systematic search for related literature was conducted in the Scopus database, resulting in the selection of 50 primary studies published by 2018. The analysis of these studies allowed us to identify trends such as: the application in text/image; use of partitioning and hierarchical algorithms; application of strategies based on split/merge, pairwise constraints, similarity metrics learning and data reassignment; and concern with visualization. In addition, some relevant issues not yet adequately addressed were identified, such as: the evaluation of expert supervision; the evaluation of the expert’s effort; and the conduction of studies effectively involving human experts, instead of computer simulations.},
  archive      = {J_AIR},
  author       = {Neubauer, Thais Rodrigues and Peres, Sarajane Marques and Fantinato, Marcelo and Lu, Xixi and Reijers, Hajo Alexander},
  doi          = {10.1007/s10462-020-09913-7},
  journal      = {Artificial Intelligence Review},
  number       = {4},
  pages        = {2765-2826},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Interactive clustering: A scoping review},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). M-polar neutrosophic soft mapping with application to
multiple personality disorder and its associated mental disorders.
<em>AIR</em>, <em>54</em>(4), 2717–2763. (<a
href="https://doi.org/10.1007/s10462-020-09912-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multiple personality disorder (MPD) or dissociative identity disorder is the mental disease in which one can observe the existence of two or more than two personalities in a single person. We define the controversies nearby the diagnosis of MPD with its associated mental disorders. We discuss the various symptoms of MPD, dissociative amnesia, depersonalization or derealization disorder, and major depression disorder. After this exploration, we perceive that these disorders enclose parallel symptoms and it is difficult to identify the accurate type of disorder with its severeness. Since in experimental diagnosis the indeterminacy and falsity parts are often neglected. Due to this problem, we cannot see the accuracy in the patient’s improvement record and cannot predict the duration of treatment. To eradicate these boundaries, we present the m-polar neutrosophic soft set (MPNSS) and m-polar neutrosophic soft mapping (MPNS-mapping) with its inverse mapping. These notions are proficient and valuable to diagnose the disorder appropriately by connecting it with the mathematical modeling. The connection of m-polar neutrosophic set (MPNS) with the soft set characterizes a relation among patients, symptoms, and treatments which decreases the complexity of the case study. We build a chart based on a fuzzy interval [0, 1] to range the types of disorders. We establish an algorithm based on MPNS-mapping to identify the disease appropriately and to select the finest treatment for the corresponding disease of every patient. At last, we introduce the generalized MPNS-mapping which will helps a doctor to save the patient’s improvement record and to predict the period of treatment until the disease is cured.},
  archive      = {J_AIR},
  author       = {Riaz, Muhammad and Hashmi, Masooma Raza},
  doi          = {10.1007/s10462-020-09912-8},
  journal      = {Artificial Intelligence Review},
  number       = {4},
  pages        = {2717-2763},
  shortjournal = {Artif. Intell. Rev.},
  title        = {M-polar neutrosophic soft mapping with application to multiple personality disorder and its associated mental disorders},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A comprehensive survey of crow search algorithm and its
applications. <em>AIR</em>, <em>54</em>(4), 2669–2716. (<a
href="https://doi.org/10.1007/s10462-020-09911-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Crow Search Algorithm (CSA) is a recent swarm intelligence optimization algorithm inspired by the social intelligent behavior of crows for hiding food. It has been widely used to solve a large variety of optimization problems in several fields and areas of research and has proved its efficiency compared to several state-of-the-art optimization algorithms available in the literature. This paper presents a comprehensive overview of Crow Search Algorithm and its new variants categorized into modified and hybridized versions. It also describes the several applications of CSA in various domains such as feature selection, image processing, scheduling, economic dispatch, distributed generation, and other engineering problems. In addition, the paper suggests some interesting research areas related to CSA enhancement, CSA hybridization, and possible new applications.},
  archive      = {J_AIR},
  author       = {Meraihi, Yassine and Gabis, Asma Benmessaoud and Ramdane-Cherif, Amar and Acheli, Dalila},
  doi          = {10.1007/s10462-020-09911-9},
  journal      = {Artificial Intelligence Review},
  number       = {4},
  pages        = {2669-2716},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A comprehensive survey of crow search algorithm and its applications},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Role of artificial intelligence in rotor fault diagnosis: A
comprehensive review. <em>AIR</em>, <em>54</em>(4), 2609–2668. (<a
href="https://doi.org/10.1007/s10462-020-09910-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial intelligence (AI)-based rotor fault diagnosis (RFD) poses a variety of challenges to the prognostics and health management (PHM) of the Industry 4.0 revolution. Rotor faults have drawn more attention from the AI research community in terms of utilizing fault-specific characteristics in its feature engineering, compared to any other rotating machinery faults. While the rotor faults, specifically structural rotor faults (SRF), have proven to be the root cause of most of the rotating machinery issues, the research in this field largely revolves around bearing and gear faults. Within this scenario, this paper is the first of its kind to attempt to review and define the role of AI in RFD and provides an all-encompassing review of rotor faults for the researchers and academics. In addition, this study is unique in three ways: (i) it emphasizes the use of fault-specific characteristic features with AI, (ii) it is grounded in fault-wise analysis rather than component-wise analysis with appropriate fault categorization, and (iii) it portrays the current research and analysis in accordance with different phases of an AI-based RFD framework. Finally, the section on future research directions is aimed at bridging the gap between a laboratory-based solution and a real-world industrial solution for RFD.},
  archive      = {J_AIR},
  author       = {Nath, Aneesh G. and Udmale, Sandeep S. and Singh, Sanjay Kumar},
  doi          = {10.1007/s10462-020-09910-w},
  journal      = {Artificial Intelligence Review},
  number       = {4},
  pages        = {2609-2668},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Role of artificial intelligence in rotor fault diagnosis: A comprehensive review},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Advances in sine cosine algorithm: A comprehensive survey.
<em>AIR</em>, <em>54</em>(4), 2567–2608. (<a
href="https://doi.org/10.1007/s10462-020-09909-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Sine Cosine Algorithm (SCA) is a population-based optimization algorithm introduced by Mirjalili in 2016, motivated by the trigonometric sine and cosine functions. After providing an overview of the SCA algorithm, we survey a number of SCA variants and applications that have appeared in the literature. We then present the results of a series of computational experiments to validate the performance of the SCA against similar algorithms.},
  archive      = {J_AIR},
  author       = {Abualigah, Laith and Diabat, Ali},
  doi          = {10.1007/s10462-020-09909-3},
  journal      = {Artificial Intelligence Review},
  number       = {4},
  pages        = {2567-2608},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Advances in sine cosine algorithm: A comprehensive survey},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Stochastic local search for partial max-SAT: An experimental
evaluation. <em>AIR</em>, <em>54</em>(4), 2525–2566. (<a
href="https://doi.org/10.1007/s10462-020-09908-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stochastic local search (SLS) methods are heuristic-based algorithms that have gained in popularity for their efficiency and robustness when solving very large and complex problems from various areas of artificial intelligence. This study aims to gain insights into SLS methods for solving the Partial Max-SAT (PMSAT) problem. The PMSAT is an NP-Hard problem, an optimization variant of the Propositional Boolean Satisfiability (SAT) problem, that has importance in theory and practice. Many real-world problems including timetabling, scheduling, planning, routing, and software debugging can be reduced to the PMSAT problem. Modern PMSAT solvers are able to solve practical instances with hundreds of thousands to millions of variables and clauses. However, performance of PMSAT solvers are still limited for solving some benchmark instances. In this paper, we present, investigate, and analyze state-of-the-art SLS methods for solving the PMSAT problem. An experimental evaluation is presented based on the MAX-SAT evaluations from 2014 to 2019. The results of this evaluation study show that the currently best performing SLS methods for the PMSAT problem fall into three categories: distinction-based, configuration checking-based, and dynamic local search methods. Very good performance was reported for the dynamic local search based method. The paper gives a detailed picture of the performance of SLS solvers for the PMSAT problem, aims to improve our understanding of their capabilities and limitations, and identifies future research directions.},
  archive      = {J_AIR},
  author       = {AlKasem, Haifa Hamad and Menai, Mohamed El Bachir},
  doi          = {10.1007/s10462-020-09908-4},
  journal      = {Artificial Intelligence Review},
  number       = {4},
  pages        = {2525-2566},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Stochastic local search for partial max-SAT: An experimental evaluation},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Understanding lombard speech: A review of compensation
techniques towards improving speech based recognition systems.
<em>AIR</em>, <em>54</em>(4), 2495–2523. (<a
href="https://doi.org/10.1007/s10462-020-09907-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Building voice-based Artificial Intelligence (AI) systems that can efficiently interact with humans through speech has become plausible today due to rapid strides in efficient data-driven AI techniques. Such a human–machine voice interaction in real world would often involve a noisy ambience, where humans tend to speak with additional vocal effort than in a quiet ambience, to mitigate the noise-induced suppression of vocal self-feedback. This noise induced change in the vocal effort is called Lombard speech. In order to build intelligent conversational devices that can operate in a noisy ambience, it is imperative to study the characteristics and processing of Lombard speech. Though the progress of research on Lombard speech started several decades ago, it needs to be explored further in the current scenario which is seeing an explosion of voice-driven applications. The system designed to work with normal speech spoken in a quiet ambience fails to provide the same performance in changing environmental contexts. Different contexts lead to different styles of Lombard speech and hence there arises a need for efficient ways of handling variations in speaking styles in noise. The Lombard speech is also more intelligible than normal speech of a speaker. Applications like public announcement systems with speech output interface should talk with varying degrees of vocal effort to enhance naturalness in a way that humans adapt to speak in noise, in real time. This review article is an attempt to summarize the progress of work on the possible ways of processing Lombard speech to build smart and robust human–machine interactive systems with speech input–output interface, irrespective of operating environmental contexts, for different application needs. This article is a comprehensive review of the studies on Lombard speech, highlighting the key differences observed in acoustic and perceptual analysis of Lombard speech and detailing the Lombard effect compensation methods towards improving the robustness of speech based recognition systems.},
  archive      = {J_AIR},
  author       = {Uma Maheswari, S. and Shahina, A. and Nayeemulla Khan, A.},
  doi          = {10.1007/s10462-020-09907-5},
  journal      = {Artificial Intelligence Review},
  number       = {4},
  pages        = {2495-2523},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Understanding lombard speech: A review of compensation techniques towards improving speech based recognition systems},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). From classical to deep learning: Review on cartilage and
bone segmentation techniques in knee osteoarthritis research.
<em>AIR</em>, <em>54</em>(4), 2445–2494. (<a
href="https://doi.org/10.1007/s10462-020-09924-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knee osteoarthritis is a major diarthrodial joint disorder with profound global socioeconomic impact. Diagnostic imaging using magnetic resonance image can produce morphometric biomarkers to investigate the epidemiology of knee osteoarthritis in clinical trials, which is critical to attain early detection and develop effective regenerative treatment/therapy. With tremendous increase in image data size, manual segmentation as the standard practice becomes largely unsuitable. This review aims to provide an in-depth insight about a broad collection of classical and deep learning segmentation techniques used in knee osteoarthritis research. Specifically, this is the first review that covers both bone and cartilage segmentation models in recognition that knee osteoarthritis is a “whole joint” disease, as well as highlights on diagnostic values of deep learning in emerging knee osteoarthritis research. Besides, we have collected useful deep learning reviews to serve as source of reference to ease future development of deep learning models in this field. Lastly, we highlight on the diagnostic value of deep learning as key future computer-aided diagnosis applications to conclude this review.},
  archive      = {J_AIR},
  author       = {Gan, Hong-Seng and Ramlee, Muhammad Hanif and Wahab, Asnida Abdul and Lee, Yeng-Seng and Shimizu, Akinobu},
  doi          = {10.1007/s10462-020-09924-4},
  journal      = {Artificial Intelligence Review},
  number       = {4},
  pages        = {2445-2494},
  shortjournal = {Artif. Intell. Rev.},
  title        = {From classical to deep learning: Review on cartilage and bone segmentation techniques in knee osteoarthritis research},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A survey on parallel clustering algorithms for big data.
<em>AIR</em>, <em>54</em>(4), 2411–2443. (<a
href="https://doi.org/10.1007/s10462-020-09918-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data clustering is one of the most studied data mining tasks. It aims, through various methods, to discover previously unknown groups within the data sets. In the past years, considerable progress has been made in this field leading to the development of innovative and promising clustering algorithms. These traditional clustering algorithms present some serious issues in connection with the speed-up, the throughput, and the scalability. Thus, they can no longer be directly used in the context of Big Data, where data are mainly characterized by their volume, velocity, and variety. In order to overcome their limitations, the research today is heading to the parallel computing concept by giving rise to the so-called parallel clustering algorithms. This paper presents an overview of the latest parallel clustering algorithms categorized according to the computing platforms used to handle the Big Data, namely, the horizontal and vertical scaling platforms. The former category includes peer-to-peer networks, MapReduce, and Spark platforms, while the latter category includes Multi-core processors, Graphics Processing Unit, and Field Programmable Gate Arrays platforms. In addition, it includes a comparison of the performance of the reviewed algorithms based on some common criteria of clustering validation in the Big Data context. Therefore, it provides the reader with an overall vision of the current parallel clustering techniques.},
  archive      = {J_AIR},
  author       = {Dafir, Zineb and Lamari, Yasmine and Slaoui, Said Chah},
  doi          = {10.1007/s10462-020-09918-2},
  journal      = {Artificial Intelligence Review},
  number       = {4},
  pages        = {2411-2443},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A survey on parallel clustering algorithms for big data},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Performance assessment of the metaheuristic optimization
algorithms: An exhaustive review. <em>AIR</em>, <em>54</em>(3),
2323–2409. (<a
href="https://doi.org/10.1007/s10462-020-09906-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The simulation-driven metaheuristic algorithms have been successful in solving numerous problems compared to their deterministic counterparts. Despite this advantage, the stochastic nature of such algorithms resulted in a spectrum of solutions by a certain number of trials that may lead to the uncertainty of quality solutions. Therefore, it is of utmost importance to use a correct tool for measuring the performance of the diverse set of metaheuristic algorithms to derive an appropriate judgment on the superiority of the algorithms and also to validate the claims raised by researchers for their specific objectives. The performance of a randomized metaheuristic algorithm can be divided into efficiency and effectiveness measures. The efficiency relates to the algorithm’s speed of finding accurate solutions, convergence, and computation. On the other hand, effectiveness relates to the algorithm’s capability of finding quality solutions. Both scopes are crucial for continuous and discrete problems either in single- or multi-objectives. Each problem type has different formulation and methods of measurement within the scope of efficiency and effectiveness performance. One of the most decisive verdicts for the effectiveness measure is the statistical analysis that depends on the data distribution and appropriate tool for correct judgments.},
  archive      = {J_AIR},
  author       = {Halim, A. Hanif and Ismail, I. and Das, Swagatam},
  doi          = {10.1007/s10462-020-09906-6},
  journal      = {Artificial Intelligence Review},
  number       = {3},
  pages        = {2323-2409},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Performance assessment of the metaheuristic optimization algorithms: An exhaustive review},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A survey on video-based human action recognition: Recent
updates, datasets, challenges, and applications. <em>AIR</em>,
<em>54</em>(3), 2259–2322. (<a
href="https://doi.org/10.1007/s10462-020-09904-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human Action Recognition (HAR) involves human activity monitoring task in different areas of medical, education, entertainment, visual surveillance, video retrieval, as well as abnormal activity identification, to name a few. Due to an increase in the usage of cameras, automated systems are in demand for the classification of such activities using computationally intelligent techniques such as Machine Learning (ML) and Deep Learning (DL). In this survey, we have discussed various ML and DL techniques for HAR for the years 2011–2019. The paper discusses the characteristics of public datasets used for HAR. It also presents a survey of various action recognition techniques along with the HAR applications namely, content-based video summarization, human–computer interaction, education, healthcare, video surveillance, abnormal activity detection, sports, and entertainment. The advantages and disadvantages of action representation, dimensionality reduction, and action analysis methods are also provided. The paper discusses challenges and future directions for HAR.},
  archive      = {J_AIR},
  author       = {Pareek, Preksha and Thakkar, Ankit},
  doi          = {10.1007/s10462-020-09904-8},
  journal      = {Artificial Intelligence Review},
  number       = {3},
  pages        = {2259-2322},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A survey on video-based human action recognition: Recent updates, datasets, challenges, and applications},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Virtual machine placement in cloud data centers using a
hybrid multi-verse optimization algorithm. <em>AIR</em>, <em>54</em>(3),
2221–2257. (<a
href="https://doi.org/10.1007/s10462-020-09903-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cloud computing is a computing paradigm, where a large pool of systems is connected in private or public networks to provide dynamically scalable infrastructure for application, data, and file storage. With the advent of this technology, the cost of power computation, application hosting, content storage, resource wastage, and delivery is reduced significantly. Cloud computing provides the possibility of merely concentrating on business goals instead of expanding hardware resources for users. Challenging work in virtualization technology is the placement of virtual machines under optimal conditions on physical machines in cloud data centers. Optimal placement of virtual machines over physical ones in cloud data centers can lead to the management of resources and prevention of the resources waste. Hereby, a new approach is proposed based on the combination of the hybrid discrete multi-object whale optimization algorithm, multi-verse optimizer with chaotic functions for optimal placement in the cloud data center. The first object of the proposed algorithm is to decrease power consumption, which is consumed in cloud data centers by reducing active physical machines. The second goal is to cut the resource wastage and managing resources using the optimal placement of virtual machines over physical machines in cloud data centers. With this method, the increasing rate of virtual migration to physical machines is prevented. Finally, the results obtained from the proposed algorithm were compared to some algorithms such as first fit, VMPACS, MBFD.},
  archive      = {J_AIR},
  author       = {Gharehpasha, Sasan and Masdari, Mohammad and Jafarian, Ahmad},
  doi          = {10.1007/s10462-020-09903-9},
  journal      = {Artificial Intelligence Review},
  number       = {3},
  pages        = {2221-2257},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Virtual machine placement in cloud data centers using a hybrid multi-verse optimization algorithm},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). When artificial intelligence meets building energy
efficiency, a review focusing on zero energy building. <em>AIR</em>,
<em>54</em>(3), 2193–2220. (<a
href="https://doi.org/10.1007/s10462-020-09902-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Building energy efficiency, as a traditional field which has been existing for decades performs a prosperous needs with diversity of corresponding methods. In the flow of artificial intelligence (AI) background, where does the building energy efficiency advance and how does it emphasize? This question seems to become more significant with the blueprints of zero energy building implementation issued by many countries. The major objective of this research is to review, analyze and identify the performance of AI based applications in buildings, especially for building energy efficiency and zero energy building. Based on the present research trends, the possible changes AI based approach brings to related laws, regulations and standards are firstly analyzed. The main aspects of the AI based approach infrastructure in buildings is thoroughly reviewed and compared. IoT based sensor applications for thermal comfort, platforms and algorithms for building multi energies control, and forecasting methods for building load, subsystem performance and structure safety are summarized. To provide more optimal references for zero energy building solutions, the AI based approach in zero energy building is then predicted in detail, with particular analysis of occupant presence and behaviors. Finally, the future directions of the research on AI based applications for zero energy building implementation are summarized.},
  archive      = {J_AIR},
  author       = {Yan, Biao and Hao, Fei and Meng, Xi},
  doi          = {10.1007/s10462-020-09902-w},
  journal      = {Artificial Intelligence Review},
  number       = {3},
  pages        = {2193-2220},
  shortjournal = {Artif. Intell. Rev.},
  title        = {When artificial intelligence meets building energy efficiency, a review focusing on zero energy building},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Methodological aspects for cognitive architectures
construction: A study and proposal. <em>AIR</em>, <em>54</em>(3),
2133–2192. (<a
href="https://doi.org/10.1007/s10462-020-09901-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the field of Artificial Intelligence (AI), efforts to achieve human-like behavior have taken very different paths through time. Cognitive Architectures (CAs) differentiate from traditional AI approaches, due to their intention to model cognitive and behavioral processes by understanding the brain’s structure and their functionalities in a natural way. However, the development of distinct CAs has not been easy, mainly because there is no consensus on the theoretical basis, assumptions or even purposes for their creation nor how well they reflect human function. In consequence, there is limited information about the methodological aspects to construct this type of models. To address this issue, some initial statements are established to contextualize about the origins and directions of cognitive architectures and their development, which help to outline perspectives, approaches and objectives of this work, supported by a brief study of methodological strategies and historical aspects taken by some of the most relevant architectures to propose a methodology which covers general perspectives for the construction of CAs. This proposal is intended to be flexible, focused on use-case tasks, but also directed by theoretic paradigms or manifestos. A case study between cognitive functions is then detailed, using visual perception and working memory to exemplify the proposal’s assumptions, postulates and binding tools, from their meta-architectural conceptions to validation. Finally, the discussion addresses the challenges found at this stage of development and future work directions.},
  archive      = {J_AIR},
  author       = {Jiménez, Juan P. and Martin, Luis and Dounce, Iván Axel and Ávila-Contreras, Cynthia and Ramos, Félix},
  doi          = {10.1007/s10462-020-09901-x},
  journal      = {Artificial Intelligence Review},
  number       = {3},
  pages        = {2133-2192},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Methodological aspects for cognitive architectures construction: A study and proposal},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Consensus-based robust decision making methods under a novel
study of probabilistic uncertain linguistic information and their
application in forex investment. <em>AIR</em>, <em>54</em>(3),
2091–2132. (<a
href="https://doi.org/10.1007/s10462-020-09900-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The probabilistic uncertain linguistic terms set (PULTS) is an effective tool to depict uncertain linguistic opinions of individuals or groups in the procedure of decision making. Motivated by the power of PULTS and the linguistic scale function, this study aims to propose robust techniques to solve multi-attribute group decision making problems with uncertain linguistic evaluations. To enrich calculation and enhance the flexibility of PULTS, we first generalize the aggregation formula to fuse opinions of decision makers represented as PULTSs and secondly derive adjusting rule of probability to adjust the probability distribution of two or more than two probabilistic uncertain elements (PULEs) into the same probability distribution. Novel operations of PULTSs are designed based on the adjusting rule of probability distribution and linguistic scale function for the semantics of linguistic terms. Many related properties of these operations are also discussed. New score function and deviation degree of PULEs are also developed to compare PULEs. Two aggregation operators i.e., probabilistic uncertain linguistic averaging (PULWA) operator and probabilistic uncertain linguistic geometric (PULWG) operator are also redefined in terms of novel operations. In addition, a series of distance measure is defined to overcome the shortcomings of existing ones. After defining a correlation measure, the probabilistic uncertain linguistic (PUL)-consensus reaching method (in which two specific consensus approaches are described separately) is put forward to refine the consensus level of a group. To suit the needs of different semantics, two robust decision making methods named as consensus-based PUL-gained and lost dominance score method and consensus-based PUL-aggregation method are proposed. Finally, a case study concerning the selection of the best commodity for investment in Forex is conducted to illustrate the practicality of the proposed methods. Lastly, a detailed comparative analysis is done with the existing technique to highlight the improvements and advantages of proposed work.},
  archive      = {J_AIR},
  author       = {Bashir, Zia and Ali, Jawad and Rashid, Tabasam},
  doi          = {10.1007/s10462-020-09900-y},
  journal      = {Artificial Intelligence Review},
  number       = {3},
  pages        = {2091-2132},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Consensus-based robust decision making methods under a novel study of probabilistic uncertain linguistic information and their application in forex investment},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Hierarchical classification with multi-path selection based
on granular computing. <em>AIR</em>, <em>54</em>(3), 2067–2089. (<a
href="https://doi.org/10.1007/s10462-020-09899-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hierarchical classification is a research hotspot in machine learning due to the widespread existence of data with hierarchical class structures. Existing hierarchical classification methods based on granular computing can effectively reduce the computational complexity by considering the granularity of classes. However, their predictive accuracy is affected by inter-level error propagation within the hierarchy. In this paper, we propose a hierarchical classification method with multi-path selection based on coarse- and fine-grained class relationships, which mitigates the inter-level error propagation problem. Firstly, we use a top-down recursive method to calculate the probabilities of the hierarchical classes by logistic regression classification. Secondly, the current class probability is calculated by combining the parent and current classes probabilities. We select multiple possible fine-grained classes at the current level according to their sibling relationships. Compared with existing methods, the proposed method reduces the possibility of misclassification from the upper layer. Finally, the multi-path prediction result is provided to a classical classifier for final prediction. Our hierarchical classification method is evaluated on six benchmark datasets to demonstrate that it provides better classification performance than existing state-of-the-art hierarchical methods.},
  archive      = {J_AIR},
  author       = {Guo, Shunxin and Zhao, Hong},
  doi          = {10.1007/s10462-020-09899-2},
  journal      = {Artificial Intelligence Review},
  number       = {3},
  pages        = {2067-2089},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Hierarchical classification with multi-path selection based on granular computing},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A survey of attack detection approaches in collaborative
filtering recommender systems. <em>AIR</em>, <em>54</em>(3), 2011–2066.
(<a href="https://doi.org/10.1007/s10462-020-09898-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, due to the increasing amount of data, the use of recommender systems has increased. Therefore, the quality of the recommendations for the users of these systems is very important. One of the recommender systems models is collaborative filtering (CF) which uses the ratings given by the users to the items. But many of these ratings may be noisy or inaccurate so they reduce the quality of the recommendations. Sometimes users, using fake profiles, try to change the recommendations in their favor. Since satisfaction and trust in such systems are very important and useful, it would be better to find a way to identify these types of users. Despite numerous studies on CF recommender systems, the design of a robust recommender system is still a challenging problem. In this paper, we have analyzed the 25 previous samples of research on collaborative filtering recommender system (CFRS) for attack detection from 2009 to 2019. Most of these papers focus mainly on movie recommendations. According to these analyzes, we have categorized attack detection methods on CFRS in four categories: clustering, classifying, feature extraction and probabilistic approaches. The evaluation measures, the dataset, and attacks features used in the attack detection approaches are discussed.},
  archive      = {J_AIR},
  author       = {Rezaimehr, Fatemeh and Dadkhah, Chitra},
  doi          = {10.1007/s10462-020-09898-3},
  journal      = {Artificial Intelligence Review},
  number       = {3},
  pages        = {2011-2066},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A survey of attack detection approaches in collaborative filtering recommender systems},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Persistence codebooks for topological data analysis.
<em>AIR</em>, <em>54</em>(3), 1969–2009. (<a
href="https://doi.org/10.1007/s10462-020-09897-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Persistent homology is a rigorous mathematical theory that provides a robust descriptor of data in the form of persistence diagrams (PDs) which are 2D multisets of points. Their variable size makes them, however, difficult to combine with typical machine learning workflows. In this paper we introduce persistence codebooks, a novel expressive and discriminative fixed-size vectorized representation of PDs that adapts to the inherent sparsity of persistence diagrams. To this end, we adapt bag-of-words, vectors of locally aggregated descriptors and Fischer vectors for the quantization of PDs. Persistence codebooks represent PDs in a convenient way for machine learning and statistical analysis and have a number of favorable practical and theoretical properties including 1-Wasserstein stability. We evaluate the presented representations on several heterogeneous datasets and show their (high) discriminative power. Our approach yields comparable—and partly even higher—performance in much less time than alternative approaches.},
  archive      = {J_AIR},
  author       = {Zieliński, Bartosz and Lipiński, Michał and Juda, Mateusz and Zeppelzauer, Matthias and Dłotko, Paweł},
  doi          = {10.1007/s10462-020-09897-4},
  journal      = {Artificial Intelligence Review},
  number       = {3},
  pages        = {1969-2009},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Persistence codebooks for topological data analysis},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A comparative analysis of gradient boosting algorithms.
<em>AIR</em>, <em>54</em>(3), 1937–1967. (<a
href="https://doi.org/10.1007/s10462-020-09896-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The family of gradient boosting algorithms has been recently extended with several interesting proposals (i.e. XGBoost, LightGBM and CatBoost) that focus on both speed and accuracy. XGBoost is a scalable ensemble technique that has demonstrated to be a reliable and efficient machine learning challenge solver. LightGBM is an accurate model focused on providing extremely fast training performance using selective sampling of high gradient instances. CatBoost modifies the computation of gradients to avoid the prediction shift in order to improve the accuracy of the model. This work proposes a practical analysis of how these novel variants of gradient boosting work in terms of training speed, generalization performance and hyper-parameter setup. In addition, a comprehensive comparison between XGBoost, LightGBM, CatBoost, random forests and gradient boosting has been performed using carefully tuned models as well as using their default settings. The results of this comparison indicate that CatBoost obtains the best results in generalization accuracy and AUC in the studied datasets although the differences are small. LightGBM is the fastest of all methods but not the most accurate. Finally, XGBoost places second both in accuracy and in training speed. Finally an extensive analysis of the effect of hyper-parameter tuning in XGBoost, LightGBM and CatBoost is carried out using two novel proposed tools.},
  archive      = {J_AIR},
  author       = {Bentéjac, Candice and Csörgő, Anna and Martínez-Muñoz, Gonzalo},
  doi          = {10.1007/s10462-020-09896-5},
  journal      = {Artificial Intelligence Review},
  number       = {3},
  pages        = {1937-1967},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A comparative analysis of gradient boosting algorithms},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). On the evaluation and combination of state-of-the-art
features in twitter sentiment analysis. <em>AIR</em>, <em>54</em>(3),
1887–1936. (<a
href="https://doi.org/10.1007/s10462-020-09895-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sentiment analysis of short informal texts, such as tweets, remains a challenging task due to their particular characteristics. Much effort has been made in the literature of Twitter sentiment analysis to achieve an effective and efficient representation of tweets. In this context, distinct types of features have been proposed and employed, from the simple n-gram representation to meta-features to word embeddings. Hence, in this work, using a relevant set of twenty-two datasets of tweets, we present a thorough evaluation of features by means of different supervised learning algorithms. We evaluate not only a rich set of meta-features examined in state-of-the-art studies, but also a significant collection of pre-trained word embedding models. Also, we evaluate and analyze the effect of combining those distinct types of features in order to detect which combination may provide core information in the polarity detection task in Twitter sentiment analysis. For this purpose, we exploit different strategies for combination, such as feature concatenation and ensemble learning techniques, and show that the sentiment detection of tweets benefits from combining different types of features proposed in the literature.},
  archive      = {J_AIR},
  author       = {Carvalho, Jonnathan and Plastino, Alexandre},
  doi          = {10.1007/s10462-020-09895-6},
  journal      = {Artificial Intelligence Review},
  number       = {3},
  pages        = {1887-1936},
  shortjournal = {Artif. Intell. Rev.},
  title        = {On the evaluation and combination of state-of-the-art features in twitter sentiment analysis},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Genetic programming in civil engineering: Advent,
applications and future trends. <em>AIR</em>, <em>54</em>(3), 1863–1885.
(<a href="https://doi.org/10.1007/s10462-020-09894-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Over the past two decades, machine learning has been gaining significant attention for solving complex engineering problems. Genetic programing (GP) is an advanced framework that can be used for a variety of machine learning tasks. GP searches a program space instead of a data space without a need to pre-defined models. This method generates transparent solutions that can be easily deployed for practical civil engineering applications. GP is establishing itself as a robust intelligent technique to solve complicated civil engineering problems. This paper provides a review of the GP technique and its applications in the civil engineering arena over the last decade. We discuss the features of GP and its variants followed by their potential for solving various civil engineering problems. We finally envision the potential research avenues and emerging trends for the application of GP in civil engineering.},
  archive      = {J_AIR},
  author       = {Zhang, Qianyun and Barri, Kaveh and Jiao, Pengcheng and Salehi, Hadi and Alavi, Amir H.},
  doi          = {10.1007/s10462-020-09894-7},
  journal      = {Artificial Intelligence Review},
  number       = {3},
  pages        = {1863-1885},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Genetic programming in civil engineering: Advent, applications and future trends},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Nature inspired optimization algorithms or simply variations
of metaheuristics? <em>AIR</em>, <em>54</em>(3), 1841–1862. (<a
href="https://doi.org/10.1007/s10462-020-09893-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the last decade, we observe an increasing number of nature-inspired optimization algorithms, with authors often claiming their novelty and their capabilities of acting as powerful optimization techniques. However, a considerable number of these algorithms do not seem to draw inspiration from nature or to incorporate successful tactics, laws, or practices existing in natural systems, while also some of them have never been applied in any optimization field, since their first appearance in literature. This paper presents some interesting findings that have emerged after the extensive study of most of the existing nature-inspired algorithms. The need for irrationally introducing new nature inspired intelligent (NII) algorithms in literature is also questioned and possible drawbacks of NII algorithms met in literature are discussed. In addition, guidelines for the development of new nature-inspired algorithms are proposed, in an attempt to limit the misleading appearance of variation of metaheuristics as nature inspired optimization algorithms.},
  archive      = {J_AIR},
  author       = {Tzanetos, Alexandros and Dounias, Georgios},
  doi          = {10.1007/s10462-020-09893-8},
  journal      = {Artificial Intelligence Review},
  number       = {3},
  pages        = {1841-1862},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Nature inspired optimization algorithms or simply variations of metaheuristics?},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An association between fingerprint patterns with blood group
and lifestyle based diseases: A review. <em>AIR</em>, <em>54</em>(3),
1803–1839. (<a
href="https://doi.org/10.1007/s10462-020-09891-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the current era of the digital world, the hash of any digital means considered as a footprint or fingerprint of any digital term but from the ancient era, human fingerprint considered as the most trustworthy criteria for identification and it also cannot be changed with time even up to the death of an individual. In the court of law, fingerprint-proof is undeniably the most dependable and acceptable evidence to date. Fingerprint designs are exclusive in each human and the chance of two individuals having identical fingerprints is an exceptional case about one in sixty-four thousand million also the fingerprint minutiae patterns of the undistinguishable twins are different, and the ridge pattern of each fingertip remain unchanged from birth to till death. Fingerprints can be divided into basic four categories i.e. Loop, whorl, arch, and composites, nevertheless, there are more than 100 interleaved ridge and valleys physiognomies, called Galton’s details, in a single rolled fingerprint. Due to the immense potential of fingerprints as an effective method of identification, the present research paper tries to investigate the problem of blood group identification and analysis of diseases those arises with aging like hypertension, type 2-diabetes and arthritis from a fingerprint by analyzing their patterns correlation with blood group and age of an individual. The work has been driven by studies of anthropometry, biometric trademark, and pattern recognition proposing that it is possible to predict blood group using fingerprint map reading. Dermatoglyphics as a diagnostic aid used from ancient eras and now it is well established in number of diseases which have strong hereditary basis and is employed as a method for screening for abnormal anomalies. Apart from its use in predicting the diagnosis of disease; dermatoglyphics is also used in forensic medicine in individual identification, physical anthropology, human genetics and medicine. However, the Machine and Deep Learning techniques, if used for fingerprint minutiae patterns to be trained by Neural Network for blood group prediction and classification of common clinical diseases arises with aging based on lifestyle would be an unusual research work.},
  archive      = {J_AIR},
  author       = {Patil, Vijaykumar and Ingle, D. R.},
  doi          = {10.1007/s10462-020-09891-w},
  journal      = {Artificial Intelligence Review},
  number       = {3},
  pages        = {1803-1839},
  shortjournal = {Artif. Intell. Rev.},
  title        = {An association between fingerprint patterns with blood group and lifestyle based diseases: A review},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Electric charged particles optimization and its application
to the optimal design of a circular antenna array. <em>AIR</em>,
<em>54</em>(3), 1767–1802. (<a
href="https://doi.org/10.1007/s10462-020-09890-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a new metaheuristic, Electric Charged Particles Optimization (ECPO) algorithm, is developed. This algorithm is inspired by the interaction (forces exerted) between electric charged particles. It this algorithm not all the particles interact with each other, only selected ones. Then the way they interact with each other is defined by the selected strategy among the three available strategies. Therefore, there are several combinations possible between the number of interacting particles and strategies to find the most suitable one for the problem in hand which will help the algorithm to solve a wide range of optimization problems. The performance of the developed algorithm is first tested on the set of problems used for single objective real parameter algorithm competition that was held in the congress on evolutionary computation 2014. Then, the ECPO has been applied to optimal design of circular antenna array for sidelobe level reduction. The obtained results are then compared with other well-known metaheuristics using statistical tools. The analysis of the experimental results shows that the ECPO is a very competitive optimization algorithm.},
  archive      = {J_AIR},
  author       = {Bouchekara, H. R. E. H.},
  doi          = {10.1007/s10462-020-09890-x},
  journal      = {Artificial Intelligence Review},
  number       = {3},
  pages        = {1767-1802},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Electric charged particles optimization and its application to the optimal design of a circular antenna array},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Joint feature and instance selection using manifold data
criteria: Application to image classification. <em>AIR</em>,
<em>54</em>(3), 1735–1765. (<a
href="https://doi.org/10.1007/s10462-020-09889-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In many pattern recognition applications feature selection and instance selection can be used as two data preprocessing methods that aim at reducing the computational cost of the learning process. Moreover, in some cases, feature subset selection can improve the classification performance. Feature selection and instance selection can be interesting since the choice of features and instances greatly influence the performance of the learnt models as well as their training costs. In the past, unifying both problems was carried out by solving a global optimization problem using meta-heuristics. This paradigm not only does not exploit the manifold structure of data but can be computationally expensive. To the best of our knowledge, the joint use of sparse modeling representative and feature subset relevance have not been exploited by the joint feature and selection methods. In this paper, we target the joint feature and instance selection by adopting feature subset relevance and sparse modeling representative selection. More precisely, we propose three schemes for the joint feature and instance selection. The first is a wrapper technique while the two remaining ones are filter approaches. In the filter approaches, the search process adopts a genetic algorithm in which the evaluation is mainly given by a score that quantify the goodness of the features and instances. An efficient instance selection technique is used and integrated in the search process in order to adapt the instances to the candidate feature subset. We evaluate the performance of the proposed schemes using image classification where classifiers are the nearest neighbor classifier and support vector machine classifier. The study is conducted on five public image datasets. These experiments show the superiority of the proposed schemes over various baselines. The results confirm that the filter approaches leads to promising improvement on classification accuracy when both feature selection and instance selection are adopted.},
  archive      = {J_AIR},
  author       = {Dornaika, Fadi},
  doi          = {10.1007/s10462-020-09889-4},
  journal      = {Artificial Intelligence Review},
  number       = {3},
  pages        = {1735-1765},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Joint feature and instance selection using manifold data criteria: Application to image classification},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Vision-based robotic grasping from object localization,
object pose estimation to grasp estimation for parallel grippers: A
review. <em>AIR</em>, <em>54</em>(3), 1677–1734. (<a
href="https://doi.org/10.1007/s10462-020-09888-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a comprehensive survey on vision-based robotic grasping. We conclude three key tasks during vision-based robotic grasping, which are object localization, object pose estimation and grasp estimation. In detail, the object localization task contains object localization without classification, object detection and object instance segmentation. This task provides the regions of the target object in the input data. The object pose estimation task mainly refers to estimating the 6D object pose and includes correspondence-based methods, template-based methods and voting-based methods, which affords the generation of grasp poses for known objects. The grasp estimation task includes 2D planar grasp methods and 6DoF grasp methods, where the former is constrained to grasp from one direction. These three tasks could accomplish the robotic grasping with different combinations. Lots of object pose estimation methods need not object localization, and they conduct object localization and object pose estimation jointly. Lots of grasp estimation methods need not object localization and object pose estimation, and they conduct grasp estimation in an end-to-end manner. Both traditional methods and latest deep learning-based methods based on the RGB-D image inputs are reviewed elaborately in this survey. Related datasets and comparisons between state-of-the-art methods are summarized as well. In addition, challenges about vision-based robotic grasping and future directions in addressing these challenges are also pointed out.},
  archive      = {J_AIR},
  author       = {Du, Guoguang and Wang, Kai and Lian, Shiguo and Zhao, Kaiyong},
  doi          = {10.1007/s10462-020-09888-5},
  journal      = {Artificial Intelligence Review},
  number       = {3},
  pages        = {1677-1734},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Vision-based robotic grasping from object localization, object pose estimation to grasp estimation for parallel grippers: A review},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Interval valued m-polar fuzzy planar graph and its
application. <em>AIR</em>, <em>54</em>(3), 1649–1675. (<a
href="https://doi.org/10.1007/s10462-020-09879-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, a new idea of interval-valued m-polar fuzzy (IVmPF) graph is introduced and investigated some of it’s properties. Here, IVmPF multiset, interval-valued m-polar fuzzy (IVmPF) multi graph are presented. IVmPF planar value of an interval-valued m-polar fuzzy (IVmPF) planar graph along with degree of planarity value is also introduced to measure the planarity value of an interval-valued m-polar fuzzy (IVmPF) graph. Some related terms like complete IVmPF graph, strong IVmPF graph, strong edges, faces of IVmPF planar graph are presented. In this paper, IVmPF dual graph is also described which is closely related to IVmPF planar graph. Some important properties are studied on IVmPF dual graph. Lastly, a real life application on IVmPF planar graph has been discussed to show its practicability.},
  archive      = {J_AIR},
  author       = {Mahapatra, Tanmoy and Sahoo, Sankar and Ghorai, Ganesh and Pal, Madhumangal},
  doi          = {10.1007/s10462-020-09879-6},
  journal      = {Artificial Intelligence Review},
  number       = {3},
  pages        = {1649-1675},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Interval valued m-polar fuzzy planar graph and its application},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A new approach for the detection of abnormal heart sound
signals using TQWT, VMD and neural networks. <em>AIR</em>,
<em>54</em>(3), 1613–1647. (<a
href="https://doi.org/10.1007/s10462-020-09875-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Phonocardiogram (PCG) plays an important role in evaluating many cardiac abnormalities, such as the valvular heart disease, congestive heart failure and anatomical defects of the heart. However, effective cardiac auscultation requires trained physicians whose work is tough, laborious and subjective. The objective of this study is to develop an automatic classification method for anomaly (normal vs. abnormal) detection of PCG recordings without any segmentation of heart sound signals. Hybrid signal processing and artificial intelligence tools, including tunable Q-factor wavelet transform (TQWT), variational mode decomposition (VMD), phase space reconstruction (PSR) and neural networks, are utilized to extract representative features in order to model, identify and detect abnormal patterns in the dynamics of PCG system caused by heart disease. First, heart sound signal is decomposed into a set of frequency subbands with a number of decomposition levels by using the TQWT method. Second, VMD is employed to decompose the subband of the heart sound signal into different intrinsic modes, in which the first four intrinsic modes contain the majority of the heart sound signal’s energy and are considered to be the predominant intrinsic modes. They are selected to construct the reference variable for analysis. Third, phase space of the reference variable is reconstructed, in which the properties associated with the nonlinear PCG system dynamics are preserved. Three-dimensional PSR together with Euclidean distance has been utilized to derive features, which demonstrate significant difference in PCG system dynamics between normal and abnormal heart sound signals. Finally, PhysioNet/CinC Challenge heart sound database is used for evaluation and the synthetic minority over-sampling technique method is applied to balance the datasets. By using the 10-fold cross-validation style, experimental results demonstrate that the proposed features with dynamical neural networks based classifier yield classification performance with sensitivity, specificity, overall score and accuracy values of 97.73 $$\%$$ , 98.05 $$\%$$ , 97.89 $$\%$$ , and 97.89 $$\%$$ , respectively. The results verify the effectiveness of the proposed method which can serve as a potential candidate for the automatic anomaly detection in the clinical application.},
  archive      = {J_AIR},
  author       = {Zeng, Wei and Yuan, Jian and Yuan, Chengzhi and Wang, Qinghui and Liu, Fenglin and Wang, Ying},
  doi          = {10.1007/s10462-020-09875-w},
  journal      = {Artificial Intelligence Review},
  number       = {3},
  pages        = {1613-1647},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A new approach for the detection of abnormal heart sound signals using TQWT, VMD and neural networks},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A texture feature based approach for person verification
using footprint bio-metric. <em>AIR</em>, <em>54</em>(2), 1581–1611. (<a
href="https://doi.org/10.1007/s10462-020-09887-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Biometrics is the study of unique characteristics present in the human body such as fingerprint, palm-print, retina, iris, footprint, etc. While other traits have been explored widely, only a few people have been considered the foot-palm region, despite having unique properties. Prior work has explored the foot shape features using length, width, major axis, minor axis, centroid, etc. but they are not reliable for personal verification due to similarity in the physical composition of two persons. It increases the demand for more unique features based on the footprint. Footprint texture features coming from creases of foot palm are unique and permanent like palmprint texture features. Hence the main objective of the paper is to investigate various kinds of texture feature techniques. These techniques will be further used in correct extraction of footprint features. After extraction of footprint features a detailed experimental analysis is performed to discover the uniqueness in foot texture. It is further utilized to test its viability as a human recognition trait. We describe a detailed feature extraction and classification technique applied to a collected footprint data-set. For feature extraction, we use three techniques: Gray Level Co-occurrence Matrix (GLCM), Histogram Oriented Gradient (HOG), and Local Binary Patterns (LBP). Feature classification is performed using four techniques: Linear Discriminant Analysis (LDA), Support Vector Machine (SVM), K-Nearest Neighbor (KNN), and Ensemble Subspace Discriminant (ESD). GLCM provides less accuracy, while HOG generates a big feature vector which takes more execution time. LBP provides a trade-off between the accuracy and the execution time. Detailed quantitative experiments show: GLCM with LDA provides an accuracy of $$88.5\%$$ , HOG with Fine-KNN achieves $$86.5\%$$ accuracy and LBP with LDA achieves the accuracy of $$97.9\%$$ .},
  archive      = {J_AIR},
  author       = {Kushwaha, Riti and Singal, Gaurav and Nain, Neeta},
  doi          = {10.1007/s10462-020-09887-6},
  journal      = {Artificial Intelligence Review},
  number       = {2},
  pages        = {1581-1611},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A texture feature based approach for person verification using footprint bio-metric},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Online handwriting recognition systems for indic and
non-indic scripts: A review. <em>AIR</em>, <em>54</em>(2), 1525–1579.
(<a href="https://doi.org/10.1007/s10462-020-09886-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Handwriting recognition is one of the challenging tasks in the area of pattern recognition and machine learning. Handwriting recognition has two flavors, namely, Offline Handwriting Recognition and Online Handwriting Recognition. Though, saturation level has been achieved in machine printed (Offline) character recognition. Presently, due to dramatical development in IT sector, touch-based devices are available in the market with efficient processing capabilities. With this revolution, research in the area of handwriting recognition has become more popular in real-time (Online) mode. In this paper, a comprehensive review has been reported for online handwriting recognition of non-Indic and Indic scripts. The six non-Indic-scripts and eight Indic script namely, Arabic, Chinese, Japanese, Persian, Roman, Thai, and, Assamese, Bangla, Devanagari, Gurmukhi, Kannada, Malayalam, Tamil, Telugu, respectively have been considered in this article. This study comprises introduction of online handwriting recognition process, various challenges, motivations, feature extraction, and classification methodologies, used for recognizing the various scripting languages. Moreover, an effort has been made to provide the list of publicly available online handwritten dataset for various scripting languages. This study also provides the recognition and beneficial assistance to the novice researchers in field of handwriting recognition by providing a nut shell studies of various feature extraction strategies and classification techniques, used for the recognition of both Indic and non-Indic scripts.},
  archive      = {J_AIR},
  author       = {Singh, Harjeet and Sharma, R. K. and Singh, V. P.},
  doi          = {10.1007/s10462-020-09886-7},
  journal      = {Artificial Intelligence Review},
  number       = {2},
  pages        = {1525-1579},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Online handwriting recognition systems for indic and non-indic scripts: A review},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Artificial intelligence based on fuzzy logic for the
analysis of human movement in healthy people: A systematic review.
<em>AIR</em>, <em>54</em>(2), 1507–1523. (<a
href="https://doi.org/10.1007/s10462-020-09885-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Technological advances that involve computing and artificial intelligence (AI) have led to advances in analysis methods. Fuzzy logic (FL) serves as a qualitative interpretation tool for AI. The objective of this systematic review is to investigate the methods of human movement (HM) analysis using AI through FL to understand the characteristics of the movement of healthy people. To identify relevant studies published up to April 19, 2019, we conducted a study of the PubMed, Scopus, ScienceDirect, and IEEE Xplore databases. We included studies that evaluated HM through AI using FL in healthy people. A total of 951 articles were examined, of which six were selected because they met the criteria presented in the methods. The protocols had high heterogeneity, yet all articles selected presented statistically satisfactory results, in addition to low errors or a false positive index. Only one selected article presented protocol applicability within the free-living model. Generally, AI using FL is a good tool to help assess HM in healthy people, but the model still needs new data acquisition entries to make it applicability within the free-living model.},
  archive      = {J_AIR},
  author       = {Lima, Bráulio Nascimento and Balducci, Pietro and Passos, Ricardo Pablo and Novelli, Claudio and Fileni, Carlos Henrique Prevital and Vieira, Fábio and Camargo, Leandro Borelli de and Vilela Junior, Guanis de Barros},
  doi          = {10.1007/s10462-020-09885-8},
  journal      = {Artificial Intelligence Review},
  number       = {2},
  pages        = {1507-1523},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Artificial intelligence based on fuzzy logic for the analysis of human movement in healthy people: A systematic review},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). 360 degree view of cross-domain opinion classification: A
survey. <em>AIR</em>, <em>54</em>(2), 1385–1506. (<a
href="https://doi.org/10.1007/s10462-020-09884-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the field of natural language processing and text mining, sentiment analysis (SA) has received huge attention from various researchers’ across the globe. By the prevalence of Web 2.0, user’s became more vigilant to share, promote and express themselves along with any issues or challenges that are being encountered on daily activities through the Internet (social media, micro-blogs, e-commerce, etc.) Expression and opinion are a complex sequence of acts that convey a huge volume of data that pose a challenge for computational researchers to decode. Over the period of time, researchers from various segments of public and private sectors are involved in the exploration of SA with an aim to understand the behavioral perspective of various stakeholders in society. Though the efforts to positively construct SA are successful, challenges still prevail for efficiency. This article presents an organized survey of SA (also known as opinion mining) along with methodologies or algorithms. The survey classifies SA into categories based on levels, tasks, and sub-task along with various techniques used for performing them. The survey explicitly focuses on different directions in which the research was explored in the area of cross-domain opinion classification. The article is concluded with an objective to present an exclusive and exhaustive analysis in the area of opinion mining containing approaches, datasets, languages, and applications used. The observations made are expected to support researches to get a greater understanding on emerging trends and state-of-the-art methods to be applied for future exploration.},
  archive      = {J_AIR},
  author       = {Singh, Rahul Kumar and Sachan, Manoj Kumar and Patel, R. B.},
  doi          = {10.1007/s10462-020-09884-9},
  journal      = {Artificial Intelligence Review},
  number       = {2},
  pages        = {1385-1506},
  shortjournal = {Artif. Intell. Rev.},
  title        = {360 degree view of cross-domain opinion classification: A survey},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Risk assessment in discrete production processes considering
uncertainty and reliability: Z-number multi-stage fuzzy cognitive map
with fuzzy learning algorithm. <em>AIR</em>, <em>54</em>(2), 1349–1383.
(<a href="https://doi.org/10.1007/s10462-020-09883-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Failure Mode and Effects Analysis (FMEA) technique due to its proactive nature can identify failures and their causes as well as potential effects, and provide preventive/controlling measures before they occur. Nevertheless, some of the shortcomings of the FMEA technique like lack of a mental framework for considering the relationships between risks, lack of systematic perspective in confronting with risks, and weakness of Risk Priority Number (RPN) score in mathematical basis and disregarding the uncertainty of problem reduce the reliability of the outputs. In this study, an approach based on the Multi-Stage Fuzzy Cognitive Map and the Z-number theory (Z-MSFCM) is proposed to simultaneously consider the concept of uncertainty and reliability in quantities of risk factors and the weights of causal relationships in the MSFCM. Besides, a novel learning approach for Z-MSFCM has been applied based on the combination of the Particle Swarm Optimization (PSO) and S-shaped transfer function (PSO-STF) to preserve the uncertain environment of the problem. The proposed approach has been applied in a manufacturing automotive parts company and results indicate that: first, Z-MSFCM by considering the causal relationships between risks and their uncertainty and reliability in comparison with traditional RPN can provide better process-oriented insight into the impact of risks on the system; and second, the PSO-STF has high potential in generating solutions with high separability compared to Nonlinear Hebbian Learning and PSO algorithms. To put it differently, the mentioned advantages of the proposed approach can help decision-makers to analyze the problem with high reliability.},
  archive      = {J_AIR},
  author       = {Abbaspour Onari, Mohsen and Yousefi, Samuel and Jahangoshai Rezaee, Mustafa},
  doi          = {10.1007/s10462-020-09883-w},
  journal      = {Artificial Intelligence Review},
  number       = {2},
  pages        = {1349-1383},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Risk assessment in discrete production processes considering uncertainty and reliability: Z-number multi-stage fuzzy cognitive map with fuzzy learning algorithm},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Evolutionary computation for solving search-based data
analytics problems. <em>AIR</em>, <em>54</em>(2), 1321–1348. (<a
href="https://doi.org/10.1007/s10462-020-09882-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic extracting of knowledge from massive data samples, i.e., big data analytics (BDA), has emerged as a vital task in almost all scientific research fields. The BDA problems are rather difficult to solve due to their large-scale, high-dimensional, and dynamic properties, while the problems with small data are usually hard to handle due to insufficient data samples and incomplete information. Such difficulties lead to the search-based data analytics problem, where a data analysis task is modeled as a complex, dynamic, and computationally expensive optimization problem and then solved by using an iterative algorithm. In this paper, we intend to present an extensive and in-depth discussion on the utilizing of evolutionary computation (EC) based optimization methods [including evolutionary algorithms (EAs) and swarm intelligence (SI)] for solving search-based data analysis problems. Then, as an example for illustration, we provide a comprehensive review of the applications of state-of-the-art EC methods for different types of data mining problems in bioinformatics. Here, the detailed analysis and discussion are conducted on three types of data samples, which include sequences data, network data, and image data. Finally, we survey the challenges faced by EC methods and the trend for future directions. Based on the applications of EC methods for search-based data analysis problems involving inexact and uncertain information, the insights of data analytics are able to understand better, and more efficient algorithms could be designed to solve real-world complex BDA problems.},
  archive      = {J_AIR},
  author       = {Cheng, Shi and Ma, Lianbo and Lu, Hui and Lei, Xiujuan and Shi, Yuhui},
  doi          = {10.1007/s10462-020-09882-x},
  journal      = {Artificial Intelligence Review},
  number       = {2},
  pages        = {1321-1348},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Evolutionary computation for solving search-based data analytics problems},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). PROMETHEE II method based on variable precision fuzzy rough
sets with fuzzy neighborhoods. <em>AIR</em>, <em>54</em>(2), 1281–1319.
(<a href="https://doi.org/10.1007/s10462-020-09878-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The model of covering-based fuzzy rough sets (CFRSs) can be regarded as a hybrid one by combining covering-based rough sets with fuzzy sets. In this paper, based on fuzzy neighborhoods, we propose two types of covering-based variable precision fuzzy rough sets (CVPFRSs) via fuzzy logical operators, i.e., type-I CVPFRSs and type-II CVPFRSs. Then, several basic properties of the two types of CVPFRSs are discussed. In addition, by virtue of the idea of PROMETHEE II methods, we construct a novel method to multi-attribute decision-making (MADM) in the context of medical diagnosis based on the proposed rough approximation operators. Finally, a test example for illustrating the proposed method is given. Meanwhile, a comparative analysis and an experimental evaluation are further discussed to interpret and evaluate the effectiveness and superiority of the proposed method. The proposed rough set model not only extends the theory of CFRSs, but also provides a new perspective for MADM with fuzzy evaluation information.},
  archive      = {J_AIR},
  author       = {Jiang, Haibo and Zhan, Jianming and Chen, Degang},
  doi          = {10.1007/s10462-020-09878-7},
  journal      = {Artificial Intelligence Review},
  number       = {2},
  pages        = {1281-1319},
  shortjournal = {Artif. Intell. Rev.},
  title        = {PROMETHEE II method based on variable precision fuzzy rough sets with fuzzy neighborhoods},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A new chaotic complex map for robust video watermarking.
<em>AIR</em>, <em>54</em>(2), 1237–1280. (<a
href="https://doi.org/10.1007/s10462-020-09877-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, using a new two-dimensional complex map, a secure video watermarking system is presented. Standard analyzes have been performed to analyze a dynamical system to prove the existence of chaos in the proposed map and the results indicate a chaotic behavior in this complex chaotic map. In addition, an efficient algorithm based on IWT, DWT, and CT transforms with the participation of single value decomposition for the embedding and extraction process is introduced. The simulation results showed that the proposed algorithm has good visual quality based on criteria such as PSNR and SSIM. Geometric and non-geometric attacks were also performed on the video obtained by watermarking, and the results showed that the proposed algorithm in many attacks with a value of 1.00 for the NC criterion can be a very robust algorithm against attacks. A correlation-based process for detecting the rotational attack is also presented which makes the rotational geometric attack successfully pass. The comparison of simulation results with other similar algorithms shows that the proposed method performs better than any of these methods in terms of visual quality analysis and attack resistance and can be used as an efficient robust algorithm in applied processes.},
  archive      = {J_AIR},
  author       = {Ayubi, Peyman and Jafari Barani, Milad and Yousefi Valandar, Milad and Yosefnezhad Irani, Behzad and Sedagheh Maskan Sadigh, Reza},
  doi          = {10.1007/s10462-020-09877-8},
  journal      = {Artificial Intelligence Review},
  number       = {2},
  pages        = {1237-1280},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A new chaotic complex map for robust video watermarking},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Data stream clustering: A review. <em>AIR</em>,
<em>54</em>(2), 1201–1236. (<a
href="https://doi.org/10.1007/s10462-020-09874-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Number of connected devices is steadily increasing and these devices continuously generate data streams. Real-time processing of data streams is arousing interest despite many challenges. Clustering is one of the most suitable methods for real-time data stream processing, because it can be applied with less prior information about the data and it does not need labeled instances. However, data stream clustering differs from traditional clustering in many aspects and it has several challenging issues. Here, we provide information regarding the concepts and common characteristics of data streams, such as concept drift, data structures for data streams, time window models and outlier detection. We comprehensively review recent data stream clustering algorithms and analyze them in terms of the base clustering technique, computational complexity and clustering accuracy. A comparison of these algorithms is given along with still open problems. We indicate popular data stream repositories and datasets, stream processing tools and platforms. Open problems about data stream clustering are also discussed.},
  archive      = {J_AIR},
  author       = {Zubaroğlu, Alaettin and Atalay, Volkan},
  doi          = {10.1007/s10462-020-09874-x},
  journal      = {Artificial Intelligence Review},
  number       = {2},
  pages        = {1201-1236},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Data stream clustering: A review},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Review text based rating prediction approaches: Preference
knowledge learning, representation and utilization. <em>AIR</em>,
<em>54</em>(2), 1171–1200. (<a
href="https://doi.org/10.1007/s10462-020-09873-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Numerous rating prediction approaches have exploited users’ review texts to learn the associated preference knowledge or content semantics in order to make more accurate predictions. Such approaches either involve traditional machine learning techniques or deep learning practices to learn, extract and represent different preference knowledge such as review topics, review sentiments, linguistic aspects and feature words. With the huge number of users’ review texts on products or services and as researchers propose new rating prediction methods which utilize different preference knowledge, it’s necessary to review the methods, the acquired knowledge and how such methods make predictions. This study unveils comprehensive overview of the acquired preference knowledge and how the rating prediction approaches learn, represent and utilize such knowledge. Associated prediction methods were analyzed and presented along two perspectives: traditional machine learning; and deep learning practices. This paper not only evaluates the influence of the acquired preference knowledge in extending or regulating base methods but also identifies associated challenges in predicting ratings. Selected publications were analyzed to reveal different tactics which rating prediction approaches utilize to resolve data sparsity along with cold start problems. Finally, a discussion about possible future trends is presented. The study suggests that application of effective techniques for learning, representing and utilizing preference knowledge can improve prediction accuracy of the models. It also advocates that different combinations of the acquired preference knowledge can enhance prediction performance of the rating prediction approaches.},
  archive      = {J_AIR},
  author       = {Chambua, James and Niu, Zhendong},
  doi          = {10.1007/s10462-020-09873-y},
  journal      = {Artificial Intelligence Review},
  number       = {2},
  pages        = {1171-1200},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Review text based rating prediction approaches: Preference knowledge learning, representation and utilization},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A study on evolutionary computing based web service
selection techniques. <em>AIR</em>, <em>54</em>(2), 1117–1170. (<a
href="https://doi.org/10.1007/s10462-020-09872-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many service providers are offering their business functionality as web services. The problem of web service selection is a complex and time-consuming activity. Among other techniques, a significant work has been reported on the use of evolutionary computing based algorithms in determining optimal web service for a task. A rigorous review of the state-of-the-art for efficient selection of web services using evolutionary computing based algorithms published over the last decade is presented. The existing works on web service selection using various evolutionary approaches with a discussion on algorithmic variations, their effect on selection, quality of service parameters used, contributions, limitations and research gaps of these works are explored.},
  archive      = {J_AIR},
  author       = {Purohit, Lalit and Kumar, Sandeep},
  doi          = {10.1007/s10462-020-09872-z},
  journal      = {Artificial Intelligence Review},
  number       = {2},
  pages        = {1117-1170},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A study on evolutionary computing based web service selection techniques},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A survey of sentiment analysis in the portuguese language.
<em>AIR</em>, <em>54</em>(2), 1087–1115. (<a
href="https://doi.org/10.1007/s10462-020-09870-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sentiment analysis is an area of study that aims to develop computational methods and tools to extract and classify the opinions and emotions expressed by people on social networks, blogs, forums, online shoppings, and others. A lot of research has been developed addressing opinions expressed in the English language. However, studies involving the Portuguese language still need to be advanced to make better use of the specificities of the language. This paper aims to survey the efforts made specifically to address sentiment analysis in the Portuguese language. It categorizes and describes state of the art works involving approaches to each of the tasks of sentiment analysis, as well as supporting language resources such as natural language processing tools, lexicons, corpora, ontologies, and datasets.},
  archive      = {J_AIR},
  author       = {Pereira, Denilson Alves},
  doi          = {10.1007/s10462-020-09870-1},
  journal      = {Artificial Intelligence Review},
  number       = {2},
  pages        = {1087-1115},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A survey of sentiment analysis in the portuguese language},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Dıscrete socıal spıder algorıthm for the travelıng salesman
problem. <em>AIR</em>, <em>54</em>(2), 1063–1085. (<a
href="https://doi.org/10.1007/s10462-020-09869-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Heuristic algorithms are often used to find solutions to real complex world problems. These algorithms can provide solutions close to the global optimum at an acceptable time for optimization problems. Social Spider Algorithm (SSA) is one of the newly proposed heuristic algorithms and based on the behavior of the spider. Firstly it has been proposed to solve the continuous optimization problems. In this paper, SSA is rearranged to solve discrete optimization problems. Discrete Social Spider Algorithm (DSSA) is developed by adding explorer spiders and novice spiders in discrete search space. Thus, DSSA&#39;s exploration and exploitation capabilities are increased. The performance of the proposed DSSA is investigated on traveling salesman benchmark problems. The Traveling Salesman Problem (TSP) is one of the standard test problems used in the performance analysis of discrete optimization algorithms. DSSA has been tested on a low, middle, and large-scale thirty-eight TSP benchmark datasets. Also, DSSA is compared to eighteen well-known algorithms in the literature. Experimental results show that the performance of proposed DSSA is especially good for low and middle-scale TSP datasets. DSSA can be used as an alternative discrete algorithm for discrete optimization tasks.},
  archive      = {J_AIR},
  author       = {BAŞ, Emine and ÜLKER, Erkan},
  doi          = {10.1007/s10462-020-09869-8},
  journal      = {Artificial Intelligence Review},
  number       = {2},
  pages        = {1063-1085},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Dıscrete socıal spıder algorıthm for the travelıng salesman problem},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Bio-inspired VANET routing optimization: An overview.
<em>AIR</em>, <em>54</em>(2), 1005–1062. (<a
href="https://doi.org/10.1007/s10462-020-09868-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper demonstrates a recapitulated historic evolution further to a future overview of all vehicular ad-hoc network (VANET) routing problems that concern either directly related routing tasks or targeting a set of diverse routing-related techniques with the aid of the bio-inspired approaches. In this lecture, we serialize, in a synchronous observation, the evolution and tendencies of the VANET routing problem’s solving simultaneously with the emergence of different classes of nature-based meta-heuristics, by bringing a proposed taxonomy of different major VANET routing problems seen their nature, studied range and metaheuristic types used for their optimization. Then, we follow with a visionary deduction of the other appearing routing issues of VANETs that can be approached or already began to be solved by nature-inspired optimization algorithms. Noting that each spread routing problem is illustrated with notable related works, describing initially realized conventional protocols to vulgarize different routing modules, then detailing bio-inspired protocols for VANET routing to explain the utility of nature-inspired optimization techniques. The motivation of this work came from the lack of a reference classifying the VANET-related routing problems within the notion of nature-inspired optimization. That’s further to giving and up-to-date literature on the context for opening out a visionary opinion on the tendencies of either emerging recent bio-inspired optimization approaches or the different metaheuristic-based combinations on specific VANET routing problems.},
  archive      = {J_AIR},
  author       = {Azzoug, Youcef and Boukra, Abdelmadjid},
  doi          = {10.1007/s10462-020-09868-9},
  journal      = {Artificial Intelligence Review},
  number       = {2},
  pages        = {1005-1062},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Bio-inspired VANET routing optimization: An overview},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Chaos game optimization: A novel metaheuristic algorithm.
<em>AIR</em>, <em>54</em>(2), 917–1004. (<a
href="https://doi.org/10.1007/s10462-020-09867-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a novel metaheuristic algorithm called Chaos Game Optimization (CGO) is developed for solving optimization problems. The main concept of the CGO algorithm is based on some principles of chaos theory in which the configuration of fractals by chaos game concept and the fractals self-similarity issues are in perspective. A total number of 239 mathematical functions which are categorized into four different groups are collected to evaluate the overall performance of the presented novel algorithm. In order to evaluate the results of the CGO algorithm, three comparative analysis with different characteristics are conducted. In the first step, six different metaheuristic algorithms are selected from the literature while the minimum, mean and standard deviation values alongside the number of function evaluations for the CGO and these algorithms are calculated and compared. A complete statistical analysis is also conducted in order to provide a valid judgment about the performance of the CGO algorithm. In the second one, the results of the CGO algorithm are compared to some of the recently developed fractal- and chaos-based algorithms. Finally, the performance of the CGO algorithm is compared to some state-of-the-art algorithms in dealing with the state-of-the-art mathematical functions and one of the recent competitions on single objective real-parameter numerical optimization named “CEC 2017” is considered as numerical examples for this purpose. In addition, a computational cost analysis is also conducted for the presented algorithm. The obtained results proved that the CGO is superior compared to the other metaheuristics in most of the cases.},
  archive      = {J_AIR},
  author       = {Talatahari, Siamak and Azizi, Mahdi},
  doi          = {10.1007/s10462-020-09867-w},
  journal      = {Artificial Intelligence Review},
  number       = {2},
  pages        = {917-1004},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Chaos game optimization: A novel metaheuristic algorithm},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Using memetic algorithm for robustness testing of
contract-based software models. <em>AIR</em>, <em>54</em>(2), 877–915.
(<a href="https://doi.org/10.1007/s10462-020-09881-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph Transformation System (GTS) can formally specify the behavioral aspects of complex systems through graph-based contracts. Test suite generation under normal conditions from GTS specifications is a task well-suited to evolutionary algorithms such as Genetic and Particle Swarm Optimization (PSO) metaheuristics. However, testing the vulnerabilities of a system under unexpected events such as invalid inputs is essential. Furthermore, the mentioned global search algorithms tend to make big jumps in the system’s state-space that are not concentrated on particular test goals. In this paper, we extend the HGAPSO approach into a cost-aware Memetic Algorithm (MA) by making small local changes through a proposed local search operator to optimize coverage score and testing costs. Moreover, we test GTS specifications not only under normal events but also under unexpected situations. So, three coverage-based testing strategies are investigated, including normal testing, robustness testing, and a hybrid strategy. The effectiveness of the proposed test generation algorithm and the testing strategies are evaluated through a type of mutation analysis at the model-level. Our experimental results show that (1) the hybrid testing strategy outperforms normal and robustness testing strategies in terms of fault-detection capability, (2) the robustness testing is the most cost-efficient strategy, and (3) the proposed MA with the hybrid testing strategy outperforms the state-of-the-art global search algorithms.},
  archive      = {J_AIR},
  author       = {Bahrampour, Anvar and Rafe, Vahid},
  doi          = {10.1007/s10462-020-09881-y},
  journal      = {Artificial Intelligence Review},
  number       = {2},
  pages        = {877-915},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Using memetic algorithm for robustness testing of contract-based software models},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Major advancements in kernel function approximation.
<em>AIR</em>, <em>54</em>(2), 843–876. (<a
href="https://doi.org/10.1007/s10462-020-09880-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Kernel based methods have become popular in a wide variety of machine learning tasks. They rely on the computation of kernel functions, which implicitly transform the data in its input space to data in a very high dimensional space. Efficient application of these functions have been subject to study in the last 10 years. The main focus was on improving the scalability of kernel based methods. In this regard, kernel function approximation using explicit feature maps have emerged as a substitute for traditional kernel based methods. Over the years, various advancements from the theoretical perspective have been made to explicit kernel maps, especially to the method of random Fourier features (RFF), which is the main focus of our work. In this work, the major developments in the theory of kernel function approximation are reviewed in a systematic manner and the practical applications are discussed. Furthermore, we identify the shortcomings of the current research, and discuss possible avenues for future work.},
  archive      = {J_AIR},
  author       = {Francis, Deena P. and Raimond, Kumudha},
  doi          = {10.1007/s10462-020-09880-z},
  journal      = {Artificial Intelligence Review},
  number       = {2},
  pages        = {843-876},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Major advancements in kernel function approximation},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Deep learning techniques for skin lesion analysis and
melanoma cancer detection: A survey of state-of-the-art. <em>AIR</em>,
<em>54</em>(2), 811–841. (<a
href="https://doi.org/10.1007/s10462-020-09865-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Analysis of skin lesion images via visual inspection and manual examination to diagnose skin cancer has always been cumbersome. This manual examination of skin lesions in order to detect melanoma can be time-consuming and tedious. With the advancement in technology and rapid increase in computational resources, various machine learning techniques and deep learning models have emerged for the analysis of medical images most especially the skin lesion images. The results of these models have been impressive, however analysis of skin lesion images with these techniques still experiences some challenges due to the unique and complex features of the skin lesion images. This work presents a comprehensive survey of techniques that have been used for detecting skin cancer from skin lesion images. The paper is aimed to provide an up-to-date survey that will assist investigators in developing efficient models that automatically and accurately detects melanoma from skin lesion images. The paper is presented in five folds: First, we identify the challenges in detecting melanoma from skin lesions. Second, we discuss the pre-processing and segmentation techniques of skin lesion images. Third, we make comparative analysis of the state-of-the-arts. Fourth we discuss classification techniques for classifying skin lesions into different classes of skin cancer. We finally explore and analyse the performance of the state-of-the-arts methods employed in popular skin lesion image analysis competitions and challenges of ISIC 2018 and 2019. Application of ensemble deep learning models on well pre-processed and segmented images results in better classification performance of the skin lesion images.},
  archive      = {J_AIR},
  author       = {Adegun, Adekanmi and Viriri, Serestina},
  doi          = {10.1007/s10462-020-09865-y},
  journal      = {Artificial Intelligence Review},
  number       = {2},
  pages        = {811-841},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Deep learning techniques for skin lesion analysis and melanoma cancer detection: A survey of state-of-the-art},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Survey on evaluation methods for dialogue systems.
<em>AIR</em>, <em>54</em>(1), 755–810. (<a
href="https://doi.org/10.1007/s10462-020-09866-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we survey the methods and concepts developed for the evaluation of dialogue systems. Evaluation, in and of itself, is a crucial part during the development process. Often, dialogue systems are evaluated by means of human evaluations and questionnaires. However, this tends to be very cost- and time-intensive. Thus, much work has been put into finding methods which allow a reduction in involvement of human labour. In this survey, we present the main concepts and methods. For this, we differentiate between the various classes of dialogue systems (task-oriented, conversational, and question-answering dialogue systems). We cover each class by introducing the main technologies developed for the dialogue systems and then present the evaluation methods regarding that class.},
  archive      = {J_AIR},
  author       = {Deriu, Jan and Rodrigo, Alvaro and Otegi, Arantxa and Echegoyen, Guillermo and Rosset, Sophie and Agirre, Eneko and Cieliebak, Mark},
  doi          = {10.1007/s10462-020-09866-x},
  journal      = {Artificial Intelligence Review},
  number       = {1},
  pages        = {755-810},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Survey on evaluation methods for dialogue systems},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Metaheuristic-based adaptive curriculum sequencing
approaches: A systematic review and mapping of the literature.
<em>AIR</em>, <em>54</em>(1), 711–754. (<a
href="https://doi.org/10.1007/s10462-020-09864-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The presentation of learning materials in a sequence, which considers the association of students’ individual characteristics with those of the knowledge domain of interest, is an effective learning strategy in online learning systems, especially if related to traditional approaches. However, this sequencing, called Adaptive Curriculum Sequencing (ACS), represents a problem that falls in the NP-Hard class of problems given the diversity of sequences that could be chosen from ever-larger repositories of learning materials. Thus, metaheuristics are usually employed to tackle this problem. This study aims to present a systematic review and mapping of the literature to identify, analyze, and classify the published solutions related to the ACS problem addressed by metaheuristics. We considered 61 studies in the mapping and 58 studies in the review from 2005 to 2018. Even though the problem is longstanding, it is still discussed, especially considering new modeling and used metaheuristics. In this sense, we emphasize the use of Swarm Intelligence and Genetic Algorithm. Moreover, we have identified that various parameters were considered for students and knowledge domain modeling, however, few student’s intrinsic parameters have been explored in ACS literature.},
  archive      = {J_AIR},
  author       = {Machado, Marcelo de Oliveira Costa and Bravo, Natalie Ferraz Silva and Martins, André Ferreira and Bernardino, Heder Soares and Barrere, Eduardo and Souza, Jairo Francisco de},
  doi          = {10.1007/s10462-020-09864-z},
  journal      = {Artificial Intelligence Review},
  number       = {1},
  pages        = {711-754},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Metaheuristic-based adaptive curriculum sequencing approaches: A systematic review and mapping of the literature},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Electrocardiogram signals-based user authentication systems
using soft computing techniques. <em>AIR</em>, <em>54</em>(1), 667–709.
(<a href="https://doi.org/10.1007/s10462-020-09863-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the advent of various security attacks, biometric authentication methods are gaining momentum in the security literature. Electrocardiogram or ECG signals are one of the essential biometric features generated by the human heart’s electrical activities. Many authentication schemes apply these signals due to their uniqueness, resistance to fabrication attacks, and support for continuous authentication. This survey article focuses on the ECG-based authentication approaches and provides the required background knowledge about the ECG signals and authentication methods. Then, it presents a taxonomy of the ECG-based authentication approaches first based on the authentication factors and then according to the applied algorithms for conducting authentication. It then describes their key contributions, applied algorithms, and possible drawbacks. Furthermore, their employed evaluation factors, ECG datasets, and simulators are illuminated and compared. Finally, the concluding remarks and future studies directions in this context are provided.},
  archive      = {J_AIR},
  author       = {Hosseinzadeh, Mehdi and Vo, Bay and Ghafour, Marwan Yassin and Naghipour, Sajjad},
  doi          = {10.1007/s10462-020-09863-0},
  journal      = {Artificial Intelligence Review},
  number       = {1},
  pages        = {667-709},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Electrocardiogram signals-based user authentication systems using soft computing techniques},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Consensus function based on cluster-wise two level
clustering. <em>AIR</em>, <em>54</em>(1), 639–665. (<a
href="https://doi.org/10.1007/s10462-020-09862-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The ensemble clustering tries to aggregate a number of basic clusterings with the aim of producing a more consistent, robust and well-performing consensus clustering result. The current paper wants to introduce an ensemble clustering method. The proposed method, called consensus function based on two level clustering (CFTLC), introduces a new consensus clustering where it makes a cluster clustering task through applying an average hierarchical clustering on a cluster–cluster similarity matrix obtained by an innovative similarity metric. By applying the average hierarchical clustering algorithm, a set of meta clusters has been attained. Considering each meta cluster as a consensus cluster in the consensus clustering output, it then assigns each data point to a meta cluster through defining an object-cluster similarity. Before doing anything, CFTLC converts the primary partitions into a binary cluster representation where the primary ensemble has been broken into a number of basic binary clusters (BC). CFTLC first combines the basic BCs with the maximum cluster–cluster similarity. This step is iterated as long as a predefined number of meta clusters are ready. At the subsequent step, it assigns each data point to exactly one meta cluster. The proposed method has been experimentally compared with the state of the art clustering algorithms in terms of accuracy and robustness.},
  archive      = {J_AIR},
  author       = {Mahmoudi, Mohammad Reza and Akbarzadeh, Hamidreza and Parvin, Hamid and Nejatian, Samad and Rezaie, Vahideh and Alinejad-Rokny, Hamid},
  doi          = {10.1007/s10462-020-09862-1},
  journal      = {Artificial Intelligence Review},
  number       = {1},
  pages        = {639-665},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Consensus function based on cluster-wise two level clustering},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A hybrid harris hawks optimization algorithm with simulated
annealing for feature selection. <em>AIR</em>, <em>54</em>(1), 593–637.
(<a href="https://doi.org/10.1007/s10462-020-09860-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The significant growth of modern technology and smart systems has left a massive production of big data. Not only are the dimensional problems that face the big data, but there are also other emerging problems such as redundancy, irrelevance, or noise of the features. Therefore, feature selection (FS) has become an urgent need to search for the optimal subset of features. This paper presents a hybrid version of the Harris Hawks Optimization algorithm based on Bitwise operations and Simulated Annealing (HHOBSA) to solve the FS problem for classification purposes using wrapper methods. Two bitwise operations (AND bitwise operation and OR bitwise operation) can randomly transfer the most informative features from the best solution to the others in the populations to raise their qualities. The Simulate Annealing (SA) boosts the performance of the HHOBSA algorithm and helps to flee from the local optima. A standard wrapper method K-nearest neighbors with Euclidean distance metric works as an evaluator for the new solutions. A comparison between HHOBSA and other state-of-the-art algorithms is presented based on 24 standard datasets and 19 artificial datasets and their dimension sizes can reach up to thousands. The artificial datasets help to study the effects of different dimensions of data, noise ratios, and the size of samples on the FS process. We employ several performance measures, including classification accuracy, fitness values, size of selected features, and computational time. We conduct two statistical significance tests of HHOBSA like paired-samples T and Wilcoxon signed ranks. The proposed algorithm presented superior results compared to other algorithms.},
  archive      = {J_AIR},
  author       = {Abdel-Basset, Mohamed and Ding, Weiping and El-Shahat, Doaa},
  doi          = {10.1007/s10462-020-09860-3},
  journal      = {Artificial Intelligence Review},
  number       = {1},
  pages        = {593-637},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A hybrid harris hawks optimization algorithm with simulated annealing for feature selection},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A robust extension of VIKOR method for bipolar fuzzy sets
using connection numbers of SPA theory based metric spaces.
<em>AIR</em>, <em>54</em>(1), 561–591. (<a
href="https://doi.org/10.1007/s10462-020-09859-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The purpose of this study is to introduce an innovative multi-attribute group decision making (MAGDM) based on bipolar fuzzy set (BFS) by unifying“ VIseKriterijumska Optimizacija I Kompromisno Rasenje (VIKOR)” method. The VIKOR method is considered to be a useful MAGDM method, specifically in conditions where an expert is unable to determine his choice correctly at the initiation of designing a system. The method of VIKOR is suitable for problems containing conflicting attributes, with an assumption that compromising is admissible for conflict decision, the expert wishes a solution very near to the best, and the different alternatives or choices are processed according to all developed attributes. The theory of set pair analysis is a state-of-the-art uncertainty theory which consists of three factors, including “identity degree”, “discrepancy degree”, and “contrary degree” of connection numbers (CNs) and coincidence with many existing theories dealing with vagueness in the given information. Consequently, inspired by this, in the present study, we make an effort to improve the theory of data measurement by introducing some metric spaces using CNs of BFSs. In this research paper, we extend VIKOR method in the context of CNs based metrics, which are obtained form bipolar fuzzy numbers (BFNs). Firstly, we develop CNs of BFNs as well as metric spaces based on CNs. We also discuss some interesting properties of proposed metric spaces. Secondly, we develop VIKOR method using CNs based metrics to handle an MAGDM problem under bipolar fuzzy type information. The predominance of proposed metric spaces is also studied by the means of examples. Furthermore, we demonstrate the efficiency of the extended VIKOR method by solving a numerical example, sensitivity analysis and a detailed comparison with some existing approaches.},
  archive      = {J_AIR},
  author       = {Riaz, Muhammad and Tehrim, Syeda Tayyba},
  doi          = {10.1007/s10462-020-09859-w},
  journal      = {Artificial Intelligence Review},
  number       = {1},
  pages        = {561-591},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A robust extension of VIKOR method for bipolar fuzzy sets using connection numbers of SPA theory based metric spaces},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-dimensional bayesian network classifiers: A survey.
<em>AIR</em>, <em>54</em>(1), 519–559. (<a
href="https://doi.org/10.1007/s10462-020-09858-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-dimensional classification is a cutting-edge problem, in which the values of multiple class variables have to be simultaneously assigned to a given example. It is an extension of the well known multi-label subproblem, in which the class variables are all binary. In this article, we review and expand the set of performance evaluation measures suitable for assessing multi-dimensional classifiers. We focus on multi-dimensional Bayesian network classifiers, which directly cope with multi-dimensional classification and consider dependencies among class variables. A comprehensive survey of this state-of-the-art classification model is offered by covering aspects related to their learning and inference process complexities. We also describe algorithms for structural learning, provide real-world applications where they have been used, and compile a collection of related software.},
  archive      = {J_AIR},
  author       = {Gil-Begue, Santiago and Bielza, Concha and Larrañaga, Pedro},
  doi          = {10.1007/s10462-020-09858-x},
  journal      = {Artificial Intelligence Review},
  number       = {1},
  pages        = {519-559},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Multi-dimensional bayesian network classifiers: A survey},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Dual generalized bonferroni mean operators based on
2-dimensional uncertain linguistic information and their applications in
multi-attribute decision making. <em>AIR</em>, <em>54</em>(1), 491–517.
(<a href="https://doi.org/10.1007/s10462-020-09857-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The dual generalized Bonferroni mean operator is a further extension of the generalized Bonferroni mean operator which can take the interrelationship of different numbers of attributes into account by changing the embedded parameter. The 2-dimensional uncertain linguistic variable (2DULV) adds a second dimensional uncertain linguistic variable (ULV) to express the reliability of the assessment information in first dimensional information, which is more rational and accurate than the ULV. In this paper, for combining the advantages of them, we propose the dual generalized weighted Bonferroni mean operator for 2DULVs (2DULDGWBM) and the dual generalized weighted Bonferroni geometric mean operator for 2DULVs (2DULDGWBGM). In addition, we explore several particular cases and some rational characters of them. Further, a new approach is introduced to handle multi-attribute decision making problems in the environment of 2DULVs by the proposed operators. Finally, we utilize several illustrative examples to testify the validity and superiority of this new method by comparing with several other methods.},
  archive      = {J_AIR},
  author       = {Liu, Peide and Liu, Weiqiao},
  doi          = {10.1007/s10462-020-09857-y},
  journal      = {Artificial Intelligence Review},
  number       = {1},
  pages        = {491-517},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Dual generalized bonferroni mean operators based on 2-dimensional uncertain linguistic information and their applications in multi-attribute decision making},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Projection wavelet weighted twin support vector regression
for OFDM system channel estimation. <em>AIR</em>, <em>54</em>(1),
469–489. (<a href="https://doi.org/10.1007/s10462-020-09853-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, an efficient projection wavelet weighted twin support vector regression (PWWTSVR) based orthogonal frequency division multiplexing system (OFDM) system channel estimation algorithm is proposed. Most Channel estimation algorithms for OFDM systems are based on the linear assumption of channel model. In the proposed algorithm, the OFDM system channel is consumed to be nonlinear and fading in both time and frequency domains. The PWWTSVR utilizes pilot signals to estimate response of nonlinear wireless channel, which is the main work area of SVR. Projection axis in optimal objective function of PWWRSVR is sought to minimize the variance of the projected points due to the utilization of a priori information of training data. Different from traditional support vector regression algorithm, training samples in different positions in the proposed PWWTSVR model are given different penalty weights determined by the wavelet transform. The weights are applied to both the quadratic empirical risk term and the first-degree empirical risk term to reduce the influence of outliers. The final regressor can avoid the overfitting problem to a certain extent and yield great generalization ability for channel estimation. The results of numerical experiments show that the propose algorithm has better performance compared to the conventional pilot-aided channel estimation methods.},
  archive      = {J_AIR},
  author       = {Wang, Lidong and Ma, Yimei and Chang, Xudong and Gao, Chuang and Qu, Qiang and Chen, Xuebo},
  doi          = {10.1007/s10462-020-09853-2},
  journal      = {Artificial Intelligence Review},
  number       = {1},
  pages        = {469-489},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Projection wavelet weighted twin support vector regression for OFDM system channel estimation},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A systematic literature review of multicriteria recommender
systems. <em>AIR</em>, <em>54</em>(1), 427–468. (<a
href="https://doi.org/10.1007/s10462-020-09851-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Since the first years of the 90s, recommender systems have emerged as effective tools for automatically selecting items according to user preferences. Traditional recommenders rely on the relevance assessments that users express using a single rating for each item. However, some authors started to suggest that this approach could be limited, as we naturally tend to formulate different judgments according to multiple criteria. During the last decade, several studies introduced novel recommender systems capable of exploiting user preferences expressed over multiple criteria. This work proposes a systematic literature review in the field of multicriteria recommender systems. Following a replicable protocol, we selected a total number of 93 studies dealing with this topic. We subsequently analyzed them to provide an answer to five different research questions. We considered what are the most common research problems, recommendation approaches, data mining and machine learning algorithms mentioned in these studies. Furthermore, we investigated the domains of application, the exploited evaluation protocols, metrics and datasets, and the most promising suggestions for future works.},
  archive      = {J_AIR},
  author       = {Monti, Diego and Rizzo, Giuseppe and Morisio, Maurizio},
  doi          = {10.1007/s10462-020-09851-4},
  journal      = {Artificial Intelligence Review},
  number       = {1},
  pages        = {427-468},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A systematic literature review of multicriteria recommender systems},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Improving coalition structure search with an imperfect
algorithm: Analysis and evaluation results. <em>AIR</em>,
<em>54</em>(1), 397–425. (<a
href="https://doi.org/10.1007/s10462-020-09850-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optimal Coalition Structure Generation (CSG) is a significant research problem in multi-agent systems that remains difficult to solve. This problem has many important applications in transportation, eCommerce, distributed sensor networks and others. The CSG problem is NP-complete and finding the optimal result for n agents needs to check $$O (n^n)$$ possible partitions. The ODP–IP algorithm (Michalak et al. in Artif Intell 230:14–50, 2016) achieves the current lowest worst-case time complexity of $$O (3^n)$$ . In the light of its high computational time complexity, we devise an Imperfect Dynamic Programming (ImDP) algorithm for the CSG problem with runtime $$O (n2^n)$$ given n agents. Imperfect algorithm means that there are some contrived inputs for which the algorithm fails to give the optimal result. We benchmarked ImDP against ODP–IP and proved its efficiency. Experimental results confirmed that ImDP algorithm performance is better for several data distributions, and for some it improves dramatically ODP–IP. For example, given 27 agents, with ImDP for agent-based uniform distribution time gain is 91\% (i.e. 49 min).},
  archive      = {J_AIR},
  author       = {Changder, Narayan and Aknine, Samir and Dutta, Animesh},
  doi          = {10.1007/s10462-020-09850-5},
  journal      = {Artificial Intelligence Review},
  number       = {1},
  pages        = {397-425},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Improving coalition structure search with an imperfect algorithm: Analysis and evaluation results},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Image classifiers and image deep learning classifiers
evolved in detection of oryza sativa diseases: survey. <em>AIR</em>,
<em>54</em>(1), 359–396. (<a
href="https://doi.org/10.1007/s10462-020-09849-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Growth in consumption of Oryza sativa (rice) has led the farmers across Asian countries to cultivate Oryza sativa, with an impact of 2.5 percent increase in the cultivation of the crop every year. Along with the growth in Oryza sativa cultivation, there are new challenges that are faced by the farmers in terms of diseases. The absence of information to recognize what sort of infection the plant is influenced with during the harvest cycle drives the farmers over the globe to lose 37 percent of the production. Involving technology to identify these diseases during the harvest cycle will help the farmers to get benefitted by attaining better yields. Deep learning being a latest technology playing a vital role in helping human in many aspects. A thorough review of the research papers on the various classifiers used in the identification of Oryza sativa diseases was carried out and the survey was tabulated and presented.},
  archive      = {J_AIR},
  author       = {Goluguri, N. V. Raja Reddy and Suganya Devi, K. and Vadaparthi, Nagesh},
  doi          = {10.1007/s10462-020-09849-y},
  journal      = {Artificial Intelligence Review},
  number       = {1},
  pages        = {359-396},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Image classifiers and image deep learning classifiers evolved in detection of oryza sativa diseases: Survey},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Non-goal oriented dialogue agents: State of the art,
dataset, and evaluation. <em>AIR</em>, <em>54</em>(1), 329–357. (<a
href="https://doi.org/10.1007/s10462-020-09848-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dialogue agent, a derivative of intelligent agent in the field of computational linguistics, is a computer program that is capable of generating responses and performing conversation in natural language. The field of computational linguistics is flourishing due to the intensive growth of dialogue agents; the most potential one is providing voice controlled smart personal assistant service for handsets and homes. The agents are usable, accessible but perform task-related short conversations. Non-goal-oriented dialogue agents are designed to imitate extended human–human conversations, also called as chit-chat, to provide the consumer with a satisfactory experience on the conversation quality. The design of such agents is primarily defined by a language model, unlike goal-oriented dialogue agents that employees slot based or ontology-based frameworks, hence most of the methods are data-driven. This paper surveys the current state of the art of non-goal-oriented dialogue systems specifically data-driven methods, the most prevalent being deep learning. This paper aims at (a) providing an insight of recent methods and architectures proposed for building context and modeling response along with a comprehensive review of the state of the art (b) examine the type of data set and evaluation methods available (c) present the challenges and limitation that the recent models, dataset and evaluation methods constitute.},
  archive      = {J_AIR},
  author       = {Mehndiratta, Akanksha and Asawa, Krishna},
  doi          = {10.1007/s10462-020-09848-z},
  journal      = {Artificial Intelligence Review},
  number       = {1},
  pages        = {329-357},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Non-goal oriented dialogue agents: State of the art, dataset, and evaluation},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Machine learning in medicinal plants recognition: A review.
<em>AIR</em>, <em>54</em>(1), 305–327. (<a
href="https://doi.org/10.1007/s10462-020-09847-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Medicinal plants are gaining attention in the pharmaceutical industry due to having less harmful effects reactions and cheaper than modern medicine. Based on these facts, many researchers have shown considerable interest in the research of automatic medicinal plants recognition. There are various opportunities for advancement in producing a robust classifier that has the ability to classify medicinal plants accurately in real-time. In this paper, various effective and reliable machine learning algorithms for plant classifications using leaf images that have been used in recent years are reviewed. The review includes the image processing methods used to detect leaf and extract important leaf features for some machine learning classifiers. These machine learning classifiers are categorised according to their performance when classifying leaf images based on typical plant features, namely shape, vein, texture and a combination of multiple features. The leaf databases that are publicly available for automatic plants recognition are reviewed as well and we conclude with a discussion of prominent ongoing research and opportunities for enhancement in this area.},
  archive      = {J_AIR},
  author       = {Pushpanathan, Kalananthni and Hanafi, Marsyita and Mashohor, Syamsiah and Fazlil Ilahi, Wan Fazilah},
  doi          = {10.1007/s10462-020-09847-0},
  journal      = {Artificial Intelligence Review},
  number       = {1},
  pages        = {305-327},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Machine learning in medicinal plants recognition: A review},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Incremental methods in face recognition: A survey.
<em>AIR</em>, <em>54</em>(1), 253–303. (<a
href="https://doi.org/10.1007/s10462-019-09734-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Face Recognition has rapidly grown as a commercial requirement for a variety of applications in recent years. There are certain situations in which all the face images may not be available before training or the face images may be distributed at geographically apart locations. Incremental face recognition addresses these problems and possesses certain advantages i.e. being time efficient and dynamic model updation allows addition/deletion of samples on the fly. In this paper, a comprehensive review on the Incremental learning algorithms that are aimed at Face Recognition or tested over Face datasets. The contribution of this paper is three-fold: (a) a novel taxonomy of the Incremental methods have been proposed (b) a review of the face datasets used in Incremental face recognition have been carried out and (c) a performance analysis of the Incremental face recognition methods over various face datasets is also presented. Important conclusions have been drawn that will help the researchers in making suitable choices amongst various methods and datasets. This survey shall act as a useful reference to the researchers and practitioners working in incremental face recognition. Furthermore, several viable research directions have been given at the end.},
  archive      = {J_AIR},
  author       = {Madhavan, Suresh and Kumar, Nitin},
  doi          = {10.1007/s10462-019-09734-3},
  journal      = {Artificial Intelligence Review},
  number       = {1},
  pages        = {253-303},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Incremental methods in face recognition: A survey},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Deep learning for biomedical image reconstruction: A survey.
<em>AIR</em>, <em>54</em>(1), 215–251. (<a
href="https://doi.org/10.1007/s10462-020-09861-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Medical imaging is an invaluable resource in medicine as it enables to peer inside the human body and provides scientists and physicians with a wealth of information indispensable for understanding, modelling, diagnosis, and treatment of diseases. Reconstruction algorithms entail transforming signals collected by acquisition hardware into interpretable images. Reconstruction is a challenging task given the ill-posedness of the problem and the absence of exact analytic inverse transforms in practical cases. While the last decades witnessed impressive advancements in terms of new modalities, improved temporal and spatial resolution, reduced cost, and wider applicability, several improvements can still be envisioned such as reducing acquisition and reconstruction time to reduce patient’s exposure to radiation and discomfort while increasing clinics throughput and reconstruction accuracy. Furthermore, the deployment of biomedical imaging in handheld devices with small power requires a fine balance between accuracy and latency. The design of fast, robust, and accurate reconstruction algorithms is a desirable, yet challenging, research goal. While the classical image reconstruction algorithms approximate the inverse function relying on expert-tuned parameters to ensure reconstruction performance, deep learning (DL) allows automatic feature extraction and real-time inference. Hence, DL presents a promising approach to image reconstruction with artifact reduction and reconstruction speed-up reported in recent works as part of a rapidly growing field. We review state-of-the-art image reconstruction algorithms with a focus on DL-based methods. First, we examine common reconstruction algorithm designs, applied metrics, and datasets used in the literature. Then, key challenges are discussed as potentially promising strategic directions for future research.},
  archive      = {J_AIR},
  author       = {Ben Yedder, Hanene and Cardoen, Ben and Hamarneh, Ghassan},
  doi          = {10.1007/s10462-020-09861-2},
  journal      = {Artificial Intelligence Review},
  number       = {1},
  pages        = {215-251},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Deep learning for biomedical image reconstruction: A survey},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Deep learning approach for facial age classification: A
survey of the state-of-the-art. <em>AIR</em>, <em>54</em>(1), 179–213.
(<a href="https://doi.org/10.1007/s10462-020-09855-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Age estimation using face images is an exciting and challenging task. The traits from the face images are used to determine age, gender, ethnic background, and emotion of people. Among this set of traits, age estimation can be valuable in several potential real-time applications. The traditional hand-crafted methods relied-on for age estimation, cannot correctly estimate the age. The availability of huge datasets for training and an increase in computational power has made deep learning with convolutional neural network a better method for age estimation; convolutional neural network will learn discriminative feature descriptors directly from image pixels. Several convolutional neural net work approaches have been proposed by many of the researchers, and these have made a significant impact on the results and performances of age estimation systems. In this paper, we present a thorough study of the state-of-the-art deep learning techniques which estimate age from human faces. We discuss the popular convolutional neural network architectures used for age estimation, presents a critical analysis of the performance of some deep learning models on popular facial aging datasets, and study the standard evaluation metrics used for performance evaluations. Finally, we try to analyze the main aspects that can increase the performance of the age estimation system in future.},
  archive      = {J_AIR},
  author       = {Agbo-Ajala, Olatunbosun and Viriri, Serestina},
  doi          = {10.1007/s10462-020-09855-0},
  journal      = {Artificial Intelligence Review},
  number       = {1},
  pages        = {179-213},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Deep learning approach for facial age classification: A survey of the state-of-the-art},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Deep semantic segmentation of natural and medical images: A
review. <em>AIR</em>, <em>54</em>(1), 137–178. (<a
href="https://doi.org/10.1007/s10462-020-09854-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The semantic image segmentation task consists of classifying each pixel of an image into an instance, where each instance corresponds to a class. This task is a part of the concept of scene understanding or better explaining the global context of an image. In the medical image analysis domain, image segmentation can be used for image-guided interventions, radiotherapy, or improved radiological diagnostics. In this review, we categorize the leading deep learning-based medical and non-medical image segmentation solutions into six main groups of deep architectural, data synthesis-based, loss function-based, sequenced models, weakly supervised, and multi-task methods and provide a comprehensive review of the contributions in each of these groups. Further, for each group, we analyze each variant of these groups and discuss the limitations of the current approaches and present potential future research directions for semantic image segmentation.},
  archive      = {J_AIR},
  author       = {Asgari Taghanaki, Saeid and Abhishek, Kumar and Cohen, Joseph Paul and Cohen-Adad, Julien and Hamarneh, Ghassan},
  doi          = {10.1007/s10462-020-09854-1},
  journal      = {Artificial Intelligence Review},
  number       = {1},
  pages        = {137-178},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Deep semantic segmentation of natural and medical images: A review},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Deep learning techniques for rating prediction: A survey of
the state-of-the-art. <em>AIR</em>, <em>54</em>(1), 95–135. (<a
href="https://doi.org/10.1007/s10462-020-09892-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the growth of online information, varying personalization drifts and volatile behaviors of internet users, recommender systems are effective tools for information filtering to overcome the information overload problem. Recommender systems utilize rating prediction approaches i.e. predicting the rating that a user will give to a particular item, to generate ranked lists of items according to the preferences of each user in order to make personalized recommendations. Although previous recommendation systems are effective in creating attired recommendations, however, they still suffer from different types of challenges such as accuracy, scalability, cold-start, and data sparsity. In the last few years, deep learning has attained substantial interest in various research areas such as computer vision, speech recognition, and natural language processing. Deep learning based approaches are vigorous in not only performance improvement but also to feature representations learning from the scratch. The impact of deep learning is also prevalent, recently validating its efficacy on information retrieval and recommender systems research. In this study, a comprehensive review of deep learning-based rating prediction approaches is provided to help out new researchers interested in the subject. More concretely, the classification of deep learning-based recommendation/rating prediction models is provided and articulated along with an extensive summary of the state-of-the-art. Lastly, new trends are exposited with new perspectives pertaining to this novel and exciting development of the field.},
  archive      = {J_AIR},
  author       = {Khan, Zahid Younas and Niu, Zhendong and Sandiwarno, Sulis and Prince, Rukundo},
  doi          = {10.1007/s10462-020-09892-9},
  journal      = {Artificial Intelligence Review},
  number       = {1},
  pages        = {95-135},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Deep learning techniques for rating prediction: A survey of the state-of-the-art},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A review on machine learning in 3D printing: Applications,
potential, and challenges. <em>AIR</em>, <em>54</em>(1), 63–94. (<a
href="https://doi.org/10.1007/s10462-020-09876-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Additive manufacturing (AM) or 3D printing is growing rapidly in the manufacturing industry and has gained a lot of attention from various fields owing to its ability to fabricate parts with complex features. The reliability of the 3D printed parts has been the focus of the researchers to realize AM as an end-part production tool. Machine learning (ML) has been applied in various aspects of AM to improve the whole design and manufacturing workflow especially in the era of industry 4.0. In this review article, various types of ML techniques are first introduced. It is then followed by the discussion on their use in various aspects of AM such as design for 3D printing, material tuning, process optimization, in situ monitoring, cloud service, and cybersecurity. Potential applications in the biomedical, tissue engineering and building and construction will be highlighted. The challenges faced by ML in AM such as computational cost, standards for qualification and data acquisition techniques will also be discussed. In the authors’ perspective, in situ monitoring of AM processes will significantly benefit from the object detection ability of ML. As a large data set is crucial for ML, data sharing of AM would enable faster adoption of ML in AM. Standards for the shared data are needed to facilitate easy sharing of data. The use of ML in AM will become more mature and widely adopted as better data acquisition techniques and more powerful computer chips for ML are developed.},
  archive      = {J_AIR},
  author       = {Goh, G. D. and Sing, S. L. and Yeong, W. Y.},
  doi          = {10.1007/s10462-020-09876-9},
  journal      = {Artificial Intelligence Review},
  number       = {1},
  pages        = {63-94},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A review on machine learning in 3D printing: Applications, potential, and challenges},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Dynamic uncertain causality graph for computer-aided general
clinical diagnoses with nasal obstruction as an illustration.
<em>AIR</em>, <em>54</em>(1), 27–61. (<a
href="https://doi.org/10.1007/s10462-020-09871-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many AI systems have been developed for clinical diagnoses, in which most of them lack interpretability in both knowledge representation and inference results. The newly developed Dynamic Uncertain Causality Graph (DUCG) is a probabilistic graphical model with strong interpretability. However, existing DUCG is mainly for fault diagnoses of large, complex industrial systems. In this paper, we extend DUCG for better application in general clinical diagnoses. Four extensions are introduced: (1) special logic gate and zoom function event variables to represent and quantify the influences of various risk factors on the morbidities of diseases. (2) Reversal logic gate to model the case that some diseases/causes may result in at least two simultaneous symptoms/consequences. (3) Disease-specific manifestation variable for special inference and easy understanding to diagnose a specific disease. (4) Event attention importance to count contributions of isolated state-abnormal variables in inference. To illustrate and verify the extended DUCG methodology, we performed a case study for diagnosing 25 diseases causing nasal obstruction. We tested 171 cases randomly selected from total 471 cases of discharged patients in the hospital information system of Xuanwu Hospital. The diagnosis precision of the extended DUCG was 100\%. The diagnosis precision of the third-party verification performed by Suining Central Hospital was 98.86\%, which exhibited the strong generalization ability of the extended DUCG.},
  archive      = {J_AIR},
  author       = {Zhang, Qin and Bu, Xusong and Zhang, Mingxia and Zhang, Zhan and Hu, Jie},
  doi          = {10.1007/s10462-020-09871-0},
  journal      = {Artificial Intelligence Review},
  number       = {1},
  pages        = {27-61},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Dynamic uncertain causality graph for computer-aided general clinical diagnoses with nasal obstruction as an illustration},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). CovidSens: A vision on reliable social sensing for COVID-19.
<em>AIR</em>, <em>54</em>(1), 1–25. (<a
href="https://doi.org/10.1007/s10462-020-09852-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the spiraling pandemic of the Coronavirus Disease 2019 (COVID-19), it has becoming inherently important to disseminate accurate and timely information about the disease. Due to the ubiquity of Internet connectivity and smart devices, social sensing is emerging as a dynamic AI-driven sensing paradigm to extract real-time observations from online users. In this paper, we propose CovidSens, a vision of social sensing-based risk alert systems to spontaneously obtain and analyze social data to infer the state of the COVID-19 propagation. CovidSens can actively help to keep the general public informed about the COVID-19 spread and identify risk-prone areas by inferring future propagation patterns. The CovidSens concept is motivated by three observations: (1) people have been actively sharing their state of health and experience of the COVID-19 via online social media, (2) official warning channels and news agencies are relatively slower than people reporting their observations and experiences about COVID-19 on social media, and (3) online users are frequently equipped with substantially capable mobile devices that are able to perform non-trivial on-device computation for data processing and analytics. We envision an unprecedented opportunity to leverage the posts generated by the ordinary people to build a real-time sensing and analytic system for gathering and circulating vital information of the COVID-19 propagation. Specifically, the vision of CovidSens attempts to answer the questions: How to distill reliable information about the COVID-19 with the coexistence of prevailing rumors and misinformation in the social media? How to inform the general public about the latest state of the spread timely and effectively, and alert them to remain prepared? How to leverage the computational power on the edge devices (e.g., smartphones, IoT devices, UAVs) to construct fully integrated edge-based social sensing platforms for rapid detection of the COVID-19 spread? In this vision paper, we discuss the roles of CovidSens and identify the potential challenges in developing reliable social sensing-based risk alert systems. We envision that approaches originating from multiple disciplines (e.g., AI, estimation theory, machine learning, constrained optimization) can be effective in addressing the challenges. Finally, we outline a few research directions for future work in CovidSens.},
  archive      = {J_AIR},
  author       = {Rashid, Md Tahmid and Wang, Dong},
  doi          = {10.1007/s10462-020-09852-3},
  journal      = {Artificial Intelligence Review},
  number       = {1},
  pages        = {1-25},
  shortjournal = {Artif. Intell. Rev.},
  title        = {CovidSens: A vision on reliable social sensing for COVID-19},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
</ul>

</body>
</html>
