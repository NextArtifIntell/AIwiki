<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>MP_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="mp---123">MP - 123</h2>
<ul>
<li><details>
<summary>
(2021). Correction to: Exact semidefinite formulations for a class
of (random and non-random) nonconvex quadratic programs. <em>MP</em>,
<em>190</em>(1), 845–848. (<a
href="https://doi.org/10.1007/s10107-021-01684-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A correction to this paper has been published: https://doi.org/10.1007/s10107-021-01684-5},
  archive      = {J_MP},
  author       = {Burer, Samuel and Ye, Yinyu},
  doi          = {10.1007/s10107-021-01684-5},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {845-848},
  shortjournal = {Math. Program.},
  title        = {Correction to: Exact semidefinite formulations for a class of (random and non-random) nonconvex quadratic programs},
  volume       = {190},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Correction to: A sequential homotopy method for
mathematical programming problems. <em>MP</em>, <em>190</em>(1),
843–844. (<a href="https://doi.org/10.1007/s10107-021-01668-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A correction to this paper has been published: https://doi.org/10.1007/s10107-021-01668-5},
  archive      = {J_MP},
  author       = {Potschka, Andreas and Bock, Hans Georg},
  doi          = {10.1007/s10107-021-01668-5},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {843-844},
  shortjournal = {Math. Program.},
  title        = {Correction to: A sequential homotopy method for mathematical programming problems},
  volume       = {190},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Further results on an abstract model for branching and its
application to mixed integer programming. <em>MP</em>, <em>190</em>(1),
811–841. (<a href="https://doi.org/10.1007/s10107-020-01556-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A key ingredient in branch and bound (B&amp;B) solvers for mixed-integer programming (MIP) is the selection of branching variables since poor or arbitrary selection can affect the size of the resulting search trees by orders of magnitude. A recent article by Le Bodic and Nemhauser (Math Program 166(1–2):369–405, 2017) investigated variable selection rules by developing a theoretical model of B&amp;B trees from which they developed some new, effective scoring functions for MIP solvers. In their work, Le Bodic and Nemhauser left several open theoretical problems, solutions to which could guide the future design of variable selection rules. In this article, we first solve many of these open theoretical problems. We then implement an improved version of the model-based branching rules in SCIP 6.0, a state-of-the-art academic MIP solver, in which we observe an $$11\%$$ geometric average time and node reduction on instances of the MIPLIB 2017 Benchmark Set that require large B&amp;B trees.},
  archive      = {J_MP},
  author       = {Anderson, Daniel and Le Bodic, Pierre and Morgan, Kerri},
  doi          = {10.1007/s10107-020-01556-4},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {811-841},
  shortjournal = {Math. Program.},
  title        = {Further results on an abstract model for branching and its application to mixed integer programming},
  volume       = {190},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Connecting optimization with spectral analysis of
tri-diagonal matrices. <em>MP</em>, <em>190</em>(1), 795–809. (<a
href="https://doi.org/10.1007/s10107-020-01549-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We show that the global minimum (resp. maximum) of a continuous function on a compact set can be approximated from above (resp. from below) by computing the smallest (rest. largest) eigenvalue of a hierarchy of $$(r\times r)$$ tri-diagonal matrices of increasing size. Equivalently it reduces to computing the smallest (resp. largest) root of a certain univariate degree-r orthonormal polynomial. This provides a strong connection between the fields of optimization, orthogonal polynomials, numerical analysis and linear algebra, via asymptotic spectral analysis of tri-diagonal symmetric matrices.},
  archive      = {J_MP},
  author       = {Lasserre, Jean B.},
  doi          = {10.1007/s10107-020-01549-3},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {795-809},
  shortjournal = {Math. Program.},
  title        = {Connecting optimization with spectral analysis of tri-diagonal matrices},
  volume       = {190},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A loose benders decomposition algorithm for approximating
two-stage mixed-integer recourse models. <em>MP</em>, <em>190</em>(1),
761–794. (<a href="https://doi.org/10.1007/s10107-020-01559-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a new class of convex approximations for two-stage mixed-integer recourse models, the so-called generalized alpha-approximations. The advantage of these convex approximations over existing ones is that they are more suitable for efficient computations. Indeed, we construct a loose Benders decomposition algorithm that solves large problem instances in reasonable time. To guarantee the performance of the resulting solution, we derive corresponding error bounds that depend on the total variations of the probability density functions of the random variables in the model. The error bounds converge to zero if these total variations converge to zero. We empirically assess our solution method on several test instances, including the SIZES and SSLP instances from SIPLIB. We show that our method finds near-optimal solutions if the variability of the random parameters in the model is large. Moreover, our method outperforms existing methods in terms of computation time, especially for large problem instances.},
  archive      = {J_MP},
  author       = {van der Laan, Niels and Romeijnders, Ward},
  doi          = {10.1007/s10107-020-01559-1},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {761-794},
  shortjournal = {Math. Program.},
  title        = {A loose benders decomposition algorithm for approximating two-stage mixed-integer recourse models},
  volume       = {190},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A tight degree 4 sum-of-squares lower bound for the
sherrington–kirkpatrick hamiltonian. <em>MP</em>, <em>190</em>(1),
721–759. (<a href="https://doi.org/10.1007/s10107-020-01558-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We show that, if $${\varvec{W}}$$ is an $$N \times N$$ matrix drawn from the gaussian orthogonal ensemble, then with high probability the degree 4 sum-of-squares relaxation cannot certify an upper bound on the objective $$N^{-1} \cdot \varvec{x}^\top \varvec{W} \varvec{x}$$ under the constraints $$x_i^2 - 1 = 0$$ (i.e. $$\varvec{x}\in {\pm 1 }^N$$ ) that is asymptotically smaller than $$\lambda _{\max }({\varvec{W}}) \approx 2$$ . We also conjecture a proof technique for lower bounds against sum-of-squares relaxations of any degree held constant as $$N \rightarrow \infty $$ , by proposing an approximate pseudomoment construction.},
  archive      = {J_MP},
  author       = {Kunisky, Dmitriy and Bandeira, Afonso S.},
  doi          = {10.1007/s10107-020-01558-2},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {721-759},
  shortjournal = {Math. Program.},
  title        = {A tight degree 4 sum-of-squares lower bound for the Sherrington–Kirkpatrick hamiltonian},
  volume       = {190},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Statistical robustness in utility preference robust
optimization models. <em>MP</em>, <em>190</em>(1), 679–720. (<a
href="https://doi.org/10.1007/s10107-020-01555-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Utility preference robust optimization (PRO) concerns decision making problems where information on decision maker’s utility preference is incomplete and has to be elicited through partial information and the optimal decision is based on the worst case utility function elicited. A key assumption in the PRO models is that the true probability distribution is either known or can be recovered by real data generated by the true distribution. In data-driven optimization, this assumption may not be satisfied when perceived data differ from real data and consequently it raises a question as to whether statistical estimators of the PRO models based on perceived data are reliable. In this paper, we investigate the issue which is also known as qualitative robustness in the literature of statistics (Huber in Robust statistics, 3rd edn, Wiley, New York, 1981) and risk management (Krätschmer et al. in Finance Stoch 18:271–295, 2014). By utilizing the framework proposed by Krätschmer et al. (2014), we derive moderate sufficient conditions under which the optimal value and optimal solution of the PRO models are robust against perturbation of the exogenous uncertainty data, and examine how the tail behaviour of utility functions affects the robustness. Moreover, under some additional conditions on the Lipschitz continuity of the underlying functions with respect to random data, we establish quantitative robustness of the statistical estimators under the Kantorovich metric. Finally, we investigate uniform consistency of the optimal value and optimal solution of the PRO models. The results cover utility selection problems and stochastic optimization problems as special cases.},
  archive      = {J_MP},
  author       = {Guo, Shaoyan and Xu, Huifu},
  doi          = {10.1007/s10107-020-01555-5},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {679-720},
  shortjournal = {Math. Program.},
  title        = {Statistical robustness in utility preference robust optimization models},
  volume       = {190},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Fully asynchronous stochastic coordinate descent: A tight
lower bound on the parallelism achieving linear speedup. <em>MP</em>,
<em>190</em>(1), 615–677. (<a
href="https://doi.org/10.1007/s10107-020-01552-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We seek tight bounds on the viable parallelism in asynchronous implementations of coordinate descent that achieves linear speedup. We focus on asynchronous coordinate descent (ACD) algorithms on convex functions which consist of the sum of a smooth convex part and a possibly non-smooth separable convex part. We quantify the shortfall in progress compared to the standard sequential stochastic gradient descent. This leads to a simple yet tight analysis of the standard stochastic ACD in a partially asynchronous environment, generalizing and improving the bounds in prior work. We also give a considerably more involved analysis for general asynchronous environments in which the only constraint is that each update can overlap with at most q others. The new lower bound on the maximum degree of parallelism attaining linear speedup is tight and improves the best prior bound almost quadratically.},
  archive      = {J_MP},
  author       = {Cheung, Yun Kuen and Cole, Richard and Tao, Yixin},
  doi          = {10.1007/s10107-020-01552-8},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {615-677},
  shortjournal = {Math. Program.},
  title        = {Fully asynchronous stochastic coordinate descent: A tight lower bound on the parallelism achieving linear speedup},
  volume       = {190},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A smooth homotopy method for incomplete markets.
<em>MP</em>, <em>190</em>(1), 585–613. (<a
href="https://doi.org/10.1007/s10107-020-01551-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the general equilibrium with incomplete asset markets (GEI) model, the excess demand functions are typically not continuous at the prices for which the assets have redundant returns. The reason is that, at these prices, the return matrix drops rank and households’ budget sets collapse suddenly. This discontinuity results in a serious problem for the existence and computation of general equilibrium. In this paper, we show that this problem can be resolved with a new return matrix, which has constant rank. As a function of the price vector, the continuity of this new return matrix is ensured on a subset of the price space. This enables us to handle incomplete markets using a standard homotopy path-following argument by restricting the price vector to such a subset. The proposed approach naturally provides a constructive proof for the generic existence of general equilibrium. A homotopy method can then be applied to compute equilibria in the GEI model. Numerical experiments are presented to illustrate its efficiency.},
  archive      = {J_MP},
  author       = {Zhan, Yang and Dang, Chuangyin},
  doi          = {10.1007/s10107-020-01551-9},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {585-613},
  shortjournal = {Math. Program.},
  title        = {A smooth homotopy method for incomplete markets},
  volume       = {190},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Determination of convex functions via subgradients of
minimal norm. <em>MP</em>, <em>190</em>(1), 561–583. (<a
href="https://doi.org/10.1007/s10107-020-01550-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We show, in Hilbert space setting, that any two convex proper lower semicontinuous functions bounded from below, for which the norm of their minimal subgradients coincide, they coincide up to a constant. Moreover, under classic boundary conditions, we provide the same results when the functions are continuous and defined over an open convex domain. These results show that for convex functions bounded from below, the slopes provide sufficient first-order information to determine the function up to a constant, giving a positive answer to the conjecture posed in Boulmezaoud et al. (SIAM J Optim 28(3):2049–2066, 2018) .},
  archive      = {J_MP},
  author       = {Pérez-Aros, Pedro and Salas, David and Vilches, Emilio},
  doi          = {10.1007/s10107-020-01550-w},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {561-583},
  shortjournal = {Math. Program.},
  title        = {Determination of convex functions via subgradients of minimal norm},
  volume       = {190},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Computation and efficiency of potential function minimizers
of combinatorial congestion games. <em>MP</em>, <em>190</em>(1),
523–560. (<a href="https://doi.org/10.1007/s10107-020-01546-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the computation and efficiency of pure Nash equilibria in combinatorial congestion games, where the strategies of each player i are given by the binary vectors of a polytope $$P_i$$ . Our main goal is to understand which structural properties of such polytopal congestion games enable us to derive an efficient equilibrium selection procedure to compute pure Nash equilibria with attractive social cost approximation guarantees. To this aim, we identify two general properties of the underlying aggregation polytope $$P_N = \sum _i P_i$$ which are sufficient for our results to go through, namely the integer decomposition property (IDP) and the box-totally dual integrality property (box-TDI). Our main results for polytopal congestion games satisfying IDP and box-TDI are as follows: (i) we show that pure Nash equilibria can be computed in polynomial time. In fact, we obtain this result through a general framework for separable convex function minimization, which might be of independent interest. (ii) We bound the inefficiency of these equilibria and show that this provides a tight bound on the price of stability. (iii) We also prove that these results extend to strong equilibria for the “bottleneck variant” of polytopal congestion games. Examples of polytopal congestion games satisfying IDP and box-TDI include common source network congestion games, symmetric totally unimodular congestion games, non-symmetric matroid congestion games and symmetric matroid intersection congestion games (in particular, r-arborescences and strongly base-orderable matroids).},
  archive      = {J_MP},
  author       = {Kleer, Pieter and Schäfer, Guido},
  doi          = {10.1007/s10107-020-01546-6},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {523-560},
  shortjournal = {Math. Program.},
  title        = {Computation and efficiency of potential function minimizers of combinatorial congestion games},
  volume       = {190},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Prophet secretary through blind strategies. <em>MP</em>,
<em>190</em>(1), 483–521. (<a
href="https://doi.org/10.1007/s10107-020-01544-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the classic prophet inequality, a well-known problem in optimal stopping theory, samples from independent random variables (possibly differently distributed) arrive online. A gambler who knows the distributions, but cannot see the future, must decide at each point in time whether to stop and pick the current sample or to continue and lose that sample forever. The goal of the gambler is to maximize the expected value of what she picks and the performance measure is the worst case ratio between the expected value the gambler gets and what a prophet that sees all the realizations in advance gets. In the late seventies, Krengel and Sucheston (Bull Am Math Soc 83(4):745–747, 1977), established that this worst case ratio is 0.5. A particularly interesting variant is the so-called prophet secretary problem, in which the only difference is that the samples arrive in a uniformly random order. For this variant several algorithms are known to achieve a constant of $$1-1/e \approx 0.632$$ and very recently this barrier was slightly improved by Azar et al. (in: Proceedings of the ACM conference on economics and computation, EC, 2018). In this paper we introduce a new type of multi-threshold strategy, called blind strategy. Such a strategy sets a nonincreasing sequence of thresholds that depends only on the distribution of the maximum of the random variables, and the gambler stops the first time a sample surpasses the threshold of the stage. Our main result shows that these strategies can achieve a constant of 0.669 for the prophet secretary problem, improving upon the best known result of Azar et al. (in: Proceedings of the ACM conference on economics and computation, EC, 2018), and even that of Beyhaghi et al. (Improved approximations for posted price and second price mechanisms. CoRR arXiv:1807.03435 , 2018) that works in the case in which the gambler can select the order of the samples. The crux of the result is a very precise analysis of the underlying stopping time distribution for the gambler’s strategy that is inspired by the theory of Schur-convex functions. We further prove that our family of blind strategies cannot lead to a constant better than 0.675. Finally we prove that no algorithm for the gambler can achieve a constant better than $$\sqrt{3}-1 \approx 0.732$$ , which also improves upon a recent result of Azar et al. (in: Proceedings of the ACM conference on economics and computation, EC, 2018). This implies that the upper bound on what the gambler can get in the prophet secretary problem is strictly lower than what she can get in the i.i.d. case. This constitutes the first separation between the prophet secretary problem and the i.i.d. prophet inequality.},
  archive      = {J_MP},
  author       = {Correa, Jose and Saona, Raimundo and Ziliotto, Bruno},
  doi          = {10.1007/s10107-020-01544-8},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {483-521},
  shortjournal = {Math. Program.},
  title        = {Prophet secretary through blind strategies},
  volume       = {190},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Strengthening convex relaxations of 0/1-sets using boolean
formulas. <em>MP</em>, <em>190</em>(1), 467–482. (<a
href="https://doi.org/10.1007/s10107-020-01542-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In convex integer programming, various procedures have been developed to strengthen convex relaxations of sets of integer points. On the one hand, there exist several general-purpose methods that strengthen relaxations without specific knowledge of the set S of feasible integer points, such as popular linear programming or semi-definite programming hierarchies. On the other hand, various methods have been designed for obtaining strengthened relaxations for very specific sets S that arise in combinatorial optimization. We propose a new efficient method that interpolates between these two approaches. Our procedure strengthens any convex set containing a set $$ S \subseteq {0,1}^n $$ by exploiting certain additional information about S. Namely, the required extra information will be in the form of a Boolean formula $$\phi $$ defining the target set S. The new relaxation is obtained by “feeding” the convex set into the formula $$\phi $$ . We analyze various aspects regarding the strength of our procedure. As one application, interpreting an iterated application of our procedure as a hierarchy, our findings simplify, improve, and extend previous results by Bienstock and Zuckerberg on covering problems.},
  archive      = {J_MP},
  author       = {Fiorini, Samuel and Huynh, Tony and Weltge, Stefan},
  doi          = {10.1007/s10107-020-01542-w},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {467-482},
  shortjournal = {Math. Program.},
  title        = {Strengthening convex relaxations of 0/1-sets using boolean formulas},
  volume       = {190},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A new framework to relax composite functions in nonlinear
programs. <em>MP</em>, <em>190</em>(1), 427–466. (<a
href="https://doi.org/10.1007/s10107-020-01541-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we devise new relaxations for composite functions, which improve the prevalent factorable relaxations, without introducing additional variables, by exploiting the inner-function structure. We outer-approximate inner-functions using arbitrary under- and over-estimators and then convexify the outer-function over a polytope P, which models the ordering relationships between the inner-functions and their estimators and utilizes bound information on the inner-functions as well as on the estimators. We show that there is a subset Q of P, with significantly simpler combinatorial structure, such that the separation problem of the graph of the outer-function over P is polynomially equivalent, via a fast combinatorial algorithm, to that of its graph over Q. We specialize our study to consider the product of two inner-functions with one non-trivial underestimator for each inner-function. For the corresponding polytope P, we show that there are eight valid inequalities besides the four McCormick inequalities, which improve the factorable relaxation. Finally, we show that our results generalize to simultaneous convexification of a vector of outer-functions.},
  archive      = {J_MP},
  author       = {He, Taotao and Tawarmalani, Mohit},
  doi          = {10.1007/s10107-020-01541-x},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {427-466},
  shortjournal = {Math. Program.},
  title        = {A new framework to relax composite functions in nonlinear programs},
  volume       = {190},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Generalized chvátal-gomory closures for integer programs
with bounds on variables. <em>MP</em>, <em>190</em>(1), 393–425. (<a
href="https://doi.org/10.1007/s10107-020-01539-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Integer programming problems that arise in practice often involve decision variables with one or two sided bounds. In this paper, we consider a generalization of Chvátal-Gomory inequalities obtained by strengthening Chvátal-Gomory inequalities using the bounds on the variables. We prove that the closure of a rational polyhedron obtained after applying the generalized Chvátal-Gomory inequalities is also a rational polyhedron. This generalizes a result of Dunkel and Schulz on 0–1 problems to the case when some of the variables have upper or lower bounds or both while the rest of them are unbounded.},
  archive      = {J_MP},
  author       = {Dash, Sanjeeb and Günlük, Oktay and Lee, Dabeen},
  doi          = {10.1007/s10107-020-01539-5},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {393-425},
  shortjournal = {Math. Program.},
  title        = {Generalized chvátal-gomory closures for integer programs with bounds on variables},
  volume       = {190},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Quasi-monte carlo methods for two-stage stochastic
mixed-integer programs. <em>MP</em>, <em>190</em>(1), 361–392. (<a
href="https://doi.org/10.1007/s10107-020-01538-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider randomized QMC methods for approximating the expected recourse in two-stage stochastic optimization problems containing mixed-integer decisions in the second stage. It is known that the second-stage optimal value function is piecewise linear-quadratic with possible kinks and discontinuities at the boundaries of certain convex polyhedral sets. This structure is exploited to provide conditions implying that first and higher order terms of the integrand’s ANOVA decomposition (Math. Comp. 79 (2010), 953–966) have mixed weak first order partial derivatives. This leads to a good smooth approximation of the integrand and, hence, to good convergence rates of randomized QMC methods if the effective (superposition) dimension is low.},
  archive      = {J_MP},
  author       = {Leövey, H. and Römisch, W.},
  doi          = {10.1007/s10107-020-01538-6},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {361-392},
  shortjournal = {Math. Program.},
  title        = {Quasi-monte carlo methods for two-stage stochastic mixed-integer programs},
  volume       = {190},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The sum-of-squares hierarchy on the sphere and applications
in quantum information theory. <em>MP</em>, <em>190</em>(1), 331–360.
(<a href="https://doi.org/10.1007/s10107-020-01537-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the problem of maximizing a homogeneous polynomial on the unit sphere and its hierarchy of sum-of-squares relaxations. Exploiting the polynomial kernel technique, we obtain a quadratic improvement of the known convergence rate by Reznick and Doherty and Wehner. Specifically, we show that the rate of convergence is no worse than $$O(d^2/\ell ^2)$$ in the regime $$\ell = \Omega (d)$$ where $$\ell $$ is the level of the hierarchy and d the dimension, solving a problem left open in the recent paper by de Klerk and Laurent ( arXiv:1904.08828 ). Importantly, our analysis also works for matrix-valued polynomials on the sphere which has applications in quantum information for the Best Separable State problem. By exploiting the duality relation between sums of squares and the Doherty–Parrilo–Spedalieri hierarchy in quantum information theory, we show that our result generalizes to nonquadratic polynomials the convergence rates of Navascués, Owari and Plenio.},
  archive      = {J_MP},
  author       = {Fang, Kun and Fawzi, Hamza},
  doi          = {10.1007/s10107-020-01537-7},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {331-360},
  shortjournal = {Math. Program.},
  title        = {The sum-of-squares hierarchy on the sphere and applications in quantum information theory},
  volume       = {190},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Convergence rates for an inertial algorithm of gradient type
associated to a smooth non-convex minimization. <em>MP</em>,
<em>190</em>(1), 285–329. (<a
href="https://doi.org/10.1007/s10107-020-01534-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We investigate an inertial algorithm of gradient type in connection with the minimization of a non-convex differentiable function. The algorithm is formulated in the spirit of Nesterov’s accelerated convex gradient method. We prove some abstract convergence results which applied to our numerical scheme allow us to show that the generated sequences converge to a critical point of the objective function, provided a regularization of the objective function satisfies the Kurdyka–Łojasiewicz property. Further, we obtain convergence rates for the generated sequences and the objective function values formulated in terms of the Łojasiewicz exponent of a regularization of the objective function. Finally, some numerical experiments are presented in order to compare our numerical scheme and some algorithms well known in the literature.},
  archive      = {J_MP},
  author       = {László, Szilárd Csaba},
  doi          = {10.1007/s10107-020-01534-w},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {285-329},
  shortjournal = {Math. Program.},
  title        = {Convergence rates for an inertial algorithm of gradient type associated to a smooth non-convex minimization},
  volume       = {190},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Existence of efficient and properly efficient solutions to
problems of constrained vector optimization. <em>MP</em>,
<em>190</em>(1), 259–283. (<a
href="https://doi.org/10.1007/s10107-020-01532-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paper is devoted to the existence of global optimal solutions for a general class of nonsmooth problems of constrained vector optimization without boundedness assumptions on constraint set. The main attention is paid to the two major notions of optimality in vector problems: Pareto efficiency and proper efficiency in the sense of Geoffrion. Employing adequate tools of variational analysis and generalized differentiation, we first establish relationships between the notions of properness, M-tameness, and the Palais–Smale conditions formulated for the restriction of the vector cost mapping on the constraint set. These results are instrumental to derive verifiable necessary and sufficient conditions for the existence of Pareto efficient solutions in vector optimization. Furthermore, the developed approach allows us to obtain new sufficient conditions for the existence of Geoffrion-properly efficient solutions to such constrained vector problems.},
  archive      = {J_MP},
  author       = {Kim, Do Sang and Mordukhovich, Boris S. and Phạm, Tiến-Sơn and Van Tuyen, Nguyen},
  doi          = {10.1007/s10107-020-01532-y},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {259-283},
  shortjournal = {Math. Program.},
  title        = {Existence of efficient and properly efficient solutions to problems of constrained vector optimization},
  volume       = {190},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). On the linear convergence rates of exchange and continuous
methods for total variation minimization. <em>MP</em>, <em>190</em>(1),
221–257. (<a href="https://doi.org/10.1007/s10107-020-01530-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We analyze an exchange algorithm for the numerical solution total-variation regularized inverse problems over the space $$\mathcal {M}(\varOmega )$$ of Radon measures on a subset $$\varOmega $$ of $$\mathbb {R}^d$$ . Our main result states that under some regularity conditions, the method eventually converges linearly. Additionally, we prove that continuously optimizing the amplitudes of positions of the target measure will succeed at a linear rate with a good initialization. Finally, we propose to combine the two approaches into an alternating method and discuss the comparative advantages of this approach.},
  archive      = {J_MP},
  author       = {Flinth, Axel and de Gournay, Frédéric and Weiss, Pierre},
  doi          = {10.1007/s10107-020-01530-0},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {221-257},
  shortjournal = {Math. Program.},
  title        = {On the linear convergence rates of exchange and continuous methods for total variation minimization},
  volume       = {190},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Discrete optimization methods for group model selection in
compressed sensing. <em>MP</em>, <em>190</em>(1), 171–220. (<a
href="https://doi.org/10.1007/s10107-020-01529-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article we study the problem of signal recovery for group models. More precisely for a given set of groups, each containing a small subset of indices, and for given linear sketches of the true signal vector which is known to be group-sparse in the sense that its support is contained in the union of a small number of these groups, we study algorithms which successfully recover the true signal just by the knowledge of its linear sketches. We derive model projection complexity results and algorithms for more general group models than the state-of-the-art. We consider two versions of the classical iterative hard thresholding algorithm (IHT). The classical version iteratively calculates the exact projection of a vector onto the group model, while the approximate version (AM-IHT) uses a head- and a tail-approximation iteratively. We apply both variants to group models and analyse the two cases where the sensing matrix is a Gaussian matrix and a model expander matrix. To solve the exact projection problem on the group model, which is known to be equivalent to the maximum weight coverage problem, we use discrete optimization methods based on dynamic programming and Benders’ decomposition. The head- and tail-approximations are derived by a classical greedy-method and LP-rounding, respectively.},
  archive      = {J_MP},
  author       = {Bah, Bubacarr and Kurtz, Jannis and Schaudt, Oliver},
  doi          = {10.1007/s10107-020-01529-7},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {171-220},
  shortjournal = {Math. Program.},
  title        = {Discrete optimization methods for group model selection in compressed sensing},
  volume       = {190},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Finding and verifying the nucleolus of cooperative games.
<em>MP</em>, <em>190</em>(1), 135–170. (<a
href="https://doi.org/10.1007/s10107-020-01527-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The nucleolus offers a desirable payoff-sharing solution in cooperative games, thanks to its attractive properties—it always exists and lies in the core (if the core is non-empty), and it is unique. The nucleolus is considered as the most ‘stable’ solution in the sense that it lexicographically minimizes the dissatisfactions among all coalitions. Although computing the nucleolus is very challenging, the Kohlberg criterion offers a powerful method for verifying whether a solution is the nucleolus in relatively small games (i.e. with the number of players $$n \le 15$$ ). This approach, however, becomes more challenging for larger games because of the need to form and check a criterion involving possibly exponentially large collections of coalitions, with each collection potentially of an exponentially large size. The aim of this work is twofold. First, we develop an improved version of the Kohlberg criterion that involves checking the ‘balancedness’ of at most $$(n-1)$$ sets of coalitions. Second, we exploit these results and introduce a novel descent-based constructive algorithm to find the nucleolus efficiently. We demonstrate the performance of the new algorithms by comparing them with existing methods over different types of games. Our contribution also includes the first open-source code for computing the nucleolus for games of moderately large sizes.},
  archive      = {J_MP},
  author       = {Benedek, Márton and Fliege, Jörg and Nguyen, Tri-Dung},
  doi          = {10.1007/s10107-020-01527-9},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {135-170},
  shortjournal = {Math. Program.},
  title        = {Finding and verifying the nucleolus of cooperative games},
  volume       = {190},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Decomposition of arrow type positive semidefinite matrices
with application to topology optimization. <em>MP</em>, <em>190</em>(1),
105–134. (<a href="https://doi.org/10.1007/s10107-020-01526-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Decomposition of large matrix inequalities for matrices with chordal sparsity graph has been recently used by Kojima et al. (Math Program 129(1):33–68, 2011) to reduce problem size of large scale semidefinite optimization (SDO) problems and thus increase efficiency of standard SDO software. A by-product of such a decomposition is the introduction of new dense small-size matrix variables. We will show that for arrow type matrices satisfying suitable assumptions, the additional matrix variables have rank one and can thus be replaced by vector variables of the same dimensions. This leads to significant improvement in efficiency of standard SDO software. We will apply this idea to the problem of topology optimization formulated as a large scale linear semidefinite optimization problem. Numerical examples will demonstrate tremendous speed-up in the solution of the decomposed problems, as compared to the original large scale problem. In our numerical example the decomposed problems exhibit linear growth in complexity, compared to the more than cubic growth in the original problem formulation. We will also give a connection of our approach to the standard theory of domain decomposition and show that the additional vector variables are outcomes of the corresponding discrete Steklov–Poincaré operators.},
  archive      = {J_MP},
  author       = {Kočvara, Michal},
  doi          = {10.1007/s10107-020-01526-w},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {105-134},
  shortjournal = {Math. Program.},
  title        = {Decomposition of arrow type positive semidefinite matrices with application to topology optimization},
  volume       = {190},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Correction to: A scaling algorithm for optimizing arbitrary
functions over vertices of polytopes. <em>MP</em>, <em>190</em>(1),
103–104. (<a href="https://doi.org/10.1007/s10107-021-01682-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_MP},
  author       = {Chubanov, Sergei},
  doi          = {10.1007/s10107-021-01682-7},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {103-104},
  shortjournal = {Math. Program.},
  title        = {Correction to: A scaling algorithm for optimizing arbitrary functions over vertices of polytopes},
  volume       = {190},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). A scaling algorithm for optimizing arbitrary functions over
vertices of polytopes. <em>MP</em>, <em>190</em>(1), 89–102. (<a
href="https://doi.org/10.1007/s10107-020-01522-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we present a scaling algorithm for minimizing arbitrary functions over vertices of polytopes in an oracle model of computation which includes an augmentation oracle. For the binary case, when the vertices are 0–1 vectors, we show that the oracle time is polynomial. Also, this algorithm allows us to generalize some concepts of combinatorial optimization concerning performance bounds of greedy algorithms and leads to new bounds for the complexity of the simplex method.},
  archive      = {J_MP},
  author       = {Chubanov, Sergei},
  doi          = {10.1007/s10107-020-01522-0},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {89-102},
  shortjournal = {Math. Program.},
  title        = {A scaling algorithm for optimizing arbitrary functions over vertices of polytopes},
  volume       = {190},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Accelerated proximal point method for maximally monotone
operators. <em>MP</em>, <em>190</em>(1), 57–87. (<a
href="https://doi.org/10.1007/s10107-021-01643-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes an accelerated proximal point method for maximally monotone operators. The proof is computer-assisted via the performance estimation problem approach. The proximal point method includes various well-known convex optimization methods, such as the proximal method of multipliers and the alternating direction method of multipliers, and thus the proposed acceleration has wide applications. Numerical experiments are presented to demonstrate the accelerating behaviors.},
  archive      = {J_MP},
  author       = {Kim, Donghwan},
  doi          = {10.1007/s10107-021-01643-0},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {57-87},
  shortjournal = {Math. Program.},
  title        = {Accelerated proximal point method for maximally monotone operators},
  volume       = {190},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Bi-perspective functions for mixed-integer fractional
programs with indicator variables. <em>MP</em>, <em>190</em>(1), 39–55.
(<a href="https://doi.org/10.1007/s10107-020-01519-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Perspective functions have long been used to convert fractional programs into convex programs. More recently, they have been used to form tight relaxations of mixed-integer nonlinear programs with so-called indicator variables. Motivated by a practical application (maximising energy efficiency in an OFDMA system), we consider problems that have a fractional objective and indicator variables simultaneously. To obtain a tight relaxation of such problems, one must consider what we call a “bi-perspective” (Bi-P) function. An analysis of Bi-P functions leads to the derivation of a new kind of cutting planes, which we call “Bi-P-cuts”. Computational results indicate that Bi-P-cuts typically close a substantial proportion of the integrality gap.},
  archive      = {J_MP},
  author       = {Letchford, Adam N. and Ni, Qiang and Zhong, Zhaoyu},
  doi          = {10.1007/s10107-020-01519-9},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {39-55},
  shortjournal = {Math. Program.},
  title        = {Bi-perspective functions for mixed-integer fractional programs with indicator variables},
  volume       = {190},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). On a multistage discrete stochastic optimization problem
with stochastic constraints and nested sampling. <em>MP</em>,
<em>190</em>(1), 1–37. (<a
href="https://doi.org/10.1007/s10107-020-01518-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a multistage stochastic discrete program in which constraints on any stage might involve expectations that cannot be computed easily and are approximated by simulation. We study a sample average approximation (SAA) approach that uses nested sampling, in which at each stage, a number of scenarios are examined and a number of simulation replications are performed for each scenario to estimate the next-stage constraints. This approach provides an approximate solution to the multistage problem. To establish the consistency of the SAA approach, we first consider a two-stage problem and show that in the second-stage problem, given a scenario, the optimal values and solutions of the SAA converge to those of the true problem with probability one when the sample sizes go to infinity. These convergence results do not hold uniformly over all possible scenarios for the second stage problem. We are nevertheless able to prove that the optimal values and solutions of the SAA converge to the true ones with probability one when the sample sizes at both stages increase to infinity. We also prove exponential convergence of the probability of a large deviation for the optimal value of the SAA, the true value of an optimal solution of the SAA, and the probability that any optimal solution to the SAA is an optimal solution of the true problem. All of these results can be extended to a multistage setting and we explain how to do it. Our framework and SAA results cover a large variety of resource allocation problems for which at each stage after the first one, new information becomes available and the allocation can be readjusted, under constraints that involve expectations estimated by Monte Carlo. As an illustration, we apply this SAA method to a staffing problem in a call center, in which the goal is to optimize the numbers of agents of each type under some constraints on the quality of service (QoS). The staffing allocation has to be decided under an uncertain arrival rate with a prior distribution in the first stage, and can be adjusted at some additional cost when better information on the arrival rate becomes available in later stages.},
  archive      = {J_MP},
  author       = {Ta, Thuy Anh and Mai, Tien and Bastin, Fabian and L’Ecuyer, Pierre},
  doi          = {10.1007/s10107-020-01518-w},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {1-37},
  shortjournal = {Math. Program.},
  title        = {On a multistage discrete stochastic optimization problem with stochastic constraints and nested sampling},
  volume       = {190},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). New extremal principles with applications to stochastic and
semi-infinite programming. <em>MP</em>, <em>189</em>(1), 527–553. (<a
href="https://doi.org/10.1007/s10107-020-01548-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper develops new extremal principles of variational analysis that are motivated by applications to constrained problems of stochastic programming and semi-infinite programming without smoothness and/or convexity assumptions. These extremal principles concern measurable set-valued mappings/multifunctions with values in finite-dimensional spaces and are established in both approximate and exact forms. The obtained principles are instrumental to derive via variational approaches integral representations and upper estimates of regular and limiting normals cones to essential intersections of sets defined by measurable multifunctions, which are in turn crucial for novel applications to stochastic and semi-infinite programming.},
  archive      = {J_MP},
  author       = {Mordukhovich, Boris S. and Pérez-Aros, Pedro},
  doi          = {10.1007/s10107-020-01548-4},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {527-553},
  shortjournal = {Math. Program.},
  title        = {New extremal principles with applications to stochastic and semi-infinite programming},
  volume       = {189},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). On the sensitivity of the optimal partition for parametric
second-order conic optimization. <em>MP</em>, <em>189</em>(1), 491–525.
(<a href="https://doi.org/10.1007/s10107-021-01690-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, using an optimal partition approach, we study the parametric analysis of a second-order conic optimization problem, where the objective function is perturbed along a fixed direction. We characterize the notions of so-called invariancy set and nonlinearity interval, which serve as stability regions of the optimal partition. We then propose, under the strict complementarity condition, an iterative procedure to compute a nonlinearity interval of the optimal partition. Furthermore, under primal and dual nondegeneracy conditions, we show that a boundary point of a nonlinearity interval can be numerically identified from a nonlinear reformulation of the parametric second-order conic optimization problem. Our theoretical results are supported by numerical experiments.},
  archive      = {J_MP},
  author       = {Mohammad-Nezhad, Ali and Terlaky, Tamás},
  doi          = {10.1007/s10107-021-01690-7},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {491-525},
  shortjournal = {Math. Program.},
  title        = {On the sensitivity of the optimal partition for parametric second-order conic optimization},
  volume       = {189},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Lipschitz-like property relative to a set and the
generalized mordukhovich criterion. <em>MP</em>, <em>189</em>(1),
455–489. (<a href="https://doi.org/10.1007/s10107-020-01568-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we will establish some necessary condition and sufficient condition respectively for a set-valued mapping to have the Lipschitz-like property relative to a closed set by employing regular normal cone and limiting normal cone of a restricted graph of the set-valued mapping. We will obtain a complete characterization for a set-valued mapping to have the Lipschitz-property relative to a closed and convex set by virtue of the projection of the coderivative onto a tangent cone. Furthermore, by introducing a projectional coderivative of set-valued mappings, we establish a verifiable generalized Mordukhovich criterion for the Lipschitz-like property relative to a closed and convex set. We will study the representation of the graphical modulus of a set-valued mapping relative to a closed and convex set by using the outer norm of the corresponding projectional coderivative value. For an extended real-valued function, we will apply the obtained results to investigate its Lipschitz continuity relative to a closed and convex set and the Lipschitz-like property of a level-set mapping relative to a half line.},
  archive      = {J_MP},
  author       = {Meng, K. W. and Li, M. H. and Yao, W. F. and Yang, X. Q.},
  doi          = {10.1007/s10107-020-01568-0},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {455-489},
  shortjournal = {Math. Program.},
  title        = {Lipschitz-like property relative to a set and the generalized mordukhovich criterion},
  volume       = {189},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Closed convex sets with an open or closed gauss range.
<em>MP</em>, <em>189</em>(1), 433–454. (<a
href="https://doi.org/10.1007/s10107-020-01561-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We characterize the closed convex subsets of $${\mathbb {R}}^{n}$$ which have open or closed Gauss ranges. Some special attention is paid to epigraphs of lower semicontinuous convex functions.},
  archive      = {J_MP},
  author       = {Martínez-Legaz, Juan Enrique and Pintea, Cornel},
  doi          = {10.1007/s10107-020-01561-7},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {433-454},
  shortjournal = {Math. Program.},
  title        = {Closed convex sets with an open or closed gauss range},
  volume       = {189},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Duality for extended infinite monotropic optimization
problems. <em>MP</em>, <em>189</em>(1), 409–432. (<a
href="https://doi.org/10.1007/s10107-020-01557-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We establish necessary and sufficient conditions for strong duality of extended monotropic optimization problems with possibly infinite sum of separable functions. The results are applied to a minimization problem of the infinite sum of proper convex functions. We consider a truncation method for duality and obtain the zero duality gap by using only dual variable of finite support. An application to minimum cost flow problems in infinite networks is also discussed.},
  archive      = {J_MP},
  author       = {Luc, Dinh The and Volle, Michel},
  doi          = {10.1007/s10107-020-01557-3},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {409-432},
  shortjournal = {Math. Program.},
  title        = {Duality for extended infinite monotropic optimization problems},
  volume       = {189},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A unified concept of approximate and quasi efficient
solutions and associated subdifferentials in multiobjective
optimization. <em>MP</em>, <em>189</em>(1), 379–407. (<a
href="https://doi.org/10.1007/s10107-020-01597-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we introduce some new notions of quasi efficiency and quasi proper efficiency for multiobjective optimization problems that reduce to the most important concepts of approximate and quasi efficient solutions given up to now. We establish main properties and provide characterizations for these solutions by linear and nonlinear scalarizations. With the help of quasi efficient solutions, a generalized subdifferential of a vector mapping is introduced, which generates a number of approximate subdifferentials frequently used in optimization in a unifying way. The generalized subdifferential is related to the classical subdifferential of real functions by the method of scalarization. An application of generalized subdifferential to express optimality conditions for quasi efficient solutions is also given.},
  archive      = {J_MP},
  author       = {Huerga, L. and Jiménez, B. and Luc, D. T. and Novo, V.},
  doi          = {10.1007/s10107-020-01597-9},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {379-407},
  shortjournal = {Math. Program.},
  title        = {A unified concept of approximate and quasi efficient solutions and associated subdifferentials in multiobjective optimization},
  volume       = {189},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Strongly stable c-stationary points for mathematical
programs with complementarity constraints. <em>MP</em>, <em>189</em>(1),
339–377. (<a href="https://doi.org/10.1007/s10107-020-01553-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we consider the class of mathematical programs with complementarity constraints (MPCC). Under an appropriate constraint qualification of Mangasarian–Fromovitz type we present a topological and an equivalent algebraic characterization of a strongly stable C-stationary point for MPCC. Strong stability refers to the local uniqueness, existence and continuous dependence of a solution for each sufficiently small perturbed problem where perturbations up to second order are allowed. This concept of strong stability was originally introduced by Kojima for standard nonlinear optimization; here, its generalization to MPCC demands a sophisticated technique which takes the disjunctive properties of the solution set of MPCC into account.},
  archive      = {J_MP},
  author       = {Hernández Escobar, Daniel and Rückmann, Jan-J.},
  doi          = {10.1007/s10107-020-01553-7},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {339-377},
  shortjournal = {Math. Program.},
  title        = {Strongly stable C-stationary points for mathematical programs with complementarity constraints},
  volume       = {189},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Characterizing quasiconvexity of the pointwise infimum of a
family of arbitrary translations of quasiconvex functions, with
applications to sums and quasiconvex optimization. <em>MP</em>,
<em>189</em>(1), 315–337. (<a
href="https://doi.org/10.1007/s10107-021-01647-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is well-known that the sum of two quasiconvex functions is not quasiconvex in general, and the same occurs with the minimum. Although apparently these two statements (for the sum or minimum) have nothing in common, they are related, as we show in this paper. To develop our study, the notion of quasiconvex family is introduced, and we establish various characterizations of such a concept: one of them being the quasiconvexity of the pointwise infimum of arbitrary translations of quasiconvex functions in the family; another is the convexity of the union of any two of their sublevel sets; a third one is the quasiconvexity of the sum of the quasiconvex functions, composed with arbitrary nondecreasing functions. As a by-product, any of the aforementioned characterizations, besides providing quasiconvexity of the sum, also implies the semistrict quasiconvexity of the sum if every function in the family has the same property. Three concrete applications in quasiconvex optimization are presented: First, we establish the convexity of the (Benson) proper efficient solution set to a quasiconvex vector optimization problem; second, we derive conditions that allow us to reduce a constrained optimization problem to one with a single inequality constraint, and finally, we show a class of quasiconvex minimization problems having zero duality gap.},
  archive      = {J_MP},
  author       = {Flores-Bazán, F. and García, Y. and Hadjisavvas, N.},
  doi          = {10.1007/s10107-021-01647-w},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {315-337},
  shortjournal = {Math. Program.},
  title        = {Characterizing quasiconvexity of the pointwise infimum of a family of arbitrary translations of quasiconvex functions, with applications to sums and quasiconvex optimization},
  volume       = {189},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Error bounds for inequality systems defining convex sets.
<em>MP</em>, <em>189</em>(1), 299–314. (<a
href="https://doi.org/10.1007/s10107-020-01575-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The main goal in this paper is to devise an approach to explicitly calculate the constant in the Hoffman’s error bound for (not necessarily convex) inequality systems defining convex sets. We give a constructive proof of the Hoffman’s error bound and show that we can use our method to calculate the constant at least in simple cases.},
  archive      = {J_MP},
  author       = {Dutta, Joydeep and Martínez-Legaz, Juan Enrique},
  doi          = {10.1007/s10107-020-01575-1},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {299-314},
  shortjournal = {Math. Program.},
  title        = {Error bounds for inequality systems defining convex sets},
  volume       = {189},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Duality for constrained robust sum optimization problems.
<em>MP</em>, <em>189</em>(1), 271–297. (<a
href="https://doi.org/10.1007/s10107-020-01494-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given an infinite family of extended real-valued functions $$f_{i}$$ , $$i\in I,$$ and a family $${\mathcal {H}}$$ of nonempty finite subsets of I,  the $${\mathcal {H}}$$ -partial robust sum of $$f_{i}$$ , $$i\in I,$$ is the supremum, for $$J\in {\mathcal {H}},$$ of the finite sums $$\sum _{j\in J}f_{j}$$ . These infinite sums arise in a natural way in location problems as well as in functional approximation problems, and include as particular cases the well-known sup function and the so-called robust sum function, corresponding to the set $$ {\mathcal {H}}$$ of all nonempty finite subsets of I,  whose unconstrained minimization was analyzed in previous papers of three of the authors ( https://doi.org/10.1007/s11228-019-00515-2 and https://doi.org/10.1007/s00245-019-09596-9 ). In this paper, we provide ordinary and stable zero duality gap and strong duality theorems for the minimization of a given $${\mathcal {H}}$$ -partial robust sum under constraints, as well as closedness and convex criteria for the formulas on the subdifferential of the sup-function.},
  archive      = {J_MP},
  author       = {Dinh, N. and Goberna, M. A. and Long, D. H. and Volle, M.},
  doi          = {10.1007/s10107-020-01494-1},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {271-297},
  shortjournal = {Math. Program.},
  title        = {Duality for constrained robust sum optimization problems},
  volume       = {189},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Subregular recourse in nonlinear multistage stochastic
optimization. <em>MP</em>, <em>189</em>(1), 249–270. (<a
href="https://doi.org/10.1007/s10107-020-01612-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider nonlinear multistage stochastic optimization problems in the spaces of integrable functions. We allow for nonlinear dynamics and general objective functionals, including dynamic risk measures. We study causal operators describing the dynamics of the system and derive the Clarke subdifferential for a penalty function involving such operators. Then we introduce the concept of subregular recourse in nonlinear multistage stochastic optimization and establish subregularity of the resulting systems in two formulations: with built-in nonanticipativity and with explicit nonanticipativity constraints. Finally, we derive optimality conditions for both formulations and study their relations.},
  archive      = {J_MP},
  author       = {Dentcheva, Darinka and Ruszczyński, Andrzej},
  doi          = {10.1007/s10107-020-01612-z},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {249-270},
  shortjournal = {Math. Program.},
  title        = {Subregular recourse in nonlinear multistage stochastic optimization},
  volume       = {189},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Subdifferential of the supremum function: Moving back and
forth between continuous and non-continuous settings. <em>MP</em>,
<em>189</em>(1), 217–247. (<a
href="https://doi.org/10.1007/s10107-020-01592-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we establish general formulas for the subdifferential of the pointwise supremum of convex functions, which cover and unify both the compact continuous and the non-compact non-continuous settings. From the non-continuous to the continuous setting, we proceed by a compactification-based approach which leads us to problems having compact index sets and upper semi-continuously indexed mappings, giving rise to new characterizations of the subdifferential of the supremum by means of upper semicontinuous regularized functions and an enlarged compact index set. In the opposite sense, we rewrite the subdifferential of these new regularized functions by using the original data, also leading us to new results on the subdifferential of the supremum. We give two applications in the last section, the first one concerning the nonconvex Fenchel duality, and the second one establishing Fritz-John and KKT conditions in convex semi-infinite programming.},
  archive      = {J_MP},
  author       = {Correa, R. and Hantoute, A. and López, M. A.},
  doi          = {10.1007/s10107-020-01592-0},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {217-247},
  shortjournal = {Math. Program.},
  title        = {Subdifferential of the supremum function: Moving back and forth between continuous and non-continuous settings},
  volume       = {189},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Steklov convexification and a trajectory method for global
optimization of multivariate quartic polynomials. <em>MP</em>,
<em>189</em>(1), 187–216. (<a
href="https://doi.org/10.1007/s10107-020-01536-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Steklov function $$\mu _f(\cdot ,t)$$ is defined to average a continuous function f at each point of its domain by using a window of size given by $$t&gt;0$$ . It has traditionally been used to approximate f smoothly with small values of t. In this paper, we first find a concise and useful expression for $$\mu _f$$ for the case when f is a multivariate quartic polynomial. Then we show that, for large enough t, $$\mu _f(\cdot ,t)$$ is convex; in other words, $$\mu _f(\cdot ,t)$$ convexifies f. We provide an easy-to-compute formula for t with which $$\mu _f$$ convexifies certain classes of polynomials. We present an algorithm which constructs, via an ODE involving $$\mu _f$$ , a trajectory x(t) emanating from the minimizer of the convexified f and ending at x(0), an estimate of the global minimizer of f. For a family of quartic polynomials, we provide an estimate for the size of a ball that contains all its global minimizers. Finally, we illustrate the working of our method by means of numerous computational examples.},
  archive      = {J_MP},
  author       = {Burachik, Regina S. and Kaya, C. Yalçın},
  doi          = {10.1007/s10107-020-01536-8},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {187-216},
  shortjournal = {Math. Program.},
  title        = {Steklov convexification and a trajectory method for global optimization of multivariate quartic polynomials},
  volume       = {189},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Tikhonov regularization of a second order dynamical system
with hessian driven damping. <em>MP</em>, <em>189</em>(1), 151–186. (<a
href="https://doi.org/10.1007/s10107-020-01528-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We investigate the asymptotic properties of the trajectories generated by a second-order dynamical system with Hessian driven damping and a Tikhonov regularization term in connection with the minimization of a smooth convex function in Hilbert spaces. We obtain fast convergence results for the function values along the trajectories. The Tikhonov regularization term enables the derivation of strong convergence results of the trajectory to the minimizer of the objective function of minimum norm.},
  archive      = {J_MP},
  author       = {Boţ, Radu Ioan and Csetnek, Ernö Robert and László, Szilárd Csaba},
  doi          = {10.1007/s10107-020-01528-8},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {151-186},
  shortjournal = {Math. Program.},
  title        = {Tikhonov regularization of a second order dynamical system with hessian driven damping},
  volume       = {189},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A regularized smoothing method for fully parameterized
convex problems with applications to convex and nonconvex two-stage
stochastic programming. <em>MP</em>, <em>189</em>(1), 117–149. (<a
href="https://doi.org/10.1007/s10107-020-01582-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present an approach to regularize and approximate solution mappings of parametric convex optimization problems that combines interior penalty (log-barrier) solutions with Tikhonov regularization. Because the regularized mappings are single-valued and smooth under reasonable conditions, they can be used to build a computationally practical smoothing for the associated optimal value function. The value function in question, while resulting from parameterized convex problems, need not be convex. One motivating application of interest is two-stage (possibly nonconvex) stochastic programming. We show that our approach, being computationally implementable, provides locally bounded upper bounds for the subdifferential of the value function of qualified convex problems. As a by-product of our development, we also recover that in the given setting the value function is locally Lipschitz continuous. Numerical experiments are presented for two-stage convex stochastic programming problems, comparing the approach with the bundle method for nonsmooth optimization.},
  archive      = {J_MP},
  author       = {Borges, Pedro and Sagastizábal, Claudia and Solodov, Mikhail},
  doi          = {10.1007/s10107-020-01582-2},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {117-149},
  shortjournal = {Math. Program.},
  title        = {A regularized smoothing method for fully parameterized convex problems with applications to convex and nonconvex two-stage stochastic programming},
  volume       = {189},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Characterization of filippov representable maps and clarke
subdifferentials. <em>MP</em>, <em>189</em>(1), 99–115. (<a
href="https://doi.org/10.1007/s10107-020-01540-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The ordinary differential equation $$\dot{x}(t)=f(x(t)), \; t \ge 0 $$ , for f measurable, is not sufficiently regular to guarantee existence of solutions. To remedy this we may relax the problem by replacing the function f with its Filippov regularization $$F_{f}$$ and consider the differential inclusion $$\dot{x}(t)\in F_{f}(x(t))$$ which always has a solution. It is interesting to know, inversely, when a set-valued map $$\Phi $$ can be obtained as the Filippov regularization of a (single-valued, measurable) function. In this work we give a full characterization of such set-valued maps, hereby called Filippov representable. This characterization also yields an elegant description of those maps that are Clarke subdifferentials of a Lipschitz function.},
  archive      = {J_MP},
  author       = {Bivas, Mira and Daniilidis, Aris and Quincampoix, Marc},
  doi          = {10.1007/s10107-020-01540-y},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {99-115},
  shortjournal = {Math. Program.},
  title        = {Characterization of filippov representable maps and clarke subdifferentials},
  volume       = {189},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Lipschitz modulus of linear and convex inequality systems
with the hausdorff metric. <em>MP</em>, <em>189</em>(1), 75–98. (<a
href="https://doi.org/10.1007/s10107-020-01543-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper analyzes the Lipschitz behavior of the feasible set mapping associated with linear and convex inequality systems in $${\mathbb {R}}^{n}$$ . To start with, we deal with the parameter space of linear (finite/semi-infinite) systems identified with the corresponding sets of coefficient vectors, which are assumed to be closed subsets of $${\mathbb {R}} ^{n+1}$$ . In this framework the size of perturbations is measured by means of the (extended) Hausdorff distance. A direct antecedent, extensively studied in the literature, comes from considering the parameter space of all linear systems with a fixed index set, T, where the Chebyshev (extended) distance is used to measure perturbations. In the present work we propose an appropriate indexation strategy which allows us to establish the equality of the Lipschitz moduli of the feasible set mappings in both parametric contexts, as well as to benefit from existing results in the Chebyshev setting for transferring them to the Hausdorff one. In a second stage, the possibility of perturbing directly the set of coefficient vectors of a linear system leads to new contributions on the Lipschitz behavior of convex systems via linearization techniques.},
  archive      = {J_MP},
  author       = {Beer, G. and Cánovas, M. J. and López, M. A. and Parra, J.},
  doi          = {10.1007/s10107-020-01543-9},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {75-98},
  shortjournal = {Math. Program.},
  title        = {Lipschitz modulus of linear and convex inequality systems with the hausdorff metric},
  volume       = {189},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Generalized monotone operators and their averaged
resolvents. <em>MP</em>, <em>189</em>(1), 55–74. (<a
href="https://doi.org/10.1007/s10107-020-01500-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The correspondence between the monotonicity of a (possibly) set-valued operator and the firm nonexpansiveness of its resolvent is a key ingredient in the convergence analysis of many optimization algorithms. Firmly nonexpansive operators form a proper subclass of the more general—but still pleasant from an algorithmic perspective—class of averaged operators. In this paper, we introduce the new notion of conically nonexpansive operators which generalize nonexpansive mappings. We characterize averaged operators as being resolvents of comonotone operators under appropriate scaling. As a consequence, we characterize the proximal point mappings associated with hypoconvex functions as cocoercive operators, or equivalently; as displacement mappings of conically nonexpansive operators. Several examples illustrate our analysis and demonstrate tightness of our results.},
  archive      = {J_MP},
  author       = {Bauschke, Heinz H. and Moursi, Walaa M. and Wang, Xianfu},
  doi          = {10.1007/s10107-020-01500-6},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {55-74},
  shortjournal = {Math. Program.},
  title        = {Generalized monotone operators and their averaged resolvents},
  volume       = {189},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Sensitivity analysis of maximally monotone inclusions via
the proto-differentiability of the resolvent operator. <em>MP</em>,
<em>189</em>(1), 37–54. (<a
href="https://doi.org/10.1007/s10107-020-01515-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is devoted to the study of sensitivity to perturbation of parametrized variational inclusions involving maximally monotone operators in a Hilbert space. The perturbation of all the data involved in the problem is taken into account. Using the concept of proto-differentiability of a multifunction and the notion of semi-differentiability of a single-valued map, we establish the differentiability of the solution of a parametrized monotone inclusion. We also give an exact formula of the proto-derivative of the resolvent operator associated to the maximally monotone parameterized variational inclusion. This shows that the derivative of the solution of the parametrized variational inclusion obeys the same pattern by being itself a solution of a variational inclusion involving the semi-derivative and the proto-derivative of the associated maps. An application to the study of the sensitivity analysis of a parametrized primal-dual composite monotone inclusion is given. Under some sufficient conditions on the data, it is shown that the primal and the dual solutions are differentiable and their derivatives belong to the derivative of the associated Kuhn–Tucker set.},
  archive      = {J_MP},
  author       = {Adly, Samir and Rockafellar, R. Tyrrell},
  doi          = {10.1007/s10107-020-01515-z},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {37-54},
  shortjournal = {Math. Program.},
  title        = {Sensitivity analysis of maximally monotone inclusions via the proto-differentiability of the resolvent operator},
  volume       = {189},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). New metric properties for prox-regular sets. <em>MP</em>,
<em>189</em>(1), 7–36. (<a
href="https://doi.org/10.1007/s10107-020-01525-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we present diverse new metric properties that prox-regular sets shared with convex ones. At the heart of our work lie the Legendre-Fenchel transform and complements of balls. First, we show that a connected prox-regular set is completely determined by the Legendre-Fenchel transform of a suitable perturbation of its indicator function. Then, we prove that such a function is also the right tool to extend, to the context of prox-regular sets, the famous connection between the distance function and the support function of a convex set. On the other hand, given a prox-regular set, we examine the intersection of complements of open balls containing the set. We establish that the distance of a point to a prox-regular set is the maximum of the distances of the point from boundaries of all such complements separating the set and the point. This is in the line of the known result expressing the distance from a convex set in terms of separating hyperplanes. To the best of our knowledge, these results are new in the literature and show that the class of prox-regular sets have good properties known in convex analysis.},
  archive      = {J_MP},
  author       = {Adly, S. and Nacry, F. and Thibault, L.},
  doi          = {10.1007/s10107-020-01525-x},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {7-36},
  shortjournal = {Math. Program.},
  title        = {New metric properties for prox-regular sets},
  volume       = {189},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Special issue: Continuous optimization and stability
analysis. <em>MP</em>, <em>189</em>(1), 1–5. (<a
href="https://doi.org/10.1007/s10107-021-01695-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_MP},
  author       = {Mordukhovich, B. S. and Parra, J. and Shapiro, A.},
  doi          = {10.1007/s10107-021-01695-2},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {1-5},
  shortjournal = {Math. Program.},
  title        = {Special issue: Continuous optimization and stability analysis},
  volume       = {189},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A solution framework for linear PDE-constrained
mixed-integer problems. <em>MP</em>, <em>188</em>(2), 695–728. (<a
href="https://doi.org/10.1007/s10107-021-01626-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a general numerical solution method for control problems with state variables defined by a linear PDE over a finite set of binary or continuous control variables. We show empirically that a naive approach that applies a numerical discretization scheme to the PDEs to derive constraints for a mixed-integer linear program (MILP) leads to systems that are too large to be solved with state-of-the-art solvers for MILPs, especially if we desire an accurate approximation of the state variables. Our framework comprises two techniques to mitigate the rise of computation times with increasing discretization level: First, the linear system is solved for a basis of the control space in a preprocessing step. Second, certain constraints are just imposed on demand via the IBM ILOG CPLEX feature of a lazy constraint callback. These techniques are compared with an approach where the relations obtained by the discretization of the continuous constraints are directly included in the MILP. We demonstrate our approach on two examples: modeling of the spread of wildfire and the mitigation of water contamination. In both examples the computational results demonstrate that the solution time is significantly reduced by our methods. In particular, the dependence of the computation time on the size of the spatial discretization of the PDE is significantly reduced.},
  archive      = {J_MP},
  author       = {Gnegel, Fabian and Fügenschuh, Armin and Hagel, Michael and Leyffer, Sven and Stiemer, Marcus},
  doi          = {10.1007/s10107-021-01626-1},
  journal      = {Mathematical Programming},
  number       = {2},
  pages        = {695-728},
  shortjournal = {Math. Program.},
  title        = {A solution framework for linear PDE-constrained mixed-integer problems},
  volume       = {188},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Mixed-integer optimal control under minimum dwell time
constraints. <em>MP</em>, <em>188</em>(2), 653–694. (<a
href="https://doi.org/10.1007/s10107-020-01533-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tailored Mixed-Integer Optimal Control policies for real-world applications usually have to avoid very short successive changes of the active integer control. Minimum dwell time (MDT) constraints express this requirement and can be included into the combinatorial integral approximation decomposition, which solves mixed-integer optimal control problems (MIOCPs) to $$\epsilon $$ -optimality by solving one continuous nonlinear program and one mixed-integer linear program (MILP). Within this work, we analyze the integrality gap of MIOCPs under MDT constraints by providing tight upper bounds on the MILP subproblem. We suggest different rounding schemes for constructing MDT feasible control solutions, e.g., we propose a modification of Sum Up Rounding. A numerical study supplements the theoretical results and compares objective values of integer feasible and relaxed solutions.},
  archive      = {J_MP},
  author       = {Zeile, Clemens and Robuschi, Nicolò and Sager, Sebastian},
  doi          = {10.1007/s10107-020-01533-x},
  journal      = {Mathematical Programming},
  number       = {2},
  pages        = {653-694},
  shortjournal = {Math. Program.},
  title        = {Mixed-integer optimal control under minimum dwell time constraints},
  volume       = {188},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Mixed-integer optimal control problems with switching costs:
A shortest path approach. <em>MP</em>, <em>188</em>(2), 621–652. (<a
href="https://doi.org/10.1007/s10107-020-01581-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We investigate an extension of Mixed-Integer Optimal Control Problems by adding switching costs, which enables the penalization of chattering and extends current modeling capabilities. The decomposition approach, consisting of solving a partial outer convexification to obtain a relaxed solution and using rounding schemes to obtain a discrete-valued control can still be applied, but the rounding turns out to be difficult in the presence of switching costs or switching constraints as the underlying problem is an Integer Program. We therefore reformulate the rounding problem into a shortest path problem on a parameterized family of directed acyclic graphs (DAGs). Solving the shortest path problem then allows to minimize switching costs and still maintain approximability with respect to the tunable DAG parameter $$\theta $$ . We provide a proof of a runtime bound on equidistant rounding grids, where the bound is linear in time discretization granularity and polynomial in $$\theta $$ . The efficacy of our approach is demonstrated by a comparison with an integer programming approach on a benchmark problem.},
  archive      = {J_MP},
  author       = {Bestehorn, Felix and Hansknecht, Christoph and Kirches, Christian and Manns, Paul},
  doi          = {10.1007/s10107-020-01581-3},
  journal      = {Mathematical Programming},
  number       = {2},
  pages        = {621-652},
  shortjournal = {Math. Program.},
  title        = {Mixed-integer optimal control problems with switching costs: A shortest path approach},
  volume       = {188},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Penalty alternating direction methods for mixed-integer
optimal control with combinatorial constraints. <em>MP</em>,
<em>188</em>(2), 599–619. (<a
href="https://doi.org/10.1007/s10107-021-01656-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider mixed-integer optimal control problems with combinatorial constraints that couple over time such as minimum dwell times. We analyze a lifting and decomposition approach into a mixed-integer optimal control problem without combinatorial constraints and a mixed-integer problem for the combinatorial constraints in the control space. Both problems can be solved very efficiently with existing methods such as outer convexification with sum-up-rounding strategies and mixed-integer linear programming techniques. The coupling is handled using a penalty-approach. We provide an exactness result for the penalty which yields a solution approach that convergences to partial minima. We compare the quality of these dedicated points with those of other heuristics amongst an academic example and also for the optimization of electric transmission lines with switching of the network topology for flow reallocation in order to satisfy demands.},
  archive      = {J_MP},
  author       = {Göttlich, Simone and Hante, Falk M. and Potschka, Andreas and Schewe, Lars},
  doi          = {10.1007/s10107-021-01656-9},
  journal      = {Mathematical Programming},
  number       = {2},
  pages        = {599-619},
  shortjournal = {Math. Program.},
  title        = {Penalty alternating direction methods for mixed-integer optimal control with combinatorial constraints},
  volume       = {188},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Compactness and convergence rates in the combinatorial
integral approximation decomposition. <em>MP</em>, <em>188</em>(2),
569–598. (<a href="https://doi.org/10.1007/s10107-020-01598-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The combinatorial integral approximation decomposition splits the optimization of a discrete-valued control into two steps: solving a continuous relaxation of the discrete control problem, and computing a discrete-valued approximation of the relaxed control. Different algorithms exist for the second step to construct piecewise constant discrete-valued approximants that are defined on given decompositions of the domain. It is known that the resulting discrete controls can be constructed such that they converge to a relaxed control in the $$\hbox {weak}^*$$ topology of $$L^\infty $$ if the grid constant of this decomposition is driven to zero. We exploit this insight to formulate a general approximation result for optimization problems, which feature discrete and distributed optimization variables, and which are governed by a compact control-to-state operator. We analyze the topology induced by the grid refinements and prove convergence rates of the control vectors for two problem classes. We use a reconstruction problem from signal processing to demonstrate both the applicability of the method outside the scope of differential equations, the predominant case in the literature, and the effectiveness of the approach.},
  archive      = {J_MP},
  author       = {Kirches, Christian and Manns, Paul and Ulbrich, Stefan},
  doi          = {10.1007/s10107-020-01598-8},
  journal      = {Mathematical Programming},
  number       = {2},
  pages        = {569-598},
  shortjournal = {Math. Program.},
  title        = {Compactness and convergence rates in the combinatorial integral approximation decomposition},
  volume       = {188},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Mixing convex-optimization bounds for maximum-entropy
sampling. <em>MP</em>, <em>188</em>(2), 539–568. (<a
href="https://doi.org/10.1007/s10107-020-01588-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The maximum-entropy sampling problem is a fundamental and challenging combinatorial-optimization problem, with application in spatial statistics. It asks to find a maximum-determinant order-s principal submatrix of an order-n covariance matrix. Exact solution methods for this NP-hard problem are based on a branch-and-bound framework. Many of the known upper bounds for the optimal value are based on convex optimization. We present a methodology for “mixing” these bounds to achieve better bounds.},
  archive      = {J_MP},
  author       = {Chen, Zhongzhu and Fampa, Marcia and Lambert, Amélie and Lee, Jon},
  doi          = {10.1007/s10107-020-01588-w},
  journal      = {Mathematical Programming},
  number       = {2},
  pages        = {539-568},
  shortjournal = {Math. Program.},
  title        = {Mixing convex-optimization bounds for maximum-entropy sampling},
  volume       = {188},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The confined primal integral: A measure to benchmark
heuristic MINLP solvers against global MINLP solvers. <em>MP</em>,
<em>188</em>(2), 523–537. (<a
href="https://doi.org/10.1007/s10107-020-01547-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is a challenging task to fairly compare local solvers and heuristics against each other and against global solvers. How does one weigh a faster termination time against a better quality of the found solution? In this paper, we introduce the confined primal integral, a new performance measure that rewards a balance of speed and solution quality. It emphasizes the early part of the solution process by using an exponential decay. Thereby, it avoids that the order of solvers can be inverted by choosing an arbitrarily large time limit. We provide a closed analytic formula to compute the confined primal integral a posteriori and an incremental update formula to compute it during the run of an algorithm. For the latter, we show that we can drop one of the main assumptions of the primal integral, namely the knowledge of a fixed reference solution to compare against. Furthermore, we prove that the confined primal integral is a transitive measure when comparing local solves with different final solution values. Finally, we present a computational experiment where we compare a local MINLP solver that uses certain classes of cutting planes against a solver that does not. Both versions show very different tendencies w.r.t. average running time and solution quality, and we use the confined primal integral to argue which of the two is the preferred setting.},
  archive      = {J_MP},
  author       = {Berthold, Timo and Csizmadia, Zsolt},
  doi          = {10.1007/s10107-020-01547-5},
  journal      = {Mathematical Programming},
  number       = {2},
  pages        = {523-537},
  shortjournal = {Math. Program.},
  title        = {The confined primal integral: A measure to benchmark heuristic MINLP solvers against global MINLP solvers},
  volume       = {188},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Outer approximation for global optimization of mixed-integer
quadratic bilevel problems. <em>MP</em>, <em>188</em>(2), 461–521. (<a
href="https://doi.org/10.1007/s10107-020-01601-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bilevel optimization problems have received a lot of attention in the last years and decades. Besides numerous theoretical developments there also evolved novel solution algorithms for mixed-integer linear bilevel problems and the most recent algorithms use branch-and-cut techniques from mixed-integer programming that are especially tailored for the bilevel context. In this paper, we consider MIQP-QP bilevel problems, i.e., models with a mixed-integer convex-quadratic upper level and a continuous convex-quadratic lower level. This setting allows for a strong-duality-based transformation of the lower level which yields, in general, an equivalent nonconvex single-level reformulation of the original bilevel problem. Under reasonable assumptions, we can derive both a multi- and a single-tree outer-approximation-based cutting-plane algorithm. We show finite termination and correctness of both methods and present extensive numerical results that illustrate the applicability of the approaches. It turns out that the proposed methods are capable of solving bilevel instances with several thousand variables and constraints and significantly outperform classical solution approaches.},
  archive      = {J_MP},
  author       = {Kleinert, Thomas and Grimm, Veronika and Schmidt, Martin},
  doi          = {10.1007/s10107-020-01601-2},
  journal      = {Mathematical Programming},
  number       = {2},
  pages        = {461-521},
  shortjournal = {Math. Program.},
  title        = {Outer approximation for global optimization of mixed-integer quadratic bilevel problems},
  volume       = {188},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Near-optimal analysis of lasserre’s univariate measure-based
bounds for multivariate polynomial optimization. <em>MP</em>,
<em>188</em>(2), 443–460. (<a
href="https://doi.org/10.1007/s10107-020-01586-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a hierarchy of upper approximations for the minimization of a polynomial f over a compact set $$K \subseteq \mathbb {R}^n$$ proposed recently by Lasserre (arXiv:1907.097784, 2019). This hierarchy relies on using the push-forward measure of the Lebesgue measure on K by the polynomial f and involves univariate sums of squares of polynomials with growing degrees 2r. Hence it is weaker, but cheaper to compute, than an earlier hierarchy by Lasserre (SIAM Journal on Optimization 21(3), 864–885, 2011), which uses multivariate sums of squares. We show that this new hierarchy converges to the global minimum of f at a rate in $$O(\log ^2 r / r^2)$$ whenever K satisfies a mild geometric condition, which holds, eg., for convex bodies and for compact semialgebraic sets with dense interior. As an application this rate of convergence also applies to the stronger hierarchy based on multivariate sums of squares, which improves and extends earlier convergence results to a wider class of compact sets. Furthermore, we show that our analysis is near-optimal by proving a lower bound on the convergence rate in $$\varOmega (1/r^2)$$ for a class of polynomials on $$K=[-1,1]$$ , obtained by exploiting a connection to orthogonal polynomials.},
  archive      = {J_MP},
  author       = {Slot, Lucas and Laurent, Monique},
  doi          = {10.1007/s10107-020-01586-y},
  journal      = {Mathematical Programming},
  number       = {2},
  pages        = {443-460},
  shortjournal = {Math. Program.},
  title        = {Near-optimal analysis of lasserre’s univariate measure-based bounds for multivariate polynomial optimization},
  volume       = {188},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Quadratic optimization with switching variables: The convex
hull for <span class="math display"><em>n</em> = 2</span>. <em>MP</em>,
<em>188</em>(2), 421–441. (<a
href="https://doi.org/10.1007/s10107-021-01671-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider quadratic optimization in variables (x, y) where $$0\le x\le y$$ , and $$y\in { 0,1 }^n$$ . Such binary variables are commonly referred to as indicator or switching variables and occur commonly in applications. One approach to such problems is based on representing or approximating the convex hull of the set $${ (x,xx^T, yy^T)\,:\,0\le x\le y\in { 0,1 }^n }$$ . A representation for the case $$n=1$$ is known and has been widely used. We give an exact representation for the case $$n=2$$ by starting with a disjunctive representation for the convex hull and then eliminating auxiliary variables and constraints that do not change the projection onto the original variables. An alternative derivation for this representation leads to an appealing conjecture for a simplified representation of the convex hull for $$n=2$$ when the product term $$y_1y_2$$ is ignored.},
  archive      = {J_MP},
  author       = {Anstreicher, Kurt M. and Burer, Samuel},
  doi          = {10.1007/s10107-021-01671-w},
  journal      = {Mathematical Programming},
  number       = {2},
  pages        = {421-441},
  shortjournal = {Math. Program.},
  title        = {Quadratic optimization with switching variables: The convex hull for $$n=2$$},
  volume       = {188},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Preface. <em>MP</em>, <em>188</em>(2), 411–419. (<a
href="https://doi.org/10.1007/s10107-021-01687-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_MP},
  author       = {Liberti, Leo and Sager, Sebastian and Wiegele, Angelika},
  doi          = {10.1007/s10107-021-01687-2},
  journal      = {Mathematical Programming},
  number       = {2},
  pages        = {411-419},
  shortjournal = {Math. Program.},
  title        = {Preface},
  volume       = {188},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Correction to: Stronger MIP formulations for the steiner
forest problem. <em>MP</em>, <em>188</em>(1), 409–410. (<a
href="https://doi.org/10.1007/s10107-021-01648-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A correction to this paper has been published: https://doi.org/10.1007/s10107-021-01648-9},
  archive      = {J_MP},
  author       = {Schmidt, Daniel and Zey, Bernd and Margot, François},
  doi          = {10.1007/s10107-021-01648-9},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {409-410},
  shortjournal = {Math. Program.},
  title        = {Correction to: Stronger MIP formulations for the steiner forest problem},
  volume       = {188},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Better and simpler error analysis of the sinkhorn–knopp
algorithm for matrix scaling. <em>MP</em>, <em>188</em>(1), 395–407. (<a
href="https://doi.org/10.1007/s10107-020-01503-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given a non-negative $$n \times m$$ real matrix A, the matrix scaling problem is to determine if it is possible to scale the rows and columns so that each row and each column sums to a specified positive target values. The Sinkhorn–Knopp algorithm is a simple and classic procedure which alternately scales all rows and all columns to meet these targets. The focus of this paper is the worst-case theoretical analysis of this algorithm. We present an elementary convergence analysis for this algorithm that improves upon the previous best bound. In a nutshell, our approach is to show (i) a simple bound on the number of iterations needed so that the KL-divergence between the current row-sums and the target row-sums drops below a specified threshold $$\delta $$ , and (ii) then show that for a suitable choice of $$\delta $$ , whenever KL-divergence is below $$\delta $$ , then the $$\ell _1$$ -error or the $$\ell _2$$ -error is below $$\varepsilon $$ . The well-known Pinsker’s inequality immediately allows us to translate a bound on the KL divergence to a bound on $$\ell _1$$ -error. To bound the $$\ell _2$$ -error in terms of the KL-divergence, we establish a new inequality, referred to as (KL vs $$\ell _1/\ell _2$$ ). This inequality is a strengthening of Pinsker’s inequality and may be of independent interest.},
  archive      = {J_MP},
  author       = {Chakrabarty, Deeparnab and Khanna, Sanjeev},
  doi          = {10.1007/s10107-020-01503-3},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {395-407},
  shortjournal = {Math. Program.},
  title        = {Better and simpler error analysis of the Sinkhorn–Knopp algorithm for matrix scaling},
  volume       = {188},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Sparse semidefinite programs with guaranteed near-linear
time complexity via dualized clique tree conversion. <em>MP</em>,
<em>188</em>(1), 351–393. (<a
href="https://doi.org/10.1007/s10107-020-01516-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Clique tree conversion solves large-scale semidefinite programs by splitting an $$n\times n$$ matrix variable into up to n smaller matrix variables, each representing a principal submatrix of up to $$\omega \times \omega $$ . Its fundamental weakness is the need to introduce overlap constraints that enforce agreement between different matrix variables, because these can result in dense coupling. In this paper, we show that by dualizing the clique tree conversion, the coupling due to the overlap constraints is guaranteed to be sparse over dense blocks, with a block sparsity pattern that coincides with the adjacency matrix of a tree. We consider two classes of semidefinite programs with favorable sparsity patterns that encompass the MAXCUT and MAX k-CUT relaxations, the Lovasz Theta problem, and the AC optimal power flow relaxation. Assuming that $$\omega \ll n$$ , we prove that the per-iteration cost of an interior-point method is linear O(n) time and memory, so an $$\epsilon $$ -accurate and $$\epsilon $$ -feasible iterate is obtained after $$O(\sqrt{n}\log (1/\epsilon ))$$ iterations in near-linear $$O(n^{1.5}\log (1/\epsilon ))$$ time. We confirm our theoretical insights with numerical results on semidefinite programs as large as $$n=13{,}659$$ .},
  archive      = {J_MP},
  author       = {Zhang, Richard Y. and Lavaei, Javad},
  doi          = {10.1007/s10107-020-01516-y},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {351-393},
  shortjournal = {Math. Program.},
  title        = {Sparse semidefinite programs with guaranteed near-linear time complexity via dualized clique tree conversion},
  volume       = {188},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Box-total dual integrality, box-integrality, and equimodular
matrices. <em>MP</em>, <em>188</em>(1), 319–349. (<a
href="https://doi.org/10.1007/s10107-020-01514-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Box-totally dual integral (box-TDI) polyhedra are polyhedra described by systems which yield strong min-max relations. We characterize them in several ways, involving the notions of principal box-integer polyhedra and equimodular matrices. A polyhedron is box-integer if its intersection with any integer box $${\ell \le x \le u}$$ is integer. We define principally box-integer polyhedra to be the polyhedra P such that $$ kP $$ is box-integer whenever $$ kP $$ is integer. A rational $$r\times n$$ matrix is equimodular if it has full row rank and its nonzero $$r\times r$$ determinants all have the same absolute value. A face-defining matrix is a full row rank matrix describing the affine hull of a face of the polyhedron. Our main result is that the following statements are equivalent. Along our proof, we show that a polyhedral cone is box-TDI if and only if it is box-integer, and that these properties are carried over to its polar. We illustrate these charaterizations by reviewing well known results about box-TDI polyhedra. We also provide several applications. The first one is a new perspective on the equivalence between two results about binary clutters. Secondly, we refute a conjecture of Ding, Zang, and Zhao about box-perfect graphs. Thirdly, we discuss connections with an abstract class of polyhedra having the Integer Carathéodory Property. Finally, we characterize the box-TDIness of the cone of conservative functions of a graph and provide a corresponding box-TDI system.},
  archive      = {J_MP},
  author       = {Chervet, Patrick and Grappe, Roland and Robert, Louis-Hadrien},
  doi          = {10.1007/s10107-020-01514-0},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {319-349},
  shortjournal = {Math. Program.},
  title        = {Box-total dual integrality, box-integrality, and equimodular matrices},
  volume       = {188},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Maximum edge-disjoint paths in planar graphs with congestion
2. <em>MP</em>, <em>188</em>(1), 295–317. (<a
href="https://doi.org/10.1007/s10107-020-01513-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the maximum edge-disjoint path problem (medp) in planar graphs $$G=(V,E)$$ with edge capacities u(e). We are given a set of terminal pairs $$s_it_i$$ , $$i=1,2 \ldots , k$$ and wish to find a maximum routable subset of demands. That is, a subset of demands that can be connected by a family of paths that use each edge at most u(e) times. It is well-known that there is an integrality gap of $$\Omega (\sqrt{n})$$ for the natural LP relaxation, even in planar graphs (Garg–Vazirani–Yannakakis). We show that if every edge has capacity at least 2, then the integrality gap drops to a constant. This result is tight also in a complexity-theoretic sense: recent results of Chuzhoy–Kim–Nimavat show that it is unlikely that there is any polytime-solvable LP formulation for medp which has a constant integrality gap for planar graphs. Along the way, we introduce the concept of rooted clustering which we believe is of independent interest.},
  archive      = {J_MP},
  author       = {Séguin-Charbonneau, Loïc and Shepherd, F. Bruce},
  doi          = {10.1007/s10107-020-01513-1},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {295-317},
  shortjournal = {Math. Program.},
  title        = {Maximum edge-disjoint paths in planar graphs with congestion 2},
  volume       = {188},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The condition number of a function relative to a set.
<em>MP</em>, <em>188</em>(1), 255–294. (<a
href="https://doi.org/10.1007/s10107-020-01510-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The condition number of a differentiable convex function, namely the ratio of its smoothness to strong convexity constants, is closely tied to fundamental properties of the function. In particular, the condition number of a quadratic convex function is the square of the aspect ratio of a canonical ellipsoid associated to the function. Furthermore, the condition number of a function bounds the linear rate of convergence of the gradient descent algorithm for unconstrained convex minimization. We propose a condition number of a differentiable convex function relative to a reference convex set and distance function pair. This relative condition number is defined as the ratio of relative smoothness to relative strong convexity constants. We show that the relative condition number extends the main properties of the traditional condition number both in terms of its geometric insight and in terms of its role in characterizing the linear convergence of first-order methods for constrained convex minimization. When the reference set X is a convex cone or a polyhedron and the function f is of the form $$f = g\circ A$$ , we provide characterizations of and bounds on the condition number of f relative to X in terms of the usual condition number of g and a suitable condition number of the pair (A, X).},
  archive      = {J_MP},
  author       = {Gutman, David H. and Peña, Javier F.},
  doi          = {10.1007/s10107-020-01510-4},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {255-294},
  shortjournal = {Math. Program.},
  title        = {The condition number of a function relative to a set},
  volume       = {188},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Simple bilevel programming and extensions. <em>MP</em>,
<em>188</em>(1), 227–253. (<a
href="https://doi.org/10.1007/s10107-020-01509-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we discuss the simple bilevel programming problem (SBP) and its extension, the simple mathematical programming problem under equilibrium constraints (SMPEC). Here we first define both these problems and study their interrelations. Next we study the various types of necessary and sufficient optimality conditions for the (SMPEC) problems, which occur under various reformulations. The optimality conditions for (SBP) are special cases of the results obtained for (SMPEC) when the lower level objective is the gradient of a convex function. Among the various optimality conditions presented in this article are the sequential optimality conditions, which do not need any constraint qualification. We also present a schematic algorithm for (SMPEC), where the sequential optimality conditions play a key role in the convergence analysis.},
  archive      = {J_MP},
  author       = {Dempe, Stephan and Dinh, Nguyen and Dutta, Joydeep and Pandit, Tanushree},
  doi          = {10.1007/s10107-020-01509-x},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {227-253},
  shortjournal = {Math. Program.},
  title        = {Simple bilevel programming and extensions},
  volume       = {188},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Strong formulations for conic quadratic optimization with
indicator variables. <em>MP</em>, <em>188</em>(1), 193–226. (<a
href="https://doi.org/10.1007/s10107-020-01508-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the convex hull of the mixed-integer set given by a conic quadratic inequality and indicator variables. Conic quadratic terms are often used to encode uncertainties, while the indicator variables are used to model fixed costs or enforce sparsity in the solutions. We provide the convex hull description of the set under consideration when the continuous variables are unbounded. We propose valid nonlinear inequalities for the bounded case, and show that they describe the convex hull for the two-variable case. All the proposed inequalities are described in the original space of variables, but extended SOCP-representable formulations are also given. We present computational experiments demonstrating the strength of the proposed formulations.},
  archive      = {J_MP},
  author       = {Gómez, Andrés},
  doi          = {10.1007/s10107-020-01508-y},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {193-226},
  shortjournal = {Math. Program.},
  title        = {Strong formulations for conic quadratic optimization with indicator variables},
  volume       = {188},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Stochastic quasi-gradient methods: Variance reduction via
jacobian sketching. <em>MP</em>, <em>188</em>(1), 135–192. (<a
href="https://doi.org/10.1007/s10107-020-01506-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We develop a new family of variance reduced stochastic gradient descent methods for minimizing the average of a very large number of smooth functions. Our method—JacSketch—is motivated by novel developments in randomized numerical linear algebra, and operates by maintaining a stochastic estimate of a Jacobian matrix composed of the gradients of individual functions. In each iteration, JacSketch efficiently updates the Jacobian matrix by first obtaining a random linear measurement of the true Jacobian through (cheap) sketching, and then projecting the previous estimate onto the solution space of a linear matrix equation whose solutions are consistent with the measurement. The Jacobian estimate is then used to compute a variance-reduced unbiased estimator of the gradient. Our strategy is analogous to the way quasi-Newton methods maintain an estimate of the Hessian, and hence our method can be seen as a stochastic quasi-gradient method. Our method can also be seen as stochastic gradient descent applied to a controlled stochastic optimization reformulation of the original problem, where the control comes from the Jacobian estimates. We prove that for smooth and strongly convex functions, JacSketch converges linearly with a meaningful rate dictated by a single convergence theorem which applies to general sketches. We also provide a refined convergence theorem which applies to a smaller class of sketches, featuring a novel proof technique based on a stochastic Lyapunov function. This enables us to obtain sharper complexity results for variants of JacSketch with importance sampling. By specializing our general approach to specific sketching strategies, JacSketch reduces to the celebrated stochastic average gradient (SAGA) method, and its several existing and many new minibatch, reduced memory, and importance sampling variants. Our rate for SAGA with importance sampling is the current best-known rate for this method, resolving a conjecture by Schmidt et al. (Proceedings of the eighteenth international conference on artificial intelligence and statistics, AISTATS 2015, San Diego, California, 2015). The rates we obtain for minibatch SAGA are also superior to existing rates and are sufficiently tight as to show a decrease in total complexity as the minibatch size increases. Moreover, we obtain the first minibatch SAGA method with importance sampling.},
  archive      = {J_MP},
  author       = {Gower, Robert M. and Richtárik, Peter and Bach, Francis},
  doi          = {10.1007/s10107-020-01506-0},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {135-192},
  shortjournal = {Math. Program.},
  title        = {Stochastic quasi-gradient methods: Variance reduction via jacobian sketching},
  volume       = {188},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Adaptive regularization with cubics on manifolds.
<em>MP</em>, <em>188</em>(1), 85–134. (<a
href="https://doi.org/10.1007/s10107-020-01505-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Adaptive regularization with cubics (ARC) is an algorithm for unconstrained, non-convex optimization. Akin to the trust-region method, its iterations can be thought of as approximate, safe-guarded Newton steps. For cost functions with Lipschitz continuous Hessian, ARC has optimal iteration complexity, in the sense that it produces an iterate with gradient smaller than $$\varepsilon $$ in $$O(1/\varepsilon ^{1.5})$$ iterations. For the same price, it can also guarantee a Hessian with smallest eigenvalue larger than $$-\sqrt{\varepsilon }$$ . In this paper, we study a generalization of ARC to optimization on Riemannian manifolds. In particular, we generalize the iteration complexity results to this richer framework. Our central contribution lies in the identification of appropriate manifold-specific assumptions that allow us to secure these complexity guarantees both when using the exponential map and when using a general retraction. A substantial part of the paper is devoted to studying these assumptions—relevant beyond ARC—and providing user-friendly sufficient conditions for them. Numerical experiments are encouraging.},
  archive      = {J_MP},
  author       = {Agarwal, Naman and Boumal, Nicolas and Bullins, Brian and Cartis, Coralia},
  doi          = {10.1007/s10107-020-01505-1},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {85-134},
  shortjournal = {Math. Program.},
  title        = {Adaptive regularization with cubics on manifolds},
  volume       = {188},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Separation routine and extended formulations for the stable
set problem in claw-free graphs. <em>MP</em>, <em>188</em>(1), 53–84.
(<a href="https://doi.org/10.1007/s10107-020-01502-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The maximum weighted stable set problem in claw-free graphs is a well-known generalization of the maximum weighted matching problem, and a classical problem in combinatorial optimization. In spite of the recent development of fast(er) combinatorial algorithms and some progresses in the characterization of the corresponding stable set polytope, the problem of “providing a decent linear description” for this polytope (Grötschel et al. in Geometric algorithms and combinatorial optimization, Springer, New York, 1988) is still open. The main contribution of this paper is to propose an algorithmic answer to that question by providing a polynomial-time and computationally attractive separation routine for the stable set polytope of claw-free graphs, that only requires a combinatorial decomposition algorithm, the solution of (moderate sized) compact linear programs, and Padberg and Rao’s algorithm for separating over the matching polytope. In particular, it is a generalization of the latter and avoids the heavy computational burden of resorting to the ellipsoid method, on which the only poly-time separation routine known so far relied. Besides, our separation routine comes with a ‘small’ (but not polynomial) extended linear programming formulation and a procedure to derive a linear description of the stable set polytope of claw-free graphs in the original space.},
  archive      = {J_MP},
  author       = {Faenza, Yuri and Oriolo, Gianpaolo and Stauffer, Gautier},
  doi          = {10.1007/s10107-020-01502-4},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {53-84},
  shortjournal = {Math. Program.},
  title        = {Separation routine and extended formulations for the stable set problem in claw-free graphs},
  volume       = {188},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Conservative set valued fields, automatic differentiation,
stochastic gradient methods and deep learning. <em>MP</em>,
<em>188</em>(1), 19–51. (<a
href="https://doi.org/10.1007/s10107-020-01501-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modern problems in AI or in numerical analysis require nonsmooth approaches with a flexible calculus. We introduce generalized derivatives called conservative fields for which we develop a calculus and provide representation formulas. Functions having a conservative field are called path differentiable: convex, concave, Clarke regular and any semialgebraic Lipschitz continuous functions are path differentiable. Using Whitney stratification techniques for semialgebraic and definable sets, our model provides variational formulas for nonsmooth automatic differentiation oracles, as for instance the famous backpropagation algorithm in deep learning. Our differential model is applied to establish the convergence in values of nonsmooth stochastic gradient methods as they are implemented in practice.},
  archive      = {J_MP},
  author       = {Bolte, Jérôme and Pauwels, Edouard},
  doi          = {10.1007/s10107-020-01501-5},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {19-51},
  shortjournal = {Math. Program.},
  title        = {Conservative set valued fields, automatic differentiation, stochastic gradient methods and deep learning},
  volume       = {188},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Complexity of packing common bases in matroids. <em>MP</em>,
<em>188</em>(1), 1–18. (<a
href="https://doi.org/10.1007/s10107-020-01497-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the most intriguing unsolved questions of matroid optimization is the characterization of the existence of k disjoint common bases of two matroids. The significance of the problem is well-illustrated by the long list of conjectures that can be formulated as special cases, such as Woodall’s conjecture on packing disjoint dijoins in a directed graph, or Rota’s beautiful conjecture on rearrangements of bases. In the present paper we prove that the problem is difficult under the rank oracle model, i.e., we show that there is no algorithm which decides if the common ground set of two matroids can be partitioned into k common bases by using a polynomial number of independence queries. Our complexity result holds even for the very special case when $$k=2$$ . Through a series of reductions, we also show that the abstract problem of packing common bases in two matroids includes the NAE-SAT problem and the Perfect Even Factor problem in directed graphs. These results in turn imply that the problem is not only difficult in the independence oracle model but also includes NP-complete special cases already when $$k=2$$ , one of the matroids is a partition matroid, while the other matroid is linear and is given by an explicit representation.},
  archive      = {J_MP},
  author       = {Bérczi, Kristóf and Schwarcz, Tamás},
  doi          = {10.1007/s10107-020-01497-y},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {1-18},
  shortjournal = {Math. Program.},
  title        = {Complexity of packing common bases in matroids},
  volume       = {188},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Unit stepsize for the newton method close to critical
solutions. <em>MP</em>, <em>187</em>(1), 697–721. (<a
href="https://doi.org/10.1007/s10107-020-01496-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As is well known, when initialized close to a nonsingular solution of a smooth nonlinear equation, the Newton method converges to this solution superlinearly. Moreover, the common Armijo linesearch procedure used to globalize the process for convergence from arbitrary starting points, accepts the unit stepsize asymptotically and ensures fast local convergence. In the case of a singular and possibly even nonisolated solution, the situation is much more complicated. Local linear convergence (with asymptotic ratio of 1/2) of the Newton method can still be guaranteed under reasonable assumptions, from a starlike, asymptotically dense set around the solution. Moreover, convergence can be accelerated by extrapolation and overrelaxation techniques. However, nothing was previously known on how the Newton method can be coupled in these circumstances with a linesearch technique for globalization that locally accepts unit stepsize and guarantees linear convergence. It turns out that this is a rather nontrivial issue, requiring a delicate combination of the analyses on acceptance of the unit stepsize and on the iterates staying within the relevant starlike domain of convergence. In addition to these analyses, numerical illustrations and comparisons are presented for the Newton method and the use of extrapolation to accelerate convergence speed.},
  archive      = {J_MP},
  author       = {Fischer, A. and Izmailov, A. F. and Solodov, M. V.},
  doi          = {10.1007/s10107-020-01496-z},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {697-721},
  shortjournal = {Math. Program.},
  title        = {Unit stepsize for the newton method close to critical solutions},
  volume       = {187},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Revenue maximization in stackelberg pricing games: Beyond
the combinatorial setting. <em>MP</em>, <em>187</em>(1), 653–695. (<a
href="https://doi.org/10.1007/s10107-020-01495-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In a Stackelberg Pricing Game a distinguished player, the leader, chooses prices for a set of items, and the other players, the followers, each seek to buy a minimum cost feasible subset of the items. The goal of the leader is to maximize her revenue, which is determined by the sold items and their prices. Most previously studied cases of such games can be captured by a combinatorial model where we have a base set of items, some with fixed prices, some priceable, and constraints on the subsets that are feasible for each follower. In this combinatorial setting, Briest et al. and Balcan et al. independently showed that the maximum revenue can be approximated to a factor of $$H_k\sim \log k$$ , where k is the number of priceable items. Our results are twofold. First, we strongly generalize the model by letting the follower minimize any continuous function plus a linear term over any compact subset of $${\mathbb {R}}^n_{\ge 0}$$ ; the coefficients (or prices) in the linear term are chosen by the leader and determine her revenue. In particular, this includes the fundamental case of linear programs. We give a tight lower bound on the revenue of the leader, generalizing the results of Briest et al. and Balcan et al. Besides, we prove that it is strongly NP-hard to decide whether the optimum revenue exceeds the lower bound by an arbitrarily small factor. Second, we study the parameterized complexity of computing the optimal revenue with respect to the number k of priceable items. In the combinatorial setting, given an efficient algorithm for optimal follower solutions, the maximum revenue can be found by enumerating the $$2^k$$ subsets of priceable items and computing optimal prices via a result of Briest et al., giving time $$O(2^k|I|^c)$$ where |I| is the input size. Our main result here is a W[1]-hardness proof for the case where the followers minimize a linear program, ruling out running time $$f(k)|I|^c$$ unless $$\mathsf {FPT} =\mathsf {W[1]} $$ and ruling out time $$|I|^{o(k)}$$ under the Exponential-Time Hypothesis.},
  archive      = {J_MP},
  author       = {Böhnlein, Toni and Kratsch, Stefan and Schaudt, Oliver},
  doi          = {10.1007/s10107-020-01495-0},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {653-695},
  shortjournal = {Math. Program.},
  title        = {Revenue maximization in stackelberg pricing games: Beyond the combinatorial setting},
  volume       = {187},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Convergent upper bounds in global minimization with
nonlinear equality constraints. <em>MP</em>, <em>187</em>(1), 617–651.
(<a href="https://doi.org/10.1007/s10107-020-01493-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We address the problem of determining convergent upper bounds in continuous non-convex global minimization of box-constrained problems with equality constraints. These upper bounds are important for the termination of spatial branch-and-bound algorithms. Our method is based on the theorem of Miranda which helps to ensure the existence of feasible points in certain boxes. Then, the computation of upper bounds at the objective function over those boxes yields an upper bound for the globally minimal value. A proof of convergence is given under mild assumptions. An extension of our approach to problems including inequality constraints is possible.},
  archive      = {J_MP},
  author       = {Füllner, Christian and Kirst, Peter and Stein, Oliver},
  doi          = {10.1007/s10107-020-01493-2},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {617-651},
  shortjournal = {Math. Program.},
  title        = {Convergent upper bounds in global minimization with nonlinear equality constraints},
  volume       = {187},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Regional complexity analysis of algorithms for nonconvex
smooth optimization. <em>MP</em>, <em>187</em>(1), 579–615. (<a
href="https://doi.org/10.1007/s10107-020-01492-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A strategy is proposed for characterizing the worst-case performance of algorithms for solving nonconvex smooth optimization problems. Contemporary analyses characterize worst-case performance by providing, under certain assumptions on an objective function, an upper bound on the number of iterations (or function or derivative evaluations) required until a pth-order stationarity condition is approximately satisfied. This arguably leads to conservative characterizations based on certain objectives rather than on ones that are typically encountered in practice. By contrast, the strategy proposed in this paper characterizes worst-case performance separately over regions comprising a search space. These regions are defined generically based on properties of derivative values. In this manner, one can analyze the worst-case performance of an algorithm independently from any particular class of objectives. Then, once given a class of objectives, one can obtain a tailored complexity analysis merely by delineating the types of regions that comprise the search spaces for functions in the class. Regions defined by first- and second-order derivatives are discussed in detail and example complexity analyses are provided for a few standard first- and second-order algorithms when employed to minimize convex and nonconvex objectives of interest. It is also explained how the strategy can be generalized to regions defined by higher-order derivatives and for analyzing the behavior of higher-order algorithms.},
  archive      = {J_MP},
  author       = {Curtis, Frank E. and Robinson, Daniel P.},
  doi          = {10.1007/s10107-020-01492-3},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {579-615},
  shortjournal = {Math. Program.},
  title        = {Regional complexity analysis of algorithms for nonconvex smooth optimization},
  volume       = {187},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Inexact stochastic mirror descent for two-stage nonlinear
stochastic programs. <em>MP</em>, <em>187</em>(1), 533–577. (<a
href="https://doi.org/10.1007/s10107-020-01490-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce an inexact variant of stochastic mirror descent (SMD), called inexact stochastic mirror descent (ISMD), to solve nonlinear two-stage stochastic programs where the second stage problem has linear and nonlinear coupling constraints and a nonlinear objective function which depends on both first and second stage decisions. Given a candidate first stage solution and a realization of the second stage random vector, each iteration of ISMD combines a stochastic subgradient descent using a prox-mapping with the computation of approximate (instead of exact for SMD) primal and dual second stage solutions. We provide two convergence analysis of ISMD, under two sets of assumptions. The first convergence analysis is based on the formulas for inexact cuts of value functions of convex optimization problems shown recently in Guigues (SIAM J. Optim. 30(1), 407–438, 2020). The second convergence analysis provides a convergence rate (the same as SMD) and relies on new formulas that we derive for inexact cuts of value functions of convex optimization problems assuming that the dual function of the second stage problem for all fixed first stage solution and realization of the second stage random vector, is strongly concave. We show that this assumption of strong concavity is satisfied for some classes of problems and present the results of numerical experiments on two simple two-stage problems which show that solving approximately the second stage problem for the first iterations of ISMD can help us obtain a good approximate first stage solution quicker than with SMD.},
  archive      = {J_MP},
  author       = {Guigues, Vincent},
  doi          = {10.1007/s10107-020-01490-5},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {533-577},
  shortjournal = {Math. Program.},
  title        = {Inexact stochastic mirror descent for two-stage nonlinear stochastic programs},
  volume       = {187},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Dynamic stochastic approximation for multi-stage stochastic
optimization. <em>MP</em>, <em>187</em>(1), 487–532. (<a
href="https://doi.org/10.1007/s10107-020-01489-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we consider multi-stage stochastic optimization problems with convex objectives and conic constraints at each stage. We present a new stochastic first-order method, namely the dynamic stochastic approximation (DSA) algorithm, for solving these types of stochastic optimization problems. We show that DSA can achieve an optimal $${{\mathcal {O}}}(1/\epsilon ^4)$$ rate of convergence in terms of the total number of required scenarios when applied to a three-stage stochastic optimization problem. We further show that this rate of convergence can be improved to $${{\mathcal {O}}}(1/\epsilon ^2)$$ when the objective function is strongly convex. We also discuss variants of DSA for solving more general multi-stage stochastic optimization problems with the number of stages $$T &gt; 3$$ . The developed DSA algorithms only need to go through the scenario tree once in order to compute an $$\epsilon $$ -solution of the multi-stage stochastic optimization problem. As a result, the memory required by DSA only grows linearly with respect to the number of stages. To the best of our knowledge, this is the first time that stochastic approximation type methods are generalized for multi-stage stochastic optimization with $$T \ge 3$$ .},
  archive      = {J_MP},
  author       = {Lan, Guanghui and Zhou, Zhiqiang},
  doi          = {10.1007/s10107-020-01489-y},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {487-532},
  shortjournal = {Math. Program.},
  title        = {Dynamic stochastic approximation for multi-stage stochastic optimization},
  volume       = {187},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). A sequential homotopy method for mathematical programming
problems. <em>MP</em>, <em>187</em>(1), 459–486. (<a
href="https://doi.org/10.1007/s10107-020-01488-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a sequential homotopy method for the solution of mathematical programming problems formulated in abstract Hilbert spaces under the Guignard constraint qualification. The method is equivalent to performing projected backward Euler timestepping on a projected gradient/antigradient flow of the augmented Lagrangian. The projected backward Euler equations can be interpreted as the necessary optimality conditions of a primal-dual proximal regularization of the original problem. The regularized problems are always feasible, satisfy a strong constraint qualification guaranteeing uniqueness of Lagrange multipliers, yield unique primal solutions provided that the stepsize is sufficiently small, and can be solved by a continuation in the stepsize. We show that equilibria of the projected gradient/antigradient flow and critical points of the optimization problem are identical, provide sufficient conditions for the existence of global flow solutions, and show that critical points with emanating descent curves cannot be asymptotically stable equilibria of the projected gradient/antigradient flow, practically eradicating convergence to saddle points and maxima. The sequential homotopy method can be used to globalize any locally convergent optimization method that can be used in a homotopy framework. We demonstrate its efficiency for a class of highly nonlinear and badly conditioned control constrained elliptic optimal control problems with a semismooth Newton approach for the regularized subproblems.},
  archive      = {J_MP},
  author       = {Potschka, Andreas and Bock, Hans Georg},
  doi          = {10.1007/s10107-020-01488-z},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {459-486},
  shortjournal = {Math. Program.},
  title        = {A sequential homotopy method for mathematical programming problems},
  volume       = {187},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Distributed stochastic gradient tracking methods.
<em>MP</em>, <em>187</em>(1), 409–457. (<a
href="https://doi.org/10.1007/s10107-020-01487-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study the problem of distributed multi-agent optimization over a network, where each agent possesses a local cost function that is smooth and strongly convex. The global objective is to find a common solution that minimizes the average of all cost functions. Assuming agents only have access to unbiased estimates of the gradients of their local cost functions, we consider a distributed stochastic gradient tracking method (DSGT) and a gossip-like stochastic gradient tracking method (GSGT). We show that, in expectation, the iterates generated by each agent are attracted to a neighborhood of the optimal solution, where they accumulate exponentially fast (under a constant stepsize choice). Under DSGT, the limiting (expected) error bounds on the distance of the iterates from the optimal solution decrease with the network size n, which is a comparable performance to a centralized stochastic gradient algorithm. Moreover, we show that when the network is well-connected, GSGT incurs lower communication cost than DSGT while maintaining a similar computational cost. Numerical example further demonstrates the effectiveness of the proposed methods.},
  archive      = {J_MP},
  author       = {Pu, Shi and Nedić, Angelia},
  doi          = {10.1007/s10107-020-01487-0},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {409-457},
  shortjournal = {Math. Program.},
  title        = {Distributed stochastic gradient tracking methods},
  volume       = {187},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Analysis of biased stochastic gradient descent using
sequential semidefinite programs. <em>MP</em>, <em>187</em>(1), 383–408.
(<a href="https://doi.org/10.1007/s10107-020-01486-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a convergence rate analysis for biased stochastic gradient descent (SGD), where individual gradient updates are corrupted by computation errors. We develop stochastic quadratic constraints to formulate a small linear matrix inequality (LMI) whose feasible points lead to convergence bounds of biased SGD. Based on this LMI condition, we develop a sequential minimization approach to analyze the intricate trade-offs that couple stepsize selection, convergence rate, optimization accuracy, and robustness to gradient inaccuracy. We also provide feasible points for this LMI and obtain theoretical formulas that quantify the convergence properties of biased SGD under various assumptions on the loss functions.},
  archive      = {J_MP},
  author       = {Hu, Bin and Seiler, Peter and Lessard, Laurent},
  doi          = {10.1007/s10107-020-01486-1},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {383-408},
  shortjournal = {Math. Program.},
  title        = {Analysis of biased stochastic gradient descent using sequential semidefinite programs},
  volume       = {187},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Convex hull results for generalizations of the constant
capacity single node flow set. <em>MP</em>, <em>187</em>(1), 351–382.
(<a href="https://doi.org/10.1007/s10107-020-01481-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For single node flow sets with fixed costs and constant capacities on the inflow and outflow arcs, a family of constant capacity flow covers are known to provide the convex hull in different special cases and are conjectured to provide it in the general case. Here we study more general mixed integer sets for which such single node flow cover inequalities suffice to give the convex hull. In particular we consider the case of a path in which each node has one (or several) incoming and outgoing arcs with constant capacities and fixed costs. This can be seen as a lot-sizing set with production and sales decisions driven by costs and prices and by the lower and upper bounds on stocks instead of being driven by demands as in the standard lot-sizing model. The approach we take is classical: we characterize the extreme points, derive tight extended formulations and project out the additional variables. Specifically we show that Fourier–Motzkin elimination, though far from elegant, can be used to carry out the non-trivial projections. The validity of the conjecture for the single node flow set follows from our results.},
  archive      = {J_MP},
  author       = {Wolsey, Laurence A. and Yaman, Hande},
  doi          = {10.1007/s10107-020-01481-6},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {351-382},
  shortjournal = {Math. Program.},
  title        = {Convex hull results for generalizations of the constant capacity single node flow set},
  volume       = {187},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Generalized stochastic frank–wolfe algorithm with stochastic
“substitute” gradient for structured convex optimization. <em>MP</em>,
<em>187</em>(1), 317–349. (<a
href="https://doi.org/10.1007/s10107-020-01480-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The stochastic Frank–Wolfe method has recently attracted much general interest in the context of optimization for statistical and machine learning due to its ability to work with a more general feasible region. However, there has been a complexity gap in the dependence on the optimality tolerance $$\varepsilon $$ in the guaranteed convergence rate for stochastic Frank–Wolfe compared to its deterministic counterpart. In this work, we present a new generalized stochastic Frank–Wolfe method which closes this gap for the class of structured optimization problems encountered in statistical and machine learning characterized by empirical loss minimization with a certain type of “linear prediction” property (formally defined in the paper), which is typically present in loss minimization problems in practice. Our method also introduces the notion of a “substitute gradient” that is a not-necessarily-unbiased estimate of the gradient. We show that our new method is equivalent to a particular randomized coordinate mirror descent algorithm applied to the dual problem, which in turn provides a new interpretation of randomized dual coordinate descent in the primal space. Also, in the special case of a strongly convex regularizer our generalized stochastic Frank–Wolfe method (as well as the randomized dual coordinate descent method) exhibits linear convergence. Furthermore, we present computational experiments that indicate that our method outperforms other stochastic Frank–Wolfe methods for a sufficiently small optimality tolerance, consistent with the theory developed herein.},
  archive      = {J_MP},
  author       = {Lu, Haihao and Freund, Robert M.},
  doi          = {10.1007/s10107-020-01480-7},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {317-349},
  shortjournal = {Math. Program.},
  title        = {Generalized stochastic Frank–Wolfe algorithm with stochastic “substitute” gradient for structured convex optimization},
  volume       = {187},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Chebyshev center of the intersection of balls: Complexity,
relaxation and approximation. <em>MP</em>, <em>187</em>(1), 287–315. (<a
href="https://doi.org/10.1007/s10107-020-01479-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the n-dimensional problem of finding the smallest ball enclosing the intersection of p given balls, the so-called Chebyshev center problem ( $${\mathrm{CC}}_{\mathrm{B}}$$ ). It is a minimax optimization problem and the inner maximization is a uniform quadratic optimization problem ( $$\mathrm{UQ}$$ ). When $$p\le n$$ , ( $$\mathrm{UQ}$$ ) is known to enjoy a strong duality and consequently ( $${\mathrm{CC}}_{\mathrm{B}}$$ ) is solved via a standard convex quadratic programming ( $$\mathrm{SQP}$$ ). In this paper, we first prove that ( $${\mathrm{CC}}_{\mathrm{B}}$$ ) is NP-hard and the special case when $$n=2$$ is polynomially solvable. With the help of a newly introduced linear programming relaxation (LP), the ( $$\mathrm{SQP}$$ ) relaxation is reobtained more directly and the first approximation bound for the solution obtained by ( $$\mathrm{SQP}$$ ) is established for the hard case $$p&gt;n$$ . Finally, also based on (LP), we show that ( $${\mathrm{CC}}_{\mathrm{B}}$$ ) is polynomially solvable when either n or $$p-n(&gt;0)$$ is fixed.},
  archive      = {J_MP},
  author       = {Xia, Yong and Yang, Meijia and Wang, Shu},
  doi          = {10.1007/s10107-020-01479-0},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {287-315},
  shortjournal = {Math. Program.},
  title        = {Chebyshev center of the intersection of balls: Complexity, relaxation and approximation},
  volume       = {187},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Dual-based methods for solving infinite-horizon
nonstationary deterministic dynamic programs. <em>MP</em>,
<em>187</em>(1), 253–285. (<a
href="https://doi.org/10.1007/s10107-020-01478-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We develop novel dual-ascent and primal-dual methods to solve infinite-horizon nonstationary deterministic dynamic programs. These methods are finitely implementable and converge in value to optimality. Moreover, the dual-ascent method produces a sequence of improving dual solutions that pointwise converge to an optimal dual solution, while the primal-dual algorithm provides a sequence of primal basic feasible solutions with value error bounds from optimality that converge to zero. Our dual-based methods work on a more general class of infinite network flow problems that include the shortest-path formulation of dynamic programs as a special case. To our knowledge, these are the first dual-based methods proposed in the literature to solve infinite-horizon nonstationary deterministic dynamic programs.},
  archive      = {J_MP},
  author       = {Ryan, Christopher Thomas and Smith, Robert L.},
  doi          = {10.1007/s10107-020-01478-1},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {253-285},
  shortjournal = {Math. Program.},
  title        = {Dual-based methods for solving infinite-horizon nonstationary deterministic dynamic programs},
  volume       = {187},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Facets, weak facets, and extreme functions of the
gomory–johnson infinite group problem. <em>MP</em>, <em>187</em>(1),
195–252. (<a href="https://doi.org/10.1007/s10107-020-01477-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We investigate three competing notions that generalize the notion of a facet of finite-dimensional polyhedra to the infinite-dimensional Gomory–Johnson model. These notions were known to coincide for continuous piecewise linear functions with rational breakpoints. We show that two of the notions, extreme functions and facets, coincide for the case of continuous piecewise linear functions, removing the hypothesis regarding rational breakpoints. We prove an if-and-only-if version of the Gomory–Johnson Facet Theorem. Finally, we separate the three notions using discontinuous examples.},
  archive      = {J_MP},
  author       = {Köppe, Matthias and Zhou, Yuan},
  doi          = {10.1007/s10107-020-01477-2},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {195-252},
  shortjournal = {Math. Program.},
  title        = {Facets, weak facets, and extreme functions of the Gomory–Johnson infinite group problem},
  volume       = {187},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Convergence rates of an inertial gradient descent algorithm
under growth and flatness conditions. <em>MP</em>, <em>187</em>(1),
151–193. (<a href="https://doi.org/10.1007/s10107-020-01476-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we study the convergence properties of a Nesterov’s family of inertial schemes which is a specific case of inertial Gradient Descent algorithm in the context of a smooth convex minimization problem, under some additional hypotheses on the local geometry of the objective function F, such as the growth (or Łojasiewicz) condition. In particular we study the different convergence rates for the objective function and the local variation, depending on these geometric conditions. In this setting we can give optimal convergence rates for this Nesterov scheme. Our analysis shows that there are some situations when Nesterov’s family of inertial schemes is asymptotically less efficient than the gradient descent (e.g. in the case when the objective function is quadratic).},
  archive      = {J_MP},
  author       = {Apidopoulos, Vassilis and Aujol, Jean-François and Dossal, Charles and Rondepierre, Aude},
  doi          = {10.1007/s10107-020-01476-3},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {151-193},
  shortjournal = {Math. Program.},
  title        = {Convergence rates of an inertial gradient descent algorithm under growth and flatness conditions},
  volume       = {187},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Outer approximation for integer nonlinear programs via
decision diagrams. <em>MP</em>, <em>187</em>(1), 111–150. (<a
href="https://doi.org/10.1007/s10107-020-01475-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As an alternative to traditional integer programming (IP), decision diagrams (DDs) provide a new solution technology for discrete problems exploiting their combinatorial structure and dynamic programming representation. While the literature mainly focuses on the competitive aspects of DDs as a stand-alone solver, we investigate their complementary role by introducing IP techniques that can be derived from DDs and used in conjunction with IP to enhance the overall performance. This perspective allows for studying problems with more general structure than those typically modeled via recursive formulations. In particular, we develop linear programming and subgradient-type methods to generate valid inequalities for the convex hull of the feasible region described by DDs. For convex IPs, these cutting planes dominate the so-called linearized cuts used in the outer approximation framework. These cutting planes can also be derived for nonconvex IPs, which leads to a generalization of the outer approximation framework. Computational experiments show significant optimality gap improvement for integer nonlinear programs over the traditional cutting plane methods employed in the state-of-the-art solvers.},
  archive      = {J_MP},
  author       = {Davarnia, Danial and van Hoeve, Willem-Jan},
  doi          = {10.1007/s10107-020-01475-4},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {111-150},
  shortjournal = {Math. Program.},
  title        = {Outer approximation for integer nonlinear programs via decision diagrams},
  volume       = {187},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). New characterizations of hoffman constants for systems of
linear constraints. <em>MP</em>, <em>187</em>(1), 79–109. (<a
href="https://doi.org/10.1007/s10107-020-01473-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We give a characterization of the Hoffman constant of a system of linear constraints in $${{\mathbb {R}}}^n$$ relative to a reference polyhedron $$R\subseteq {{\mathbb {R}}}^n$$ . The reference polyhedron R represents constraints that are easy to satisfy such as box constraints. In the special case $$R = {{\mathbb {R}}}^n$$ , we obtain a novel characterization of the classical Hoffman constant. More precisely, suppose $$R\subseteq \mathbb {R}^n$$ is a reference polyhedron, $$A\in {{\mathbb {R}}}^{m\times n},$$ and $$A(R):={Ax: x\in R}$$ . We characterize the sharpest constant $$H(A\vert R)$$ such that for all $$b \in A(R) + {{\mathbb {R}}}^m_+$$ and $$u\in R$$ $$\begin{aligned} {\mathrm {dist}}(u, P_{A}(b)\cap R) \le H(A\vert R) \cdot \Vert (Au-b)_+\Vert , \end{aligned}$$ where $$P_A(b) = {x\in {{\mathbb {R}}}^n:Ax\le b}$$ . Our characterization is stated in terms of the largest of a canonical collection of easily computable Hoffman constants. Our characterization in turn suggests new algorithmic procedures to compute Hoffman constants.},
  archive      = {J_MP},
  author       = {Peña, Javier and Vera, Juan C. and Zuluaga, Luis F.},
  doi          = {10.1007/s10107-020-01473-6},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {79-109},
  shortjournal = {Math. Program.},
  title        = {New characterizations of hoffman constants for systems of linear constraints},
  volume       = {187},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). High-order evaluation complexity for convexly-constrained
optimization with non-lipschitzian group sparsity terms. <em>MP</em>,
<em>187</em>(1), 47–78. (<a
href="https://doi.org/10.1007/s10107-020-01470-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies high-order evaluation complexity for partially separable convexly-constrained optimization involving non-Lipschitzian group sparsity terms in a nonconvex objective function. We propose a partially separable adaptive regularization algorithm using a pth order Taylor model and show that the algorithm needs at most $$O(\epsilon ^{-(p+1)/(p-q+1)})$$ evaluations of the objective function and its first p derivatives (whenever they exist) to produce an $$(\epsilon ,\delta )$$ -approximate qth-order stationary point. Our algorithm uses the underlying rotational symmetry of the Euclidean norm function to build a Lipschitzian approximation for the non-Lipschitzian group sparsity terms, which are defined by the group $$\ell _2$$ – $$\ell _a$$ norm with $$a\in (0,1)$$ . The new result shows that the partially-separable structure and non-Lipschitzian group sparsity terms in the objective function do not affect the worst-case evaluation complexity order.},
  archive      = {J_MP},
  author       = {Chen, X. and Toint, Ph. L.},
  doi          = {10.1007/s10107-020-01470-9},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {47-78},
  shortjournal = {Math. Program.},
  title        = {High-order evaluation complexity for convexly-constrained optimization with non-lipschitzian group sparsity terms},
  volume       = {187},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A simplex algorithm for rational cp-factorization.
<em>MP</em>, <em>187</em>(1), 25–45. (<a
href="https://doi.org/10.1007/s10107-020-01467-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we provide an algorithm, similar to the simplex algorithm, which determines a rational cp-factorization of a given matrix, whenever the matrix allows such a factorization. This algorithm can be used to show that every integral completely positive $$2 \times 2$$ matrix has an integral cp-factorization.},
  archive      = {J_MP},
  author       = {Dutour Sikirić, Mathieu and Schürmann, Achill and Vallentin, Frank},
  doi          = {10.1007/s10107-020-01467-4},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {25-45},
  shortjournal = {Math. Program.},
  title        = {A simplex algorithm for rational cp-factorization},
  volume       = {187},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An algorithm for the minimization of nonsmooth nonconvex
functions using inexact evaluations and its worst-case complexity.
<em>MP</em>, <em>187</em>(1), 1–24. (<a
href="https://doi.org/10.1007/s10107-020-01466-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An adaptive regularization algorithm using inexact function and derivatives evaluations is proposed for the solution of composite nonsmooth nonconvex optimization. It is shown that this algorithm needs at most $$O(|\log (\epsilon )|\,\epsilon ^{-2})$$ evaluations of the problem’s functions and their derivatives for finding an $$\epsilon $$ -approximate first-order stationary point. This complexity bound therefore generalizes that provided by Bellavia et al. (Theoretical study of an adaptive cubic regularization method with dynamic inexact Hessian information. arXiv:1808.06239 , 2018) for inexact methods for smooth nonconvex problems, and is within a factor $$|\log (\epsilon )|$$ of the optimal bound known for smooth and nonsmooth nonconvex minimization with exact evaluations. A practically more restrictive variant of the algorithm with worst-case complexity $$O(|\log (\epsilon )|+\epsilon ^{-2})$$ is also presented.},
  archive      = {J_MP},
  author       = {Gratton, S. and Simon, E. and Toint, Ph. L.},
  doi          = {10.1007/s10107-020-01466-5},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {1-24},
  shortjournal = {Math. Program.},
  title        = {An algorithm for the minimization of nonsmooth nonconvex functions using inexact evaluations and its worst-case complexity},
  volume       = {187},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Nonnegative rank depends on the field. <em>MP</em>,
<em>186</em>(1), 479–486. (<a
href="https://doi.org/10.1007/s10107-019-01448-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present an example of a subfield $$\mathcal {F}\subset \mathbb {R}$$ and a matrix A whose conventional and nonnegative ranks equal five, but the nonnegative rank with respect to $$\mathcal {F}$$ equals six. In other words, A can be represented as a sum of five rank-one matrices with nonnegative real entries but not as a sum of five rank-one matrices with nonnegative entries in $$\mathcal {F}$$ .},
  archive      = {J_MP},
  author       = {Shitov, Yaroslav},
  doi          = {10.1007/s10107-019-01448-2},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {479-486},
  shortjournal = {Math. Program.},
  title        = {Nonnegative rank depends on the field},
  volume       = {186},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Near-optimal discrete optimization for experimental design:
A regret minimization approach. <em>MP</em>, <em>186</em>(1), 439–478.
(<a href="https://doi.org/10.1007/s10107-019-01464-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The experimental design problem concerns the selection of k points from a potentially large design pool of p-dimensional vectors, so as to maximize the statistical efficiency regressed on the selected k design points. Statistical efficiency is measured by optimality criteria, including A(verage), D(eterminant), T(race), E(igen), V(ariance) and G-optimality. Except for the T-optimality, exact optimization is challenging, and for certain instances of D/E-optimality exact or even approximate optimization is proven to be NP-hard. We propose a polynomial-time regret minimization framework to achieve a $$(1+\varepsilon )$$ approximation with only $$O(p/\varepsilon ^2)$$ design points, for all the optimality criteria above. In contrast, to the best of our knowledge, before our work, no polynomial-time algorithm achieves $$(1+\varepsilon )$$ approximations for D/E/G-optimality, and the best poly-time algorithm achieving $$(1+\varepsilon )$$ -approximation for A/V-optimality requires $$k=\varOmega (p^2/\varepsilon )$$ design points.},
  archive      = {J_MP},
  author       = {Allen-Zhu, Zeyuan and Li, Yuanzhi and Singh, Aarti and Wang, Yining},
  doi          = {10.1007/s10107-019-01464-2},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {439-478},
  shortjournal = {Math. Program.},
  title        = {Near-optimal discrete optimization for experimental design: A regret minimization approach},
  volume       = {186},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An <span
class="math display">𝒪(<em>n</em><sup>2</sup>log <em>n</em>)</span>
algorithm for the weighted stable set problem in claw-free graphs.
<em>MP</em>, <em>186</em>(1), 409–437. (<a
href="https://doi.org/10.1007/s10107-019-01461-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A graph G(V, E) is claw-free if no vertex has three pairwise non-adjacent neighbours. The maximum weight stable set (MWSS) problem in a claw-free graph is a natural generalization of the matching problem and has been shown to be polynomially solvable by Minty and Sbihi in 1980. In a remarkable paper, Faenza, Oriolo and Stauffer have shown that, in a two-step procedure, a claw-free graph can be first turned into a quasi-line graph by removing strips containing all the irregular nodes and then decomposed into {claw, net}-free strips and strips with stability number at most three. Through this decomposition, the MWSS problem can be solved in $$\mathcal{O}(|V|(|V| \log |V| + |E|))$$ time. In this paper, we describe a direct decomposition of a claw-free graph into {claw, net}-free strips and strips with stability number at most three which can be performed in $$\mathcal{O}(|V|^2)$$ time. In two companion papers we showed that the MWSS problem can be solved in $$\mathcal{O}(|E| \log |V|)$$ time in claw-free graphs with $$\alpha (G) \le 3$$ and in $$\mathcal{O}(|V| \sqrt{|E|})$$ time in {claw, net}-free graphs with $$\alpha (G) \ge 4$$ . These results prove that the MWSS problem in a claw-free graph can be solved in $$\mathcal{O}(|V|^2 \log |V|)$$ time, the same complexity of the best and long standing algorithm for the MWSS problem in line graphs.},
  archive      = {J_MP},
  author       = {Nobili, Paolo and Sassano, Antonio},
  doi          = {10.1007/s10107-019-01461-5},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {409-437},
  shortjournal = {Math. Program.},
  title        = {An $${\mathcal {O}}(n^2 \log {n})$$ algorithm for the weighted stable set problem in claw-free graphs},
  volume       = {186},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Stronger MIP formulations for the steiner forest problem.
<em>MP</em>, <em>186</em>(1), 373–407. (<a
href="https://doi.org/10.1007/s10107-019-01460-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Steiner forest problem asks for a minimum weight forest that spans a given number of terminal sets. We propose new cut- and flow-based integer linear programming formulations for the problem which yield stronger linear programming bounds than the two previous strongest formulations: The directed cut formulation (Balakrishnan et al. in Oper Res 37(5):716–740, 1989; Chopra and Rao in Math Prog 64(1):209–229, 1994) and the advanced flow formulation by Magnanti and Raghavan (Networks 45:61–79, 2005). We further introduce strengthening constraints and provide an example where the integrality gap of our models is 1.5. In an experimental evaluation, we show that the linear programming bounds of the new formulations are indeed strong on practical instances and that the related branch-and-cut algorithm outperforms algorithms based on the previous formulations.},
  archive      = {J_MP},
  author       = {Schmidt, Daniel and Zey, Bernd and Margot, François},
  doi          = {10.1007/s10107-019-01460-6},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {373-407},
  shortjournal = {Math. Program.},
  title        = {Stronger MIP formulations for the steiner forest problem},
  volume       = {186},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Orbitopal fixing for the full (sub-)orbitope and application
to the unit commitment problem. <em>MP</em>, <em>186</em>(1), 337–372.
(<a href="https://doi.org/10.1007/s10107-019-01457-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper focuses on integer linear programs where solutions are binary matrices, and the corresponding symmetry group is the set of all column permutations. Orbitopal fixing, as introduced in Kaibel et al. (Discrete Optim 8(4):595–610, 2011), is a technique designed to break symmetries in the special case of partitioning (resp. packing) formulations involving matrices with exactly (resp. at most) one 1-entry in each row. The main result of this paper is to extend orbitopal fixing to the full orbitope, defined as the convex hull of binary matrices with lexicographically nonincreasing columns. We determine all the variables whose values are fixed in the intersection of an hypercube face with the full orbitope. Sub-symmetries arising in a given subset of matrices are also considered, thus leading to define the full sub-orbitope in the case of the sub-symmetric group. We propose a linear time orbitopal fixing algorithm handling both symmetries and sub-symmetries. We introduce a dynamic variant of this algorithm where the lexicographical order follows the branching decisions occurring along the B&amp;B search. Experimental results for the Unit Commitment Problem are presented. A comparison with state-of-the-art techniques is considered to show the effectiveness of the proposed variants of the algorithm.},
  archive      = {J_MP},
  author       = {Bendotti, Pascale and Fouilhoux, Pierre and Rottner, Cécile},
  doi          = {10.1007/s10107-019-01457-1},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {337-372},
  shortjournal = {Math. Program.},
  title        = {Orbitopal fixing for the full (sub-)orbitope and application to the unit commitment problem},
  volume       = {186},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). On sparsity of the solution to a random quadratic
optimization problem. <em>MP</em>, <em>186</em>(1), 309–336. (<a
href="https://doi.org/10.1007/s10107-019-01456-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The standard quadratic optimization problem (StQP), i.e. the problem of minimizing a quadratic form $$\mathbf{x}^TQ\mathbf{x}$$ on the standard simplex $${\mathbf{x}\ge \mathbf{0}: \mathbf{x}^T\mathbf{e}=1}$$ , is studied. The StQP arises in numerous applications, and it is known to be NP-hard. Chen, Peng and Zhang showed that almost certainly the StQP with a large random matrix $$Q=Q^T$$ , $$Q_{i,j},\, (i\le j)$$ being independent and identically concave-distributed, attains its minimum at a point $$\mathbf{x}$$ with support size $$|{j: x_j&gt;0}|$$ bounded in probability. Later Chen and Peng proved that for $$Q=(M+M^T)/2$$ , with $$M_{i,j}$$ i.i.d. normal, the likely support size is at most 2. In this paper we show that the likely support size is poly-logarithmic in n, the problem size, for a considerably broader class of the distributions. Unlike the cited papers, the mild constraints are put on the asymptotic behavior of the distribution at a single left endpoint of its support, rather than on the distribution’s shape elsewhere. It also covers the distributions with the left endpoint $$-\infty $$ , provided that the distribution of $$Q_{i,j},\, (i\le j)$$ (of $$M_{i,j}$$ , if $$Q=(M+M^T)/2$$ resp.) has a (super/sub) exponentially narrow left tail.},
  archive      = {J_MP},
  author       = {Chen, Xin and Pittel, Boris},
  doi          = {10.1007/s10107-019-01456-2},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {309-336},
  shortjournal = {Math. Program.},
  title        = {On sparsity of the solution to a random quadratic optimization problem},
  volume       = {186},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The salesman’s improved tours for fundamental classes.
<em>MP</em>, <em>186</em>(1), 289–307. (<a
href="https://doi.org/10.1007/s10107-019-01455-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Finding the exact integrality gap $$\alpha $$ for the LP relaxation of the metric travelling salesman problem (TSP) has been an open problem for over 30 years, with little progress made. It is known that $$4/3 \le \alpha \le 3/2$$ , and a famous conjecture states $$\alpha = 4/3$$ . It has also been conjectured that the integrality gap is achieved for half-integer basic solutions of the linear program. For this problem, essentially two “fundamental” classes of instances have been proposed. This fundamental property means that in order to show that the integrality gap is at most $$\rho $$ for all instances of the metric TSP, it is sufficient to show it only for the instances in the fundamental class. However, despite the importance and the simplicity of such classes, no apparent effort has been deployed for improving the integrality gap bounds for them. In this paper we take a natural first step in this endeavour, and consider the 1 / 2-integer points of one such class. We successfully improve the upper bound for the integrality gap from 3 / 2 to 10 / 7 for a superclass of these points for which a lower bound of 4 / 3 is proved. A key role in the proof of this result is played by finding Hamiltonian cycles whose existence is equivalent to Kotzig’s result on “compatible Eulerian tours”, and which lead us to delta-matroids for developing the related algorithms. Our arguments also involve other innovative tools from combinatorial optimization with the potential of a broader use.},
  archive      = {J_MP},
  author       = {Boyd, Sylvia and Sebő, András},
  doi          = {10.1007/s10107-019-01455-3},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {289-307},
  shortjournal = {Math. Program.},
  title        = {The salesman’s improved tours for fundamental classes},
  volume       = {186},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). On the behavior of lagrange multipliers in convex and
nonconvex infeasible interior point methods. <em>MP</em>,
<em>186</em>(1), 257–288. (<a
href="https://doi.org/10.1007/s10107-019-01454-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We analyze sequences generated by interior point methods (IPMs) in convex and nonconvex settings. We prove that moving the primal feasibility at the same rate as the barrier parameter $$\mu $$ ensures the Lagrange multiplier sequence remains bounded, provided the limit point of the primal sequence has a Lagrange multiplier. This result does not require constraint qualifications. We also guarantee the IPM finds a solution satisfying strict complementarity if one exists. On the other hand, if the primal feasibility is reduced too slowly, then the algorithm converges to a point of minimal complementarity; if the primal feasibility is reduced too quickly and the set of Lagrange multipliers is unbounded, then the norm of the Lagrange multiplier tends to infinity. Our theory has important implications for the design of IPMs. Specifically, we show that IPOPT, an algorithm that does not carefully control primal feasibility has practical issues with the dual multipliers values growing to unnecessarily large values. Conversely, the one-phase IPM of Hinder and Ye (A one-phase interior point method for nonconvex optimization, 2018. arXiv:1801.03072 ), an algorithm that controls primal feasibility as our theory suggests, has no such issue.},
  archive      = {J_MP},
  author       = {Haeser, Gabriel and Hinder, Oliver and Ye, Yinyu},
  doi          = {10.1007/s10107-019-01454-4},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {257-288},
  shortjournal = {Math. Program.},
  title        = {On the behavior of lagrange multipliers in convex and nonconvex infeasible interior point methods},
  volume       = {186},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Exploiting partial correlations in distributionally robust
optimization. <em>MP</em>, <em>186</em>(1), 209–255. (<a
href="https://doi.org/10.1007/s10107-019-01453-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we identify partial correlation information structures that allow for simpler reformulations in evaluating the maximum expected value of mixed integer linear programs with random objective coefficients. To this end, assuming only the knowledge of the mean and the covariance matrix entries restricted to block-diagonal patterns, we develop a reduced semidefinite programming formulation, the complexity of solving which is related to characterizing a suitable projection of the convex hull of the set $${(\mathbf x , \mathbf x {} \mathbf x &#39;): \mathbf x \in \mathcal {X}}$$ where $$\mathcal {X}$$ is the feasible region. In some cases, this lends itself to efficient representations that result in polynomial-time solvable instances, most notably for the distributionally robust appointment scheduling problem with random job durations as well as for computing tight bounds in the newsvendor problem, project evaluation and review technique networks and linear assignment problems. To the best of our knowledge, this is the first example of a distributionally robust optimization formulation for appointment scheduling that permits a tight polynomial-time solvable semidefinite programming reformulation which explicitly captures partially known correlation information between uncertain processing times of the jobs to be scheduled. We also discuss extensions where the random coefficients are assumed to be non-negative and additional overlapping correlation information is available.},
  archive      = {J_MP},
  author       = {Padmanabhan, Divya and Natarajan, Karthik and Murthy, Karthyek},
  doi          = {10.1007/s10107-019-01453-5},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {209-255},
  shortjournal = {Math. Program.},
  title        = {Exploiting partial correlations in distributionally robust optimization},
  volume       = {186},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Improved complexities of conditional gradient-type methods
with applications to robust matrix recovery problems. <em>MP</em>,
<em>186</em>(1), 185–208. (<a
href="https://doi.org/10.1007/s10107-019-01452-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Motivated by robust matrix recovery problems such as Robust Principal Component Analysis, we consider a general optimization problem of minimizing a smooth and strongly convex loss function applied to the sum of two blocks of variables, where each block of variables is constrained or regularized individually. We study a Conditional Gradient-Type method which is able to leverage the special structure of the problem to obtain faster convergence rates than those attainable via standard methods, under a variety of assumptions. In particular, our method is appealing for matrix problems in which one of the blocks corresponds to a low-rank matrix since it avoids prohibitive full-rank singular value decompositions required by most standard methods. While our initial motivation comes from problems which originated in statistics, our analysis does not impose any statistical assumptions on the data.},
  archive      = {J_MP},
  author       = {Garber, Dan and Kaplan, Atara and Sabach, Shoham},
  doi          = {10.1007/s10107-019-01452-6},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {185-208},
  shortjournal = {Math. Program.},
  title        = {Improved complexities of conditional gradient-type methods with applications to robust matrix recovery problems},
  volume       = {186},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Implementable tensor methods in unconstrained convex
optimization. <em>MP</em>, <em>186</em>(1), 157–183. (<a
href="https://doi.org/10.1007/s10107-019-01449-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we develop new tensor methods for unconstrained convex optimization, which solve at each iteration an auxiliary problem of minimizing convex multivariate polynomial. We analyze the simplest scheme, based on minimization of a regularized local model of the objective function, and its accelerated version obtained in the framework of estimating sequences. Their rates of convergence are compared with the worst-case lower complexity bounds for corresponding problem classes. Finally, for the third-order methods, we suggest an efficient technique for solving the auxiliary problem, which is based on the recently developed relative smoothness condition (Bauschke et al. in Math Oper Res 42:330–348, 2017; Lu et al. in SIOPT 28(1):333–354, 2018). With this elaboration, the third-order methods become implementable and very fast. The rate of convergence in terms of the function value for the accelerated third-order scheme reaches the level $$O\left( {1 \over k^4}\right) $$ , where k is the number of iterations. This is very close to the lower bound of the order $$O\left( {1 \over k^5}\right) $$ , which is also justified in this paper. At the same time, in many important cases the computational cost of one iteration of this method remains on the level typical for the second-order methods.},
  archive      = {J_MP},
  author       = {Nesterov, Yurii},
  doi          = {10.1007/s10107-019-01449-1},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {157-183},
  shortjournal = {Math. Program.},
  title        = {Implementable tensor methods in unconstrained convex optimization},
  volume       = {186},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). On distributionally robust chance constrained programs with
wasserstein distance. <em>MP</em>, <em>186</em>(1), 115–155. (<a
href="https://doi.org/10.1007/s10107-019-01445-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies a distributionally robust chance constrained program (DRCCP) with Wasserstein ambiguity set, where the uncertain constraints should be satisfied with a probability at least a given threshold for all the probability distributions of the uncertain parameters within a chosen Wasserstein distance from an empirical distribution. In this work, we investigate equivalent reformulations and approximations of such problems. We first show that a DRCCP can be reformulated as a conditional value-at-risk constrained optimization problem, and thus admits tight inner and outer approximations. We also show that a DRCCP of bounded feasible region is mixed integer representable by introducing big-M coefficients and additional binary variables. For a DRCCP with pure binary decision variables, by exploring the submodular structure, we show that it admits a big-M free formulation, which can be solved by a branch and cut algorithm. Finally, we present a numerical study to illustrate the effectiveness of the proposed formulations.},
  archive      = {J_MP},
  author       = {Xie, Weijun},
  doi          = {10.1007/s10107-019-01445-5},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {115-155},
  shortjournal = {Math. Program.},
  title        = {On distributionally robust chance constrained programs with wasserstein distance},
  volume       = {186},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Hypergraph k-cut in randomized polynomial time. <em>MP</em>,
<em>186</em>(1), 85–113. (<a
href="https://doi.org/10.1007/s10107-019-01443-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For a fixed integer $$k\ge 2$$ , the hypergraph k-cut problem asks for a smallest subset of hyperedges whose removal leads to at least k connected components in the remaining hypergraph. While graph k-cut is solvable efficiently (Goldschmidt and Hochbaum in Math. Oper. Res. 19(1):24–37, 1994), the complexity of hypergraph k-cut has been open. In this work, we present a randomized polynomial time algorithm to solve the hypergraph k-cut problem. Our algorithmic technique extends to solve the more general hedge k-cut problem when the subgraph induced by every hedge has a constant number of connected components. Our algorithm is based on random contractions akin to Karger’s min cut algorithm. Our main technical contribution is a non-uniform distribution over the hedges (hyperedges) so that random contraction of hedges (hyperedges) chosen from the distribution succeeds in returning an optimum solution with large probability. In addition, we present an alternative contraction based randomized polynomial time approximation scheme for hedge k-cut in arbitrary hedgegraphs (i.e., hedgegraphs whose hedges could have a large number of connected components). Our algorithm and analysis also lead to bounds on the number of optimal solutions to the respective problems.},
  archive      = {J_MP},
  author       = {Chandrasekaran, Karthekeyan and Xu, Chao and Yu, Xilin},
  doi          = {10.1007/s10107-019-01443-7},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {85-113},
  shortjournal = {Math. Program.},
  title        = {Hypergraph k-cut in randomized polynomial time},
  volume       = {186},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Why random reshuffling beats stochastic gradient descent.
<em>MP</em>, <em>186</em>(1), 49–84. (<a
href="https://doi.org/10.1007/s10107-019-01440-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We analyze the convergence rate of the random reshuffling (RR) method, which is a randomized first-order incremental algorithm for minimizing a finite sum of convex component functions. RR proceeds in cycles, picking a uniformly random order (permutation) and processing the component functions one at a time according to this order, i.e., at each cycle, each component function is sampled without replacement from the collection. Though RR has been numerically observed to outperform its with-replacement counterpart stochastic gradient descent (SGD), characterization of its convergence rate has been a long standing open question. In this paper, we answer this question by providing various convergence rate results for RR and variants when the sum function is strongly convex. We first focus on quadratic component functions and show that the expected distance of the iterates generated by RR with stepsize $$\alpha _k=\varTheta (1/k^s)$$ for $$s\in (0,1]$$ converges to zero at rate $$\mathcal{O}(1/k^s)$$ (with $$s=1$$ requiring adjusting the stepsize to the strong convexity constant). Our main result shows that when the component functions are quadratics or smooth (with a Lipschitz assumption on the Hessian matrices), RR with iterate averaging and a diminishing stepsize $$\alpha _k=\varTheta (1/k^s)$$ for $$s\in (1/2,1)$$ converges at rate $$\varTheta (1/k^{2s})$$ with probability one in the suboptimality of the objective value, thus improving upon the $$\varOmega (1/k)$$ rate of SGD. Our analysis draws on the theory of Polyak–Ruppert averaging and relies on decoupling the dependent cycle gradient error into an independent term over cycles and another term dominated by $$\alpha _k^2$$ . This allows us to apply law of large numbers to an appropriately weighted version of the cycle gradient errors, where the weights depend on the stepsize. We also provide high probability convergence rate estimates that shows decay rate of different terms and allows us to propose a modification of RR with convergence rate $$\mathcal{O}(\frac{1}{k^2})$$ .},
  archive      = {J_MP},
  author       = {Gürbüzbalaban, M. and Ozdaglar, A. and Parrilo, P. A.},
  doi          = {10.1007/s10107-019-01440-w},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {49-84},
  shortjournal = {Math. Program.},
  title        = {Why random reshuffling beats stochastic gradient descent},
  volume       = {186},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Amenable cones: Error bounds without constraint
qualifications. <em>MP</em>, <em>186</em>(1), 1–48. (<a
href="https://doi.org/10.1007/s10107-019-01439-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We provide a framework for obtaining error bounds for linear conic problems without assuming constraint qualifications or regularity conditions. The key aspects of our approach are the notions of amenable cones and facial residual functions. For amenable cones, it is shown that error bounds can be expressed as a composition of facial residual functions. The number of compositions is related to the facial reduction technique and the singularity degree of the problem. In particular, we show that symmetric cones are amenable and compute facial residual functions. From that, we are able to furnish a new Hölderian error bound, thus extending and shedding new light on an earlier result by Sturm on semidefinite matrices. We also provide error bounds for the intersection of amenable cones, this will be used to prove error bounds for the doubly nonnegative cone. At the end, we list some open problems.},
  archive      = {J_MP},
  author       = {Lourenço, Bruno F.},
  doi          = {10.1007/s10107-019-01439-3},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {1-48},
  shortjournal = {Math. Program.},
  title        = {Amenable cones: Error bounds without constraint qualifications},
  volume       = {186},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Worst-case complexity of cyclic coordinate descent: <span
class="math display"><em>O</em>(<em>n</em><sup>2</sup>)</span> gap with
randomized version. <em>MP</em>, <em>185</em>(1), 487–520. (<a
href="https://doi.org/10.1007/s10107-019-01437-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper concerns the worst-case complexity of cyclic coordinate descent (C-CD) for minimizing a convex quadratic function, which is equivalent to Gauss–Seidel method, Kaczmarz method and projection onto convex sets (POCS) in this simple setting. We observe that the known provable complexity of C-CD can be $$\mathcal {O}(n^2)$$ times slower than randomized coordinate descent (R-CD), but no example was proven to exhibit such a large gap. In this paper we show that the gap indeed exists. We prove that there exists an example for which C-CD takes at least $$\mathcal {O}(n^4 \kappa _{\text {CD}} \log \frac{1}{\epsilon })$$ operations, where $$\kappa _{\text {CD}}$$ is related to Demmel’s condition number and it determines the convergence rate of R-CD. It implies that in the worst case C-CD can indeed be $$\mathcal {O}(n^2)$$ times slower than R-CD, which has complexity $$\mathcal {O}( n^2 \kappa _{\text {CD}} \log \frac{1}{\epsilon })$$ . Note that for this example, the gap exists for any fixed update order, not just a particular order. An immediate consequence is that for Gauss–Seidel method, Kaczmarz method and POCS, there is also an $$\mathcal {O}(n^2) $$ gap between the cyclic versions and randomized versions (for solving linear systems). One difficulty with the analysis is that the spectral radius of a non-symmetric iteration matrix does not necessarily constitute a lower bound for the convergence rate. Finally, we design some numerical experiments to show that the size of the off-diagonal entries is an important indicator of the practical performance of C-CD.},
  archive      = {J_MP},
  author       = {Sun, Ruoyu and Ye, Yinyu},
  doi          = {10.1007/s10107-019-01437-5},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {487-520},
  shortjournal = {Math. Program.},
  title        = {Worst-case complexity of cyclic coordinate descent: $$O(n^2)$$ gap with randomized version},
  volume       = {185},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Mathematical programs with complementarity constraints and a
non-lipschitz objective: Optimality and approximation. <em>MP</em>,
<em>185</em>(1), 455–485. (<a
href="https://doi.org/10.1007/s10107-019-01435-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a class of mathematical programs with complementarity constraints (MPCC) where the objective function involves a non-Lipschitz sparsity-inducing term. Due to the existence of the non-Lipschitz term, existing constraint qualifications for locally Lipschitz MPCC cannot ensure that necessary optimality conditions hold at a local minimizer. In this paper, we present necessary optimality conditions and MPCC-tailored qualifications for the non-Lipschitz MPCC. The proposed qualifications are related to the constraints and the non-Lipschitz term, which ensure that local minimizers satisfy these necessary optimality conditions. Moreover, we present an approximation method for solving the non-Lipschitz MPCC and establish its convergence. Finally, we use numerical examples of sparse solutions of linear complementarity problems and the second-best road pricing problem in transportation science to illustrate the effectiveness of our approximation method for solving the non-Lipschitz MPCC.},
  archive      = {J_MP},
  author       = {Guo, Lei and Chen, Xiaojun},
  doi          = {10.1007/s10107-019-01435-7},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {455-485},
  shortjournal = {Math. Program.},
  title        = {Mathematical programs with complementarity constraints and a non-lipschitz objective: Optimality and approximation},
  volume       = {185},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Distributionally robust polynomial chance-constraints under
mixture ambiguity sets. <em>MP</em>, <em>185</em>(1), 409–453. (<a
href="https://doi.org/10.1007/s10107-019-01434-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given $${\mathbf {X}}\subset {\mathbb {R}}^n$$ , $$\varepsilon \in (0,1)$$ , a parametrized family of probability distributions $$(\mu _{{\mathbf {a}}})_{{\mathbf {a}}\in {\mathbf {A}}}$$ on $${\varvec{\Omega }}\subset {\mathbb {R}}^p$$ , we consider the feasible set $${\mathbf {X}}^*_\varepsilon \subset {\mathbf {X}}$$ associated with the distributionally robust chance-constraint $$\begin{aligned} {\mathbf {X}}^*_\varepsilon \,=\,{{\mathbf {x}}\in {\mathbf {X}}:\,\mathrm{Prob}_\mu [f({\mathbf {x}},{\omega })\,&gt;\,0]&gt; 1-\varepsilon ,\,\forall \mu \in {\mathscr {M}}_{\mathbf {a}}}, \end{aligned}$$ where $${\mathscr {M}}_{\mathbf {a}}$$ is the set of all possibles mixtures of distributions $$\mu _{\mathbf {a}}$$ , $${\mathbf {a}}\in {\mathbf {A}}$$ . For instance and typically, the family $${\mathscr {M}}_{\mathbf {a}}$$ is the set of all mixtures of Gaussian distributions on $${\mathbb {R}}$$ with mean and standard deviation $${\mathbf {a}}=(a,\sigma )$$ in some compact set $${\mathbf {A}}\subset {\mathbb {R}}^2$$ . We provide a sequence of inner approximations $${\mathbf {X}}^d_\varepsilon ={{\mathbf {x}}\in {\mathbf {X}}:w_d({\mathbf {x}}) &lt;\varepsilon }$$ , $$d\in {\mathbb {N}}$$ , where $$w_d$$ is a polynomial of degree d whose vector of coefficients is an optimal solution of a semidefinite program. The size of the latter increases with the degree d. We also obtain the strong and highly desirable asymptotic guarantee that $$\lambda ({\mathbf {X}}^*_\varepsilon {\setminus } {\mathbf {X}}^d_\varepsilon )\rightarrow 0$$ as d increases, where $$\lambda $$ is the Lebesgue measure on $${\mathbf {X}}$$ . Same results are also obtained for the more intricated case of distributionally robust “joint” chance-constraints. There is a price to pay for this strong asymptotic guarantee which is the scalability of such a numerical scheme, and so far this important drawback makes it limited to problems of modest dimension.},
  archive      = {J_MP},
  author       = {Lasserre, Jean B. and Weisser, Tillmann},
  doi          = {10.1007/s10107-019-01434-8},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {409-453},
  shortjournal = {Math. Program.},
  title        = {Distributionally robust polynomial chance-constraints under mixture ambiguity sets},
  volume       = {185},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-marginal maximal monotonicity and convex analysis.
<em>MP</em>, <em>185</em>(1), 385–408. (<a
href="https://doi.org/10.1007/s10107-019-01433-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Monotonicity and convex analysis arise naturally in the framework of multi-marginal optimal transport theory. However, a comprehensive multi-marginal monotonicity and convex analysis theory is still missing. To this end we study extensions of classical monotone operator theory and convex analysis into the multi-marginal setting. We characterize multi-marginal c-monotonicity in terms of classical monotonicity and firmly nonexpansive mappings. We provide Minty type, continuity and conjugacy criteria for multi-marginal maximal monotonicity. We extend the partition of the identity into a sum of firmly nonexpansive mappings and Moreau’s decomposition of the quadratic function into envelopes and proximal mappings into the multi-marginal settings. We illustrate our discussion with examples and provide applications for the determination of multi-marginal maximal monotonicity and multi-marginal conjugacy. We also point out several open questions.},
  archive      = {J_MP},
  author       = {Bartz, Sedi and Bauschke, Heinz H. and Phan, Hung M. and Wang, Xianfu},
  doi          = {10.1007/s10107-019-01433-9},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {385-408},
  shortjournal = {Math. Program.},
  title        = {Multi-marginal maximal monotonicity and convex analysis},
  volume       = {185},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Nonsmooth optimization using taylor-like models: Error
bounds, convergence, and termination criteria. <em>MP</em>,
<em>185</em>(1), 357–383. (<a
href="https://doi.org/10.1007/s10107-019-01432-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider optimization algorithms that successively minimize simple Taylor-like models of the objective function. Methods of Gauss–Newton type for minimizing the composition of a convex function and a smooth map are common examples. Our main result is an explicit relationship between the step-size of any such algorithm and the slope of the function at a nearby point. Consequently, we (1) show that the step-sizes can be reliably used to terminate the algorithm, (2) prove that as long as the step-sizes tend to zero, every limit point of the iterates is stationary, and (3) show that conditions, akin to classical quadratic growth, imply that the step-sizes linearly bound the distance of the iterates to the solution set. The latter so-called error bound property is typically used to establish linear (or faster) convergence guarantees. Analogous results hold when the step-size is replaced by the square root of the decrease in the model’s value. We complete the paper with extensions to when the models are minimized only inexactly.},
  archive      = {J_MP},
  author       = {Drusvyatskiy, D. and Ioffe, A. D. and Lewis, A. S.},
  doi          = {10.1007/s10107-019-01432-w},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {357-383},
  shortjournal = {Math. Program.},
  title        = {Nonsmooth optimization using taylor-like models: Error bounds, convergence, and termination criteria},
  volume       = {185},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Lower bounds for finding stationary points II: First-order
methods. <em>MP</em>, <em>185</em>(1), 315–355. (<a
href="https://doi.org/10.1007/s10107-019-01431-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We establish lower bounds on the complexity of finding $$\epsilon $$ -stationary points of smooth, non-convex high-dimensional functions using first-order methods. We prove that deterministic first-order methods, even applied to arbitrarily smooth functions, cannot achieve convergence rates in $$\epsilon $$ better than $$\epsilon ^{-8/5}$$ , which is within $$\epsilon ^{-1/15}\log \frac{1}{\epsilon }$$ of the best known rate for such methods. Moreover, for functions with Lipschitz first and second derivatives, we prove that no deterministic first-order method can achieve convergence rates better than $$\epsilon ^{-12/7}$$ , while $$\epsilon ^{-2}$$ is a lower bound for functions with only Lipschitz gradient. For convex functions with Lipschitz gradient, accelerated gradient descent achieves a better rate, showing that finding stationary points is easier given convexity.},
  archive      = {J_MP},
  author       = {Carmon, Yair and Duchi, John C. and Hinder, Oliver and Sidford, Aaron},
  doi          = {10.1007/s10107-019-01431-x},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {315-355},
  shortjournal = {Math. Program.},
  title        = {Lower bounds for finding stationary points II: First-order methods},
  volume       = {185},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Facets from gadgets. <em>MP</em>, <em>185</em>(1), 297–314.
(<a href="https://doi.org/10.1007/s10107-019-01430-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a new tool for generating cutting planes for $$\mathcal{NP}$$ -hard combinatorial optimisation problems. It is based on the concept of gadgets—small subproblems that are “glued” together to form hard problems—which we borrow from the literature on computational complexity. Using gadgets, we are able to derive huge (exponentially large) new families of strong (and sometimes facet-defining) cutting planes, accompanied by efficient separation algorithms. We illustrate the power of this approach on the asymmetric traveling salesman, stable set and clique partitioning problems.},
  archive      = {J_MP},
  author       = {Letchford, Adam N. and Vu, Anh N.},
  doi          = {10.1007/s10107-019-01430-y},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {297-314},
  shortjournal = {Math. Program.},
  title        = {Facets from gadgets},
  volume       = {185},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). New polyhedral and algorithmic results on greedoids.
<em>MP</em>, <em>185</em>(1), 275–296. (<a
href="https://doi.org/10.1007/s10107-019-01427-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present various new results on greedoids. We prove a theorem that generalizes an equivalent formulation of Edmonds’ classic matroid polytope theorem to local forest greedoids—a class of greedoids that contains matroids as well as branching greedoids. We also describe an application of this theorem in the field of measuring the reliability of networks by game-theoretical tools. Finally, we prove new results on the optimality of the greedy algorithm on greedoids and correct some mistakes that have been present in the literature for almost 3 decades.},
  archive      = {J_MP},
  author       = {Szeszlér, Dávid},
  doi          = {10.1007/s10107-019-01427-7},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {275-296},
  shortjournal = {Math. Program.},
  title        = {New polyhedral and algorithmic results on greedoids},
  volume       = {185},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Shorter tours and longer detours: Uniform covers and a bit
beyond. <em>MP</em>, <em>185</em>(1), 245–273. (<a
href="https://doi.org/10.1007/s10107-019-01426-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Motivated by the well known “four-thirds conjecture” for the traveling salesman problem (TSP), we study the problem of uniform covers. A graph $$G=(V,E)$$ has an $$\alpha $$ -uniform cover for TSP (2EC, respectively) if the everywhere $$\alpha $$ vector (i.e., $${\alpha }^{E}$$ ) dominates a convex combination of incidence vectors of tours (2-edge-connected spanning multigraphs, respectively). The polyhedral analysis of Christofides’ algorithm directly implies that a 3-edge-connected, cubic graph has a 1-uniform cover for TSP. Sebő asked if such graphs have $$(1-\epsilon )$$ -uniform covers for TSP for some $$\epsilon &gt; 0$$ . Indeed, the four-thirds conjecture implies that such graphs have $$\frac{8}{9}$$ -uniform covers. We show that these graphs have $$\frac{18}{19}$$ -uniform covers for TSP. We also study uniform covers for 2EC and show that the everywhere $$\frac{15}{17}$$ vector can be efficiently written as a convex combination of 2-edge-connected spanning multigraphs. For a weighted, 3-edge-connected, cubic graph, our results show that if the everywhere $$\frac{2}{3}$$ vector is an optimal solution for the subtour elimination linear programming relaxation for TSP, then a tour with weight at most $$\frac{27}{19}$$ times that of an optimal tour can be found efficiently. Node-weighted, 3-edge-connected, cubic graphs fall into this category. In this special case, we can apply our tools to obtain an even better approximation guarantee. An essential ingredient in our proofs is decompositions of graphs (e.g., cycle covers) that cover small-cardinality cuts an even (nonzero) number of times. Another essential tool we use is half-integral tree augmentation, which is known to have a small integrality gap. To extend our approach to input graphs that are 2-edge-connected, we present a procedure to decompose a point in the subtour elimination polytope into spanning, connected subgraphs that cover each 2-edge cut an even number of times. Using this decomposition, we obtain a $$\frac{17}{12}$$ -approximation algorithm for minimum weight 2-edge-connected spanning subgraphs on subcubic, node-weighted graphs.},
  archive      = {J_MP},
  author       = {Haddadan, Arash and Newman, Alantha and Ravi, R.},
  doi          = {10.1007/s10107-019-01426-8},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {245-273},
  shortjournal = {Math. Program.},
  title        = {Shorter tours and longer detours: Uniform covers and a bit beyond},
  volume       = {185},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Iteration complexity of inexact augmented lagrangian methods
for constrained convex programming. <em>MP</em>, <em>185</em>(1),
199–244. (<a href="https://doi.org/10.1007/s10107-019-01425-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Augmented Lagrangian method (ALM) has been popularly used for solving constrained optimization problems. Practically, subproblems for updating primal variables in the framework of ALM usually can only be solved inexactly. The convergence and local convergence speed of ALM have been extensively studied. However, the global convergence rate of the inexact ALM is still open for problems with nonlinear inequality constraints. In this paper, we work on general convex programs with both equality and inequality constraints. For these problems, we establish the global convergence rate of the inexact ALM and estimate its iteration complexity in terms of the number of gradient evaluations to produce a primal and/or primal-dual solution with a specified accuracy. We first establish an ergodic convergence rate result of the inexact ALM that uses constant penalty parameters or geometrically increasing penalty parameters. Based on the convergence rate result, we then apply Nesterov’s optimal first-order method on each primal subproblem and estimate the iteration complexity of the inexact ALM. We show that if the objective is convex, then $$O(\varepsilon ^{-1})$$ gradient evaluations are sufficient to guarantee a primal $$\varepsilon $$ -solution in terms of both primal objective and feasibility violation. If the objective is strongly convex, the result can be improved to $$O(\varepsilon ^{-\frac{1}{2}}|\log \varepsilon |)$$ . To produce a primal-dual $$\varepsilon $$ -solution, more gradient evaluations are needed for convex case, and the number is $$O(\varepsilon ^{-\frac{4}{3}})$$ , while for strongly convex case, the number is still $$O(\varepsilon ^{-\frac{1}{2}}|\log \varepsilon |)$$ . Finally, we establish a nonergodic convergence rate result of the inexact ALM that uses geometrically increasing penalty parameters. This result is established only for the primal problem. We show that the nonergodic iteration complexity result is in the same order as that for the ergodic result. Numerical experiments on quadratically constrained quadratic programming are conducted to compare the performance of the inexact ALM with different settings.},
  archive      = {J_MP},
  author       = {Xu, Yangyang},
  doi          = {10.1007/s10107-019-01425-9},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {199-244},
  shortjournal = {Math. Program.},
  title        = {Iteration complexity of inexact augmented lagrangian methods for constrained convex programming},
  volume       = {185},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Mixed-integer bilevel representability. <em>MP</em>,
<em>185</em>(1), 163–197. (<a
href="https://doi.org/10.1007/s10107-019-01424-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the representability of sets by extended formulations using mixed-integer bilevel programs. We show that feasible regions modeled by continuous bilevel constraints (with no integer variables), complementarity constraints, and polyhedral reverse convex constraints are all finite unions of polyhedra. Conversely, any finite union of polyhedra can be represented using any one of these three paradigms. We then prove that the feasible region of bilevel problems with integer variables exclusively in the upper level is a finite union of sets representable by mixed-integer programs and vice versa. Further, we prove that, up to topological closures, we do not get additional modeling power by allowing integer variables in the lower level as well. To establish the last statement, we prove that the family of sets that are finite unions of mixed-integer representable sets (up to topological closures) forms an algebra of sets; i.e., this family is closed under finite unions, intersections and complementation.},
  archive      = {J_MP},
  author       = {Basu, Amitabh and Ryan, Christopher Thomas and Sankaranarayanan, Sriram},
  doi          = {10.1007/s10107-019-01424-w},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {163-197},
  shortjournal = {Math. Program.},
  title        = {Mixed-integer bilevel representability},
  volume       = {185},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). On the equivalence of inexact proximal ALM and ADMM for a
class of convex composite programming. <em>MP</em>, <em>185</em>(1),
111–161. (<a href="https://doi.org/10.1007/s10107-019-01423-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we show that for a class of linearly constrained convex composite optimization problems, an (inexact) symmetric Gauss–Seidel based majorized multi-block proximal alternating direction method of multipliers (ADMM) is equivalent to an inexact proximal augmented Lagrangian method. This equivalence not only provides new perspectives for understanding some ADMM-type algorithms but also supplies meaningful guidelines on implementing them to achieve better computational efficiency. Even for the two-block case, a by-product of this equivalence is the convergence of the whole sequence generated by the classic ADMM with a step-length that exceeds the conventional upper bound of $$(1+\sqrt{5})/2$$ , if one part of the objective is linear. This is exactly the problem setting in which the very first convergence analysis of ADMM was conducted by Gabay and Mercier (Comput Math Appl 2(1):17–40, 1976), but, even under notably stronger assumptions, only the convergence of the primal sequence was known. A collection of illustrative examples are provided to demonstrate the breadth of applications for which our results can be used. Numerical experiments on solving a large number of linear and convex quadratic semidefinite programming problems are conducted to illustrate how the theoretical results established here can lead to improvements on the corresponding practical implementations.},
  archive      = {J_MP},
  author       = {Chen, Liang and Li, Xudong and Sun, Defeng and Toh, Kim-Chuan},
  doi          = {10.1007/s10107-019-01423-x},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {111-161},
  shortjournal = {Math. Program.},
  title        = {On the equivalence of inexact proximal ALM and ADMM for a class of convex composite programming},
  volume       = {185},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A differentiable homotopy method to compute perfect
equilibria. <em>MP</em>, <em>185</em>(1), 77–109. (<a
href="https://doi.org/10.1007/s10107-019-01422-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The notion of perfect equilibrium was formulated by Selten (Int J Game Theory 4(1):25–55, 1975) as a strict refinement of Nash equilibrium. For an extensive-form game with perfect recall, every perfect equilibrium of its agent normal-form game yields a perfect equilibrium of the extensive-form game. This paper aims to develop a differentiable homotopy method for computing perfect equilibria of normal-form games. To accomplish this objective, we constitute an artificial game by introducing a continuously differentiable function of an extra variable. The artificial game defines a differentiable homotopy mapping and establishes the existence of a smooth path to a perfect equilibrium. For numerical comparison, we also describe a simplicial homotopy method. Numerical results show that the differentiable homotopy method is numerically stable and efficient and significantly outperforms the simplicial homotopy method especially when the problem is large.},
  archive      = {J_MP},
  author       = {Chen, Yin and Dang, Chuangyin},
  doi          = {10.1007/s10107-019-01422-y},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {77-109},
  shortjournal = {Math. Program.},
  title        = {A differentiable homotopy method to compute perfect equilibria},
  volume       = {185},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multidimensional sum-up rounding for integer programming in
optimal experimental design. <em>MP</em>, <em>185</em>(1), 37–76. (<a
href="https://doi.org/10.1007/s10107-019-01421-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a numerical method for approximating the solution of convex integer programs stemming from optimal experimental design. The statistical setup consists of a Bayesian framework for linear inverse problems for which the direct relationship is described by a discretized integral equation. Specifically, we aim to find the optimal sensor placement from a set of candidate locations where data are collected with measurement error. The convex objective function is a measure of the uncertainty, described here by the trace or log-determinant of the posterior covariance matrix, for the discretized linear inverse problem solution. The resulting convex integer program is relaxed, producing a lower bound. An upper bound is obtained by extending the sum-up rounding approach to multiple dimensions. For this extension, we analyze its accuracy as a function of the discretization mesh size for a rectangular domain. We show asymptotic optimality of the integer solution defining the upper bound for different experimental design criteria (A- and D-optimal), by proving the convergence to zero of the gap between the upper and lower bounds as the mesh size goes to zero. The technique is illustrated on a two-dimensional gravity surveying problem for both A-optimal and D-optimal sensor placement where our designs yield better results compared with a thresholding rounding approach.},
  archive      = {J_MP},
  author       = {Yu, Jing and Anitescu, Mihai},
  doi          = {10.1007/s10107-019-01421-z},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {37-76},
  shortjournal = {Math. Program.},
  title        = {Multidimensional sum-up rounding for integer programming in optimal experimental design},
  volume       = {185},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Lower complexity bounds of first-order methods for
convex-concave bilinear saddle-point problems. <em>MP</em>,
<em>185</em>(1), 1–35. (<a
href="https://doi.org/10.1007/s10107-019-01420-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {On solving a convex-concave bilinear saddle-point problem (SPP), there have been many works studying the complexity results of first-order methods. These results are all about upper complexity bounds, which can determine at most how many iterations would guarantee a solution of desired accuracy. In this paper, we pursue the opposite direction by deriving lower complexity bounds of first-order methods on large-scale SPPs. Our results apply to the methods whose iterates are in the linear span of past first-order information, as well as more general methods that produce their iterates in an arbitrary manner based on first-order information. We first work on the affinely constrained smooth convex optimization that is a special case of SPP. Different from gradient method on unconstrained problems, we show that first-order methods on affinely constrained problems generally cannot be accelerated from the known convergence rate O(1 / t) to $$O(1/t^2)$$ , and in addition, O(1 / t) is optimal for convex problems. Moreover, we prove that for strongly convex problems, $$O(1/t^2)$$ is the best possible convergence rate, while it is known that gradient methods can have linear convergence on unconstrained problems. Then we extend these results to general SPPs. It turns out that our lower complexity bounds match with several established upper complexity bounds in the literature, and thus they are tight and indicate the optimality of several existing first-order methods.},
  archive      = {J_MP},
  author       = {Ouyang, Yuyuan and Xu, Yangyang},
  doi          = {10.1007/s10107-019-01420-0},
  journal      = {Mathematical Programming},
  number       = {1},
  pages        = {1-35},
  shortjournal = {Math. Program.},
  title        = {Lower complexity bounds of first-order methods for convex-concave bilinear saddle-point problems},
  volume       = {185},
  year         = {2021},
}
</textarea>
</details></li>
</ul>

</body>
</html>
