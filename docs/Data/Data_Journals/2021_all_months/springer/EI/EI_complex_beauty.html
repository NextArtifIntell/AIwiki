<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>EI_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="ei---121">EI - 121</h2>
<ul>
<li><details>
<summary>
(2021). Designing a multi-agent system architecture for managing
distributed operations within cloud manufacturing. <em>EI</em>,
<em>14</em>(4), 2051–2058. (<a
href="https://doi.org/10.1007/s12065-020-00390-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cloud manufacturing (CM) is a challenging scenario in the fourth stage of industrial production (i.e. Industry 4.0). In this context, the fusion of physical and virtual worlds in cyber-physical production systems transforms manufacturing resources into homogeneous services that can be shared and distributed in collaborative environments. CM systems are characterized by intelligent capability management and manufacturing cloud service-management. An interesting research topic in these areas is the production planning with a decentralized pool of homogeneous resources. The distributed Task Scheduling Problem in CM has been partially tackled in the current literature, but some issues, such as the dynamic task arrival, the downtime of machines, the anomalous tasks identification, have not been addressed. Armed with such a vision, we discuss the design of a multi-agent system for managing and monitoring homogeneous manufacturing services in a CM system based on Additive Manufacturing Technologies.},
  archive      = {J_EI},
  author       = {D’Aniello, Giuseppe and De Falco, Massimo and Mastrandrea, Nicola},
  doi          = {10.1007/s12065-020-00390-z},
  journal      = {Evolutionary Intelligence},
  month        = {12},
  number       = {4},
  pages        = {2051-2058},
  shortjournal = {Evol. Intell.},
  title        = {Designing a multi-agent system architecture for managing distributed operations within cloud manufacturing},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Bio-inspired motivational architecture for autonomous robots
using glucose and insulin theories. <em>EI</em>, <em>14</em>(4),
2039–2050. (<a
href="https://doi.org/10.1007/s12065-020-00489-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Motivation and emotions have been area of interest for philosophers, psychologists and neuroscientist. Researchers and scientists want to have human like intelligent robots which are self-aware and self-motivated. Motivational robots are autonomous and intelligent which can set goals and then take actions to achieve their goals independently. Moreover, intelligence in robots is not possible without autonomy and autonomy is incorporated in robots through motivation. Nowadays, attention is being paid to build robots which have computational and energy autonomy. In Literature, various motivational architectures have been presented but none seems to focus on the development of human inspired motivation in robots comprehensively. These architectures try to achieve mere functional motivation in limited way, some considered only time for the regulation of drives, others failed to incorporate physiological and psychological aspects of human motivation. To the best of our knowledge, no architecture is truly based on the physiology and psychology of humans has been considered in the literature. To solve this problem, this paper proposes a motivational architecture for autonomous robots to make them independent in deciding the goals and taking actions. The proposed architecture is primarily based on physiology and psychology of human motivation through basic human drives (hunger, thirst and sleep), emotions and glucose-insulin theories. The whole process of drives regulation is based on stimulation and satiation. The intensity of the drives and the emotional states help in setting the goal and accordingly a suitable action is taken to meet the particular goal. Empirical results show that glucose and insulin have direct relationship with basic drives and emotions in the process of intrinsic motivation generation. The proposed architecture has applications in industry, education and autonomous robots. The proposed motivational architecture has significant advantages over several state-of-the-art architectures in terms of autonomy through intrinsic motivation.},
  archive      = {J_EI},
  author       = {Khan, Ahmad Saeed and Anwar, Adeem Ali and Azeem, Kiran},
  doi          = {10.1007/s12065-020-00489-3},
  journal      = {Evolutionary Intelligence},
  month        = {12},
  number       = {4},
  pages        = {2039-2050},
  shortjournal = {Evol. Intell.},
  title        = {Bio-inspired motivational architecture for autonomous robots using glucose and insulin theories},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Numerical solution of bagley–torvik equations using legendre
artificial neural network method. <em>EI</em>, <em>14</em>(4),
2027–2037. (<a
href="https://doi.org/10.1007/s12065-020-00481-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we have used the Legendre artificial neural network to find the solution of the Bagley–Torvik equation, which is a fractional-order ordinary differential equation. Caputo fractional derivative has been considered throughout the presented work to handle the fractional order differential equation. The training of optimal weights of the network has been carried out using a simulated annealing optimization technique. Here we have presented three examples to exhibit the precision and relevance of the proposed technique with comparison to the other numerical methods with error analysis. The proposed technique is an easy, highly efficient, and robust technique for finding the approximate solution of fractional-order ordinary differential equations.},
  archive      = {J_EI},
  author       = {Verma, Akanksha and Kumar, Manoj},
  doi          = {10.1007/s12065-020-00481-x},
  journal      = {Evolutionary Intelligence},
  month        = {12},
  number       = {4},
  pages        = {2027-2037},
  shortjournal = {Evol. Intell.},
  title        = {Numerical solution of Bagley–Torvik equations using legendre artificial neural network method},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Improved chaotic binary grey wolf optimization algorithm for
workflow scheduling in green cloud computing. <em>EI</em>,
<em>14</em>(4), 1997–2025. (<a
href="https://doi.org/10.1007/s12065-020-00479-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The workflow scheduling in the cloud computing environment is a well-known NP-complete problem, and metaheuristic algorithms are successfully adapted to solve this problem more efficiently. Grey wolf optimization (GWO) is a recently proposed interesting metaheuristic algorithm to deal with continuous optimization problems. In this paper, we proposed IGWO, an improved version of the GWO algorithm which uses the hill-climbing method and chaos theory to achieve better results. The proposed algorithm can increase the convergence speed of the GWO and prevents falling into the local optimum. Afterward, a binary version of the proposed IGWO algorithm, using various S functions and V functions, is introduced to deal with the workflow scheduling problem in cloud computing data centers, aiming to minimize their executions’ cost, makespan, and the power consumption. The proposed workflow scheduling scheme is simulated using the CloudSim simulator and the results show that our scheme can outperform other scheduling approaches in terms of metrics such as power consumption, cost, and makespan.},
  archive      = {J_EI},
  author       = {Mohammadzadeh, Ali and Masdari, Mohammad and Gharehchopogh, Farhad Soleimanian and Jafarian, Ahmad},
  doi          = {10.1007/s12065-020-00479-5},
  journal      = {Evolutionary Intelligence},
  month        = {12},
  number       = {4},
  pages        = {1997-2025},
  shortjournal = {Evol. Intell.},
  title        = {Improved chaotic binary grey wolf optimization algorithm for workflow scheduling in green cloud computing},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Hybridizing ant lion with whale optimization algorithm for
compressed sensing MR image reconstruction via l1 minimization: An ALWOA
strategy. <em>EI</em>, <em>14</em>(4), 1985–1995. (<a
href="https://doi.org/10.1007/s12065-020-00475-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the field of image compression, the compressed sensing image reconstruction has made great achievements due to proper use of the image sparsity without the Nyquist sampling law constraint. For image information distribution, great deals of researches indicate that there exists obvious structural and statistical prior’s regularity and by the traditional compression algorithm it is difficult to achieve. In this paper, we propose a compressed sensing image reconstruction algorithm based on hybrid ALWOA strategy, which combines the ant lion optimization algorithm and the whale optimization algorithm. The hybrid algorithm produces a global search with faster convergence. By continuously learning the proposed hybrid method can find optimal solutions. The objective function for the image reconstruction process is taken as the l1 minimization problem. The reconstructed image is obtained by solving the l1 minimization problem. Extensive simulations have been conducted and the results show that the proposed method has achieved better performance when compared with traditional reconstruction algorithms.},
  archive      = {J_EI},
  author       = {Kavitha, Tirugatla Surya and Prasad, K. Satya},
  doi          = {10.1007/s12065-020-00475-9},
  journal      = {Evolutionary Intelligence},
  month        = {12},
  number       = {4},
  pages        = {1985-1995},
  shortjournal = {Evol. Intell.},
  title        = {Hybridizing ant lion with whale optimization algorithm for compressed sensing MR image reconstruction via l1 minimization: An ALWOA strategy},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). SOS 2.0: An evolutionary approach for SOS algorithm.
<em>EI</em>, <em>14</em>(4), 1965–1983. (<a
href="https://doi.org/10.1007/s12065-020-00476-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the shortcomings on the solution given for most-recent optimization problems, decision-makers from different fields yearn the existence of tenacious breakthrough. In fact, they all shared the same obligation to optimize work efficiency, whether to minimize cost, consumption or to maximize the profit acquirement. Metaheuristic search is the more-advanced method proven to be useful for difficult optimization tasks. Moreover, development records also signalized rapid development of these algorithms, contributing several notable and powerful optimization algorithms. Among them, Symbiotic Organisms Search (SOS) received noticeable attention due to its simplicity and also its parameter-less nature. Nonetheless, several considerable issues are still challenging for further development. For instance, local optima and premature convergence issues found from any improper and inefficiency computational procedure on higher dimensional problems. Also, exploitation and exploration trade-off is another essential issue involving stability for optimal performance. In that case, this work proposed a new evolutionary approach named SOS 2.0. There are two distinct features associated with the evolution: Self-Parameter-Updating (SPU) technique and chaotic maps sequencing. Both features are integrated for a better balance of exploration and exploitation in which SPU focuses on exploration and chaotic map focuses on exploitation instead. This work also applied benchmarks function tests and engineering design optimization problem in advance for validation purpose of the performance. The experimental results showed that SOS 2.0 delivers not only better performance from its predecessor and also several recent SOS modifications which can be concluded as one successive approach for better SOS algorithm, but also enhances the computation efficiency and capability of searching optimal solution.},
  archive      = {J_EI},
  author       = {Cheng, Min-Yuan and Gosno, Richard Antoni},
  doi          = {10.1007/s12065-020-00476-8},
  journal      = {Evolutionary Intelligence},
  month        = {12},
  number       = {4},
  pages        = {1965-1983},
  shortjournal = {Evol. Intell.},
  title        = {SOS 2.0: An evolutionary approach for SOS algorithm},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A group evaluation based binary PSO algorithm for feature
selection in high dimensional data. <em>EI</em>, <em>14</em>(4),
1949–1963. (<a
href="https://doi.org/10.1007/s12065-020-00482-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a group evolution based feature selection technique using Binary PSO, which is an essential tool of pre-processing for solving classification problem. A new updating mechanism for calculating Pbest and Gbest are also proposed and the relevance and redundancy of the selected feature subsets are considered as an objective function. The proposed algorithm is tested and compared with four existing feature selection algorithms. In this study, a decision tree classifier is employed to evaluate the classification accuracy of the selected feature subsets on five benchmark datasets. The result shows that proposed algorithm can be successfully used to improve classification accuracy and to improve stability indices as well. It is also observed that with increased weight on relevance of the function, there is a significant reduction on the cardinality of features and increase in classification accuracy. The existing four algorithms usually select a smaller feature subset while the proposed algorithm can achieves higher classification accuracy on most of the test datasets.},
  archive      = {J_EI},
  author       = {Huda, Ramesh Kumar and Banka, Haider},
  doi          = {10.1007/s12065-020-00482-w},
  journal      = {Evolutionary Intelligence},
  month        = {12},
  number       = {4},
  pages        = {1949-1963},
  shortjournal = {Evol. Intell.},
  title        = {A group evaluation based binary PSO algorithm for feature selection in high dimensional data},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Hybrid approach based on cuckoo optimization algorithm and
genetic algorithm for task scheduling. <em>EI</em>, <em>14</em>(4),
1931–1947. (<a
href="https://doi.org/10.1007/s12065-020-00471-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the most important issues in designing efficient scheduling algorithms in heterogeneous distribution systems is the reduction of execution time. In the proposed algorithm, the modified operators of the cuckoo optimization algorithm and the genetic algorithm are used to achieve a relatively optimal solution with fewer repetitions of the genetic algorithm and less execution time than the cuckoo optimization algorithm. The most important innovation in the proposed algorithm is the introduction of a new operator called spiral search, which increases the variety among the samples produced in each generation. The main idea of this operator is to replace linear search with the spiral search, which allows local search between similar schedules and accelerates the achievement of a relatively optimal answer. Also the multi objective function in the proposed algorithm is used to minimize makespan and maximize parallelization. The results obtained from the proposed algorithm on a large number of standard graphs with a various range of attributes show that it is superior to the other task scheduling algorithms.},
  archive      = {J_EI},
  author       = {Akbari, Mehdi},
  doi          = {10.1007/s12065-020-00471-z},
  journal      = {Evolutionary Intelligence},
  month        = {12},
  number       = {4},
  pages        = {1931-1947},
  shortjournal = {Evol. Intell.},
  title        = {Hybrid approach based on cuckoo optimization algorithm and genetic algorithm for task scheduling},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Hybrid particle swarm optimization with particle elimination
for the high school timetabling problem. <em>EI</em>, <em>14</em>(4),
1915–1930. (<a
href="https://doi.org/10.1007/s12065-020-00473-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a PSO-based algorithm that hybridized Particle Swarm Optimization (PSO) and Hill Climbing (HC) is applied to high school timetabling problem. This hybrid has two features, a novel solution transformation and particle elimination. The proposed methodologies are tested on the XHSTT-2014 dataset (which is relatively new for the school timetabling problem) plus other additional instances. The experimental results show that the proposed algorithm is effective in solving small and medium instances compared to standalone HC and better than the conventional PSO for most instances. In a comparison to the state of the art methods, it achieved the lowest mean of soft constraint violations for 7 instances and the lowest mean of hard constraint violations for 1 instance.},
  archive      = {J_EI},
  author       = {Tan, Joo Siang and Goh, Say Leng and Sura, Suaini and Kendall, Graham and Sabar, Nasser R.},
  doi          = {10.1007/s12065-020-00473-x},
  journal      = {Evolutionary Intelligence},
  month        = {12},
  number       = {4},
  pages        = {1915-1930},
  shortjournal = {Evol. Intell.},
  title        = {Hybrid particle swarm optimization with particle elimination for the high school timetabling problem},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An extensive experimental evaluation of automated machine
learning methods for recommending classification algorithms.
<em>EI</em>, <em>14</em>(4), 1895–1914. (<a
href="https://doi.org/10.1007/s12065-020-00463-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents an experimental comparison among four automated machine learning (AutoML) methods for recommending the best classification algorithm for a given input dataset. Three of these methods are based on evolutionary algorithms (EAs), and the other is Auto-WEKA, a well-known AutoML method based on the combined algorithm selection and hyper-parameter optimisation (CASH) approach. The EA-based methods build classification algorithms from a single machine learning paradigm: either decision-tree induction, rule induction, or Bayesian network classification. Auto-WEKA combines algorithm selection and hyper-parameter optimisation to recommend classification algorithms from multiple paradigms. We performed controlled experiments where these four AutoML methods were given the same runtime limit for different values of this limit. In general, the difference in predictive accuracy of the three best AutoML methods was not statistically significant. However, the EA evolving decision-tree induction algorithms has the advantage of producing algorithms that generate interpretable classification models and that are more scalable to large datasets, by comparison with many algorithms from other learning paradigms that can be recommended by Auto-WEKA. We also observed that Auto-WEKA has shown meta-overfitting, a form of overfitting at the meta-learning level, rather than at the base-learning level.},
  archive      = {J_EI},
  author       = {Basgalupp, M. P. and Barros, R. C. and de Sá, A. G. C. and Pappa, G. L. and Mantovani, R. G. and de Carvalho, A. C. P. L. F. and Freitas, A. A.},
  doi          = {10.1007/s12065-020-00463-z},
  journal      = {Evolutionary Intelligence},
  month        = {12},
  number       = {4},
  pages        = {1895-1914},
  shortjournal = {Evol. Intell.},
  title        = {An extensive experimental evaluation of automated machine learning methods for recommending classification algorithms},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Novel operators for quantum evolutionary algorithm in
solving timetabling problem. <em>EI</em>, <em>14</em>(4), 1869–1893. (<a
href="https://doi.org/10.1007/s12065-020-00438-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Timetabling is a well-known combinatorial optimization problem which belongs to the class of NP hard problems. Quantum Evolutionary Algorithms (QEA) are highly suitable for the class of combinatorial optimization problems, but since proposed, they have not been used in solving this problem. In this paper we develop new operators for QEA to improve its performance in solving timetabling problem. The first operator we develop is a reinitialization operator which checks the population and when it is converged, reinitializes it to maintain the diversity. The other operator is called the Diversity Preserving operator which monitors the q-individuals, and if it finds more than one q-individuals searching around the same local optimum, reinitializes some of them to make sure different q-individuals are exploiting different regions in the search space. In this paper we also study the population size and the population structure of QEA in solving timetabling problem. In order to test the proposed algorithm, we perform experiments and compare the proposed algorithm to the existing algorithms on some well-known benchmark functions.},
  archive      = {J_EI},
  author       = {Tayarani-N., Mohammad-H.},
  doi          = {10.1007/s12065-020-00438-0},
  journal      = {Evolutionary Intelligence},
  month        = {12},
  number       = {4},
  pages        = {1869-1893},
  shortjournal = {Evol. Intell.},
  title        = {Novel operators for quantum evolutionary algorithm in solving timetabling problem},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Neighborhood centroid opposite-based learning harris hawks
optimization for training neural networks. <em>EI</em>, <em>14</em>(4),
1847–1867. (<a
href="https://doi.org/10.1007/s12065-020-00465-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Harris Hawks Optimization Algorithm is a new metaheuristic optimization that simulates the process of Harris Hawk hunting prey (rabbit) in nature. The global and local search processes of the algorithm are performed by simulating several stages of cooperative behavior during hunting. To enhance the performance of this algorithm, in this paper we propose a neighborhood centroid opposite-based learning Harris Hawks optimization algorithm (NCOHHO). The mechanism of applying the neighborhood centroid under the premise of using opposite-based learning technology to improve the performance of the algorithm, the neighborhood centroid is used as a reference point for the generation of the opposite particle, while maintaining the diversity of the population and make full use of the swarm search experience to expand the search range of the reverse solution. Enhancing the probability of finding the optimal solution and the improved algorithm is superior to the original Harris Hawks Optimization algorithm in all aspects. We apply NCOHHO to the training of feed-forward neural network (FNN). To confirm that using NCOHHO to train FNN is more effective, five classification datasets are applied to benchmark the performance of the proposed method. Comprehensive comparison and analysis from the three aspects of mean, variance and classification success rate, the experimental results show that the proposed NCOHHO algorithm for optimization FNN has the best comprehensive performance and has more outstanding performance than other metaheuristic algorithms in terms of the performance measures.},
  archive      = {J_EI},
  author       = {Fan, Chencheng and Zhou, Yongquan and Tang, Zhonghua},
  doi          = {10.1007/s12065-020-00465-x},
  journal      = {Evolutionary Intelligence},
  month        = {12},
  number       = {4},
  pages        = {1847-1867},
  shortjournal = {Evol. Intell.},
  title        = {Neighborhood centroid opposite-based learning harris hawks optimization for training neural networks},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Massive MIMO perspective: Improved sea lion for optimal
antenna selection. <em>EI</em>, <em>14</em>(4), 1831–1845. (<a
href="https://doi.org/10.1007/s12065-020-00457-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The massive MIMO is an advanced technology in the wideband wireless communication system’s future, which provokes extensive attention in both academia and telecommunication industry. Pilot contamination is considered as a fundamental issue in the system of massive MIMO. The designing of wireless systems has the main concern over the system throughput. Though, the environmental protection and energy-saving have concerned as inevitable trends and global demands. Hence, on considering all these consequences, this paper intends to introduce a new improved sea lion optimization algorithm to select the optimal transmit antennas selection by accounting the multi-objective issue that maximizes both the relative energy efficiency and capacity. In fact, the proposed algorithm is the enhanced version of traditional sea lion optimization algorithm, which optimally tunes the count of transmit antennas and determines which antenna to be selected. Finally, the performance of proposed work is compared and proved over other conventional models regarding capacity analysis, relative efficiency analysis, and optimal antenna selection analysis as well.},
  archive      = {J_EI},
  author       = {Rao, Inumula Veeraraghava and Rao, V. Malleswara},
  doi          = {10.1007/s12065-020-00457-x},
  journal      = {Evolutionary Intelligence},
  month        = {12},
  number       = {4},
  pages        = {1831-1845},
  shortjournal = {Evol. Intell.},
  title        = {Massive MIMO perspective: Improved sea lion for optimal antenna selection},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). GSAPSO-MQC: Medical image encryption based on genetic
simulated annealing particle swarm optimization and modified quantum
chaos system. <em>EI</em>, <em>14</em>(4), 1817–1829. (<a
href="https://doi.org/10.1007/s12065-020-00440-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the large amount of image information data, high redundancy and high pixel correlation, the traditional medical image encryption algorithm is easy to be attacked by chosen plaintext. Therefore, a new medical image encryption algorithm combining genetic simulated annealing particle swarm optimization and modified quantum chaos system is proposed to obtain better security performance. Firstly, an improved quantum chaotic system is used to generate the key stream. Then the selection and cross operation of genetic algorithm are used to process the plaintext image. The optimal sequence generated by simulated annealing algorithm is used to scramble the image. Meanwhile, the particle swarm optimization (PSO) algorithm is introduced into the simulated annealing mechanism. The initial temperature is set according to the optimal fitness value of the initial population. Metropolis is used to optimize the generation of individual optimal position and global optimal position, and the inertial weight parameters of PSO algorithm are optimized to avoid particles falling into local optimal in the optimization process and improve the convergence speed of the algorithm. Through these three operations, the histogram of the scrambled image can be equalized to resist statistical attack. Experimental results and performance analysis show that the encryption system proposed in this paper can resist many typical attacks such as histogram analysis, correlation analysis, differential attack and violent attack, and has high security and encryption efficiency. Compared with other encryption methods, the encryption efficiency of our proposed method has improved by approximately 10%.},
  archive      = {J_EI},
  author       = {Yin, Shoulin and Li, Hang},
  doi          = {10.1007/s12065-020-00440-6},
  journal      = {Evolutionary Intelligence},
  month        = {12},
  number       = {4},
  pages        = {1817-1829},
  shortjournal = {Evol. Intell.},
  title        = {GSAPSO-MQC: Medical image encryption based on genetic simulated annealing particle swarm optimization and modified quantum chaos system},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A hybrid evolutionary approach for identifying spam websites
for search engine marketing. <em>EI</em>, <em>14</em>(4), 1803–1815. (<a
href="https://doi.org/10.1007/s12065-020-00461-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the increased digital usage, web visibility has become critically essential for organizations when catering to a larger audience. This visibility on the web is directly related to web searches on search engines which is often governed by search engine optimization techniques liked link building and link farming amongst others. The current study identifies metrics for segregating websites for the purpose of link building for search engine optimization as it is important to invest resources in the right website sources. These metrics are further used for detecting websites outliers for effective optimization and subsequent search engine marketing. Two case studies of knowledge management portals from different domains are used having 1682 and 1070 websites respectively for validation of the proposed approach. The study evolutionary intelligence by proposing a k-means chaotic firefly algorithm coupled with k-nearest neighbor outlier detection for solving the problem. Factors like Page Rank, Page Authority, Domain Authority, Alexa Rank, Social Shares, Google Index and Domain Age emerge significant in the process. Further, the proposed chaotic firefly variants are compared to K-Means integrated firefly algorithm, bat algorithm and cuckoo search algorithm for accuracy and convergence showing comparable accuracy. Findings indicate that the convergence speeds are higher for proposed chaotic firefly approach for tuning absorption and attractiveness coefficients resulting in faster search for optimal cluster centroids. The proposed approach contributes both theoretically and methodologically in the domain of vendor selection for identifying genuine websites for avoiding investment on untrustworthy websites.},
  archive      = {J_EI},
  author       = {Aswani, Reema and Ghrera, S. P. and Chandra, Satish and Kar, Arpan Kumar},
  doi          = {10.1007/s12065-020-00461-1},
  journal      = {Evolutionary Intelligence},
  month        = {12},
  number       = {4},
  pages        = {1803-1815},
  shortjournal = {Evol. Intell.},
  title        = {A hybrid evolutionary approach for identifying spam websites for search engine marketing},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Dimensionality reduction of hyperspectral image using signal
entropy and spatial information in genetic algorithm with discrete
wavelet transformation. <em>EI</em>, <em>14</em>(4), 1793–1802. (<a
href="https://doi.org/10.1007/s12065-020-00460-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Band selection is being performed in hyperspectral imagery as a dimensionality reduction measure to enhance the efficiency of processing and analysis of the data. In this paper, a genetic algorithm based method is proposed that uses weighted combination of signal entropy and image spatial information in the objective function. The spatial dimension, that also includes huge redundancy, has been reduced using discrete wavelet transformation to make the method more time efficient without compromising the quality of the output. The performance of the method is evaluated by classifying the hyperspectral image with selected bands and measuring the accuracy of the classified output. The proposed method is also compared with other state of the art methods and found to be more efficient in selecting information rich bands in the hyperspectral data.},
  archive      = {J_EI},
  author       = {Paul, Arati and Chaki, Nabendu},
  doi          = {10.1007/s12065-020-00460-2},
  journal      = {Evolutionary Intelligence},
  month        = {12},
  number       = {4},
  pages        = {1793-1802},
  shortjournal = {Evol. Intell.},
  title        = {Dimensionality reduction of hyperspectral image using signal entropy and spatial information in genetic algorithm with discrete wavelet transformation},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Artificial intelligence and game theory controlled
autonomous UAV swarms. <em>EI</em>, <em>14</em>(4), 1775–1792. (<a
href="https://doi.org/10.1007/s12065-020-00456-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autonomous unmanned aerial vehicles (uavs) operating as a swarm can be deployed in austere environments, where cyber electromagnetic activities often require speedy and dynamic adjustments to swarm operations. Use of central controllers, uav synchronization mechanisms or pre-planned set of actions to control a swarm in such deployments would hinder its ability to deliver expected services. We introduce artificial intelligence and game theory based flight control algorithms to be run by each autonomous uav to determine its actions in near real-time, while relying only on local spatial, temporal and electromagnetic (em) information. Each uav using our flight control algorithms positions itself such that the swarm maintains mobile ad-hoc network (manet) connectivity and uniform asset distribution over an area of interest. Typical tasks for swarms using our algorithms include detection, localization and tracking of mobile em transmitters. We present a formal analysis showing that our algorithms can guide a swarm to maintain a connected manet, promote a uniform network spreading, while avoiding overcrowding with other swarm members. We also prove that they maintain manet connectivity and, at the same time, they can lead a swarm of autonomous uavs to follow or avoid an em transmitter. Simulation experiments in opnet modeler verify the results of formal analysis that our algorithms are capable of providing an adequate area coverage over a mobile em source and maintain manet connectivity. These algorithms are good candidates for civilian and military applications that require agile responses to the changes in dynamic environments for tasks such as detection, localization and tracking mobile em transmitters.},
  archive      = {J_EI},
  author       = {Kusyk, Janusz and Uyar, M. Umit and Ma, Kelvin and Samoylov, Eltan and Valdez, Ricardo and Plishka, Joseph and Hoque, Sagor E. and Bertoli, Giorgio and Boksiner, Jeffrey},
  doi          = {10.1007/s12065-020-00456-y},
  journal      = {Evolutionary Intelligence},
  month        = {12},
  number       = {4},
  pages        = {1775-1792},
  shortjournal = {Evol. Intell.},
  title        = {Artificial intelligence and game theory controlled autonomous UAV swarms},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). DNAVS: An algorithm based on DNA-computing and vortex search
algorithm for task scheduling problem. <em>EI</em>, <em>14</em>(4),
1763–1773. (<a
href="https://doi.org/10.1007/s12065-020-00453-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we present DNAVS algorithm for the general job-shop scheduling problem (also known as Flexible JSSP). JSSP is an NP-complete problem, which means there is probably no deterministic or exact algorithm that can find the optimum solution in polynomial time for arbitrary instances of the problem, unless, P = NP. In the DNA computing algorithm, although the hardware is not accessible, in the future, we will have those computers that work based on biological hardware. Their most important advantages over silicon-based computers are their capacity for data storage. DNAVS is an improvement of the DNA computing algorithm by using a metaheuristic search algorithm called vortex search (VS) algorithm. The strongness of DNA computing is its parallelization. In the unavailability of DNA computers, the DNAVS reduces the time complexity of DNA computing by employing the VS algorithm. The efficiency of the DNAVS has been tested with standard test instances of job-shop scheduling problems. Our implementation results show that the DNAVS algorithm works effectively even for large scale instances on currently silicon-based computers.},
  archive      = {J_EI},
  author       = {Jazayeri, Nillofar and Sajedi, Hedieh},
  doi          = {10.1007/s12065-020-00453-1},
  journal      = {Evolutionary Intelligence},
  month        = {12},
  number       = {4},
  pages        = {1763-1773},
  shortjournal = {Evol. Intell.},
  title        = {DNAVS: An algorithm based on DNA-computing and vortex search algorithm for task scheduling problem},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Giza pyramids construction: An ancient-inspired
metaheuristic algorithm for optimization. <em>EI</em>, <em>14</em>(4),
1743–1761. (<a
href="https://doi.org/10.1007/s12065-020-00451-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, many optimization issues around us cannot be solved by precise methods or that cannot be solved in a reasonable time. One way to solve such problems is to use metaheuristic algorithms. Metaheuristic algorithms try to find the best solution out of all possible solutions in the shortest time possible. Speed in convergence, accuracy, and problem-solving ability at high dimensions are characteristics of a good metaheuristic algorithm. This paper presents a new population-based metaheuristic algorithm inspired by a new source of inspiration. This algorithm is called Giza Pyramids Construction (GPC) inspired by the ancient past has the characteristics of a good metaheuristic algorithm to deal with many issues. The ancient-inspired is to observe and reflect on the legacy of the ancient past to understand the optimal methods, technologies, and strategies of that era. The proposed algorithm is controlled by the movements of the workers and pushing the stone blocks on the ramp. This algorithm is compared with five standard and popular metaheuristic algorithms. For this purpose, thirty different and diverse benchmark test functions are utilized. The proposed algorithm is also tested on high-dimensional benchmark test functions and is used as an application in image segmentation. The results show that the proposed algorithm is better than other metaheuristic algorithms and it is successful in solving high-dimensional problems, especially image segmentation.},
  archive      = {J_EI},
  author       = {Harifi, Sasan and Mohammadzadeh, Javad and Khalilian, Madjid and Ebrahimnejad, Sadoullah},
  doi          = {10.1007/s12065-020-00451-3},
  journal      = {Evolutionary Intelligence},
  month        = {12},
  number       = {4},
  pages        = {1743-1761},
  shortjournal = {Evol. Intell.},
  title        = {Giza pyramids construction: An ancient-inspired metaheuristic algorithm for optimization},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Stochastic gradient-CAViaR-based deep belief network for
text categorization. <em>EI</em>, <em>14</em>(4), 1727–1741. (<a
href="https://doi.org/10.1007/s12065-020-00449-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Text categorization is defined as the process of assigning tags to text according to its content. Some of the text classification approaches are document organization, spam email filtering, and news groupings. This paper introduces stochastic gradient-CAViaR-based deep belief networks for text categorization. The overall procedure of the proposed approach involves four steps, such as pre-processing, feature extraction, feature selection, and text categorization. At first, the pre-processing is carried out from the input data based on stemming, stop-word removal, and then, the feature extraction is performed using a vector space model. Once the extraction is done, the feature selection is carried out based on entropy. Subsequently, the selected features are given to the text categorization step. Here, the text categorization is done using the proposed SG-CAV-based deep belief networks (SG-CAV-based DBN). The proposed SG-CAV is used to train the DBN, which is designed by combining conditional autoregressive value at risk and stochastic gradient descent. The performance of the proposed SGCAV + DBN is evaluated based on the metrics, such as recall, precision, F-measure and accuracy. Also, the performance of the proposed method is compared with the existing methods, such as Naive Bayes, K-nearest neighbours, support vector machine, and deep belief network (DBN). From the analysis, it is depicted that the proposed SGCAV + DBN method achieves the maximal precision of 0.78, the maximal recall of 0.78, maximal F-measure of 0.78, and the maximal accuracy of 0.95. Among the existing methods, DBN achieves the maximum precision, recall, F-measure and accuracy, for 20 Newsgroup database and Reuter database. The performance of the proposed system is 10.98%, 11.54%, 11.538%, and 18.33% higher than the precision, recall, F-measure, and accuracy of the DBN for 20 Newsgroup database, and 2.38%, 2.38%, 2.37%, and 0.21% higher than the precision, recall, F-measure and accuracy of the DBN for Reuter database.},
  archive      = {J_EI},
  author       = {Srilakshmi, V. and Anuradha, K. and Shoba Bindu, C.},
  doi          = {10.1007/s12065-020-00449-x},
  journal      = {Evolutionary Intelligence},
  month        = {12},
  number       = {4},
  pages        = {1727-1741},
  shortjournal = {Evol. Intell.},
  title        = {Stochastic gradient-CAViaR-based deep belief network for text categorization},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). DNA motif discovery using chemical reaction optimization.
<em>EI</em>, <em>14</em>(4), 1707–1726. (<a
href="https://doi.org/10.1007/s12065-020-00444-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {DNA motif discovery means to find short similar sequence elements within a set of nucleotide sequences. It has become a compulsory need in bioinformatics for its useful applications such as compression, summarization, and clustering algorithms. Motif discovery is an NP-hard problem and exact algorithms cannot solve it in polynomial time. Many optimization algorithms were proposed to solve this problem. However, none of them can show its supremacy by overcoming all the obstacles. Chemical Reaction Optimization (CRO) is a population based metaheuristic algorithm that can easily fit for the optimization problem. Here, we have proposed an algorithm based on Chemical Reaction Optimization technique to solve the DNA motif discovery problem. The four basic operators of CRO have been redesigned for this problem to search the solution space locally as well as globally. Two additional operators (repair functions) have been proposed to improve the quality of the solutions. They have been applied to the final solution after the iteration stage of CRO to get a better one. Using the flexible mechanism of elementary operators of CRO along with the additional operators (repair functions), it is possible to determine motif more precisely. Our proposed method is compared with other traditional algorithms such as Gibbs sampler, AlignACE (Aligns Nucleic Acid Conserved Elements), MEME (Multiple Expectation Maximization for Motif Elicitation), and ACRI (Ant-Colony-Regulatory-Identification) by testing real-world datasets. The experimental results show that the proposed algorithm can give better results than other traditional algorithms in quality and in less running time. Besides, statistical tests have been performed to show the superiority of the proposed algorithm over other state-of-the-arts in this area.},
  archive      = {J_EI},
  author       = {Saha, Sumit Kumar and Islam, Md. Rafiqul and Hasan, Mredul},
  doi          = {10.1007/s12065-020-00444-2},
  journal      = {Evolutionary Intelligence},
  month        = {12},
  number       = {4},
  pages        = {1707-1726},
  shortjournal = {Evol. Intell.},
  title        = {DNA motif discovery using chemical reaction optimization},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Opposition based competitive grey wolf optimizer for EMG
feature selection. <em>EI</em>, <em>14</em>(4), 1691–1705. (<a
href="https://doi.org/10.1007/s12065-020-00441-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a competitive grey wolf optimizer (CGWO) to solve the feature selection problem in electromyography (EMG) pattern recognition. We model the recently established feature selection method, competitive binary grey wolf optimizer (CBGWO), into a continuous version (CGWO), which enables it to perform the search on continuous search space. Moreover, another new variant of CGWO, namely opposition based competitive grey wolf optimizer (OBCGWO), is proposed to enhance the performance of CGWO in feature selection. The proposed methods show superior results in several benchmark function tests. As for EMG feature selection, the proposed algorithms are evaluated using the EMG data acquired from the publicly access EMG database. Initially, several useful features are extracted from the EMG signals to construct the feature set. The proposed CGWO and OBCGWO are then applied to select the relevant features from the original feature set. Four state-of-the-art algorithms include particle swarm optimization, flower pollination algorithm, butterfly optimization algorithm, and CBGWO are used to examine the effectiveness of proposed methods in feature selection. The experimental results show that OBCGWO can provide optimal classification performance, which is suitable for rehabilitation and clinical applications.},
  archive      = {J_EI},
  author       = {Too, Jingwei and Abdullah, Abdul Rahim},
  doi          = {10.1007/s12065-020-00441-5},
  journal      = {Evolutionary Intelligence},
  month        = {12},
  number       = {4},
  pages        = {1691-1705},
  shortjournal = {Evol. Intell.},
  title        = {Opposition based competitive grey wolf optimizer for EMG feature selection},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The hub location’s method for solving optimal control
problems. <em>EI</em>, <em>14</em>(4), 1671–1690. (<a
href="https://doi.org/10.1007/s12065-020-00437-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the p-hub median’s algorithm is modified to find an approximate solution of bounded continuous-time nonlinear optimal control problems (NOCP). For this purpose, after presenting the similarities between uncapacitated single allocation p-Hub median problem (USApHMP) which is a special case of the well-studied hub location problem and a discretized form of NOCP, an improvement on sequential general variable neighborhood search algorithm (SGVNS) is proposed. This algorithm that denoted as new-sequential general variable neighborhood search (N-SGVNS) is based on three local searches that use efficient neighborhood interchange. In addition, comparing the NOCP with the USApHMP has led us to introduce a suitable method to find an approximate solution for NOCP. Our results of the implementation of the N-SGVNS on the real-world data set for the USApHMP show the high accuracy of the obtained solutions. Because of the proposed algorithm is able to solve the USApHMP successfully, we hoped that this method would also be successful for NOCP. Solving of benchmark NOCP and then comparing the results of the N-SGVNS with recently developed algorithms suggest that the presented strategy may provide an outstanding framework for designing cost-effective control functions.},
  archive      = {J_EI},
  author       = {Salimi, Mitra and Borzabadi, Akbar H. and Mehne, Hamed H. and Heydari, Aghileh},
  doi          = {10.1007/s12065-020-00437-1},
  journal      = {Evolutionary Intelligence},
  month        = {12},
  number       = {4},
  pages        = {1671-1690},
  shortjournal = {Evol. Intell.},
  title        = {The hub location’s method for solving optimal control problems},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Investigating the use of an ensemble of evolutionary
algorithms for letter identification in tremulous medieval handwriting.
<em>EI</em>, <em>14</em>(4), 1657–1669. (<a
href="https://doi.org/10.1007/s12065-020-00427-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ensemble classifiers are known for performing good generalization from simpler and less accurate classifiers. Ensembles have the ability to use the variety in classification patterns of the smaller classifiers in order to make better predictions. However, to create an ensemble it is necessary to determine how the component classifiers should be combined to generate the final predictions. One way to do this is to search different combinations of classifiers with evolutionary algorithms, which are largely employed when the objective is to find a structure that serves for some purpose. In this work, an investigation is carried about the use of ensembles obtained via evolutionary algorithm for identifying individual letters in tremulous medieval writing and to differentiate between scribes. The aim of this research is to use this process as the first step towards classifying the tremor type with more accuracy. The ensembles are obtained through evolutionary search of trees that aggregate the output of base classifiers, which are neural networks trained prior to the ensemble search. The misclassification patterns of the base classifiers are analysed in order to determine how much better an ensemble of those classifiers can be than its components. The best ensembles have their misclassification patterns compared to those of their component classifiers. The results obtained suggest interesting methods for letter (up to 96% accuracy) and user classification (up to 88% accuracy) in an offline scenario.},
  archive      = {J_EI},
  author       = {da Silva, Ronnypetson Souza and Da Costa-Abreu, Márjory and Smith, Stephen},
  doi          = {10.1007/s12065-020-00427-3},
  journal      = {Evolutionary Intelligence},
  month        = {12},
  number       = {4},
  pages        = {1657-1669},
  shortjournal = {Evol. Intell.},
  title        = {Investigating the use of an ensemble of evolutionary algorithms for letter identification in tremulous medieval handwriting},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A new pareto multi-objective sine cosine algorithm for
performance enhancement of radial distribution network by optimal
allocation of distributed generators. <em>EI</em>, <em>14</em>(4),
1635–1656. (<a
href="https://doi.org/10.1007/s12065-020-00428-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The integration of distributed generators (DGs) is considered to be one of the best cost-effective techniques to improve the efficiency of power distribution systems in the recent deregulation caused by continuous load demand and transmission system contingency. In this perspective, a new multi-objective sine cosine algorithm is proposed for optimal DG allocation in radial distribution systems with minimization of total active power loss, maximization of voltage stability index, minimization of annual energy loss costs as well as pollutant gas emissions without violating the system and DG operating constraints. The proposed algorithm is enhanced by incorporating exponential variation of the conversion parameter and the self-adapting levy mutation to increase its performance during different iteration phases. The contradictory relationships among the objectives motivate the authors to generate an optimal Pareto set in order to help the network operators in taking fast appropriate decisions. The proposed approach is successfully applied to 33-bus and 69-bus distribution systems under four practical load conditions and is evaluated in different two-objective and three-objective optimization cases. The effectiveness of the algorithm is confirmed by comparing the results against other well-known multi-objective algorithms, namely, strength Pareto evolutionary algorithm 2, non-dominated sorting genetic algorithm II and multi-objective particle swarm optimization. The quality of Pareto fronts from different multi-objective algorithms is compared in terms of certain performance indicators, such as generational distance, spacing metric and spread metric ( $${\varDelta }$$ ), and its statistical significance is verified by performing Wilcoxon signed rank test.},
  archive      = {J_EI},
  author       = {Raut, Usharani and Mishra, Sivkumar},
  doi          = {10.1007/s12065-020-00428-2},
  journal      = {Evolutionary Intelligence},
  month        = {12},
  number       = {4},
  pages        = {1635-1656},
  shortjournal = {Evol. Intell.},
  title        = {A new pareto multi-objective sine cosine algorithm for performance enhancement of radial distribution network by optimal allocation of distributed generators},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A deep contractive autoencoder for solving multiclass
classification problems. <em>EI</em>, <em>14</em>(4), 1619–1633. (<a
href="https://doi.org/10.1007/s12065-020-00424-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Contractive auto encoder (CAE) is on of the most robust variant of standard Auto Encoder (AE). The major drawback associated with the conventional CAE is its higher reconstruction error during encoding and decoding process of input features to the network. This drawback in the operational procedure of CAE leads to its incapability of going into finer details present in the input features by missing the information worth consideration. Resultantly, the features extracted by CAE lack the true representation of all the input features and the classifier fails in solving classification problems efficiently. In this work, an improved variant of CAE is proposed based on layered architecture following feed forward mechanism named as deep CAE. In the proposed architecture, the normal CAEs are arranged in layers and inside each layer, the process of encoding and decoding take place. The features obtained from the previous CAE are given as inputs to the next CAE. Each CAE in all layers are responsible for reducing the reconstruction error thus resulting in obtaining the informative features. The feature set obtained from the last CAE is given as input to the softmax classifier for classification. The performance and efficiency of the proposed model has been tested on five MNIST variant-datasets. The results have been compared with standard SAE, DAE, RBM, SCAE, ScatNet and PCANet in term of training error, testing error and execution time. The results revealed that the proposed model outperform the aforementioned models.},
  archive      = {J_EI},
  author       = {Aamir, Muhammad and Mohd Nawi, Nazri and Wahid, Fazli and Mahdin, Hairulnizam},
  doi          = {10.1007/s12065-020-00424-6},
  journal      = {Evolutionary Intelligence},
  month        = {12},
  number       = {4},
  pages        = {1619-1633},
  shortjournal = {Evol. Intell.},
  title        = {A deep contractive autoencoder for solving multiclass classification problems},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Chaotic multi verse optimizer based fuzzy logic controller
for frequency control of microgrids. <em>EI</em>, <em>14</em>(4),
1597–1618. (<a
href="https://doi.org/10.1007/s12065-020-00405-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper represents an arrangement of fuzzy PD and derivative filter based PID controller (FPIDF) with its optimally designed membership functions and is employed for the load frequency control (LFC) of isolated multi- microgrids. The performance of a recently developed multi verse optimizer (MVO) algorithm is improved by introducing chaotic map appropriately in the algorithm. The improved algorithm, named as CMVO algorithm is applied to tune the proportional integral derivative (PID) controller gains for the LFC of microgrid. The superiority of the proposed CMVO algorithm is examined by its superior performance compared to MVO PID, recently published IAYA PID, JAYA PID and GA PID in the microgrid system. Further, CMVO based FPIDF with its optimized membership position (FPIDF-OM) outperforms compared to CMVO based FPIDF, IJAYA tuned FPID and FPD/PI-PD controller in microgrid system. Better dynamic performances are found with the proposed technique for stochastic type wind power, solar irradiance and load variations in the microgrid compared with FPIDF and PID. The robustness of the proposed technique is established by the sensitivity analysis. The proposed design approach has been extended to a microgrid model including biogas turbine generator, biodiesel engine generator and aqua electrolyser along with fuel cell unit. Finally, OPAL-RT based hardware-in-the-loop simulation of proposed techniques has been done.},
  archive      = {J_EI},
  author       = {Sahoo, Bibhuti Prasad and Panda, Sidhartha},
  doi          = {10.1007/s12065-020-00405-9},
  journal      = {Evolutionary Intelligence},
  month        = {12},
  number       = {4},
  pages        = {1597-1618},
  shortjournal = {Evol. Intell.},
  title        = {Chaotic multi verse optimizer based fuzzy logic controller for frequency control of microgrids},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Distributed-elite local search based on a genetic algorithm
for bi-objective job-shop scheduling under time-of-use tariffs.
<em>EI</em>, <em>14</em>(4), 1581–1595. (<a
href="https://doi.org/10.1007/s12065-020-00426-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid growth of electricity demand has led governments around the world to implement energy-conscious policies, such as time-of-use tariffs. The manufacturing sector can embrace these policies by implementing an innovative scheduling system to reduce its energy consumption. Therefore, this study addresses bi-objective job-shop scheduling with total weighted tardiness and electricity cost minimization under time-of-use tariffs. The problem can be decomposed into two sub-problems, operation sequencing and start time determination. To solve this problem, we propose a distributed-elite local search based on a genetic algorithm that uses local improvement strategies based on the distribution of elites. Specifically, chromosome encoding uses two lines of gene representation corresponding to the operation sequence and start time. We propose a decoding method to obtain a schedule that incorporates operation sequencing and start time. A perturbation scheme to reduce electricity costs was developed. Finally, a local search framework based on the distribution of elites is used to guide the selection of individuals and the determination of perturbation. Comprehensive numerical experiments using benchmark data from the literature demonstrate that the proposed method is more effective than NSGA-II, MOEA/D, and SPEA2. The results presented in this work may be useful for the manufacturing sector to adopt the time-of-use tariffs policy.},
  archive      = {J_EI},
  author       = {Kurniawan, Bobby and Song, Wen and Weng, Wei and Fujimura, Shigeru},
  doi          = {10.1007/s12065-020-00426-4},
  journal      = {Evolutionary Intelligence},
  month        = {12},
  number       = {4},
  pages        = {1581-1595},
  shortjournal = {Evol. Intell.},
  title        = {Distributed-elite local search based on a genetic algorithm for bi-objective job-shop scheduling under time-of-use tariffs},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Self-adaptive learning for hybrid genetic algorithms.
<em>EI</em>, <em>14</em>(4), 1565–1579. (<a
href="https://doi.org/10.1007/s12065-020-00425-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Local search can be introduced into genetic algorithms to create a hybrid, but any improvement in performance is dependent on the learning mechanism. In the Lamarckian model, a candidate solution is replaced by a fitter neighbour if one is found by local search. In the Baldwinian model, the original solution is retained but with an upgraded fitness if a fitter solution is found in the local search space. The effectiveness of using either model or a variable proportion of the two within a hybrid genetic algorithm is affected by the topology of the fitness function and the details of the hybrid algorithm. This paper investigates an intelligent adaptive approach to decide on the learning mechanism to be used by an individual over the course of the search. Evolution is used to self-adapt both the frequency of a steepest-descent local search and the relative proportions of Lamarckian and Baldwinian inheritance. Experiments have shown that this form of adaptive learning can improve the ability to find high-quality solutions and can accelerate the hybrid search without the need to find optimal control parameters for the learning process.},
  archive      = {J_EI},
  author       = {El-Mihoub, Tarek A. and Hopgood, Adrian A. and Nolle, Lars},
  doi          = {10.1007/s12065-020-00425-5},
  journal      = {Evolutionary Intelligence},
  month        = {12},
  number       = {4},
  pages        = {1565-1579},
  shortjournal = {Evol. Intell.},
  title        = {Self-adaptive learning for hybrid genetic algorithms},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Genetic algorithm-based fuzzy clustering applied to
multivariate time series. <em>EI</em>, <em>14</em>(4), 1547–1563. (<a
href="https://doi.org/10.1007/s12065-020-00422-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite the fact that the fuzzy clustering of time series based on genetic algorithm (GA) is mostly used in applications involving univariate time series, this paper presents an approach based on GA and Fuzzy C-Means (FCM) for clustering multivariate time series. Each chromosome is an individual or solution which encodes the clusters&#39; centroids (patterns) and a bi-criterion constrained clustering is proposed to maximize both the similarity of objects in the same cluster (based on the SPCA metric) and the distance between the centers of the clusters. The proposed method is applied in two case studies involving a real industrial case which comprises pattern recognition for detecting operation failures in a gas turbine and a well-known benchmark industrial system (Tennessee Eastman process) used to evaluate techniques for detecting and diagnosing failures. The proposed approach was able to obtain better classification results compared to FCM based on classical optimization methods.},
  archive      = {J_EI},
  author       = {do Prado Ribeiro, Karine and Fontes, Cristiano Hora and de Melo, Gabriel Jesus Alves},
  doi          = {10.1007/s12065-020-00422-8},
  journal      = {Evolutionary Intelligence},
  month        = {12},
  number       = {4},
  pages        = {1547-1563},
  shortjournal = {Evol. Intell.},
  title        = {Genetic algorithm-based fuzzy clustering applied to multivariate time series},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Enhancing cartesian genetic programming through preferential
selection of larger solutions. <em>EI</em>, <em>14</em>(4), 1539–1546.
(<a href="https://doi.org/10.1007/s12065-020-00421-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We demonstrate how the efficiency of Cartesian genetic programming methods can be enhanced through the preferential selection of phenotypically larger solutions among equally good solutions. The advantage is demonstrated in two qualitatively different problems: the eight-bit parity problems and the “Paige” regression problem. In both cases, the preferential selection of larger solutions provides an advantage in term of the performance and of speed, i.e. number of evaluations required to evolve optimal or high-quality solutions. Performance can be further enhanced by self-adapting the mutation rate through the one-fifth success rule. Finally, we demonstrate that, for problems like the Paige regression in which neutrality plays a smaller role, performance can be further improved by preferentially selecting larger solutions also among candidates with similar fitness.},
  archive      = {J_EI},
  author       = {Milano, Nicola and Nolfi, Stefano},
  doi          = {10.1007/s12065-020-00421-9},
  journal      = {Evolutionary Intelligence},
  month        = {12},
  number       = {4},
  pages        = {1539-1546},
  shortjournal = {Evol. Intell.},
  title        = {Enhancing cartesian genetic programming through preferential selection of larger solutions},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Intelligent environment for advanced brain imaging:
Multi-agent system for an automated alzheimer diagnosis. <em>EI</em>,
<em>14</em>(4), 1523–1538. (<a
href="https://doi.org/10.1007/s12065-020-00420-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Over decades Alzheimer’s disease (AD) researches presented increasing challenges. However, various methods were proposed to detect AD including image processing. This paper presents a concrete solution to diagnose AD based on a multi-agent system (MAS). This approach highlights the importance of the cooperation paradigm within a robust system, in which all agents cooperate to accomplish the segmentation tasks. The exchanges between agents remain an essential part of the segmentation process. The original contribution of this paper is twofold: (1) To present an agent-based segmentation methodology by highlighting the main characteristics, advantages, and disadvantages of MAS. (2) To provide a usable solution by facilitating the detection of AD while taking into account both the expertise and the requirements of specialists in the application domain. Ensuring a cooperative segmentation using the multi-agent system offers a strong point in terms of system stability as well as clarity of the process for physicians. For this, several tests have been carried out to prove the effectiveness of our work. The results ensure that the performance indices in our proposed method were higher.},
  archive      = {J_EI},
  author       = {Allioui, Hanane and Sadgal, Mohamed and Elfazziki, Aziz},
  doi          = {10.1007/s12065-020-00420-w},
  journal      = {Evolutionary Intelligence},
  month        = {12},
  number       = {4},
  pages        = {1523-1538},
  shortjournal = {Evol. Intell.},
  title        = {Intelligent environment for advanced brain imaging: Multi-agent system for an automated alzheimer diagnosis},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Harmony search algorithm for simultaneous minimization of
bi-objectives in multi-row parallel machine layout problem. <em>EI</em>,
<em>14</em>(4), 1495–1522. (<a
href="https://doi.org/10.1007/s12065-020-00419-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The manufacturing cost of products and productivity mainly depends on the arrangements of manufacturing facilities on the shop floor. The process of designing a good layout ensures the relative positions of different types of machines to satisfy the objectives of the manufacturers. Probably, the arrangement of machines in a single row with considering duplicate machines and forward flow of materials under a multi-product environment is providing better solutions to the manufacturers in view of satisfying the objectives. Since the usage of duplicate machines in a single row machine layout, the investment cost on machines is high along with the requirement of a lengthy space. In addition to that, the forward flow of materials is resulting from an increase in the flow distance of products. In view of eliminating these two constraints, the laying of machines in multi-row with forward and backward flow of products is being considered. The proposed work is discussed about the effective way of laying parallel machines in multiple rows to satisfy the minimization of bi-objective namely flow distance of products and area of the layout. A simple heuristic is developed to evaluate the bi-objectives for the given sequence of machines placed on the constrained multiple rows. Further, a harmony search algorithm is utilized to identify the best sequence of machines to be arranged in multi-rows to simultaneously minimize the bi-objectives. The effectiveness of the proposed algorithm is tested on the problems associated with single row machine layout and the problems dealt by Vitayasak and Pongcharoen (Expert Syst Appl 98:129–152, 2018). The results ensured that the proposed algorithm was capable of providing the best solution to the multi-row parallel machine layout problem by significantly minimizing the bi-objectives simultaneously.},
  archive      = {J_EI},
  author       = {Lenin, N. and Siva Kumar, M.},
  doi          = {10.1007/s12065-020-00419-3},
  journal      = {Evolutionary Intelligence},
  month        = {12},
  number       = {4},
  pages        = {1495-1522},
  shortjournal = {Evol. Intell.},
  title        = {Harmony search algorithm for simultaneous minimization of bi-objectives in multi-row parallel machine layout problem},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Enhanced forensic speaker verification performance using the
ICA-EBM algorithm under noisy and reverberant environments. <em>EI</em>,
<em>14</em>(4), 1475–1494. (<a
href="https://doi.org/10.1007/s12065-020-00406-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Forensic speaker verification performance reduces significantly under high levels of noise and reverberation. Multiple channel speech enhancement algorithms, such as independent component analysis by entropy bound minimization (ICA-EBM), can be used to improve noisy forensic speaker verification performance. Although the ICA-EBM was used in previous studies to separate mixed speech signals under clean conditions, the effectiveness of using the ICA-EBM for improving forensic speaker verification performance under noisy and reverberant conditions has not been investigated yet. In this paper, the ICA-EBM algorithm is used to separate the clean speech from noisy speech signals. Features from the enhanced speech are obtained by combining the feature-warped mel frequency cepstral coefficients with similar features extracted from the discrete wavelet transform. The identity vector (i-vector) length normalized Gaussian probabilistic linear discriminant analysis is used as a classifier. The Australian Forensic Voice Comparison and QUT-NOISE corpora were used to evaluate forensic speaker verification performance under noisy and reverberant conditions. Simulation results demonstrate that forensic speaker verification performance based on ICA-EBM improves compared with that of the traditional independent component analysis under different types of noise and reverberation environments. For surveillance recordings corrupted with different types of noise (CAR, STREET and HOME) at − 10 dB signal to noise ratio, the average equal error rate of the proposed method based on ICA-EBM is better than that of the traditional ICA by 12.68% when the interview recordings are kept clean, and 7.25% when the interview recordings have simulated room reverberations.},
  archive      = {J_EI},
  author       = {Al-Ali, Ahmed Kamil Hasan and Chandran, Vinod and Naik, Ganesh R.},
  doi          = {10.1007/s12065-020-00406-8},
  journal      = {Evolutionary Intelligence},
  month        = {12},
  number       = {4},
  pages        = {1475-1494},
  shortjournal = {Evol. Intell.},
  title        = {Enhanced forensic speaker verification performance using the ICA-EBM algorithm under noisy and reverberant environments},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Automated mammogram breast cancer detection using the
optimized combination of convolutional and recurrent neural network.
<em>EI</em>, <em>14</em>(4), 1459–1474. (<a
href="https://doi.org/10.1007/s12065-020-00403-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The objective of this study is to frame mammogram breast detection model using the optimized hybrid classifier. Image pre-processing, tumor segmentation, feature extraction, and detection are the functional phases of the proposed breast cancer detection. A median filter eliminates the noise of the input mammogram. Further, the optimized region growing segmentation is carried out for segmenting the tumor from the image and the optimized region growing depends on a hybrid meta-heuristic algorithm termed as firefly updated chicken based CSO (FC-CSO). To the next of tumor segmentation, feature extraction is done, which intends to extract the features like grey level co-occurrence matrix (GLCM), and gray level run-length matrix (GRLM). The two deep learning architectures termed as convolutional neural network (CNN), and recurrent neural network (RNN). Moreover, both GLCM and GLRM are considered as input to RNN, and the tumor segmented binary image is considered as input to CNN. The result of this study shows that the AND operation of two classifier output will tend to yield the overall diagnostic accuracy, which outperforms the conventional models.},
  archive      = {J_EI},
  author       = {Patil, Rajeshwari S. and Biradar, Nagashettappa},
  doi          = {10.1007/s12065-020-00403-x},
  journal      = {Evolutionary Intelligence},
  month        = {12},
  number       = {4},
  pages        = {1459-1474},
  shortjournal = {Evol. Intell.},
  title        = {Automated mammogram breast cancer detection using the optimized combination of convolutional and recurrent neural network},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). RetrieveNet: A novel deep network for medical image
retrieval. <em>EI</em>, <em>14</em>(4), 1449–1458. (<a
href="https://doi.org/10.1007/s12065-020-00401-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Content-Based Image Retrieval is an accurate characterization of visual information used for medical and natural image classification, retrieval, face recognition, etc. In recent years, deep networks achieved state-of-the-art accuracy in various vision tasks. In this paper, we propose an end-to-end approach for medical image retrieval. The proposed approach comprises a novel deep network for classification of input query image followed by the retrieval module to retrieve the images belongs to the query image class. The proposed network comprises of multi-scale filter bank for robust feature extraction. We make use of skip connections to share the initially learned features across the network. The performance of the proposed network for medical image retrieval is validated in terms of precision and recall on three publicly available medical image databases. We validated the proposed approach for two different image modalities, namely CT scans and MRI scans. Performance evaluation depicts that proposed RetrieveNet outperforms other existing methods for medical image retrieval.},
  archive      = {J_EI},
  author       = {Hussain, Chesti Altaff and Rao, Dhulipalla Venkata and Mastani, S. Aruna},
  doi          = {10.1007/s12065-020-00401-z},
  journal      = {Evolutionary Intelligence},
  month        = {12},
  number       = {4},
  pages        = {1449-1458},
  shortjournal = {Evol. Intell.},
  title        = {RetrieveNet: A novel deep network for medical image retrieval},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Optimal feature selection-based diabetic retinopathy
detection using improved rider optimization algorithm enabled with deep
learning. <em>EI</em>, <em>14</em>(4), 1431–1448. (<a
href="https://doi.org/10.1007/s12065-020-00400-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This proposal tempts to develop automated DR detection by analyzing the retinal abnormalities like hard exudates, haemorrhages, Microaneurysm, and soft exudates. The main processing phases of the developed DR detection model is Pre-processing, Optic Disk removal, Blood vessel removal, Segmentation of abnormalities, Feature extraction, Optimal feature selection, and Classification. At first, the pre-processing of the input retinal image is done by Contrast Limited Adaptive Histogram Equalization. The next phase performs the optic disc removal, which is carried out by open-close watershed transformation. Further, the Grey Level thresholding is done for segmenting the blood vessels and its removal. Once the optic disk and blood vessels are removed, segmentation of abnormalities is done by Top hat transformation and Gabor filtering. Further, the feature extraction phase is started, which tends to extract four sets of features like Local Binary Pattern, Texture Energy Measurement, Shanon’s and Kapur’s entropy. Since the length of the feature vector seems to be long, the feature selection process is done, which selects the unique features with less correlation. Moreover, the Deep Belief Network (DBN)-based classification algorithm performs the categorization of images into four classes normal, earlier, moderate, or severe stages. The optimal feature selection is done by the improved meta-heuristic algorithm called Modified Gear and Steering-based Rider Optimization Algorithm (MGS-ROA), and the same algorithm updates the weight in DBN. Finally, the effectual performance and comparative analysis prove the stable and reliable performance of the proposed model over existing models. The performance of the proposed model is compared with the existing classifiers, such as, NN, KNN, SVM, DBN and the conventional Heuristic-Based DBNs, such as PSO-DBN, GWO-DBN, WOA-DBN, and ROA-DBN for the evaluation metrics, accuracy, sensitivity, specificity, precision, FPR, FNR, NPV, FDR, F1 score, and MC. From the results, it is exposed that the accuracy of the proposed MGS-ROA-DBN is 30.1% higher than NN, 32.2% higher than KNN, and 17.1% higher than SVM and DBN. Similarly, the accuracy of the developed MGS-ROA-DBN is 13.8% superior to PSO, 5.1% superior to GWO, 10.8% superior to WOA, and 2.5% superior to ROA.},
  archive      = {J_EI},
  author       = {Jadhav, Ambaji S. and Patil, Pushpa B. and Biradar, Sunil},
  doi          = {10.1007/s12065-020-00400-0},
  journal      = {Evolutionary Intelligence},
  month        = {12},
  number       = {4},
  pages        = {1431-1448},
  shortjournal = {Evol. Intell.},
  title        = {Optimal feature selection-based diabetic retinopathy detection using improved rider optimization algorithm enabled with deep learning},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Neuromodulated multiobjective evolutionary neurocontrollers
without speciation. <em>EI</em>, <em>14</em>(4), 1415–1430. (<a
href="https://doi.org/10.1007/s12065-020-00394-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neuromodulation is a biologically-inspired technique that can adapt the per-connection learning rates of synaptic plasticity. Neuromodulation has been used to facilitate unsupervised learning by adapting neural network weights. Multiobjective evolution of neural network topology and weights has been used to design neurocontrollers for autonomous robots. This paper presents a novel multiobjective evolutionary neurocontroller with unsupervised learning for robot navigation. Multiobjective evolution of network weights and topologies (NEAT-MODS) is augmented with neuromodulated learning. NEAT-MODS is an NSGA-II based multiobjective neurocontroller that uses two conflicting objectives. The first rewards the robot when it moves in a direct manner with minimal turning; the second objective is to reach as many targets as possible. NEAT-MODS uses speciation, a selection process that aims to ensure Pareto-optimal genotypic diversity and elitism. The effectiveness of the design is demonstrated using a series of experiments with a simulated robot traversing a simple maze containing target goals. It is shown that when neuromodulated learning is combined with multiobjective evolution, better-performing neural controllers are synthesized than by evolution alone. Secondly, it is demonstrated that speciation is unnecessary in neuromodulated neuroevolution, as neuromodulation preserves topological innovation. The proposed neuromodulated approach is found to be statistically superior to NEAT-MODS alone when applied to solve a multiobjective navigation problem.},
  archive      = {J_EI},
  author       = {Showalter, Ian and Schwartz, Howard M.},
  doi          = {10.1007/s12065-020-00394-9},
  journal      = {Evolutionary Intelligence},
  month        = {12},
  number       = {4},
  pages        = {1415-1430},
  shortjournal = {Evol. Intell.},
  title        = {Neuromodulated multiobjective evolutionary neurocontrollers without speciation},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A review of genetic-based evolutionary algorithms in SVM
parameters optimization. <em>EI</em>, <em>14</em>(4), 1389–1414. (<a
href="https://doi.org/10.1007/s12065-020-00439-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Parameters optimization is a research hotspot of SVM and has gained increasing interest from various research fields. Compared with other optimization algorithms, genetic-based evolutionary algorithms that have achieved optimization according to the laws of separation and free combination in genetics are gradually attracted much attention. Also, due to the characteristics of self-organization and self-adaptation, these algorithms often enable SVM to obtain appropriate parameters, so that the model can be applied to more applications. Additionally, many improvements have been proposed in the past two decades in order to allow the optimized SVM model to obtain better performance. This work focuses on reviewing the current state of genetic-based evolutionary algorithms used to optimize parameters of SVM and its variants. First, we introduce the principles of SVM and provide a survey on optimization methods of its parameters. Then we propose a taxonomy of improving genetic-based evolutionary algorithms according to code mechanism, parameters control, population structure, evolutionary strategy, operation mechanism, operators, and many other hybrid approaches. Furthermore, this paper analyzes and compares the advantages and disadvantages of the above algorithms explicitly, and provides their applicable scenarios as well. Finally, we highlight the existing problems of genetic-based evolutionary algorithms used for parameters optimization of SVM and prospect development trends of this field in the future.},
  archive      = {J_EI},
  author       = {Ji, Weizhen and Liu, Deer and Meng, Yifei and Xue, Yun},
  doi          = {10.1007/s12065-020-00439-z},
  journal      = {Evolutionary Intelligence},
  month        = {12},
  number       = {4},
  pages        = {1389-1414},
  shortjournal = {Evol. Intell.},
  title        = {A review of genetic-based evolutionary algorithms in SVM parameters optimization},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Just noticeable difference color space consistency spectral
clustering based on firefly algorithm for image segmentation.
<em>EI</em>, <em>14</em>(4), 1379–1388. (<a
href="https://doi.org/10.1007/s12065-020-00396-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When applied into image segmentation, the traditional spectral clustering algorithm may suffer from parameters influence, inconvenient storage, and high computational complexity. In order to solve these problems, a just noticeable difference color space consistency spectral clustering method based on firefly algorithm is proposed to segment color images. Firstly, some representative color pixels are obtained by using just noticeable difference thresholding measure. Then, a similarity measure with the properties of color space connectivity and discreteness measure is proposed to construct the similarity between any two representative pixels. Finally, using the proposed similarity measure, representative color pixels are grouped according to the graph partition criterion. In order to overcome the influence of threshold parameter in just noticeable difference measure, the supervised information and firefly algorithm are introduced in the proposed method. According to the result of representative pixels, all pixels in the image are partitioned into different groups and the final segmentation result is obtained. Experimental results on Berkeley segmentation images show that this method has better segmentation performance and is superior to the existing clustering methods.},
  archive      = {J_EI},
  author       = {Liu, Hanqiang and Sun, Yuan and Sun, Ning and Zhao, Feng},
  doi          = {10.1007/s12065-020-00396-7},
  journal      = {Evolutionary Intelligence},
  month        = {12},
  number       = {4},
  pages        = {1379-1388},
  shortjournal = {Evol. Intell.},
  title        = {Just noticeable difference color space consistency spectral clustering based on firefly algorithm for image segmentation},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An efficient nuclei segmentation method based on roulette
wheel whale optimization and fuzzy clustering. <em>EI</em>,
<em>14</em>(3), 1367–1378. (<a
href="https://doi.org/10.1007/s12065-019-00288-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image segmentation is a technique in which an image is partitioned into different categories or regions that correspond to objects or parts of objects. The performance of segmentation methods is generally reduced for the hematoxylin and eosin stained histopathological images due to complex background and varying intensity values. Therefore, in this paper, the roulette wheel selection whale optimization based fuzzy clustering method is introduced for the nuclei segmentation of histopathological images. The proposed clustering method finds the optimal clusters using the objective function that reduces the sum of squared error or compactness. The performance of the proposed clustering method has been examined on the histopathological image dataset of Triple-Negative Breast Cancer patients and compared with k-means and fuzzy c-means in respect of F1 score and aggregated Jaccard index. The proposed method attains 0.6701 mean F1 scores and 0.7387 mean aggregated Jaccard index value, which are the best values among other methods. The experimental outcomes validate the efficiency of the introduced method over the other clustering-based segmentation methods.},
  archive      = {J_EI},
  author       = {Vishnoi, Susheela and Jain, Ajit Kumar and Sharma, Pradeep Kumar},
  doi          = {10.1007/s12065-019-00288-5},
  journal      = {Evolutionary Intelligence},
  month        = {9},
  number       = {3},
  pages        = {1367-1378},
  shortjournal = {Evol. Intell.},
  title        = {An efficient nuclei segmentation method based on roulette wheel whale optimization and fuzzy clustering},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Lunar cycle inspired PSO for single machine total weighted
tardiness scheduling problem. <em>EI</em>, <em>14</em>(3), 1355–1366.
(<a href="https://doi.org/10.1007/s12065-020-00556-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the large scale Single machine total weighted tardiness scheduling problem (SMTWTSP) is a group of not-interrelated tasks having different parameters to be executed on one machine. The problem’s objective is to identify the minimum total weighted tardiness using a newly developed variant of the particle swarm optimization (PSO) algorithm. In the past, the PSO algorithm has proved itself as an efficient swarm intelligence based strategy to solve complex combinatorial problems. Here, in this article, the lunar cycle inspired local search technique is assimilated into PSO, and the designed PSO variant is termed as lunar cycle inspired PSO (LCPSO). The performance of the designed LCPSO is tested over 25 large SMTWTSP instances of job size 1000. The reported results show that the designed LCPSO is a competitive PSO variant that can be applied to provide an effective solution for the SMTWTSP type combinatorial optimization problem.},
  archive      = {J_EI},
  author       = {Gupta, Shruti and Kumari, Rajani and Singh, Rishi Pal},
  doi          = {10.1007/s12065-020-00556-9},
  journal      = {Evolutionary Intelligence},
  month        = {9},
  number       = {3},
  pages        = {1355-1366},
  shortjournal = {Evol. Intell.},
  title        = {Lunar cycle inspired PSO for single machine total weighted tardiness scheduling problem},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Limaçon inspired artificial bee colony algorithm for
numerical optimization. <em>EI</em>, <em>14</em>(3), 1345–1353. (<a
href="https://doi.org/10.1007/s12065-020-00430-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The artificial bee colony algorithm (ABCA) has established itself as a signature algorithm in the area of swarm intelligence based algorithms. The hybridization of the local search technique enhances the exploitation capability in the search process of the global optimization strategies. In this article, an effective local search technique that is designed by taking inspiration by Limaçon curve, is incorporated in ABCA and the designed strategy is named Limaçon inspired ABC (LABC) algorithm. The exploitation capability of the LABC strategy is tested over 18 complex benchmark optimization problems. The test results are compared with similar state-of-art algorithms and statistical analysis shows the LABC can be considered an effective variant of the ABC algorithms to solve the complex optimization problems.},
  archive      = {J_EI},
  author       = {Sharma, Kavita and Gupta, P. C. and Sharma, Nirmala},
  doi          = {10.1007/s12065-020-00430-8},
  journal      = {Evolutionary Intelligence},
  month        = {9},
  number       = {3},
  pages        = {1345-1353},
  shortjournal = {Evol. Intell.},
  title        = {Limaçon inspired artificial bee colony algorithm for numerical optimization},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Improved convolutional neural network based
histopathological image classification. <em>EI</em>, <em>14</em>(3),
1337–1343. (<a
href="https://doi.org/10.1007/s12065-020-00367-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Histopathological image classification is one of the important application areas of medical imaging. However, an accurate and efficient classification is still an open-ended research due to the complexity in histopathological images. For the same, this paper presents an efficient architecture of convolutional neural network for the classification of histopathological images. The proposed method consists of five subsequent blocks of layers, each having convolutional, drop-out, and max-pooling layers. The performance of the introduced classification system is validated on colorectal cancer histology image dataset which consists of RGB-colored images belonging to eight different classes. The experimental results confirm the higher performance of the proposed convolutional neural network against existing different machine learning models with the lowest error rate of 22.7%.},
  archive      = {J_EI},
  author       = {Rachapudi, Venubabu and Lavanya Devi, G.},
  doi          = {10.1007/s12065-020-00367-y},
  journal      = {Evolutionary Intelligence},
  month        = {9},
  number       = {3},
  pages        = {1337-1343},
  shortjournal = {Evol. Intell.},
  title        = {Improved convolutional neural network based histopathological image classification},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Random offset minimization in low frequency front-end
amplifiers using swarm intelligence based techniques. <em>EI</em>,
<em>14</em>(3), 1317–1335. (<a
href="https://doi.org/10.1007/s12065-020-00495-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Random offset in amplifiers arises mainly due to random variations i.e. inherent mismatch in transistor parameters and greatly impacts its overall design specifications, especially in case of low frequency application. It must be minimized for high precision in the amplifier’s performance. A new approach for minimization of random offset voltage in amplifiers has been proposed through the use of swarm intelligence based optimization algorithms due to their derivative free nature and easy search mechanism. The approach involves firstly, modelling the random offset voltage due to mismatch between transistors parameters based on Pelgrom’s model and then minimizing the formulated model subjected to design constraints using swarm intelligence based algorithms. Two case studies are considered, firstly, a high swing Folded Cascode Operational Transconductance Amplifier (OTA) and secondly, a Recycling Folded Cascode (RFC) OTA. Comparative analysis have been performed by recording best, worst and mean data for 2500 function evaluations and also using statistical analysis such as Friedmann’s test and Mann–Whitney’s U test. The results indicate that the Hybrid Whale Particle Swarm Optimization (HWPSO) algorithm outperforms the other state of the art algorithms by giving a minimum random offset voltage of 7.2 mV and 1.452 mV with a mean rank of 1.55 and 1.75 for the 1st and 2nd case studies respectively. Validation of HWPSO results have been done by performing simulations and Monte Carlo Analysis for the two amplifiers in Cadence Virtuoso, which are found to be in close agreement with the algorithmic results.},
  archive      = {J_EI},
  author       = {Laskar, Naushad Manzoor and Guha, Koushik and Paul, P. K. and Baishnab, K. L.},
  doi          = {10.1007/s12065-020-00495-5},
  journal      = {Evolutionary Intelligence},
  month        = {9},
  number       = {3},
  pages        = {1317-1335},
  shortjournal = {Evol. Intell.},
  title        = {Random offset minimization in low frequency front-end amplifiers using swarm intelligence based techniques},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Twitter sentiment analysis using hybrid spider monkey
optimization method. <em>EI</em>, <em>14</em>(3), 1307–1316. (<a
href="https://doi.org/10.1007/s12065-019-00334-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The use of social media, over the past few years, has escalated enormously. Social media has formed a platform for the availability of abundant data. Thousands of people express their perceptions through social media. Sentiment Analysis (SA) of such views and perceptions is very substantial to measure public notion on a peculiar/specific subject matter of concern. SA is a remarkable field of data mining concerned with identification and translation of sentiments accessible on social media. Twitter is a microblogging site in which users can post updates (tweets) to friends (followers). This paper proposes a mechanism for extracting the sentiments from the tweets posted on Twitter. Tweets can be classified as positive, neutral or negative. The metaheuristic-based clustering techniques are superior to conventional techniques due to the subjective behaviour of tweets. A hybrid strategy, named as Hybrid Spider Monkey optimization with k-means clustering, is introduced to obtain the optimal cluster-heads of the dataset. The accuracy of the proposed method is determined on two datasets, namely, sender2 and twitter. To analyse the authenticity of the proposed method, a comparative analysis is performed with a few significant Nature-Inspired Algorithms such as Spider-Monkey optimization, Particle-Swarm algorithm, Genetic-Algorithm and Differential Evolution.},
  archive      = {J_EI},
  author       = {Shekhawat, Sayar Singh and Shringi, Sakshi and Sharma, Harish},
  doi          = {10.1007/s12065-019-00334-2},
  journal      = {Evolutionary Intelligence},
  month        = {9},
  number       = {3},
  pages        = {1307-1316},
  shortjournal = {Evol. Intell.},
  title        = {Twitter sentiment analysis using hybrid spider monkey optimization method},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An image segmentation method using logarithmic kbest
gravitational search algorithm based superpixel clustering. <em>EI</em>,
<em>14</em>(3), 1293–1305. (<a
href="https://doi.org/10.1007/s12065-018-0192-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image segmentation partitions an image into coherent and non-overlapping regions. Due to variations of visual patterns in images, it is a challenging problem. This paper introduces a new superpixel-based clustering method to efficiently perform the image segmentation. In the proposed method, initially superpixels from an image are obtained. The superpixels are further clustered into the required number of regions by a newly proposed variant of gravitational search algorithm namely; logarithmic kbest gravitational search algorithm. Experiments are conducted on the Berkeley Segmentation Dataset and Benchmark (BSDS500). It is affirmed from both visual and numerical analyses that the proposed method is efficacious and accurate in segmenting an image than the other considered segmentation methods.},
  archive      = {J_EI},
  author       = {Mittal, Himanshu and Saraswat, Mukesh},
  doi          = {10.1007/s12065-018-0192-y},
  journal      = {Evolutionary Intelligence},
  month        = {9},
  number       = {3},
  pages        = {1293-1305},
  shortjournal = {Evol. Intell.},
  title        = {An image segmentation method using logarithmic kbest gravitational search algorithm based superpixel clustering},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An optimal feature selection method for histopathology
tissue image classification using adaptive jaya algorithm. <em>EI</em>,
<em>14</em>(3), 1279–1292. (<a
href="https://doi.org/10.1007/s12065-019-00205-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the complex background and heterogeneous structure, classification of histopathological tissue images is a challenging problem. Further, the selection of appropriate features is an important phase of classification process as irrelevant and redundant features may result in high computation and degrade the performance. Therefore, a new adaptive jaya algorithm has been introduced in this paper which is used to obtain the prominent feature set from the extracted features. The proposed adaptive jaya algorithm modifies the updation equation using the best and the worst solutions. For the feature extraction, a pre-trained AlexNet has been used due to its distinguishing performance in the image classification. Moreover, the performance of five different classifiers have been analyzed over the selected features in context of classifying the histopathological tissue images into four categories, namely epithelium tissue, nervous tissue, connective tissue, and muscular tissue. Experimental results validate that the proposed adaptive jaya algorithm attains better optimal values on CEC2015 functions. The proposed method eliminates 91.3% features from the extracted features which is maximum among other considered methods and also achieves high classification accuracy.},
  archive      = {J_EI},
  author       = {Tiwari, Varun and Jain, S. C.},
  doi          = {10.1007/s12065-019-00205-w},
  journal      = {Evolutionary Intelligence},
  month        = {9},
  number       = {3},
  pages        = {1279-1292},
  shortjournal = {Evol. Intell.},
  title        = {An optimal feature selection method for histopathology tissue image classification using adaptive jaya algorithm},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Improved gbest artificial bee colony algorithm for the
constraints optimization problems. <em>EI</em>, <em>14</em>(3),
1271–1277. (<a
href="https://doi.org/10.1007/s12065-019-00231-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Living beings in nature are most intelligent creation of nature as they evolve with time and try to find optimum solution for each problem individually or collectively. Artificial bee colony algorithm is nature inspired algorithm that mimic the swarming behaviour of honey bee and successfully solved various optimization problems. Solution quality in artificial bee colony depends on the step size during position update. Randomly decided step size always has high possibility of miss out the exact solution. Its popular variant, namely Gbest-guided artificial bee colony algorithm tried to balance it and accomplished effectively for unconstrained optimization problems but, not satisfactory for the constrained optimization problems. Further, in the Gbest-guided artificial bee colony, individuals, which are going to update their positions, attract towards the current best solution in the swarm, which sometimes leads to premature convergence. To avoid such situation as well as to enhance the efficiency of Gbest-guided artificial bee colony to solve the unconstrained continuous optimization problems, an improved variant is proposed here. The improved Gbest-guided artificial bee colony proposed modifications in the position update during both the phase i.e. employed and onlooker bee phase to introduce diversification in search space additionally intensification of the identified region. The performance of new algorithm is evaluated for 21 benchmark optimization problems. Based on statistical analyses, it is shown that the new variant is a viable alternate of Gbest-guided artificial bee colony for the constraint optimization problems.},
  archive      = {J_EI},
  author       = {Sharma, Sonal and Kumar, Sandeep and Sharma, Kavita},
  doi          = {10.1007/s12065-019-00231-8},
  journal      = {Evolutionary Intelligence},
  month        = {9},
  number       = {3},
  pages        = {1271-1277},
  shortjournal = {Evol. Intell.},
  title        = {Improved gbest artificial bee colony algorithm for the constraints optimization problems},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Voltage stability constrained transmission network expansion
planning using fast convergent grey wolf optimization algorithm.
<em>EI</em>, <em>14</em>(3), 1261–1270. (<a
href="https://doi.org/10.1007/s12065-019-00200-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Transmission network expansion planning problem (TNEP) is of utmost importance in power system now a days. In this paper, a voltage stability indicator (L-index) is applied to limit the voltage of buses. Hence TNEP is formulated incorporating this voltage stability feature. Thus formulated TNEP is termed as voltage stability constrained TNEP (VSC-TNEP). TNEP has been solved using various conventional and non-conventional strategies by various researchers in these days. Here, TNEP and VSC-TNEP for IEEE-24 bus test system is solved using grey wolf optimization technique (GWO) and modified GWO. The modified GWO algorithm namely, fast convergent GWO (FCGWO) is validated over 25 standard benchmark test functions and compared with other techniques.},
  archive      = {J_EI},
  author       = {Khandelwal, Ashish and Bhargava, Annapurna and Sharma, Ajay},
  doi          = {10.1007/s12065-019-00200-1},
  journal      = {Evolutionary Intelligence},
  month        = {9},
  number       = {3},
  pages        = {1261-1270},
  shortjournal = {Evol. Intell.},
  title        = {Voltage stability constrained transmission network expansion planning using fast convergent grey wolf optimization algorithm},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-objective three level parallel PSO algorithm for
structural alignment of complex RNA sequences. <em>EI</em>,
<em>14</em>(3), 1251–1259. (<a
href="https://doi.org/10.1007/s12065-018-00198-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a caching enabled parallel multi-objective tri-level particle swarm optimization algorithm (MO-3LPPSO) with objective to address a challenging NP-hard problem from bioinformatics i.e. structural alignment of complex RNA sequences. MO-3LPPSO implements master-slave topology based communication strategy on the parallely connected machines via message passing interface (MPI). Level 1 of the proposed algorithm acquires the optimal alignment of the sequences distributed on slave processors in the order of their complexities. Further, the aligned sequences along with their alignment scores are stored on the master processor. In the second level, the secondary structures of all the gbest aligned sequences of level 1 is obtained. Each sequence set is distributed on a slave processors, that constructs secondary structure of all sequences from the set. The alignment scores and secondary structure scores obtained from level 1 and level 2, now move towards level 3, forming a bi-objective optimization problem with the objectives to maximize sequence similarity score and minimize free energy score for most stable RNA secondary structure. The top-level non-dominated solutions are extracted further in level three and the external archive in Ctrie is updated. The improvement from MO-TLPSO to MO-3LPPSO has been remarkable in the sense: inclusion of Ctrie enables the algorithm to work with multi-client environment for handling RNA structural alignment queries; implementation of parallelization facilitates structural alignment of highly complex massive datasets of RNA sequences. Further, the difference between the time taken by MO-TLPSO and MO-3LPPSO is found extremely significant, as confirmed by non-parametric statistical test Mann-Whitney U test. Further, the structural alignment of highly complex sequence sets is performed by MO-3LPPSO, which is tested for prediction accuracy and processing time. The algorithm is found producing highly accurate results at significantly lesser processing time.},
  archive      = {J_EI},
  author       = {Lalwani, Soniya and Sharma, Harish},
  doi          = {10.1007/s12065-018-00198-y},
  journal      = {Evolutionary Intelligence},
  month        = {9},
  number       = {3},
  pages        = {1251-1259},
  shortjournal = {Evol. Intell.},
  title        = {Multi-objective three level parallel PSO algorithm for structural alignment of complex RNA sequences},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Numerical optimization and feed-forward neural networks
training using an improved optimization algorithm: Multiple leader salp
swarm algorithm. <em>EI</em>, <em>14</em>(3), 1233–1249. (<a
href="https://doi.org/10.1007/s12065-019-00269-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Metaheuristics are one of the most promising techniques for solving optimization problems. Salp swarm algorithm (SSA) is a new swarm intelligence based metaheuristic. To improve the performance of SSA, this paper introduces multiple leader salp swarm algorithm (MLSSA), which has more exploratory power than SSA. The algorithm is tested on several mathematical optimization benchmark functions. Results are compared with some well known metaheuristics. The results represents the capability of MLSSA to converge towards the optimum. In recent studies many metaheuristic techniques are applied to train feed-forward neural networks. In this paper MLSSA is also applied for neural network training and is analysed for thirteen different datasets. Performance is compared with SSA, particle swarm optimization, differential evolution, genetic algorithm, ant colony optimization and evolution strategy.},
  archive      = {J_EI},
  author       = {Bairathi, Divya and Gopalani, Dinesh},
  doi          = {10.1007/s12065-019-00269-8},
  journal      = {Evolutionary Intelligence},
  month        = {9},
  number       = {3},
  pages        = {1233-1249},
  shortjournal = {Evol. Intell.},
  title        = {Numerical optimization and feed-forward neural networks training using an improved optimization algorithm: Multiple leader salp swarm algorithm},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An efficient hybrid PSO polygamous crossover based
clustering algorithm. <em>EI</em>, <em>14</em>(3), 1213–1231. (<a
href="https://doi.org/10.1007/s12065-019-00235-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Clustering of data into cohesive groups is an open area of research with lots of applications in different domains. Many traditional and metaheuristic algorithms have been proposed in the literature, but the main inherent problem with most of these algorithms is that they can easily get trapped in local optima and can lead to premature convergence. Thus a significant balance is required between exploration and exploitation to find a near optimal solution. This paper attempts to resolve this problem by proposing a real encoded hybrid algorithm (PSOPC) using PSO for global search and polygamous approach for crossover in order to refine the exploration and exploitation strategy. Parameters like inertia weight, crossover probability and alpha values in arithmetic crossover are also tuned dynamically to refine the optimization process. The Proposed hybrid algorithm is simulated on seven real life data sets. It has also been compared with other four standard well known metaheuristic clustering algorithms i.e. Particle Swarm Optimization, Genetic Algorithm, Differential Evolution, Firefly Algorithm and Grey Wolf Optimization. The computational results demonstrate that the PSOPC outperforms other approaches in context of within cluster distance, cluster quality measures and convergence speed to find the near optimal solutions. Simulation results clearly reveal that the proposed algorithm PSOPC is able to generate compact clusters. Various external quality evaluation measurements (like Precision, Sensitivity, Accuracy and G-measure) used for quality evaluation demonstrated that the proposed algorithm is able to perform better clustering than the other compared algorithms.},
  archive      = {J_EI},
  author       = {Sharma, Manju and Chhabra, Jitender Kumar},
  doi          = {10.1007/s12065-019-00235-4},
  journal      = {Evolutionary Intelligence},
  month        = {9},
  number       = {3},
  pages        = {1213-1231},
  shortjournal = {Evol. Intell.},
  title        = {An efficient hybrid PSO polygamous crossover based clustering algorithm},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Automated face retrieval using bag-of-features and sigmoidal
grey wolf optimization. <em>EI</em>, <em>14</em>(3), 1201–1212. (<a
href="https://doi.org/10.1007/s12065-019-00213-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A content based image retrieval system is one of the prime research fields due to the exponential increasing of multimedia data over Internet especially images. Although, a number of content based image retrieval methods have been introduced, it is still a challenging task specially for face recognition. Therefore, this work presents an automated face retrieval system using an enhanced bag-of-features framework. The bag-of-features framework has been modified by incorporating a new sigmoidal grey wolf optimization algorithm. The sigmoidal grey wolf optimization algorithm uses a sigmoid decreasing function to escape it from local optima. The efficiency of the proposed sigmoidal grey wolf optimization algorithm has been analyzed over various standard benchmark functions for average fitness values and convergence behavior. Furthermore, it has successfully been used to generate the codewords in bag-of-features framework. The modified bag-of-features has been utilized in content based image retrieval for Oracle Research Laboratory (ORL) face database. The simulation results represent that the proposed method effectively retrieves the faces as compared to other nature-inspired based methods.},
  archive      = {J_EI},
  author       = {Shukla, Arun Kumar and Kanungo, Suvendu},
  doi          = {10.1007/s12065-019-00213-w},
  journal      = {Evolutionary Intelligence},
  month        = {9},
  number       = {3},
  pages        = {1201-1212},
  shortjournal = {Evol. Intell.},
  title        = {Automated face retrieval using bag-of-features and sigmoidal grey wolf optimization},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). FPA clust: Evaluation of the flower pollination algorithm
for data clustering. <em>EI</em>, <em>14</em>(3), 1189–1199. (<a
href="https://doi.org/10.1007/s12065-019-00254-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, a standalone approach based on the flower pollination algorithm (FPA) is proposed for solving data clustering problems. The FPA is a nature-inspired algorithm simulating the behavior of flower pollination. The proposed approach is used to extract key information in terms of optimal cluster centers that are derived from training samples of the selected databases. These extracted cluster centers are then validated on test samples. Three datasets from the UCI machine learning data repository and an additional multi-spectral, real-time satellite image are chosen to illustrate the effectiveness and diversity of the proposed technique. The FPA performance is compared with the k-means, a popular clustering algorithm and metaheuristic algorithms, namely, the Genetic Algorithm, Particle Swarm Optimization, Cuckoo Search, Spider Monkey Optimization, Grey Wolf Optimization, Differential Evolution, Harmony Search and Bat Algorithm. The results are evaluated based on classification error percentage (CEP), time complexity and statistical significance. FPA has the lowest CEP for all four datasets and an average CEP of 28%, which is 5.5% lower than next best algorithm in that sense. The FPA is the second quickest algorithm to converge after HS algorithm. FPA also shows a higher level of statistical significance. Therefore, the obtained results show that the FPA efficiently clusters the data and performs better than the state-of-the-art methods.},
  archive      = {J_EI},
  author       = {Senthilnath, J. and Kulkarni, Sushant and Suresh, S. and Yang, X. S. and Benediktsson, J. A.},
  doi          = {10.1007/s12065-019-00254-1},
  journal      = {Evolutionary Intelligence},
  month        = {9},
  number       = {3},
  pages        = {1189-1199},
  shortjournal = {Evol. Intell.},
  title        = {FPA clust: Evaluation of the flower pollination algorithm for data clustering},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Special issue on swarm intelligence and its applications to
engineering. Journal: Evolutionary intelligence. <em>EI</em>,
<em>14</em>(3), 1187–1188. (<a
href="https://doi.org/10.1007/s12065-021-00646-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_EI},
  author       = {Bansal, Jagdish Chand and Deep, Kusum and Nagar, Atulya K.},
  doi          = {10.1007/s12065-021-00646-2},
  journal      = {Evolutionary Intelligence},
  month        = {9},
  number       = {3},
  pages        = {1187-1188},
  shortjournal = {Evol. Intell.},
  title        = {Special issue on swarm intelligence and its applications to engineering. journal: Evolutionary intelligence},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Non-dominated sorting genetic algorithm (NSGA-III) for
effective resource allocation in cloud. <em>EI</em>, <em>14</em>(2),
759–765. (<a href="https://doi.org/10.1007/s12065-020-00436-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Resource management system helps the enterprises to coordinate the IT resources in connection to the action performed by the key players such as cloud customers and service providers. Present day cloud resource and service providers use a heterogeneous allocation strategy for resources allocation across various geographical locations. Further, these allocations are completely in need of secure transactions, effective scheduling and dynamic resource allocation strategies. To overcome the above mentioned issues, this paper proposes a novel resource allocation framework for the cloud service providers to schedule and effective resource allocation. The key idea of the proposed resource allocation scheme is to utilize Non dominated Sorting Genetic Algorithm (NSGA-III) to effectively allocate resources. Furthermore, the proposed NSGA-III is modified to support any interim data sources (any middle wares). The proposed model is experimentally validated in the test bed with multi-node Hadoop cluster. The experimental results confirm that the proposed model outperforms the existing state of the art models such as Lion optimization, Traditional ACO and Particle based Kernel function algorithms with more than 95% in accuracy.},
  archive      = {J_EI},
  author       = {Miriam, A. Jemshia and Saminathan, R. and Chakaravarthi, S.},
  doi          = {10.1007/s12065-020-00436-2},
  journal      = {Evolutionary Intelligence},
  month        = {6},
  number       = {2},
  pages        = {759-765},
  shortjournal = {Evol. Intell.},
  title        = {Non-dominated sorting genetic algorithm (NSGA-III) for effective resource allocation in cloud},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Supervised machine learning approach to predict qualitative
software product. <em>EI</em>, <em>14</em>(2), 741–758. (<a
href="https://doi.org/10.1007/s12065-020-00434-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Software development process (SDP) is a framework imposed on software product development and is a multi-stage process wherein a wide range of tasks and activities pan out in each stage. Each stage requires careful observations to improve productivity, quality, etc. to ease the process of development. During each stage, problems surface likes constraint of on-time completion, proper utilization of available resources and appropriate traceability of work progress, etc. and may lead to reiteration due to the defects spotted during testing and then, results into the negative walk-through due to unsatisfactory outcomes. Working on such defects can help to take a step towards the proper steering of activities and thus to improve the expected performance of the software product. Handpicking the proper notable features of SDP and then analyzing their nature towards the outcome can greatly help in getting a reliable software product by meeting the expected objectives. This paper proposed supervised Machine Learning (ML) models for the predictions of better SDP, particularly focusing on cost estimation, defect prediction, and reusability. The experimental studies were conducted on the primary data, and the evaluation reveals the model suitability in terms of efficiency and effectiveness for SDP prediction (accuracy of cost estimation: 65%, defect prediction: 93% and reusability: 82%).},
  archive      = {J_EI},
  author       = {Sinha, Hariom and Behera, Rajat Kumar},
  doi          = {10.1007/s12065-020-00434-4},
  journal      = {Evolutionary Intelligence},
  month        = {6},
  number       = {2},
  pages        = {741-758},
  shortjournal = {Evol. Intell.},
  title        = {Supervised machine learning approach to predict qualitative software product},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Mining of multiple ailments correlated to diabetes mellitus.
<em>EI</em>, <em>14</em>(2), 733–740. (<a
href="https://doi.org/10.1007/s12065-020-00432-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Efficient and user friendly database technologies have enabled the digitization of information pertaining to the medical domain. This has not only eased the smooth record manipulation but also attracted man a researchers to explore certain challenges to solve through implementation of data mining tools and techniques. Among the nature of ailments, the information related to diabetes mellitus (DM) are found to be the maximally digitized. This has provided a challenging but buzzing platform for the researchers to do in-depth analysis and present modern edge solutions which can lead to early diagnosis of the fatal ailment. There arise numerous side-effects to a human body when it is affected by DM. These multiple ailments attack a human body with the direct or indirect influence of DM and it’s corresponding drug intake. Thus, there has been a demand for a generic scheme which can predict the likeliness of certain multiple ailments that a DM patient is supposed to be attacked by in near future. In this work, a suitable scheme has been proposed in the same direction. This scheme provides a viable platform where the probabilities of multiple ailments for a DM patient can be computed. The proposed scheme also provides the probabilities of occurrence of individual ailment as well as the probabilities of occurrence of certain combination of the ailments. Occurrence of three of the major ailment are being computed in this work. These are retinal disorder, kidney malfunction, and heart disease. A Fuzzy logic strategy has been used for matching several disease constraints and produce a decisive outcome. Certain number of novel heuristic functions are presented which take these outputs and provide a probabilistically accurate prediction of occurrences of the said ailments. Suitable experimental evaluation have been made with proper data inputs. The proposed scheme has also been compared with competent schemes. An overall rates of accuracy of 97% is calculated based on a k-fold cross validation performance metric.},
  archive      = {J_EI},
  author       = {Reddy, Shiva Shankar and Sethi, Nilambar and Rajender, R.},
  doi          = {10.1007/s12065-020-00432-6},
  journal      = {Evolutionary Intelligence},
  month        = {6},
  number       = {2},
  pages        = {733-740},
  shortjournal = {Evol. Intell.},
  title        = {Mining of multiple ailments correlated to diabetes mellitus},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An efficient approach for sentiment analysis using machine
learning algorithm. <em>EI</em>, <em>14</em>(2), 725–731. (<a
href="https://doi.org/10.1007/s12065-020-00429-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sentimental analysis determines the views of the user from the social media. It is used to classify the content of the text into neutral, negative and positive classes. Various researchers have used different methods to train and classify twitter dataset with different results. Particularly when time is taken as constraint in some applications like airline and sales, the algorithm plays a major role. In this paper an optimization based machine learning algorithm is proposed to classify the twitter data. The process was done in three stages. In the first stage data is collected and preprocessed, in the second stage the data is optimized by extracting necessary features and in the third stage the updated training set is classified into different classes by applying different machine learning algorithms. Each algorithm gives different results. It is observed that the proposed method i.e., sequential minimal optimization with decision tree gives good accuracy of 89.47% compared to other machine learning algorithms.},
  archive      = {J_EI},
  author       = {Naresh, A. and Venkata Krishna, P.},
  doi          = {10.1007/s12065-020-00429-1},
  journal      = {Evolutionary Intelligence},
  month        = {6},
  number       = {2},
  pages        = {725-731},
  shortjournal = {Evol. Intell.},
  title        = {An efficient approach for sentiment analysis using machine learning algorithm},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Soft computing approach for multi-objective task allocation
problem in wireless sensor network. <em>EI</em>, <em>14</em>(2),
711–723. (<a href="https://doi.org/10.1007/s12065-020-00412-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sensor nodes of a wireless sensor network (WSN) are resource constrained and the real time applications of WSN may exceed the computational capacity of a particular sensor node. Thus, such real-time applications of WSN cannot be completed by a single sensor node in many cases, but the problem can be solved by distributing the task among multiple sensor nodes. Thus, given a set of sensor nodes and a computationally heavy task to be executed, to find best suitable set of sensor nodes from the available sensor nodes to complete the assigned task is an important research problem in the WSN domain. This allows the system to utilize the resources of a sensor node in a better way and to enhance the parallel processing capacity of WSN. The sensor nodes should be selected for a task such that, with the selected set of nodes, the task can be completed in an efficient manner in terms of resource consumption. The problem of task allocation is to select best suitable set of sensor nodes for a task considering the energy consumption, communication over head, network life time and computational requirements. In this paper, we propose two methods for this problem, namely modified multi-objective binary particle swarm optimization (MOMBPSO) and non-dominated sorting genetic algorithm-II (NSGA-II) for task allocation in WSN. We carried out extensive simulation experiments with varying number of iterations, sensor nodes and number of tasks. Simulation results show that modified binary PSO performs better in terms of energy consumption and NSGA-II is performing better in terms of spread of solutions compared to MOMBPSO.},
  archive      = {J_EI},
  author       = {Javvaji, Gowthami and Udgata, Siba K.},
  doi          = {10.1007/s12065-020-00412-w},
  journal      = {Evolutionary Intelligence},
  month        = {6},
  number       = {2},
  pages        = {711-723},
  shortjournal = {Evol. Intell.},
  title        = {Soft computing approach for multi-objective task allocation problem in wireless sensor network},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Intrusion detection system for cloud forensics using
bayesian fuzzy clustering and optimization based SVNN. <em>EI</em>,
<em>14</em>(2), 699–709. (<a
href="https://doi.org/10.1007/s12065-020-00410-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intrusion detection has emerged as one of the major challenges involved in the cloud forensics. This work introduces an intrusion detection framework for the cloud environment with clustering and two-level classifiers. In the first step of the process, a Bayesian fuzzy clustering is used for clustering the nodes in the cloud. And in the next step, two-level gravitational group search-based support vector neural network (GG-SVNN) classifier identifies intrusion in clusters. GG-SVNN is a novel optimization scheme proposed in this work, by combining the group search optimizer, and gravitational search algorithm. The intrusion information provided by level 1 classifier is arranged to form compact data, and provided to the level 2 classifier. The level 2 classifier finally identifies total nodes affected by the intruders. The simulation of the proposed intrusion detection is done with the help of KDD cup dataset. From the simulation results, it is evident that the proposed GG-SVNN classifier has achieved overall best performance by achieving high accuracy value of 92.41% and low false alarm rate of 4.75% respectively.},
  archive      = {J_EI},
  author       = {Tummalapalli, Siva Rama Krishna and Chakravarthy, A. S. N.},
  doi          = {10.1007/s12065-020-00410-y},
  journal      = {Evolutionary Intelligence},
  month        = {6},
  number       = {2},
  pages        = {699-709},
  shortjournal = {Evol. Intell.},
  title        = {Intrusion detection system for cloud forensics using bayesian fuzzy clustering and optimization based SVNN},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Hybrid encryption framework for securing big data storage in
multi-cloud environment. <em>EI</em>, <em>14</em>(2), 691–698. (<a
href="https://doi.org/10.1007/s12065-020-00404-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the present scenario, big data is facing many challenges regarding the data storage, data theft and unauthorized access. Many researchers are concentrated on developing the security mechanism for big data storage. To overcome the above issue, this paper concentrated on developing the encryption algorithm for storing big data in the multi cloud storage. The multi cloud storage environment permits the user to store the data in to different cloud storage services. This paper aims to develop the secure framework which restricts the insider attacks. The proposed framework contains data uploading, slicing, indexing, encryption, distribution, decryption, retrieval and merging process. The hybrid encryption algorithm was developed to provide the security to the big data before storing it in to the multi cloud. The Simulation analysis is carried with real time cloud storage environments. The proposed algorithm recorded around 2630 KB/S for the encryption process. The results prove the superiority of the proposed algorithm compared to the bench mark algorithms.},
  archive      = {J_EI},
  author       = {Viswanath, G. and Krishna, P. Venkata},
  doi          = {10.1007/s12065-020-00404-w},
  journal      = {Evolutionary Intelligence},
  month        = {6},
  number       = {2},
  pages        = {691-698},
  shortjournal = {Evol. Intell.},
  title        = {Hybrid encryption framework for securing big data storage in multi-cloud environment},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Distributed deduplication with fingerprint index management
model for big data storage in the cloud. <em>EI</em>, <em>14</em>(2),
683–690. (<a href="https://doi.org/10.1007/s12065-020-00395-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As data progressively grows within data centers, the cloud storage models face several issues while storing data and offers abilities needed to shift data in an adequate time frame. This study aims to develop a distributed deduplication model to achieve scalable throughput and capacity utilizing many data servers for duplicating data in parallel with minimal loss. This paper proposes a new cloud storage model based on a distributed deduplication with the fingerprint index management (DDFI) model. The DDFI model operates on three main stages. At the initial stage, the DDFI model makes use of an effective routing technique depending upon the similarity level of the data, which leads to low network overhead by rapid identification of storage locations. In the second stage, the duplicate data identification procedure is carried out by the use of the MD5 algorithm. At the final stage, a fingerprint index management process is executed where a fingerprint index comprises fingerprints and its corresponding position details of every written chunk. For optimizing the results of the deduplication performance, the DDFI model manages the fingerprint index in storage space and only sometimes writes to disk at the same time as the cloud database scheme is idle. The simulation outcome exhibited that the presented DDFI model offered maximum results with a higher deduplication ratio (DR) with a minimum overhead of network bandwidth. From the detailed comparative analysis, it is inferred that the presented DFFI model offered maximum relative DR, maximum duplication performance, minimum read bandwidth, and write bandwidth.},
  archive      = {J_EI},
  author       = {Saraswathi, S. Sabeetha and Malarvizhi, N.},
  doi          = {10.1007/s12065-020-00395-8},
  journal      = {Evolutionary Intelligence},
  month        = {6},
  number       = {2},
  pages        = {683-690},
  shortjournal = {Evol. Intell.},
  title        = {Distributed deduplication with fingerprint index management model for big data storage in the cloud},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Feedback-based fuzzy resource management in IoT using fog
computing. <em>EI</em>, <em>14</em>(2), 669–681. (<a
href="https://doi.org/10.1007/s12065-020-00377-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The goal of Internet of Things (IoT) is to make “things” (wearable devices, smart cameras, sensors and smart home appliances) connect to internet. Large storage is required to store huge volume of data that is generated, data processing need to be carried out between IoT devices and the massive number of applications. This process can be made effectively with the help of cloud computing technology. Resources can be effectively utilized with the help of cloud, and IoT plays a significant role in managing the tasks that are to be offloaded to the cloud. The performance of the application is to be enhanced by providing Quality of Service (QoS) and the performance is evaluated in terms of QoS parameters like Power utilization, Makespan and Execution Time. The tasks are allocated based on priority. Fog computing paradigm is used in the proposed model to decrease the makespan of time. The projected mechanism is tested and compared with different present systems and is shown that proposed methodology produced effective results.},
  archive      = {J_EI},
  author       = {Arunkumar Reddy, D. and Venkata Krishna, P.},
  doi          = {10.1007/s12065-020-00377-w},
  journal      = {Evolutionary Intelligence},
  month        = {6},
  number       = {2},
  pages        = {669-681},
  shortjournal = {Evol. Intell.},
  title        = {Feedback-based fuzzy resource management in IoT using fog computing},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Evolving dictionary based sentiment scoring framework for
patient authored text. <em>EI</em>, <em>14</em>(2), 657–667. (<a
href="https://doi.org/10.1007/s12065-020-00366-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent days, the Government and other organizations are focusing on providing better health care to people. Understanding the patients experience of care-received is key for providing better health care. With prevailing usage of social media applications, patients are expressing their experience over social media. This patient authored text is a free-unstructured data which is available over social media in large chunks. To extract the sentiments from this huge data, a domain-specific dictionary is required to get better accuracy. The proposed approach defines a new domain-specific dictionary and uses this in sentiment scoring to enhance the overall sentiment classification on patient authored text. We conducted experiments on the proposed approach using NHS Choices dataset and compared it with popular classifiers like linear regression, stochastic gradient descent, dictionary-based approaches: VADER and AFINN. The results prove that the proposed approach is an effective strategy for sentiment analysis over patient authored text which helps in improving the classification accuracy.},
  archive      = {J_EI},
  author       = {Kumar, Chitturi Satya Pavan and Babu, Lekkala Dasaratha Dhinesh},
  doi          = {10.1007/s12065-020-00366-z},
  journal      = {Evolutionary Intelligence},
  month        = {6},
  number       = {2},
  pages        = {657-667},
  shortjournal = {Evol. Intell.},
  title        = {Evolving dictionary based sentiment scoring framework for patient authored text},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Analysis of net asset value prediction using low complexity
neural network with various expansion techniques. <em>EI</em>,
<em>14</em>(2), 643–655. (<a
href="https://doi.org/10.1007/s12065-020-00365-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Net asset value (NAV) is a crucial measure that reveals the financial condition of a mutual fund and its prediction becomes important in decision making especially for fund managers. For this purpose, several works have been done using FLANN for NAV prediction. However, when it comes to FLANN model, the choice of various parameters and expansion functions has huge impact on the performance of the prediction must be considered. This study focuses on the objective of finding the optimal parameters for each model built with one type of functional expansion and compare them to find the most suitable for NAV prediction. Comparisons made on the learning rate, the sliding widow’s size, the number of expansions, reveal that these parameters must be found by heuristic tests for each expansion. The analysis on the number of days ahead of prediction shows that Legendre expansion is more appropriate for short term prediction whereas Power series expansion gives good results for both short and long-term prediction. In case of Convergence, Power series followed by Chebyshev expansion converge faster than the other models.},
  archive      = {J_EI},
  author       = {Rout, Minakhi and Koudjonou, Koffi Mawuna and Satapathy, Suresh Chandra},
  doi          = {10.1007/s12065-020-00365-0},
  journal      = {Evolutionary Intelligence},
  month        = {6},
  number       = {2},
  pages        = {643-655},
  shortjournal = {Evol. Intell.},
  title        = {Analysis of net asset value prediction using low complexity neural network with various expansion techniques},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). RETRACTED ARTICLE: Automatic alert generation in a
surveillance systems for smart city environment using deep learning
algorithm. <em>EI</em>, <em>14</em>(2), 635–642. (<a
href="https://doi.org/10.1007/s12065-020-00353-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In Smart cities surveillance is an extremely important feature required for ensuring the safety of citizens and also for deterring the crime. Hence, intelligent video surveillance (IVS) frameworks are by and large increasingly more famous in security applications. The investigation and acknowledgment of anomalous practices in a video succession has step by step attracted the consideration in the field of IVS, as it permits sifting through an enormous number of pointless data, which ensures the high productivity in the security assurance, and spare a great deal of human and material assets. Techniques are proposed in the literature for analyzing the IVS systems. Existing systems for video analysis, suffer with some limitations. The one of the major limitation is lack of real time response from the surveillance systems. In order to overcome this limitation, an IVS system design is proposed using convolution neural networks. In case of emergency like fire, thieves’ attacks, Intrusion Detector, the proposed system sends an alert for the corresponding services automatically. Experimentation has done on the number of datasets available for video surveillance testing. The results show that the proposed surveillance system achieves very low false alarm rates.},
  archive      = {J_EI},
  author       = {Janakiramaiah, B. and Kalyani, G. and Jayalakshmi, A.},
  doi          = {10.1007/s12065-020-00353-4},
  journal      = {Evolutionary Intelligence},
  month        = {6},
  number       = {2},
  pages        = {635-642},
  shortjournal = {Evol. Intell.},
  title        = {RETRACTED ARTICLE: Automatic alert generation in a surveillance systems for smart city environment using deep learning algorithm},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Predicting bipolar disorder and schizophrenia based on
non-overlapping genetic phenotypes using deep neural network.
<em>EI</em>, <em>14</em>(2), 619–634. (<a
href="https://doi.org/10.1007/s12065-019-00346-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Computational Psychiatry is an emerging field of science. It focuses on identifying the complex relationship between the brain’s neurobiology. Mental illness has recently become an important problem to be addressed as the number of people affected is increasing over time. Schizophrenia and Bipolar Disorder are two major types of psychiatric disorders. Most of the people are experienced these illness in their lifetime. But, diagnosing psychiatric disorders is even more a complex problem. Genetic factors play a vital role in developing mental illness. Interestingly, few psychiatric disorders have common genetic overlapping between each other. It causes detrimental effect on diagnosing the illness accurately. To overcome this existing issue, a Rank based Gene Biomarker Identification and Classification framework is proposed to identify the overlapping and non-overlapping gene patterns of bipolar disorder and schizophrenia. The dataset used in this experiment is obtained from Gene Expression Omnibus database. As an outcome of this experiment, seven biomarkers are identified as the overlapping genes. Also, 60 and 68 informative gene biomarkers are identified on bipolar disorder and schizophrenia dataset as feature subsets to discriminate the samples. Overlapping genes are eliminated to increase the diagnostic accuracy of the disorders. The performance of the proposed system is evaluated with standard existing machine learning algorithms. This proposed framework attained 97.01% and 95.65% accuracy on bipolar disorder and schizophrenia dataset with Deep Neural Network model outperformed other benchmarked algorithms and proved its efficacy.},
  archive      = {J_EI},
  author       = {Karthik, S. and Sudha, M.},
  doi          = {10.1007/s12065-019-00346-y},
  journal      = {Evolutionary Intelligence},
  month        = {6},
  number       = {2},
  pages        = {619-634},
  shortjournal = {Evol. Intell.},
  title        = {Predicting bipolar disorder and schizophrenia based on non-overlapping genetic phenotypes using deep neural network},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A cognitive mechanism for mitigating DDoS attacks using the
artificial immune system in a cloud environment. <em>EI</em>,
<em>14</em>(2), 607–618. (<a
href="https://doi.org/10.1007/s12065-019-00340-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Denial of Service (DoS) and Distributed Denial of Service (DDoS) attacks can largely damage the availability of the cloud services and can be effectively initiated by utilizing different tools, prompting financial harm or influencing the reputation. Consequently, there is a requirement for a more grounded and general approach to block these attacks. This paper proposes the use of artificial immune systems to alleviate DDoS attacks in cloud computing by identifying the most potential features of the attack. This methodology is capable of detecting threats and responding according to the behavior of the biological resistance mechanism in human beings. It is carried out by emulating the various immune reactions and the construction of the intrusion detection system. For the assessment, experiments with public domain datasets (KDD cup 99) were implemented. Based on broad theoretical and performance analysis, the proposed system is capable to identify the anomalous entries with high detection accuracy and low false alarm rate.},
  archive      = {J_EI},
  author       = {Prathyusha, Damai Jessica and Kannayaram, Govinda},
  doi          = {10.1007/s12065-019-00340-4},
  journal      = {Evolutionary Intelligence},
  month        = {6},
  number       = {2},
  pages        = {607-618},
  shortjournal = {Evol. Intell.},
  title        = {A cognitive mechanism for mitigating DDoS attacks using the artificial immune system in a cloud environment},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Analytics on real time security attacks in healthcare,
retail and banking applications in the cloud. <em>EI</em>,
<em>14</em>(2), 595–605. (<a
href="https://doi.org/10.1007/s12065-019-00337-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cloud computing is used by large enterprises to provide services to customers. The major advantage of adapting cloud systems is that the clients need not have to manage the maintenance and operations of the cloud systems along with the maintenance of hardware but they will have full control over the data. The downsides of the cloud systems are the security threats that includes confidentiality and security issues. Software as a service, platform as a service, and infrastructure as a service; all comes with its own security issues of different complexities. The security challenges posed by cloud computing systems are overshadowing the economic edge it has. Based on the analysis of the research performed in the area of security issues in the cloud it is evident that a detailed analysis on the same will throw light on root causes and vulnerabilities. The research primarily throws light on the statistics and detailed analysis on the security attacks in the cloud systems in different domains. The paper focuses on the issues and threats in healthcare, retail and banking domains. Analytics on the attacks in these domains will give insights on the loss, mitigation time etc. The real time data on security threats is acquired from IT cloud service providers. The statistics on the same will open up different perspectives of cloud security issues and can throw light on the possible research directions and that is the motivation behind this preliminary research.},
  archive      = {J_EI},
  author       = {Padmaja, K. and Seshadri, R.},
  doi          = {10.1007/s12065-019-00337-z},
  journal      = {Evolutionary Intelligence},
  month        = {6},
  number       = {2},
  pages        = {595-605},
  shortjournal = {Evol. Intell.},
  title        = {Analytics on real time security attacks in healthcare, retail and banking applications in the cloud},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). RETRACTED ARTICLE: Optimal feature selection through a
cluster-based DT learning (CDTL) in heart disease prediction.
<em>EI</em>, <em>14</em>(2), 583–593. (<a
href="https://doi.org/10.1007/s12065-019-00336-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the rural side, there is the absence of centers for cardiovascular ailment. Due to this, around 12 million people passing worldwide reported by WHO. The principal purpose of coronary illness is a propensity for smoking. ML classifiers are applied to predict the risk of cardiovascular disease. However, the ML model has some inherent problems like it’s serene to feature selection, splitting attribute, and imbalanced datasets prediction. Most of the mass datasets have multi-class labels, but their combinations are in different proportions. In this paper, we experiment with our system with Cleveland’s heart samples from the UCI repository. Our cluster-based DT learning (CDTL) mainly includes five key stages. At first, the original set has partitioned through target label distribution. From the high distribution samples, the other possible class combination has made. For each class-set combination, the significant features have identified through entropy. With the significant critical features, an entropy-based partition has made. At last, on these entropy clusters, RF performance is made through significant and all features in the prediction of heart disease. From our CDTL approach, the RF classifier achieves 89.30% improved prediction accuracy from 76.70% accuracy (without CDTL). Hence, the error rate of RF with CDTL has significantly reduced from 23.30 to 9.70%.},
  archive      = {J_EI},
  author       = {Magesh, G. and Swarnalatha, P.},
  doi          = {10.1007/s12065-019-00336-0},
  journal      = {Evolutionary Intelligence},
  month        = {6},
  number       = {2},
  pages        = {583-593},
  shortjournal = {Evol. Intell.},
  title        = {RETRACTED ARTICLE: Optimal feature selection through a cluster-based DT learning (CDTL) in heart disease prediction},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Blood vessel extraction in fundus images using hessian
eigenvalues and adaptive thresholding. <em>EI</em>, <em>14</em>(2),
577–582. (<a href="https://doi.org/10.1007/s12065-019-00329-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Retinal image blood vessels are having significant role in different eye related diseases such as diabetic retinopathy, glaucoma, cataract, age-related macular degeneration and many more. Vasculature retinal feature extraction is an important factor to different doctors for treatment and diagnosis of different diseases. For automatic extraction of retinal blood vessels, different types of clustering related approaches (i.e. k-means/fuzzy c-means) are introduced to explore blood vessels from real time retinal images. Novel blood vessel extraction approach is introduced to explore retinal blood vessels with unsupervised clustering procedures like fuzzy c-means followed with Gabor filter. In this paper, we propose Enhanced blood vessel exploration approach (EBVEA) to improve the segmentation and visualization of vasculature retinal images or fundus images in blood vessel extraction with a combination of hessian based center-to boundary (BB) filters. These filters are used to indicate elongated boundary structures by enhancing the functions based on hessian Eigen values represented in (nxn) matrix. Performance of proposed enhanced approach with traditional approaches in terms of true positive rate (tpr), accuracy etc. are tested. Experimental results carried out and tested on bench mark data sets like DRIVE and STARE datasets produced better results.},
  archive      = {J_EI},
  author       = {Prasad Reddy, P. V. G. D.},
  doi          = {10.1007/s12065-019-00329-z},
  journal      = {Evolutionary Intelligence},
  month        = {6},
  number       = {2},
  pages        = {577-582},
  shortjournal = {Evol. Intell.},
  title        = {Blood vessel extraction in fundus images using hessian eigenvalues and adaptive thresholding},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Architecture for distributed query processing using the RDF
data in cloud environment. <em>EI</em>, <em>14</em>(2), 567–575. (<a
href="https://doi.org/10.1007/s12065-019-00315-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {From past decade, the advancement in the field of RDF data management poses many challenges to researchers. Processing large volumes of RDF data is very difficult task in the cloud. The RDF data actually contains complex graphs along with large number of schemas. Distributing the RDF data with traditional approaches or partitioning them with conventional mechanism leads to faulty distribution as well as generated large number of join operations. To address the above issues, this paper developed architecture for distributed query processing using the adaptive hash partitioning approach along with hash join operation. This paper also developed an algorithm for executing the query by minimizing the joins. This paper presented an evaluation of the proposed model with other standard model. The experimental results proved that the proposed method had faster response time compared to the other standard models.},
  archive      = {J_EI},
  author       = {Ranichandra, C. and Tripathy, B. K.},
  doi          = {10.1007/s12065-019-00315-5},
  journal      = {Evolutionary Intelligence},
  month        = {6},
  number       = {2},
  pages        = {567-575},
  shortjournal = {Evol. Intell.},
  title        = {Architecture for distributed query processing using the RDF data in cloud environment},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Correction to: Visual topic models for healthcare data
clustering. <em>EI</em>, <em>14</em>(2), 563–565. (<a
href="https://doi.org/10.1007/s12065-019-00323-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The algorithms in section 5 were missing in the online publrished article. Now, section 5 text is given below.},
  archive      = {J_EI},
  author       = {Rajendra Prasad, K. and Mohammed, Moulana and Noorullah, R. M.},
  doi          = {10.1007/s12065-019-00323-5},
  journal      = {Evolutionary Intelligence},
  month        = {6},
  number       = {2},
  pages        = {563-565},
  shortjournal = {Evol. Intell.},
  title        = {Correction to: Visual topic models for healthcare data clustering},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Visual topic models for healthcare data clustering.
<em>EI</em>, <em>14</em>(2), 545–562. (<a
href="https://doi.org/10.1007/s12065-019-00300-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Social media is a great source to search health-related topics for envisages solutions towards healthcare. Topic models originated from Natural Language Processing that is receiving much attention in healthcare areas because of interpretability and its decision making, which motivated us to develop visual topic models. Topic models are used for the extraction of health topics for analyzing discriminative and coherent latent features of tweet documents in healthcare applications. Discovering the number of topics in topic models is an important issue. Sometimes, users enable an incorrect number of topics in traditional topic models, which leads to poor results in health data clustering. In such cases, proper visualizations are essential to extract information for identifying cluster trends. To aid in the visualization of topic clouds and health tendencies in the document collection, we present hybrid topic modeling techniques by integrating traditional topic models with visualization procedures. We believe proposed visual topic models viz., Visual Non-Negative Matrix Factorization (VNMF), Visual Latent Dirichlet Allocation (VLDA), Visual intJNon-negative Matrix Factorization (VintJNMF), and Visual Probabilistic Latent Schematic Indexing (VPLSI) are promising methods for extracting tendency of health topics from various sources in healthcare data clustering. Standard and benchmark social health datasets are used in an experimental study to demonstrate the efficiency of proposed models concerning clustering accuracy (CA), Normalized Mutual Information (NMI), precision (P), recall (R), F-Score (F) measures and computational complexities. VNMF visual model performs significantly at an increased rate of 32.4% under cosine based metric in the display of visual clusters and an increased rate of 35–40% in performance measures compared to other visual methods on different number of health topics.},
  archive      = {J_EI},
  author       = {Rajendra Prasad, K. and Mohammed, Moulana and Noorullah, R. M.},
  doi          = {10.1007/s12065-019-00300-y},
  journal      = {Evolutionary Intelligence},
  month        = {6},
  number       = {2},
  pages        = {545-562},
  shortjournal = {Evol. Intell.},
  title        = {Visual topic models for healthcare data clustering},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Development and performance evaluation of hybrid KELM models
for forecasting of agro-commodity price. <em>EI</em>, <em>14</em>(2),
529–544. (<a href="https://doi.org/10.1007/s12065-019-00295-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Incurring the benefits of kernel type-based extreme learning machine (KELM), this paper proposes a Grey wolf optimization based multiquadratic kernel KELM (GWO-KELM) models for effective forecasting of agro-commodity prices such as Chana and Barley. The objective is to obtain best possible weight between hidden and output layer of an artificial neural network using GWO optimization techniques. These weights are used in KELM model to achieve improved performance. To assess the superiority performance of the proposed models, similar results are obtained using simulation study by simulating GA-KELM (genetic algorithm based KELM), PSO-KELM (particle swarm optimization based KELM) and GWO-KELM multiquadratic kernel types (GWO-KELM) models. From exhaustive simulation result, it is demonstrated that GWO-KELM forecasting model offers the best performance using three models in terms of matrices. The study pertains to short and long range prediction for prices of Chana and Barley using publicly available database.},
  archive      = {J_EI},
  author       = {Parida, Nirjharinee and Mishra, Debahuti and Das, Kaberi and Rout, Narendra Kumar},
  doi          = {10.1007/s12065-019-00295-6},
  journal      = {Evolutionary Intelligence},
  month        = {6},
  number       = {2},
  pages        = {529-544},
  shortjournal = {Evol. Intell.},
  title        = {Development and performance evaluation of hybrid KELM models for forecasting of agro-commodity price},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A work load prediction strategy for power optimization on
cloud based data centre using deep machine learning. <em>EI</em>,
<em>14</em>(2), 519–527. (<a
href="https://doi.org/10.1007/s12065-019-00289-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The application development industry has moved into cloud computing for stratifying the need of the customer for higher availability and higher scalability. The cloud computing environment provides the infrastructure off the premises for the application owner, which reduces the need for cost and security aspects. The primary intension of the cloud-based data centres is to virtualize the infrastructure for the applications and present it as Infrastructure As A Service (IAAS). The deployment of the applications from the application owner is done on the data centres and must be allocated to any of the pre-configured instances. The instances are again configured with virtual machines for virtualizing the computing capabilities, memory capabilities, network bandwidth capabilities and finally the storage capabilities. The deployed applications on the virtual machines must be accessible by the application consumers or the clients of the application owners. Load balancing typically includes committed programming or equipment, for example, a multilayer switch or a Domain Name System server process. Once the load is balanced, then the application performances can be justified. Great number of research endeavors have endeavored to build the presentation of the applications during load balancing by sending different calculations for distinguishing proof of the loaded virtual machines and less loaded cases for determination of the goal servers. Nevertheless, the performances of these strategies for load balancing is always criticized by various research attempts for being highly time complex and directly effecting the overall performances. Extraordinary number of research tries have attempted to construct the introduction of the applications during load balancing by sending various estimations for recognizing verification of the loaded virtual machines and less loaded cases for assurance of the objective servers. The outcome from this research is highly satisfactory and demonstrates nearly 98% accuracy on the load prediction and nearly 85% reduction on the time complexity with 88% reduction on the SLA violation.},
  archive      = {J_EI},
  author       = {Kalyampudi, P. S. Latha and Krishna, P. Venkata and Kuppani, Sathish and Saritha, V.},
  doi          = {10.1007/s12065-019-00289-4},
  journal      = {Evolutionary Intelligence},
  month        = {6},
  number       = {2},
  pages        = {519-527},
  shortjournal = {Evol. Intell.},
  title        = {A work load prediction strategy for power optimization on cloud based data centre using deep machine learning},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An efficient system model to minimize signal interference
and delay in mobile cloud environment. <em>EI</em>, <em>14</em>(2),
509–517. (<a href="https://doi.org/10.1007/s12065-019-00285-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The integration of mobile computing with cloud computing has increased advantages to the users to access the applications from anywhere at any time. The traditional cellular system is overlaid by number of low power nodes which allows users to attain services at any time. But the increase of femto cells causes intra-tier, inter-tier interference and delay in the network. To overcome the bottleneck a sub-modular optimizing based offloading algorithm is proposed in this paper where the task is divided into two functions and processed. The main aim is to optimize execution time and interference. The simulation results show that the execution time has been reduced by 57.89% and performs well to obtain optimum solution compared to other existing methods.},
  archive      = {J_EI},
  author       = {Akki, Praveena and Vijayarajan, V.},
  doi          = {10.1007/s12065-019-00285-8},
  journal      = {Evolutionary Intelligence},
  month        = {6},
  number       = {2},
  pages        = {509-517},
  shortjournal = {Evol. Intell.},
  title        = {An efficient system model to minimize signal interference and delay in mobile cloud environment},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Deep learning based dynamic task offloading in mobile
cloudlet environments. <em>EI</em>, <em>14</em>(2), 499–507. (<a
href="https://doi.org/10.1007/s12065-019-00284-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The mobile computing world is migrating from 4G to 5G and one of the major offering of 5G is the seamless computing power and it is the major set back in the current scenario. The major difficulties that need to be addressed are computing, quality of services. Speed, power and security. This research paper aims in addressing the issue of task management in the mobile systems that is directly related to quality. The article proposes a deep learning-based algorithm that performs dynamic task offloading in the mobile cloudlet since cloudlet aids in the reduction of the delay that occur in the WLAN. The delay in performing tasks is one of the major drawback of cloudlet that it is deprived of resources when compared to cloud server due to which the tasks that are to be performed are divided and is designated to mobile devices, different cloud servers and cloudlet itself. Therefore, to determine the combination of devices required to perform different tasks, deep learning algorithms are considered. The algorithm is responsible to identify the subtasks, the subtasks that has to be computed/executed in which device or cloudlet or cloud server. The proposed algorithm is named Deep Learning based Dynamic Task Offloading in Mobile Cloudlet (DLDTO). The algorithm is implemented and compared with Cloudlet based Dynamic Task Offloading (CDTO). The overall analysis and comparison with the existing CDTO for job allocation proved that the performance of the proposed DLDTO algorithm is better in terms of energy consumption and completion time.},
  archive      = {J_EI},
  author       = {Rani, D. Shobha and Pounambal, M.},
  doi          = {10.1007/s12065-019-00284-9},
  journal      = {Evolutionary Intelligence},
  month        = {6},
  number       = {2},
  pages        = {499-507},
  shortjournal = {Evol. Intell.},
  title        = {Deep learning based dynamic task offloading in mobile cloudlet environments},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Data augmentation for cancer classification in oncogenomics:
An improved KNN based approach. <em>EI</em>, <em>14</em>(2), 489–498.
(<a href="https://doi.org/10.1007/s12065-019-00283-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There is currently a great need for research in gene expression data to help with cancer classification in the field of oncogenomics. This is especially true since the disease occurs sporadically and often does not show symptoms. Typically, gene expression data is disproportionate with a large number of features and a low number of samples. A small sample size is likely to adversely affect accuracy of classification, as the performance of a classifier depends largely on the data. There is a pressing need to generate data which could be provided as better input to classifiers. Primitive augmentation techniques like uniform random generation and addition of noise do not assure good probability distribution. Secondly, as we deal with critical applications, the augmented data needs to have greater likelihood to the original values. Thus, we propose an improved variant of K-nearest neighborhood (KNN) rule. We use Counting Quotient Filter, Euclidean distance and mean best value from the k-neighbors for each target sample to get synthetic samples. A comparison is drawn amongst the raw data from public domain (original data), data generated using standard K-nearest neighbor rule and data generated using improved K-nearest neighbor rule. The data generated through these approaches is then further classified using state-of-art classifiers like SVM, J48 and DNN. The samples generated through our improvisation technique yield better recall values than the standard implementation; ensuring sensitivity of data. Average classification accuracy from all the three classifiers conclude enhancement of 7.72% as compared to traditional KNN approach and 16% when raw data is considered as input to the classifiers. Thus, the proposed algorithm attains two objectives; firstly, ensuring sensitivity of data for critical applications and secondly, enhancing classification accuracy.},
  archive      = {J_EI},
  author       = {Chaudhari, Poonam and Agarwal, Himanshu and Bhateja, Vikrant},
  doi          = {10.1007/s12065-019-00283-w},
  journal      = {Evolutionary Intelligence},
  month        = {6},
  number       = {2},
  pages        = {489-498},
  shortjournal = {Evol. Intell.},
  title        = {Data augmentation for cancer classification in oncogenomics: An improved KNN based approach},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An improved analytical approach for customer churn
prediction using grey wolf optimization approach based on stochastic
customer profiling over a retail shopping analysis: CUPGO. <em>EI</em>,
<em>14</em>(2), 479–488. (<a
href="https://doi.org/10.1007/s12065-019-00282-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Challenge of an early prediction of customer churn is a major demand among research community. To understand an intention of a customer on reasons to make a churn as well time taken by a customer to churn is always an unknown mystery. Though good numbers of research works have suggested works on customer churn an exact measure of accurate churn and approaches to suggest on retention is the major discussion of this paper. Traditional approaches such as ACO, PSO are supports on appreciable churn prediction but consider more time to converge, whereas GWO algorithm supports with minimal time to converge as well improved accuracy of 89.26% along with actual churn match compared to PSO and ACO approaches. CUPGO also focuses on customer retention of 34.81% to retain valuable customers. CUPGO works on a large dataset collected over two consistent years.},
  archive      = {J_EI},
  author       = {Manivannan, R. and Saminathan, R. and Saravanan, S.},
  doi          = {10.1007/s12065-019-00282-x},
  journal      = {Evolutionary Intelligence},
  month        = {6},
  number       = {2},
  pages        = {479-488},
  shortjournal = {Evol. Intell.},
  title        = {An improved analytical approach for customer churn prediction using grey wolf optimization approach based on stochastic customer profiling over a retail shopping analysis: CUPGO},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Thickness optimization of high temperature protective
clothing. <em>EI</em>, <em>14</em>(2), 469–477. (<a
href="https://doi.org/10.1007/s12065-019-00281-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aiming at the goal of protecting the personal safety of high temperature workers and reducing the cost of R&amp;D in enterprises, the article put forward the optimization of the thickness of high temperature protective clothing. A one-dimensional unsteady heat conduction model is constructed by combining the heat conduction equation with the definite solution conditions established by the initial state and boundary state to represent the temperature conduction process of the external—high temperature protective clothing—human epidermis system. The finite difference method is used to find the numerical solution of the heat conduction equation to represent the temperature distribution in the system. In this paper, an optimization algorithm based on control variable method and dichotomy method is designed to obtain the optimal solution of double-layer thickness of high temperature protective clothing. Finally, through simulation experiments, the practical problems are analyzed by using the proposed model and algorithm.},
  archive      = {J_EI},
  author       = {Zou, YiLin and Zhou, Kang and Ji, BinGe and Wu, XiaoDong and Zhen, YiTing},
  doi          = {10.1007/s12065-019-00281-y},
  journal      = {Evolutionary Intelligence},
  month        = {6},
  number       = {2},
  pages        = {469-477},
  shortjournal = {Evol. Intell.},
  title        = {Thickness optimization of high temperature protective clothing},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A proficient remote information responsibility check
protocol in multi-cloud environment. <em>EI</em>, <em>14</em>(2),
453–467. (<a href="https://doi.org/10.1007/s12065-019-00273-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Remote information respectability is one of the testing issues in the distributed storage framework which guarantees to deal with the re-appropriating information securely without downloading the entire information. Because of some useful circumstances, there is a need to spare the customer’s information is distributed over multi-cloud servers. In the interim, the information honesty confirmation convention ought to viable for diminishing the verifier cost. Existing information respectability approaches depend on hash capacities and advanced marks which are not fitting for the remote multi-cloud condition because of high computational over-burden and remote in nature. Furthermore, another current issue is that aggressors can hack the information in few occasions from the cloud regardless of the way that information respectability checking convention was presented. Remembering these issues, in this work, we anticipate a multi-cloud confined information respectability checking convention. The proposed technique offers consistent assertion towards the customer and assesses the data, which is immovably settled with the help of the new information respectability checking convention. At the point when an aggressor attempts to take the data in multi-cloud, the proposed continuous reviewing system will help the verifier to execute square dimension checking to ensure the information respectability through the one-round test-response or test reaction technique. A multi-cloud data integrity verification protocol is presented in test plan that depends on signature and symmetric keys. Using the proposed method, the clients can test the engaged information in one phase test reaction interaction with little transmission cost. In addition, it empowers public auditing and helps dynamic information preservation that enables the clients to adjust and erase the data with minimized execution overhead. For evaluating the execution of the proposed technique interms of information trustworthiness, a broad arrangement of experimentation happens. The proposed work enables various clients to manage remote cloud information. The execution of the proposed method is verified concerning update, verify, and inquiry time cost. From the accomplished outcomes, it is discovered that the proposed technique ensures the nature of administration and fixed security by having reasonable refresh time and a strict confirmation rule separate.},
  archive      = {J_EI},
  author       = {AnwarBasha, H. and SasiKumar, S. and Dhanasekaran, D. and Arunnehru, J.},
  doi          = {10.1007/s12065-019-00273-y},
  journal      = {Evolutionary Intelligence},
  month        = {6},
  number       = {2},
  pages        = {453-467},
  shortjournal = {Evol. Intell.},
  title        = {A proficient remote information responsibility check protocol in multi-cloud environment},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An efficient method for group key management in internet of
things using machine learning approach. <em>EI</em>, <em>14</em>(2),
445–452. (<a href="https://doi.org/10.1007/s12065-019-00258-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Internet of Things (IoT) represent a network of pervasive devices with different characteristics and features. It is important to provide security in IoT as Internet plays a prominent role in the communication process. In this paper, a novel group and hierarchical group key management scheme is proposed. The devices are found into groups and placed into various levels of hierarchy. The group leader shares a key to the members in the group and the key needs to be updated based on the entry and exit of the members into and out of the groups. Also, the machine learning techniques are used to make the system adapt to the provision of the keys to the devices which enter into the group. Incremental Gaussian Mixture Model is used to determine whether the particular device belong to the group or not. The proposed algorithm, machine learning based group and hierarchical key management is simulated and compared with the group and hierarchical key management scheme for solving security problems in IoT in terms of throughput and delay with varying no. of groups and overall cost with respect to no. of nodes and mobility speed.},
  archive      = {J_EI},
  author       = {Karrothu, Aravind and Norman, Jasmine},
  doi          = {10.1007/s12065-019-00258-x},
  journal      = {Evolutionary Intelligence},
  month        = {6},
  number       = {2},
  pages        = {445-452},
  shortjournal = {Evol. Intell.},
  title        = {An efficient method for group key management in internet of things using machine learning approach},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A new framework to locate, connect and share mobile web
services through intelligence techniques. <em>EI</em>, <em>14</em>(2),
433–444. (<a href="https://doi.org/10.1007/s12065-019-00249-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The advancement in mobile technology is taking place at very high speed, especially in the case of smart devices. In recent years, the use of mobile phones has changed the life style of common people. As days pass, new and better technologies are emerging in this field which make the life of people easier and also help people to connect with one another in a better way than before. Initially, the usage of mobile phones was restricted only to make phone calls and send messages. The current use of mobile phones has evolved into a new revolution. The current smart phones provide almost all features that a laptop or desktop provides. It is also seen that social network has influenced a lot of message and call transfers among the known group of users. There are thousands of mobile applications available and most of these applications communicate to a well-known server or cloud service provider through the Internet and gives back an appropriate response to the mobile user. It is really challenging to find an interesting service provided by an unknown mobile user to another mobile user who is interested in receiving that service. In the present scenario, people find it difficult to pursue their interests or connect to other people of similar interests. Most of the times, mobile users are unaware of the activities that are happening around them. The main idea behind this work is to provide a framework to notify a mobile user about his interests currently available near him/her or in different locations. It connects people of similar interests in the location where they are currently in. This framework uses the existing SOAP and HTTP technologies along with redefined WSDL for describing web services on the mobile device. The data to be shared by the mobile web service provider may be generated by the sensors within the mobile device or the data is explicitly updated by the user dynamically or the data is collected from the external sensors/devices connected to internet of things through the mobile device. The cloud service is used to enable the service request mapping and repository. This framework may be used to define any web service on mobile devices and make them available to users based on interest, location and time. The main objective of the proposed work is to identify various dynamic location based mobile web services and to provide them a framework to share their services with the interested mobile service consumers.},
  archive      = {J_EI},
  author       = {Fernandes, Roshan and Rio D’Souza, G. L. and Rodrigues, Anisha P.},
  doi          = {10.1007/s12065-019-00249-y},
  journal      = {Evolutionary Intelligence},
  month        = {6},
  number       = {2},
  pages        = {433-444},
  shortjournal = {Evol. Intell.},
  title        = {A new framework to locate, connect and share mobile web services through intelligence techniques},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Decade research on text detection in images/videos: A
review. <em>EI</em>, <em>14</em>(2), 405–431. (<a
href="https://doi.org/10.1007/s12065-019-00248-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Text present in an image or a video is a good representative as it provides semantic information of a respective image or video frame. Nowadays detection of textual information from videos are very challenging and exciting research area in video processing and machine learning field. Text detection finds a vital role in current applications such as indexing, easy and efficient retrieval, keyword based image search and event identification. However, the text region detection from video has several challenges like low resolution, complex background, alignment of text and variation in size, color, style. The ample of works have been done on text detection, and all these considered different properties to distinguish the text region from its background in a video frame. The main aim of this paper is to demonstrate the comprehensive study of decade research on various video text detection methods, which are categorized into horizontal text detection, arbitrarily oriented text detection, and multilingual text detection (Indian scenario and non-Indian scenario) methods. Different kinds of challenges are explained with examples and various types of applications are discussed to know the importance of the text detection process. Tables are demonstrated for all categories to provide useful information for the readers. Finally, possible future directions are discussed with respect to all categories and methods are evaluated using datasets such as ICDAR 2003, ICDAR 2013, ICDAR 2015, Nusdataset, TrecVId, YVT, MSRRC, SVT, MSRA, KAIST, Hau ’s, Neocr dataset, oriented scene text dataset, artificial text dataset and own horizontal, arbitrarily oriented, multilingual text datasets.},
  archive      = {J_EI},
  author       = {Manjunath Aradhya, V. N. and Basavaraju, H. T. and Guru, D. S.},
  doi          = {10.1007/s12065-019-00248-z},
  journal      = {Evolutionary Intelligence},
  month        = {6},
  number       = {2},
  pages        = {405-431},
  shortjournal = {Evol. Intell.},
  title        = {Decade research on text detection in images/videos: A review},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Design and analysis of behaviour based DDoS detection
algorithm for data centres in cloud. <em>EI</em>, <em>14</em>(2),
395–404. (<a href="https://doi.org/10.1007/s12065-019-00244-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the recent years, security is the major concern in cloud computing. One of the major security threats to the cloud is distributed denial of service (DDoS). This DDoS attacks results in data corruption, losing of sensitive information and leads to denial of cloud service. To overcome the drawbacks of security, we proposed the behaviour-based DDoS detection algorithm that is based on the behaviour of the user which generates the traffic. The proposed work is divided into two phases which can be executed in parallel. In general, the hackers or illegitimate user floods the traffic and uses more bandwidth. In first phase, the analysis of the dynamic traffic and effectively differentiating the genuine traffic and attacker’s traffic is done in the proposed algorithm. The packet analyzer is responsible to identify the genuine packets from the flooding traffic. In second phase, the CPU utilization is monitored and the process consuming more CPU power or the source is illegitimate, the process is rejected. The simulation is carried by using the OPNET simulator. The simulation results are tested with three different scenarios. It is proved that the proposed model has efficient response time and it has better efficiency in DDoS prone zones.},
  archive      = {J_EI},
  author       = {Shaik Mohammed Penukonda, Qubeb and Paramasivam, Ilango},
  doi          = {10.1007/s12065-019-00244-3},
  journal      = {Evolutionary Intelligence},
  month        = {6},
  number       = {2},
  pages        = {395-404},
  shortjournal = {Evol. Intell.},
  title        = {Design and analysis of behaviour based DDoS detection algorithm for data centres in cloud},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Automated cloud service based quality requirement
classification for software requirement specification. <em>EI</em>,
<em>14</em>(2), 389–394. (<a
href="https://doi.org/10.1007/s12065-019-00241-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The scale of software is growing rapidly for organizations begin to deploy their business on internet. It is a need of avoid ambiguity between engineers and users and to avoid mistakes in software requirements. And provide automatic requirement analysis techniques for modeling and analyzing requirements formally and save manpower. In this paper proposed cloud service method for automated detection of quality requirement in software requirement specification. This paper also present novel approach for process of automatic classification of software quality requirements based on supervised machine learning technique applied for the classification of training document and predict target document software quality requirements.},
  archive      = {J_EI},
  author       = {Merugu, R Raja Ramesh and Chinnam, Satyananda Reddy},
  doi          = {10.1007/s12065-019-00241-6},
  journal      = {Evolutionary Intelligence},
  month        = {6},
  number       = {2},
  pages        = {389-394},
  shortjournal = {Evol. Intell.},
  title        = {Automated cloud service based quality requirement classification for software requirement specification},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Genetic algorithm for quality of service based resource
allocation in cloud computing. <em>EI</em>, <em>14</em>(2), 381–387. (<a
href="https://doi.org/10.1007/s12065-019-00233-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the recent years, cloud computing has emerged as one of the important fields in the information technology. Cloud offers different types of services to the web applications. The major issue faced by cloud customers are selecting the resources for their application deployment without compromising the quality of service (QoS) requirements. This paper proposed the improved optimization algorithm for resource allocation by considering the objectives of minimizing the deployment cost and improving the QoS performance. The proposed algorithm considers different customer QoS requirements and allocates the resources within the given budget. The experimental analysis is conducted on various workloads by deploying into the Amazon Web Services. The results shows the efficiency of the proposed algorithm.},
  archive      = {J_EI},
  author       = {Devarasetty, Prasad and Reddy, Satyananda},
  doi          = {10.1007/s12065-019-00233-6},
  journal      = {Evolutionary Intelligence},
  month        = {6},
  number       = {2},
  pages        = {381-387},
  shortjournal = {Evol. Intell.},
  title        = {Genetic algorithm for quality of service based resource allocation in cloud computing},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Categorization of intercloud users and auto-scaling of
resources. <em>EI</em>, <em>14</em>(2), 369–379. (<a
href="https://doi.org/10.1007/s12065-019-00220-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optimal allocation of resources in Intercloud computing is NP-complete program. Constraints are many and configuration of each cloud varies from each other. The mapping of the tasks to available virtual machines is challenging. In real life scenarios customer requirements may change. The complexity of the problem increases as requirement changes in terms of capacity, speed and time. To tide overfrequent changes in customer requirement and optimum utilization of available resources, a heuristic algorithm is proposed which will fit to the specification. The proposed algorithm is primarily divided into three phases, namely categorization of users, genetic algorithm-based resource allocation and earliest deadline first scheduling. The objective is to map the tasks to be executed to available VMs of the multi-cloud federation in order to have minimum makespan time and maximum customer satisfaction. After pr simulation on synthetic data, compared the simulation results with the existing scheduling algorithm. Results of the simulation confirm that the proposed categorization of the user in cloud domain can be beneficial in many folds and can address the existing challenges as per concerned metrics.},
  archive      = {J_EI},
  author       = {Jena, Tamanna and Mohanty, J. R. and Satapathy, Suresh Chandra},
  doi          = {10.1007/s12065-019-00220-x},
  journal      = {Evolutionary Intelligence},
  month        = {6},
  number       = {2},
  pages        = {369-379},
  shortjournal = {Evol. Intell.},
  title        = {Categorization of intercloud users and auto-scaling of resources},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Deluge based genetic algorithm for feature selection.
<em>EI</em>, <em>14</em>(2), 357–367. (<a
href="https://doi.org/10.1007/s12065-019-00218-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selection methods are used to identify and remove irrelevant and redundant attributes from the original feature vector that do not have much contribution to enhance the performance of a predictive model. Meta-heuristic feature selection algorithms, used as a solution to this problem, need to have a good trade-off between exploitation and exploration of the search space. Genetic Algorithm (GA), a popular meta-heuristic algorithm, lacks exploitation capability, which in turn affects the local search ability of the algorithm. Basically, GA uses mutation operation to take care of exploitation which has certain limitations. As a result, GA gets stuck in local optima. To encounter this problem, in the present work, we have intelligently blended the Great Deluge Algorithm (GDA), a local search algorithm, with GA. Here GDA is used in place of mutation operation of the GA. Application of GDA yields a high degree of exploitation through the use of perturbation of candidate solutions. The proposed method is named as Deluge based Genetic Algorithm (DGA). We have applied the DGA on 15 publicly available standard datasets taken from the UCI dataset repository. To show the classifier independent nature of the proposed feature selection method, we have used 3 different classifiers namely K-Nearest Neighbour (KNN), Multi-layer Perceptron (MLP) and Support Vector Machine (SVM). Comparison of DGA has been performed with other contemporary algorithms like the basic version of GA, Particle Swarm Optimisation (PSO), Simulated Annealing (SA) and Histogram based Multi-Objective GA (HMOGA). From the comparison results, it has been observed that DGA performs much better than others in most of the cases. Thus, our main contributions in this paper are introduction of a new variant of GA for FS which uses GDA to strengthen its exploitational ability and application of the proposed method on 15 well-known UCI datasets using KNN, MLP and SVM classifiers.},
  archive      = {J_EI},
  author       = {Guha, Ritam and Ghosh, Manosij and Kapri, Souvik and Shaw, Sushant and Mutsuddi, Shyok and Bhateja, Vikrant and Sarkar, Ram},
  doi          = {10.1007/s12065-019-00218-5},
  journal      = {Evolutionary Intelligence},
  month        = {6},
  number       = {2},
  pages        = {357-367},
  shortjournal = {Evol. Intell.},
  title        = {Deluge based genetic algorithm for feature selection},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Performance evaluation of multilevel inverter based hybrid
active filter using soft computing techniques. <em>EI</em>,
<em>14</em>(2), 345–355. (<a
href="https://doi.org/10.1007/s12065-019-00217-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a multilevel inverter based shunt hybrid active filter is used, which is composed of passive filter and shunt active filter, used for enhancing the quality of power, by reducing the total harmonic distortions below 5% as per IEEE-519 standard and managing the reactive power as well as correcting the power factor. The objective of this paper is to advance the power quality by reducing the harmonic distortions in the distribution line, which are affected because of utilising non-linear loads across the load end. For reference current generation and for controlling the switching signal, conventionally PI controller was used with different reference signal detection techniques. But with the evolution of different intelligence approaches, made more advantageous than the PI controller. In this paper, two artificial intelligence methods, i.e, artificial neural network and adaptive neuro-fuzzy interference system (ANFIS) are applied. Comparison of the results of the proposed methods is analysed using MATLAB/ SIMULINK tool. For reference current generation, synchronous reference frame theory is used and hysteresis current control technique is employed for generating the gating signal.},
  archive      = {J_EI},
  author       = {Das, Soumya Ranjan and Ray, Prakash K. and Mohanty, Asit and Das, Himansu},
  doi          = {10.1007/s12065-019-00217-6},
  journal      = {Evolutionary Intelligence},
  month        = {6},
  number       = {2},
  pages        = {345-355},
  shortjournal = {Evol. Intell.},
  title        = {Performance evaluation of multilevel inverter based hybrid active filter using soft computing techniques},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Data storage in cellular DNA: Contextualizing diverse
encoding schemes. <em>EI</em>, <em>14</em>(2), 331–343. (<a
href="https://doi.org/10.1007/s12065-019-00202-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nature has been using DNA to store biological data for millions of years, and finally humans are learning to use the same medium for our own data. In this paper, we survey the field of cellular DNA encoding, where encoding schemes are used to insert data into pcDNA and ncDNA areas while bypassing the biological restrictions associated with those areas. We first characterize the unique bio-restrictions associated with existing cellular DNA encoding schemes, then we contrast the schemes with respect to the restrictions they meet, supported features, and implementation details. We discuss the pros and cons of the implementation of each encoding scheme, and make recommendations accordingly. Finally, we highlight existing gaps, and provide our insight into future research directions.},
  archive      = {J_EI},
  author       = {Dagher, Gaby G. and Machado, Anthony P. and Davis, Eddie C. and Green, Thomas and Martin, John and Ferguson, Matthew},
  doi          = {10.1007/s12065-019-00202-z},
  journal      = {Evolutionary Intelligence},
  month        = {6},
  number       = {2},
  pages        = {331-343},
  shortjournal = {Evol. Intell.},
  title        = {Data storage in cellular DNA: Contextualizing diverse encoding schemes},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Threshold estimation from software metrics by using
evolutionary techniques and its proposed algorithms, models.
<em>EI</em>, <em>14</em>(2), 315–329. (<a
href="https://doi.org/10.1007/s12065-019-00201-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The software metrics play the important role in the software industry. As the software industry growing in size and complexity enhanced support is mandatory for computing and managing the software quality. Quality measurement is one of the key features of the manager in the software industry; where threshold plays the crucial role. Software measurement is necessary by means for evaluating different quality attributes and characteristics, such as size, complexity, maintainability, and usability. Instead of that effective and efficient software system is straightforward dependent on the meaning of suitable thresholds. The objective of this paper is to estimate the threshold values from software metrics by using novel evolutionary intelligence techniques. The threshold and aging software design optimization algorithms and models to prevent software aging by using machine learning (evolutionary algorithms). Apart from the above-mentioned techniques, this paper also proposed a novel threshold estimation, aging, and survivability aware (sensitive) reusability optimization model of an object-oriented software system. To expand firmness, aging and survivability aware (sensitive) optimization threshold scheme aging prediction and software rejuvenation model and algorithms proposed.},
  archive      = {J_EI},
  author       = {Padhy, Neelamadhab and Panigrahi, Rasmita and Neeraja, K.},
  doi          = {10.1007/s12065-019-00201-0},
  journal      = {Evolutionary Intelligence},
  month        = {6},
  number       = {2},
  pages        = {315-329},
  shortjournal = {Evol. Intell.},
  title        = {Threshold estimation from software metrics by using evolutionary techniques and its proposed algorithms, models},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Particle swarm optimization with adaptive inertia weight
based on cumulative binomial probability. <em>EI</em>, <em>14</em>(2),
305–313. (<a href="https://doi.org/10.1007/s12065-018-0188-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Particle swarm optimization (PSO) is a population oriented heuristic numerical optimization algorithm, influenced by the combined behavior of some birds. Since its introduction in 1995, a large number of variants of PSO algorithm have been introduced that improves its performance. The performance of the algorithm mostly rely upon inertia weight and optimal parameter setting. Inertia weight brings equivalence among exploitation and exploration while searching optimal solution within the search region. This paper presents a new improved version of PSO that uses adaptive inertia weight technique which is based on cumulative binomial probability (CBPPSO). The proposed approach along with four other PSO variants are tested over a set of ten well-known optimization test problems. The result confirms that the performance of proposed algorithm (CBPPSO) is better than other PSO variants in most of the cases. Also, the proposed algorithm has been evaluated on three real-world engineering problems and the results obtained are promising.},
  archive      = {J_EI},
  author       = {Agrawal, Ankit and Tripathi, Sarsij},
  doi          = {10.1007/s12065-018-0188-7},
  journal      = {Evolutionary Intelligence},
  month        = {6},
  number       = {2},
  pages        = {305-313},
  shortjournal = {Evol. Intell.},
  title        = {Particle swarm optimization with adaptive inertia weight based on cumulative binomial probability},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Automated soil prediction using bag-of-features and chaotic
spider monkey optimization algorithm. <em>EI</em>, <em>14</em>(2),
293–304. (<a href="https://doi.org/10.1007/s12065-018-0186-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A proper soil prediction is one of the most important parameters to decide the suitable crop which is generally performed manually by the farmers. Therefore, the efficiency of the farmers may be increased by producing an automated tools for soil prediction. This paper presents an automated system for categorization of the soil datasets into respective categories using images of the soils which can further be used for the decision of crops. For the same, a novel Bag-of-words and chaotic spider monkey optimization based method has been proposed which is used to classify the soil images into its respective categories. The novel chaotic spider monkey optimization algorithm shows desirable convergence and improved global search ability over standard benchmark functions. Hence, it has been used to cluster the keypoints in Bag-of-words method for soil prediction. The experimental outcomes illustrate that the anticipated methods effectively classify the soil in comparison to other meta-heuristic based methods.},
  archive      = {J_EI},
  author       = {Kumar, Sandeep and Sharma, Basudev and Sharma, Vivek Kumar and Poonia, Ramesh C.},
  doi          = {10.1007/s12065-018-0186-9},
  journal      = {Evolutionary Intelligence},
  month        = {6},
  number       = {2},
  pages        = {293-304},
  shortjournal = {Evol. Intell.},
  title        = {Automated soil prediction using bag-of-features and chaotic spider monkey optimization algorithm},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An application of artificial neural network classifier to
analyze the behavioral traits of smallholder farmers in kenya.
<em>EI</em>, <em>14</em>(2), 281–291. (<a
href="https://doi.org/10.1007/s12065-018-0180-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper develops and employs a novel artificial neural network (ANN) model to study farmers’ behavior towards decision making on maize production in Kenya. The paper has compared the accuracy level of ANN based models and the statistical model. The results show that the ANN models has achieved higher accuracy and efficiency. The findings from the study reveal that the farmers are mostly influenced by their demographic characteristics and food security conditions in their decision making. Further to examine the relative importance of different demographic and food security characteristics, an ANOVA test is undertaken. The results found that education and food security indices are instrumental in influencing farmers’ decision making.},
  archive      = {J_EI},
  author       = {Jena, Pradyot Ranjan and Majhi, Ritanjali},
  doi          = {10.1007/s12065-018-0180-2},
  journal      = {Evolutionary Intelligence},
  month        = {6},
  number       = {2},
  pages        = {281-291},
  shortjournal = {Evol. Intell.},
  title        = {An application of artificial neural network classifier to analyze the behavioral traits of smallholder farmers in kenya},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). PSO based combined kernel learning framework for recognition
of first-person activity in a video. <em>EI</em>, <em>14</em>(2),
273–279. (<a href="https://doi.org/10.1007/s12065-018-0177-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents human activity recognition problem from first-person view-point (ego-centric video). The task is to understand the activities of a person by an observer (wearable camera or robot) from real-time video data. An efficient human activity recognition system demands the choice of useful traits and the suitable kernels for those traits. In this work, we have proposed a combined kernel learning (CKL) framework using PSO as optimization algorithm for first-person activity recognition in a video. This framework does appropriate feature selection and combines those features from their respective kernels from the video data in a productive way. The proposed algorithm learns an optimal composite kernel from the combination of the basis kernel constructed from different motion-related features of the first-person video. To determine both basis kernel and their combination, this method can optimize a data-dependent kernel evaluation measure. The performance of the proposed CKL is evaluated by combining different types of motion features from the first-person video (JPL-interaction dataset). The result shows a comparatively better rate of accuracy than that of other state-of-the-art human activity recognition methods.},
  archive      = {J_EI},
  author       = {Mishra, Soumya Ranjan and Mishra, Tusar Kanti and Sarkar, Anirban and Sanyal, Goutam},
  doi          = {10.1007/s12065-018-0177-x},
  journal      = {Evolutionary Intelligence},
  month        = {6},
  number       = {2},
  pages        = {273-279},
  shortjournal = {Evol. Intell.},
  title        = {PSO based combined kernel learning framework for recognition of first-person activity in a video},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Assessment of electromyograms using genetic algorithm and
artificial neural networks. <em>EI</em>, <em>14</em>(2), 261–271. (<a
href="https://doi.org/10.1007/s12065-018-0174-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The recorded electrical activity associated with muscles and nerves are called electromyograms (EMG) and are useful for examination of disorders in the muscle and nerve systems. The efficient discrimination of normal and abnormal EMG signals play vital role in the automated diagnostic assistance tools. Hence, the proper extraction of feature subset, selection of best feature subset and development of classifier model were essential to differentiate the abnormal and normal signals. In this paper, a total of 80 time–frequency features of normal, myopathy and Amyotrophic Lateral Sclerosis (ALS) EMG signals were extricated using four different transformation approach namely Stockwell, Synchro-Extracting, Wigner–Ville and Short-TIme Fourier Transform. The selection of 15 significant features was performed using Genetic Algorithm (GA). Also, the statistical significance of the selected features were analyzed using three different classification models of normal, myopathy, ALS cases. Further, the artificial neural network (ANN) classifiers were developed individually for extracted transformed time–frequency features and GA selected features. Results demonstrated that the selected features by genetic algorithm are efficient for the design of EMG classifiers.},
  archive      = {J_EI},
  author       = {Ambikapathy, Bakiya and Kirshnamurthy, Kamalanand and Venkatesan, Rajinikanth},
  doi          = {10.1007/s12065-018-0174-0},
  journal      = {Evolutionary Intelligence},
  month        = {6},
  number       = {2},
  pages        = {261-271},
  shortjournal = {Evol. Intell.},
  title        = {Assessment of electromyograms using genetic algorithm and artificial neural networks},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A novel improved prediction of protein structural class
using deep recurrent neural network. <em>EI</em>, <em>14</em>(2),
253–260. (<a href="https://doi.org/10.1007/s12065-018-0171-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For last few decades, sequence arrangement of amino acids have been utilized for the prediction of protein secondary structure. Recent methods have applied high dimensional natural language based features in machine learning models. Performance measures of machine learning based models are significantly affected by data size and data dimensionality. It is a huge challenge to develop a generic model which can be trained to perform both for small and large sized datasets in a low dimensional framework. In the present research, we suggest a low dimensional representation for both small and large sized datasets. A hybrid space of Atchley’s factors II, IV, V, electron ion interaction potential and SkipGram based word2vec have been employed for amino acid sequence representation. Subsequently Stockwell transformation is applied to the representation to preserve features both in time and frequency domains. Finally, deep gated recurrent network with dropout, categorical-cross entropy error estimation and Adam optimization is used for classification purpose. The introduced method results in better prediction accuracies for both small (204,277, and 498) and large sized (PDB25, Protein 640 and FC699) bench mark data sets of low sequence similarity (25–40%). The obtained classification accuracies for PDB25, 640, FC699, 498, 277, 204 datasets are 84.2%, 94.31%, 93.1%, 95.9%, 94.5% and 85.36% respectively. The major contributions in this research is that, for the first time, we verify the protein secondary structural class prediction in a very low dimensional (18-D) feature space with a novel feature representation method. Secondly, we also verify for the first time, the behaviour of deep networks for low dimensional small sized data sets.},
  archive      = {J_EI},
  author       = {Panda, Bishnupriya and Majhi, Babita},
  doi          = {10.1007/s12065-018-0171-3},
  journal      = {Evolutionary Intelligence},
  month        = {6},
  number       = {2},
  pages        = {253-260},
  shortjournal = {Evol. Intell.},
  title        = {A novel improved prediction of protein structural class using deep recurrent neural network},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Velocity adaptation based PSO for localization in wireless
sensor networks. <em>EI</em>, <em>14</em>(2), 243–251. (<a
href="https://doi.org/10.1007/s12065-018-0170-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wireless sensor networks are a network of sensors interconnected through a wireless medium. Wireless sensor networks are utilized for many array of applications where determining precise location of the sensors are treated to be the crucial task. The prime job of localization is to determine the exact location of sensors placed at particular area as it makes the reference of anchor nodes to determine the location of remaining nodes in the network. Position information of sensor node in an area is useful for routing techniques and some application specific tasks. The localization accuracy is affected due to the estimations in anchor node placements. Localization information is not always easy as it varies with respect to the environment in which the sensors are deployed. Ranging errors occur in hostile environments and accuracy effects as there are signal attenuations in sensors when deployed underwater, underground etc. Efficiency can be enhanced by reducing the error using localization algorithms. Particle swarm optimization is one approach to overcome the localization problem. Results are considered for localization algorithms like Particle swarm optimization, Social group optimization and Velocity adaptation based Particle swarm optimization. The goal of this work is to implement a velocity adaptation based particle swarm optimization for localization method to achieve minimum error. The results reveal that the proposed approach works better for obtaining improved location accuracy.},
  archive      = {J_EI},
  author       = {Nagireddy, Vyshnavi and Parwekar, Pritee and Mishra, Tusar Kanti},
  doi          = {10.1007/s12065-018-0170-4},
  journal      = {Evolutionary Intelligence},
  month        = {6},
  number       = {2},
  pages        = {243-251},
  shortjournal = {Evol. Intell.},
  title        = {Velocity adaptation based PSO for localization in wireless sensor networks},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Mesh smoothing of complex geometry using variations of
cohort intelligence algorithm. <em>EI</em>, <em>14</em>(2), 227–242. (<a
href="https://doi.org/10.1007/s12065-018-0166-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Several approaches including optimization based methods were developed for mesh quality improvement using only node movement, keeping intact the element connectivity. In this research, a socio-inspired optimization approach referred to as cohort intelligence (CI) was investigated for mesh smoothing. Minimization of summation of condition numbers of all elements was the final aim. The geometrical boundaries of the object defined the surface and edge constraints for movement of external nodes. Movement of internal nodes was completely governed by variations of CI algorithm, viz. roulette wheel, follow best, follow better, alienation and random selection, follow worst and follow itself. The approach was demonstrated with pentagonal prism, hexagonal prism and hexagonal prism with hole. The performance of follow best and roulette wheel variations of CI algorithm was observed to be satisfactory as compared to other variations of the algorithm.},
  archive      = {J_EI},
  author       = {Sapre, Mandar S. and Kulkarni, Anand J. and Chettiar, Lakshmanan and Deshpande, Ishani and Piprikar, Bharat},
  doi          = {10.1007/s12065-018-0166-0},
  journal      = {Evolutionary Intelligence},
  month        = {6},
  number       = {2},
  pages        = {227-242},
  shortjournal = {Evol. Intell.},
  title        = {Mesh smoothing of complex geometry using variations of cohort intelligence algorithm},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Gray level run length matrix based on various illumination
normalization techniques for texture classification. <em>EI</em>,
<em>14</em>(2), 217–226. (<a
href="https://doi.org/10.1007/s12065-018-0164-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Texture classification under varying illumination conditions is one of the most important challenges. This paper presents a new texture classification approach by taking the combinations of robust illumination normalization techniques applied on gray level run length matrix (GLRLM) for texture features extraction. The purpose of selecting the GRLM, as texture descriptor is that, it extracts information of an image from its gray level runs. A set of consecutive, collinear picture points having the same gray level values is considered as a gray level run. The textured materials usually go through a deep change in their images with variations in illumination and camera pose. For instance, keeping all the parameters fixed but just changing the scale and rotation can result in a completely new texture. Hence, change in gray level values also occurred. Dealing with these variations successfully by utilizing GRLM descriptor for texture classification is the main purpose of this paper. In the suggested approach, 2D wavelet, Tan and Triggs (TT) normalization methods are employed to compensate illumination variations. Experimental results on the Brodatz, VisTex, STex and ALOT databases show that the suggested approach improves the performance significantly as compared to the classical GLRLM descriptor.},
  archive      = {J_EI},
  author       = {Dash, Sonali and Senapati, Manas Ranjan},
  doi          = {10.1007/s12065-018-0164-2},
  journal      = {Evolutionary Intelligence},
  month        = {6},
  number       = {2},
  pages        = {217-226},
  shortjournal = {Evol. Intell.},
  title        = {Gray level run length matrix based on various illumination normalization techniques for texture classification},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Location estimation of non-geo-tagged tweets. <em>EI</em>,
<em>14</em>(2), 205–216. (<a
href="https://doi.org/10.1007/s12065-018-0163-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Internet users are getting more and more dependent for information regarding their daily lives. Most of the users are connected to each other using social networks. Social networking sites not only helps the users to connect and talk to each other but also share information with each other. Twitter [1] users attach their location information with the post or tweet to show their presence at the location. But, not all users tags or integrate the location information within the post. If a person wants to obtain the latest updates about an event then he/she have to go through all the tweets about that event, which is impossible because nearly 500 million tweets are posted on Twitter on a daily basis. Using Twitter the users can post up to 140 characters in their posts or tweet. Also, the tweets that originate from the location of the event are latest and contain new facts and the rest of the tweets convey that information only. Non-geo-tagged tweets are eliminated by the traditional systems. This paper presents a method to tag the non-geo-tagged tweets with the location then the user would be able to obtain the latest information by including the new. The proposed method performs better than previous methods and yields better results.},
  archive      = {J_EI},
  author       = {Samuel, Avinash and Sharma, Dilip Kumar},
  doi          = {10.1007/s12065-018-0163-3},
  journal      = {Evolutionary Intelligence},
  month        = {6},
  number       = {2},
  pages        = {205-216},
  shortjournal = {Evol. Intell.},
  title        = {Location estimation of non-geo-tagged tweets},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Evolutionary intelligence techniques for humanized
computing. <em>EI</em>, <em>14</em>(2), 203. (<a
href="https://doi.org/10.1007/s12065-021-00617-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_EI},
  author       = {Satapathy, Suresh Chandra and Yang, Xin-She and Bhateja, Vikrant},
  doi          = {10.1007/s12065-021-00617-7},
  journal      = {Evolutionary Intelligence},
  month        = {6},
  number       = {2},
  pages        = {203},
  shortjournal = {Evol. Intell.},
  title        = {Evolutionary intelligence techniques for humanized computing},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-agent path planning with nonlinear restrictions.
<em>EI</em>, <em>14</em>(1), 191–201. (<a
href="https://doi.org/10.1007/s12065-020-00534-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a novel simplified mathematical modeling that can solve a path planning problem comprising three agents in a triangular formation. The problem is modeled to optimize the trajectories of the agents and to minimize the distances traveled. The trajectories are obtained in a way that deviates them from fixed obstacles whose dimensions are known. Furthermore, geometry and orientation constraints of the formation of the multi-agent are imposed. Heuristics methods such as the Genetic Algorithm, Differential Evolution and Particle Swarm Optimization are applied to solve the non-linear algebraic equations which represent the system. Comparisons are presented among the results of the different methods highlighting the processing time and the convergence to the global minimum solution. The results prove that all the algorithms can be applied to the path planning problem with constraints. The Particle Swarm Optimization method presents the lowest processing time for all simulated cases. However, the Differential Evolution method is more robust than the others when searching for the global minimum solution.},
  archive      = {J_EI},
  author       = {de Lima, Juliana Veiga C. F. and Belo, Eduardo Morgado and Marques, Vinícius Abrão da Silva},
  doi          = {10.1007/s12065-020-00534-1},
  journal      = {Evolutionary Intelligence},
  month        = {3},
  number       = {1},
  pages        = {191-201},
  shortjournal = {Evol. Intell.},
  title        = {Multi-agent path planning with nonlinear restrictions},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Hyper-parameter tuned deep q network for area estimation of
oil spills: A meta-heuristic approach. <em>EI</em>, <em>14</em>(1),
175–190. (<a href="https://doi.org/10.1007/s12065-020-00500-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Oil Spills near shoreline are a major environmental hazard. Rapid estimation of spill perimeter provides a quick estimate of its area extent thus facilitating its quick removal. In this study; a meta-heuristic algorithm; “Gamma-Levy Hybrid Meta-heuristic with Conditional Evolution (GLHM-CE)” is proposed. The proposed algorithm is then used to evolve a distributed control strategy for a swarm of unmanned aerial vehicles for rapid confinement and estimation of spill perimeter. Every agent is controlled by a Deep Q Network whose Hyper-Parameters are tuned by GLHM-CE. Evaluation of GLHM-CE over 28 Blackbox Problems of CEC-2013,Special Session on Real-Parameter Optimization and its comparison with evolutionary algorithms like SHADE,Co-DE and JADE reveals that GLHM-CE successfully evades local minima and has a fast convergence. The effectiveness in hyper-parameter tuning of a Deep Q Network by GLHM-CE was evaluated over the quintessential CartPole problem from OpenAI Gym framework.},
  archive      = {J_EI},
  author       = {Banerjee, Abhiit and Ghosh, Dipendranath and Das, Suvrojit},
  doi          = {10.1007/s12065-020-00500-x},
  journal      = {Evolutionary Intelligence},
  month        = {3},
  number       = {1},
  pages        = {175-190},
  shortjournal = {Evol. Intell.},
  title        = {Hyper-parameter tuned deep q network for area estimation of oil spills: A meta-heuristic approach},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). On the cryptanalysis of s-DES using nature inspired
optimization algorithms. <em>EI</em>, <em>14</em>(1), 163–173. (<a
href="https://doi.org/10.1007/s12065-020-00417-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cryptanalysis has emerged to be an important topic in the era of modern emerging technologies. The cryptanalysis of Simplified Data Encryption Standard (S-DES) is a NP-Hard combinatorial problem. This paper has two goals. Firstly, we study the cryptanalysis of S-DES via nature-inspired meta-heuristic algorithms namely Cuckoo Search, Firefly and Black-Hole Optimization Algorithms. Each of these algorithms is based on fascinating natural phenomena and exploits the inherent uniqueness of such phenomena to solve optimization problems. Secondly, we present a comparative study on the efficiency of these three fairly new algorithms with that of previously established Memetic Algorithm and Genetic Algorithms in regard to S-DES cryptanalysis. Through experimentations and extensive tests, it has been shown that the proposed algorithm based on Cuckoo Search proves to be most efficient with respect to accuracy and execution time.},
  archive      = {J_EI},
  author       = {Kamal, Ritwiz and Bag, Moynak and Kule, Malay},
  doi          = {10.1007/s12065-020-00417-5},
  journal      = {Evolutionary Intelligence},
  month        = {3},
  number       = {1},
  pages        = {163-173},
  shortjournal = {Evol. Intell.},
  title        = {On the cryptanalysis of S-DES using nature inspired optimization algorithms},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). RETRACTED ARTICLE: Ensemble learning with recursive feature
elimination integrated software effort estimation: A novel approach.
<em>EI</em>, <em>14</em>(1), 151–162. (<a
href="https://doi.org/10.1007/s12065-020-00360-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To develop software, estimating actual effort is important for any organization as there is no chance of getting either overestimation or underestimation. Due to the overestimation of effort, there may be an immediate need to compromise with the quality and testing. Similarly, underestimation may lead to allocating more resource. Compared to some of the early developed estimation techniques, machine learning based approaches are keen to estimate the effort more accurately due to their dynamic adaptivity with any type of data. With the rapid development of software products, many methods fail to satisfy the objective of development in an effective way. In this paper, a novel model based on ensemble learning and recursive feature elimination based method has been proposed to estimate the effort. With the feature ranking and selection method, the proposed method is able to estimate the efforts with the parameters like size and cost. Simulation results are encouraging with the proposed method with COCOMO II dataset.},
  archive      = {J_EI},
  author       = {Rao, K. Eswara and Rao, G. Appa},
  doi          = {10.1007/s12065-020-00360-5},
  journal      = {Evolutionary Intelligence},
  month        = {3},
  number       = {1},
  pages        = {151-162},
  shortjournal = {Evol. Intell.},
  title        = {RETRACTED ARTICLE: ensemble learning with recursive feature elimination integrated software effort estimation: a novel approach},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A novel stacked sparse denoising autoencoder for mammography
restoration to visual interpretation of breast lesion. <em>EI</em>,
<em>14</em>(1), 133–149. (<a
href="https://doi.org/10.1007/s12065-019-00344-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a deep unsupervised learning based denoising autoencoder model for the restoration of degraded mammogram with visual interpretation of breast lumps or lesion in mammography images (called SSDAE). The proposed model attempts to intensify the underexposed and abnormal structural regions through noise elimination in mammography image. A deep stacked convolutional autoencoder is designed by combining the autoencoder and the deconvolution network which conjointly reduces noisy artifacts and improves image details in mammogram. The proposed SSDAE model takes large noisy mammogram image patches as input and extracts relevant features from target batches. The suggested model can extract relevant features and reduce the dimensionality through sparsity property of the image data while preserving the key features that have been applied to restore image data in feature space. In order to reconstruct a deafening mammogram, the proposed model is carried out through a patched base training on samples to suppress noise thereby preserving structural details in mammography imaging. Experimental results authenticate that the suggested SSDAE model outplays a number of state-of-the-art methods for both X-ray mammogram and ultrasonographic mammogram. The execution speed for target noisy images increases with fine tuning of the network when compared to other algorithms.},
  archive      = {J_EI},
  author       = {Ghosh, Swarup Kr and Biswas, Biswajit and Ghosh, Anupam},
  doi          = {10.1007/s12065-019-00344-0},
  journal      = {Evolutionary Intelligence},
  month        = {3},
  number       = {1},
  pages        = {133-149},
  shortjournal = {Evol. Intell.},
  title        = {A novel stacked sparse denoising autoencoder for mammography restoration to visual interpretation of breast lesion},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). On accurate localization of sensor nodes in underwater
sensor networks: A doppler shift and modified genetic algorithm based
localization technique. <em>EI</em>, <em>14</em>(1), 119–131. (<a
href="https://doi.org/10.1007/s12065-019-00343-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The problem of localization in under water sensor nodes has led to proposal of many techniques over the past few decades that depend primarily on Time of Arrival and Time Difference of Arrival. While these techniques are intuitively very appealing and easy to deploy, accurate node localization in dynamic under water environment has remained elusive. Sensor nodes deployed underwater tend to move from their original positions due to water currents and hence their exact positions at a given moment of time are not known with precision. Due to inherent drawbacks of radio signal propagation in underwater environment, localization of sensor nodes depends on acoustic signals. In this paper, we propose a Doppler shift based localization followed by a genetic algorithm based optimization technique that improves accuracy in localizing unknown nodes in underwater sensor networks. The proposed technique envisages sink nodes playing a pivotal role in taking over a bulk of the computational load on account of being comparatively more accessible and serviceable as compared to any other nodes in the network that are deployed underwater. The algorithm relies on observed frequency shifts (Doppler shift) of sound waves compared to actual, that happen when source and observer are mobile as they do in a marine environment. While Doppler shift determines the approximate location of an unknown sensor node, genetic algorithm minimizes the error in localization. Our proposed methodology has much lower localization error as compared to existing protocols.},
  archive      = {J_EI},
  author       = {Datta, Amrita and Dasgupta, Mou},
  doi          = {10.1007/s12065-019-00343-1},
  journal      = {Evolutionary Intelligence},
  month        = {3},
  number       = {1},
  pages        = {119-131},
  shortjournal = {Evol. Intell.},
  title        = {On accurate localization of sensor nodes in underwater sensor networks: A doppler shift and modified genetic algorithm based localization technique},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). MC/DC guided test sequence prioritization using firefly
algorithm. <em>EI</em>, <em>14</em>(1), 105–118. (<a
href="https://doi.org/10.1007/s12065-019-00322-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optimization of the regression testing process has been playing an important role in developing quality software. Still, it is difficult to achieve satisfactory results on the generation of non-redundant and optimized test sequences. There are many optimization techniques applied to regression testing. Firefly algorithm (FA) has gained its popularity as an optimization technique to provide better solutions in the areas of science and engineering. But, the original FA needs to have a better or modified objective function. This work uses FA with an improvised objective function to generate optimal test paths guided by “Modified Condition/Decision Coverage” (MC/DC) criteria in the form of a guided matrix. This matrix is built with MC/DC influence values that we obtained from the predicate nodes of “control flow graph” (CFG). This guided matrix also helps in measuring the fault-finding potential of a node. It also helps in routing fireflies to move between the nodes of a CFG. We have chosen MC/DC criteria, as it is the second strongest code coverage criteria due to its linear time complexity. Then, FA is used by defining an appropriate objective function to traverse the graph using fireflies. We obtain optimal test sequences after executing the FA. These test sequences are ranked by computing the mean brightness of nodes along a path and then prioritized based on their ranks. Our simulation and comparison are validated by experimenting on several moderate sized Java programs.},
  archive      = {J_EI},
  author       = {Barisal, Swadhin Kumar and Dutta, Arpita and Godboley, Sangharatna and Sahoo, Bibhudatta and Mohapatra, Durga Prasad},
  doi          = {10.1007/s12065-019-00322-6},
  journal      = {Evolutionary Intelligence},
  month        = {3},
  number       = {1},
  pages        = {105-118},
  shortjournal = {Evol. Intell.},
  title        = {MC/DC guided test sequence prioritization using firefly algorithm},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Software fault localization using BP neural network based on
function and branch coverage. <em>EI</em>, <em>14</em>(1), 87–104. (<a
href="https://doi.org/10.1007/s12065-019-00318-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Software failure is inevitable with the increase in scale and complexity of the software. Existing fault localization techniques based on neural networks take statement coverage information and test case execution results into account to train the network. In this paper, we propose an effective approach for fault localization based on back-propagation neural network which utilizes branch and function coverage information along with test case execution results to train the network. We investigated our approach using Siemens suite. Our experimental result shows that our proposed approach performs on average 23.50–44.27% better than existing fault localization techniques.},
  archive      = {J_EI},
  author       = {Maru, Abha and Dutta, Arpita and Kumar, K. Vinod and Mohapatra, Durga Prasad},
  doi          = {10.1007/s12065-019-00318-2},
  journal      = {Evolutionary Intelligence},
  month        = {3},
  number       = {1},
  pages        = {87-104},
  shortjournal = {Evol. Intell.},
  title        = {Software fault localization using BP neural network based on function and branch coverage},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Image compression using explored bat algorithm by renyi 2-d
histogram based on multilevel thresholding. <em>EI</em>, <em>14</em>(1),
75–85. (<a href="https://doi.org/10.1007/s12065-019-00313-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The main objective of the image compression is to extract meaningful clusters from a given image. A meaningful cluster is possible with perfect threshold values, which are optimized by assuming Renyi entropy as an objective function. Due to the equal distribution of energy over the entire 1-D histogram, it is computationally complex. In order to improve the visual quality of a reconstructed image, a 2-D histogram based multilevel thresholding is proposed to maximize the Renyi entropy using explored bat algorithm. Thus procured results are compared with other optimization techniques and these are incorporated. It is the first time, incorporating a weighted peak signal to noise ratio (WPSNR) and the visual PSNR (VPSNR) in the proposed method, because of the failure in measuring the visual quality of peak signal to noise ratio (PSNR). Experimental results are examined on a standard set of images, which are observed precisely and efficiently in the multilevel thresholding problem.},
  archive      = {J_EI},
  author       = {Manohar, V. and Laxminarayana, G. and Satya Savithri, T.},
  doi          = {10.1007/s12065-019-00313-7},
  journal      = {Evolutionary Intelligence},
  month        = {3},
  number       = {1},
  pages        = {75-85},
  shortjournal = {Evol. Intell.},
  title        = {Image compression using explored bat algorithm by renyi 2-d histogram based on multilevel thresholding},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Parameters tuning of a quadrotor PID controllers by using
nature-inspired algorithms. <em>EI</em>, <em>14</em>(1), 61–73. (<a
href="https://doi.org/10.1007/s12065-019-00312-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper aims to investigate the control of a quadrotor by PID controller. The mathematical model is derived from Euler–Lagrange approach. Due to nonlinearities, coupling and under-actuation constraints, the model imposes difficulties to generate its controller by using classic ways. Firstly, we have designed a control structure which weakens the couplings and permits to develop a decentralized control. Secondly, in order to get the optimal path tracking, the controllers’ parameters were tuned by stochastic nature-inspired algorithms; Genetic Algorithm, Evolution Strategies, Differential Evolutionary and Cuckoo Search. A comparison study between these algorithms according to the path tracking is carried out by implementing simulations under MATLAB/Simulink. The results show the efficiency of the proposed strategy where the optimization algorithms achieve good performance with a slight difference between the indicate techniques.},
  archive      = {J_EI},
  author       = {Hasseni, Seif-El-Islam and Abdou, Latifa and Glida, Hossam-Eddine},
  doi          = {10.1007/s12065-019-00312-8},
  journal      = {Evolutionary Intelligence},
  month        = {3},
  number       = {1},
  pages        = {61-73},
  shortjournal = {Evol. Intell.},
  title        = {Parameters tuning of a quadrotor PID controllers by using nature-inspired algorithms},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). UIDS: A unified intrusion detection system for IoT
environment. <em>EI</em>, <em>14</em>(1), 47–59. (<a
href="https://doi.org/10.1007/s12065-019-00291-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intrusion detection system (IDS) using machine learning approach is getting popularity as it has an advantage of getting updated by itself to defend against any new type of attack. Another emerging technology, called internet of things (IoT) is taking the responsibility to make automated system by communicating the devices without human intervention. In IoT based systems, the wireless communication between several devices through the internet causes vulnerability for different security threats. This paper proposes a novel unified intrusion detection system for IoT environment (UIDS) to defend the network from four types of attacks such as: exploit, DoS, probe, and generic. The system is also able to detect normal category of network traffic. Most of the related works on IDS are based on KDD99 or NSL-KDD 99 data sets which are unable to detect new type of attacks. In this paper, UNSW-NB15 data set is considered as the benchmark dataset to design UIDS for detecting malicious activities in the network. The performance analysis proves that the attack detection rate of the proposed model is higher compared to two existing approaches ENADS and DENDRON which also worked on UNSW-NB15 data set.},
  archive      = {J_EI},
  author       = {Kumar, Vikash and Das, Ayan Kumar and Sinha, Ditipriya},
  doi          = {10.1007/s12065-019-00291-w},
  journal      = {Evolutionary Intelligence},
  month        = {3},
  number       = {1},
  pages        = {47-59},
  shortjournal = {Evol. Intell.},
  title        = {UIDS: A unified intrusion detection system for IoT environment},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Fuzzy clustering algorithm based on modified whale
optimization algorithm for automobile insurance fraud detection.
<em>EI</em>, <em>14</em>(1), 35–46. (<a
href="https://doi.org/10.1007/s12065-019-00260-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fuzzy c-means (FCM) clustering method is used for performing the task of clustering. This method is the most widely used among various clustering techniques. However, it gets easily stuck in the local optima. whale optimization algorithm (WOA) is a stochastic global optimization algorithm, which is used to find out global optima of a provided dataset. The WOA is further modified to achieve better global optimum. In this paper, a fuzzy clustering method has been proposed by using the strengths of both modified whale optimization algorithm (MWOA) and FCM. The effectiveness of the proposed clustering technique is evaluated by considering some of the well-known existing metrics. The proposed hybrid clustering method based on MWOA is employed as an under sampling method to optimize the cluster centroids in the proposed automobile insurance fraud detection system (AIFDS). In the AIFDS, first the majority sample data set is trimmed by removing the outliers using proposed fuzzy clustering method, and then the modified dataset is undergone with some advanced classifiers such as CATBoost, XGBoost, Random Forest, LightGBM and Decision Tree. The classifiers are evaluated by measuring the performance parameters such as sensitivity, specificity and accuracy. The proposed AIFDS consisting of fuzzy clustering based on MWOA and CATBoost performs better than other compared methods.},
  archive      = {J_EI},
  author       = {Majhi, Santosh Kumar},
  doi          = {10.1007/s12065-019-00260-3},
  journal      = {Evolutionary Intelligence},
  month        = {3},
  number       = {1},
  pages        = {35-46},
  shortjournal = {Evol. Intell.},
  title        = {Fuzzy clustering algorithm based on modified whale optimization algorithm for automobile insurance fraud detection},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Modified crash-minimization path designing approach for
autonomous material handling robot. <em>EI</em>, <em>14</em>(1), 21–34.
(<a href="https://doi.org/10.1007/s12065-019-00247-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The potentiality of particle swarm optimization (PSO), artificial potential field (APF) and improved PSO (IPSO) approaches are exploited in this paper for designing and generating the best possible optimum trajectory for a mobile material handling robot. The paper has an aim to develop a robot, which used to create a bridge between primary and secondary handling system. This principally saves the transportation time, so the total cycle time and manufacturing lead time can be reduced. For performing simulation practice two practical surroundings has been developed with a layout of institute machine shop and advanced laboratory. Objective of this study are to slash the track size, computational time, degree of crash risk, travel time and better path smoothness. To check the robustness and applicability of the approaches a comparison report has been prepared among their simulation and experimental outcomes. For surrounding setup-I; PSO algorithm provides 35.3568 m track length, 20.778 s computational time and 280.098 s travel time. Similarly the trajectory dimension, computational time and travel time generated in APF approach is 44.1632 m, 10.923 s and 343.441 s respectively. 33.6278 m track size, 20.651 s computational time and 266.612 s travel time is developed by IPSO approach. For surrounding setup-II; PSO algorithm provides 14.7769 m track length, 18.655 s computational time and 117.063 s travel time. Similarly the trajectory dimension, computational time and travel time generated in APF approach is 22.8645 m, 27.623 s and 189.077 s respectively. 13.0859 m track size, 18.507 s computational time and 103.769 s travel time is developed by IPSO approach. From comparison study it is found that, IPSO approach delivers smoother less collision risk associated path having less length, and computational time irrespective to environment complexity. The approaches are relying on computer programming commands, which are written, compiled and run using MATLAB software.},
  archive      = {J_EI},
  author       = {Pattanayak, Suvranshu and Choudhury, Bibhuti Bhusan},
  doi          = {10.1007/s12065-019-00247-0},
  journal      = {Evolutionary Intelligence},
  month        = {3},
  number       = {1},
  pages        = {21-34},
  shortjournal = {Evol. Intell.},
  title        = {Modified crash-minimization path designing approach for autonomous material handling robot},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Differential evolution algorithm tuned tilt integral
derivative controller with filter controller for automatic generation
control. <em>EI</em>, <em>14</em>(1), 5–20. (<a
href="https://doi.org/10.1007/s12065-019-00215-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A differential evolution (DE) tuned tilt integral derivative controller with filter (TIDF) has been implemented to a multi area reheat thermal power system for automatic generation control by taking the physical constraints like generation rate constraint and governor dead band nonlinearity. Initially, dissimilar integral controllers are considered in each area and the integral controller gains have been optimized by integral of time multiplied by absolute value of error (ITAE) criterion exploiting different strategies of DE algorithm. In next step, the control parameters such as step size and crossover probability of DE for the best strategy can be chosen with multiple iterations of the algorithm systematically for variation in each control parameter and DE proposes the control parameters. Further, PI/PID/TIDF type controller schemes have been modified and their gains have been optimized by optimal DE. Furthermore, to improve the transient system response, TIDF controller coordinated unified power flow controller (UPFC) has been investigated. The simulation results reveal that the minimum ITAE value is obtained when UPFC is placed in area-5 only. Finally, sensitivity analysis has been done by changing the operating load conditions along with the time constants of system parameters, from the simulation results it has been examined that there is no need to reset the controller parameters from their nominal setting for these variations. The proposed control scheme effectiveness is also observed by considering random step load disturbance and sinusoidal load disturbance.},
  archive      = {J_EI},
  author       = {Sahu, Rabindra Kumar and Sekhar, G. T. Chandra and Priyadarshani, Sonali},
  doi          = {10.1007/s12065-019-00215-8},
  journal      = {Evolutionary Intelligence},
  month        = {3},
  number       = {1},
  pages        = {5-20},
  shortjournal = {Evol. Intell.},
  title        = {Differential evolution algorithm tuned tilt integral derivative controller with filter controller for automatic generation control},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Nature inspired optimization and its application to
engineering. <em>EI</em>, <em>14</em>(1), 1–3. (<a
href="https://doi.org/10.1007/s12065-021-00586-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_EI},
  author       = {Nayak, Janmenjoy and Naik, Bighnaraj and Das, Asit Kumar and Pelusi, Danilo},
  doi          = {10.1007/s12065-021-00586-x},
  journal      = {Evolutionary Intelligence},
  month        = {3},
  number       = {1},
  pages        = {1-3},
  shortjournal = {Evol. Intell.},
  title        = {Nature inspired optimization and its application to engineering},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
</ul>

</body>
</html>
