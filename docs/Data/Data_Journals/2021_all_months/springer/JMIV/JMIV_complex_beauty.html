<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>JMIV_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="jmiv---66">JMIV - 66</h2>
<ul>
<li><details>
<summary>
(2021). Elastic shape analysis of planar objects using tensor field
representations. <em>JMIV</em>, <em>63</em>(9), 1204–1221. (<a
href="https://doi.org/10.1007/s10851-021-01047-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Shape analysis of objects in images is a critical area of research, and several approaches, including those that utilize elastic Riemannian metrics, have been proposed. While elastic techniques for shape analysis of curves are pretty advanced, the corresponding results for higher-dimensional objects (surfaces and disks) are less developed. This paper studies shapes of solid planar objects that are embeddings of a compact domain—a unit square or a unit disk—in $${\mathbb {R}}^2$$ . Specifically, it introduces a mathematical representation of objects using tensor fields and uses a re-parametrization-invariant Riemannian metric on these tensor fields to analyze object shapes elastically. The essential contribution here is developing an efficient numerical technique to map tensor fields back to the object space, allowing one to approximate geodesic paths in these objects’ shape spaces. Finally, the paper extends this framework to reach landmark-driven registration and improve geodesic computations. The paper illustrates this framework using several simulated and natural objects.},
  archive      = {J_JMIV},
  author       = {Zhang, Ruiyi and Srivastava, Anuj},
  doi          = {10.1007/s10851-021-01047-x},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {11},
  number       = {9},
  pages        = {1204-1221},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Elastic shape analysis of planar objects using tensor field representations},
  volume       = {63},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Radon cumulative distribution transform subspace modeling
for image classification. <em>JMIV</em>, <em>63</em>(9), 1185–1203. (<a
href="https://doi.org/10.1007/s10851-021-01052-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a new supervised image classification method applicable to a broad class of image deformation models. The method makes use of the previously described Radon Cumulative Distribution Transform (R-CDT) for image data, whose mathematical properties are exploited to express the image data in a form that is more suitable for machine learning. While certain operations such as translation, scaling, and higher-order transformations are challenging to model in native image space, we show the R-CDT can capture some of these variations and thus render the associated image classification problems easier to solve. The method—utilizing a nearest-subspace algorithm in the R-CDT space—is simple to implement, non-iterative, has no hyper-parameters to tune, is computationally efficient, label efficient, and provides competitive accuracies to state-of-the-art neural networks for many types of classification problems. In addition to the test accuracy performances, we show improvements (with respect to neural network-based methods) in terms of computational efficiency (it can be implemented without the use of GPUs), number of training samples needed for training, as well as out-of-distribution generalization. The Python code for reproducing our results is available at Shifat-E-Rabbi et al. (Python code implementing the Radon cumulative distribution transform subspace model for image classification. https://github.com/rohdelab/rcdt_ns_classifier ).},
  archive      = {J_JMIV},
  author       = {Shifat-E-Rabbi, Mohammad and Yin, Xuwang and Rubaiyat, Abu Hasnat Mohammad and Li, Shiying and Kolouri, Soheil and Aldroubi, Akram and Nichols, Jonathan M. and Rohde, Gustavo K.},
  doi          = {10.1007/s10851-021-01052-0},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {11},
  number       = {9},
  pages        = {1185-1203},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Radon cumulative distribution transform subspace modeling for image classification},
  volume       = {63},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An algebraic proof of the necessary and sufficient condition
for a P3P problem having a pair of point-sharing solutions.
<em>JMIV</em>, <em>63</em>(9), 1179–1184. (<a
href="https://doi.org/10.1007/s10851-021-01051-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently in this journal, Wang et al. (J Math Imaging Vis 62(5): 1214–1226, 2020) reported an interesting multi-solution phenomenon in P3P (perspective-3-point) problem: A pair of point-sharing solutions appears always in companionship with a pair of side-sharing solutions, and they also gave the necessary and sufficient condition for the existence of such solution pairs. Although the conclusions are correct, their proof is lengthy and difficult to follow due to the heavy reliance of geometrical entities, such as cross-ratio in projective geometry. In this short note, we provide an algebraic proof for the existence of a pair of point-sharing solutions. Our proof is simple and easily accessible to commoners in P3P field. As a by-product in the proof, we also show that although it is impossible to find analytical solutions for general P3P problem, the point-sharing solutions, if they exist, can be computed analytically. Finally, we also propose a way to construct a pair of point-sharing solutions.},
  archive      = {J_JMIV},
  author       = {Hu, Lihua and Zhang, Jifu and Li, Xiaoming},
  doi          = {10.1007/s10851-021-01051-1},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {11},
  number       = {9},
  pages        = {1179-1184},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {An algebraic proof of the necessary and sufficient condition for a P3P problem having a pair of point-sharing solutions},
  volume       = {63},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Double medical images zero-watermarking algorithm based on
the chaotic system and ternary accurate polar complex exponential
transform. <em>JMIV</em>, <em>63</em>(9), 1160–1178. (<a
href="https://doi.org/10.1007/s10851-021-01048-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Different from the traditional watermarking schemes, zero-watermarking schemes are lossless embedding methods, which are applicable to be used in medical, military, remote sensing and other fields requiring high-integrity image copyright protection. However, most of the existing zero-watermarking schemes only provide copyright protection for one image at a time, which has certain limitations. This paper proposes a novel zero-watermarking scheme for protecting the copyright of two similar medical images simultaneously. Firstly, an accurate polar complex exponential transform (APCET) is designed using Gaussian numerical integration (GNI) method, which effectively improves the computation accuracy of polar complex exponential transform (PCET). Then, ternary accurate polar complex exponential transform (TAPCET) is constructed based on ternary number theory and APCET, which describes two similar medical images simultaneously. Finally, a robust zero-watermarking algorithm for two similar medical images is proposed based on TAPCET and chaotic mapping. The experimental results show that the proposed scheme can resist common image processing attacks and geometric attacks, and is superior to other zero-watermarking algorithms, being applicable for the copyright protection of two similar medical images simultaneously.},
  archive      = {J_JMIV},
  author       = {Ma, Bin and Chang, Lili and Wang, Chunpeng and Li, Jian and Li, Gang and Xia, Zhiqiu and Wang, Xingyuan},
  doi          = {10.1007/s10851-021-01048-w},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {11},
  number       = {9},
  pages        = {1160-1178},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Double medical images zero-watermarking algorithm based on the chaotic system and ternary accurate polar complex exponential transform},
  volume       = {63},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Variances of surface area estimators based on pixel
configuration counts. <em>JMIV</em>, <em>63</em>(9), 1143–1159. (<a
href="https://doi.org/10.1007/s10851-021-01045-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The surface area of a set which is only observed as a binary pixel image is often estimated by a weighted sum of pixel configurations counts. In this paper we examine these estimators in a design based setting—we assume that the observed set is shifted uniformly randomly. Bounds for the difference between the essential supremum and the essential infimum of such an estimator are derived, which imply that the variance is in $$O(t^2)$$ as the lattice distance t tends to zero. In particular, it is asymptotically neglectable compared to the bias. A simulation study shows that the theoretically derived convergence order is optimal in general, but further improvements are possible in special cases.},
  archive      = {J_JMIV},
  author       = {Kampf, Jürgen},
  doi          = {10.1007/s10851-021-01045-z},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {11},
  number       = {9},
  pages        = {1143-1159},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Variances of surface area estimators based on pixel configuration counts},
  volume       = {63},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Construction of generalized hybrid trigonometric bézier
surfaces with shape parameters and their applications. <em>JMIV</em>,
<em>63</em>(9), 1118–1142. (<a
href="https://doi.org/10.1007/s10851-021-01046-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To tackle the problem of modeling and shape designing of complex engineering surfaces, the continuity constraints between generalized hybrid trigonometric Bézier (GHT-Bézier for short) surfaces with three different shape parameters are proposed in this study. Initially, we describe the basic properties of GHT-Bézier surface and influence of shape parameters. Some special triangular surfaces and biangular surfaces by varying the different values of shape control parameters are described. $$G^{2}$$ continuity conditions in various directions between two adjacent GHT-Bézier surfaces with graphical representation are studied. Finally, the construction of some free-form complex engineering surfaces such as cylindrical surface, swung surface, ruled surface, and swept surface by using GHT-Bézier surfaces is also studied. Some graphical examples ensure that the proposed method greatly improves the ability to design complex surfaces and is easy to implement.},
  archive      = {J_JMIV},
  author       = {Bibi, Samia and Abbas, Muhammad and Misro, Md Yushalify and Majeed, Abdul and Nazir, Tahir},
  doi          = {10.1007/s10851-021-01046-y},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {11},
  number       = {9},
  pages        = {1118-1142},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Construction of generalized hybrid trigonometric bézier surfaces with shape parameters and their applications},
  volume       = {63},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Uncertainty quantification in image segmentation using the
ambrosio–tortorelli approximation of the mumford–shah energy.
<em>JMIV</em>, <em>63</em>(9), 1095–1117. (<a
href="https://doi.org/10.1007/s10851-021-01034-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The quantification of uncertainties in image segmentation based on the Mumford–Shah model is studied. The aim is to address the error propagation of noise and other error types in the original image to the restoration result and especially the reconstructed edges (sharp image contrasts). Analytically, we rely on the Ambrosio–Tortorelli approximation and discuss the existence of measurable selections of its solutions as well as sampling-based methods and the limitations of other popular methods. Numerical examples illustrate the theoretical findings.},
  archive      = {J_JMIV},
  author       = {Hintermüller, Michael and Stengl, Steven-Marian and Surowiec, Thomas M.},
  doi          = {10.1007/s10851-021-01034-2},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {11},
  number       = {9},
  pages        = {1095-1117},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Uncertainty quantification in image segmentation using the Ambrosio–Tortorelli approximation of the Mumford–Shah energy},
  volume       = {63},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Three-dimensional maximal and boundary ghosts.
<em>JMIV</em>, <em>63</em>(8), 1084–1093. (<a
href="https://doi.org/10.1007/s10851-021-01043-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In discrete tomography, ghosts represent indeterminate locations of a reconstruction when there is insufficient projection information to admit a unique solution. Our previous work presented maximal ghosts, which are tilings of $$2^N$$ connected points of $$\pm 1$$ values with zero line sums over N directions. These directions are given by the recursion $$v_{n+1}=v_n + 2\epsilon _{n+1}v_{n-1}$$ with $$\epsilon _{n+1} \in \{-1,1\}$$ . By including one additional direction, interior points are cancelled leaving only a thin boundary of ghost errors. Here, we show that a simple modification to this recursion is not possible to generate boundary ghosts in three dimensions. Rather, we present a combination of three different recurrences to achieve this goal. We derive results pertaining to the connectivity, size and structure of these shapes.},
  archive      = {J_JMIV},
  author       = {Ceko, Matthew and Tijdeman, Rob},
  doi          = {10.1007/s10851-021-01043-1},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {10},
  number       = {8},
  pages        = {1084-1093},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Three-dimensional maximal and boundary ghosts},
  volume       = {63},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Measuring shape relations using r-parallel sets.
<em>JMIV</em>, <em>63</em>(8), 1069–1083. (<a
href="https://doi.org/10.1007/s10851-021-01041-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Geometrical measurements of biological objects form the basis of many quantitative analyses. Hausdorff measures such as the volume and the area of objects are simple and popular descriptors of individual objects; however, for most biological processes, the interaction between objects cannot be ignored, and the shape and function of neighboring objects are mutually influential. In this paper, we present a theory on the geometrical interaction between objects inspired by K-functions for spatial point-processes. Our theory describes the relation between two objects: a reference and an observed object. We generate the r-parallel sets of the reference object, calculate the intersection between the r-parallel sets and the observed object, and define measures on these intersections. The measures are simple, like the volume or surface area, but describe further details about the shape of individual objects and their pairwise geometrical relation. Finally, we propose a summary-statistics. To evaluate these measures, we present a new segmentation of cell membrane, mitochondria, synapses, vesicles, and endoplasmic reticulum in a publicly available FIB-SEM 3D brain tissue data set and use our proposed method to analyze key biological structures herein.},
  archive      = {J_JMIV},
  author       = {Stephensen, Hans J. T. and Svane, Anne Marie and Villanueva, Carlos B. and Goldman, Steven A. and Sporring, Jon},
  doi          = {10.1007/s10851-021-01041-3},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {10},
  number       = {8},
  pages        = {1069-1083},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Measuring shape relations using r-parallel sets},
  volume       = {63},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A variational model for deformable registration of uni-modal
medical images with intensity biases. <em>JMIV</em>, <em>63</em>(8),
1057–1068. (<a
href="https://doi.org/10.1007/s10851-021-01042-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deformable image registration aims at estimating a proper displacement field from a fixed image and a moving one. Variational deformable registration models often consist of a data term of the images and a regularization term of the estimated displacement field. In this paper, we propose a variational model for registering uni-modal medical images with intensity biases. Precisely, the proposed model employs local correlation coefficients (LCC) as the data term and regularizes all possible displacement fields as functions of bounded deformation (BD functions), which is thus termed as BDLCC model. A primal-dual algorithm is derived for solving the model. Two conclusions can be drawn from two-dimensional and three-dimensional numerical experiments: (1) the proposed primal-dual algorithm is effective and stable, (2) the BDLCC model is effective for deformable registration of uni-modal images with intensity biases, and competitive with other state-of-the-art deformable registration models.},
  archive      = {J_JMIV},
  author       = {Nie, Ziwei and Li, Chen and Liu, Hairong and Yang, Xiaoping},
  doi          = {10.1007/s10851-021-01042-2},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {10},
  number       = {8},
  pages        = {1057-1068},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {A variational model for deformable registration of uni-modal medical images with intensity biases},
  volume       = {63},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Fast and robust certifiable estimation of the relative pose
between two calibrated cameras. <em>JMIV</em>, <em>63</em>(8),
1036–1056. (<a
href="https://doi.org/10.1007/s10851-021-01044-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work contributes an efficient algorithm to compute the relative pose problem (RPp) between calibrated cameras and certify the optimality of the solution, given a set of pair-wise feature correspondences affected by noise and probably corrupted by wrong matches. We propose a family of certifiers that is shown to increase the ratio of detected optimal solutions. This set of certifiers is incorporated into a fast essential matrix estimation pipeline that, given any initial guess for the RPp, refines it iteratively on the product space of 3D rotations and 2-sphere. In addition, this fast certifiable pipeline is integrated into a robust framework that combines graduated non-convexity and the Black-Rangarajan duality between robust functions and line processes. We proved through extensive experiments on synthetic and real data that the proposed framework provides a fast and robust relative pose estimation. We make the code publicly available https://github.com/mergarsal/FastCertRelPose.git .},
  archive      = {J_JMIV},
  author       = {Garcia-Salguero, Mercedes and Gonzalez-Jimenez, Javier},
  doi          = {10.1007/s10851-021-01044-0},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {10},
  number       = {8},
  pages        = {1036-1056},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Fast and robust certifiable estimation of the relative pose between two calibrated cameras},
  volume       = {63},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Dimensionality reduction based on kCCC and manifold
learning. <em>JMIV</em>, <em>63</em>(8), 1010–1035. (<a
href="https://doi.org/10.1007/s10851-021-01031-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper first proposes a statistic for measuring the correlation between two random variables. Because the data are usually polluted by noise and the feature of the data is usually task-relevant, this paper proposes to perform a transformation on the data before measuring their correlation. In addition, since the kernel method is a commonly used data transformation method in the field of machine learning, choosing different kernel functions is to choose different features, so we use kernel functions to perform this transformation. The random variable transformed by the kernel function becomes a kernelized random variable. Most importantly, the kernelized random variable is a random process, so we propose to use the norm of their cross-covariance function, which is called the kernelized cross-covariance criterion (kCCC), to measure the task-related correlation of two random variables. The kCCC criterion is a universal principle, based on which a variety of statistical machine learning algorithms can be constructed. This paper proposes to apply the kCCC to data dimensionality reduction, referred to as kCCC-DR for short. Further, we propose kCCC-DR in combination with the most widely studied and efficient local geometric property preservation method and manifold learning dimensionality reduction method, referred as kCCC-ML-DR for short. It is a dimensionality reduction method that maintains the global statistical characteristics and local geometric characteristics of the data at the same time. In the experiments presented in this paper, kCCC is combined with LLE, LE and LTSA. These algorithms are famous manifold learning algorithms, in which LLE is local linearity-preserving, LE is local similarity-preserving and LTSA is local homeomorphism-preserving. Experiments verify the effectiveness of our method.},
  archive      = {J_JMIV},
  author       = {Huang, Gengshi and Ma, Zhengming and Luo, Tianshi},
  doi          = {10.1007/s10851-021-01031-5},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {10},
  number       = {8},
  pages        = {1010-1035},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Dimensionality reduction based on kCCC and manifold learning},
  volume       = {63},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). On inversion-free mapping and distortion minimization.
<em>JMIV</em>, <em>63</em>(8), 974–1009. (<a
href="https://doi.org/10.1007/s10851-021-01038-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses a general problem of computing inversion-free maps between continuous and discrete domains that induce minimal geometric distortions. We will refer to this problem as optimal mapping problem. Finding a good solution to the optimal mapping problem is a key part in many applications in geometry processing and computer vision, including: parameterization of surfaces and volumetric domains, shape matching and shape analysis. The first goal of this paper is to provide a self-contained exposition of the optimal mapping problem and to highlight the interrelationship of various aspects of the problem. This includes a formal definition of the problem and of the related unitarily invariant geometric measures, which we call distortions. The second goal is to identify novel properties of distortion measures and to explain how these properties can be used in practice. Our major contributions are: (i) formalization and juxtaposition of key concepts of the optimal mapping problem, which so far have not been formalized in a unified manner; (ii) providing a detailed survey of existing methods for optimal mapping, including exposition of recent optimization algorithms and methods for finding injective mappings between meshes; (iii) providing novel theoretical findings on practical aspects of geometric distortions, including the multi-resolution invariance of geometric energies and the characterization of convex distortion measures. In particular, we introduce a new family of convex distortion measures, and prove that, on meshes, most of the existing distortion energies are non-convex functions of vertex coordinates.},
  archive      = {J_JMIV},
  author       = {Naitsat, Alexander and Naitzat, Gregory and Zeevi, Yehoshua Y.},
  doi          = {10.1007/s10851-021-01038-y},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {10},
  number       = {8},
  pages        = {974-1009},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {On inversion-free mapping and distortion minimization},
  volume       = {63},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Locating perspective three-point problem solutions in
spatial regions. <em>JMIV</em>, <em>63</em>(8), 953–973. (<a
href="https://doi.org/10.1007/s10851-021-01040-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The distribution of the solutions to the Perspective 3-Point Problem (P3P) has been studied for a few decades, and some understanding of this issue has emerged. However, the present article is the first to comprehensively describe, for a given location p in space, the number of other points that solve the same P3P setup that p solves, and where to find these related points. A dynamic approach is employed to solve this problem. The related points are restricted to certain regions in space, defined by certain “basic” toroids and by a surface called the “companion surface to the danger cylinder.” The nature of this surface is explored in detail, along with its intersections with the basic toroids, and the pairwise intersection of these toroids.},
  archive      = {J_JMIV},
  author       = {Rieck, Michael Q. and Wang, Bo},
  doi          = {10.1007/s10851-021-01040-4},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {10},
  number       = {8},
  pages        = {953-973},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Locating perspective three-point problem solutions in spatial regions},
  volume       = {63},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Automated data-driven selection of the hyperparameters for
total-variation-based texture segmentation. <em>JMIV</em>,
<em>63</em>(7), 923–952. (<a
href="https://doi.org/10.1007/s10851-021-01035-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Penalized least squares are widely used in signal and image processing. Yet, it suffers from a major limitation since it requires fine-tuning of the regularization parameters. Under assumptions on the noise probability distribution, Stein-based approaches provide unbiased estimator of the quadratic risk. The Generalized Stein Unbiased Risk Estimator is revisited to handle correlated Gaussian noise without requiring to invert the covariance matrix. Then, in order to avoid expansive grid search, it is necessary to design algorithmic scheme minimizing the quadratic risk with respect to regularization parameters. This work extends the Stein’s Unbiased GrAdient estimator of the Risk of Deledalle et al. (SIAM J Imaging Sci 7(4):2448–2487, 2014) to the case of correlated Gaussian noise, deriving a general automatic tuning of regularization parameters. First, the theoretical asymptotic unbiasedness of the gradient estimator is demonstrated in the case of general correlated Gaussian noise. Then, the proposed parameter selection strategy is particularized to fractal texture segmentation, where problem formulation naturally entails inter-scale and spatially correlated noise. Numerical assessment is provided, as well as discussion of the practical issues.},
  archive      = {J_JMIV},
  author       = {Pascal, Barbara and Vaiter, Samuel and Pustelnik, Nelly and Abry, Patrice},
  doi          = {10.1007/s10851-021-01035-1},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {9},
  number       = {7},
  pages        = {923-952},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Automated data-driven selection of the hyperparameters for total-variation-based texture segmentation},
  volume       = {63},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Complete and incomplete sets of invariants. <em>JMIV</em>,
<em>63</em>(7), 917–922. (<a
href="https://doi.org/10.1007/s10851-021-01039-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paper shows that the moment invariants proposed recently in this journal by Hjouji et al. (J Math Imaging Vis 62:606–624, 2020) are incomplete, which leads to a limited discriminability. We prove this by means of circular projection of the image. In a broader context, we demonstrate that completeness of the invariants leads to a better recognition power.},
  archive      = {J_JMIV},
  author       = {Flusser, Jan and Suk, Tomáš and Zitová, Barbara},
  doi          = {10.1007/s10851-021-01039-x},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {9},
  number       = {7},
  pages        = {917-922},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Complete and incomplete sets of invariants},
  volume       = {63},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Pairwise rigid registration based on riemannian geometry and
lie structures of orientation tensors. <em>JMIV</em>, <em>63</em>(7),
894–916. (<a href="https://doi.org/10.1007/s10851-021-01037-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pairwise rigid registration can be developed by comparing local geometry encoded by intrinsic second-order orientation tensors which allows to model the registration problem using the associated Riemannian geometry or related group structures. Everything starts by representing those tensor fields as multivariate normal models that permit us to manipulate Gaussians in two ways: using the Riemannian manifold elements, that can be embedded into matrix spaces with geometric structures, or through Lie group/algebra techniques. In this paper we discuss some points behind these approaches in the context of rigid registration problems. Firstly, they are not equivalent since, in general, there is no isometry linking them. Secondly, embedding methodologies are not invariant with respect to rigid motion. We discuss these points using two variants of the Iterative Closest Point that use the comparative tensor shape factor (CTSF) to match orientation tensors. We replace the CTSF to different criteria computed through geodesic distance and algebraic embeddings and compare the registration algorithms showing that the latter is more efficient for registration of point clouds.},
  archive      = {J_JMIV},
  author       = {de Almeida, Liliane Rodrigues and Giraldi, Gilson Antonio and Vieira, Marcelo Bernardes and Miranda Jr, Gastão Florêncio},
  doi          = {10.1007/s10851-021-01037-z},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {9},
  number       = {7},
  pages        = {894-916},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Pairwise rigid registration based on riemannian geometry and lie structures of orientation tensors},
  volume       = {63},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Transporting deformations of face emotions in the shape
spaces: A comparison of different approaches. <em>JMIV</em>,
<em>63</em>(7), 875–893. (<a
href="https://doi.org/10.1007/s10851-021-01030-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Studying the changes of shape is a common concern in many scientific fields. We address here two problems: (1) quantifying the deformation between two given shapes and (2) transporting this deformation to morph a third shape. These operations can be done with or without point correspondence, depending on the availability of a surface matching algorithm, and on the type of mathematical procedure adopted. In computer vision, the re-targeting of emotions mapped on faces is a common application. We contrast here four different methods used for transporting the deformation toward a target once it was estimated upon the matching of two shapes. These methods come from very different fields such as computational anatomy, computer vision and biology. We used the large diffeomorphic deformation metric mapping and thin plate spline, in order to estimate deformations in a deformational trajectory of a human face experiencing different emotions. Then we use naive transport (NT), linear shift (LS), direct transport (DT) and fanning scheme (FS) to transport the estimated deformations toward four alien faces constituted by 240 homologous points and identifying a triangulation structure of 416 triangles. We used both local and global criteria for evaluating the performance of the 4 methods, e.g., the maintenance of the original deformation. We found DT, LS and FS very effective in recovering the original deformation while NT fails under several aspects in transporting the shape change. As the best method may differ depending on the application, we recommend carefully testing different methods in order to choose the best one for any specific application.},
  archive      = {J_JMIV},
  author       = {Piras, Paolo and Varano, Valerio and Louis, Maxime and Profico, Antonio and Durrleman, Stanley and Charlier, Benjamin and Milicchio, Franco and Teresi, Luciano},
  doi          = {10.1007/s10851-021-01030-6},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {9},
  number       = {7},
  pages        = {875-893},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Transporting deformations of face emotions in the shape spaces: A comparison of different approaches},
  volume       = {63},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Poisson shot noise removal by an oracular non-local
algorithm. <em>JMIV</em>, <em>63</em>(7), 855–874. (<a
href="https://doi.org/10.1007/s10851-021-01033-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we address the problem of denoising images obtained under low-light conditions for the Poisson shot noise model. Under such conditions, the variance stabilization transform (VST) is no longer applicable, so that the state-of-the-art algorithms which are proficient for the additive white Gaussian noise cannot be applied. We first introduce an oracular non-local algorithm and prove its convergence with the optimal rate of convergence under a Hölder regularity assumption for the underlying image, when the search window size is suitably chosen. We also prove that the convergence remains valid when the oracle function is estimated within a prescribed error range. We then define a realizable filter by a statistical estimation of the similarity function which determines the oracle weight. The convergence of the realizable filter is justified by proving that the estimator of the similarity function lies in the prescribed error range with high probability. The experiments show that under low-light conditions the proposed filter is competitive compared with the recent state-of-the-art algorithms.},
  archive      = {J_JMIV},
  author       = {Jin, Qiyu and Grama, Ion and Liu, Quansheng},
  doi          = {10.1007/s10851-021-01033-3},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {9},
  number       = {7},
  pages        = {855-874},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Poisson shot noise removal by an oracular non-local algorithm},
  volume       = {63},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). On bayesian posterior mean estimators in imaging sciences
and hamilton–jacobi partial differential equations. <em>JMIV</em>,
<em>63</em>(7), 821–854. (<a
href="https://doi.org/10.1007/s10851-021-01036-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Variational and Bayesian methods are two widely used set of approaches to solve image denoising problems. In a Bayesian setting, these approaches correspond, respectively, to using maximum a posteriori estimators and posterior mean estimators for reconstructing images. In this paper, we propose novel theoretical connections between Hamilton–Jacobi partial differential equations (HJ PDEs) and a broad class of posterior mean estimators with quadratic data fidelity term and log-concave prior. Where solutions to some first-order HJ PDEs with initial data describe maximum a posteriori estimators, here we show that solutions to some viscous HJ PDEs with initial data describe a broad class of posterior mean estimators. We use these connections to establish representation formulas and various properties of posterior mean estimators. In particular, we use these connections to show that some Bayesian posterior mean estimators can be expressed as proximal mappings of smooth functions and derive representation formulas for these functions.},
  archive      = {J_JMIV},
  author       = {Darbon, Jérôme and Langlois, Gabriel P.},
  doi          = {10.1007/s10851-021-01036-0},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {9},
  number       = {7},
  pages        = {821-854},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {On bayesian posterior mean estimators in imaging sciences and Hamilton–Jacobi partial differential equations},
  volume       = {63},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Generalized eigenvalue decomposition applied to estimation
of spatial rPPG distribution of skin. <em>JMIV</em>, <em>63</em>(7),
807–820. (<a href="https://doi.org/10.1007/s10851-021-01025-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Remote photoplethysmography (rPPG) has been at the forefront recently, thanks to its capacity in estimating non-contact physiological parameters such as heart rate and heart rate variability (Wang et al. in FBB 6:33, 2018). rPPG signals are typically extracted from facial videos by performing spatial averaging to obtain temporal RGB traces. Although this spatial averaging simplifies computation, it is accompanied by loss of essential spatial information which might reveal interesting relationships between signals from different spatial regions. In this article, we present a novel algorithm adapted from generalized eigenvalue decomposition (GEVD) to estimate this spatial rPPG distribution. GEVD is an extremely versatile algorithm that finds uses in signal and image processing and analytical problems such as principal component analysis and Fisher discriminant analysis (Ghojogh et al. in Tutorial 2: 1–8, 2019)(Han and Clemmensen in PR 49:43-54, 2016). It is performed using the QZ algorithm (Moler and Stewart in JNA 10(2):241–256, 2010), which in turn uses Householder transformations (Householder in JACM 5(4):339–342, 1958) to extract generalized eigenvectors of a pair of matrices. We adapt the QZ algorithm for the domain of spatio-temporal biomedical signals such as remote photoplethysmography (rPPG), electrocardiography and electroencephalography signals. We call this algorithm Temporal-QZ, which employs vectorization techniques to extract generalized eigenvectors over spatial data points simultaneously. We validate this extension in the domain of remote photoplethysmography (rPPG) measurement, for the estimation of spatial rPPG distribution of skin.},
  archive      = {J_JMIV},
  author       = {Macwan, Richard and Benezeth, Yannick and Mansouri, Alamin},
  doi          = {10.1007/s10851-021-01025-3},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {9},
  number       = {7},
  pages        = {807-820},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Generalized eigenvalue decomposition applied to estimation of spatial rPPG distribution of skin},
  volume       = {63},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). On biases in displacement estimation for image registration,
with a focus on photomechanics. <em>JMIV</em>, <em>63</em>(7), 777–806.
(<a href="https://doi.org/10.1007/s10851-021-01032-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image registration under small displacements is the keystone of several image analysis tasks such as optical flow estimation, stereoscopic imaging, or full-field displacement estimation in photomechanics. A popular approach consists in locally modeling the displacement field between two images by a parametric transformation and performing least-squares estimation afterward. This procedure is known as “digital image correlation” in several domains as in photomechanics. The present article is part of this approach. First, the estimated displacement is shown to be impaired by biases related to the interpolation scheme needed to reach subpixel accuracy, the image gradient distribution, as well as the difference between the hypothesized parametric transformation and the true displacement. A quantitative estimation of the difference between the estimated value and the actual one is of importance in application domains such as stereoscopy or photomechanics, which have metrological concerns. Second, we question the extent to which these biases could be eliminated or reduced. We also present numerical assessments of our predictive formula in the context of photomechanics. Software codes are freely available to reproduce our results. Although this paper is focused on a particular application field, namely photomechanics, it is relevant to various scientific areas concerned by image registration.},
  archive      = {J_JMIV},
  author       = {Sur, Frédéric and Blaysat, Benoît and Grédiac, Michel},
  doi          = {10.1007/s10851-021-01032-4},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {9},
  number       = {7},
  pages        = {777-806},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {On biases in displacement estimation for image registration, with a focus on photomechanics},
  volume       = {63},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Correction to: Non-congruent non-degenerate curves with
identical signatures. <em>JMIV</em>, <em>63</em>(6), 776. (<a
href="https://doi.org/10.1007/s10851-021-01028-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A correction to this paper has been published: https://doi.org/10.1007/s10851-021-01028-0},
  archive      = {J_JMIV},
  author       = {Geiger, Eric and Kogan, Irina A.},
  doi          = {10.1007/s10851-021-01028-0},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {7},
  number       = {6},
  pages        = {776},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Correction to: Non-congruent non-degenerate curves with identical signatures},
  volume       = {63},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Bilevel parameter learning for nonlocal image denoising
models. <em>JMIV</em>, <em>63</em>(6), 753–775. (<a
href="https://doi.org/10.1007/s10851-021-01026-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a bilevel optimization approach for the estimation of parameters in nonlocal image denoising models. The parameters we consider are both the fidelity weight and weights within the kernel of the nonlocal operator. In both cases, we investigate the differentiability of the solution operator in function spaces and derive a first-order optimality system that characterizes local minima. For the numerical solution of the problems, we use a second-order trust-region algorithm in combination with a finite element discretization of the nonlocal denoising models and introduce a computational strategy for the solution of the resulting dense linear systems. Several experiments illustrate the applicability and effectiveness of our approach.},
  archive      = {J_JMIV},
  author       = {D’Elia, M. and De Los Reyes, J. C. and Miniguano-Trujillo, A.},
  doi          = {10.1007/s10851-021-01026-2},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {7},
  number       = {6},
  pages        = {753-775},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Bilevel parameter learning for nonlocal image denoising models},
  volume       = {63},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A quotient space formulation for generative statistical
analysis of graphical data. <em>JMIV</em>, <em>63</em>(6), 735–752. (<a
href="https://doi.org/10.1007/s10851-021-01027-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Complex analyses involving multiple, dependent random quantities often lead to graphical models—a set of nodes denoting variables of interest, and corresponding edges denoting statistical interactions between nodes. To develop statistical analyses for graphical data, especially towards generative modeling, one needs mathematical representations and metrics for matching and comparing graphs, and subsequent tools, such as geodesics, means, and covariances. This paper utilizes a quotient structure to develop efficient algorithms for computing these quantities, leading to useful statistical tools, including principal component analysis, statistical testing, and modeling. We demonstrate the efficacy of this framework using datasets taken from several problem areas, including letters, biochemical structures, and social networks.},
  archive      = {J_JMIV},
  author       = {Guo, Xiaoyang and Srivastava, Anuj and Sarkar, Sudeep},
  doi          = {10.1007/s10851-021-01027-1},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {7},
  number       = {6},
  pages        = {735-752},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {A quotient space formulation for generative statistical analysis of graphical data},
  volume       = {63},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Color image zero-watermarking using accurate quaternion
generalized orthogonal fourier–mellin moments. <em>JMIV</em>,
<em>63</em>(6), 708–734. (<a
href="https://doi.org/10.1007/s10851-020-01002-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, digital image zero-watermarking algorithm has made great progress. But there are still some problems. First, most algorithms only focus on robustness and ignore discrimination. Second, most methods have good robustness against conventional signal attacks but poor robustness against geometric attacks. Thirdly, most of the existing zero-watermarking algorithms only focus on gray-scale images, and there are relatively few researches on color images. In order to cope with these issues, this paper introduces a novel color image zero-watermarking scheme using accurate quaternion generalized orthogonal Fourier–Mellin moments (AQGOFMMs). In the first stage of the proposed method, accurate computation of generalized orthogonal Fourier–Mellin moments (GOFMMs) based on the polar pixel tiling scheme. In the next stage, the high-precision GOFMMs are extended to the accurate quaternion GOFMMs (AQGOFMMs). Finally, the immutable set of features is extracted to construct a zero-watermark. It is worth mentioning that, different from the traditional way of constructing watermark with the amplitude of moments, this algorithm uses the full 4-D features of AQGOFMMs to construct watermark. The experiment proved that proposed zero-watermarking scheme gives a good balance between discriminability and robustness. Furthermore, the proposed algorithm achieves better performance than the other existing zero-watermarking.},
  archive      = {J_JMIV},
  author       = {Wang, Xiang-yang and Wang, Li and Tian, Jia-lin and Niu, Pan-pan and Yang, Hong-ying},
  doi          = {10.1007/s10851-020-01002-2},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {7},
  number       = {6},
  pages        = {708-734},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Color image zero-watermarking using accurate quaternion generalized orthogonal Fourier–Mellin moments},
  volume       = {63},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Globally optimal point set registration by joint symmetry
plane fitting. <em>JMIV</em>, <em>63</em>(6), 689–707. (<a
href="https://doi.org/10.1007/s10851-021-01024-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The present work proposes a solution to the challenging problem of registering two partial point sets of the same object with very limited overlap. We leverage the fact that most objects found in man-made environments contain a plane of symmetry. By reflecting the points of each set with respect to the plane of symmetry, we can largely increase the overlap between the sets and therefore boost the registration process. However, prior knowledge about the plane of symmetry is generally unavailable or at least very hard to find, especially with limited partial views. Finding this plane could strongly benefit from a prior alignment of the partial point sets. We solve this chicken-and-egg problem by jointly optimizing the relative pose and symmetry plane parameters. We present a globally optimal solver by employing the branch-and-bound paradigm and thereby demonstrate that joint symmetry plane fitting leads to a great improvement over the current state of the art in globally optimal point set registration for common objects. We conclude with an interesting application of our method to dense 3D reconstruction of scenes with repetitive objects.},
  archive      = {J_JMIV},
  author       = {Hu, Lan and Kneip, Laurent},
  doi          = {10.1007/s10851-021-01024-4},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {7},
  number       = {6},
  pages        = {689-707},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Globally optimal point set registration by joint symmetry plane fitting},
  volume       = {63},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). From riemannian trichromacy to quantum color opponency via
hyperbolicity. <em>JMIV</em>, <em>63</em>(6), 681–688. (<a
href="https://doi.org/10.1007/s10851-021-01023-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a mathematical description of human color perception that relies on a hyperbolic structure of the space $${\mathcal {P}}$$ of perceived colors. We show that hyperbolicity allows us to reconcile both trichromaticity, from a Riemannian point of view, and color opponency, from a quantum viewpoint. In particular, we will underline how the opponent behavior can be represented by a rebit, a real analog of a qubit, whose state space is endowed with the Hilbert metric.},
  archive      = {J_JMIV},
  author       = {Berthier, Michel and Provenzi, Edoardo},
  doi          = {10.1007/s10851-021-01023-5},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {7},
  number       = {6},
  pages        = {681-688},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {From riemannian trichromacy to quantum color opponency via hyperbolicity},
  volume       = {63},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Active contour directed by the poisson gradient vector field
and edge tracking. <em>JMIV</em>, <em>63</em>(6), 665–680. (<a
href="https://doi.org/10.1007/s10851-021-01017-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper develops a new active contour (AC) model capable of multiple complex objects segmentation in the presence of heavy noise. The model segments images in the framework of two types of partial differential equations (PDEs): the Euler–Lagrange and Poisson PDEs. The former is used to build an evolution algorithm, while the Poisson solution gradient vector field (PGVF) directs the evolution toward the boundaries of all image objects. The AC halts on boundaries and PGVF separatrices, splits on the latter, and leaves at least one segment (called label) on every boundary. Each label tracks its boundary until the corresponding object is enveloped. The advantages of the new method are validated on a number of skin lesions, road, and aircraft images of varying sizes and in the presence of Gaussian noise. The obtained results are compared against results by contemporary and established active contours and neural networks.},
  archive      = {J_JMIV},
  author       = {Bowden, Adam and Sirakov, Nikolay Metodiev},
  doi          = {10.1007/s10851-021-01017-3},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {7},
  number       = {6},
  pages        = {665-680},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Active contour directed by the poisson gradient vector field and edge tracking},
  volume       = {63},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Statistical model and ML-EM algorithm for emission
tomography with known movement. <em>JMIV</em>, <em>63</em>(5), 650–663.
(<a href="https://doi.org/10.1007/s10851-021-01021-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In positron emission tomography, movement leads to blurry reconstructions when not accounted for. Whether known a priori or estimated jointly to reconstruction, motion models are increasingly defined in continuum rather that in discrete, for example by means of diffeomorphisms. The present work provides both a statistical and functional analytic framework suitable for handling such models. It is based on time-space Poisson point processes as well as regarding images as measures, and allows to compute the maximum likelihood problem for line-of-response data with a known movement model. Solving the resulting optimisation problem, we derive an maximum likelihood expectation maximisation (ML-EM)-type algorithm which recovers the classical ML-EM algorithm as a particular case for a static phantom. The algorithm is proved to be monotone and convergent in the low-noise regime. Simulations confirm that it correctly removes the blur that would have occurred if movement were neglected.},
  archive      = {J_JMIV},
  author       = {Pouchol, Camille and Verdier, Olivier},
  doi          = {10.1007/s10851-021-01021-7},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {6},
  number       = {5},
  pages        = {650-663},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Statistical model and ML-EM algorithm for emission tomography with known movement},
  volume       = {63},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Robust PCA via regularized reaper with a matrix-free
proximal algorithm. <em>JMIV</em>, <em>63</em>(5), 626–649. (<a
href="https://doi.org/10.1007/s10851-021-01019-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Principal component analysis (PCA) is known to be sensitive to outliers, so that various robust PCA variants were proposed in the literature. A recent model, called reaper, aims to find the principal components by solving a convex optimization problem. Usually the number of principal components must be determined in advance and the minimization is performed over symmetric positive semi-definite matrices having the size of the data, although the number of principal components is substantially smaller. This prohibits its use if the dimension of the data is large which is often the case in image processing. In this paper, we propose a regularized version of reaper which enforces the sparsity of the number of principal components by penalizing the nuclear norm of the corresponding orthogonal projector. If only an upper bound on the number of principal components is available, our approach can be combined with the L-curve method to reconstruct the appropriate subspace. Our second contribution is a matrix-free algorithm to find a minimizer of the regularized reaper which is also suited for high-dimensional data. The algorithm couples a primal-dual minimization approach with a thick-restarted Lanczos process. This appears to be the first efficient convex variational method for robust PCA that can handle high-dimensional data. As a side result, we discuss the topic of the bias in robust PCA. Numerical examples demonstrate the performance of our algorithm.},
  archive      = {J_JMIV},
  author       = {Beinert, Robert and Steidl, Gabriele},
  doi          = {10.1007/s10851-021-01019-1},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {6},
  number       = {5},
  pages        = {626-649},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Robust PCA via regularized reaper with a matrix-free proximal algorithm},
  volume       = {63},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Non-congruent non-degenerate curves with identical
signatures. <em>JMIV</em>, <em>63</em>(5), 601–625. (<a
href="https://doi.org/10.1007/s10851-020-01015-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While the equality of differential signatures (Calabi et al., Int. J. Comput. Vis. 26: 107–135, 1998) is known to be a necessary condition for congruence, it is not sufficient (Musso and Nicolodi, J. Math Imaging Vis. 35: 68–85, 2009). Hickman (J. Math Imaging Vis. 43: 206–213, 2012, Theorem 2) claimed that for non-degenerate planar curves, equality of Euclidean signatures implies congruence. We prove that while Hickman’s claim holds for simple, closed curves with simple signatures, it fails for curves with non-simple signatures. In the latter case, we associate a directed graph with the signature and show how various paths along the graph give rise to a family of non-congruent, non-degenerate curves with identical signatures. Using this additional structure, we formulate congruence criteria for non-degenerate, closed, simple curves and show how the paths reflect the global and local symmetries of the corresponding curve.},
  archive      = {J_JMIV},
  author       = {Geiger, Eric and Kogan, Irina A.},
  doi          = {10.1007/s10851-020-01015-x},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {6},
  number       = {5},
  pages        = {601-625},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Non-congruent non-degenerate curves with identical signatures},
  volume       = {63},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Inexact derivative-free optimization for bilevel learning.
<em>JMIV</em>, <em>63</em>(5), 580–600. (<a
href="https://doi.org/10.1007/s10851-021-01020-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Variational regularization techniques are dominant in the field of mathematical imaging. A drawback of these techniques is that they are dependent on a number of parameters which have to be set by the user. A by-now common strategy to resolve this issue is to learn these parameters from data. While mathematically appealing, this strategy leads to a nested optimization problem (known as bilevel optimization) which is computationally very difficult to handle. It is common when solving the upper-level problem to assume access to exact solutions of the lower-level problem, which is practically infeasible. In this work we propose to solve these problems using inexact derivative-free optimization algorithms which never require exact lower-level problem solutions, but instead assume access to approximate solutions with controllable accuracy, which is achievable in practice. We prove global convergence and a worst-case complexity bound for our approach. We test our proposed framework on ROF denoising and learning MRI sampling patterns. Dynamically adjusting the lower-level accuracy yields learned parameters with similar reconstruction quality as high-accuracy evaluations but with dramatic reductions in computational work (up to 100 times faster in some cases).},
  archive      = {J_JMIV},
  author       = {Ehrhardt, Matthias J. and Roberts, Lindon},
  doi          = {10.1007/s10851-021-01020-8},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {6},
  number       = {5},
  pages        = {580-600},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Inexact derivative-free optimization for bilevel learning},
  volume       = {63},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Combining the band-limited parameterization and
semi-lagrangian runge–kutta integration for efficient PDE-constrained
LDDMM. <em>JMIV</em>, <em>63</em>(5), 555–579. (<a
href="https://doi.org/10.1007/s10851-021-01016-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The family of PDE-constrained Large Deformation Diffeomorphic Metric Mapping (LDDMM) methods is emerging as a particularly interesting approach for physically meaningful diffeomorphic transformations. The original combination of Gauss–Newton–Krylov optimization and Runge–Kutta integration shows excellent numerical accuracy and fast convergence rate. However, its most significant limitation is the huge computational complexity, hindering its extensive use in Computational Anatomy applied studies. This limitation has been treated independently by the problem formulation in the space of band-limited vector fields and semi-Lagrangian integration. The purpose of this work is to combine both in three variants of band-limited PDE-constrained LDDMM for further increasing their computational efficiency. The accuracy of the resulting methods is evaluated extensively. For all the variants, the proposed combined approach shows a significant increment of the computational efficiency. In addition, the variant based on the deformation state equation is positioned consistently as the best performing method across all the evaluation frameworks in terms of accuracy and efficiency.},
  archive      = {J_JMIV},
  author       = {Hernandez, Monica},
  doi          = {10.1007/s10851-021-01016-4},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {6},
  number       = {5},
  pages        = {555-579},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Combining the band-limited parameterization and semi-lagrangian Runge–Kutta integration for efficient PDE-constrained LDDMM},
  volume       = {63},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A novel discriminant locality preserving projections method.
<em>JMIV</em>, <em>63</em>(5), 541–554. (<a
href="https://doi.org/10.1007/s10851-020-01008-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Locality preserving projections (LPP) is a popular unsupervised dimensionality reduction method based on manifold learning. As a supervised version of the LPP method, discriminant locality preserving projections (DLPP) method has been recently proposed and paid much attention to by researchers. However, the DLPP method has the small-sample-size (SSS) problem. In this paper, in the view of the eigenvalues of scattering matrices of DLPP, they are first mapped to the new values by two polynomial functions, and with the properties of the matrix function of the two polynomial functions, the criterion of the DLPP method is reconstructed; thus, a novel dimensionality reduction method, named polynomial discriminant locality preserving projections (PDLPP) method, is proposed. The proposed PDLPP method has two advantages: one is that it addresses the SSS problem of DLPP, and the other is that, with the nonlinear mapping implied by PDLPP, the distance between inter-class samples is much enlarged and then the better performance of pattern classification is achieved. The experiments are conducted on the COIL-20 database, ORL, Georgia Tech, and AR face datasets, and the results show that the PDLPP is superior to state-of-the-art methods.},
  archive      = {J_JMIV},
  author       = {Ran, Ruisheng and Ren, Yinshan and Zhang, Shougui and Fang, Bin},
  doi          = {10.1007/s10851-020-01008-w},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {6},
  number       = {5},
  pages        = {541-554},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {A novel discriminant locality preserving projections method},
  volume       = {63},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Analysing “simple” image registrations. <em>JMIV</em>,
<em>63</em>(4), 528–540. (<a
href="https://doi.org/10.1007/s10851-021-01018-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Processes such as growth and atrophy cause changes through time that can be visible in a series of medical images, following the hypothesis that form follows function. As was hypothesised by D’Arcy Thompson more than 100 years ago, models of the changes inherent in these actions can aid understanding of the processes at work. We consider how image registration using finite-dimensional planar Lie groups (in contrast to general diffeomorphisms) can be used in this process. The deformations identified can be described as points in the Lie algebra, thus enabling processes such as evolutionary change, growth, and deformation from disease, to be described in a linear space. The choice of appropriate Lie group becomes a modelling choice and can be selected using model selection; Occam’s razor suggests that groups with the smallest number of parameters (which Thompson referred to as ‘simple transformations’) are to be preferred. We demonstrate our method on an example from Thompson of the cannon-bones of three hoofed mammals and a set of outline curves of the development of the human skull, with promising results.},
  archive      = {J_JMIV},
  author       = {Marsland, Stephen and McLachlan, Robert I. and Zarre, Raziyeh},
  doi          = {10.1007/s10851-021-01018-2},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {5},
  number       = {4},
  pages        = {528-540},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Analysing ‘Simple’ image registrations},
  volume       = {63},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Adaptive periodic noise reduction in digital images using
fuzzy transform. <em>JMIV</em>, <em>63</em>(4), 503–527. (<a
href="https://doi.org/10.1007/s10851-020-01004-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Periodic noise degrades the image quality by overlaying similar patterns. This noise appears as peaks in the image spectrum. In this research, a method based on fuzzy transform has been developed to identify and reduce the peaks adaptively. We convert the periodic noise removal task as image compression and a smoothing problem. We first utilize the direct and inverse fuzzy transform of the spectrum to detect periodic noise peaks. Second, we propose a fuzzy transform-based notch filter for spectral smoothing and separating the original image from the periodic noise components. This noise correction approach filters out a portion (given by fuzzy transform) of the noise component. Extensive experiments on both synthetic and non-synthetic noisy images have been carried out to validate the effectiveness and efficiency of the proposed algorithm. The simulation results demonstrate that the proposed method outperforms state of the art algorithms both visually and quantitatively.},
  archive      = {J_JMIV},
  author       = {Alibabaie, Najmeh and Latif, AliMohammad},
  doi          = {10.1007/s10851-020-01004-0},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {5},
  number       = {4},
  pages        = {503-527},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Adaptive periodic noise reduction in digital images using fuzzy transform},
  volume       = {63},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Levenberg–marquardt algorithm for acousto-electric
tomography based on the complete electrode model. <em>JMIV</em>,
<em>63</em>(4), 492–502. (<a
href="https://doi.org/10.1007/s10851-020-01006-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The inverse problem in acousto-electric tomography concerns the reconstruction of the electric conductivity in a body from knowledge of the power density function in the interior of the body. This interior power density results from currents prescribed at boundary electrodes, and it can be obtained through electro-static boundary measurements together with auxiliary acoustic probing. Previous works on acousto-electric tomography used the continuum model for the electrostatic boundary conditions; however, from Electrical Impedance Tomography, it is known that the complete electrode model is much more realistic and accurate. In this paper, the inverse problem of acousto-electric tomography is posed using the (smoothened) complete electrode model, and a reconstruction method based on the Levenberg–Marquardt iteration is formulated in appropriate function spaces. This results in a system of partial differential equations to be solved in each step. To increase the computational efficiency and stability, a strategy based on both the complete electrode model and the continuum model is proposed. The method is implemented numerically for a two-dimensional scenario, and the algorithm is tested on two different numerical phantoms, a heart and lung model and a human brain model. Several numerical experiments are carried out confirming the feasibility, accuracy and stability of the developed method.},
  archive      = {J_JMIV},
  author       = {Li, Changyou and Karamehmedović, Mirza and Sherina, Ekaterina and Knudsen, Kim},
  doi          = {10.1007/s10851-020-01006-y},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {5},
  number       = {4},
  pages        = {492-502},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Levenberg–Marquardt algorithm for acousto-electric tomography based on the complete electrode model},
  volume       = {63},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A continuous relaxation of the constrained <span
class="math display"><em>ℓ</em><sub>2</sub> − <em>ℓ</em><sub>0</sub></span>
problem. <em>JMIV</em>, <em>63</em>(4), 472–491. (<a
href="https://doi.org/10.1007/s10851-020-01014-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We focus on the minimization of the least square loss function under a k-sparse constraint encoded by a $$\ell _0$$ pseudo-norm. This is a non-convex, non-continuous and NP-hard problem. Recently, for the penalized form (sum of the least square loss function and a $$\ell _0$$ penalty term), a relaxation has been introduced which has strong results in terms of minimizers. This relaxation is continuous and does not change the global minimizers, among other favorable properties. The question that has driven this paper is the following: can a continuous relaxation of the k-sparse constraint problem be developed following the same idea and same steps as for the penalized $$\ell _2-\ell _0$$ problem? We calculate the convex envelope of the constrained problem when the observation matrix is orthogonal and propose a continuous non-smooth, non-convex relaxation of the k-sparse constraint functional. We give some equivalence of minimizers between the original and the relaxed problems. The subgradient is calculated as well as the proximal operator of the new regularization term, and we propose an algorithm that ensures convergence to a critical point of the k-sparse constraint problem. We apply the algorithm to the problem of single-molecule localization microscopy and compare the results with well-known sparse minimization schemes. The results of the proposed algorithm are as good as the state-of-the-art results for the penalized form, while fixing the constraint constant is usually more intuitive than fixing the penalty parameter.},
  archive      = {J_JMIV},
  author       = {Bechensteen, Arne Henrik and Blanc-Féraud, Laure and Aubert, Gilles},
  doi          = {10.1007/s10851-020-01014-y},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {5},
  number       = {4},
  pages        = {472-491},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {A continuous relaxation of the constrained $$\ell _2-\ell _0$$ problem},
  volume       = {63},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Point cloud registration using virtual interest points from
macaulay’s resultant of quadric surfaces. <em>JMIV</em>, <em>63</em>(4),
457–471. (<a href="https://doi.org/10.1007/s10851-020-01013-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A novel formulation called Virtual Interest Point is presented and used to register point clouds. An implicit quadric surface representation is first used to model the point cloud segments. Macaulay’s resultant then provides the intersection of three such quadrics, which forms a virtual interest point (VIP). A unique feature descriptor for each VIP is computed, and correspondences in descriptor space are established to compute the rigid transformation to register two point clouds. Each step in the process is designed to consider robustness to noise and data density variations, as well as computational efficiency. Experiments were performed on 12 data sets, collected with a variety of range sensors, to characterize robustness to noise, data density variation, and computational efficiency. The data sets were extracted from both natural scenes, including plants and rocks, and indoor architectural scenes, such as cluttered offices and laboratories. Similarly, several 3D models were tested for registration to demonstrate the generality of the technique. The proposed method significantly outperformed a variety of alternative state-of-the-art approaches, such as 2.5D SIFT-based RANSAC method, Super 4-Point Congruent Sets and Super Generalized 4PCS, and the Go-ICP method in registering overlapping point clouds with both a higher success rate and reduced computational cost.},
  archive      = {J_JMIV},
  author       = {Ahmed, Mirza Tahir and Ziauddin, Sheikh and Marshall, Joshua A. and Greenspan, Michael},
  doi          = {10.1007/s10851-020-01013-z},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {5},
  number       = {4},
  pages        = {457-471},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Point cloud registration using virtual interest points from macaulay’s resultant of quadric surfaces},
  volume       = {63},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). On the reconstruction of the center of a projection by
distances and incidence relations. <em>JMIV</em>, <em>63</em>(4),
443–456. (<a href="https://doi.org/10.1007/s10851-020-00999-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Up to an orientation-preserving symmetry, photographic images are produced by a central projection of a restricted area in the space into the image plane. To obtain reliable information about physical objects and the environment through the process of recording is the basic problem of photogrammetry. We present a reconstruction process based on distances from the center of projection and incidence relations among the points to be projected. For any triplet of collinear points in the space, we construct a surface of revolution containing the center of the projection. It is a generalized conic that can be represented as an algebraic surface. The rotational symmetry allows us to restrict the investigations to the defining polynomial of the profile curve in the image plane. An equivalent condition for the boundedness is given in terms of the input parameters, and it is shown that the defining polynomial of the profile curve is irreducible.},
  archive      = {J_JMIV},
  author       = {Pongrácz, András and Vincze, Csaba},
  doi          = {10.1007/s10851-020-00999-w},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {5},
  number       = {4},
  pages        = {443-456},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {On the reconstruction of the center of a projection by distances and incidence relations},
  volume       = {63},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Appreciation to the journal of mathematical imaging and
vision reviewers. <em>JMIV</em>, <em>63</em>(3), 441–442. (<a
href="https://doi.org/10.1007/s10851-021-01022-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JMIV},
  doi          = {10.1007/s10851-021-01022-6},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {3},
  number       = {3},
  pages        = {441-442},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Appreciation to the journal of mathematical imaging and vision reviewers},
  volume       = {63},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Boundary ghosts for discrete tomography. <em>JMIV</em>,
<em>63</em>(3), 428–440. (<a
href="https://doi.org/10.1007/s10851-020-01010-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Discrete tomography reconstructs an image of an object on a grid from its discrete projections along relatively few directions. When the resulting system of linear equations is under-determined, the reconstructed image is not unique. Ghosts are arrays of signed pixels that have zero sum projections along these directions; they define the image pixel locations that have non-unique solutions. In general, the discrete projection directions are chosen to define a ghost that has minimal impact on the reconstructed image. Here we construct binary boundary ghosts, which only affect a thin string of pixels distant from the object centre. This means that a large portion of the object around its centre can be uniquely reconstructed. We construct these boundary ghosts from maximal primitive ghosts, configurations of $$2^N$$ connected binary ( $$\pm 1$$ ) points over N directions. Maximal ghosts obfuscate image reconstruction and find application in secure storage of digital data.},
  archive      = {J_JMIV},
  author       = {Ceko, Matthew and Petersen, Timothy and Svalbe, Imants and Tijdeman, Rob},
  doi          = {10.1007/s10851-020-01010-2},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {3},
  number       = {3},
  pages        = {428-440},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Boundary ghosts for discrete tomography},
  volume       = {63},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Gray balance adjusting in electrophotography by means of
discrete geodesics of gradation surfaces. <em>JMIV</em>, <em>63</em>(3),
417–427. (<a href="https://doi.org/10.1007/s10851-020-01009-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gray balance is one of the key issues of color balance and color appearance adjustment during printing. It takes into account the overlap of two or more colorants to achieve a visually neutral tone. It works in parallel with the adjustment of the main color channels. In electrophotography, the setting of color channels separately is usually carried out using tone reproduction curves. However, this traditional approach does not take into account the effect of changes in shades caused by their overlapping, We previously suggested using gradation trajectories (an analogue of tone reproduction curves in CIE Lab space) as an alternative paradigm for color channel adjustment. Further, we expanded the idea to the gradation surfaces as an expression of binary overlays. We proposed both analytic and discrete approaches to the computation of gradation trajectories and surfaces. The computations use the mathematical apparatus of differential geometry of spatial curves and surfaces. Discretization uses color quantization in digital printing devices and means that color coordinates are considered as continuous functions of filling a discrete raster cell with dyes. The color space metric is determined by the value of the CIE dE color difference. As gradation trajectories, we apply the discrete type of geodesic lines on the gradation surfaces of the corresponding binaries. In this work, we suggest using gradation surfaces in discrete form as a mathematical model of double dye overlays to adjust the gray balance in electrophotography.},
  archive      = {J_JMIV},
  author       = {Tarasov, Dmitry A. and Milder, Oleg B.},
  doi          = {10.1007/s10851-020-01009-9},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {3},
  number       = {3},
  pages        = {417-427},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Gray balance adjusting in electrophotography by means of discrete geodesics of gradation surfaces},
  volume       = {63},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). <span class="math display"><em>C</em><sup>2</sup></span>
rational interpolation splines with region control and image
interpolation application. <em>JMIV</em>, <em>63</em>(3), 394–416. (<a
href="https://doi.org/10.1007/s10851-020-01005-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we deal with the region control of $$C^2$$ interpolation curves and surfaces using a class of rational interpolation splines in one and two dimensions. Simple sufficient data-dependent constraints are derived on the local control parameters to generate $$C^2$$ interpolation curves lying strictly between two given piecewise linear curves and $$C^2$$ interpolation surfaces lying strictly between two given piecewise bi-liner blending quintic interpolation surfaces. Moreover, we also develop an algorithm concerning the application of the $$C^2$$ rational interpolation spline surfaces on image interpolation.},
  archive      = {J_JMIV},
  author       = {Liu, Zhuo and Liu, Shengjun and Zhu, Yuanpeng},
  doi          = {10.1007/s10851-020-01005-z},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {3},
  number       = {3},
  pages        = {394-416},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {$$C^2$$ rational interpolation splines with region control and image interpolation application},
  volume       = {63},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Benefiting from duplicates of compressed data: Shift-based
holographic compression of images. <em>JMIV</em>, <em>63</em>(3),
380–393. (<a href="https://doi.org/10.1007/s10851-020-01003-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Storage systems often rely on multiple copies of the same compressed data, enabling recovery in case of binary data errors, of course, at the expense of a higher storage cost. In this paper, we show that a wiser method of duplication entails great potential benefits for data types tolerating approximate representations, like images and videos. We propose a method to produce a set of distinct compressed representations for a given signal, such that any subset of them allows reconstruction of the signal at a quality depending only on the number of compressed representations utilized. Essentially, we implement the holographic representation idea, where all the representations are equally important in refining the reconstruction. Here, we propose to exploit the shift sensitivity of common compression processes and generate holographic representations via compression of various shifts of the signal. Two implementations for the idea, based on standard compression methods, are presented: the first is a simple, optimization-free design. The second approach originates in a challenging rate-distortion optimization, mitigated by the alternating direction method of multipliers (ADMM), leading to a process of repeatedly applying standard compression techniques. Evaluation of the approach, in conjunction with the JPEG2000 image compression standard, shows the effectiveness of the optimization in providing compressed holographic representations that, by means of an elementary reconstruction process, enable impressive gains of several dBs in PSNR over exact duplications.},
  archive      = {J_JMIV},
  author       = {Dar, Yehuda and Bruckstein, Alfred M.},
  doi          = {10.1007/s10851-020-01003-1},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {3},
  number       = {3},
  pages        = {380-393},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Benefiting from duplicates of compressed data: Shift-based holographic compression of images},
  volume       = {63},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Effective two-stage image segmentation: A new non-lipschitz
decomposition approach with convergent algorithm. <em>JMIV</em>,
<em>63</em>(3), 356–379. (<a
href="https://doi.org/10.1007/s10851-020-01001-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image segmentation is an important median level vision topic. Accurate and efficient multiphase segmentation for images with intensity inhomogeneity is still a great challenge. We present a new two-stage multiphase segmentation method trying to tackle this, where the key is to compute an inhomogeneity-free approximate image. For this, we propose to use a new non-Lipschitz variational decomposition model in the first stage. The minimization problem is solved by an iterative support shrinking algorithm. By assuming that the subproblem at each iteration is exactly solved, we show the global convergence of the iterative algorithm and a lower bound theory of the image gradient of the iterative sequence, which indicates that the generated approximate image (inhomogeneity-corrected component) is with very neat edges and suitable for the following thresholding operation. Implementation details based on the alternating direction method of multipliers for the strongly convex subproblems are also given. In the second stage, the segmentation is done by applying a widely used simple thresholding technique to the piecewise constant approximation. Numerical experiments indicate good convergence properties and effectiveness of our method in multiphase segmentation for either clean or noisy homogeneous and inhomogeneous images. Both visual and quantitative comparisons with some state-of-the-art approaches demonstrate the performance advantages of our non-Lipschitz-based method.},
  archive      = {J_JMIV},
  author       = {Guo, Xueyan and Xue, Yunhua and Wu, Chunlin},
  doi          = {10.1007/s10851-020-01001-3},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {3},
  number       = {3},
  pages        = {356-379},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Effective two-stage image segmentation: A new non-lipschitz decomposition approach with convergent algorithm},
  volume       = {63},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Predictive online optimisation with applications to optical
flow. <em>JMIV</em>, <em>63</em>(3), 329–355. (<a
href="https://doi.org/10.1007/s10851-020-01000-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Online optimisation revolves around new data being introduced into a problem while it is still being solved; think of deep learning as more training samples become available. We adapt the idea to dynamic inverse problems such as video processing with optical flow. We introduce a corresponding predictive online primal-dual proximal splitting method. The video frames now exactly correspond to the algorithm iterations. A user-prescribed predictor describes the evolution of the primal variable. To prove convergence we need a predictor for the dual variable based on (proximal) gradient flow. This affects the model that the method asymptotically minimises. We show that for inverse problems the effect is, essentially, to construct a new dynamic regulariser based on infimal convolution of the static regularisers with the temporal coupling. We finish by demonstrating excellent real-time performance of our method in computational image stabilisation and convergence in terms of regularisation theory.},
  archive      = {J_JMIV},
  author       = {Valkonen, Tuomo},
  doi          = {10.1007/s10851-020-01000-4},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {3},
  number       = {3},
  pages        = {329-355},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Predictive online optimisation with applications to optical flow},
  volume       = {63},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Image morphing in deep feature spaces: Theory and
applications. <em>JMIV</em>, <em>63</em>(2), 309–327. (<a
href="https://doi.org/10.1007/s10851-020-00974-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper combines image metamorphosis with deep features. To this end, images are considered as maps into a high-dimensional feature space and a structure-sensitive, anisotropic flow regularization is incorporated in the metamorphosis model proposed by Miller and Younes (Int J Comput Vis 41(1):61–84, 2001) and Trouvé and Younes (Found Comput Math 5(2):173–198, 2005). For this model, a variational time discretization of the Riemannian path energy is presented and the existence of discrete geodesic paths minimizing this energy is demonstrated. Furthermore, convergence of discrete geodesic paths to geodesic paths in the time continuous model is investigated. The spatial discretization is based on a finite difference approximation in image space and a stable spline approximation in deformation space; the fully discrete model is optimized using the iPALM algorithm. Numerical experiments indicate that the incorporation of semantic deep features is superior to intensity-based approaches.},
  archive      = {J_JMIV},
  author       = {Effland, Alexander and Kobler, Erich and Pock, Thomas and Rajković, Marko and Rumpf, Martin},
  doi          = {10.1007/s10851-020-00974-5},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {2},
  number       = {2},
  pages        = {309-327},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Image morphing in deep feature spaces: Theory and applications},
  volume       = {63},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A stochastic multi-layer algorithm for semi-discrete optimal
transport with applications to texture synthesis and style transfer.
<em>JMIV</em>, <em>63</em>(2), 282–308. (<a
href="https://doi.org/10.1007/s10851-020-00975-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates a new stochastic algorithm to approximate semi-discrete optimal transport for large-scale problem, i.e., in high dimension and for a large number of points. The proposed technique relies on a hierarchical decomposition of the target discrete distribution and the transport map itself. A stochastic optimization algorithm is derived to estimate the parameters of the corresponding multi-layer weighted nearest neighbor model. This model allows for fast evaluation during synthesis and training, for which it exhibits faster empirical convergence. Several applications to patch-based image processing are investigated: texture synthesis, texture inpainting, and style transfer. The proposed models compare favorably to the state of the art, either in terms of image quality, computation time, or regarding the number of parameters. Additionally, they do not require any pixel-based optimization or training on a large dataset of natural images.},
  archive      = {J_JMIV},
  author       = {Leclaire, Arthur and Rabin, Julien},
  doi          = {10.1007/s10851-020-00975-4},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {2},
  number       = {2},
  pages        = {282-308},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {A stochastic multi-layer algorithm for semi-discrete optimal transport with applications to texture synthesis and style transfer},
  volume       = {63},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Cortical-inspired wilson–cowan-type equations for
orientation-dependent contrast perception modelling. <em>JMIV</em>,
<em>63</em>(2), 263–281. (<a
href="https://doi.org/10.1007/s10851-020-00960-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the evolution model proposed in Bertalmío (Front Comput Neurosci 8:71, 2014), Bertalmío et al. (IEEE Trans Image Process 16(4):1058–1072, 2007) to describe illusory contrast perception phenomena induced by surrounding orientations. Firstly, we highlight its analogies and differences with the widely used Wilson–Cowan equations (Wilson and Cowan in BioPhys J 12(1):1–24, 1972), mainly in terms of efficient representation properties. Then, in order to explicitly encode local directional information, we exploit the model of the primary visual cortex (V1) proposed in Citti and Sarti (J Math Imaging Vis 24(3):307–326, 2006) and largely used over the last years for several image processing problems (Duits and Franken in Q Appl Math 68(2):255–292, 2010; Prandi and Gauthier in A semidiscrete version of the Petitot model as a plausible model for anthropomorphic image reconstruction and pattern recognition. SpringerBriefs in Mathematics, Springer, Cham, 2017; Franceschiello et al. in J Math Imaging Vis 60(1):94–108, 2018). The resulting model is thus defined in the space of positions and orientation, and it is capable of describing assimilation and contrast visual bias at the same time. We report several numerical tests showing the ability of the model to reproduce, in particular, orientation-dependent phenomena such as grating induction and a modified version of the Poggendorff illusion. For this latter example, we empirically show the existence of a set of threshold parameters differentiating from inpainting to perception-type reconstructions and describing long-range connectivity between different hypercolumns in V1.},
  archive      = {J_JMIV},
  author       = {Bertalmío, Marcelo and Calatroni, Luca and Franceschi, Valentina and Franceschiello, Benedetta and Prandi, Dario},
  doi          = {10.1007/s10851-020-00960-x},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {2},
  number       = {2},
  pages        = {263-281},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Cortical-inspired Wilson–Cowan-type equations for orientation-dependent contrast perception modelling},
  volume       = {63},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Total variation and mean curvature PDEs on the homogeneous
space of positions and orientations. <em>JMIV</em>, <em>63</em>(2),
237–262. (<a href="https://doi.org/10.1007/s10851-020-00991-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Two key ideas have greatly improved techniques for image enhancement and denoising: the lifting of image data to multi-orientation distributions and the application of nonlinear PDEs such as total variation flow (TVF) and mean curvature flow (MCF). These two ideas were recently combined by Chambolle and Pock (for TVF) and Citti et al. (for MCF) for two-dimensional images. In this work, we extend their approach to enhance and denoise images of arbitrary dimension, creating a unified geometric and algorithmic PDE framework, relying on (sub-)Riemannian geometry. In particular, we follow a different numerical approach, for which we prove convergence in the case of TVF by an application of Brezis–Komura gradient flow theory. Our framework also allows for additional data adaptation through the use of locally adaptive frames and coherence enhancement techniques. We apply TVF and MCF to the enhancement and denoising of elongated structures in 2D images via orientation scores and compare the results to Perona–Malik diffusion and BM3D. We also demonstrate our techniques in 3D in the denoising and enhancement of crossing fiber bundles in DW-MRI. In comparison with data-driven diffusions, we see a better preservation of bundle boundaries and angular sharpness in fiber orientation densities at crossings.},
  archive      = {J_JMIV},
  author       = {Smets, Bart M. N. and Portegies, Jim and St-Onge, Etienne and Duits, Remco},
  doi          = {10.1007/s10851-020-00991-4},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {2},
  number       = {2},
  pages        = {237-262},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Total variation and mean curvature PDEs on the homogeneous space of positions and orientations},
  volume       = {63},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Block-based refitting in <span
class="math display"><em>ℓ</em><sub>12</sub></span> sparse
regularization. <em>JMIV</em>, <em>63</em>(2), 216–236. (<a
href="https://doi.org/10.1007/s10851-020-00993-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In many linear regression problems, including ill-posed inverse problems in image restoration, the data exhibit some sparse structures that can be used to regularize the inversion. To this end, a classical path is to use $$\ell _{12}$$ block-based regularization. While efficient at retrieving the inherent sparsity patterns of the data—the support—the estimated solutions are known to suffer from a systematical bias. We propose a general framework for removing this artifact by refitting the solution toward the data while preserving key features of its structure such as the support. This is done through the use of refitting block penalties that only act on the support of the estimated solution. Based on an analysis of related works in the literature, we introduce a new penalty that is well suited for refitting purposes. We also present a new algorithm to obtain the refitted solution along with the original (biased) solution for any convex refitting block penalty. Experiments illustrate the good behavior of the proposed block penalty for refitting solutions of total variation and total generalized variation models.},
  archive      = {J_JMIV},
  author       = {Deledalle, Charles-Alban and Papadakis, Nicolas and Salmon, Joseph and Vaiter, Samuel},
  doi          = {10.1007/s10851-020-00993-2},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {2},
  number       = {2},
  pages        = {216-236},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Block-based refitting in $$\ell _{12}$$ sparse regularization},
  volume       = {63},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Learning adaptive regularization for image labeling using
geometric assignment. <em>JMIV</em>, <em>63</em>(2), 186–215. (<a
href="https://doi.org/10.1007/s10851-020-00977-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the inverse problem of model parameter learning for pixelwise image labeling, using the linear assignment flow and training data with ground truth. This is accomplished by a Riemannian gradient flow on the manifold of parameters that determines the regularization properties of the assignment flow. Using the symplectic partitioned Runge–Kutta method for numerical integration, it is shown that deriving the sensitivity conditions of the parameter learning problem and its discretization commute. A convenient property of our approach is that learning is based on exact inference. Carefully designed experiments demonstrate the performance of our approach, the expressiveness of the mathematical model as well as its limitations, from the viewpoint of statistical learning and optimal control.},
  archive      = {J_JMIV},
  author       = {Hühnerbein, Ruben and Savarino, Fabrizio and Petra, Stefania and Schnörr, Christoph},
  doi          = {10.1007/s10851-020-00977-2},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {2},
  number       = {2},
  pages        = {186-215},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Learning adaptive regularization for image labeling using geometric assignment},
  volume       = {63},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). PDE evolutions for m-smoothers in one, two, and three
dimensions. <em>JMIV</em>, <em>63</em>(2), 157–185. (<a
href="https://doi.org/10.1007/s10851-020-00986-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Local M-smoothers are interesting and important signal and image processing techniques with many connections to other methods. In our paper, we derive a family of partial differential equations (PDEs) that result in one, two, and three dimensions as limiting processes from M-smoothers which are based on local order-p means within a ball the radius of which tends to zero. The order p may take any nonzero value $$&gt;-1$$ , allowing also negative values. In contrast to results from the literature, we show in the space-continuous case that mode filtering does not arise for $$p \rightarrow 0$$ , but for $$p \rightarrow -1$$ . Extending our filter class to p-values smaller than $$-1$$ allows to include, e.g. the classical image sharpening flow of Gabor. The PDEs we derive in 1D, 2D, and 3D show large structural similarities. Since our PDE class is highly anisotropic and may contain backward parabolic operators, designing adequate numerical methods is difficult. We present an $$L^\infty $$ -stable explicit finite difference scheme that satisfies a discrete maximum–minimum principle, offers excellent rotation invariance, and employs a splitting into four fractional steps to allow larger time step sizes. Although it approximates parabolic PDEs, it consequently benefits from stabilisation concepts from the numerics of hyperbolic PDEs. Our 2D experiments show that the PDEs for $$p&lt;1$$ are of specific interest: Their backward parabolic term creates favourable sharpening properties, while they appear to maintain the strong shape simplification properties of mean curvature motion.},
  archive      = {J_JMIV},
  author       = {Welk, Martin and Weickert, Joachim},
  doi          = {10.1007/s10851-020-00986-1},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {2},
  number       = {2},
  pages        = {157-185},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {PDE evolutions for M-smoothers in one, two, and three dimensions},
  volume       = {63},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Towards PDE-based video compression with optimal masks
prolongated by optic flow. <em>JMIV</em>, <em>63</em>(2), 144–156. (<a
href="https://doi.org/10.1007/s10851-020-00973-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lossy image compression methods based on partial differential equations have received much attention in recent years. They may yield high-quality results but rely on the computationally expensive task of finding an optimal selection of data. For the possible extension to video compression, this data selection is a crucial issue. In this context, one could either analyse the video sequence as a whole or perform a frame-by-frame optimisation strategy. Both approaches are prohibitive in terms of memory and run time. In this work, we propose to restrict the expensive computation of optimal data to a single frame and to approximate the optimal reconstruction data for the remaining frames by prolongating it by means of an optic flow field. In this way, we achieve a notable decrease in the computational complexity. As a proof-of-concept, we evaluate the proposed approach for multiple sequences with different characteristics. In doing this, we discuss in detail the influence of possible computational setups. We show that the approach preserves a reasonable quality in the reconstruction and is very robust against errors in the flow field.},
  archive      = {J_JMIV},
  author       = {Breuß, Michael and Hoeltgen, Laurent and Radow, Georg},
  doi          = {10.1007/s10851-020-00973-6},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {2},
  number       = {2},
  pages        = {144-156},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Towards PDE-based video compression with optimal masks prolongated by optic flow},
  volume       = {63},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Computed tomography reconstruction with uncertain view
angles by iteratively updated model discrepancy. <em>JMIV</em>,
<em>63</em>(2), 133–143. (<a
href="https://doi.org/10.1007/s10851-020-00972-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a new model and a corresponding iterative algorithm for Computed Tomography (CT) when the view angles are uncertain. The uncertainty is described by an additive model discrepancy term which is included in the data fidelity term of a total variation regularized variational model. We approximate the model discrepancy with a Gaussian distribution. Our iterative algorithm alternates between updating the CT reconstruction and parameters of the model discrepancy. By assuming that the uncertainties in the view angles are independent we achieve a covariance matrix structure that we can take advantage of in a stochastic primal dual method to greatly reduce the computational work compared to classical primal dual methods. Using simulations with 2D problems we demonstrate that our method is able to reduce the reconstruction error and improve the visual quality, compared to methods that ignore the uncertainties in the angles.},
  archive      = {J_JMIV},
  author       = {Riis, Nicolai André Brogaard and Dong, Yiqiu and Hansen, Per Christian},
  doi          = {10.1007/s10851-020-00972-7},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {2},
  number       = {2},
  pages        = {133-143},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Computed tomography reconstruction with uncertain view angles by iteratively updated model discrepancy},
  volume       = {63},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Guest editorial: Scale space and variational methods.
<em>JMIV</em>, <em>63</em>(2), 131–132. (<a
href="https://doi.org/10.1007/s10851-020-01012-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JMIV},
  author       = {Lellmann, Jan and Modersitzki, Jan},
  doi          = {10.1007/s10851-020-01012-0},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {2},
  number       = {2},
  pages        = {131-132},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Guest editorial: Scale space and variational methods},
  volume       = {63},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Rigidity properties of the blum medial axis. <em>JMIV</em>,
<em>63</em>(1), 120–129. (<a
href="https://doi.org/10.1007/s10851-020-00998-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the Blum medial axis of a region in $$\mathbb R^n$$ with piecewise smooth boundary and examine its “rigidity properties,”by which we mean properties preserved under diffeomorphisms of the regions preserving the medial axis. There are several possible versions of rigidity depending on what features of the Blum medial axis we wish to retain. We use a form of the cross ratio from projective geometry to show that in the case of four smooth sheets of the medial axis meeting along a branching submanifold, the cross ratio defines a function on the branching sheet which must be preserved under any diffeomorphism of the medial axis with another. Second, we show in the generic case, along a Y-branching submanifold, that there are three cross ratios involving the three limiting tangent planes of the three smooth sheets and each of the hyperplanes defined by one of the radial lines and the tangent space to the Y-branching submanifold at the point, which again must be preserved. Moreover, the triple of cross ratios then locally uniquely determines the angles between the smooth sheets. Third, we observe that for a diffeomorphism of the region preserving the Blum medial axis and the infinitesimal directions of the radial lines, the second derivative of the diffeomorphism at points of the medial axis must satisfy a condition relating the radial shape operators and hence the differential geometry of the boundaries at corresponding boundary points.},
  archive      = {J_JMIV},
  author       = {Damon, James},
  doi          = {10.1007/s10851-020-00998-x},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {1},
  number       = {1},
  pages        = {120-129},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Rigidity properties of the blum medial axis},
  volume       = {63},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). On particle-size distribution of convex similar bodies in
<span class="math display">ℝ<sup>3</sup></span>. <em>JMIV</em>,
<em>63</em>(1), 108–119. (<a
href="https://doi.org/10.1007/s10851-020-00997-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We have solved an old problem posed by Santaló of determining the size distribution of particles derived from the size distribution of their sections. We give an explicit form of particle-size distributions of convex similar bodies for random planes and random lines, which naturally generalize famous Wicksell’s corpuscle problem. The results are achieved by applying the method of model solutions for solving well-known Santaló’s integral equations. We give a partial result related to the question of the existence and uniqueness of these solutions. We also emphasize that the original form of solution of Wicksell’s problem is insufficient. We finally illustrate our approach in several examples.},
  archive      = {J_JMIV},
  author       = {Kisel’ák, J. and Baluchová, G.},
  doi          = {10.1007/s10851-020-00997-y},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {1},
  number       = {1},
  pages        = {108-119},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {On particle-size distribution of convex similar bodies in $${\mathbb {R}}^3$$},
  volume       = {63},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Ground metric learning on graphs. <em>JMIV</em>,
<em>63</em>(1), 89–107. (<a
href="https://doi.org/10.1007/s10851-020-00996-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optimal transport (OT) distances between probability distributions are parameterized by the ground metric they use between observations. Their relevance for real-life applications strongly hinges on whether that ground metric parameter is suitably chosen. The challenge of selecting it adaptively and algorithmically from prior knowledge, the so-called ground metric learning (GML) problem, has therefore appeared in various settings. In this paper, we consider the GML problem when the learned metric is constrained to be a geodesic distance on a graph that supports the measures of interest. This imposes a rich structure for candidate metrics, but also enables far more efficient learning procedures when compared to a direct optimization over the space of all metric matrices. We use this setting to tackle an inverse problem stemming from the observation of a density evolving with time; we seek a graph ground metric such that the OT interpolation between the starting and ending densities that result from that ground metric agrees with the observed evolution. This OT dynamic framework is relevant to model natural phenomena exhibiting displacements of mass, such as the evolution of the color palette induced by the modification of lighting and materials.},
  archive      = {J_JMIV},
  author       = {Heitz, Matthieu and Bonneel, Nicolas and Coeurjolly, David and Cuturi, Marco and Peyré, Gabriel},
  doi          = {10.1007/s10851-020-00996-z},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {1},
  number       = {1},
  pages        = {89-107},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Ground metric learning on graphs},
  volume       = {63},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Video denoising by combining patch search and CNNs.
<em>JMIV</em>, <em>63</em>(1), 73–88. (<a
href="https://doi.org/10.1007/s10851-020-00995-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Non-local patch-based methods were until recently the state of the art for image denoising but are now outperformed by CNNs. In video denoising, however, they are still competitive with CNNs, as they can effectively exploit the video temporal redundancy, which is a key factor to attain high denoising performance. The problem is that CNN architectures are not compatible with the search for self-similarities. In this work, we propose a simple, yet efficient way to feed video self-similarities to a CNN. The non-locality is incorporated into the network via a first non-trainable layer which finds for each patch in the input image its most similar patches in a search region. The central values of these patches are then gathered in a feature vector which is assigned to each image pixel. This information is presented to a CNN which is trained to predict the clean image. We apply the proposed method to image and video denoising. In the case of video, the patches are searched for in a 3D spatiotemporal volume. The proposed method achieves state-of-the-art results.},
  archive      = {J_JMIV},
  author       = {Davy, Axel and Ehret, Thibaud and Morel, Jean-Michel and Arias, Pablo and Facciolo, Gabriele},
  doi          = {10.1007/s10851-020-00995-0},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {1},
  number       = {1},
  pages        = {73-88},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Video denoising by combining patch search and CNNs},
  volume       = {63},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Efficient position estimation of 3D fluorescent spherical
beads in confocal microscopy via poisson denoising. <em>JMIV</em>,
<em>63</em>(1), 56–72. (<a
href="https://doi.org/10.1007/s10851-020-00994-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Particle estimation is a classical problem arising in many science fields, such as biophysics, fluid mechanics and biomedical imaging. Many interesting applications in these areas involve 3D imaging data: This work presents a technique to estimate the 3D coordinates of the center of spherical particles. This procedure has its core in the processing of the images of the scanned volume: It firstly applies denoising techniques to each frame of the scanned volume and then provides an estimation of both the center and the profile of the 2D intersections of the particles with the frames, by coupling the usage of Total Variation functional and of a regularized weighted Least Squares fit. Then, the 2D information is used to retrieve the 3D coordinates using geometrical properties. The experiments provide evidence that image denoising has a large impact on the performance of the particle tracking procedures, since they strongly depend on the quality of the initial acquisition. This work shows that the choice of tailored image denoising technique for Poisson noise leads to a better estimation of the particle positions.},
  archive      = {J_JMIV},
  author       = {Benfenati, Alessandro and Bonacci, Francesco and Bourouina, Tarik and Talbot, Hugues},
  doi          = {10.1007/s10851-020-00994-1},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {1},
  number       = {1},
  pages        = {56-72},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Efficient position estimation of 3D fluorescent spherical beads in confocal microscopy via poisson denoising},
  volume       = {63},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Image reconstruction by minimizing curvatures on image
surface. <em>JMIV</em>, <em>63</em>(1), 30–55. (<a
href="https://doi.org/10.1007/s10851-020-00992-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The curvature regularities are well-known for providing strong priors in the continuity of edges, which have been applied to a wide range of applications in image processing and computer vision. However, these models are usually non-convex, non-smooth, and highly nonlinear, the first-order optimality condition of which are high-order partial differential equations. Thus, numerical computation is extremely challenging. In this paper, we estimate the discrete mean curvature and Gaussian curvature on the local $$3\times 3$$ stencil, based on the fundamental forms in differential geometry. By minimizing certain functions of curvatures over the image surface, it yields a kind of weighted image surface minimization problem, which can be efficiently solved by the alternating direction method of multipliers. Numerical experiments on image restoration and inpainting are implemented to demonstrate the effectiveness and superiority of the proposed curvature-based model compared to state-of-the-art variational approches.},
  archive      = {J_JMIV},
  author       = {Zhong, Qiuxiang and Yin, Ke and Duan, Yuping},
  doi          = {10.1007/s10851-020-00992-3},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {1},
  number       = {1},
  pages        = {30-55},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Image reconstruction by minimizing curvatures on image surface},
  volume       = {63},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A bisector line field approach to interpolation of
orientation fields. <em>JMIV</em>, <em>63</em>(1), 18–29. (<a
href="https://doi.org/10.1007/s10851-020-00990-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose an approach to the problem of global reconstruction of an orientation field. The method is based on a geometric model called bisector line fields, which maps a pair of vector fields to an orientation field, effectively generalizing the notion of doubling phase vector fields. Endowed with a well-chosen energy minimization problem, we provide a polynomial interpolation of a target orientation field while bypassing the doubling phase step. The procedure is then illustrated with examples from fingerprint analysis.},
  archive      = {J_JMIV},
  author       = {Boizot, Nicolas and Sacchelli, Ludovic},
  doi          = {10.1007/s10851-020-00990-5},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {1},
  number       = {1},
  pages        = {18-29},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {A bisector line field approach to interpolation of orientation fields},
  volume       = {63},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An elastica-driven digital curve evolution model for image
segmentation. <em>JMIV</em>, <em>63</em>(1), 1–17. (<a
href="https://doi.org/10.1007/s10851-020-00983-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Geometric priors have been shown to be useful in image segmentation to regularize the results. For example, the classical Mumford–Shah functional uses region perimeter as prior. This has inspired much research in the last few decades, with classical approaches like the Rudin–Osher–Fatemi and most graph-cut formulations, which all use a weighted or binary perimeter prior. It has been observed that this prior is not suitable in many applications, for example for segmenting thin objects or some textures, which may have high perimeter/surface ratio. Mumford observed that an interesting prior for natural objects is the Euler elastical model, which involves the squared curvature. In other areas of science, researchers have noticed that some physical binarization processes, like emulsion unmixing, can be well-approximated by curvature-related flow like the Willmore flow. However, curvature-related flows are not easy to compute because curvature is difficult to estimate accurately, and the underlying optimization processes are not convex. In this article, we propose to formulate a digital flow that approximates an Elastica-related flow using a multigrid-convergent curvature estimator, within a discrete variational framework. We also present an application of this model as a post-processing step to a segmentation framework.},
  archive      = {J_JMIV},
  author       = {Antunes, Daniel and Lachaud, Jacques-Olivier and Talbot, Hugues},
  doi          = {10.1007/s10851-020-00983-4},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {1},
  number       = {1},
  pages        = {1-17},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {An elastica-driven digital curve evolution model for image segmentation},
  volume       = {63},
  year         = {2021},
}
</textarea>
</details></li>
</ul>

</body>
</html>
