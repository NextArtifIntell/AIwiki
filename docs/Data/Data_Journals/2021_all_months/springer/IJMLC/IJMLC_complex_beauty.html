<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>IJMLC_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="ijmlc---219">IJMLC - 219</h2>
<ul>
<li><details>
<summary>
(2021). A novel federated learning approach based on the confidence
of federated kalman filters. <em>IJMLC</em>, <em>12</em>(12), 3607–3627.
(<a href="https://doi.org/10.1007/s13042-021-01410-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning (FL) is an emerging distributed artificial intelligence (AI) algorithm. It can train a global model with multiple participants and at the same time ensure the privacy of the participants’ data. Thus, FL provides a solution for the problems faced by data silos. Existing federated learning algorithms face two significant challenges when dealing with (1) non-independent and identically distributed (non-IID) data, and (2) data with noise or without preprocessing. To address these challenges, a novel federated learning approach based on the confidence of federated Kalman filters is proposed and is referred to as FedCK in this paper. Firstly, this paper proposes a deep Generative Adversarial Network with an advanced auxiliary classifier as a pre-training module. The Non-IID increases the discreteness of the parameters of local models, it is difficult for FL to aggregate an excellent global model. The pre-training module proposed in this paper can deeply mine hidden features and increase the correlation between local model parameters. Secondly, a federated learning framework based on Federated Kalman Filter (FKF) is proposed in this paper. Because the general federation average aggregation algorithm cannot identify the model parameters with noise. This paper uses the idea of FKF to propose a set of adaptive confidence to improve the fault tolerance of FL. Experiments carried out on the MNIST, CIFAR-10 and SVHN datasets demonstrate that FedCK has better robustness and accuracy than classical federated learning methods.},
  archive      = {J_IJMLC},
  author       = {Hu, Kai and Wu, Jiasheng and Weng, Liguo and Zhang, Yanwen and Zheng, Fei and Pang, Zichao and Xia, Min},
  doi          = {10.1007/s13042-021-01410-9},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {12},
  pages        = {3607-3627},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A novel federated learning approach based on the confidence of federated kalman filters},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Metric learning with clustering-based constraints.
<em>IJMLC</em>, <em>12</em>(12), 3597–3605. (<a
href="https://doi.org/10.1007/s13042-021-01408-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In most of the existing metric learning methods, the relation is fixed throughout the metric learning process. However, the fixed relation may be harmful to learn a good metric. The adversarial metric learning implements a dynamic update of the pairwise constraints. Inspired by the idea of dynamically updating constraints, we propose in this paper a metric learning model with clustering-based constraints (ML-CC), wherein the triple constraints of large margin are iteratively generated with the clusters of data points. The proposed method can overcome the shortage of the fixed triple constraints constructed under the Euclidian distance. The experimental results on synthetic and real datasets indicate that the performance of the ML-CC is superior to that of the existing state-of-the-art metric learning methods.},
  archive      = {J_IJMLC},
  author       = {Guo, Xinyao and Dang, Chuangyin and Liang, Jianqing and Wei, Wei and Liang, Jiye},
  doi          = {10.1007/s13042-021-01408-3},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {12},
  pages        = {3597-3605},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Metric learning with clustering-based constraints},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A data-driven study for evaluating the compressive strength
of high-strength concrete. <em>IJMLC</em>, <em>12</em>(12), 3585–3595.
(<a href="https://doi.org/10.1007/s13042-021-01407-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To estimate the compressive strength of high-strength concrete (HSC), a hybrid model integrating the firefly algorithm (FFA) and fuzzy c-means (FCM) clustering method into the adaptive neuro fuzzy inference system (ANFIS) was developed in this paper. The FFA and FCM techniques were utilized to improve the forecasting accuracy of the proposed ANFIS. To establish the hybrid ANFIS-FFA model, five main constituents of HSC, cement, water, fine and coarse aggregates, and superplasticizer, are considered the input variables, and the compressive strength of HSC is used as the output variable. A comparison was conducted among four artificial intelligence models, including the proposed ANFIS-FFA model, the traditional ANFIS, the back propagation neural network (BPNN) and the extreme learning machine (ELM), in terms of four statistical indices. In addition, a detailed parametric study was conducted to investigate the influence of each input variable on the compressive strength of HSC. The results showed that the developed ANFIS-FFA model exhibits greater accuracy than the other three models, with a higher correlation coefficient (R) and lower root mean squared error (RMSE), mean absolute error (MAE), and mean absolute percentage error (MAPE) values, and it has great potential to accurately estimate the compressive strength of HSC.},
  archive      = {J_IJMLC},
  author       = {Wei, Yufeng and Han, Aiguo and Xue, Xinhua},
  doi          = {10.1007/s13042-021-01407-4},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {12},
  pages        = {3585-3595},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A data-driven study for evaluating the compressive strength of high-strength concrete},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Underdetermined blind source separation of speech mixtures
unifying dictionary learning and sparse representation. <em>IJMLC</em>,
<em>12</em>(12), 3573–3583. (<a
href="https://doi.org/10.1007/s13042-021-01406-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Underdetermined blind source separation of speech mixtures is a challenging issue in the classical “Cocktail-party” problem. Recently, there has been attention to use dictionary learning to solve this problem. In this paper, we build a novel framework to solve the underdetermined blind separation of speech mixtures as a sparse signal recovery problem by using a compressed sensing model. First, to eliminate the influence of additive white Gaussian noise, a wavelet transform with tunable Q-factor is used as noise reduction pretreatment. Second, to obtain an accurate mixing matrix estimation, a blind identification method is designed by identifying single source data. Third, to find the best dictionary to represent the training signals, an arbitrary subset of codewords and the corresponding coefficients are updated simultaneously. In the source signal recovery stage, a block processing is used into the mixing signals so that the source components are separated from each block by using sparse representation. Then, the whole source signals are reconstructed by concatenating the separated source components from all the block. The advantage is reducing the computational complexity. Finally, experimental results by separating the underdetermined speech mixtures demonstrate the superiority of the proposed algorithm.},
  archive      = {J_IJMLC},
  author       = {Xie, Yuan and Xie, Kan and Xie, Shengli},
  doi          = {10.1007/s13042-021-01406-5},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {12},
  pages        = {3573-3583},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Underdetermined blind source separation of speech mixtures unifying dictionary learning and sparse representation},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An improved neural dynamics based approach with territorial
mechanism to online path planning of multi-robot systems.
<em>IJMLC</em>, <em>12</em>(12), 3561–3572. (<a
href="https://doi.org/10.1007/s13042-021-01405-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The coordination of multi-robot system (MRS) are applied commonly to various fields of the automotive industry. In a variety of cooperative modes, online path planning with obstacles avoidance is a fundamentally important hotspot, especially in a 3-D, complex, or dynamic environment. In the paper, an improved neural dynamics based approach with territorial mechanism is proposed to online path planning of MRS, which can be used as the online path planner for multi-AUVs and multi-UAVs in complex and dynamic environments. This approach integrates biological neural network, computational fluid dynamics, and territorial mechanism of animals, which has the characteristics and advantages of the biological nervous system, namely self-regulation, self-adaptation, self-organization, etc. It can cope with a variety of accidents during path planning, such as the disappearance of targets, the breakdown of robots, the change of environments, and so forth. Meanwhile, the proposed approach has better time performance and is insensitive to the number of robots in MRS. During the path planning of MRS, it can also guarantee to balance workload and to reduce entire workload and total time, which enhance robustness and fairness. The effectiveness and efficiency of the proposed approach are demonstrated by simulations and comparative studies.},
  archive      = {J_IJMLC},
  author       = {Yi, Xin and Zhu, Anmin and Yang, Simon X. and Shi, Daming},
  doi          = {10.1007/s13042-021-01405-6},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {12},
  pages        = {3561-3572},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {An improved neural dynamics based approach with territorial mechanism to online path planning of multi-robot systems},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A new multi-period optimization model for
resilient-sustainable project portfolio evaluation under interval-valued
pythagorean fuzzy sets with a case study. <em>IJMLC</em>,
<em>12</em>(12), 3541–3560. (<a
href="https://doi.org/10.1007/s13042-021-01403-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In project portfolio selection, a set of goals is considered that is derived from the strategies and missions of firms. Due to the importance of social and environmental aspects of decision making in recent years, several attempts have been made to address sustainability in project portfolio selection. Given the turbulent environment and market conditions, one of the issues that has been the focus point of many scholars and practitioners is resilience. Simultaneous consideration of resiliency and sustainability in business environments is a new trend that has recently emerged. In this paper, to improve the decision-making process of firms in project portfolio selection, a novel resilient-sustainable project portfolio evaluation and optimization process is introduced. This new approach is based on two main phases. First, the projects are separately evaluated based on resiliency and sustainability criteria. In this process, weights of decision-makers and criteria are computed by new processes, and also the concept of linear assignment is applied. Then, in the second phase, a new multi-objective mathematical model is presented that aims at presenting a portfolio of multi-period projects with objectives of sustainability, resilience, and skill utilization. Then, the concept of the VIKOR method is applied to make an equivalent model and find the best portfolio. To address uncertainty in this process, interval-valued Pythagorean fuzzy sets (IVPFSs) are used. Utilization of such sets provides the process with high power in expressing the agreements, disagreements, and hesitations of project experts. To display the application steps of this method, a case study in petrochemical projects is presented and solved. The results show that the method can assist project portfolio managers in selecting and planning projects in addition to selecting the best project manager for each period of each project. Moreover, the manager can consider sustainability and resiliency in the selection and implementation of the projects.},
  archive      = {J_IJMLC},
  author       = {Mohagheghi, Vahid and Mousavi, Seyed Meysam},
  doi          = {10.1007/s13042-021-01403-8},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {12},
  pages        = {3541-3560},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A new multi-period optimization model for resilient-sustainable project portfolio evaluation under interval-valued pythagorean fuzzy sets with a case study},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Weakly-supervised learning for community detection based on
graph convolution in attributed networks. <em>IJMLC</em>,
<em>12</em>(12), 3529–3539. (<a
href="https://doi.org/10.1007/s13042-021-01400-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Community detection in complex networks has been revisited with graph deep learning recently and has attracted great attention. It is often challenging to uncover underlying communities on attributed networks because of the complexity and diversity of graph-structured data. A recent prominent graph deep learning model is graph convolutional network (GCN), which effectively integrates network topology and attribute information in graph representation learning. However, most GCN-based community detection methods are semi-supervised and require a considerable amount of labeled data for training. Here, we propose a weakly-supervised learning method based on GCN for community detection in attributed networks. Our new method integrates the techniques of GCN and label propagation and the latter constructs a balanced label set to uncover underlying community structures with topology and attribute information. The experiments on various real-world networks give a comparison view to evaluate the proposed method. The experimental result demonstrates the proposed method performs more efficiently with a comparative performance over current state-of-the-art community detection algorithms.},
  archive      = {J_IJMLC},
  author       = {Wang, Xiaofeng and Li, Jianhua and Yang, Li and Mi, Hongmei and Yu, Jia Yuan},
  doi          = {10.1007/s13042-021-01400-x},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {12},
  pages        = {3529-3539},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Weakly-supervised learning for community detection based on graph convolution in attributed networks},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Joint resource allocation for emotional 5G IoT systems using
deep reinforcement learning. <em>IJMLC</em>, <em>12</em>(12), 3517–3528.
(<a href="https://doi.org/10.1007/s13042-021-01398-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In emotional computing related IoT system, emotional sensors, as the IoT devices, are usually deployed to collect the emotional data from humans. The IoT devices need wireless connections to send the collected data to the server, that conducts the prediction to give user instructions. Mobile edge computing (MEC) is a promising technology to fit into this scenario. However, the IoT devices are usually short of energy supply and the local computation gives less accurate emotional computing results. To solve the problem, this paper intends to maximize the total energy efficiency of communication and computation within the MEC servers and sensors by jointly optimizing the allocation of channels and computing resources. The formulated problem is non-convex and usually solved through the successive convex approximation (SCA) method. Compared to SCA, deep Q network (DQN) method is used in this paper, which involves less computation cost to be more practically deployed. The simulation results show that the DQN solution outperforms the other benchmarking solutions, and the total energy consumption of the system is effectively reduced with a guaranteed emotional computing accuracy.},
  archive      = {J_IJMLC},
  author       = {Yang, Ziyan and Mei, Haibo and Wang, Wenyong and Zhou, Dongdai and Yang, Kun},
  doi          = {10.1007/s13042-021-01398-2},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {12},
  pages        = {3517-3528},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Joint resource allocation for emotional 5G IoT systems using deep reinforcement learning},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Character-level syntax infusion in pre-trained models for
chinese semantic role labeling. <em>IJMLC</em>, <em>12</em>(12),
3503–3515. (<a
href="https://doi.org/10.1007/s13042-021-01397-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semantic role labeling (SRL) aims at identifying the predicate-argument structure of a sentence. Recent work has significantly improved SRL performance by incorporating syntactic information and exploiting pre-trained models like BERT. Most of them use pre-trained models as isolated encoders to obtain word embeddings and enhance them with word-level syntax. Unlike many other languages, Chinese pre-trained models normally use Chinese characters instead of subwords as the basic input units, making the many-units-in-one-word phenomena more frequent and the relationship between characters more important. However, this character-level information is often ignored by previous research. In this paper, we propose the Character-Level Syntax-Infused network for Chinese SRL, which effectively incorporates the syntactic information between Chinese characters into pre-trained models. Experiments on the Chinese benchmarks of CoNLL-2009 and Universal Proposition Bank (UPB) show that the proposed approach achieves state-of-the-art results.},
  archive      = {J_IJMLC},
  author       = {Wang, Yuxuan and Lei, Zhilin and Che, Wanxiang},
  doi          = {10.1007/s13042-021-01397-3},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {12},
  pages        = {3503-3515},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Character-level syntax infusion in pre-trained models for chinese semantic role labeling},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Adaptive exploration policy for exploration–exploitation
tradeoff in continuous action control optimization. <em>IJMLC</em>,
<em>12</em>(12), 3491–3501. (<a
href="https://doi.org/10.1007/s13042-021-01387-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The optimization of continuous action control is an important research field. It aims to find optimal decisions by the experience of making decisions in a continuous action control task. This process can be done via reinforcement learning to train an agent for learning a policy by maximizing cumulative rewards of making decisions in a dynamic environment. Exploration–exploitation tradeoff is a key issue in learning this policy. The current solution called exploration policy addresses this issue by adding exploration noise to the policy in training for more efficient exploration while keeping exploitation. This noise is from a fixed distribution during the training process. However, in the dynamic environment, the stability of training is frequently changed in different training episodes, leading to the low adaptability for exploration policy to training stability. In this paper, we propose an adaptive exploration policy to address exploration–exploitation tradeoff. The motivation is that the noise scale should be increased to enhance exploration when the stability of training is high, while it should be reduced to keep exploitation when the stability of training is low. Firstly, we regard the variance of cumulative rewards from decisions as an index of the training stability. Then, based on this index, we construct a tradeoff coefficient, which is negatively correlated to the training stability. Finally, we propose adaptive exploration policy by the tradeoff coefficient to adjust the added exploration noise for adapting to the training stability. By the theoretical analysis and the experiments, we illustrate the effectiveness of our adaptive exploration policy. The source code can be downloaded from https://github.com/grcai/AEP-algorithm .},
  archive      = {J_IJMLC},
  author       = {Li, Min and Huang, Tianyi and Zhu, William},
  doi          = {10.1007/s13042-021-01387-5},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {12},
  pages        = {3491-3501},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Adaptive exploration policy for exploration–exploitation tradeoff in continuous action control optimization},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Delay-dependent stability analysis of nonlinear
truck-trailer systems based on non-fragile memory sampled-data via fuzzy
control. <em>IJMLC</em>, <em>12</em>(12), 3475–3490. (<a
href="https://doi.org/10.1007/s13042-021-01386-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the problem of a truck-trailer reversing to a given position at any initial position is studied, which is the optimal control of the nonlinear system in mathematical model. We describe this system by means of the T-S fuzzy rule and extend the system to general fuzzy time-varying delay systems. Non-fragile controller is designed for the time-varying delay T-S fuzzy systems on the basis of aperiodic memory sampling control. An improved time-delay-dependent Lyapunov–Krasovskii functional (LKF) is proposed, which covers all the information of the sampling interval and the time-delay information in the system and controller, which greatly reduces the conservativeness of the results. On this basis, we use the advanced technique of treating integral inequality to estimate the derivative term of Lyapunov function. The weighted matrix introduced in the integral inequality makes our results more flexible, which will be illustrated in the practical examples in the last section. Using the linear matrix inequalities (LMIs) method, a set of sufficient conditions is established to guarantee the system to be stable.},
  archive      = {J_IJMLC},
  author       = {Zhang, Jun and Liu, Deyou and Ma, Yuechao},
  doi          = {10.1007/s13042-021-01386-6},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {12},
  pages        = {3475-3490},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Delay-dependent stability analysis of nonlinear truck-trailer systems based on non-fragile memory sampled-data via fuzzy control},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Is the simple assignment enough? Exploring the
interpretability for community detection. <em>IJMLC</em>,
<em>12</em>(12), 3463–3474. (<a
href="https://doi.org/10.1007/s13042-021-01384-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The maximum likelihood estimation is a probabilistic inferencing model of community connectivity in large networks. In general, only the adjacency matrix is utilized to perform community structure parameter inference. Although there are recent examples that combine connectivity and attribute information for community detection, our model is an enhanced overlapping community detection model that combines adjacency spectral embedding with maximum likelihood estimation. This provides the flexibility of complex networks to increase connectivity information through measurements from attribute embedding. The attribute information can be effectively captured and transformed by attribute embedding to encode the combination with structure information. Then, the link strength among communities is designed to adjust the impact of these structural information on community generation based on the contribution of the structure to the clusters, and the node assignment allow for the nature of the real network (overlapping and outliers). Experiments highlight attributed networks in which attributed community detection task provides satisfactory performance.},
  archive      = {J_IJMLC},
  author       = {Zhao, Qiqi and Ma, Huifang and Li, Xiaohong and Li, Zhixin},
  doi          = {10.1007/s13042-021-01384-8},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {12},
  pages        = {3463-3474},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Is the simple assignment enough? exploring the interpretability for community detection},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Human activity recognition using pre-trained network with
informative templates. <em>IJMLC</em>, <em>12</em>(12), 3449–3461. (<a
href="https://doi.org/10.1007/s13042-021-01383-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A gait history image (GHI) is a spatial template that accumulates regions of motion into a single image in which moving pixels are brighter than others. A new descriptor named Time-sliced averaged gradient boundary magnitude (TAGBM) is also designed to show the time variations of motion. The spatial and temporal information of each video can be condensed using these templates. Recently, the advantage of deep learning architectures for human activity recognition encourages us to explore the effectiveness of combining them with these templates. Based on this opinion, a new method is proposed in this paper. Each video is split into N and M groups of consecutive frames, and the GHI and TAGBM are computed for each group, resulting spatial and temporal templates. Transfer learning with the fine-tuning technique has been used for classifying these templates. This proposed method achieves the recognition accuracies of 96.5\%, 92.7\%, 97.13\% and 86.6\% for KTH, UCF Sport, UCF-11 and Olympic Sport action datasets, respectively. Also it is compared with state-of-the-art approaches and the results demonstrate that the proposed method has the best efficiency.},
  archive      = {J_IJMLC},
  author       = {Zebhi, Saeedeh and AlModarresi, S. M. T. and Abootalebi, Vahid},
  doi          = {10.1007/s13042-021-01383-9},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {12},
  pages        = {3449-3461},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Human activity recognition using pre-trained network with informative templates},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An adversarial sample defense method based on multi-scale
GAN. <em>IJMLC</em>, <em>12</em>(12), 3437–3447. (<a
href="https://doi.org/10.1007/s13042-021-01374-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, the development of deep neural networks is in full gear in the fields of computer vision, natural language processing, and others. However, the existence of adversarial examples brings risks to the completion of these tasks, which is also a huge obstacle to implement deep learning applications in the real world. In order to solve the aforementioned problems and improve the robustness of neural networks, a novel defense network based on generative adversarial networks (GANs) is proposed. First, we use generators to eliminate disturbances of adversarial samples and utilize multi-scale discriminators to classify images of different scales to better assist the generator to produce high-quality images. Then, we utilize salient feature extraction model to extract salient maps of both clean examples and adversarial samples, thus improving the denoising effect of the generator by reducing the difference between salient images. The proposed method can guide the generation networks to accurately remove the invisible disturbance and to restore the adversarial samples to clean samples, which not only improves the success rate of classification, but also achieves satisfactory defense effect. Extensive experiments are conducted to compare the defense effect of our proposed method with other defense methods against various attacks. Results show that our method has strong defensive capabilities against the tested attack methods.},
  archive      = {J_IJMLC},
  author       = {Shao, Mingwen and Liu, Shuqi and Wang, Ran and Zhang, Gaozhi},
  doi          = {10.1007/s13042-021-01374-w},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {12},
  pages        = {3437-3447},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {An adversarial sample defense method based on multi-scale GAN},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Robust truncated l <span
class="math display"><sub>2</sub></span> -norm twin support vector
machine. <em>IJMLC</em>, <em>12</em>(12), 3415–3436. (<a
href="https://doi.org/10.1007/s13042-021-01368-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a new robust truncated L $$_2$$ -norm twin support vector machine (T $$^2$$ SVM), where the truncated L $$_2$$ -norm is used to measure the empirical risk to make the classifiers more robust when encountering lots of outliers. Meanwhile, chance constraints are also employed to specify false positive and false negative error rates. T $$^2$$ SVM considers a pair of chance constrained nonconvex nonsmooth problems. To solve these difficult problems, we propose an efficient iterative method for T $$^2$$ SVM based on difference of convex functions (DC) programs and DC Algorithms (DCA). Experiments on benchmark data sets and artificial data sets demonstrate the significant virtues of T $$^2$$ SVM in terms of robustness and generalization performance.},
  archive      = {J_IJMLC},
  author       = {Yang, Linxi and Li, Guoquan and Wu, Zhiyou and Wu, Changzhi},
  doi          = {10.1007/s13042-021-01368-8},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {12},
  pages        = {3415-3436},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Robust truncated l $$_2$$ -norm twin support vector machine},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Logic could be learned from images. <em>IJMLC</em>,
<em>12</em>(12), 3397–3414. (<a
href="https://doi.org/10.1007/s13042-021-01366-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Logic reasoning is a significant ability of human intelligence and also an important task in artificial intelligence. The existing logic reasoning methods, quite often, need to design some reasoning patterns beforehand. This has led to an interesting question: can logic reasoning patterns be directly learned from given data? The problem is termed as a data concept logic. In this study, a learning logic task from images, called a LiLi task, first is proposed. This task is to learn and reason the logic relation from images, without presetting any reasoning patterns. As a preliminary exploration, we design six LiLi data sets (Bitwise And, Bitwise Or, Bitwise Xor, Addition, Subtraction and Multiplication), in which each image is embedded with a n-digit number. It is worth noting that a learning model beforehand does not know the meaning of the n-digit numbers embedded in images and the relation between the input images and the output image. In order to tackle the task, in this work we use many typical neural network models and produce fruitful results. However, these models have the poor performances on the difficult logic task. For furthermore addressing this task, a novel network framework called a divide and conquer model by adding some label information is designed, achieving a high testing accuracy.},
  archive      = {J_IJMLC},
  author       = {Guo, Qian and Qian, Yuhua and Liang, Xinyan and She, Yanhong and Li, Deyu and Liang, Jiye},
  doi          = {10.1007/s13042-021-01366-w},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {12},
  pages        = {3397-3414},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Logic could be learned from images},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Performance guarantees of transformed schatten-1
regularization for exact low-rank matrix recovery. <em>IJMLC</em>,
<em>12</em>(12), 3379–3395. (<a
href="https://doi.org/10.1007/s13042-021-01361-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Low-rank matrix recovery aims to recover a matrix of minimum rank that subject to linear system constraint. It arises in various real world applications, such as recommender systems, image processing, and deep learning. Inspired by compressive sensing, the rank minimization can be relaxed to nuclear norm minimization. However, such a method treats all singular values of target matrix equally. To address this issue, recently the transformed Schatten-1 (TS1) penalty function was proposed and utilized to construct low-rank matrix recovery models. Unfortunately, the method for TS1-based models cannot provide both convergence accuracy and convergence speed. To alleviate such problems, this paper further investigates the basic properties of TS1 penalty function. And we describe a novel algorithm, which we called ATS1PGA, that is highly efficient in solving low-rank matrix recovery problems at a convergence rate of O(1/N), where N denotes the iterate count. In addition, we theoretically prove that the original rank minimization problem can be equivalently transformed into the TS1 optimization problem under certain conditions. Finally, extensive experimental results on real image data sets show that our proposed algorithm outperforms state-of-the-art methods in both accuracy and efficiency. In particular, our proposed algorithm is about 30 times faster than TS1 algorithm in solving low-rank matrix recovery problems.},
  archive      = {J_IJMLC},
  author       = {Wang, Zhi and Hu, Dong and Luo, Xiaohu and Wang, Wendong and Wang, Jianjun and Chen, Wu},
  doi          = {10.1007/s13042-021-01361-1},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {12},
  pages        = {3379-3395},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Performance guarantees of transformed schatten-1 regularization for exact low-rank matrix recovery},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Fusion of probabilistic unreliable indirect information into
estimation serving to decision making. <em>IJMLC</em>, <em>12</em>(12),
3367–3378. (<a
href="https://doi.org/10.1007/s13042-021-01359-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bayesian decision making (DM) quantifies information by the probability density (pd) of treated variables. Gradual accumulation of information during acting increases the DM quality reachable by an agent exploiting it. The inspected accumulation way uses a parametric model forecasting observable DM outcomes and updates the posterior pd of its unknown parameter. In the thought multi-agent case, a neighbouring agent, moreover, provides a privately-designed pd forecasting the same observation. This pd may notably enrich the information of the focal agent. Bayes’ rule is a unique deductive tool for a lossless compression of the information brought by the observations. It does not suit to processing of the forecasting pd. The paper extends solutions of this case. It: $$\triangleright$$ refines the Bayes’-rule-like use of the neighbour’s forecasting pd $$\triangleright$$ deductively complements former solutions so that the learnable neighbour’s reliability can be taken into account $$\triangleright$$ specialises the result to the exponential family, which shows the high potential of this information processing $$\triangleright$$ cares about exploiting population statistics.},
  archive      = {J_IJMLC},
  author       = {Kárný, Miroslav and Hůla, František},
  doi          = {10.1007/s13042-021-01359-9},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {12},
  pages        = {3367-3378},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Fusion of probabilistic unreliable indirect information into estimation serving to decision making},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Deep transfer learning-based network traffic classification
for scarce dataset in 5G IoT systems. <em>IJMLC</em>, <em>12</em>(11),
3351–3365. (<a
href="https://doi.org/10.1007/s13042-021-01415-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Internet of Things (IoT) can provide the interconnection and data sharing among devices, vehicles, buildings via various sensors with the development of 5G, and it has been widely used in different services such as e-commerce, heath-care, smart buildings. In the meantime, various cyber-attacks for IoT have increased and caused huge losses. Lots of security mechanisms are rapidly being proposed to prevent the potentially malicious attackers for IoT, in which machine learning especially deep learning (DL) as increasingly popular solution for security has been implemented in intrusion detection system (IDS) and others. However, the lack of enough datasets prevents the application of IDS in 5G IoT system. As one of fundamental components of IDS, network traffic classification shows a discretization, individualization and fine-grained trend which derives the different personalized classification methods for different requirements and scenarios. In this case, the data-driven DL faces the following challenges. First, there are only a few labeled datasets in the various personalized application scenarios, which undoubtedly limits the deployment of DL classification. Second, not all scenarios have rich computing capability for that training a neural network requires lots of computing resources. Therefore, this paper proposes a traffic classification method based on deep transfer learning for 5G IoT scenarios with scarce labeled data and limited computing capability, and trains the classification model by weight transferring and neural network fine-tuning. Different from the previous work that extract artificially designed features, the proposed method retains the end-to-end learning performance of DL and reduces the risk of suffering concept drift to reduce human intervention. Experimental results show that when only 10\% of dataset are used to label the data samples, the classification accuracy is close to the results of full training dataset.},
  archive      = {J_IJMLC},
  author       = {Guan, Jianfeng and Cai, Junxian and Bai, Haozhe and You, Ilsun},
  doi          = {10.1007/s13042-021-01415-4},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {11},
  pages        = {3351-3365},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Deep transfer learning-based network traffic classification for scarce dataset in 5G IoT systems},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). DDoS detection in 5G-enabled IoT networks using deep kalman
backpropagation neural network. <em>IJMLC</em>, <em>12</em>(11),
3337–3349. (<a
href="https://doi.org/10.1007/s13042-021-01323-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The fifth-generation (5G) wireless communication systems associating with the high achievable data-transfer speeds will significantly affect the performance of IoT networks. On one hand, the internet goes through a dramatic transaction period that shapes every aspect of our lives, industry, and business where cloud computing, smart cities, and the Internet of Things (IoT) play a significant role in the advancement of data transfer, storing, and processing. On the other hand, it plays a significant role in emerging advanced versions of different types of cybersecurity attacks especially that are novel, hard-to-detect, and that of distributive never cease-fire characteristics. To mitigate these concerns, we present a distributed denial-of-service (DDoS) intrusion detection model that can be implemented in IoT dynamic environments, providing an intelligent intrusion detection mechanism against the second biggest threat to data traffic and transfer on IoT networks. Kalman backpropagation neural network-based DDoS intrusion detection is proposed in this work. The framework is validated through various simulations via the most up to date CICDDoS2019 dataset to demonstrate the effectiveness of the solution in terms of intrusion detection. the proposed solution achieved an average detection accuracy of 94\% with 0.0952 false alarm rate and 97.49\%, 91.22\% for detection rate, and precision respectively.},
  archive      = {J_IJMLC},
  author       = {Almiani, Muder and AbuGhazleh, Alia and Jararweh, Yaser and Razaque, Abdul},
  doi          = {10.1007/s13042-021-01323-7},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {11},
  pages        = {3337-3349},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {DDoS detection in 5G-enabled IoT networks using deep kalman backpropagation neural network},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Adversarial examples: Attacks and defenses in the physical
world. <em>IJMLC</em>, <em>12</em>(11), 3325–3336. (<a
href="https://doi.org/10.1007/s13042-020-01242-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning technology has become an important branch of artificial intelligence. However, researchers found that deep neural networks, as the core algorithm of deep learning technology, are vulnerable to adversarial examples. The adversarial examples are some special input examples which were added small magnitude and carefully crafted perturbations to yield erroneous results with extremely confidence. Hence, they bring serious security risks to deep-learning-based systems. Furthermore, adversarial examples exist not only in the digital world, but also in the physical world. This paper presents a comprehensive overview of adversarial attacks and defenses in the real physical world. First, we reviewed these works that can successfully generate adversarial examples in the digital world, analyzed the challenges faced by applications in real environments. Then, we compare and summarize the work of adversarial examples on image classification tasks, target detection tasks, and speech recognition tasks. In addition, the relevant feasible defense strategies are summarized. Finally, relying on the reviewed work, we propose potential research directions for the attack and defense of adversarial examples in the physical world.},
  archive      = {J_IJMLC},
  author       = {Ren, Huali and Huang, Teng and Yan, Hongyang},
  doi          = {10.1007/s13042-020-01242-z},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {11},
  pages        = {3325-3336},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Adversarial examples: Attacks and defenses in the physical world},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Reduced PAPR model predictive control based FBMC/OQAM signal
for NB-IoT paradigm. <em>IJMLC</em>, <em>12</em>(11), 3309–3323. (<a
href="https://doi.org/10.1007/s13042-020-01263-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The competent class of fifth-generation mobile network used in NB-IoT demands for an extended and efficient massive device to a device communication system that exhibits narrow band with a focus on maximum spectrum resource usage, time and frequency synchronization and minimum out of band leakage. Filter bank multi-carrier with offset quadrature amplitude modulation (FBMC/OQAM) based systems act as a remarkable candidate for the fulfilment of application requirements of NarrowBand Internet of Things (NB-IoT) but suffer high peak to average power ratio (PAPR). Due to the overlapping of signals in the FBMC/OQAM structure, the basic SLM and PTS techniques cannot be applied on FBMC/OQAM systems. Therefore, in this work, a novel, cost-effective and low computation complexity solution SLM-MPC scheme is proposed which utilizes Model Predictive Control (MPC) algorithm for the optimization of PAPR of FBMC/OQAM transmitted signal and a significant reduction in PAPR of the FBMC/OQAM signal has been observed with negligible change in the BER of the system. The mathematical analysis is provided which justifies the simulation results and addresses the effectiveness of the proposed technique achieving a PAPR reduction of 1.61 dB and 1.2 dB for the number of sub-carriers as 128 and 256, respectively in comparison of SLM based FBMC/OQAM system.},
  archive      = {J_IJMLC},
  author       = {Sharma, Pavika and Shankar, Achyut and Cheng, Xiaochun},
  doi          = {10.1007/s13042-020-01263-8},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {11},
  pages        = {3309-3323},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Reduced PAPR model predictive control based FBMC/OQAM signal for NB-IoT paradigm},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Generating transferable adversarial examples based on
perceptually-aligned perturbation. <em>IJMLC</em>, <em>12</em>(11),
3295–3307. (<a
href="https://doi.org/10.1007/s13042-020-01240-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural networks (NNs) are known to be susceptible to adversarial examples (AEs), which are intentionally designed to deceive a target classifier by adding small perturbations to the inputs. And interestingly, AEs crafted for one NN can mislead another model. Such a property is referred to as transferability, which is often leveraged to perform attacks in black-box settings. To mitigate the transferability of AEs, many approaches are explored to enhance the NN’s robustness. Especially, adversarial training (AT) and its variants are shown be the strongest defense to resist such transferable AEs. To boost the transferability of AEs against the robust models that have undergone AT, a novel AE generating method is proposed in this paper. The motivation of our method is based on the observation that robust models with AT is more sensitive to the perceptually-relevant gradients, hence it is reasonable to synthesize the AEs by the perturbations that have the perceptually-aligned features. The detailed process of the proposed method is given as below. First, by optimizing the loss function over an ensemble of random noised inputs, we obtain perceptually-aligned perturbations that have the noise-invariant property. Second, we employ Perona–Malik (P–M) filter to smooth the derived adversarial perturbations, such that the perceptually-relevant feature of the perturbation is significantly reinforced and the local oscillation of the perturbation is substantially suppressed. Our method can be generally applied to any gradient-based attack method. We carry out extensive experiments under ImageNet dataset for various robust and non-robust models, and the experimental results demonstrate the effectiveness of our method. Particularly, by combining our method with diverse inputs method and momentum iterative fast gradient sign method, we can achieve state-of-the-art performance in terms of fooling the robust models.},
  archive      = {J_IJMLC},
  author       = {Chen, Hongqiao and Lu, Keda and Wang, Xianmin and Li, Jin},
  doi          = {10.1007/s13042-020-01240-1},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {11},
  pages        = {3295-3307},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Generating transferable adversarial examples based on perceptually-aligned perturbation},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Energy and spectrum aware unequal clustering with deep
learning based primary user classification in cognitive radio sensor
networks. <em>IJMLC</em>, <em>12</em>(11), 3261–3294. (<a
href="https://doi.org/10.1007/s13042-020-01154-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The problem of energy efficiency in cognitive radio sensor networks (CRSN) is mainly caused by the limited energy of sensor nodes and other channel-related operations for data transmission. The unequal clustering method should be considered for balancing the energy consumption among the cluster heads (CHs) for prolonging the network lifetime. The CH selection should consider the number of accessible free channels for efficient channel assignment. To improve fairness, the channel assignment problem should consider energy consumption among the cluster members. Furthermore, the relay metric for the selection of the best next-hop should consider the stability of the link for improving the transmission time. The CH rotation for cluster maintenance should be energy and spectrum aware. With regard to the above objectives, this paper proposes an energy and spectrum aware unequal clustering (ESAUC) protocol that jointly overcomes the limitations of energy and spectrum for maximizing the lifetime of CRSN. Our proposed ESAUC protocol improves fairness by achieving residual energy balance among the sensor nodes and enhances the network lifetime by reducing the overall energy consumption. Deep Belief Networks algorithm is exploited to predict the spectrum holes. ESAUC improves the stability of the cluster by optimally adjusting the number of common channels. ESAUC uses a CogAODV based routing mechanism to perform inter-cluster forwarding. Simulation results show that the proposed scheme outperforms the existing CRSN clustering algorithms in terms of residual energy, Network Lifetime, secondary user–primary user Interference Ratio, Route Discovery Frequency, throughput, Packet Delivery Ratio, and end-to-end delay.},
  archive      = {J_IJMLC},
  author       = {Stephan, Thompson and Al-Turjman, Fadi and K, Suresh Joseph and Balusamy, Balamurugan},
  doi          = {10.1007/s13042-020-01154-y},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {11},
  pages        = {3261-3294},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Energy and spectrum aware unequal clustering with deep learning based primary user classification in cognitive radio sensor networks},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Optimal deep learning based convolution neural network for
digital forensics face sketch synthesis in internet of things (IoT).
<em>IJMLC</em>, <em>12</em>(11), 3249–3260. (<a
href="https://doi.org/10.1007/s13042-020-01168-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid development in 5G cellular and IoT technologies is expected to be deployed widespread in the next few years. At the same time, crime rates are also increasing to a greater extent while the investigation officers are held responsible to deal with a broad range of cyber and internet issues in investigations. Therefore, advanced IT technologies and IoT devices can be deployed to ease the investigation process, especially, the identification of suspects. At present, only a few research works has been conducted upon deep learning-based Face Sketch Synthesis (FSS) models, concerning its success in diverse application domains including conventional face recognition. This paper proposes a new IoT-enabled Optimal Deep Learning based Convolutional Neural Network (ODL-CNN) for FSS to assist in suspect identification process. The hyper parameter optimization of the DL-CNN model was performed using Improved Elephant Herd Optimization (IEHO) algorithm. In the beginning, the proposed method captures the surveillance videos using IoT-based cameras which are then fed into the proposed ODL-CNN model. The proposed method initially involves preprocessing in which the contrast enhancement process is carried out using Gamma correction method. Then, the ODL-CNN model draws the sketches of the input images following which it undergoes similarity assessment, with professional sketch being drawn as per the directions from eyewitnesses. When the similarity between both the sketches are high, the suspect gets identified. A comprehensive qualitative and quantitative examination was conducted to assess the effectiveness of the presented ODL-CNN model. A detailed simulation analysis pointed out the effective performance of ODL-CNN model with maximum average Peak Signal to Noise Ratio (PSNR) of 20.11dB, Average Structural Similarity (SSIM) of 0.64 and average accuracy of 90.10\%.},
  archive      = {J_IJMLC},
  author       = {Elhoseny, Mohamed and Selim, Mahmoud Mohamed and Shankar, K.},
  doi          = {10.1007/s13042-020-01168-6},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {11},
  pages        = {3249-3260},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Optimal deep learning based convolution neural network for digital forensics face sketch synthesis in internet of things (IoT)},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). IoT enabled depthwise separable convolution neural network
with deep support vector machine for COVID-19 diagnosis and
classification. <em>IJMLC</em>, <em>12</em>(11), 3235–3248. (<a
href="https://doi.org/10.1007/s13042-020-01248-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {At present times, the drastic advancements in the 5G cellular and internet of things (IoT) technologies find useful in different applications of the healthcare sector. At the same time, COVID-19 is commonly spread from animals to persons, but today it is transmitting among persons by adapting the structure. It is a severe virus and inappropriately resulted in a global pandemic. Radiologists utilize X-ray or computed tomography (CT) images to diagnose COVID-19 disease. It is essential to identify and classify the disease through the use of image processing techniques. So, a new intelligent disease diagnosis model is in need to identify the COVID-19. In this view, this paper presents a novel IoT enabled Depthwise separable convolution neural network (DWS-CNN) with Deep support vector machine (DSVM) for COVID-19 diagnosis and classification. The proposed DWS-CNN model aims to detect both binary and multiple classes of COVID-19 by incorporating a set of processes namely data acquisition, Gaussian filtering (GF) based preprocessing, feature extraction, and classification. Initially, patient data will be collected in the data acquisition stage using IoT devices and sent to the cloud server. Besides, the GF technique is applied to remove the existence of noise that exists in the image. Then, the DWS-CNN model is employed for replacing default convolution for automatic feature extraction. Finally, the DSVM model is applied to determine the binary and multiple class labels of COVID-19. The diagnostic outcome of the DWS-CNN model is tested against Chest X-ray (CXR) image dataset and the results are investigated interms of distinct performance measures. The experimental results ensured the superior results of the DWS-CNN model by attaining maximum classification performance with the accuracy of 98.54\% and 99.06\% on binary and multiclass respectively.},
  archive      = {J_IJMLC},
  author       = {Le, Dac-Nhuong and Parvathy, Velmurugan Subbiah and Gupta, Deepak and Khanna, Ashish and Rodrigues, Joel J. P. C. and Shankar, K.},
  doi          = {10.1007/s13042-020-01248-7},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {11},
  pages        = {3235-3248},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {IoT enabled depthwise separable convolution neural network with deep support vector machine for COVID-19 diagnosis and classification},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A reinforcement learning optimization for future smart
cities using software defined networking. <em>IJMLC</em>,
<em>12</em>(11), 3221–3233. (<a
href="https://doi.org/10.1007/s13042-020-01245-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays smart cities towards software defined network (SDN) approach will become better flexibility and manageability. A stronger, more dynamic network is an SDN network, which is precisely what a smart city network must be if it wants to be viable on a real-world scale. SDN architecture is developed to implement a learning framework for network optimization. The proposed method is called mixed-integer and reinforcement learned network optimization (MI-RLNO) for SDN monitoring. In the first phase, mixed-integer programming formulation is used as an optimization formulation for latency and convergence time. In the second phase, a reinforced Q Learning model is designed that uses communication and computation time as input state vector. Optimization formulation is used as the actions and strategies to be followed during the design and operation of communication networks, therefore contributing fairness and throughput. Simulation results improved the efficiency of the MI-RLNO method.},
  archive      = {J_IJMLC},
  author       = {Rajkumar, Kulandaivel and Ramachandran, Manikandan and Al-Turjman, Fadi and Patan, Rizwan},
  doi          = {10.1007/s13042-020-01245-w},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {11},
  pages        = {3221-3233},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A reinforcement learning optimization for future smart cities using software defined networking},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Localizing pedestrians in indoor environments using magnetic
field data with term frequency paradigm and deep neural networks.
<em>IJMLC</em>, <em>12</em>(11), 3203–3219. (<a
href="https://doi.org/10.1007/s13042-021-01279-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Indoor environments are challenging for global navigation satellite systems and cripple its performance. Magnetic field data-based positioning and localization has emerged as a potential solution for ubiquitous indoor positioning and localization. The availability of embedded magnetic sensors in the smartphone simplifies the positioning without the additional cost of infrastructure. However, the data divergence due to smartphone heterogeneity circumscribes the wide applicability of magnetic field-based positioning approaches. This research proposes the use of term frequency (TF) extracted from the magnetic field data to alleviate the impact of smartphone heterogeneity. For this purpose, the magnetic field data are transformed into terms (words) and documents. Extracted TF vectors are used to train long short term memory and gated recurrent unit networks. A voting scheme is contrived to incorporate the predictions from these networks. Experiment results with three different smartphones like LG G6, Galaxy S8, and LG Q6 demonstrate that the use of TF mitigates the impact of the smartphones’ variability. Performance comparison with state-of-the-art approaches reveals that the proposed approach performs better than those of other approaches in alleviating the influence of using various smartphones for magnetic field-based indoor localization. Furthermore, the localization performance of the proposed is better than those of other approaches, even using a smaller amount of magnetic field data.},
  archive      = {J_IJMLC},
  author       = {Ashraf, Imran and Zikria, Yousaf Bin and Hur, Soojung and Bashir, Ali Kashif and Alhussain, Thamer and Park, Yongwan},
  doi          = {10.1007/s13042-021-01279-8},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {11},
  pages        = {3203-3219},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Localizing pedestrians in indoor environments using magnetic field data with term frequency paradigm and deep neural networks},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Ensemble machine learning approach for classification of IoT
devices in smart home. <em>IJMLC</em>, <em>12</em>(11), 3179–3202. (<a
href="https://doi.org/10.1007/s13042-020-01241-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The emergence of the Internet of Things (IoT) concept as a new direction of technological development raises new problems such as valid and timely identification of such devices, security vulnerabilities that can be exploited for malicious activities, and management of such devices. The communication of IoT devices generates traffic that has specific features and differences with respect to conventional devices. This research seeks to analyze the possibilities of applying such features for classifying devices, regardless of their functionality or purpose. This kind of classification is necessary for a dynamic and heterogeneous environment, such as a smart home where the number and types of devices grow daily. This research uses a total of 41 IoT devices. The logistic regression method enhanced by the concept of supervised machine learning (logitboost) was used for developing a classification model. Multiclass classification model was developed using 13 network traffic features generated by IoT devices. Research has shown that it is possible to classify devices into four previously defined classes with high performances and accuracy (99.79\%) based on the traffic flow features of such devices. Model performance measures such as precision, F-measure, True Positive Ratio, False Positive Ratio and Kappa coefficient all show high results (0.997–0.999, 0.997–0.999, 0.997–0.999, 0–0.001 and 0.9973, respectively). Such a developed model can have its application as a foundation for monitoring and managing solutions of large and heterogeneous IoT environments such as Industrial IoT, smart home, and similar.},
  archive      = {J_IJMLC},
  author       = {Cvitić, Ivan and Peraković, Dragan and Periša, Marko and Gupta, Brij},
  doi          = {10.1007/s13042-020-01241-0},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {11},
  pages        = {3179-3202},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Ensemble machine learning approach for classification of IoT devices in smart home},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An intelligent prediction model for UCG state based on
dual-source LSTM. <em>IJMLC</em>, <em>12</em>(11), 3169–3178. (<a
href="https://doi.org/10.1007/s13042-020-01210-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Underground coal gasification (UCG) is a serious attempt to clean and efficient use of coal, but it has not been able to solve the problem of stable production. Predicting UCG can provide effective guidance for control, which effectively solves this problem. Existing UCG prediction models are not accurate, and most of them can only predict a single variable, and cannot adequately predict the UCG state. The paper proposes the concept of combustible gas equivalents that can characterize the concentration of mixed gas through stoichiometry and material balance equations. The equivalent gradient is introduced to characterize the trends in equivalent, and the UCG state discrimination standard is established to evaluate the UCG state. Eventually, a dual-source long short-term memory (LSTM) prediction model is proposed for predicting UCG state. The experimental results show that compared with Support Vector Machine (SVM) and Back Propagation Neural Network (BPNN) prediction model, the model can make a better prediction of equivalent value and the accuracy of predicting trends in equivalent reaches 90.99\%.},
  archive      = {J_IJMLC},
  author       = {Xiao, Yuteng and Yin, Hongsheng and Duan, Tianhong and Qi, Honggang and Zhang, Yudong and Jolfaei, Alireza and Xia, Kaijian},
  doi          = {10.1007/s13042-020-01210-7},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {11},
  pages        = {3169-3178},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {An intelligent prediction model for UCG state based on dual-source LSTM},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Recurrent autonomous autoencoder for intelligent DDoS attack
mitigation within the ISP domain. <em>IJMLC</em>, <em>12</em>(11),
3145–3167. (<a
href="https://doi.org/10.1007/s13042-021-01306-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The continuous advancement of DDoS attack technology and an increasing number of IoT devices connected on 5G networks escalate the level of difficulty for DDoS mitigation. A growing number of researchers have started to utilise Deep Learning algorithms to improve the performance of DDoS mitigation systems. Real DDoS attack data has no labels, and hence, we present an intelligent attack mitigation (IAM) system, which takes an ensemble approach by employing Recurrent Autonomous Autoencoders (RAA) as basic learners with a majority voting scheme. The RAA is a target-driven, distributionenabled, and imbalanced clustering algorithm, which is designed to work with the ISP’s blackholing mechanism for DDoS flood attack mitigation. It can dynamically select features, decide a reference target (RT), and determine an optimal threshold to classify network traffic. A novel Comparison-Max Random Walk algorithm is used to determine the RT, which is used as an instrument to direct the model to classify the data so that the predicted positives are close or equal to the RT. We also propose Estimated Evaluation Metrics (EEM) to evaluate the performance of unsupervised models. The IAM system is tested with UDP flood, TCP flood, ICMP flood, multi-vector and a real UDP flood attack data. Additionally, to check the scalability of the IAM system, we tested it on every subdivided data set for distributed computing. The average Recall on all data sets was above 98\%.},
  archive      = {J_IJMLC},
  author       = {Ko, Ili and Chambers, Desmond and Barrett, Enda},
  doi          = {10.1007/s13042-021-01306-8},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {11},
  pages        = {3145-3167},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Recurrent autonomous autoencoder for intelligent DDoS attack mitigation within the ISP domain},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A multiple-kernel clustering based intrusion detection
scheme for 5G and IoT networks. <em>IJMLC</em>, <em>12</em>(11),
3129–3144. (<a
href="https://doi.org/10.1007/s13042-020-01253-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The 5G network provides higher bandwidth and lower latency for edge IoT devices to access the core business network. But at the same time, it also expands the attack surface of the core network, which makes the enterprise network face greater security threats. To protect the security of core business, the network infrastructure must be able to recognize not only the known abnormal traffic, but also new emerging threats. Intrusion Detection Systems (IDSs) are widely used to protect the core network against external intrusions. Most of the existing research works design anomaly detection models for a specific set of traffic attributes. In fact, it is difficult for us to find the specific correspondence between traffic attributes and attack behaviors. Worse, some traffic attributes will be missing in the IoT environment, which further increases the difficulty of anomaly analysis. In traditional solutions, the missing attributes are usually filled with zero or mean values. Sometimes, the attributes are directly discarded. Both of these methods may result in lower detection accuracy. To solve this problem, we propose an intrusion detection method based on multiple-kernel clustering (MKC) algorithms. Be different from zero value filling and mean value filling, the proposed method completes the absent traffic property through similarity calculation. Experimental results show that this method can effectively improve the clustering accuracy of incomplete sampled data, at the same time it can reduce the sensitivity of the anomaly detection model to the selection of traffic feature, and has a better tolerance for poor-quality traffic sampled data.},
  archive      = {J_IJMLC},
  author       = {Hu, Ning and Tian, Zhihong and Lu, Hui and Du, Xiaojiang and Guizani, Mohsen},
  doi          = {10.1007/s13042-020-01253-w},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {11},
  pages        = {3129-3144},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A multiple-kernel clustering based intrusion detection scheme for 5G and IoT networks},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Clone detection in 5G-enabled social IoT system using graph
semantics and deep learning model. <em>IJMLC</em>, <em>12</em>(11),
3115–3127. (<a
href="https://doi.org/10.1007/s13042-020-01246-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The protection and privacy of the 5G-IoT framework is a major challenge due to the vast number of mobile devices. Specialized applications running these 5G-IoT systems may be vulnerable to clone attacks. Cloning applications can be achieved by stealing or distributing commercial Android apps to harm the advanced services of the 5G-IoT framework. Meanwhile, most Android app stores run and manage Android apps that developers have submitted separately without any central verification systems. Android scammers sell pirated versions of commercial software to other app stores under different names. Android applications are typically stored on cloud servers, while API access services may be used to detect and prevent cloned applications from being released. In this paper, we proposed a hybrid approach to the Control Flow Graph (CFG) and a deep learning model to secure the smart services of the 5G-IoT framework. First, the newly submitted APK file is extracted and the JDEX decompiler is used to retrieve Java source files from possibly original and cloned applications. Second, the source files are broken down into various android-based components. After generating Control-Flow Graphs (CFGs), the weighted features are stripped from each component. Finally, the Recurrent Neural Network (RNN) is designed to predict potential cloned applications by training features from different components of android applications. Experimental results have shown that the proposed approach can achieve an average accuracy of 96.24\% for cloned applications selected from different android application stores.},
  archive      = {J_IJMLC},
  author       = {Ullah, Farhan and Naeem, Muhammad Rashid and Mostarda, Leonardo and Shah, Syed Aziz},
  doi          = {10.1007/s13042-020-01246-9},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {11},
  pages        = {3115-3127},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Clone detection in 5G-enabled social IoT system using graph semantics and deep learning model},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Routing protocol for low power and lossy network–load
balancing time-based. <em>IJMLC</em>, <em>12</em>(11), 3101–3114. (<a
href="https://doi.org/10.1007/s13042-020-01261-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently 6G/IoT emerged the latest technology of traditional wireless sensor network devices for 6G/IoT-oriented infrastructure. The construction of 6G/IoT utilizes the routing protocol for low power and lossy networks (RPL) protocol in the network layer. RPL is a proactive routing protocol with an IPV6 distance vector. The enormous number of connected smart devices and a huge amount of common information and services have shown the important need for an effective load balancing mechanism to distribute the load between nodes. The motivation of this research is to observe some of the load balancing challenges and problems and propose a solution. This paper proposes a new mechanism called Load Balancing Time Based (LBTB). The proposed LBTB is composed of the node count of neighbors and the remaining node power. The proposed LBTB deployed a modified edition of trickle timer algorithm to act as the constructor of the Destination Oriented Directed Acyclic Graph (DODAG) and controls the messages distribution between nodes. The simulation of the experiments performed using Cooja 2.7 on different network densities (low, medium, and high) under reception of success ratios (80\%). Grid and random network topologies were deployed. The performance of RPL using the LBTB algorithm was measured using metrics including convergence time, the packet delivery ratio (PDR), power consumption, and delay. We compared the results with the LBSR and the standard algorithms. The results of the simulation showed that the average enhancement of the performance as follows: 68\% convergence time, 16\% power consumption, and 56\% delay. In addition, the results showed that the PDR in some cases were better using the LBTB algorithm.},
  archive      = {J_IJMLC},
  author       = {Yassien, Muneer Bani and Aljawarneh, Shadi A. and Eyadat, Mohammad and Eaydat, Eman},
  doi          = {10.1007/s13042-020-01261-w},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {11},
  pages        = {3101-3114},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Routing protocol for low power and lossy network–load balancing time-based},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Sentence pair modeling based on semantic feature map for
human interaction with IoT devices. <em>IJMLC</em>, <em>12</em>(11),
3081–3099. (<a
href="https://doi.org/10.1007/s13042-021-01349-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid development of Internet of Things (IoT) brings an urgent requirement on intelligent human–device interactions using natural language, which are critical for facilitating people to use IoT devices. The efficient interactive approaches depend on various natural language understanding technologies. Among them, sentence pair modeling (SPM) is essential, where neural networks have achieved great success in SPM area due to their powerful abilities in feature extraction and representation. However, as sentences are one-dimensional (1D) texts, the available neural networks are usually limited to 1D sequential models, which prevents the performance improvement of SPM task. To address this gap, in this paper, we propose a novel neural architecture for sentence pair modeling, which utilizes 1D sentences to construct multi-dimensional feature maps similar to images containing multiple color channels. Based on the feature maps, more kinds of neural models become applicable on SPM task, including 2D CNN. In the proposed model, first, the sentence on a specific granularity is encoded with BiLSTM to generate the representation on this granularity, which is viewed as a special channel of the sentence. The representations from different granularity are merged together to construct semantic feature map of the input sentence. Then, 2D CNN is employed to encode the feature map to capture the deeper semantic features contained in the sentence. Next, another 2D CNN is utilized to capture the interactive matching features between sentences, followed by 2D max-pooling and attention mechanism to generate the final matching representation. Finally, the matching degree of sentences are judged with a sigmoid function according to the matching representation. Extensive experiments are conducted on two real-world data sets. In comparison with benchmarks, the proposed model achieved remarkable results, and performed better or comparably with BERT-based models. Our work is beneficial to building a more powerful humanized interaction system with IoT devices.},
  archive      = {J_IJMLC},
  author       = {Yu, Rui and Lu, Wenpeng and Lu, Huimin and Wang, Shoujin and Li, Fangfang and Zhang, Xu and Yu, Jiguo},
  doi          = {10.1007/s13042-021-01349-x},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {11},
  pages        = {3081-3099},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Sentence pair modeling based on semantic feature map for human interaction with IoT devices},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Improved VGG model-based efficient traffic sign recognition
for safe driving in 5G scenarios. <em>IJMLC</em>, <em>12</em>(11),
3069–3080. (<a
href="https://doi.org/10.1007/s13042-020-01185-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid development and application of AI in intelligent transportation systems has widely impacted daily life. The application of an intelligent visual aid for traffic sign information recognition can provide assistance and even control vehicles to ensure safe driving. The field of autonomous driving is booming, and great progress has been made. Many traffic sign recognition algorithms based on convolutional neural networks (CNNs) have been proposed because of the fast execution and high recognition rate of CNNs. However, this work addresses a challenging question in the autonomous driving field: how can traffic signs be recognized in real time and accurately? The proposed method designs an improved VGG convolutional neural network and has significantly superior performance compared with existing schemes. First, some redundant convolutional layers are removed efficiently from the VGG-16 network, and the number of parameters is greatly reduced to further optimize the overall architecture and accelerate calculation. Furthermore, the BN (batch normalization) layer and GAP (global average pooling) layer are added to the network to improve the accuracy without increasing the number of parameters. The proposed method needs only 1.15 M when using the improved VGG-16 network. Finally, extensive experiments on the German Traffic Sign Recognition Benchmark (GTSRB) Dataset are performed to evaluate our proposed scheme. Compared with traditional methods, our scheme significantly improves recognition accuracy while maintaining good real-time performance.},
  archive      = {J_IJMLC},
  author       = {Bi, Zhongqin and Yu, Ling and Gao, Honghao and Zhou, Ping and Yao, Hongyang},
  doi          = {10.1007/s13042-020-01185-5},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {11},
  pages        = {3069-3080},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Improved VGG model-based efficient traffic sign recognition for safe driving in 5G scenarios},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Top view multiple people tracking by detection using deep
SORT and YOLOv3 with transfer learning: Within 5G infrastructure.
<em>IJMLC</em>, <em>12</em>(11), 3053–3067. (<a
href="https://doi.org/10.1007/s13042-020-01220-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, 5G profoundly impacts video surveillance and monitoring services by processing video streams at high-speed with high-reliability, high bandwidth, and secure network connectivity. It also enhances artificial intelligence, machine learning, and deep learning techniques, which require intense processing to deliver near-real-time solutions. In video surveillance, person tracking is a crucial task due to the deformable nature of the human body, various environmental components such as occlusion, illumination, and background conditions, specifically, from a top view perspective where the person’s visual appearance is significantly different from a frontal or side view. In this work, multiple people tracking framework is presented, which uses 5G infrastructure. A top view perspective is used, which offers broad coverage of the scene or field of view. To perform a person tracking deep learning-based tracking by detection framework is proposed, which includes detection by YOLOv3 and tracking by Deep SORT algorithm. Although the model is pre-trained using the frontal view images, even then, it gives good detection results. In order to further enhance the accuracy of the detection model, the transfer learning approach is adopted. In this way, a detection model takes advantage of a pre-trained model appended with an additional trained layer using top view data set. To evaluate the performance, experiments are carried out on different top view video sequences. Experimental results reveal that transfer learning improves the overall performance, detection accuracy, and reduces false positives. The deep learning detection model YOLOv3 achieves detection accuracy of 92\% with a pre-trained model without transfer learning and 95\% with transfer learning. The tracking algorithm Deep SORT also achieves excellent results with a tracking accuracy of 96\%.},
  archive      = {J_IJMLC},
  author       = {Ahmed, Imran and Ahmad, Misbah and Ahmad, Awais and Jeon, Gwanggil},
  doi          = {10.1007/s13042-020-01220-5},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {11},
  pages        = {3053-3067},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Top view multiple people tracking by detection using deep SORT and YOLOv3 with transfer learning: Within 5G infrastructure},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Editorial: Deep learning for 5G IoT systems. <em>IJMLC</em>,
<em>12</em>(11), 3049–3051. (<a
href="https://doi.org/10.1007/s13042-021-01382-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IJMLC},
  author       = {Cheng, Xiaochun and Zhang, Chengqi and Qian, Yi and Aloqaily, Moayad and Xiao, Yang},
  doi          = {10.1007/s13042-021-01382-w},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {11},
  pages        = {3049-3051},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Editorial: Deep learning for 5G IoT systems},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Scheduling method with adaptive learning for microservice
workflows with hybrid resource provisioning. <em>IJMLC</em>,
<em>12</em>(10), 3037–3048. (<a
href="https://doi.org/10.1007/s13042-021-01396-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {More and more attention has been paid to microservices from traditional monolithic workflows. How to rent on-demand and spot instances for microservice tasks in cloud computing is crucial to save rental costs for customers. According to the out-of-bid failure risks of spot instances and application deadline constraints, it is challenging to adaptively determine the number of on-demand and spot instances, allocate microservice tasks to the rented instances, and reschedule interrupted tasks. In this paper, we consider the problem of scheduling microservice workflows with hybrid resource provisioning. An adaptive-learning based scheduling algorithmic framework is proposed to intelligently sequence, allocate and online adjust tasks as well as monitor spot instance. Strategies for each component are developed. Components and parameter values are statistically calibrated over a comprehensive set of random instances. The proposed algorithm is compared to modified classical algorithms for similar problems. Experimental results demonstrate the effectiveness of the proposal for the considered problem.},
  archive      = {J_IJMLC},
  author       = {Gu, Haihua and Li, Xiaoping and Liu, Muyao and Wang, Shuang},
  doi          = {10.1007/s13042-021-01396-4},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {10},
  pages        = {3037-3048},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Scheduling method with adaptive learning for microservice workflows with hybrid resource provisioning},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Discrete matrix factorization hashing for cross-modal
retrieval. <em>IJMLC</em>, <em>12</em>(10), 3023–3036. (<a
href="https://doi.org/10.1007/s13042-021-01395-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cross-modal hashing has recently attracted considerable attention in the large-scale retrieval task due to its low storage cost and high retrieval efficiency. However, the existing hashing methods still have some issues that need to be further solved. For example, most existing cross-modal hashing methods convert the original data into a common Hamming space to learn unified hash codes, which ignores the specific properties of multi-modal data. In addition, most of them relax the discrete constraint to learn hash codes, which may lead to quantization loss and suboptimal performance. In order to address the above problems, this paper proposes a novel cross-modal retrieval method, named discrete matrix factorization hashing (DMFH). DMFH is a two-stage approach. In the first stage, given training data, DMFH exploits the matrix factorization technique to learn modality-specific semantic representation for each modality, then generates the corresponding hash codes by linear projection. Meanwhile, in order to ensure that the hash codes can preserve the semantic similarity between different modalities, DMFH optimizes the hash codes by an affinity matrix constructed from the label information. During the first stage, DMFH proposes a discrete optimal algorithm to solve the discrete constraint problem in learning hash codes. In the second stage, given the hash codes learned in the first stage, DMFH utilizes kernel logistic regression to learn the nonlinear features from the unseen instance, then generates corresponding hash codes for each modality. Extensive experimental results on three public benchmark datasets show that the proposed DMFH outperforms several state-of-art cross-modal hashing methods in terms of accuracy and efficiency.},
  archive      = {J_IJMLC},
  author       = {Fang, Xiaozhao and Liu, Zhihu and Han, Na and Jiang, Lin and Teng, Shaohua},
  doi          = {10.1007/s13042-021-01395-5},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {10},
  pages        = {3023-3036},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Discrete matrix factorization hashing for cross-modal retrieval},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Adaptive fuzzy leader-following consensus for nonlinear
multi-agent systems via state-constraint impulsive control.
<em>IJMLC</em>, <em>12</em>(10), 3011–3022. (<a
href="https://doi.org/10.1007/s13042-021-01392-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the adaptive fuzzy leader-following consensus problem of multi-agent systems (MASs) with unknown nonlinear dynamics via state-constraint impulsive control. The fuzzy logic systems(FLSs) are established to estimate the unknown nonlinear dynamics. Meanwhile, the purpose of designing one adaptive parameter is to reduce the impact on uncertain factors of FLSs, where this parameter is constantly adjusted by exchanging required information between follower agents and its neighbors. The impulsive control theory is applied to reduce the cost of continuous communication due to the achievement of discontinuous control, where follower agents only communicate with leader agent at fixed impulsive instants. To consider the physical or environmental constraints in real control systems, the state-constraint based on saturation function is introduced to MASs. Then, both adaptive fuzzy control and state-constraint impulsive control are employed to guarantee that total agents can converge to consensus. Finally, some numerical simulations are given to illustrate the feasibility of the theoretical results.},
  archive      = {J_IJMLC},
  author       = {Ke, Can and Li, Chuandong and Han, Yiyan and You, Le},
  doi          = {10.1007/s13042-021-01392-8},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {10},
  pages        = {3011-3022},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Adaptive fuzzy leader-following consensus for nonlinear multi-agent systems via state-constraint impulsive control},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Ant colony optimization for mining gradual patterns.
<em>IJMLC</em>, <em>12</em>(10), 2989–3009. (<a
href="https://doi.org/10.1007/s13042-021-01390-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gradual pattern extraction is a field in Knowledge Discovery in Databases that maps correlations between attributes of a data set as gradual dependencies. A gradual dependency may take the form: “the more Attribute $$_{K}$$ , the less Attribute $$_{L}$$ ”. Classical approa-ches for extracting gradual patterns extend either a breath-first search or a depth-first search strategy. However, these strategies can be computationally expensive and inefficient especially when dealing with large data sets. In this study, we investigate 3 population-based optimization techniques (i.e. ant colony optimization, genetic algorithm and particle swarm optimization) that may be employed improve the efficiency of mining gradual patterns. We show that ant colony optimization technique is better suited for gradual pattern mining task than the other 2 techniques. Through computational experiments on real-world data sets, we compared the computational performance of the proposed algorithms that implement the 3 population-based optimization techniques to classical algorithms for the task of gradual pattern mining and we show that the proposed algorithms outperform their classical counterparts.},
  archive      = {J_IJMLC},
  author       = {Owuor, Dickson Odhiambo and Runkler, Thomas and Laurent, Anne and Orero, Joseph Onderi and Menya, Edmond Odhiambo},
  doi          = {10.1007/s13042-021-01390-w},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {10},
  pages        = {2989-3009},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Ant colony optimization for mining gradual patterns},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). ECG arrhythmia classification based on variational mode
decomposition, shannon energy envelope and deterministic learning.
<em>IJMLC</em>, <em>12</em>(10), 2963–2988. (<a
href="https://doi.org/10.1007/s13042-021-01389-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electrocardiography (ECG) signals play an important role in the cardiac disorder diagnosis and arrhythmia detection since they reflect all the electrical activities of the heart and include information about heart function and heart conditions. Due to the subtle alterations in the amplitude, duration and morphology of the ECG, the development of computer-based intelligent system in the arrhythmia diagnosis field is attractive in terms of the amount of data and the importance of the data it contains for the classification of heartbeats from different types of arrhythmias. In the present study we propose a novel technique for the automatic detection of cardiac arrhythmia with one-lead ECG signals based upon variational mode decomposition (VMD), Shannon energy envelope, phase space reconstruction (PSR) and deterministic learning theory. First, VMD is employed to decompose the ECG signals into different intrinsic modes, in which the first four intrinsic modes contain the majority of the ECG signals’ energy and are considered to be the predominant intrinsic modes. Second, Shannon energy is used to extract the characteristic envelope of predominant intrinsic modes. Third, phase space of the Shannon energy envelope (SEE) is reconstructed, in which properties associated with the nonlinear ECG characteristics are preserved. Three-dimensional (3D) phase space reconstruction (PSR) together with Euclidean distance (ED) has been utilized to derive features, which demonstrate significant difference in ECG system dynamics between normal versus abnormal individual heartbeats. Fourth, neural networks are then used to model, identify and classify ECG system dynamics between normal (healthy) and arrhythmic ECG signals based on deterministic learning theory. Finally, experiments are carried out on the MIT-BIH arrhythmia database to verify the effectiveness of the proposed method, in which 626 ECG signal fragments for one lead (MLII) from 28 persons of five classes of heartbeats were extracted. These five classes are normal sinus rhythm (NSR), premature ventricular contraction (PVC), paced beat (PB), left bundle branch block (LBBB), and right bundle branch block (RBBB). By using the 10-fold cross-validation style, the achieved average classification accuracy is reported to be 98.72 $$\%$$ . Experimental results verify the effectiveness of the proposed method and indicate that it has the potential to serve as a candidate for the automatic detection of myocardial dysfunction in the clinical application.},
  archive      = {J_IJMLC},
  author       = {Zeng, Wei and Yuan, Chengzhi},
  doi          = {10.1007/s13042-021-01389-3},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {10},
  pages        = {2963-2988},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {ECG arrhythmia classification based on variational mode decomposition, shannon energy envelope and deterministic learning},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Modified action decoder using bayesian reasoning for
multi-agent deep reinforcement learning. <em>IJMLC</em>,
<em>12</em>(10), 2947–2961. (<a
href="https://doi.org/10.1007/s13042-021-01385-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep reinforcement learning has achieved superhuman performance in zero-sum games such as Go and Poker in recent years. In the real world, however, many scenarios are non-zero-sum settings, meaning that success feels the necessity for cooperation and communication rather than competition. Hanabi game has been established as an ideal benchmark for agents to learn to cooperate adequately with other agents and humans. The Bayesian action decoder methods perform well on the 2 players Hanabi game while there remains a large performance gap between the numbers achieved by these methods and the performance of hat-coding strategies on the 3–5 players settings. The pivotal problem is the contradiction of the exploration of actions against the exploitation of observed actions. We present a novel deep multi-agent reinforcement learning method, the Modified Action Decoder to resolve this problem leveraging centralized training with decentralized execution paradigm. During the training phase, agents not only observe the exploratory action selected but also observe the optimal action of their teammates for better exploitation. We verify our method on Hanabi game in the 2–5 players setting, and it is superior to previously published reinforcement learning methods and establishes a new state of the art.},
  archive      = {J_IJMLC},
  author       = {Du, Wei and Ding, Shifei and Zhang, Chenglong and Du, Shuying},
  doi          = {10.1007/s13042-021-01385-7},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {10},
  pages        = {2947-2961},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Modified action decoder using bayesian reasoning for multi-agent deep reinforcement learning},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Mixed <span
class="math display"><em>H</em><sub>∞</sub></span> and passivity
analysis for t-s fuzzy system with non-fragile memory sampled-data
control via augment lyapunov–krasovskii functional. <em>IJMLC</em>,
<em>12</em>(10), 2933–2945. (<a
href="https://doi.org/10.1007/s13042-021-01379-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The performance of mixed $$H_{\infty }$$ and passivity for T-S fuzzy system under the non-fragile memory sampled-data controller is considered in this paper. We construct a non-fragile memory sampled-data controller, which includes a constant signal transmission delay. And by constructing an augment Lyapunov–Krasovskii functional (LKF), taking into account Wirtinger-based integral inequality and the Convex combination technique, we can get a new criteria that mixed $$H_{\infty }$$ and passivity for closed-loop system. Numerical examples are used to demonstrate the effectiveness and superiority of the results.},
  archive      = {J_IJMLC},
  author       = {Liu, Yuanyuan and Ma, Yuechao},
  doi          = {10.1007/s13042-021-01379-5},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {10},
  pages        = {2933-2945},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Mixed $$H_{\infty }$$ and passivity analysis for T-S fuzzy system with non-fragile memory sampled-data control via augment Lyapunov–Krasovskii functional},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Trust consistency in public data games on complex networks.
<em>IJMLC</em>, <em>12</em>(10), 2917–2932. (<a
href="https://doi.org/10.1007/s13042-021-01378-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The trust on network of Chinese public database is involved many factors in sociology, economics, technology, social psychology and so on, which resulted in the complexity of trust mechanism. The construction of trust mechanism plays a decisive role in public data governance via theoretical analysis. In the view of system science, trust is the key feedback control variable of data exchanging in the information structure and function of social economic system, while the emergence variable, not individual variable. In other words, the trust is unexpressed individually or locally, missed the principle of reductionism and belonging to the category of systems. The evolution of the structure and function of the trust in the public data trust game is a typical complex system dynamics process. By systematic approach, this research provides an overall framework for trust mechanisms in the Chinese public database network to reach trust consistency, thereby, improving the quality of Chinese public data products and the credibility of data authority in public sector. The problem of control is studied which betrayal is restricted to limit size of belief, in the viewpoints of public sector bureaucratic behavior, the data trust game and the trust psychological mechanism. One of proposed Byzantine general algorithm is provide for public data game with the &quot;cheap talk&quot;, and the trust dynamics equations is set up on the trust overlay network of hierarchical public data game, while the economic and sociological explains of the model conditions and model solving are presented for us to understand this algorithm and model.},
  archive      = {J_IJMLC},
  author       = {Li, Meng and Di, Zengru and Liu, Wenqi},
  doi          = {10.1007/s13042-021-01378-6},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {10},
  pages        = {2917-2932},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Trust consistency in public data games on complex networks},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Unsupervised person re-identification via k-reciprocal
encoding and style transfer. <em>IJMLC</em>, <em>12</em>(10), 2899–2916.
(<a href="https://doi.org/10.1007/s13042-021-01376-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study the unsupervised person re-identification (re-ID) problem, which does not require any annotation information. Our approach considers three aspects in unsupervised re-ID task, i.e., variance across various cameras, label allocation to unlabeled images and hard negative mining. First, an unsupervised style transfer model is adopted to generate style-transferred images with different camera styles, which contributes to reduce the variance across various cameras. Then we apply k-reciprocal encoding method to obtain k-reciprocal nearest neighbors. According to the feature similarity of the probe person with its neighbors, soft pseudo labels are allocated to the probe person iteratively. Due to lack of annotation information to pairwise images, we propose the k-reciprocal nearest neighbors loss (KNNL) to learn discriminative features. Furthermore, a hard negative mining strategy is adopted to improve the accuracy and robustness of our framework. We conduct experiments on three large-scale datasets: Market-1501, DukeMTMC-reID and MSMT17. Results show that our method not only outperforms the state-of-the-art unsupervised re-ID approaches, but also is superior to unsupervised domain adaptation methods (UDA) and semi-supervised learning methods.},
  archive      = {J_IJMLC},
  author       = {Xie, Kun and Wu, You and Xiao, Jing and Li, Jingjing and Xiao, Guohui and Cao, Yang},
  doi          = {10.1007/s13042-021-01376-8},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {10},
  pages        = {2899-2916},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Unsupervised person re-identification via K-reciprocal encoding and style transfer},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Hierarchical high-order co-clustering algorithm by
maximizing modularity. <em>IJMLC</em>, <em>12</em>(10), 2887–2898. (<a
href="https://doi.org/10.1007/s13042-021-01375-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The star-structured high-order heterogeneous data is ubiquitous, such data represent objects of a certain type, connected to other types of data, or the features, so that the overall data schema forms a star-structure of inter-relationships. In this paper, we study the problem of co-clustering of star-structured high-order heterogeneous data. We present a new solution, a Hierarchical High-order Co-clustering Algorithm by Maximizing Modularity, MHCoC, which iteratively optimizes the objective function based on modularity and finally converges to a unique clustering result. In contrast to the traditional co-clustering methods, MHCoC merges information of multiple feature spaces of high-order heterogeneous data. Moreover, MHCoC takes a top-down strategy to perform a greedy divisive procedure, generating a tree-like hierarchical clustering result that reveal the relationship between clusters. To illustrate the process in more detail, we design a toy example to describe how MHCoC selects the appropriate co-cluster and splits it. Extensive experiments on real-world datasets demonstrate the effectiveness of the proposed method.},
  archive      = {J_IJMLC},
  author       = {Wei, Jiahui and Ma, Huifang and Liu, Yuhang and Li, Zhixin and Li, Ning},
  doi          = {10.1007/s13042-021-01375-9},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {10},
  pages        = {2887-2898},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Hierarchical high-order co-clustering algorithm by maximizing modularity},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Hand gesture recognition using machine learning and infrared
information: A systematic literature review. <em>IJMLC</em>,
<em>12</em>(10), 2859–2886. (<a
href="https://doi.org/10.1007/s13042-021-01372-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Currently, gesture recognition is like a problem of feature extraction and pattern recognition, in which a movement is labeling as belonging to a given class. A gesture recognition system’s response could solve different problems in various fields, such as medicine, robotics, sign language, human–computer interfaces, virtual reality, augmented reality, and security. In this context, this work proposes a systematic literature review of hand gesture recognition based on infrared information and machine learning algorithms. This systematic literature review is an extended version of the work presented at the 2019 ICSE conference. To develop this systematic literature review, we used the Kitchenham methodology. This systematic literature review retrieves information about the models’ architectures, the implemented techniques in each module, the type of learning used (supervised, unsupervised, semi-supervised, and reinforcement learning), and recognition accuracy classification, and the processing time. Also, it will identify literature gaps for future research.},
  archive      = {J_IJMLC},
  author       = {Nogales, Rubén E. and Benalcázar, Marco E.},
  doi          = {10.1007/s13042-021-01372-y},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {10},
  pages        = {2859-2886},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Hand gesture recognition using machine learning and infrared information: A systematic literature review},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Diversity-promoting multi-view graph learning for
semi-supervised classification. <em>IJMLC</em>, <em>12</em>(10),
2843–2857. (<a
href="https://doi.org/10.1007/s13042-021-01370-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we focus on how to boost the semi-supervised classification performance by exploring the multi-view graph learning. The key of multi-view graph learning is to learn a discriminative and informative graph from the multiple input graphs. However, we observe that existing multi-view graph learning methods do not sufficiently consider the diversity among views. This results in giving great weighted coefficients for mutually redundant views and affects the diversity of information of views utilized for multi-view graph learning, which finally deteriorates the semi-supervised classification performance. To address this issue, we propose a robust multi-view graph learning method with a novel and effective diversity-promoting regularized term to reduce the redundancy of views and enhance the diversity of the views. To improve the accuracy of label propagation, we further propose a unified framework which integrates multi-view graph learning, label propagation and diversity-promoting of views together. We develop an effective alternating optimization strategy to solve the optimization problem. Extensive experiments on synthetic and several benchmark data sets demonstrate the effectiveness of the proposed method.},
  archive      = {J_IJMLC},
  author       = {Zhan, Shanhua and Sun, Weijun and Du, Cuifeng and Zhong, Weifang},
  doi          = {10.1007/s13042-021-01370-0},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {10},
  pages        = {2843-2857},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Diversity-promoting multi-view graph learning for semi-supervised classification},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A novel density peaks clustering algorithm based on k
nearest neighbors with adaptive merging strategy. <em>IJMLC</em>,
<em>12</em>(10), 2825–2841. (<a
href="https://doi.org/10.1007/s13042-021-01369-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently the density peaks clustering algorithm (DPC) has received a lot of attention from researchers. The DPC algorithm is able to find cluster centers and complete clustering tasks quickly. It is also suitable for different kinds of clustering tasks. However, deciding the cutoff distance $${d}_{c}$$ largely depends on human experience which greatly affects clustering results. In addition, the selection of cluster centers requires manual participation which affects the efficiency of the algorithm. In order to solve these problems, we propose a density peaks clustering algorithm based on K nearest neighbors with adaptive merging strategy (KNN-ADPC). A clusters merging strategy is proposed to automatically aggregate over-segmented clusters. Additionally, the K nearest neighbors are adopted to divide data points more reasonably. There is only one parameter in KNN-ADPC algorithm, and the clustering task can be conducted automatically without human involvement. The experiment results on artificial and real-world datasets prove higher accuracy of KNN-ADPC compared with DBSCAN, K-means++, DPC, and DPC-KNN.},
  archive      = {J_IJMLC},
  author       = {Yuan, Xiaoning and Yu, Hang and Liang, Jun and Xu, Bing},
  doi          = {10.1007/s13042-021-01369-7},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {10},
  pages        = {2825-2841},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A novel density peaks clustering algorithm based on k nearest neighbors with adaptive merging strategy},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A novel method for mandarin speech synthesis by inserting
prosodic structure prediction into tacotron2. <em>IJMLC</em>,
<em>12</em>(10), 2809–2823. (<a
href="https://doi.org/10.1007/s13042-021-01365-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Speech synthesis, an artificial intelligence technology that employs computers to imitate human speech, has played a crucial role in human–computer interaction since it can automatically convert text into speech with satisfactory intelligibility and naturalness. Tacotron2 is the second generation end-to-end English speech synthesis model developed by Google. As Mandarin becomes more and more popular in the world, the associated speech synthesis technologies have been applied in various applications. Aiming at extending Tacotron2 to synthesize Mandarin speech, we propose in this paper a novel synthesis method by adding a Mandarin-to-PinYin module and a prosodic structure prediction model into Tacotron2. By evaluating synthesized results with subjective and objective methods, the added prosodic structure prediction model is demonstrated to help Tacotron2 synthesize more natural and human-like Mandarin speech.},
  archive      = {J_IJMLC},
  author       = {Liu, Junmin and Xie, Zhuangzhuang and Zhang, Chunxia and Shi, Guang},
  doi          = {10.1007/s13042-021-01365-x},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {10},
  pages        = {2809-2823},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A novel method for mandarin speech synthesis by inserting prosodic structure prediction into tacotron2},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). LHFF-net: Local heterogeneous feature fusion network for
6DoF pose estimation. <em>IJMLC</em>, <em>12</em>(10), 2795–2807. (<a
href="https://doi.org/10.1007/s13042-021-01364-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pose estimation based on RGB-D images is a hot issue that has attracted much attention in recent years. A key technical challenge is to extract features from depth information and image information separately and fully leverage the two complementary data sources. The previous methods ignored the internal connection of local features and the feature fusion of heterogeneous data, limiting the robustness and real-time performance in cluttered scenes. In this article, we propose LHFF-Net, a generic framework based on dynamic graph convolution to strengthen the information aggregation among all point clouds in a local region. After extracting heterogeneous features, we fuse information from two data sources in different receptive fields, to estimate the pose of the object while fully extracting local features. We show in experiments that the proposed approach outperforms state-of-the-art approaches on two challenging data sets, YCB-Video and LineMOD. We also have deployed our proposed method on the UR5 robot for grasping experiments and achieved good grasping performance.},
  archive      = {J_IJMLC},
  author       = {Wang, Fei and He, Zhenquan and Zhang, Xing and Jiang, Yong},
  doi          = {10.1007/s13042-021-01364-y},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {10},
  pages        = {2795-2807},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {LHFF-net: Local heterogeneous feature fusion network for 6DoF pose estimation},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). LSTM-assisted evolutionary self-expressive subspace
clustering. <em>IJMLC</em>, <em>12</em>(10), 2777–2793. (<a
href="https://doi.org/10.1007/s13042-021-01363-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Massive volumes of high-dimensional data that evolve over time are continuously collected by contemporary information processing systems, which bring up the problem of organizing these data into clusters, i.e. achieving the purpose of dimensional reduction, and meanwhile learning their temporal evolution patterns. In this paper, a framework for evolutionary subspace clustering, referred to as LSTM–ESCM, is introduced, which aims at clustering a set of evolving high-dimensional data points that lie in a union of low-dimensional evolving subspaces. In order to obtain the parsimonious data representation at each time step, we propose to exploit the so-called self-expressive trait of the data at each time point. At the same time, LSTM networks are implemented to extract the inherited temporal patterns behind data in the overall time frame. An efficient algorithm has been proposed. Numerous experiments are carried out on real-world datasets to demonstrate the effectiveness of our proposed approach. The results show that the suggested algorithm dramatically outperforms other known similar approaches in terms of both run time and accuracy.},
  archive      = {J_IJMLC},
  author       = {Xu, Di and Bai, Mingyuan and Long, Tianhang and Gao, Junbin},
  doi          = {10.1007/s13042-021-01363-z},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {10},
  pages        = {2777-2793},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {LSTM-assisted evolutionary self-expressive subspace clustering},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A decision making model based on intuitionistic
multiplicative preference relations with approximate consistency.
<em>IJMLC</em>, <em>12</em>(10), 2761–2775. (<a
href="https://doi.org/10.1007/s13042-021-01362-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intuitionistic fuzzy numbers possess the ability to model the bipolarity of practical objects and phenomena. The positive and negative opinions of decision makers (DMs) could be captured by intuitionistic multiplicative preference relations (IMPRs). In this study, the known consistency definitions of IMPRs are reviewed and the underlying ideas are analyzed. By considering the uncertainty shown by IMPRs, the concept of approximate consistency (AC) is proposed. Then the AC and acceptable AC of IMPRs are defined by dividing the non-determinacy judgements of the DM with the introduction of an attitude factor. The methods of eliciting the priorities of alternatives from an IMPR with acceptable AC are studied. A decision making model is proposed by considering the acceptable AC of IMPRs. Numerical results are reported to demonstrate that the application of different attitude factors could lead to different optimal solutions. It is observed that the inherent property of IMPRs should be incorporated into theoretical and practical models under intuitionistic fuzzy environments.},
  archive      = {J_IJMLC},
  author       = {Zhao, Hui and Tan, Xu and Liu, Fang},
  doi          = {10.1007/s13042-021-01362-0},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {10},
  pages        = {2761-2775},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A decision making model based on intuitionistic multiplicative preference relations with approximate consistency},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Compressed sensing using generative models based on fisher
information. <em>IJMLC</em>, <em>12</em>(10), 2747–2759. (<a
href="https://doi.org/10.1007/s13042-021-01337-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In compressed sensing applications, self-learning generative models have attracted increasing attention because they provide guarantees that are similar to those of standard compressed sensing without employing sparsity. However, improving the performances of a generative model is challenging. In this paper, we improve the recovery performances of generative models (generative adversarial networks) by making use of prior knowledge about the support of the vector of the original signal in the relevant domain. We demonstrate the advantage of using a parametric model with the Fisher distance metric for the exploitation of a distribution over the support when constraints on the distribution have been specified. We combine the generative model with the Fisher distance to study the recovery of sparse signals that satisfy a distribution for the purpose of improving the recovery performance of the model when there are some constraints on the distribution. Finally, we present the results of extensive experiments conducted on simulated signals and imaging signals.},
  archive      = {J_IJMLC},
  author       = {Wang, Meng and Yu, Jing and Ning, Zhen-Hu and Xiao, Chuang-Bai},
  doi          = {10.1007/s13042-021-01337-1},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {10},
  pages        = {2747-2759},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Compressed sensing using generative models based on fisher information},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A projection and contraction method for circular cone
programming support vector machines. <em>IJMLC</em>, <em>12</em>(9),
2733–2746. (<a
href="https://doi.org/10.1007/s13042-021-01360-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The second-order cone programming support vector machine (SOCP-SVM) formulations have received much attention as the robust and efficient framework for classification. In this paper, we formulate the SOCP-SVM as the convex quadratic circular cone programming support vector machine (CCP-SVM). A projection and contraction method is used to solve the CCP-SVM. Experiments on the benchmark datasets from the UCI Repository and synthetic dataset show that the projection and contraction method for the CCP-SVM needs less computation time than the primal-dual interior point method (implemented by SeDuMi) for the SOCP-SVM. In addition, the proposed method has the almost similar accuracy, F-measure values and G-mean values as the primal-dual interior point method for the linear classifiers. The proposed method for kernel-based nonlinear classifiers can obtain higher performances of accuracy, F-measure and G-mean than the primal-dual interior point method for SOCP-SVM in some datasets.},
  archive      = {J_IJMLC},
  author       = {Mu, Xuewen and Dong, Guishan},
  doi          = {10.1007/s13042-021-01360-2},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {9},
  pages        = {2733-2746},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A projection and contraction method for circular cone programming support vector machines},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Towards on-line tuning of adaptive-agent’s multivariate
meta-parameter. <em>IJMLC</em>, <em>12</em>(9), 2717–2731. (<a
href="https://doi.org/10.1007/s13042-021-01358-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A decision-making (DM) agent models its environment and quantifies its DM preferences. An adaptive agent models them locally nearby the realisation of the behaviour of the closed DM loop. Due to this, a simple tool set often suffices for solving complex dynamic DM tasks. The inspected Bayesian agent relies on a unified learning and optimisation framework, which works well when tailored by making a range of case-specific options. Many of them can be made off-line. These options concern the sets of involved variables, the knowledge and preference elicitation, structure estimation, etc. Still, some meta-parameters need an on-line choice. This concerns, for instance, a weight balancing exploration with exploitation, a weight reflecting agent’s willingness to cooperate, a discounting factor, etc. Such options influence, often vitally, DM quality and their adaptive tuning is needed. Specific ways exist, for instance, a data-dependent choice of a forgetting factor serving to tracking of parameter changes. A general methodology is, however, missing. The paper opens a pathway to it. The solution uses a hierarchical feedback exploiting a generic, DM-related, observable, mismodelling indicator. The paper presents and justifies the theoretical concept, outlines and illustrates its use.},
  archive      = {J_IJMLC},
  author       = {Kárný, Miroslav},
  doi          = {10.1007/s13042-021-01358-w},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {9},
  pages        = {2717-2731},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Towards on-line tuning of adaptive-agent’s multivariate meta-parameter},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Modification of the BWM and MABAC method for MAGDM based on
q-rung orthopair fuzzy rough numbers. <em>IJMLC</em>, <em>12</em>(9),
2693–2715. (<a
href="https://doi.org/10.1007/s13042-021-01357-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Considering the uncertainties of multi-attribute group decision-making (MAGDM) problems, we put forward the concept of q-rung orthopair fuzzy rough numbers, which is obtained by integrating q-rung orthopair fuzzy numbers and rough numbers. Further a weight calculation method based on q-rung orthopair fuzzy rough number is investigated and a new decision making approach is designed to solve MAGDM problems. The main contributions of this work are listed as follows: (1) The construction process of q-rung orthopair fuzzy rough number is given along with its ranking rules, arithmetic operations, aggregation operators and some corresponding attributes. (2) A novel attributes’ weight calculation approach q-rung orthopair fuzzy rough best-worst method (q-ROFRBWM) is proposed by modifying classical best-worst method (BWM). (3) We introduce the q-rung orthopair fuzzy rough numbers into the multi-attribute boundary approximation regional comparison (MABAC) method, and a modified q-ROFRBWM-MABAC method for solving the MAGDM problem is constructed by combining the q-ROFRBWM weight calculation method. (4) Applying q-ROFRBWM-MABAC method to solve the impact of major infrastructure projects on various social vulnerability factors. The effectiveness and merits of the q-ROFRBWM-MABAC method are also verified by comparing with existing methods.},
  archive      = {J_IJMLC},
  author       = {Liu, Fang and Li, Tianrui and Wu, Ju and Liu, Yi},
  doi          = {10.1007/s13042-021-01357-x},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {9},
  pages        = {2693-2715},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Modification of the BWM and MABAC method for MAGDM based on q-rung orthopair fuzzy rough numbers},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Adaptive factorization rank selection-based NMF and its
application in tumor recognition. <em>IJMLC</em>, <em>12</em>(9),
2673–2691. (<a
href="https://doi.org/10.1007/s13042-021-01353-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The nonnegative matrix factorization (NMF) has been widely used because it can accomplish both feature representation learning and dimension reduction. However, there are two critical and challenging issues affecting the performance of NMF models. One is the selection of matrix factorization rank, while most of the existing methods are based on experiments or experience. For tackling this issue, an adaptive and stable NMF model is constructed based on an adaptive factorization rank selection (AFRS) strategy, which skillfully and simply integrates a row constraint similar to the generalized elastic net. The other is the sensitivity to the initial value of the iteration, which seriously affects the result of matrix factorization. This issue is alleviated by complementing NMF and deep learning each other and avoiding complex network structure. The proposed NMF model is called deep AFRS-NMF model for short, and the corresponding optimization solution, convergence and stability are analyzed. Moreover, the statistical consistency is discussed between the rank obtained by the proposed model and the ideal rank. The performance of the proposed deep AFRS-NMF model is demonstrated by applying in genetic data-based tumor recognition. Experiments show that the factorization rank obtained by the deep AFRS-NMF model is stable and superior to classical and state-of-the-art methods.},
  archive      = {J_IJMLC},
  author       = {Yang, Xiaohui and Wu, Wenming and Xin, Xin and Su, Limin and Xue, Liugen},
  doi          = {10.1007/s13042-021-01353-1},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {9},
  pages        = {2673-2691},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Adaptive factorization rank selection-based NMF and its application in tumor recognition},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Local positive and negative label correlation analysis with
label awareness for multi-label classification. <em>IJMLC</em>,
<em>12</em>(9), 2659–2672. (<a
href="https://doi.org/10.1007/s13042-021-01352-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In multi-label learning, exploiting label correlation, alleviating class imbalance and learning label-specific features have been hot topics to increase classification performance. In the paper, we propose a method to address the three issues simultaneously. The method, named LPLC-LA, builds a Bayesian model by exploiting the local positive and negative label correlations with label awareness. LPLC-LA consists of extracting label-specific features to obtain the local positive and negative correlation, defining two label aware weights for label imbalance and label separability, and then improving the estimation of label conditional probability through the two weights. The experimental results over eight benchmark datasets show that LPLC-LA can achieve better performance compared with other state-of-the-art approaches.},
  archive      = {J_IJMLC},
  author       = {Huang, Rui and Kang, Liuyue},
  doi          = {10.1007/s13042-021-01352-2},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {9},
  pages        = {2659-2672},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Local positive and negative label correlation analysis with label awareness for multi-label classification},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A recursive feature retention method for semi-supervised
feature selection. <em>IJMLC</em>, <em>12</em>(9), 2639–2657. (<a
href="https://doi.org/10.1007/s13042-021-01346-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To deal with semi-supervised feature selection tasks, this paper presents a recursive feature retention (RFR) method based on a neighborhood discriminant index (NDI) method (a supervised feature selection method) and a forward iterative Laplacian score (FILS) method (an unsupervised method), where FILS is designed specially for RFR. The goal of RFR is to determine an optimal feature subset that has not only a high discriminant ability but also a strong ability to maintain the local structure of data. The discriminant ability of a feature is measured by NDI, and the ability of a feature to maintain the local structure of data is described by FILS. RFR compromises these two scores to give a balanced score for a feature. RFR iteratively selects a feature with the smallest balanced score and moves it into the current optimal feature subset. This paper also shows theoretical analysis to speed up iterations. Extensive experiments are conducted on toy and real-world data sets. Experimental results confirm that RFR can achieve a better performance compared with the state-of-the-art semi-supervised methods.},
  archive      = {J_IJMLC},
  author       = {Pang, Qingqing and Zhang, Li},
  doi          = {10.1007/s13042-021-01346-0},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {9},
  pages        = {2639-2657},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A recursive feature retention method for semi-supervised feature selection},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Diversity collaboratively guided random drift particle swarm
optimization. <em>IJMLC</em>, <em>12</em>(9), 2617–2638. (<a
href="https://doi.org/10.1007/s13042-021-01345-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The random drift particle swarm optimization (RDPSO) algorithm is an effective random search technique inspired by the trajectory analysis of the canonical PSO and the free electron model in metal conductors placed in an external electric field. However, like other PSO variants, the RDPSO algorithm also inevitably encounters premature convergence when solving multimodal problems. To address this issue, this paper proposes a novel diversity collaboratively guided (DCG) strategy for the RDPSO algorithm that enhances the search ability of the algorithm. In this strategy, two kinds of diversity measures are defined and modified in a collaborative manner. Specifically, the whole search process of the RDPSO is divided into three phases based on the changes in the two diversity measures. In each phase, different values are selected for the key parameters of the update equation in the RDPSO to make the particle swarm perform different search modes. Consequently, the improved RDPSO algorithm with the DCG strategy (DCG-RDPSO) can maintain its diversity dynamically at a certain level, and thus can search constantly without stagnation until the search process terminates. The performance evaluation of the proposed algorithm is done on the CEC-2013 benchmark suite, in comparison with several versions of RDPSO, different variants of PSO and several non-PSO evolutionary algorithms. Experimental results show that the proposed DCG strategy can significantly improve the performance and robustness of the RDPSO algorithm for most of the multimodal problems. Further experiments on economic dispatch problems also verify the effectiveness of the DCG strategy.},
  archive      = {J_IJMLC},
  author       = {Li, Chao and Sun, Jun and Palade, Vasile and Li, Li-Wei},
  doi          = {10.1007/s13042-021-01345-1},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {9},
  pages        = {2617-2638},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Diversity collaboratively guided random drift particle swarm optimization},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Learning to capture contrast in sarcasm with contextual
dual-view attention network. <em>IJMLC</em>, <em>12</em>(9), 2607–2615.
(<a href="https://doi.org/10.1007/s13042-021-01344-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sarcasm is a common way of rhetoric in our daily life. It is used to express the opposite of the literal meaning, which makes it a challenging task in sentiment analysis of natural language processing (NLP). The formation mechanism of sarcasm is usually caused by the contrast between the positive sentiment and the negative situation. In this paper, we propose a contextual dual-view attention network (CDVaN) for sarcasm detection according to the formation mechanism of sarcasm. A Contrast Understanding Unit is proposed to effectively extract the contrast between the positive sentiment and the negative situation from the view of formation mechanism of sarcasm. Apart from it, we further use a Context Understanding Unit to extract the contextual semantic information from the contextual semantic view. Our experiments on the IAC-V1 dataset and IAC-V2 dataset demonstrate that the proposed CDVaN model can distinguish sarcasm effectively. The results show that our model achieves state-of-the-art or comparable results.},
  archive      = {J_IJMLC},
  author       = {Ren, Lu and Lin, Hongfei and Xu, Bo and Yang, Liang and Zhang, Dongyu},
  doi          = {10.1007/s13042-021-01344-2},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {9},
  pages        = {2607-2615},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Learning to capture contrast in sarcasm with contextual dual-view attention network},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Sequence and graph structure co-awareness via gating
mechanism and self-attention for session-based recommendation.
<em>IJMLC</em>, <em>12</em>(9), 2591–2605. (<a
href="https://doi.org/10.1007/s13042-021-01343-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Session-based recommendation (SR) is important in online applications for its ability to predict user’s next interactions solely based on ongoing sessions. To recommend proper items at proper time are two key aspects in SR. The sequence of items in a session implies user’s preferences shift, which may give us clues about when the user interacted. The graph constructed based on a session can give latent structural dependencies between items, which may give us clues about which items users interacted with. They complement each other and collaborate to boost the performance of recommendation. Based on the motivation, we propose a novel sequence and graph structure co-awareness session-based recommendation model, namely SeqGo for short. In this model, a gated recurrent unit is employed to obtain sequence information and a gated graph neural network to get graph structure information. A two-stage fusion strategy is built to combine these two types of information to generate the representation of the general interest of users. The gating mechanism is used to calculate the relative importance of sequence and graph structure information. Then, multi-head masked self-attention is applied to assign different weights to different items and ignore irrelevant items. The user&#39;s general interest and the last item representing the user&#39;s current interest are combined to get the session representation to predict the probability of clicking on the next items. Experiment results on two real-world datasets show that SeqGo outperforms the state-of-the-art baselines.},
  archive      = {J_IJMLC},
  author       = {Qiao, Jingjing and Wang, Li and Duan, Liguo},
  doi          = {10.1007/s13042-021-01343-3},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {9},
  pages        = {2591-2605},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Sequence and graph structure co-awareness via gating mechanism and self-attention for session-based recommendation},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A stochastic sensitivity-based multi-objective optimization
method for short-term wind speed interval prediction. <em>IJMLC</em>,
<em>12</em>(9), 2579–2590. (<a
href="https://doi.org/10.1007/s13042-021-01340-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the increasing penetration of wind power in renewable energy systems, it is important to improve the accuracy of wind speed prediction. However, wind power generation has great uncertainties which make high-quality interval prediction a challenge. Existing multi-objective optimization interval prediction methods do not consider the robustness of the model. Thus, trained models for wind speed interval prediction may not be optimal for future predictions. In this paper, the prediction interval coverage probability, the prediction interval average width, and the robustness of the model are used as three objective functions for determining the optimal model of short-term wind speed interval prediction using multi-objective optimization. Furthermore, a new Stochastic Sensitivity for Prediction Intervals (SS_PIs) is proposed in this work to measure the stability and robustness of the model for interval prediction. Using wind farm data from countries on two different continents as case studies, experimental results show that the proposed method yields better prediction intervals in terms of all metrics including prediction interval coverage probability (PICP), prediction interval normalized average width (PINAW) and SS_PIs. For example, at the prediction interval nominal confidence (PINC) of 85\%, 90\% and 95\%, the proposed method has the best performance in all metrics of the USA wind farm dataset.},
  archive      = {J_IJMLC},
  author       = {Chen, Xuanqun and Lai, Chun Sing and Ng, Wing W. Y. and Pan, Keda and Lai, Loi Lei and Zhong, Cankun},
  doi          = {10.1007/s13042-021-01340-6},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {9},
  pages        = {2579-2590},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A stochastic sensitivity-based multi-objective optimization method for short-term wind speed interval prediction},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Binary domain adaptation with independence maximization.
<em>IJMLC</em>, <em>12</em>(9), 2559–2578. (<a
href="https://doi.org/10.1007/s13042-021-01339-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the following study, an innovative domain adaptation technique is proposed. dCor based Domain Adaptation or dDA technique is based on maximum mean discrepancy (MMD) and distance correlation (dCor); a powerful yet general correlation measure which is applicable to arbitrary-dimensional random variables. By projecting the samples to a common latent feature space, dDA minimizes the discrepancy between the source and target distributions while preserving the structural information of the data. The proposed dDA algorithm can be easily implemented and it has a closed-form and simple solution. Extensive analyses across various real-world and sentiment analysis benchmark data sets indicate that our algorithm is the method of choice; as it offers superior results in comparison with several state-of-the-art domain adaptation approaches in the literature in both unsupervised and semi-supervised settings.},
  archive      = {J_IJMLC},
  author       = {Abdi, Lida and Hasehmi, Sattar},
  doi          = {10.1007/s13042-021-01339-z},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {9},
  pages        = {2559-2578},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Binary domain adaptation with independence maximization},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Hier2vec: Interpretable multi-granular representation
learning for hierarchy in social networks. <em>IJMLC</em>,
<em>12</em>(9), 2543–2557. (<a
href="https://doi.org/10.1007/s13042-021-01338-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Network representation learning (NRL) maps vertices into latent vector space for further network inference. The existing algorithms concern more about whether the vectors of two similar nodes be close in latent vector space while the hierarchy proximity has been largely neglected by them. The distribution of the representation vectors needs to reflect the hierarchical structural properties which widely exist in networks. In this paper, we propose a novel network representation learning framework that can encode the interpretable hierarchical structural semantics into the representation vectors. Specifically, we measure the distance and importance degree of nodes in the original network and map the nodes to a tree space. This makes the hierarchical structural relations in the original network be clearly revealed by the tree which is also of good interpretability. In this paper, the local structural proximities and the interpretable hierarchy knowledge are encoded into vector space by optimizing the objective function. Extensive experiments conducted on the realistic data sets demonstrate that the proposed approach outperforms the existing state-of-the-art approaches on tasks of node classification, link prediction, and visualization. Finally, a case study is conducted for further analysis about how the proposed model works.},
  archive      = {J_IJMLC},
  author       = {Fu, Shun and Wang, Guoyin and Xu, Ji},
  doi          = {10.1007/s13042-021-01338-0},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {9},
  pages        = {2543-2557},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Hier2vec: Interpretable multi-granular representation learning for hierarchy in social networks},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Self-paced hierarchical metric learning (SPHML).
<em>IJMLC</em>, <em>12</em>(9), 2529–2541. (<a
href="https://doi.org/10.1007/s13042-021-01336-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Metric learning aims to learn a distance to measure the difference between two samples, and it plays an important role in pattern recognition tasks. Most of the existing metric learning methods rely on pairs of samples. However, the importance of sample pairs varies greatly because of possible noise and the difference between samples and the decision boundaries. In this paper, we propose a robust hierarchical metric learning (SPHML) framework based on self-paced learning, which can help gain knowledge about the weights of sample pairs and utilize them in an easy or hard manner. Hierarchical nonlinear functions are learned by back-propagation to map sample pairs into a more discriminative feature space. Experimentally, our method achieves very competitive performance when compared with state-of-the-art methods.},
  archive      = {J_IJMLC},
  author       = {Al-taezi, Mohammed and Zhu, Pengfei and Hu, Qinghua and Wang, Yu and Al-badwi, Abdulrahman},
  doi          = {10.1007/s13042-021-01336-2},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {9},
  pages        = {2529-2541},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Self-paced hierarchical metric learning (SPHML)},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Case2vec: Joint variational autoencoder for case text
embedding representation. <em>IJMLC</em>, <em>12</em>(9), 2517–2528. (<a
href="https://doi.org/10.1007/s13042-021-01335-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The embedding representation of the case text represent text as vector which consist information of original texts abundantly. Text embedding representation usually uses text statistical features or content features alone. However, case texts have characteristics that include similar structure, repeated words, and different text lengths. And the statistical feature or content feature cannot represent case text efficiently. In this paper, we propose a joint variational autoencoder (VAE) to represent case text embedding representation. We consider the statistical features and content features of case texts together, and use VAE to align the two features into the same space. We compare our representations with existing methods in terms of quality, relationship, and efficiency. The experiment results show that our method has achieved good results, which have higher performance than the model using single feature.},
  archive      = {J_IJMLC},
  author       = {Song, Ran and Gao, Shengxiang and Yu, Zhengtao and Zhang, Yafei and Zhou, Gaofeng},
  doi          = {10.1007/s13042-021-01335-3},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {9},
  pages        = {2517-2528},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Case2vec: Joint variational autoencoder for case text embedding representation},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Froth image clustering with feature semi-supervision through
selection and label information. <em>IJMLC</em>, <em>12</em>(9),
2499–2516. (<a
href="https://doi.org/10.1007/s13042-021-01333-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate classification and recognition of coal flotation froth is one of the key technologies for intelligent coal separation. At present, the coal flotation process relies on artificial recognition of froth features for adjusting the reagent dosage, which cannot realize the optimal control of the quality of the clean coal product and the cost of the reagents. Therefore, in this paper, it is proposed a method of froth image clustering with feature semi-supervision through selection and label information. It is mainly divided into two stages: offline clustering and online recognition. The offline stage is to preprocess the froth image under various reagent conditions, extract the morphology, colour and texture features, and select the multi-dimensional optimal froth image features. A small number of marked samples are introduced to optimize the Gaussian mixture model. The selected optimal features are integrated into the optimized Gaussian mixture model to construct a froth image clusterer with multi-dimensional optimal features and class labels. In the online stage, the real-time froth image features are input clusterer and compared with the cluster feature samples to identify the current reagents conditions, which is used as feedback information to guide the abnormal reagent conditions during the production process. The effect of the amount of supervision information and the quality of feature on clustering results is analyzed and compared through experiments. The application results show that this method can provide key technical support for the accurate control of the dosage of reagents and the quality of clean coal product in the coal flotation production process, reduce the cost of reagents and the number of production accidents, improve the economic benefits, and promote the development of coal flotation intelligence to a higher level.},
  archive      = {J_IJMLC},
  author       = {Cao, Wenyan and Wang, Ranfeng and Fan, Minqiang and Fu, Xiang and Wang, Yulong and Guo, Zhongtian and Fan, Fubo},
  doi          = {10.1007/s13042-021-01333-5},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {9},
  pages        = {2499-2516},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Froth image clustering with feature semi-supervision through selection and label information},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A BSC-based network DEA model equipped with computational
linguistics for performance assessment and improvement. <em>IJMLC</em>,
<em>12</em>(9), 2479–2497. (<a
href="https://doi.org/10.1007/s13042-021-01331-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This research introduces a fusion architecture that integrates balanced scorecards (BSCs) and network data envelopment analysis (NDEA) to conduct a performance evaluation task from multiple perspectives. The architecture is able to capture the dynamics of production processes and sub-processes, uncover some of the components behind successful business practices, and shed light on needed actions for decision makers. Furthermore, the architecture not only can support decision makers to plan for improvement, but also equip them with forecasting ability. To enhance its forecasting quality, this study goes beyond quantitative ratios and extends them to qualitative ratios (i.e., readability: the complexities of disclosure) borrowed from computational linguistics. The results indicate that a poor readability score is highly associated with bad operations. Finally, to enlarge the mechanism’s applicable fields, the study executes the genetic algorithm (GA) to extract the inherent decision logics and represents them in a human-readable manner. The mechanism, examined by real cases, is a promising alternative for performance evaluation and forecasting.},
  archive      = {J_IJMLC},
  author       = {Hsu, Ming-Fu and Lin, Sin-Jin},
  doi          = {10.1007/s13042-021-01331-7},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {9},
  pages        = {2479-2497},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A BSC-based network DEA model equipped with computational linguistics for performance assessment and improvement},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A new feature selection metric for text classification:
Eliminating the need for a separate pruning stage. <em>IJMLC</em>,
<em>12</em>(9), 2461–2478. (<a
href="https://doi.org/10.1007/s13042-021-01324-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Terms that occur too frequently or rarely in various texts are not useful for text classification. Pruning can be used to remove such irrelevant terms reducing the dimensionality of the feature space and, thus making feature selection more efficient and effective. Normally, pruning is achieved by manually setting threshold values. However, incorrect threshold values can result in the loss of many useful terms or retention of irrelevant ones. Existing feature ranking metrics can assign higher ranks to these irrelevant terms, thus degrading the performance of a text classifier. In this paper, we propose a new feature ranking metric, which can select the most useful terms in the presence of these too frequently and rarely occurring terms, thus eliminating the need for pruning these terms. To investigate the usefulness of the proposed metric, we compare it against seven well-known feature selection metrics on five data sets namely Reuters-21578 (re0, re1, r8) and WebACE (k1a, k1b) using multinomial naive Bayes and support vector machines classifiers. Our results based on a paired t-test show that the performance of our metric is statistically significant than that of the other seven metrics.},
  archive      = {J_IJMLC},
  author       = {Asim, Muhammad and Javed, Kashif and Rehman, Abdur and Babri, Haroon A.},
  doi          = {10.1007/s13042-021-01324-6},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {9},
  pages        = {2461-2478},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A new feature selection metric for text classification: Eliminating the need for a separate pruning stage},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Correction to: Path-based estimation for link prediction.
<em>IJMLC</em>, <em>12</em>(9), 2459. (<a
href="https://doi.org/10.1007/s13042-021-01350-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A correction to this paper has been published: https://doi.org/10.1007/s13042-021-01350-4},
  archive      = {J_IJMLC},
  author       = {Ma, Guoshuai and Yan, Hongren and Qian, Yuhua and Wang, Lingfeng and Dang, Chuangyin and Zhao, Zhongying},
  doi          = {10.1007/s13042-021-01350-4},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {9},
  pages        = {2459},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Correction to: Path-based estimation for link prediction},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Path-based estimation for link prediction. <em>IJMLC</em>,
<em>12</em>(9), 2443–2458. (<a
href="https://doi.org/10.1007/s13042-021-01312-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Link prediction has received a great deal of attention from researchers. Most of the existing researches are based on the network topology but ignore the importance of its preference; for aggregating multiple pieces of information, they normally sum up them directly. In this paper, a path-based probabilistic model is proposed to estimate the potential connectivity between any two nodes. It takes carefully the effective influence of nodes and the dependency among paths between two fixed nodes into account. Furthermore, we formulate the connectivity of two inner-community nodes and that of two inter-community nodes. The qualitative analysis shows that the links between inner-community nodes are more likely to be predicted by the proposed model. The performance is verified on both the multi-barbell network and Lesmis network. Considering the proposed model’s practicability, we develop an algorithm that iterates over the adjacent matrix to simulate paths of different lengths, with the parameters automatically grid-searched. The results of the experiments show that the proposed model outperforms competitive methods.},
  archive      = {J_IJMLC},
  author       = {Ma, Guoshuai and Yan, Hongren and Qian, Yuhua and Wang, Lingfeng and Dang, Chuangyin and Zhao, Zhongying},
  doi          = {10.1007/s13042-021-01312-w},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {9},
  pages        = {2443-2458},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Path-based estimation for link prediction},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Investigations of butterfly species identification from
images in natural environments. <em>IJMLC</em>, <em>12</em>(8),
2431–2442. (<a
href="https://doi.org/10.1007/s13042-021-01322-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It has been a challenging problem to identify species of butterflies, especially from images taken in natural environments. Therefore the First international butterfly species recognition competition was organized at the third Data Mining Competition in China in 2018, so as to find good solutions to this challenging problem. The baseline for the competition was based on the Faster R-CNN for it was the latest deep learning algorithm at that time. Nearly all the competition teams chose the Faster R-CNN, or its variations, to solve the problem. But the identification rates were not good enough, and Faster R-CNN is very time consuming. As a result we have been trying to find the most suitable algorithm to solve the butterfly species identification challenge. This paper will present some investigations we have undertaken in this field over the past two years, and show the results we have obtained. We propose a new partition and augmentation technique for the extremely unbalanced ecological butterfly database. We found that RetinaNet is, so far, the best deep learning algorithm to tackle butterfly species identification based on butterfly images taken in natural environments. The best result we obtained was 79.7\% in terms of mAP (mean average precision). This is the best result compared to the state-of-the-art studies in this field on the same database so far.},
  archive      = {J_IJMLC},
  author       = {Xie, Juanying and Lu, Yinyuan and Wu, Zhaozhong and Xu, Shengquan and Grant, Phil W.},
  doi          = {10.1007/s13042-021-01322-8},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {8},
  pages        = {2431-2442},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Investigations of butterfly species identification from images in natural environments},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Covering-based variable precision l-fuzzy rough sets based
on residuated lattices and corresponding applications. <em>IJMLC</em>,
<em>12</em>(8), 2407–2429. (<a
href="https://doi.org/10.1007/s13042-021-01320-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There are many extensions of Pawlak’s rough sets. Particularly, fuzzy rough set theory based on residuated lattices is considered as one of the generalizations that extends the truth values to lattices. In this paper, we attempt to combine the idea of “variable precision” with covering-based fuzzy rough sets based on residuated lattices and present the concept of covering-based variable precision L-fuzzy rough sets. After the presentation of this concept, some basic properties of the proposed rough set model are discussed. Then, with the aid of the PROMETHEE and TOPSIS methods, we put forth a novel multi-attribute decision-making (MADM) method based on covering-based variable precision L-fuzzy rough sets (for $$L=[0,1]$$ ). Finally, an illustrative example is give to demonstrate the proposed decision-making method. By a sensitivity analysis along with a comparative analysis, we reveal the applicability and validity of the proposed decision-making method.},
  archive      = {J_IJMLC},
  author       = {Jiang, Haibo and Zhan, Jianming and Chen, Degang},
  doi          = {10.1007/s13042-021-01320-w},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {8},
  pages        = {2407-2429},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Covering-based variable precision L-fuzzy rough sets based on residuated lattices and corresponding applications},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Fuzzy measure with regularization for gene selection and
cancer prediction. <em>IJMLC</em>, <em>12</em>(8), 2389–2405. (<a
href="https://doi.org/10.1007/s13042-021-01319-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dealing with high-dimensional gene expression data is a challenging issue, and it is crucial to select multiple informative subsets of genes for cancer classification. In this regard, many statistical and machine learning methods with regulations have been developed. However, these methods neglected the epistasis, i.e., some genes may cover or affect other genes. In this article, we propose a fuzzy measure with regularization, which adopts L1 and L1/2 norms for sparse solutions, known as FMR, to describe the interaction between genes. Regularization with L1 and L1/2 can obtain a series of sparse solutions which help solving fuzzy measure quicker than traditional methods, such as Genetic Algorithm. FMR obtains a subset of genes corresponding to the fewest nonzero fuzzy measure values, and consequently, selects the important gene(s) according to the frequency of appearance in the selected gene subsets. Besides, three base classifiers, including SVM, KNN and DBN, are employed as underlying models to verify the effectiveness of the selected subset(s) of genes. Experimental results indicate that the selected genes by FMR are consistent with several clinical studies. In addition, it can produce comparable results in terms of accuracy as compared with other methods reported in the literature. The codes used in this article are freely available at: https://github.com/wangphoenix/ICMLC .},
  archive      = {J_IJMLC},
  author       = {Wang, JinFeng and He, ZhenYu and Huang, ShuaiHui and Chen, Hao and Wang, WenZhong and Pourpanah, Farhad},
  doi          = {10.1007/s13042-021-01319-3},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {8},
  pages        = {2389-2405},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Fuzzy measure with regularization for gene selection and cancer prediction},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A novel self-attention deep subspace clustering.
<em>IJMLC</em>, <em>12</em>(8), 2377–2387. (<a
href="https://doi.org/10.1007/s13042-021-01318-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most of the existing deep subspace clustering methods leverage convolutional autoencoders to obtain feature representation for non-linear data points. These methods commonly adopt the structure of a few convolutional layers because stacking many convolutional layers may cause computationally inefficient and optimization difficulties. However, long-range dependencies can hardly be captured when convolutional operations are not repeated enough, thus affect the quality of feature extraction which the performance of deep subspace clustering method highly lies in. To deal with this issue, we propose a novel self-attention deep subspace clustering (SADSC) model, which learns more favorable data representations by introducing self-attention mechanisms into convolutional autoencoders. Specifically, SADSC leverages three convolutional layers and add the self-attention layers after the first and third ones in encoders, then decoders have symmetric structures. The self-attention layers maintain the variable input sizes and can be easily combined with different convolutional layers in autoencoder. Experimental results on the handwritten recognition, face and object clustering datasets demonstrate the advantages of SADSC over the state-of-the-art deep subspace clustering models.},
  archive      = {J_IJMLC},
  author       = {Chen, Zhengfan and Ding, Shifei and Hou, Haiwei},
  doi          = {10.1007/s13042-021-01318-4},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {8},
  pages        = {2377-2387},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A novel self-attention deep subspace clustering},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Machine translation using deep learning for universal
networking language based on their structure. <em>IJMLC</em>,
<em>12</em>(8), 2365–2376. (<a
href="https://doi.org/10.1007/s13042-021-01317-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a deep learning-based machine translation (MT) system that translates a sentence of subject-object-verb (SOV) structured language into subject-verb-object (SVO) structured language. This system uses recurrent neural networks (RNNs) and Encodings. Encode embedded RNNs generate a set of numbers from the input sentence, where the second RNNs generate the output from these sets of numbers. Three popular datasets of SOV structured language i.e., EMILLE corpus, Prothom-Alo corpus and Punjabi Monolingual Text Corpus ILCI-II are used as two different case-study to validate. In our experimental case-study 1, for the EMILLE corpus and Prothom-Alo corpus dataset, we have achieved 0.742, 4.11 and 0.18, respectively as Bilingual Evaluation Understudy (BLEU), NIST (metric) and tertiary entrance rank scores. Another case-study for Punjabi Monolingual Text Corpus ILCI-II dataset achieved a BLEU score of 0.75. Our results can be compared with the state-of-the-art results.},
  archive      = {J_IJMLC},
  author       = {Ali, Md. Nawab Yousuf and Rahman, Md. Lizur and Chaki, Jyotismita and Dey, Nilanjan and Santosh, K. C.},
  doi          = {10.1007/s13042-021-01317-5},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {8},
  pages        = {2365-2376},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Machine translation using deep learning for universal networking language based on their structure},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Model-agnostic multi-stage loss optimization meta learning.
<em>IJMLC</em>, <em>12</em>(8), 2349–2363. (<a
href="https://doi.org/10.1007/s13042-021-01316-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Model Agnostic Meta Learning (MAML) has become the most representative meta learning algorithm to solve few-shot learning problems. This paper mainly discusses MAML framework, focusing on the key problem of solving few-shot learning through meta learning. However, MAML is sensitive to the base model for the inner loop, and training instability occur during the training process, resulting in an increase of the training difficulty of the model in the process of training and verification process, causing degradation of model performance. In order to solve these problems, we propose a multi-stage loss optimization meta-learning algorithm. By discussing a learning mechanism for inner and outer loops, it improves the training stability and accelerates the convergence for the model. The generalization ability of MAML has been enhanced.},
  archive      = {J_IJMLC},
  author       = {Yao, Xiao and Zhu, Jianlong and Huo, Guanying and Xu, Ning and Liu, Xiaofeng and Zhang, Ce},
  doi          = {10.1007/s13042-021-01316-6},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {8},
  pages        = {2349-2363},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Model-agnostic multi-stage loss optimization meta learning},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multipolar fuzzy a-ideals in BCI-algebras. <em>IJMLC</em>,
<em>12</em>(8), 2339–2348. (<a
href="https://doi.org/10.1007/s13042-021-01314-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The notion of an m-polar $$(\in ,$$ $$\in )$$ -fuzzy a-ideal is introduced, and its properties are investigated. The relationship between m-polar fuzzy subalgebra, m-polar fuzzy ideal, and m-polar $$(\in ,$$ $$\in )$$ -fuzzy a-ideal is examined. Conditions for an m-polar fuzzy ideal to be an m-polar $$(\in ,$$ $$\in )$$ -fuzzy a-ideal are provided. The relationship between m-polar $$(\in ,$$ $$\in )$$ -fuzzy p-ideal, m-polar $$(\in ,$$ $$\in )$$ -fuzzy q-ideal, and m-polar $$(\in ,$$ $$\in )$$ -fuzzy a-ideal is shown. The normal m-polar $$(\in ,$$ $$\in )$$ -fuzzy a-ideal is introduced, and its characterizations are considered. Characterizations and extension property of an m-polar $$(\in ,$$ $$\in )$$ -fuzzy a-ideal are discussed.},
  archive      = {J_IJMLC},
  author       = {Borzooei, Rajab Ali and Rezaei, Gholam Reza and Muhiuddin, G. and Jun, Young Bae},
  doi          = {10.1007/s13042-021-01314-8},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {8},
  pages        = {2339-2348},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Multipolar fuzzy a-ideals in BCI-algebras},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Robust adaptive iterative learning control for nonrepetitive
systems with iteration-varying parameters and initial state.
<em>IJMLC</em>, <em>12</em>(8), 2327–2337. (<a
href="https://doi.org/10.1007/s13042-021-01313-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper explores how to construct an adaptive iteration learning control (AILC) mechanism for a class of discrete-time nonrepetitive systems subject to iteration-varying unknown parameters and unidentical initial condition. Firstly, for the linear discrete-time nonrepetitive systems, by minimizing the discrepancy of the real system outputs from the estimated system outputs, a gradient-type adaptation law is designed to estimate the system lower triangular parameter matrix and the system initial state. Especially, the current parametric estimation is updated by virtue of the input-output data and the previous estimation. Secondly, an AILC mechanism is constructed based on the estimated system lower triangular parameter matrix, where the control input algorithm and the adaptation law are scheduled in an interactive mode. Thirdly, the boundedness of the estimation error between the real system matrix and the estimation one is derived by means of vector norm theory. Based on the boundedness of the estimation error, the robust condition of the proposed AILC is given. Finally, the proposed AILC is investigated for a class of nonlinear affine systems and the corresponding results are captured. Simulation results illustrate the validity and effectiveness of the proposed AILC schemes.},
  archive      = {J_IJMLC},
  author       = {Geng, Yan and Ruan, Xiaoe and Zhou, Qinghua and Yang, Xuan},
  doi          = {10.1007/s13042-021-01313-9},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {8},
  pages        = {2327-2337},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Robust adaptive iterative learning control for nonrepetitive systems with iteration-varying parameters and initial state},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Self-questioning dynamical evolutionary game with altruistic
behavior and sharing mechanism in scale-free network. <em>IJMLC</em>,
<em>12</em>(8), 2317–2325. (<a
href="https://doi.org/10.1007/s13042-021-01311-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The spatial evolutionary game is one of the efficient models to explain the emergence and maintenance of cooperation among selfish individuals. In the existing work, the relationship between self-questioning dynamical evolutionary game model and Ising model has been discussed. However, the study on the dividing lines which were used to distinguish entirely cooperative phase, entirely defective phase and cooperative and defective coexistence in the ground state is not enough. That is, the dividing lines were only considered to be suitable for regular networks before. To address this issue, a self-questioning evolutionary game model with altruistic or sharing preference is studied in scale-free Barabási–Albert networks. Using the Ising model theory and Monte Carlo simulation, it is found that the players considering their opponents’ payoffs with probability p are equivalent to the players sharing their payoffs with probability $$p/(1+p)$$ . A further research on the relationship between the self-questioning dynamical evolutionary game model and Ising model shows that the dividing lines are in fact unrelated to network structure, which means that the dividing lines are suitable for arbitrary networks. In addition, the nodes with large degree have higher stability and robustness than those with small degree.},
  archive      = {J_IJMLC},
  author       = {Yang, Bo and Li, Jinhai},
  doi          = {10.1007/s13042-021-01311-x},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {8},
  pages        = {2317-2325},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Self-questioning dynamical evolutionary game with altruistic behavior and sharing mechanism in scale-free network},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Integrate new cross association fuzzy logical relationships
to multi-factor high-order forecasting model of time series.
<em>IJMLC</em>, <em>12</em>(8), 2297–2315. (<a
href="https://doi.org/10.1007/s13042-021-01310-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In any multi-factor high-order fuzzy logical relationship (FLR) based forecasting model, a FLR reflects the influence of both the main factor (the forecasted factor) and all the influence factors on the main factor. Thus, the antecedent of a FLR includes multiple premises related to the main factor as well as all the influence factors. In real time series, there may exist another kind of influence: the cross association influence which is from a part of influence factor(s) on the main factor. To describe such kind of influence, we propose the concept of multi-factor high-order cross association FLRs (CAFLRs). The antecedent of a CAFLR includes some premises related to a part of influence factors. The proposed CAFLRs are divided into two categories: short-cross association FLRs and long-cross association FLRs, which describe the influence on the consequent observation from the premise observations at the closest consecutive moments and the premise observations at the non-closest non-consecutive moments respectively. Based on the concept of CAFLRs, a novel forecasting model is built up. In the proposed model, more FLRs than in the existing models can be mined from historical observations and added to the rule base, which further improve the prediction accuracy by raising the possibility of finding available forecasting FLRs. Superior performance of the proposed model has been verified in the experiments by comparing with Nonlinear Autoregressive Neural Networks, Autoregressive Model, Support Vector Regression and some other FLR based forecasting models.},
  archive      = {J_IJMLC},
  author       = {Li, Fang and Yu, Fusheng and Wang, Xiao and Yang, Xiyang and Liu, Shihu and Liu, Yuming},
  doi          = {10.1007/s13042-021-01310-y},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {8},
  pages        = {2297-2315},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Integrate new cross association fuzzy logical relationships to multi-factor high-order forecasting model of time series},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Imitating targets from all sides: An unsupervised transfer
learning method for person re-identification. <em>IJMLC</em>,
<em>12</em>(8), 2281–2295. (<a
href="https://doi.org/10.1007/s13042-021-01308-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Person re-identification (Re-ID) models usually present a limited performance when they are trained on one dataset and tested on another dataset due to the inter-dataset bias (e.g. completely different identities and backgrounds) and the intra-dataset difference (e.g. camera and pose changes). In other words, the absence of identity labels (who the person is) and pairwise labels (whether a pair of images belongs to the same person or not) leads to failures in unsupervised person Re-ID problem. We argue that synchronous consideration of these two aspects can improve the performance of unsupervised person Re-ID model. In this work, we introduce a Classification and Latent Commonality (CLC) method based on transfer learning for the unsupervised person Re-ID problem. Our method has three characteristics: (1) proposing an imitate model to generate an imitated target domain with estimated identity labels and create a pseudo target domain to compensate the pairwise labels across camera views; (2) formulating a dual classification loss on both the source domain and imitated target domain to learn a discriminative representation and diminish the inter-domain bias; (3) investigating latent commonality and reducing the intra-domain difference by constraining triplet loss on the source domain, imitated target domain and pairwise label target domain (composed of pseudo target domain and target domain). Extensive experiments are conducted on three widely employed benchmarks, including Market-1501, DukeMTMC-reID and MSMT17, and experimental results demonstrate that the proposed method can achieve a competitive performance against other state-of-the-art unsupervised Re-ID approaches.},
  archive      = {J_IJMLC},
  author       = {Tian, Jiajie and Teng, Zhu and Zhang, Baopeng and Wang, Yanxue and Fan, Jianping},
  doi          = {10.1007/s13042-021-01308-6},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {8},
  pages        = {2281-2295},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Imitating targets from all sides: An unsupervised transfer learning method for person re-identification},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Learning number reasoning for numerical table-to-text
generation. <em>IJMLC</em>, <em>12</em>(8), 2269–2280. (<a
href="https://doi.org/10.1007/s13042-021-01305-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although the existing numerical table-to-text generation models have achieved remarkable progress, the idea of generating an accurate analysis of the input table is not well explored. Most existing table-to-text generation algorithms for generating table related information only copy the table record directly but ignore reasoning or calculating over table records. One of the key steps to achieve this ability is number reasoning, which refers to do logical reasoning about the numbers from table records. In this paper, we attempt to improve the number reasoning capability of neural table-to-text generation by generating additional mathematical equations from numerical table records. We propose a neural architecture called Neural Table Reasoning Generator (NTRG), with an additional switching gate as well as a specifically designed equation decoder for generating mathematical equations adaptively. Moreover, we present a pre-training strategy for NTRG similar to the mask language model. Empirical results show that NTRG yields new state-of-the-art results on ROTOWIRE. Furthermore, in order to give a quantitative evaluation of the ability of number reasoning, we construct a sentence-level number reasoning dataset. Results demonstrate the superiority of our approaches over strong baselines.},
  archive      = {J_IJMLC},
  author       = {Feng, Xiaocheng and Gong, Heng and Chen, Yuyu and Sun, Yawei and Qin, Bing and Bi, Wei and Liu, Xiaojiang and Liu, Ting},
  doi          = {10.1007/s13042-021-01305-9},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {8},
  pages        = {2269-2280},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Learning number reasoning for numerical table-to-text generation},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Hierarchical learning recurrent neural networks for 3D
motion synthesis. <em>IJMLC</em>, <em>12</em>(8), 2255–2267. (<a
href="https://doi.org/10.1007/s13042-021-01304-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Three-dimensional human motion synthesis is one of the key technologies in the field of computer animation and multimedia applications. It is well known that the human body&#39;s own motion is full of strong personality, emotion, and high-dimensional characteristics, leading to the automatic synthesis of diverse and lifelike 3D human motion data continues to be a challenging task. Facing the challenge, this paper proposes a human motion synthesis framework based on hierarchical learning recurrent neural networks (HL-RNN). The framework includes a low-level network and a high-level network, which are used to extract the path information of the movement and the spatio-temporal relationship of the human bone structure, respectively. Then, after fusion, motions that satisfy the path constraints could be generated. This method can not only synthesize high-quality human movements that follow a specified trajectory, but also synthesize smooth transitions between various movements, and can also be used to synthesize data of different motion styles. Compared with some latest methods, experiments showed that the proposed method can significantly improve the quality and generalization performance of motion synthesis.},
  archive      = {J_IJMLC},
  author       = {Zhou, Dongsheng and Guo, Chongyang and Liu, Rui and Che, Chao and Yang, Deyun and Zhang, Qiang and Wei, Xiaopeng},
  doi          = {10.1007/s13042-021-01304-w},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {8},
  pages        = {2255-2267},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Hierarchical learning recurrent neural networks for 3D motion synthesis},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Stochastic gradient support vector machine with local
structural information for pattern recognition. <em>IJMLC</em>,
<em>12</em>(8), 2237–2254. (<a
href="https://doi.org/10.1007/s13042-021-01303-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Structural information is very important for improving the classification performance of classifiers. In order to increase the generalization performance of support vector machine (SVM) directly, several kinds of structured SVMs have been proposed. These algorithms with structural information only simply embed the global structural information or the local within-class information into SVM model. Thus, they sometimes are not suitable for real-world problems. To overcome the drawbacks, we firstly propose a novel SVM with local structural information (LSI-SVM) in this paper. In the LSI-SVM, the K-nearest neighbor (KNN) method is adopted. Applying the KNN method, the farthest neighbors set intra-class and the nearest neighbors set inter-class of the overall samples are obtained. It is more reasonable to maximize the margin between the nearest neighbors and the farthest neighbors. Both the global and local data structures are added into the optimization problem, making the LSI-SVM can fully utilize the underlying structural information and yield better performance. Furthermore, for nonlinear classification, the reproducing kernel Hilbert space theory is introduced and the kernel-based LSI-SVM is generated. What’s more, in order to accelerate the training speed of LSI-SVM, a stochastic gradient LSI-SVM (LSI-SVM +) is constructed using the stochastic gradient descent (SGD) solver. Lastly, experimental results on regular-scale datasets, steel surface defects datasets, ORL face dataset and large-scale datasets demonstrate that both LSI-SVM and LSI-SVM + outperform other state-of-the-art algorithms on accuracy. In the meanwhile, our LSI-SVM + has high efficiency.},
  archive      = {J_IJMLC},
  author       = {Liu, Liming and Li, Ping and Chu, Maoxiang and Cai, Hongbin},
  doi          = {10.1007/s13042-021-01303-x},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {8},
  pages        = {2237-2254},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Stochastic gradient support vector machine with local structural information for pattern recognition},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). DEP-TSPmeta: A multiple criteria dynamic ensemble pruning
technique ad-hoc for time series prediction. <em>IJMLC</em>,
<em>12</em>(8), 2213–2236. (<a
href="https://doi.org/10.1007/s13042-021-01302-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time series prediction (TSP) is a process of using data collected at different times in the past for statistical analysis, so as to speculate on the trend of things, where the non-stationary and non-linear characteristics of data portray a hard setting for predictive tasks. Obviously, there will be no single model that could perform the best for all TSP issues. Dynamic Ensemble Selection (DES) technique achieves more accurate and robust performance than a single model, due to that it aims to select an ensemble of the most competent models in a dynamic fashion according to each test sample. A variety of DES approaches have been proposed to address pattern classification problems, but little work has been conducted on the research of TSP adopting the DES paradigm. Commonly, the DES approaches work by the definition of a single criterion to evaluate the capability of base classifiers. However, only one criterion is often inadequate for the comprehensive evaluation of classifier power. Thus, in this paper, a multiple criteria Dynamic Ensemble Pruning (DEP) technique exploiting meta-learning ad-hoc for TSP, termed DEP-TSPmeta, based on the inspiration from a state-of-the-art META-DES framework specifically presented for classification tasks, is developed. Within DEP-TSPmeta, Extreme Learning Machines (ELMs) and Hierarchical Extreme Learning Machines (H-ELMs) are integrated as the base models, and four distinct meta-attributes collections, i.e., hard prediction, local accuracy, global accuracy, and prediction confidence, are presented. Each set of meta-attributes corresponds to a specific assessment criterion, i.e., the prediction accuracy in local area of the eigenspace, the overall local accuracy, the prediction accuracy in global area of the decision space, and the confidence level of predictor. A desirable meta-predictor, obtained by training on the strength of these meta-attributes, is the key to deciding whether a base predictor is capable of predicting the unseen instance well or not. Those incapable base predictors determined by the meta-predictor will be pruned and the capable predictors will be expanded into the final dynamic ensemble system. The size of the sets of meta-attributes is specified dynamically by genetic algorithm for different time series benchmark datasets. Empirical results on eight benchmark datasets with different time granularities have verified that, the proposed DEP-TSPmeta algorithm possesses dramatically improved prediction performance at different granularities, when compared against three other DES approaches and four static selective ensemble learning methods.},
  archive      = {J_IJMLC},
  author       = {Zhang, Jing and Dai, Qun and Yao, Changsheng},
  doi          = {10.1007/s13042-021-01302-y},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {8},
  pages        = {2213-2236},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {DEP-TSPmeta: A multiple criteria dynamic ensemble pruning technique ad-hoc for time series prediction},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A two-stage temporal proposal network for precise action
localization in untrimmed video. <em>IJMLC</em>, <em>12</em>(8),
2199–2211. (<a
href="https://doi.org/10.1007/s13042-021-01301-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a two-stage temporal proposal algorithm for the action detection task of long untrimmed videos. In the first stage, we propose a novel prior-minor watershed algorithm for action proposals with precise prior watershed proposal algorithm and minor supplementary sliding window algorithm. Here, we propose the correctness discriminator to fill the proposals that watershed proposal algorithm may omit with the sliding window proposals. In the second stage, an extended context pooling (ECP) is firstly proposed with two modules (internal and context). The context information module of ECP can structure the proposals and enhance the extended features of action proposals. Different level of ECP is introduced to model the action proposal region and make its extended context region more targeted and precise. Then, we propose a temporal context regression network, which adopts a multi-task loss to realize the training of the temporal coordinate regression and the action/background classification simultaneously, and outputs the precise temporal boundaries of the proposals. Here, we also propose prior-minor ranking to balance the effect of the prior watershed proposals and the minor supplementary proposals. On three large scale benchmarks THUMOS14, ActivityNet (v1.2 and v1.3), and Charades, our approach achieves superior performances compared with other state-of-the-art methods and runs over 1020 frames per second (fps) on a single NVIDIA Titan-X Pascal GPU, indicating that our method can efficiently improve the precision of action localization task.},
  archive      = {J_IJMLC},
  author       = {Wang, Fei and Wang, Guorui and Du, Yuxuan and He, Zhenquan and Jiang, Yong},
  doi          = {10.1007/s13042-021-01301-z},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {8},
  pages        = {2199-2211},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A two-stage temporal proposal network for precise action localization in untrimmed video},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Online domain description of big data based on
hyperellipsoid models. <em>IJMLC</em>, <em>12</em>(8), 2185–2197. (<a
href="https://doi.org/10.1007/s13042-021-01300-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Big data is usually massive, diverse, time-varying, and high-dimensional. The focus of this paper is on the domain description of big data, which is the basis for solving the above problems. This paper has three main contributions. Firstly, one hyperellipsoid model is proposed to analyze domain description of big data. The parameters of the hyperellipsoid model can be adaptively adjusted according to the proposed objective function without relying on manual parameter selection, which expands the application range of the model. Secondly, an improved FDPC algorithm is proposed to generate multiple hyperellipsoid models to approximate the spatial distribution of big data, thus improving the accuracy of domain description. Multiple hyperellipsoid models can not only greatly eliminate the spatial redundancy of the domain description based on one hyperellipsoid model, but also provide a feasible method for describing complex spatial distribution. Thirdly, an online domain description algorithm based on hyperellipsoid models is proposed, which improves the robustness of hyperellipsoid models on time-varying data. The parallel processing flow of the algorithm is given. In the experiment, synthetic instances and real-world datasets were applied to test the performance of hyperellipsoid models. By comparing LOF, OneClassSVM, SVDD and isolation forest, the performance of the proposed method is competitive and promising.},
  archive      = {J_IJMLC},
  author       = {Qiu, Zengshuai},
  doi          = {10.1007/s13042-021-01300-0},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {8},
  pages        = {2185-2197},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Online domain description of big data based on hyperellipsoid models},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Probabilistic reliable linguistic term sets applied to
investment project selection with the gained and lost dominance score
method. <em>IJMLC</em>, <em>12</em>(8), 2163–2183. (<a
href="https://doi.org/10.1007/s13042-021-01299-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Probabilistic linguistic term sets (PLTSs) are an effective tool in keeping with the habits of decision makers (DMs). However, in multi-criteria group decision making (MCGDM) problems, it is necessary to deal with the information reliability problem because of the difference of the DMs’ knowledge backgrounds and knowledge structures. Therefore, this paper proposes a novel concept called probabilistic reliable linguistic term sets. Based on which, some basic operations, comparison laws, distance measures, similarity measures and aggregation operators are defined. After that, we propose the probabilistic reliable linguistic gained and lost dominance score method to cope with MCGDM problems, and we further apply the proposed method to solve an investment project selection problem about lucky bag machine. Finally, we make some comparative analyses to verify the effectiveness and highlight the strength of the proposed method compared with four methods, i.e., the aggregation-based method, the TOPSIS method under probabilistic reliable linguistic environment, the gained and lost dominance score (GLDS) method with probabilistic linguistic information and the GLDS method with hesitant linguistic information.},
  archive      = {J_IJMLC},
  author       = {Hong, Nan and Wang, Xinxin and Xu, Zeshui},
  doi          = {10.1007/s13042-021-01299-4},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {8},
  pages        = {2163-2183},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Probabilistic reliable linguistic term sets applied to investment project selection with the gained and lost dominance score method},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Machine learning based air traffic control strategy.
<em>IJMLC</em>, <em>12</em>(7), 2151–2161. (<a
href="https://doi.org/10.1007/s13042-012-0096-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Development of an absolute, secure and reliable air traffic control (ATC) has become a challenging problem due to its inherited complexity, emergence of new technologies and growth of airways in the airspace. Accordingly, safe and secure ATC system is mandatory as its failure or erroneous performance might cause serious consequences. In this paper, formal analysis of major components of ATC system and its safety properties is presented to prevent collision of aircrafts in the airspace. A step by step model is proposed to analyze the system and safety properties reducing complexity of the system using graph theory and Z notation. Initially, a network model of airspace for traffic flow management is presented. Then aircrafts with on-board system and ground-based controls are defined. For safety analysis, it is supposed that existence of two aircrafts in a smallest unit, block of airspace, is a collision. The issue of air crossing that is approaching two aircrafts to same point is also addressed. Based on these definitions abstract safety properties are defined by introducing a notion of protected area of an aircraft in front of it. Further, the safety properties are analyzed and extended by introduction of computer based air traffic controls. The formal specification is analyzed and validated using Z/Eves tool.},
  archive      = {J_IJMLC},
  author       = {Rehman, Amjad},
  doi          = {10.1007/s13042-012-0096-6},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {7},
  pages        = {2151-2161},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Machine learning based air traffic control strategy},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A comparative experimental evaluation on performance of
type-1 and interval type-2 takagi-sugeno fuzzy models. <em>IJMLC</em>,
<em>12</em>(7), 2135–2150. (<a
href="https://doi.org/10.1007/s13042-021-01298-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the literature, there have been numerous studies demonstrating experimentally that type-2 fuzzy models outperform their type-1 counterparts. Although the advantages of these models seem to be well justified, the quantification of the improvements is not carefully evaluated and critically assessed in the existing studies. A thorough multi-objective experimental numeric evaluation of benefits of type-2 fuzzy models is still lacking. In this study, a numeric evaluation of the performance of type-1 and type-2 fuzzy models is carried out in terms of the criteria of accuracy and computing overhead, which leads to a thorough analysis of existing trade-offs between these two performance indexes. In the proposed numeric evaluation, type-2 fuzzy models are evaluated against their associated type-1 counterparts (the type-2 associated type-1 models sharing similar structure and the same development method). Three architectures of fuzzy models are involved in the comparative studies presented here: (1) fuzzy clustering method-based Takagi-Sugeno (TS) fuzzy models (Fuzzy C-Means based type-1, Fuzzy C-Means based interval type-2); (2) static TS-based fuzzy models (static type-1, A2C0, A2C1, EKFT2 and their associated type-1 models) and (3) evolving TS fuzzy models (SEIT2 and its associated type-1 counterpart, SCIT2 and its associated type-1 model). The experiments are carried out by involving 15 publicly available datasets. The accuracy of these two types of fuzzy models is assessed vis-a-vis their development time. Testing is involved to evaluate whether there are statistically significant differences between the performance of the type-2 and type-1 fuzzy models.},
  archive      = {J_IJMLC},
  author       = {Yuan, Kehua and Li, Wentao and Xu, Weihua and Zhan, Tao and Zhang, Libo and Liu, Shuai},
  doi          = {10.1007/s13042-021-01298-5},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {7},
  pages        = {2135-2150},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A comparative experimental evaluation on performance of type-1 and interval type-2 takagi-sugeno fuzzy models},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). One-step multi-view spectral clustering by learning common
and specific nonnegative embeddings. <em>IJMLC</em>, <em>12</em>(7),
2121–2134. (<a
href="https://doi.org/10.1007/s13042-021-01297-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view spectral clustering is a hot research area which has attracted increasing attention. Most existing multi-view spectral clustering methods utilize a two-step strategy. The first step obtains a common embedding by fusing spectral embeddings of different views, and the second step conducts hard clustering, such as K-means or spectral rotation, on the common embedding. Because the goal of the first step is not obtaining optimal clustering result, and the requirement to post-processing makes the final clustering result uncertain. In this paper, we propose a novel one-step multi-view spectral clustering method, in which the spectral embedding and nonnegative embedding are unified into one framework. Therefore, our method can avoid the uncertainty brought by post-processing and obtain optimal clustering result. Moreover, the nonnegative embedding is divided into two parts. The common nonnegative embedding indicates the shared cluster structure, and the specific nonnegative embedding indicates the exclusive cluster structure of each view. Hence, our method can well tackle with noises and outliers of different views. Furthermore, an alternating iterative algorithm is used to solve the joint optimization problem. Extensive experimental results on four real-world datasets have demonstrated the effectiveness of the proposed method.},
  archive      = {J_IJMLC},
  author       = {Yin, Hongwei and Hu, Wenjun and Li, Fanzhang and Lou, Jungang},
  doi          = {10.1007/s13042-021-01297-6},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {7},
  pages        = {2121-2134},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {One-step multi-view spectral clustering by learning common and specific nonnegative embeddings},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Cooperative representation of multiscale patch face
recognition based on fuzzy decision. <em>IJMLC</em>, <em>12</em>(7),
2109–2119. (<a
href="https://doi.org/10.1007/s13042-021-01296-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The machine learning of small sample size is one of the most challenging problems in face recognition. Multiscale patch cooperative representation for face recognition provides multiple patch scales to a sample set. In each patch scale, all samples in the training set and test set are segmented into patches of the same size, followed by a collaborative representation classification. A sample belongs to the category in which the number of patch blocks is the highest. Under a single scale, however, the patch blocks of a sample often belong to different categories. If the decision value of the sample is defined as the category with the largest number of patches, the possibility of the sample belonging to other categories is often disregarded; this will then significantly reduce the recognition accuracy. Therefore, a multiscale patched collaborative representation based on fuzzy decision is proposed herein. In a single scale, among all the patch blocks in a sample, the proportion of patch blocks belonging to a category to the total patch blocks is used to represent the degree of a sample belonging to the category. Hence, a fuzzy decision matrix can be obtained for a sample set in each scale. The elements of the decision matrix represent the possibility of samples belonging to categories, thereby solving the absolute problem of classification. Corresponding weights are applied to the patch scales, and multiscale outputs can be integrated by regularizing boundary distribution optimization. It is experimentally demonstrated that the proposed method exhibits high recognition accuracy and is superior to some existing algorithms.},
  archive      = {J_IJMLC},
  author       = {Pei, Shibing and Wang, Changzhong and Fan, Xiaodong and Zhu, Pengfeng},
  doi          = {10.1007/s13042-021-01296-7},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {7},
  pages        = {2109-2119},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Cooperative representation of multiscale patch face recognition based on fuzzy decision},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). L-fuzzy rough automaton: A mathematical model for natural
languages. <em>IJMLC</em>, <em>12</em>(7), 2091–2107. (<a
href="https://doi.org/10.1007/s13042-021-01294-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is to study a mathematical model of computation for natural languages. Specifically, we enrich the L-fuzzy automata theory by using the concepts from L-fuzzy rough set theory so that new model, namely, L-fuzzy rough automata can handle both the concepts such as ambiguity and impreciseness arise in natural languages. Further, we study the determinization of an L-fuzzy rough automaton and introduce the concept of a factor L-fuzzy rough automaton. Also, we study some properties of L-fuzzy languages accepted by introduced concepts of L-fuzzy rough automata. Finally, we provide an application of the L-fuzzy rough automaton in a real-life problem.},
  archive      = {J_IJMLC},
  author       = {Pal, Priyanka and Tiwari, S. P. and Singh, Shailendra},
  doi          = {10.1007/s13042-021-01294-9},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {7},
  pages        = {2091-2107},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {L-fuzzy rough automaton: A mathematical model for natural languages},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A rough set based algorithm for updating the modes in
categorical clustering. <em>IJMLC</em>, <em>12</em>(7), 2069–2090. (<a
href="https://doi.org/10.1007/s13042-021-01293-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The categorical clustering problem has attracted much attention especially in the last decades since many real world applications produce categorical data. The k-mode algorithm, proposed since 1998, and its multiple variants were widely used in this context. However, they suffer from a great limitation related to the update of the modes in each iteration. The mode in the last step of these algorithms is randomly selected although it is possible to identify many candidate ones. In this paper, a rough density mode selection method is proposed to identify the adequate modes among a list of candidate ones in each iteration of the k-modes. The proposed method, called Density Rough k-Modes (DRk-M) was experimented using real world datasets extracted from the UCI Machine Learning Repository, the Global Terrorism Database (GTD) and a set of collected Tweets. The DRk-M was also compared to many states of the art clustering methods and has shown great efficiency.},
  archive      = {J_IJMLC},
  author       = {Salem, Semeh Ben and Naouali, Sami and Chtourou, Zied},
  doi          = {10.1007/s13042-021-01293-w},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {7},
  pages        = {2069-2090},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A rough set based algorithm for updating the modes in categorical clustering},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Uncertain two-echelon green supply chain models based on
revenue sharing contract. <em>IJMLC</em>, <em>12</em>(7), 2059–2068. (<a
href="https://doi.org/10.1007/s13042-021-01292-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the present paper, we consider a two-echelon supply chain problem including a manufacturer selling green products to a retailer, and then selling to customers. The market base, customer demand, production cost, and sensitivity to price are recognized as uncertain variables due to the influence of many human factors in reality. The aim is to maximize the entire profit of the supply chain, improve the greening level of products, and solve the contradiction between economic growth, resource protection and ecological environment. Retailer-led and bargaining expected value game models with revenue sharing contract are established. The market demand is affected by retail price and greening level. The revenue sharing contract and its parameters are designed to achieve perfect coordination of the established supply chain models. Some inferences about the optimal decision variables are obtained. Finally, numerical experiments suggest that the revenue sharing contract raises the greening level and reduces the retail price significantly compared to the decentralized decision model.},
  archive      = {J_IJMLC},
  author       = {Shen, Jiayu},
  doi          = {10.1007/s13042-021-01292-x},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {7},
  pages        = {2059-2068},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Uncertain two-echelon green supply chain models based on revenue sharing contract},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A novel binary many-objective feature selection algorithm
for multi-label data classification. <em>IJMLC</em>, <em>12</em>(7),
2041–2057. (<a
href="https://doi.org/10.1007/s13042-021-01291-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For Multi-label classification, redundant and irrelevant features degrade the performance of classification. To select the best features based on several conflicting objectives, feature selection can be modeled as a large-scale optimization problem. However, most existing multi-objective feature selection methods select the features based on minimizing two well-known objectives, the number of features and classification error, additional objectives can be considered to improve the classification performance. In this study, for the first time, a many-objective optimization method is proposed to select the efficient features for multi-label classification based on not only two mentioned objectives, but also maximizing the correlation between features and labels and minimizing the computational complexity of features. Maximizing the correlation could lead to increasing the accuracy of classification. On the other hand, selecting less complex features decreases the computational complexity of feature extraction phase. The most important aim of this paper is to tackle the multi-label feature selection based on the number of features, classification error, correlation between features and labels, and computational complexity of features, simultaneously. The conducted many-objective feature selection problem is solved using a proposed binary version of NSGA-III algorithm. The binary operator improves the exploration power of optimizer to search the large-scale space. In order to evaluate the proposed algorithm (called binary NSGA-III), a benchmarking experiments is conducted on eight multi-label datasets in terms of several multi-objective assessment metrics, including Hypervolume indicator, Pure Diversity, and Set-coverage. Experimental results show significant improvements for proposed method in comparison with other algorithms.},
  archive      = {J_IJMLC},
  author       = {Asilian Bidgoli, Azam and Ebrahimpour-komleh, Hossein and Rahnamayan, Shahryar},
  doi          = {10.1007/s13042-021-01291-y},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {7},
  pages        = {2041-2057},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A novel binary many-objective feature selection algorithm for multi-label data classification},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Symmetrical filters in convolutional neural networks.
<em>IJMLC</em>, <em>12</em>(7), 2027–2039. (<a
href="https://doi.org/10.1007/s13042-021-01290-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Symmetry is present in nature and science. In image processing, kernels for spatial filtering possess some symmetry (e.g. Sobel operators, Gaussian, Laplacian). Convolutional layers in artificial feed-forward neural networks have typically considered the kernel weights without any constraint. We propose to investigate the impact of a symmetry constraint in convolutional layers for image classification tasks, taking our inspiration from the processes involved in the primary visual cortex and common image processing techniques. The goal is to determine if it is necessary to learn each weight of the filters independently, and the extent to which it is possible to enforce symmetrical constraints on the filters throughout the training process of a convolutional neural network by modifying the weight update preformed during the backpropagation algorithm and to evaluate the change in performance. The symmetrical constraint reduces the number of free parameters in the network, and it is able to achieve near identical performance. We address the following cases: x/y-axis symmetry, point reflection, and anti-point reflection. The performance is evaluated on four databases of images representing handwritten digits. The results support the conclusion that while random weights offer more freedom to the model, the symmetry constraint provides a similar level of performance while decreasing substantially the number of free parameters in the model. Such an approach can be valuable in phase-sensitive applications that require a linear phase property throughout the feature extraction process.},
  archive      = {J_IJMLC},
  author       = {Dzhezyan, Gregory and Cecotti, Hubert},
  doi          = {10.1007/s13042-021-01290-z},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {7},
  pages        = {2027-2039},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Symmetrical filters in convolutional neural networks},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Distance, similarity and entropy measures of dynamic
interval-valued neutrosophic soft sets and their application in decision
making. <em>IJMLC</em>, <em>12</em>(7), 2007–2025. (<a
href="https://doi.org/10.1007/s13042-021-01289-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we introduce the notion of dynamic interval-valued neutrosophic soft sets (DIVNSSs) by embedding the time factor to interval-valued neutrosophic soft sets (IVNSSs). We also present some related set theoretic operations, such as complement, union, intersection, and-product, and or-product. Then, we propose the information measures of DIVNSSs, including the distance, similarity, and entropy measures. And we develop three corresponding decision making methods. In the decision making process, we employ a nonlinear programming model to weight every single time objectively, considering that the importance degrees of every single time are quite different. Further, we put forward a dynamic interval-valued neutrosophic soft aggregation rule to combine the parameter weights evaluated by all experts under every single time. Moreover, we give a numerical example to display the application of the proposed methods in decision making. Finally, we present a sensitivity analysis of the parameter time-degree and a comparative analysis with the methods of IVNSSs and interval-valued neutrosophic sets (IVNSs). The results show the effectiveness and superiority of the proposed method in solving the problem with dynamic inconsistent information.},
  archive      = {J_IJMLC},
  author       = {Dong, Yuanxiang and Cheng, Xiaoting and Hou, Chenjing and Chen, Weijie and Shi, Hongbo and Gong, Ke},
  doi          = {10.1007/s13042-021-01289-6},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {7},
  pages        = {2007-2025},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Distance, similarity and entropy measures of dynamic interval-valued neutrosophic soft sets and their application in decision making},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). DLSA: Dual-learning based on self-attention for rating
prediction. <em>IJMLC</em>, <em>12</em>(7), 1993–2005. (<a
href="https://doi.org/10.1007/s13042-021-01288-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Latent factor models (LFMs) have been widely applied in many rating recommendation systems because of their prediction rating capability. Nevertheless, LFMs may not fully leverage rating information and lack good recommendation performance. Furthermore, many subsequent works have often used auxiliary text information, such as user attributes, to improve the prediction effect. However, they did not fully utilize implicit information (i.e., users’ preferences, items’ common features), and additional information is sometimes difficult to acquire. In this paper, we propose a new framework, named dual-learning based on self-attention for rating prediction (DLSA), to solve these problems. Self-attention has a proven ability to learn implicit information about sentences in machine translation, which can be used to mine implicit information in recommendation systems. Additionally, dual learning has shown that the model can generate feedback information when it learns from unlabeled data; therefore, we were inspired to use it in recommendation and obtain implicit information feedback. From the user’s perspective, we design a user self-attention model to learn user-user implicit information and create an interactive user-item self-attention mechanism to learn user-item information. We can also obtain item self-attention to utilize item-item information and an item-user self-attention model to acquire item-user information from an item’s perspective. The interactive structure of the user-item and item-user can adopt the dual learning mechanism to learn implicit information feedback. Moreover, no auxiliary text information was used in the process. The proposed model combines the power of self-attention for implicit information and dual learning for information feedback in a new neural network architecture. Experiments on several real-world datasets demonstrate the effectiveness of DLSA over competitive algorithms on rating recommendation.},
  archive      = {J_IJMLC},
  author       = {Qian, Fulan and Huang, Yafan and Li, Jianhong and Wang, Chengjun and Zhao, Shu and Zhang, Yanping},
  doi          = {10.1007/s13042-021-01288-7},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {7},
  pages        = {1993-2005},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {DLSA: Dual-learning based on self-attention for rating prediction},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Cancer cells population control in a delayed-model of a
leukemic patient using the combination of the eligibility traces
algorithm and neural networks. <em>IJMLC</em>, <em>12</em>(7),
1973–1992. (<a
href="https://doi.org/10.1007/s13042-021-01287-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The main purpose of this paper is to provide a solution, through which one can efficiently reduce the population of cancer cells by injecting the lowest dose of the drug; therefore, reducing the side effects of the drug on healthy cells. In this paper, a mathematical model of stem Chronic Myelogenous Leukemia (CML) is used. To this aim, a hybrid method is used, that is a combination of the Eligibility Traces algorithm and Neural Networks. The eligibility traces algorithm is one of the well-known methods for solving problems under the Reinforcement Learning (RL) approach. The reason is that the population of cancer cells can be controlled with a higher accuracy and will have a significant impact on dosage of injection. The eligibility traces algorithm has the advantage of backward view, meaning it will investigate previous states, as well. That will result in improving the learning procedure, speed of reduction in cancer cells population and the total dosage of the injected drug during the treatment period, in patients with CML. Combination of the mentioned method and neural networks has provided continuous states in the considered problem. Hence, there will be no limitation for considering all possible states for solving the problem. Moreover, this can accelerate obtaining the optimal dosage with a high accuracy, which is a significant advantage of the proposed method. To show the effectiveness of the proposed method to control the population of cancer cells and obtaining the optimal dosage, it is compared with four different cases: when only the eligibility traces algorithm is employed, in the case only the Q-learning algorithm is used, when the Optimal Control is applied and in the case no dosage is injected. Finally, it is revealed that the combinatory method of the eligibility traces algorithm and neural networks can control the population of cancer cells more quickly, with a higher accuracy as well as applying a lower dosage of the drug.},
  archive      = {J_IJMLC},
  author       = {Kalhor, Elnaz and Noori, Amin and Noori, Ghazaleh},
  doi          = {10.1007/s13042-021-01287-8},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {7},
  pages        = {1973-1992},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Cancer cells population control in a delayed-model of a leukemic patient using the combination of the eligibility traces algorithm and neural networks},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An adaptive neuro-fuzzy backstepping sliding mode controller
for finite time stabilization of fractional-order uncertain chaotic
systems with time-varying delays. <em>IJMLC</em>, <em>12</em>(7),
1949–1971. (<a
href="https://doi.org/10.1007/s13042-021-01286-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the design of a fractional-order hyperbolic adaptive neuro-fuzzy backstepping sliding mode controller (HANFBSMC) has been addressed for a class of fractional-order chaotic systems with time-varying delays in their states, control inputs, disturbances and uncertainties. In the proposed controller, adaptive rules are used both in a neuro-fuzzy estimator to estimate the unknown system dynamics, and in updating uncertainty bounds of system. The robust part of the proposed hybrid controller includes backstepping sliding mode controller, in which, the hyperbolic tangential fractional-order sliding surfaces are employed to prevent large tracking errors. Employing backstepping control strategy also extends the flexibility of controller to deal with higher order systems and under more extensive design issues. Adaptive rules based on Lyapunov stability analysis are also employed for tuning of relating robust control parameters according to the estimated upper bounds of the uncertainties. Analysis of stability of this controller has been performed via Lyapunov–Krasovskii theorem and Barbalat&#39;s lemma. Besides, finite time reaching to sliding surfaces has been proved. Finally, out performance of the proposed controller has been reflected via stabilization of a fractional-order hyper-chaotic system with time varying delays in its states as well as fractional-order Chen system with time delay in its inputs and states, where both systems experience unknown uncertainties and disturbances.},
  archive      = {J_IJMLC},
  author       = {Dalir, Mehdi and Bigdeli, Nooshin},
  doi          = {10.1007/s13042-021-01286-9},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {7},
  pages        = {1949-1971},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {An adaptive neuro-fuzzy backstepping sliding mode controller for finite time stabilization of fractional-order uncertain chaotic systems with time-varying delays},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A PSO-based deep learning approach to classifying patients
from emergency departments. <em>IJMLC</em>, <em>12</em>(7), 1939–1948.
(<a href="https://doi.org/10.1007/s13042-021-01285-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a deep belief network (DBN) is employed to deal with the problem of the patient attendance disposal in accident &amp; emergency (A&amp;E) departments. The selection of the hyperparameters of the employed DBN is automated by using the particle swarm optimization (PSO) algorithm that is known for its simplicity, easy implementation and relatively fast convergence rate to a satisfactory solution. Specifically, a recently developed randomly occurring distributedly delayed PSO (RODDPSO) algorithm, which is capable of seeking the optimal solution and alleviating the premature convergence, is exploited with aim to optimize the hyperparameters of the DBN. The developed RODDPSO-based DBN is successfully applied to analyze the A&amp;E data for classifying the patient attendance disposal in the A&amp;E department of a hospital in west London. Experimental results show that the proposed RODDPSO-based DBN outperforms the standard DBN and the modified DBN in terms of the classification accuracy.},
  archive      = {J_IJMLC},
  author       = {Liu, Weibo and Wang, Zidong and Zeng, Nianyin and Alsaadi, Fuad E. and Liu, Xiaohui},
  doi          = {10.1007/s13042-021-01285-w},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {7},
  pages        = {1939-1948},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A PSO-based deep learning approach to classifying patients from emergency departments},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Density peaks clustering based on k-nearest neighbors and
self-recommendation. <em>IJMLC</em>, <em>12</em>(7), 1913–1938. (<a
href="https://doi.org/10.1007/s13042-021-01284-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Density peaks clustering (DPC) model focuses on searching density peaks and clustering data with arbitrary shapes for machine learning. However, it is difficult for DPC to select a cut-off distance in the calculation of a local density of points, and DPC easily ignores the cluster centers with lower density in datasets with variable densities. In addition, for clusters with complex shapes, DPC selects only one cluster center for a cluster, meaning that the structure of the whole cluster is not fully reflected. To overcome these drawbacks, this paper presents a novel DPC model that merges microclusters based on k-nearest neighbors (kNN) and self-recommendation, called DPC-MC for short. First, the kNN-based neighbourhood of point is defined and the mutual neighbour degree of point is presented in this neighbourhood, and then a new local density based on the mutual neighbour degree is proposed. This local density does not need to set the cut-off distance manually. Second, to address the artificial setting of cluster centers, a self-recommendation strategy for local centers is provided. Third, after the selection of multiple local centers, the binding degree of microclusters is developed to quantify the combination degree between a microcluster and its neighbour clusters. After that, homogeneous clusters are found according to the binding degree of microclusters during the process of deleting boundary points layer by layer. The homologous clusters are merged, the points in the abnormal clusters are reallocated, and then the clustering process ends. Finally, the DPC-MC algorithm is designed, and nine synthetic datasets and twenty-seven real-world datasets are used to verify the effectiveness of our algorithm. The experimental results demonstrate that the presented algorithm outperforms other compared algorithms in terms of several evaluation metrics for clustering.},
  archive      = {J_IJMLC},
  author       = {Sun, Lin and Qin, Xiaoying and Ding, Weiping and Xu, Jiucheng and Zhang, Shiguang},
  doi          = {10.1007/s13042-021-01284-x},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {7},
  pages        = {1913-1938},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Density peaks clustering based on k-nearest neighbors and self-recommendation},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Remaining useful life prediction of integrated modular
avionics using ensemble enhanced online sequential parallel extreme
learning machine. <em>IJMLC</em>, <em>12</em>(7), 1893–1911. (<a
href="https://doi.org/10.1007/s13042-021-01283-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Integrated modular avionics is the core system of modern aircraft, which hosts almost all kinds of electrical functions. The performance of integrated modular avionics has an immediate influence on flight mission. Remaining useful life prediction is an effective manner to guarantee the safety and reliability of airplane. To satisfy the real-time requirement of integrated modular avionics, the prediction algorithm should have fast learning speed. This paper proposes an ensemble enhanced online sequential parallel extreme learning machine to predict the remaining useful life of integrated modular avionics. Firstly, a network with parallel hidden layers is designed to improve feature extraction. Secondly, to enhance the learning stability, the input weights of the network are determined by using extreme learning machine autoencoder. Thirdly, an updating method is developed for online prediction and an adaptive weight is designed to construct the ensemble online sequential prediction method. The effectiveness and superiority of the proposed method are verified through the standard datasets. Finally, this paper regards intermittent faults as the feature of integrated modular avionics and builds a degradation model by using Lévy Process. The proposed method is applied to remaining useful life prediction of integrated modular avionics.},
  archive      = {J_IJMLC},
  author       = {Zehai, Gao and Cunbao, Ma and Jianfeng, Zhang and Weijun, Xu},
  doi          = {10.1007/s13042-021-01283-y},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {7},
  pages        = {1893-1911},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Remaining useful life prediction of integrated modular avionics using ensemble enhanced online sequential parallel extreme learning machine},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An efficiency-enhanced deep learning model for citywide
crowd flows prediction. <em>IJMLC</em>, <em>12</em>(7), 1879–1891. (<a
href="https://doi.org/10.1007/s13042-021-01282-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The crowd flows prediction plays an important role in urban planning management and urban public safety. Accuracy is a challenge for predicting the flow of crowds in a region. On the one hand, crowd flow is influenced by many factors such as holidays and weather. On the other hand, sample data about crowd flows are generally high-dimensional, which not only has a negative impact on the prediction accuracy but also increases computational complexity. In this paper, an efficiency-enhanced model is constructed for predicting citywide crowd flows based on multi-source data using deep learning techniques. Specifically, a data reconstruction mechanism is built with Bernoulli restricted Boltzmann machine (BRBM), for the purpose of reducing the dimension of sample data. A collaborative prediction mechanism is introduced to improve the prediction accuracy of crowd flows, in which a spatio-temporal data oriented prediction model is constructed based on bottleneck residual network that can reduce the effectively computational complexity of model training, and an auxiliary prediction to further optimize the prediction accuracy based on the fully-connected network. The proposed method is evaluated by using two open datasets. The experimental results show that our method can significantly improve the prediction accuracy and reduce the training time of the prediction model, compared with other methods.},
  archive      = {J_IJMLC},
  author       = {Zhai, Zhongyi and Liu, Peipei and Zhao, Lingzhong and Qian, Junyan and Cheng, Bo},
  doi          = {10.1007/s13042-021-01282-z},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {7},
  pages        = {1879-1891},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {An efficiency-enhanced deep learning model for citywide crowd flows prediction},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Universal consistency of twin support vector machines.
<em>IJMLC</em>, <em>12</em>(7), 1867–1877. (<a
href="https://doi.org/10.1007/s13042-021-01281-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A classification problem aims at constructing a best classifier with the smallest risk. When the sample size approaches infinity, the learning algorithms for a classification problem are characterized by an asymptotical property, i.e., universal consistency. It plays a crucial role in measuring the construction of classification rules. A universal consistent algorithm ensures that the larger the sample size of the algorithm is, the more accurately the distribution of the samples could be reconstructed. Support vector machines (SVMs) are regarded as one of the most important models in binary classification problems. How to effectively extend SVMs to twin support vector machines (TWSVMs) so as to improve performance of classification has gained increasing interest in many research areas recently. Many variants for TWSVMs have been proposed and used in practice. Thus in this paper, we focus on the universal consistency of TWSVMs in a binary classification setting. We first give a general framework for TWSVM classifiers that unifies most of the variants of TWSVMs for binary classification problems. Based on it, we then investigate the universal consistency of TWSVMs. To do this, we give some useful definitions of risk, Bayes risk and universal consistency for TWSVMs. Theoretical results indicate that universal consistency is valid for various TWSVM classifiers under some certain conditions, including covering number, localized covering number and stability. For applications of our general framework, several variants of TWSVMs are considered.},
  archive      = {J_IJMLC},
  author       = {Xu, Weixia and Huang, Dingjiang and Zhou, Shuigeng},
  doi          = {10.1007/s13042-021-01281-0},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {7},
  pages        = {1867-1877},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Universal consistency of twin support vector machines},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A study on the uncertainty of convolutional layers in deep
neural networks. <em>IJMLC</em>, <em>12</em>(6), 1853–1865. (<a
href="https://doi.org/10.1007/s13042-021-01278-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper shows a Min–Max property existing in the connection weights of the convolutional layers in a neural network structure, i.e., the LeNet. Specifically, the Min–Max property means that, during the back propagation-based training for LeNet, the weights of the convolutional layers will become far away from their centers of intervals, i.e., decreasing to their minimum or increasing to their maximum. From the perspective of uncertainty, we demonstrate that the Min–Max property corresponds to minimizing the fuzziness of the model parameters through a simplified formulation of convolution. It is experimentally confirmed that the model with the Min–Max property has a stronger adversarial robustness, thus this property can be incorporated into the design of loss function. This paper points out a changing tendency of uncertainty in the convolutional layers of LeNet structure, and gives some insights to the interpretability of convolution.},
  archive      = {J_IJMLC},
  author       = {Shen, Haojing and Chen, Sihong and Wang, Ran},
  doi          = {10.1007/s13042-021-01278-9},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {6},
  pages        = {1853-1865},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A study on the uncertainty of convolutional layers in deep neural networks},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Numerical solution for high-dimensional partial differential
equations based on deep learning with residual learning and data-driven
learning. <em>IJMLC</em>, <em>12</em>(6), 1839–1851. (<a
href="https://doi.org/10.1007/s13042-021-01277-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Solving high-dimensional partial differential equations (PDEs) is a long-term computational challenge due to the fundamental obstacle known as the curse of dimensionality. This paper develops a novel method (DL4HPDE) based on residual neural network learning with data-driven learning elliptic PDEs on a box-shaped domain. However, to combine a strong mechanism with a weak mechanism, we reconstruct a trial solution to the equations in two parts: the first part satisfies the initial and boundary conditions, while the second part is the residual neural network algorithm, which is used to train the other part. In our proposed method, residual learning is adopted to make our model easier to optimize. Moreover, we propose a data-driven algorithm that can increase the training spatial points according to the regional error and improve the accuracy of the model. Finally, the numerical experiments show the efficiency of our proposed model.},
  archive      = {J_IJMLC},
  author       = {Wang, Zheng and Weng, Futian and Liu, Jialin and Cao, Kai and Hou, Muzhou and Wang, Juan},
  doi          = {10.1007/s13042-021-01277-w},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {6},
  pages        = {1839-1851},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Numerical solution for high-dimensional partial differential equations based on deep learning with residual learning and data-driven learning},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Improving crowd labeling using stackelberg models.
<em>IJMLC</em>, <em>12</em>(6), 1825–1838. (<a
href="https://doi.org/10.1007/s13042-021-01276-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Crowdsourcing systems provide an easy means of acquiring labeled training data for supervised learning. However, the labels provided by non-expert crowd workers (labelers) often appear low quality. In order to solve this problem, in practice each sample always obtains a multiple noisy label set from multiple different labelers, then ground truth inference algorithms are employed to obtain integrated labels of samples. So ground truth inference methods directly determine the label quality of samples. In this paper, we propose a novel label integration method based on game theory. We assume that there is an adversary in crowdsourcing system who intentionally provides incorrect integrated labels. We model the interaction between the data miner and the adversary as a Stackelberg game in which one player (the data miner) controls the predictive model whereas another (the adversary) tries to choose the integrated labels which would be most harmful for the current classifier. On this basis, we transform the label integration problem into a repeated Stackelberg model. We call our method Stackelberg label inference (SLI). SLI does not need to estimate the quality of labelers, and avoids the chicken-egg problem that can lead to poor result. Moreover, because SLI has little involvement of multiple noisy label sets on the noise data set, it is not very sensitive to the number of labelers. SLI shows better performance when the number of labelers is relatively small. In term of both label quality and model quality, the experimental results show that SLI is superior to the other state-of-the-art ground truth inference methods used to compare.},
  archive      = {J_IJMLC},
  author       = {Yang, Wenjun and Li, Chaoqun},
  doi          = {10.1007/s13042-021-01276-x},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {6},
  pages        = {1825-1838},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Improving crowd labeling using stackelberg models},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Adaptive robust local online density estimation for
streaming data. <em>IJMLC</em>, <em>12</em>(6), 1803–1824. (<a
href="https://doi.org/10.1007/s13042-021-01275-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate online density estimation is crucial to numerous applications that are prevalent with streaming data. Existing online approaches for density estimation somewhat lack prompt adaptability and robustness when facing concept-drifting and noisy streaming data, resulting in delayed or even deteriorated approximations. To alleviate this issue, in this work, we first propose an adaptive local online kernel density estimator (ALoKDE) for real-time density estimation on data streams. ALoKDE consists of two tightly integrated strategies: (1) a statistical test for concept drift detection and (2) an adaptive weighted local online density estimation when a drift does occur. Specifically, using a weighted form, ALoKDE seeks to provide an unbiased estimation by factoring in the statistical hallmarks of the latest learned distribution and any potential distributional changes that could be introduced by each incoming instance. A robust variant of ALoKDE, i.e., R-ALoKDE, is further developed to effectively handle data streams with varied types/levels of noise. Moreover, we analyze the asymptotic properties of ALoKDE and R-ALoKDE, and also derive their theoretical error bounds regarding bias, variance, MSE and MISE. Extensive comparative studies on various artificial and real-world (noisy) streaming data demonstrate the efficacies of ALoKDE and R-ALoKDE in online density estimation and real-time classification (with noise).},
  archive      = {J_IJMLC},
  author       = {Chen, Zhong and Fang, Zhide and Sheng, Victor and Zhao, Jiabin and Fan, Wei and Edwards, Andrea and Zhang, Kun},
  doi          = {10.1007/s13042-021-01275-y},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {6},
  pages        = {1803-1824},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Adaptive robust local online density estimation for streaming data},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Fault detection of railway freight cars mechanical
components based on multi-feature fusion convolutional neural network.
<em>IJMLC</em>, <em>12</em>(6), 1789–1801. (<a
href="https://doi.org/10.1007/s13042-021-01274-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The fault detection of the mechanical components in railway freight cars is important to the safety of railway transportation. Owing to the small size of the mechanical components, a manual detection method has a low detection efficiency. In addition, traditional computer vision technology has difficulty detecting multiple categories of objects simultaneously. Inspired by the use of one-stage deep-learning-based object detectors, in this paper, a multi-feature fusion network (MFF-net) for the simultaneous detection of three typical mechanical component faults is proposed. By embedding three modules in the network to improve the detection effect of small mechanical component faults, the feature fusion module is used to supplement the deep semantic information of the shallow feature maps. A multi-branch dilated convolution module uses dilated convolution and multi-branch networks to obtain the fusion features of multi-scale receptive fields, and the squeeze-and-excitation block is embedded in the network to enhance the channel features. All experiments used Nvidia 1080Ti GPUs for training on the PyTorch platform. The experimental results show that the three modules used in the network all contribute to the fault detection of railway freight car mechanical components, and that the detection performance of MFF-net is better than that of most other popular SSD-based one-stage object detectors. When the input image size is 300 pixels × 300 pixels, MFF-net can achieve 0.8872 mAP and 33 frames per second. It has good robustness to complex noise environment and can realize real-time fault detection of railway freight car mechanical components.},
  archive      = {J_IJMLC},
  author       = {Ye, Tao and Zhang, Zhihao and Zhang, Xi and Chen, Yongran and Zhou, Fuqiang},
  doi          = {10.1007/s13042-021-01274-z},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {6},
  pages        = {1789-1801},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Fault detection of railway freight cars mechanical components based on multi-feature fusion convolutional neural network},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Uncertainty measurement for a fuzzy set-valued information
system. <em>IJMLC</em>, <em>12</em>(6), 1769–1787. (<a
href="https://doi.org/10.1007/s13042-020-01273-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Uncertainty measurement (UM) can offer new visual angle for data analysis. A fuzzy set-valued information system (FSVIS) which means an information system (IS) where its information values are fuzzy sets. This article investigates UM for a FSVIS. First, a FSVIS is introduced. Then, the distance between two information values of each attribute in a FSVIS is founded. After that, the tolerance relation induced by a given subsystem is acquired by this distance. Moreover, the information structure of this subsystem is brought forward. Additionally, measures of uncertainty for a FSVIS are explored. Eventually, to verify the validity of these measures, statistical effectiveness analysis is carried out. The obtained results will help us understand the intrinsic properties of uncertainty in a FSVIS.},
  archive      = {J_IJMLC},
  author       = {Li, Zhaowen and Wang, Zhihong and Li, Qingguo and Wang, Pei and Wen, Ching-Feng},
  doi          = {10.1007/s13042-020-01273-6},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {6},
  pages        = {1769-1787},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Uncertainty measurement for a fuzzy set-valued information system},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Sample-based online learning for bi-regular hinge loss.
<em>IJMLC</em>, <em>12</em>(6), 1753–1768. (<a
href="https://doi.org/10.1007/s13042-020-01272-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Support vector machine (SVM), a state-of-the-art classifier for supervised classification task, is famous for its strong generalization guarantees derived from the max-margin property. In this paper, we focus on the maximum margin classification problem cast by SVM and study the bi-regular hinge loss model, which not only performs feature selection but tends to select highly correlated features together. To solve this model, we propose an online learning algorithm that aims at solving a non-smooth minimization problem by alternating iterative mechanism. Basically, the proposed algorithm alternates between intrusion samples detection and iterative optimization, and at each iteration it obtains a closed-form solution to the model. In theory, we prove that the proposed algorithm achieves $$O(1/\sqrt{T})$$ convergence rate under some mild conditions, where T is the number of training samples received in online learning. Experimental results on synthetic data and benchmark datasets demonstrate the effectiveness and performance of our approach in comparison with several popular algorithms, such as LIBSVM, SGD, PEGASOS, SVRG, etc.},
  archive      = {J_IJMLC},
  author       = {Xue, Wei and Zhong, Ping and Zhang, Wensheng and Yu, Gaohang and Chen, Yebin},
  doi          = {10.1007/s13042-020-01272-7},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {6},
  pages        = {1753-1768},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Sample-based online learning for bi-regular hinge loss},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Development of ensemble learning classification with density
peak decomposition-based evolutionary multi-objective optimization.
<em>IJMLC</em>, <em>12</em>(6), 1737–1751. (<a
href="https://doi.org/10.1007/s13042-020-01271-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The ensemble learning methods have always been paid attention to their successful performance in handling supervised classification problems. Nevertheless, some deficiencies, such as inadequate diversity between classifiers and existing redundant classifiers, are among the main challenges in this kind of learning. In recent years, a method called density peak has been used in clustering methods to improve this process, which selects cluster centers from the local density peak. In this paper, inspiring this matter, and using the density peak criterion, a new method is proposed to create parallel ensembles. This criterion creates diverse training sets resulting in the generation of diverse classifiers. In the proposed method, during a multi-objective evolutionary decomposition-based optimization process, some (near) optimum diverse training datasets are created to improve the performance of the non-sequential ensemble learning methods. To do so, in addition to density peak as the first objective, the accuracy criterion is used as the second objective function. To show the superiority of the proposed method, it has been compared with the state-of-the-art methods over 19 datasets. To conduct a better comparison, non-parametric statistical tests are used, where the obtained results demonstrate that the proposed method can significantly dominate the other employed methods.},
  archive      = {J_IJMLC},
  author       = {Roshan, SeyedEhsan and Asadi, Shahrokh},
  doi          = {10.1007/s13042-020-01271-8},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {6},
  pages        = {1737-1751},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Development of ensemble learning classification with density peak decomposition-based evolutionary multi-objective optimization},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Problems selection under dynamic selection of the best base
classifier in one versus one: PSEUDOVO. <em>IJMLC</em>, <em>12</em>(6),
1721–1735. (<a
href="https://doi.org/10.1007/s13042-020-01270-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Class binarization techniques are used to decompose multi-class problems into several easier-to-solve binary sub-problems. One of the most popular binarization techniques is One versus One (OVO), which creates a sub-problem for each pair of classes of the original problem. Different versions of OVO have been developed to try to solve some of its problems, such as DYNOVO, which dynamically tries to select the best classifier for each sub-problem. In this paper, a new extension that has been made for DYNOVO, called PSEUDOVO, is presented. This extension also tries to avoid the non-competent sub-problems. An empirical study has been carried out over several UCI data sets, as well as a new data set of musical pieces of well-known classical composers. Promising results have been obtained, from which can be concluded that the PSEUDOVO extension improves the performance of DYNOVO.},
  archive      = {J_IJMLC},
  author       = {Goienetxea, Izaro and Mendialdua, Iñigo and Rodríguez, Igor and Sierra, Basilio},
  doi          = {10.1007/s13042-020-01270-9},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {6},
  pages        = {1721-1735},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Problems selection under dynamic selection of the best base classifier in one versus one: PSEUDOVO},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Feature distribution-based label correlation in multi-label
classification. <em>IJMLC</em>, <em>12</em>(6), 1705–1719. (<a
href="https://doi.org/10.1007/s13042-020-01268-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In multi-label classification, multiple label variables in output space are equally important and can be predicted according to a common set of input variables. To improve the accuracy and efficiency of multi-label learner, measuring and utilizing label correlation is the core breakthrough. Extensive research on label correlation focuses on the co-occurrence or mutual exclusion frequency of label values in output space. In this paper, to handle the multi-label learning tasks, a novel method, named FL-MLC, is proposed by considering the influence of feature-label dependencies on inter-label correlations. In order to describe the intrinsic relationship between feature variable and label variable, the discriminant weight of any feature to label is first defined. Therefore, the concept of feature distribution for inputs on label is proposed to reflect the discriminant weights of features to the label. The corresponding calculation process is also designed based on multiple kernel learning and kernel alignment. Furthermore, the feature distributions on different labels are integrated into the feature distribution-based label correlation by using two different aggregation strategies. Obviously, arbitrary label variables with highly similar feature distributions have strong relevance. Thus, the feature distribution-based label correlation is applied to adjust the distance between the parameters for different labels in the predictive learner of FL-MLC method. Finally, the experimental results on twelve real-world datasets demonstrate that our methods achieves good effectiveness and versatility for multi-label classification.},
  archive      = {J_IJMLC},
  author       = {Che, Xiaoya and Chen, Degang and Mi, Jusheng},
  doi          = {10.1007/s13042-020-01268-3},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {6},
  pages        = {1705-1719},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Feature distribution-based label correlation in multi-label classification},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Deep reinforcement learning based home energy management
system with devices operational dependencies. <em>IJMLC</em>,
<em>12</em>(6), 1687–1703. (<a
href="https://doi.org/10.1007/s13042-020-01266-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Advanced metering infrastructure and bilateral communication technologies facilitate the development of the home energy management system in the smart home. In this paper, we propose an energy management strategy for controllable loads based on reinforcement learning (RL). First, based on the mathematical model, the Markov decision process of different types of home energy resources (HERs) is formulated. Then, two RL algorithms, i.e. deep Q-learning and deep deterministic policy gradient are utilized. Based on the living habits of the residents, the dependency modes for HERs are proposed and are integrated into the reinforcement learning algorithms. Through the case studies, it is verified that the proposed method can schedule HERs properly to satisfy the established dependency modes. The difference between the achieved result and the optimal solution is relatively small.},
  archive      = {J_IJMLC},
  author       = {Si, Caomingzhe and Tao, Yuechuan and Qiu, Jing and Lai, Shuying and Zhao, Junhua},
  doi          = {10.1007/s13042-020-01266-5},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {6},
  pages        = {1687-1703},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Deep reinforcement learning based home energy management system with devices operational dependencies},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Joint learning of author and citation contexts for computing
drift in scholarly documents. <em>IJMLC</em>, <em>12</em>(6), 1667–1686.
(<a href="https://doi.org/10.1007/s13042-020-01265-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Scholarly documents are sources of information on research topics written by academic experts. Topic drift in such scholarly documents is usually linked with the contextual variation in the title or abstract or entire document over time. However, topic distribution over words in different components of the document is non-uniform due to the varying impact of authors and citations, and their contribution to drift must be processed accordingly. This paper builds a model that distinguishes the context of a research document based on the author and citation by incorporating relation between topic, author, citation, word and time in the form of author context vector and citation context vector. To infer posterior probabilities, a parallel author cited_author topic model is presented. Continuous time bivariate Brownian motion model is employed for deducing the evolving bivariate topic parameters, specific to the author and citation. The word, topic pairs from the author and citation context vectors are jointly learned to yield topical word embeddings over time conditioned on author and citation contexts. When evaluated with NIPS and business journals datasets, the proposed model identifies topical variations over time precisely compared to other methods. It is found that broadening of topic happens due to the author context, and topic deviation is mainly caused by citation context.},
  archive      = {J_IJMLC},
  author       = {Vijayarani, J. and Geetha, T. V.},
  doi          = {10.1007/s13042-020-01265-6},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {6},
  pages        = {1667-1686},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Joint learning of author and citation contexts for computing drift in scholarly documents},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A scalable network intrusion detection system towards
detecting, discovering, and learning unknown attacks. <em>IJMLC</em>,
<em>12</em>(6), 1649–1665. (<a
href="https://doi.org/10.1007/s13042-020-01264-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Network intrusion detection systems (IDSs) based on deep learning have reached fairly accurate attack detection rates. But these deep learning approaches usually have been performed in a closed-set protocol that only known classes appear in training are considered during classification, the existing IDSs will fail to detect the unknown attacks and misclassify them as the training known classes, hence are not scalable. Furthermore, these IDSs are not efficient for updating the deep detection model once new attacks are discovered. To address those problems, we propose a scalable IDS towards detecting, discovering, and learning unknown attacks, it has three components. Firstly, we propose the open-set classification network (OCN) to detect unknown attacks, OCN based on the convolutional neural network adopts the nearest class mean (NCM) classifier, two new loss are designed to jointly optimize it, including Fisher loss and maximum mean discrepancy (MMD) loss. Subsequently, the semantic embedding clustering method is proposed to discover the hidden unknown attacks from all unknown instances detected by OCN. Then we propose the incremental nearest cluster centroid (INCC) method for learning the discovered unknown attacks through updating the NCM classifier. Extensive experiments on KDDCUP’99 dataset and CICIDS2017 dataset indicate that our OCN outperforms the state-of-the-art comparison methods in detecting multiple types of unknown attacks. Our experiments also verify the feasibility of the semantic embedding clustering method and INCC in discovering and learning unknown attacks.},
  archive      = {J_IJMLC},
  author       = {Zhang, Zhao and Zhang, Yong and Guo, Da and Song, Mei},
  doi          = {10.1007/s13042-020-01264-7},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {6},
  pages        = {1649-1665},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A scalable network intrusion detection system towards detecting, discovering, and learning unknown attacks},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Hierarchical multi-attention networks for document
classification. <em>IJMLC</em>, <em>12</em>(6), 1639–1647. (<a
href="https://doi.org/10.1007/s13042-020-01260-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Research of document classification is ongoing to employ the attention based-deep learning algorithms and achieves impressive results. Owing to the complexity of the document, classical models, as well as single attention mechanism, fail to meet the demand of high-accuracy classification. This paper proposes a method that classifies the document via the hierarchical multi-attention networks, which describes the document from the word-sentence level and the sentence-document level. Further, different attention strategies are performed on different levels, which enables accurate assigning of the attention weight. Specifically, the soft attention mechanism is applied to the word-sentence level while the CNN-attention to the sentence-document level. Due to the distinctiveness of the model, the proposed method delivers the highest accuracy compared to other state-of-the-art methods. In addition, the attention weight visualization outcomes present the effectiveness of attention mechanism in distinguishing the importance.},
  archive      = {J_IJMLC},
  author       = {Huang, Yingren and Chen, Jiaojiao and Zheng, Shaomin and Xue, Yun and Hu, Xiaohui},
  doi          = {10.1007/s13042-020-01260-x},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {6},
  pages        = {1639-1647},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Hierarchical multi-attention networks for document classification},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Caps-OWKG: A capsule network model for open-world knowledge
graph. <em>IJMLC</em>, <em>12</em>(6), 1627–1637. (<a
href="https://doi.org/10.1007/s13042-020-01259-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge graphs are typical multi-relational structures, which is consisted of many entities and relations. Nonetheless, existing knowledge graphs are still sparse and far from being complete. To refine the knowledge graphs, representation learning is utilized to embed entities and relations into low-dimensional spaces. Many existing knowledge graphs embedding models focus on learning latent features in close-world assumption but omit the changeable of each knowledge graph.In this paper, we propose a knowledge graph representation learning model, called Caps-OWKG, which leverages the capsule network to capture the both known and unknown triplets features in open-world knowledge graph. It combines the descriptive text and knowledge graph to get descriptive embedding and structural embedding, simultaneously. Then, the both above embeddings are used to calculate the probability of triplet authenticity. We verify the performance of Caps-OWKG on link prediction task with two common datasets FB15k-237-OWE and DBPedia50k. The experimental results are better than other baselines, and achieve the state-of-the-art performance.},
  archive      = {J_IJMLC},
  author       = {Wang, Yuhan and Xiao, Weidong and Tan, Zhen and Zhao, Xiang},
  doi          = {10.1007/s13042-020-01259-4},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {6},
  pages        = {1627-1637},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Caps-OWKG: A capsule network model for open-world knowledge graph},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Consensus model based on probability k-means clustering
algorithm for large scale group decision making. <em>IJMLC</em>,
<em>12</em>(6), 1609–1626. (<a
href="https://doi.org/10.1007/s13042-020-01258-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, the increasing complexity of the social environment brings much difficulty in group decision making. The more uncertainty exists in a decision-making problem, the more collective wisdom is needed. Therefore, large scale group decision making has attracted a lot of researchers to investigate. Since the probabilistic linguistic terms have impressive performance in expressing DMs’ opinions, this paper proposes a novel method for large scale group decision making with probabilistic linguistic preference relations. More specifically, (1) a probability k-means clustering algorithm is introduced to segment DMs with similar features into different sub-groups; (2) an integration method is proposed to construct the collective probabilistic preference relation that retains initial information to the most extent; (3) taking the personality of each DM into account, a consensus model is constructed to improve the rationality and efficiency of consensus reaching process. Several simulation experiments are designed to analyze the influence factor in the feedback mechanism and make some comparative analysis with the existing method. Finally, an illustrative example of contractor selection is conducted to verify the validity of the proposed method.},
  archive      = {J_IJMLC},
  author       = {Liu, Qian and Wu, Hangyao and Xu, Zeshui},
  doi          = {10.1007/s13042-020-01258-5},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {6},
  pages        = {1609-1626},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Consensus model based on probability K-means clustering algorithm for large scale group decision making},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). <span
class="math display"><em>L</em><sub><em>p</em></sub></span> -norm
probabilistic k-means clustering via nonlinear programming.
<em>IJMLC</em>, <em>12</em>(6), 1597–1607. (<a
href="https://doi.org/10.1007/s13042-020-01257-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generalized fuzzy c-means (GFCM) is an extension of fuzzy c-means using $$L_{p}$$ -norm distances. However, existing methods cannot solve GFCM with m = 1. To solve this problem, we define a new kind of clustering models, called $$L_{p}$$ -norm probabilistic K-means ( $$L_{p}$$ -PKM). Theoretically, $$L_{p}$$ -PKM is equivalent to GFCM at m = 1, and can have nonlinear programming solutions based on an efficient active gradient projection (AGP) method, namely, inverse recursion maximum-step active gradient projection (IRMSAGP). On synthetic and UCI datasets, experimental results show that $$L_{p}$$ -PKM performs better than GFCM (m &gt; 1) in terms of initialization robustness, p-influence, and clustering performance, and the proposed IRMSAGP also achieves better performance than the traditional AGP in terms of convergence speed.},
  archive      = {J_IJMLC},
  author       = {Liu, Bowen and Li, Yujian and Zhang, Ting and Liu, Zhaoying},
  doi          = {10.1007/s13042-020-01257-6},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {6},
  pages        = {1597-1607},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {$$L_{p}$$ -norm probabilistic K-means clustering via nonlinear programming},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Attention-based context aggregation network for monocular
depth estimation. <em>IJMLC</em>, <em>12</em>(6), 1583–1596. (<a
href="https://doi.org/10.1007/s13042-020-01251-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Depth estimation is a traditional computer vision task, which plays a crucial role in understanding 3D scene geometry. Recently, algorithms that combine the multi-scale features extracted by the dilated convolution based block (atrous spatial pyramid pooling, ASPP) have gained significant improvements in depth estimation. However, the discretized and predefined dilation kernels cannot capture the continuous context information that differs in diverse scenes and easily introduce the grid artifacts. This paper proposes a novel algorithm, called attention-based context aggregation network (ACAN) for depth estimation. A supervised self-attention model is designed and utilized to adaptively learn the task-specific similarities between different pixels to model the continuous context information. Moreover, a soft ordinal inference is proposed to transform the predicted probabilities to continuous depth values which reduce the discretization error (about 1\% decrease in RMSE). ACAN achieves state-of-the-art performance on public monocular depth-estimation benchmark datasets. The source code of ACAN can be found in https://github.com/miraiaroha/ACAN .},
  archive      = {J_IJMLC},
  author       = {Chen, Yuru and Zhao, Haitao and Hu, Zhengwei and Peng, Jingchao},
  doi          = {10.1007/s13042-020-01251-y},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {6},
  pages        = {1583-1596},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Attention-based context aggregation network for monocular depth estimation},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An improved density-based adaptive p-spectral clustering
algorithm. <em>IJMLC</em>, <em>12</em>(6), 1571–1582. (<a
href="https://doi.org/10.1007/s13042-020-01236-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a generalization algorithm of spectral clustering, p-spectral clustering has gradually attracted extensive attention of researchers. Gaussian kernel function is generally used in traditional p-spectral clustering to construct the similarity matrix of data. However, the Gaussian kernel function based on Euclidean distance is not effective when the data-set is complex with multiple density peaks or the density distribution is uniform. In order to solve this problem, an improved Density-based adaptive p-spectral clustering algorithm (DAPSC) is proposed, the prior information is considering to adjust the similarity between sample points and strengthen the local correlation between data points. In addition, by combining the density canopy method to update the initial clustering center and the number of clusters, the algorithm sensitivity of the original p-spectral clustering caused by the two is weakened. By experiments on four artificial data-sets and 8F UCI data-sets, we show that the proposed DAPSC has strong adaptability and more accurate compared with the four baseline methods.},
  archive      = {J_IJMLC},
  author       = {Wang, Yanru and Ding, Shifei and Wang, Lijuan and Ding, Ling},
  doi          = {10.1007/s13042-020-01236-x},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {6},
  pages        = {1571-1582},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {An improved density-based adaptive p-spectral clustering algorithm},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Algorithms of matrix recovery based on truncated schatten
p-norm. <em>IJMLC</em>, <em>12</em>(5), 1557–1570. (<a
href="https://doi.org/10.1007/s13042-020-01256-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, algorithms to recovery low-rank matrix have become one of the research hotspots, and more corresponding optimization models with nuclear norm have also been proposed. However, nuclear norm is not a good approximation to the rank function. This paper proposes a matrix completion model and a low-rank sparse decomposition model based on truncated Schatten p-norm, respectively, which combine Schatten p-norm with truncated nuclear norm, so that the models are more flexible. To solve these models, the function expansion method is first used to transform the non-convex optimization models into the convex optimization ones. Then, the two-step iterative algorithm based on alternating direction multiplier method (ADMM) is employed to solve the models. Further, the convergence of the proposed algorithm is proved mathematically. The superiority of the proposed method is further verified by comparing the existing methods in synthetic data and actual images.},
  archive      = {J_IJMLC},
  author       = {Wen, Chenglin and Qian, Wenchao and Zhang, Qinghua and Cao, Feilong},
  doi          = {10.1007/s13042-020-01256-7},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {5},
  pages        = {1557-1570},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Algorithms of matrix recovery based on truncated schatten p-norm},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An automatic three-way clustering method based on sample
similarity. <em>IJMLC</em>, <em>12</em>(5), 1545–1556. (<a
href="https://doi.org/10.1007/s13042-020-01255-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The three-way clustering is an extension of traditional clustering by adding the concept of fringe region, which can effectively solve the problem of inaccurate decision-making caused by inaccurate information or insufficient data in traditional two-way clustering methods. The existing three-way clustering works often select the appropriate number of clusters and the thresholds for three-way partition according to subjective tuning. However, the method of fixing the number of clusters and the thresholds of the partition cannot automatically select the optimal number of clusters and partition thresholds for different data sets with different sizes and densities. To address the above problem, this paper proposed an improved three-way clustering method. First, we define the roughness degree by introducing the sample similarity to measure the uncertainty of the fringe region. Moreover, based on the roughness degree, we define a novel partitioning validity index to measure the clustering partitions and propose an automatic threshold selection method. Second, based on the concept of sample similarity, we introduce the intra-class similarity and the inter-class similarity to describe the quantitative change of the relationship between the sample and the clusters, and define a novel clustering validity index to measure the clustering performance under different numbers of clusters through the integration of the above two kinds of similarities. Furthermore, we propose an automatic cluster number selection method. Finally, we give an automatic three-way clustering approach by combining the proposed threshold selection method and the cluster number selection method. The comparison experiments demonstrate the effectiveness of our proposal.},
  archive      = {J_IJMLC},
  author       = {Jia, Xiuyi and Rao, Ya and Li, Weiwei and Yang, Sichun and Yu, Hong},
  doi          = {10.1007/s13042-020-01255-8},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {5},
  pages        = {1545-1556},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {An automatic three-way clustering method based on sample similarity},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Vortex search optimization algorithm for training of
feed-forward neural network. <em>IJMLC</em>, <em>12</em>(5), 1517–1544.
(<a href="https://doi.org/10.1007/s13042-020-01252-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Training of feed-forward neural-networks (FNN) is a challenging nonlinear task in supervised learning systems. Further, derivative learning-based methods are frequently inadequate for the training phase and cause a high computational complexity due to the numerous weight values that need to be tuned. In this study, training of neural-networks is considered as an optimization process and the best values of weights and biases in the structure of FNN are determined by Vortex Search (VS) algorithm. The VS algorithm is a novel metaheuristic optimization method recently developed, inspired by the vortex shape of stirred liquids. VS fulfills the training task to set the optimal weights and biases stated in a matrix. In this context, the proposed VS-based learning method for FNNs (VS-FNN) is conducted to analyze the effectiveness of the VS algorithm in FNN training for the first time in the literature. The proposed method is applied to six datasets whose names are 3-bit XOR, Iris Classification, Wine-Recognition, Wisconsin-Breast-Cancer, Pima-Indians-Diabetes, and Thyroid-Disease. The performance of the proposed algorithm is analyzed by comparing with other training methods based on Artificial Bee Colony Optimization (ABC), Particle Swarm Optimization (PSO), Simulated Annealing (SA), Genetic Algorithm (GA) and Stochastic Gradient Descent (SGD) algorithms. The experimental results show that VS-FNN is generally leading and competitive. It is also said that VS-FNN can be used as a capable tool for neural networks.},
  archive      = {J_IJMLC},
  author       = {Sağ, Tahir and Abdullah Jalil Jalil, Zainab},
  doi          = {10.1007/s13042-020-01252-x},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {5},
  pages        = {1517-1544},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Vortex search optimization algorithm for training of feed-forward neural network},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Dynamic neural orthogonal mapping for fault detection.
<em>IJMLC</em>, <em>12</em>(5), 1501–1516. (<a
href="https://doi.org/10.1007/s13042-020-01250-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic principal component analysis (DPCA) and its nonlinear extension, dynamic kernel principal component analysis (DKPCA), are widely used in the monitoring of dynamic multivariate processes. In traditional DPCA and DKPCA, extended vectors through concatenating current process data point and a certain number of previous process data points are utilized for feature extraction. The dynamic relations among different variables are fixed in the extended vectors, i.e. the adoption of the dynamic information is not adaptively learned from raw process data. Although DKPCA utilizes a kernel function to handle dynamic and (or) nonlinear information, the prefixed kernel function and the associated parameters cannot be most effective for characterizing the dynamic relations among different process variables. To address these problems, this paper proposes a novel nonlinear dynamic method, called dynamic neural orthogonal mapping (DNOM), which consists of data dynamic extension, a nonlinear feedforward neural network, and an orthogonal mapping matrix. Through backpropagation and Eigen decomposition (ED) technique, DNOM can be optimized to extract key low-dimensional features from original high-dimensional data. The advantages of DNOM are demonstrated by both theoretical analysis and extensive experimental results on the Tennessee Eastman (TE) benchmark process. The results on the TE benchmark process show the superiority of DNOM in terms of missed detection rate and false alarm rate. The source codes of DNOM can be found in https://github.com/htz-ecust/DNOM .},
  archive      = {J_IJMLC},
  author       = {Hu, Zhengwei and Peng, Jingchao and Zhao, Haitao},
  doi          = {10.1007/s13042-020-01250-z},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {5},
  pages        = {1501-1516},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Dynamic neural orthogonal mapping for fault detection},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Ensemble adaptive convolutional neural networks with
parameter transfer for rotating machinery fault diagnosis.
<em>IJMLC</em>, <em>12</em>(5), 1483–1499. (<a
href="https://doi.org/10.1007/s13042-020-01249-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There exist many rotating machinery parts, and many types of failure modes, including single failure modes and compound failure modes. This brings high requirements on the performance and generalization ability of fault diagnosis methods. Compared with single fixed model, ensemble model can gather the strengths of others to achieve more accurate identification performance and stronger generalization ability. Based on this, a novel method called ensemble adaptive batch-normalized convolutional neural networks is proposed for rotating machinery fault diagnosis. Firstly, batch normalization and exponentially decaying learning rate are applied to basic convolutional neural network to address internal covariate shift problem, and achieve better diagnostic results and faster convergence speed. Secondly, a series of adaptive batch-normalized convolutional neural networks with different properties are designed. Thirdly, K-fold cross validation is utilized to train all models and parameter transfer is adopted to save computing time. Finally, a new combination strategy is proposed to efficiently ensemble the diagnosis results of all models. The proposed method is demonstrated by practical locomotive bearing dataset and extensive experiments.},
  archive      = {J_IJMLC},
  author       = {Zhao, Ke and Jiang, Hongkai and Li, Xingqiu and Wang, Ruixin},
  doi          = {10.1007/s13042-020-01249-6},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {5},
  pages        = {1483-1499},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Ensemble adaptive convolutional neural networks with parameter transfer for rotating machinery fault diagnosis},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Three-level and three-way uncertainty measurements for
interval-valued decision systems. <em>IJMLC</em>, <em>12</em>(5),
1459–1481. (<a
href="https://doi.org/10.1007/s13042-020-01247-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Uncertainty measurements underlie the system interaction and data learning. Their relevant studies are extensive for the single-valued decision systems, but become relatively less for the interval-valued decision systems. Thus, three-level and three-way uncertainty measurements of the interval-valued decision systems are proposed, mainly by systematically constructing vertical-horizontal weighted entropies. Firstly, the interval-valued decision systems are endowed with three-level structures, including Micro-Bottom, Meso-Middle, and Macro-Top. Secondly, a three-level decomposition is hierarchically made for the existing conditional entropy. Thirdly, three-way weighted entropies are systematically and hierarchically constructed at the three levels, and they achieve their hierarchy, systematicness, algorithm, boundedness, and granulation monotonicity/non-monotonicity. The three-level and three-way weighted entropies deepen and extend the conditional entropy, and they realize the ingenious criss-cross informatization for the interval-valued decision systems. Their effectiveness of uncertainty measurements is ultimately verified by table examples and data experiments.},
  archive      = {J_IJMLC},
  author       = {Liao, Shengjun and Zhang, Xianyong and Mo, Zhiwen},
  doi          = {10.1007/s13042-020-01247-8},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {5},
  pages        = {1459-1481},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Three-level and three-way uncertainty measurements for interval-valued decision systems},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Attribution reduction based on sequential three-way search
of granularity. <em>IJMLC</em>, <em>12</em>(5), 1439–1458. (<a
href="https://doi.org/10.1007/s13042-020-01244-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most existing results about attribute reduction are reported by considering one and only one granularity, especially for the strategies of searching reducts. Nevertheless, how to derive reduct from multi-granularity has rarely been taken into account. One of the most important advantages of multi-granularity based attribute reduction is that it is useful in investigating the variation of the performances of reducts with respect to different granularities. From this point of view, the concept of Sequential Granularity Attribute Reduction (SGAR) is systemically studied in this paper. Different from previous attribute reductions, the aim of SGAR is to find multiple reducts which are derived from a family of ordered granularities. Assuming that a reduct related to the previous granularity may offer the guidance for computing a reduct related to the current granularity, the idea of the three-way is introduced into the searching of sequential granularity reduct. The three different ways in such process are: (1) the reduct related to the previous granularity is precisely the reduct related to the current granularity; (2) the reduct related to the previous granularity is not the reduct related to the current granularity; (3) the reduct related to the previous granularity is possible to be the reduct related to the current granularity. Therefore, a three-way based forward greedy searching is designed to calculate the sequential granularity reduct. The main advantage of our strategy is that the number of times to evaluate the candidate attributes can be reduced. Experimental results over 12 UCI data sets demonstrate the following: (1) three-way based searching is superior to some state-of-the-art acceleration algorithms in time consumption of deriving reducts; (2) the sequential granularity reducts obtained by proposed three-way based searching will provide well-matched classification performances. This study suggests new trends concerning the problem of attribute selection.},
  archive      = {J_IJMLC},
  author       = {Wang, Xun and Wang, Pingxin and Yang, Xibei and Yao, Yiyu},
  doi          = {10.1007/s13042-020-01244-x},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {5},
  pages        = {1439-1458},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Attribution reduction based on sequential three-way search of granularity},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Entropy based optimal scale combination selection for
generalized multi-scale information tables. <em>IJMLC</em>,
<em>12</em>(5), 1427–1437. (<a
href="https://doi.org/10.1007/s13042-020-01243-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In many real-life applications, data are often hierarchically structured at different levels of granulations. A multi-scale information table is a special hierarchical data set in which each object can take on as many values as there are scales under the same attribute. An important issue in such a data set is to select optimal scale combination in order to keep certain condition for final decision. In this paper, by employing Shannon’s entropy, we study the selection of optimal scale combination to maintain uncertain measure of a knowledge from a generalized multi-scale information table. We first review the concept of entropy and its basic properties in information tables. We then introduce the notion of scale combinations in a generalized multi-scale information table. We further define entropy optimal scale combination in generalized multi-scale information tables and generalized multi-scale decision tables. Finally, we examine relationship between the entropy optimal scale combination and the classical optimal scale combination. We show that, in either a generalized multi-scale information table or a consistent generalized multi-scale decision table, the entropy optimal scale combination and the classical optimal scale combination are equivalent. And in an inconsistent generalized multi-scale decision table, a scale combination is generalized decision optimal if and only if it is a generalized decision entropy optimal.},
  archive      = {J_IJMLC},
  author       = {Bao, Han and Wu, Wei-Zhi and Zheng, Jia-Wen and Li, Tong-Jun},
  doi          = {10.1007/s13042-020-01243-y},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {5},
  pages        = {1427-1437},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Entropy based optimal scale combination selection for generalized multi-scale information tables},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A credibility-based fuzzy programming model for the
hierarchical multimodal hub location problem with time uncertainty in
cargo delivery systems. <em>IJMLC</em>, <em>12</em>(5), 1413–1426. (<a
href="https://doi.org/10.1007/s13042-020-01239-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the fuzzy hierarchical multimodal hub location problem for cargo delivery systems. It differs from traditional hub location problem in two ways. First, this paper constructs a hierarchical multimodal hub-and-spoke distribution network for the cargo delivery systems, which involves two transportation modes (road and air), two types of hubs (ground and airport) and three corresponding layers. Second, this paper develops a credibility-based fuzzy programming model capturing the uncertainty in travel time and handling time of the cargo delivery systems. This new model aims to minimize the latest arrival time (travel time plus handling time) for delivering cargoes from each pair of origin and destination nodes under diverse credibility of chance constraints. Under mild assumptions, the original model can be turned into an equivalent deterministic integer linear programming model. However, even for small instances of the problem, the equivalent model becomes too hard to be tackled by a general solver, e.g., CPLEX. This fact motivates the development of a two-stage heuristic procedure, wherein the first stage for the hub location subproblem is solved by a variable neighborhood search algorithm. These location solutions are then embedded into the second-stage process for the link assignment subproblem based on a shortest path method. To verify the proposed model and method, extensive numerical experiments are conducted on the well-known Turkish network data set.},
  archive      = {J_IJMLC},
  author       = {Shang, Xiaoting and Jia, Bin and Yang, Kai and Yuan, Yaping and Ji, Hao},
  doi          = {10.1007/s13042-020-01239-8},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {5},
  pages        = {1413-1426},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A credibility-based fuzzy programming model for the hierarchical multimodal hub location problem with time uncertainty in cargo delivery systems},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). SemiDroid: A behavioral malware detector based on
unsupervised machine learning techniques using feature selection
approaches. <em>IJMLC</em>, <em>12</em>(5), 1369–1411. (<a
href="https://doi.org/10.1007/s13042-020-01238-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the exponential growth in Android apps, Android based devices are becoming victims of target attackers in the “silent battle” of cybernetics. To protect Android based devices from malware has become more complex and crucial for academicians and researchers. The main vulnerability lies in the underlying permission model of Android apps. Android apps demand permission or permission sets at the time of their installation. In this study, we consider permission and API calls as features that help in developing a model for malware detection. To select appropriate features or feature sets from thirty different categories of Android apps, we implemented ten distinct feature selection approaches. With the help of selected feature sets we developed distinct models by using five different unsupervised machine learning algorithms. We conduct an experiment on 5,00,000 distinct Android apps which belongs to thirty distinct categories. Empirical results reveals that the model build by considering rough set analysis as a feature selection approach, and farthest first as a machine learning algorithm achieved the highest detection rate of 98.8\% to detect malware from real-world apps.},
  archive      = {J_IJMLC},
  author       = {Mahindru, Arvind and Sangal, A. L.},
  doi          = {10.1007/s13042-020-01238-9},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {5},
  pages        = {1369-1411},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {SemiDroid: A behavioral malware detector based on unsupervised machine learning techniques using feature selection approaches},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). L-fuzzifying approximation operators derived from general
l-fuzzifying neighborhood systems. <em>IJMLC</em>, <em>12</em>(5),
1343–1367. (<a
href="https://doi.org/10.1007/s13042-020-01237-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For a completely distributive De Morgan algebra L, we develop a general framework of L-fuzzy rough sets. Said precisely, we introduce a pair of L-fuzzy approximation operators, called upper and lower L-fuzzifying approximation operators derived from general L-fuzzifying neighborhood systems. It is shown that the proposed approximation operators are a common extension of the L-fuzzifying approximation operators derived from L-fuzzy relations (INS 2019) and the approximation operators derived from general neighborhood systems (KBS 2014). Furthermore, we investigate the unary, serial, reflexive, transitive and symmetric conditions in general L-fuzzifying neighborhood systems, and then study the associated approximation operators from both a constructive method and an axiomatic method. Particularly, for transitivity (resp., symmetry), we give two interpretations, one is an appropriate generalization of transitivity (resp., symmetry) for L-fuzzy relations, and the other is a suitable extension of transitivity (resp., symmetry) for general neighborhood systems. In addition, for some special L-fuzzifying approximation operators, we use single axiom to characterize them, respectively. At last, the proposed approximation operators are applied in the research of incomplete information system, and a three-way decision model based on them is established. To exhibit the effectiveness of the model, a practical example is presented.},
  archive      = {J_IJMLC},
  author       = {Li, Lingqiang and Yao, Bingxue and Zhan, Jianming and Jin, Qiu},
  doi          = {10.1007/s13042-020-01237-w},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {5},
  pages        = {1343-1367},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {L-fuzzifying approximation operators derived from general L-fuzzifying neighborhood systems},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Regularized based implicit lagrangian twin extreme learning
machine in primal for pattern classification. <em>IJMLC</em>,
<em>12</em>(5), 1311–1342. (<a
href="https://doi.org/10.1007/s13042-020-01235-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we suggest a novel approach termed as regularized based implicit Lagrangian twin extreme learning machine in primal as a pair of unconstrained convex minimization problem (RILTELM) where regularization term is added to follow the structural risk minimization principle. Here, we consider 2-norm of the slack vector of variables to make the problem strongly convex which results in a unique solution. Since it has non-smooth plus functions in their objective function, so we find an approximate solution by replacing the non-smooth plus function with smooth approximation function because to find an approximation solution in primal space is always superior to its dual. Due to non-smooth plus function, we solve the problem by either smooth approximation approach or generalized derivative approach. In addition, a functional iterative scheme is also suggested to find the optimal solution. Hence, no external optimization toolbox is required unlike in twin extreme learning machine (TELM) and twin support vector machine (TWSVM). The numerical experiments are demonstrated on artificial and real-world datasets and compared with TWSVM, ELM, TELM and LSTELM to establish the efficacy and applicability of proposed RILTELM.},
  archive      = {J_IJMLC},
  author       = {Gupta, Umesh and Gupta, Deepak},
  doi          = {10.1007/s13042-020-01235-y},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {5},
  pages        = {1311-1342},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Regularized based implicit lagrangian twin extreme learning machine in primal for pattern classification},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Hierarchical extreme learning machine with l21-norm loss and
regularization. <em>IJMLC</em>, <em>12</em>(5), 1297–1310. (<a
href="https://doi.org/10.1007/s13042-020-01234-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, multilayer extreme learning machine (ELM) algorithms have been extensively studied for hierarchical abstract representation learning in the ELM community. In this paper, we investigate the specific combination of $$L_{21}$$ -norm based loss function and regularization to improve the robustness and the sparsity of multilayer ELM. As we all known, the mean square error (MSE) cost function (or squared $$L_{2}$$ -norm cost function) is commonly used as optimization cost function for ELM, but it is sensitive to outliers and impulsive noises that are pervasive in real-world data. Our $$L_{21}$$ -norm loss function can lessen the harmful influence caused by noises and outliers and enhance robustness and stability of the learned model. Additionally, the row sparse inducing $$L_{21}$$ -norm regularization can learn the most-relevant sparse representation and reduce the intrinsic complexity of the learning model. We propose a specific combination of $$L_{21}$$ -norm loss function and regularization ELM auto-encoder (LR21-ELM-AE), and then stack LR21-ELM-AE hierarchically to construct the hierarchical extreme learning machine (H-LR21-ELM). Experiments conducted on several well-known benchmark datasets are presented, the results show that the proposed H-LR21-ELM can generate a more robust, more discriminative and sparser model compared with the other state-of-the-art multilayer ELM algorithms.},
  archive      = {J_IJMLC},
  author       = {Li, Rui and Wang, Xiaodan and Song, Yafei and Lei, Lei},
  doi          = {10.1007/s13042-020-01234-z},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {5},
  pages        = {1297-1310},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Hierarchical extreme learning machine with l21-norm loss and regularization},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A social immunity based approach to suppress rumors in
online social networks. <em>IJMLC</em>, <em>12</em>(5), 1281–1296. (<a
href="https://doi.org/10.1007/s13042-020-01233-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Online social networks (OSNs) connect people around the globe under one virtual society. It helps people gather, communate and share their common interests. But many times, OSNs are also exploited and eventually become a major platform for rumor or false information propagation. Controlling such rumors in OSNs has been the most challenging research interest in recent days. Since OSNs are a platform of collective behavior, we focus on a collective rumor containment approach to control or eradicate rumors. In this paper, an anti-rumor information spreading approach is proposed to contain rumors collectively by following a bio-inspired immunization method called social immunity. First, A competitive information propagation model called competitive cascade (CC) model that spreads rumor and true information simultaneously is defined. This model continuously updates the trustworthiness of individuals in the network on every communication among the participants of OSNs. Then, the initial spreaders of anti-rumors are identified with the help of the intensity of the rumor in the network as well as the individual’s trustworthiness. Finally, a collective rumor containment approach is applied by considering the cost of rumor containment and a rumor intensity threshold. The proposed approach is compared with recent and well-known rumor control approaches and the results show that the proposed approach is effective in eradicating rumors.},
  archive      = {J_IJMLC},
  author       = {Srinivasan, Santhoshkumar and L D, Dhinesh Babu},
  doi          = {10.1007/s13042-020-01233-0},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {5},
  pages        = {1281-1296},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A social immunity based approach to suppress rumors in online social networks},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Classifying imbalanced data using SMOTE based class-specific
kernelized ELM. <em>IJMLC</em>, <em>12</em>(5), 1255–1280. (<a
href="https://doi.org/10.1007/s13042-020-01232-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In machine learning, a problem is imbalanced when the class distributions are highly skewed. Imbalanced classification problems occur usually in many application domains and pose a hindrance to the conventional learning algorithms. Several approaches have been proposed to handle the imbalanced learning. For example, Weighted kernel-based SMOTE (WKSMOTE) and SMOTE based class-specific extreme learning machine (SMOTE-CSELM) are recently proposed algorithms that use the minority oversampling to handle imbalanced learning. It has been illustrated in Raghuwanshi and Shukla (Knowl-Based Syst 187(104):814, 2020) that our recently proposed classifier, SMOTE-CSELM outperforms the other state of art classifiers for class imbalance learning. One drawback of SMOTE-CSELM is the performance fluctuation due to the random initialization of weights between the input and the hidden layer. To handle this problem, this work proposes SMOTE based class-specific kernelized extreme learning machine (SMOTE-CSKELM), which uses the Gaussian kernel function to map the input data to the feature space. The proposed work has the advantage of both the minority oversampling and the class-specific regularization coefficients. SMOTE-CSKELM with the Gaussian kernel function also handles the non-optimal hidden node problem associated with the sigmoid node based variants of ELM. To increase the significance of the specific region corresponding to the minority class in the decision boundary, the synthetic minority oversampling technique (SMOTE) is applied to generate synthetic instances for the minority class to balance the training dataset. The proposed work has comparable training time in contrast with the kernelized weighted extreme learning machine (KWELM) for imbalanced learning. The proposed method is determined by employing benchmark real-world imbalanced datasets. The extensive experimental results report that the proposed method outperforms compared to the other state-of-the-art methods for imbalanced learning.},
  archive      = {J_IJMLC},
  author       = {Raghuwanshi, Bhagat Singh and Shukla, Sanyam},
  doi          = {10.1007/s13042-020-01232-1},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {5},
  pages        = {1255-1280},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Classifying imbalanced data using SMOTE based class-specific kernelized ELM},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A robust spectral clustering algorithm based on
grid-partition and decision-graph. <em>IJMLC</em>, <em>12</em>(5),
1243–1254. (<a
href="https://doi.org/10.1007/s13042-020-01231-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spectral clustering (SC) transforms the dataset into a graph structure, and then finds the optimal subgraph by the way of graph-partition to complete the clustering. However, SC algorithm constructs the similarity matrix and feature decomposition for overall datasets, which needs high consumption. Secondly, k-means is taken at the clustering stage and it selects the initial cluster centers randomly, which leads to the unstable performance. Thirdly, SC needs prior knowledge to determine the number of clusters. To deal with these issues, we propose a robust spectral clustering algorithm based on grid-partition and decision-graph (PRSC) to reduce the amount of calculation and improve the clustering efficiency. In addition, a decision-graph method is added to identify the cluster centers quickly to improve the algorithm stability without any prior knowledge. A numerical experiments validate that PRSC algorithm can effectively improve the efficiency of SC. It can quickly obtain the stable performance without any prior knowledge.},
  archive      = {J_IJMLC},
  author       = {Wang, Lijuan and Ding, Shifei and Wang, Yanru and Ding, Ling},
  doi          = {10.1007/s13042-020-01231-2},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {5},
  pages        = {1243-1254},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A robust spectral clustering algorithm based on grid-partition and decision-graph},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). MAGDM-oriented dual hesitant fuzzy multigranulation
probabilistic models based on MULTIMOORA. <em>IJMLC</em>,
<em>12</em>(5), 1219–1241. (<a
href="https://doi.org/10.1007/s13042-020-01230-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In real world, multi-attribute group decision making (MAGDM) is a complicated cognitive process that involves expression, fusion and analysis of multi-source uncertain information. Among diverse soft computing tools for addressing MAGDM, the ones from granular computing (GrC) frameworks perform excellently via efficient strategies for multi-source uncertain information. However, they usually lack convincing semantic interpretations for MAGDM due to extreme information fusion rules and instabilities of information analysis mechanisms. This work adopts a typical GrC framework named multigranulation probabilistic models to enrich semantic interpretations for GrC-based MAGDM approaches, and constructs MAGDM-oriented multigranulation probabilistic models with dual hesitant fuzzy (DHF) information in light of the MULTIMOORA (Multi-Objective Optimization by Ratio Analysis plus the full MULTIplicative form) method. After reviewing several basic knowledge, we first put forward four types of DHF multigranulation probabilistic models. Then, according to the MULTIMOORA method, a DHF MAGDM algorithm is designed via the proposed theoretical models in the context of person-job (P-J) fit. Finally, an illustrative case study for P-J fit is investigated, and corresponding validity tests and comparative analysis are conducted as well to demonstrate the rationality of the presented models.},
  archive      = {J_IJMLC},
  author       = {Zhang, Chao and Li, Deyu and Liang, Jiye and Wang, Baoli},
  doi          = {10.1007/s13042-020-01230-3},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {5},
  pages        = {1219-1241},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {MAGDM-oriented dual hesitant fuzzy multigranulation probabilistic models based on MULTIMOORA},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A hybrid of XGBoost and aspect-based review mining with
attention neural network for user preference prediction. <em>IJMLC</em>,
<em>12</em>(5), 1203–1217. (<a
href="https://doi.org/10.1007/s13042-020-01229-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of the internet, users tend to refer to the rating scores or review opinions on social platforms. Most recommendation systems use collaborative filtering (CF) methods to recommend items based on users’ ratings. The rating-based CF methods do not consider users’ review opinions on different aspects of items. The accuracy of the rating predictions can be effectively improved by considering the latent semantics and various aspects of user reviews. In this paper, a novel rating prediction method is proposed according to an attention-based gated recurrent unit (GRU) deep learning model with semantic aspects. A two-phase method is proposed herein; it combines the word attention mechanism and review semantics to extract aspect features from user preferences. In the first phase, a bidirectional GRU neural network is adopted according to word attention in order to extract important words from users’ reviews. In the second phase, we split users’ reviews into words, and generate the aspect-based attention semantic vectors from these reviews based on Latent Dirichlet Allocation and the attention weights of the chosen words. The XGBoost method is then adopted to predict user preference ratings based on the aspect-based attention semantic vectors. The experimental results show that the proposed method outperforms traditional prediction methods and effectively improves the accuracy of predictions.},
  archive      = {J_IJMLC},
  author       = {Lai, Chin-Hui and Liu, Duen-Ren and Lien, Kun-Sin},
  doi          = {10.1007/s13042-020-01229-w},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {5},
  pages        = {1203-1217},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A hybrid of XGBoost and aspect-based review mining with attention neural network for user preference prediction},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Class-weighted neural network for monotonic imbalanced
classification. <em>IJMLC</em>, <em>12</em>(4), 1191–1201. (<a
href="https://doi.org/10.1007/s13042-020-01228-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In real life scenarios, classification problems with the characters of monotonicity constraints and imbalanced class distribution widely exist. However, at present, the research on this kind of problem is still rare. Traditional algorithms designed only for monotonic classification and imbalanced classification are not available for monotonic imbalanced classification. So far, there is only one approach specially designed for monotonic imbalanced classification problems, which is based on the resampling technique. In this paper, from the algorithmic point of view, we propose a weighted single-hidden-layer feedforward neural network (WMCS-SLFN) based on multi-objective genetic algorithm, where both the monotonicity constraints and the imbalanced distribution are considered. Additionally, in order to improve the generalization capability of WMCS-SLFN, we put forward a selective ensemble strategy for WMCS-SLFN based on the 0–1 knapsack problem, which can generate an ensemble of WMCS-SLFN with the optimal prediction accuracy under the monotonicity constraints. Contrast experiments conducted on eight monotonic imbalanced datasets verify the effectiveness of our proposed methods, and moreover, the experimental results analyzed by Wilcoxon statistical test highlight the advantage of our work significantly.},
  archive      = {J_IJMLC},
  author       = {Zhu, Hong and Liu, Han and Fu, Aimin},
  doi          = {10.1007/s13042-020-01228-x},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {4},
  pages        = {1191-1201},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Class-weighted neural network for monotonic imbalanced classification},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Towards wide-scale continuous gesture recognition model for
in-depth and grayscale input videos. <em>IJMLC</em>, <em>12</em>(4),
1173–1189. (<a
href="https://doi.org/10.1007/s13042-020-01227-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, gesture recognition in video sequences has aroused growing interest in the fields of computer vision and behavioral understanding, for example in the control of robots and video games, in the field of video surveillance, automatic video indexing or content-based video retrieval. Processing large-scale continuous gesture data with in-depth, grayscale input videos remains a primary challenge for academic researchers. A wide range of recognition models have been proposed to solve this problem but have not proven their great performance. The main contribution of this article to address this problem is to segment the sequences of continuous gestures into isolated gestures, using the average of the velocity information calculated on the basis of the estimate of the deep optical flow, and to extract a set of relevant descriptors, called characteristics. signature, in order to characterize different intensities and spatial information describing the location, speed and orientation of movement. Finally, to transmit to a linear SVM the characteristics built for the depth and gray scale sequences, for each isolated segment for its classification. The experimental study carried out on the various standard data collections namely KTH, Chalearn and Weizmann, on our model and on the main models that we have studied in the literature, as well as the analysis of the results, which we obtained, clearly show the limits of these studied models and confirms the performance of our model as well as efficiency in terms of precision, recall and robustness.},
  archive      = {J_IJMLC},
  author       = {Mahmoud, Rihem and Belgacem, Selma and Omri, Mohamed Nazih},
  doi          = {10.1007/s13042-020-01227-y},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {4},
  pages        = {1173-1189},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Towards wide-scale continuous gesture recognition model for in-depth and grayscale input videos},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Automated worker skill evaluation for improving productivity
based on labeled LDA. <em>IJMLC</em>, <em>12</em>(4), 1151–1171. (<a
href="https://doi.org/10.1007/s13042-020-01226-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposed automated systems for analyzing elemental processes and for evaluating work skills. The systems use labeled latent Dirichlet allocation (L-LDA) to classify worker motions obtained from sensors into four elemental processes. L-LDA automatically learns characteristic motions, so there is no need to define and identify motion features. The proposed system predicts elemental processes with over 86.9\% recall in experiments using the assembly process data. Analyst burden is greatly reduced as compared to systems requiring manual analysis of elemental processes from recorded task data. The system evaluates worker skills based on analyzed time series data for elemental processes in four categories, namely, correctness, stability, speed, and rhythm. As a result, the evaluation system clarifies workers’ strong and weak points in tasks performed in experiments, providing new knowledge that would be unobtainable under conventional evaluation methods. Manufacturing efficiency can be improved by allocating workers based on their strengths, and training efficiency will be improved when workers’ weak areas are revealed.},
  archive      = {J_IJMLC},
  author       = {Mori, Kentaro and Nakajima, Hiroshi and Hata, Yutaka},
  doi          = {10.1007/s13042-020-01226-z},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {4},
  pages        = {1151-1171},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Automated worker skill evaluation for improving productivity based on labeled LDA},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). UsfAD: A robust anomaly detector based on unsupervised
stochastic forest. <em>IJMLC</em>, <em>12</em>(4), 1137–1150. (<a
href="https://doi.org/10.1007/s13042-020-01225-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In real-world applications, data can be represented using different units/scales. For example, weight in kilograms or pounds and fuel-efficiency in km/l or l/100 km. One unit can be a linear or non-linear scaling of another. The variation in metrics due to the non-linear scaling makes Anomaly Detection (AD) challenging. Most existing AD algorithms rely on distance- or density-based functions, which makes them sensitive to how data is expressed. This means that they are representation dependent. To avoid such a problem, we introduce a new anomaly detection method, which we call ‘usfAD: Unsupervised Stochastic Forest-based Anomaly Detector’. Our empirical evaluation in synthetic and real-world cybersecurity (spam detection, malicious URL detection and intrusion detection) datasets shows that our approach is more robust to the variation in units/scales used to express data. It produces more consistent and better results than five state-of-the-art AD methods namely: local outlier factor; one-class support vector machine; isolation forest; nearest neighbor in a random subsample of data; and, simple histogram-based probabilistic method.},
  archive      = {J_IJMLC},
  author       = {Aryal, Sunil and Santosh, K.C. and Dazeley, Richard},
  doi          = {10.1007/s13042-020-01225-0},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {4},
  pages        = {1137-1150},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {UsfAD: A robust anomaly detector based on unsupervised stochastic forest},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Recurrence quantification analysis of EEG signals for
tactile roughness discrimination. <em>IJMLC</em>, <em>12</em>(4),
1115–1136. (<a
href="https://doi.org/10.1007/s13042-020-01224-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Roughness recognition is an important function in the nervous system that facilitates our interactions with the environment. Previous studies have focused on the neuro-cognitive aspects and frequency-based changes in response to the roughness stimuli. In this study, we investigate the effect of different roughness levels on the nonlinear characteristics of EEG signals. Nine healthy subjects participated in the current research and touched three surfaces with different levels of roughness in a passive dynamical way. The experiment was repeated for both hands separately. During the experiment, the EEG signals were recorded. Next, three nonlinear features were extracted using the recurrence quantification analysis (RQA) method; and four classifiers were hired to distinguish six conditions, including three levels of roughness and the touching hand. The results showed that EEG nonlinear characteristics were significantly affected by the variation of surface roughness. The effects were different between touching by the left or the right hand. Moreover, it was observed that employing the RQA-based features leads to the higher accuracy of classification compared to the conventional frequency-based features. Additionally, we found that the brain representation of tactile roughness has a pseudo-random dynamic, and the amount of roughness can influence a network of brain channels. Finally, utilizing the weighted combination of different brain channels while considering the extracted nonlinear features, the LDA classification accuracy was reached 93\%. Therefore, it can be suggested that not only temporal variations of brain signals but also their spatial distribution (brain channels) are important to recognize the surface roughness.},
  archive      = {J_IJMLC},
  author       = {Baghdadi, Golnaz and Amiri, Mahmood and Falotico, Egidio and Laschi, Cecilia},
  doi          = {10.1007/s13042-020-01224-1},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {4},
  pages        = {1115-1136},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Recurrence quantification analysis of EEG signals for tactile roughness discrimination},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Dynamic clustering collaborative filtering recommendation
algorithm based on double-layer network. <em>IJMLC</em>, <em>12</em>(4),
1097–1113. (<a
href="https://doi.org/10.1007/s13042-020-01223-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of internet economy, personal recommender system plays an increasingly important role in e-commerce. In order to improve the quality of recommendation, a variety of scholars and engineers devoted themselves in developing the recommendation algorithms. Traditional collaborative filtering algorithms are only dependent on rating information or attribute information. Most of them were considered in perspective of a single-layer network, which destroyed the original hierarchy of data and resulted in sparse matrix and poor timeliness. In order to address these problems and improve the accuracy of recommendation, dynamic clustering collaborative filtering recommendation algorithm based on double-layer network is put forward in this paper. Firstly, attribute information of users and items are respectively used to construct the user layer network and the item layer network. Secondly, new hierarchical clustering method is further presented, which separates users into different communities according to dynamic evolutionary clustering. Finally, score prediction and top-N recommendation lists are obtained by similarity between users in each community. Extensive experiments are conducted with three real datasets, and the effectiveness of our algorithm is verified by different metrics.},
  archive      = {J_IJMLC},
  author       = {Chen, Jianrui and Wang, Bo and Ouyang, Zhiping and Wang, Zhihui},
  doi          = {10.1007/s13042-020-01223-2},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {4},
  pages        = {1097-1113},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Dynamic clustering collaborative filtering recommendation algorithm based on double-layer network},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An algorithm based on valuation forecasting for game tree
search. <em>IJMLC</em>, <em>12</em>(4), 1083–1095. (<a
href="https://doi.org/10.1007/s13042-020-01222-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study proposes a novel best-first search algorithm, called Valuation Increment Search Algorithm (VIS), which applies the increment of exploratory value change to predict the valuation and guide the selection of the game tree. The proposed method can effectively use node valuation and game tree size information to solve the game tree by fewer exploration steps. The relevant assumptions and search principles of the proposed algorithm are detailed. Moreover, comparative experiments with Alpha–Beta Search (α–β search), Proof-Number Search (PNS) and Monte-Carlo Tree Search (MCTS) in the domain of Dou Dizhu has been performed to verify the performance. Result demonstrate that VIS is superior to α–β search, PNS and MCTS algorithm in solving the game tree and finding the best move for some game scenarios by consuming less time and few memory resources. The improvement effect of the average Increment, magnitude of Increment, and the number of visits to node on the original VIS was validated. Also, a new selection strategy is defined for the improved VIS algorithm combined with these factors. The experimental comparison results show that improved VIS has a better performance in solving game tree with less nodes generated and expanded than original VIS.},
  archive      = {J_IJMLC},
  author       = {Tan, Guangyun and Wei, Peipei and He, Yongyi and Xu, Huahu and Shi, Xinxin and Yi, Ping},
  doi          = {10.1007/s13042-020-01222-3},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {4},
  pages        = {1083-1095},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {An algorithm based on valuation forecasting for game tree search},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Knowledge-driven graph similarity for text classification.
<em>IJMLC</em>, <em>12</em>(4), 1067–1081. (<a
href="https://doi.org/10.1007/s13042-020-01221-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic text classification using machine learning is significantly affected by the text representation model. The structural information in text is necessary for natural language understanding, which is usually ignored in vector-based representations. In this paper, we present a graph kernel-based text classification framework which utilises the structural information in text effectively through the weighting and enrichment of a graph-based representation. We introduce weighted co-occurrence graphs to represent text documents, which weight the terms and their dependencies based on their relevance to text classification. We propose a novel method to automatically enrich the weighted graphs using semantic knowledge in the form of a word similarity matrix. The similarity between enriched graphs, knowledge-driven graph similarity, is calculated using a graph kernel. The semantic knowledge in the enriched graphs ensures that the graph kernel goes beyond exact matching of terms and patterns to compute the semantic similarity of documents. In the experiments on sentiment classification and topic classification tasks, our knowledge-driven similarity measure significantly outperforms the baseline text similarity measures on five benchmark text classification datasets.},
  archive      = {J_IJMLC},
  author       = {Shanavas, Niloofer and Wang, Hui and Lin, Zhiwei and Hawe, Glenn},
  doi          = {10.1007/s13042-020-01221-4},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {4},
  pages        = {1067-1081},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Knowledge-driven graph similarity for text classification},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Matrix-based incremental updating approximations in
multigranulation rough set under two-dimensional variation.
<em>IJMLC</em>, <em>12</em>(4), 1041–1065. (<a
href="https://doi.org/10.1007/s13042-020-01219-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multigranulation rough set model (MGRS) uses multiple equivalence relations on the universe to calculate the approximations, which can solve problem in mutigranulation spaces. In practical applications, information systems often dynamically update due to the variation of objects, attributes or attribute values. Incremental approach is an effective method to calculate approximations for dynamically updated information system. However, existing incremental updating approximations in MGRS mainly focus on single-dimensional variation of objects, attributes or attribute values respectively, without considering multi-dimensional variation of objects, attributes and attribute values. In this paper, we propose matrix-based incremental updating approximations in multigranulation rough set under two-dimensional variation of objects, attributes and attribute values. One is the simultaneous variation of objects and attributes (VOA). The other is the simultaneous variation of objects and attribute values (VOV). First, we give the incremental approaches to update the relevant matrices for the dynamically updated information system due to VOA and VOV. Second, based on the updated matrices, we propose two matrix-based incremental algorithms to update approximations. Finally, examples and experimental results demonstrate the effectiveness of the proposed algorithms for incremental updating approximations in multigranulation rough set under two-dimensional variation.},
  archive      = {J_IJMLC},
  author       = {Xu, Yi and Wang, Quan and Sun, Weikang},
  doi          = {10.1007/s13042-020-01219-y},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {4},
  pages        = {1041-1065},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Matrix-based incremental updating approximations in multigranulation rough set under two-dimensional variation},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Dynamic fusion for ensemble of deep q-network.
<em>IJMLC</em>, <em>12</em>(4), 1031–1040. (<a
href="https://doi.org/10.1007/s13042-020-01218-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ensemble reinforcement learning, which combines the decisions of a set of base agents, is proposed to enhance the decision making process and speed up training time. Many studies indicate that an ensemble model may achieve better results than a single agent because of the complement of base agents, in which the error of an agent may be corrected by others. However, the fusion method is a fundamental issue in ensemble. Currently, existing studies mainly focus on static fusion which either assumes all agents have the same ability or ignores the ones with poor average performance. This assumption causes current static fusion methods to overlook base agents with poor overall performance, but excellent results in select scenarios, which results in the ability of some agents not being fully utilized. This study aims to propose a dynamic fusion method which utilizes each base agent according to its local competence on test states. The performance of a base agent on the validation set is measured in terms of the rewards achieved by the agent in next n steps. The similarity between a validation state and a new state is quantified by Euclidian distance in the latent space and the weights of each base agent are updated according to its performance on validation states and their similarity to a new state. The experimental studies confirm that the proposed dynamic fusion method outperforms its base agents and also the static fusion methods. This is the first dynamic fusion method proposed for deep reinforcement learning, which extends the study on dynamic fusion from classification to reinforcement learning.},
  archive      = {J_IJMLC},
  author       = {Chan, Patrick P. K. and Xiao, Meng and Qin, Xinran and Kees, Natasha},
  doi          = {10.1007/s13042-020-01218-z},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {4},
  pages        = {1031-1040},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Dynamic fusion for ensemble of deep Q-network},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Dynamic pricing in profit-driven task assignment: A
domain-of-influence based approach. <em>IJMLC</em>, <em>12</em>(4),
1015–1030. (<a
href="https://doi.org/10.1007/s13042-020-01217-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The development of mobile Internet and sharing economy brings the prosperity of spatial crowdsourcing (SC). Pricing is a crucial step for SC platforms to solve the Profit-driven Task Assignment (PTA) problem to maximize their total profit. However, dynamic pricing is still large unexplored in PTA. In addition, existing works seek solutions without considering the uncertainty of workers’ acceptance for assigned tasks in the task assignment process. To deal with these challenges, we develop a two-stage task assignment framework with dynamic pricing. Specifically, we propose a novel Domain-of-Influence based dynamic pricing algorithm, which can iteratively figure out the price that represents the balance between task demand and worker supply. Then we employ hyperbolic temporal discounting function to estimate the worker’s psychological reward that indicates the acceptance or rejection of assigned task. With considering the driver’s psychological reward, we adopt an optimal algorithm to achieve the optimal task assignment and propose greedy algorithms to improve the computational efficiency. Finally, we evaluate the performance using two road network datasets of Jinan and Luoyang in China. The experimental results show the effectiveness and efficiency of our proposed approaches.},
  archive      = {J_IJMLC},
  author       = {Zhou, Zhifeng and Chen, Rong and Wang, Can and Zhang, Chengwei},
  doi          = {10.1007/s13042-020-01217-0},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {4},
  pages        = {1015-1030},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Dynamic pricing in profit-driven task assignment: A domain-of-influence based approach},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Knowledge representation and reasoning with industrial
application using interval-valued intuitionistic fuzzy petri nets and
extended TOPSIS. <em>IJMLC</em>, <em>12</em>(4), 987–1013. (<a
href="https://doi.org/10.1007/s13042-020-01216-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fuzzy Petri nets (FPNs) have many successes in various applications as an important modeling technique for knowledge representation and reasoning. However, in the real world, the following conditions may make it difficult to precisely model knowledge based on current FPNs, including the cognitive nonconformity, fuzziness and uncertainty of experiential cognition of experts. In an effort to overcome the shortcomings of current FPNs, the interval-valued intuitionistic FPNs (IVIFPNs) are proposed based on interval-valued intuitionistic fuzzy sets (IVIFSs), IVIFSs hybrid averaging (IVIFSsHA) operator and extended TOPSIS (ETOPSIS). Combining with IVIFSsHA operator, an inference algorithm based on matrix operation is proposed to improve the efficiency of computing final truth values. In addition, an optimal alternative is determined based on the proposed ETOPSIS, in which intuitionistic information and fuzzy information can be considered simultaneously based on the proposed information collaborative entropy. Finally, a comparison test is presented to show the effectiveness of ETOPSIS. Moreover, a novel model for the identification of aluminum electrolysis cell condition is proposed based on IVIFPNs and ETOPSIS, and the application result shows that the proposed methods are efficient to deal with cognitive nonconformity and manage fuzziness and uncertainty of expert knowledge. These facts demonstrate the usefulness and advantages of the proposed methods in complex real-world applications.},
  archive      = {J_IJMLC},
  author       = {Yue, Weichao and Liu, Xiao and Li, Sanyi and Gui, Weihua and Xie, Yongfang},
  doi          = {10.1007/s13042-020-01216-1},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {4},
  pages        = {987-1013},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Knowledge representation and reasoning with industrial application using interval-valued intuitionistic fuzzy petri nets and extended TOPSIS},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An improved TODIM method based on the hesitant fuzzy
psychological distance measure. <em>IJMLC</em>, <em>12</em>(4), 973–985.
(<a href="https://doi.org/10.1007/s13042-020-01215-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The distance measure plays an important role in the hesitant fuzzy theory. Experts always focus on the attributes aggregation of hesitant fuzzy information, ignoring the preference relationships between alternatives. Therefore, it is necessary to consider the competition effect between alternatives and develop a more suitable distance measure. Considering the background information of the connections and competitive relationships between different alternatives, the hesitant fuzzy psychological distance measure is proposed. Based on which, a novel similarity measure for hesitant fuzzy information is also developed. Next, an improved TODIM based on the hesitant fuzzy psychological distance measure is proposed for decision making problems. At last but not least, we apply the proposed improved TODIM to the application of the temporary rescue airport decision making problem of the Arctic Northwest Passage. The results demonstrate the advantages of the proposed method in decision making under the hesitant fuzzy environment.},
  archive      = {J_IJMLC},
  author       = {Song, Chenyang and Xu, Zeshui and Hou, Jian},
  doi          = {10.1007/s13042-020-01215-2},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {4},
  pages        = {973-985},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {An improved TODIM method based on the hesitant fuzzy psychological distance measure},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A novel BNMF-DNN based speech reconstruction method for
speech quality evaluation under complex environments. <em>IJMLC</em>,
<em>12</em>(4), 959–972. (<a
href="https://doi.org/10.1007/s13042-020-01214-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Speech quality evaluation (SQE) under complex noisy environment is important for audio processing systems and quality of service. Recently, the non-intrusive SQE is getting more and more attentive due to its efficient and ease of use. However, non-intrusive SQEs are expected to be underperformed the intrusive ones since it has no prior knowledge of the clean speech. In this paper, a novel quasi-clean speech reconstruction method for non-intrusive SQE is proposed. The method incorporates Bayesian NMF (BNMF) with deep neural network (DNN), which takes the advantages of both NMF and DNN. BNMF is utilized to calculate the basic spectro-temporal matrixes of target speech, and the obtained matrices are integrated into the DNN model as an individual layer. Then DNN is trained to learn the complex mapping between the target source and the mixture signal, and reconstruct the magnitude spectrograms of the quasi-clean speech. Finally, the reconstructed speech is regarded as the reference of the perceptual model to estimate the Mean opinion score of the tested noisy sample. The experiment results show that the proposed method outperforms the comparative non-intrusive SQE algorithms under challenging conditions in terms of objective measurement.},
  archive      = {J_IJMLC},
  author       = {Zhou, Weili and Zhu, Zhen},
  doi          = {10.1007/s13042-020-01214-3},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {4},
  pages        = {959-972},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A novel BNMF-DNN based speech reconstruction method for speech quality evaluation under complex environments},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A hybrid many-objective competitive swarm optimization
algorithm for large-scale multirobot task allocation problem.
<em>IJMLC</em>, <em>12</em>(4), 943–957. (<a
href="https://doi.org/10.1007/s13042-020-01213-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large-scale multi-robot task allocation (MRTA) problem is an important part of intelligent logistics scheduling. And the load capacity of robot and picking station are important factors affecting the MRTA problem. In this paper, the MRTA problem is built as a many-objective optimization model with four objectives, which takes the load capacity of single robot, single picking station, all robots and all picking stations into account. To solve the model, a hybrid many-objective competitive swarm optimization (HMaCSO) algorithm is designed. The novel selection method employing two different measurement mechanisms will form the mating selection operation. Then the population will be updated by employing the competitive swarm optimization strategy. Meanwhile, the environment selection will play a role in choosing the excellent solution. To prove the superiority of our approach, there are two series of experiments are carried out. On the one hand, our approach is compared with other five famous many-objective algorithms on benchmark problem. On the other hand, the involved algorithms are applied in solving large-scale MRTA problem. Simulation results prove that the performance of our approach is superior than other algorithms.},
  archive      = {J_IJMLC},
  author       = {Xue, Fei and Dong, Tingting and You, Siqing and Liu, Yan and Tang, Hengliang and Chen, Lei and Yang, Xi and Li, Juntao},
  doi          = {10.1007/s13042-020-01213-4},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {4},
  pages        = {943-957},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A hybrid many-objective competitive swarm optimization algorithm for large-scale multirobot task allocation problem},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Dense crowd counting based on adaptive scene division.
<em>IJMLC</em>, <em>12</em>(4), 931–942. (<a
href="https://doi.org/10.1007/s13042-020-01212-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of computer vision and artificial intelligence, crowd counting has attracted significant attention from researchers and many well-known methods were proposed. However, due to interocclusions, perspective distortion, and uneven crowd distribution, crowd counting is still a highly challenging task in crowd analysis. Motivated by granular computing, a novel end-to-end crowd counting network (GrCNet) is proposed to enable the problem of crowd counting to be conceptualized at different levels of granularity, and to map problem into computationally tractable subproblems. It shows that by adaptively dividing the image into granules and then feeding the granules into different counting subnetworks separately, the scale variation range of image is narrowed and the the adaptability of counting algorithm to different scenarios is improved. Experiments on four well-known crowd counting benchmark datasets indicate that GrCNet achieves state-of-the-art counting performance and high robustness in dense crowd counting.},
  archive      = {J_IJMLC},
  author       = {Yu, Ying and Zhu, Huilin and Wang, Lewei and Pedrycz, Witold},
  doi          = {10.1007/s13042-020-01212-5},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {4},
  pages        = {931-942},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Dense crowd counting based on adaptive scene division},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A two-sided matching method considering the lowest value of
acceptability with regret theory for probabilistic linguistic term sets.
<em>IJMLC</em>, <em>12</em>(4), 917–930. (<a
href="https://doi.org/10.1007/s13042-020-01211-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to solve matching problems for probabilistic linguistic information, a novel two-sided matching decision method for the probabilistic linguistic term sets (PLTSs) based on the regret theory considering the lowest value of acceptability is proposed. First, we propose a new utility function to transform the PLTSs to utility values, which can be conveniently applied to two-sided matching models. Then, to reflect the bounded rationality of expert and make the decision result close to real decision process, we put forward a novel regret-based model to obtain regret-rejoice by setting the lowest value of acceptability based on the utility function. Furthermore, we presented a new type of two-sided matching method considering constraint condition based on the lowest value of acceptability. Finally, we apply our method to a real case and make comparisons with two traditional two-sided methods.},
  archive      = {J_IJMLC},
  author       = {Li, Peng and Wang, Nannan and Wei, Cuiping and Zhang, Na},
  doi          = {10.1007/s13042-020-01211-6},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {4},
  pages        = {917-930},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A two-sided matching method considering the lowest value of acceptability with regret theory for probabilistic linguistic term sets},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Balanced graph-based regularized semi-supervised extreme
learning machine for EEG classification. <em>IJMLC</em>, <em>12</em>(4),
903–916. (<a href="https://doi.org/10.1007/s13042-020-01209-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning algorithms play a critical role in electroencephalograpy (EEG)-based brain-computer interface (BCI) systems. However, collecting labeled samples for classifier training and calibration is still difficult and time-consuming, especially for patients. As a promising alternative way to address the problem, semi-supervised learning has attracted much attention by exploiting both labeled and unlabeled samples in the training process. Nowadays, semi-supervised extreme learning machine (SS-ELM) is widely used in EEG classification due to its fast training speed and good generalization performance. However, the classification performance of SS-ELM largely depends on the quality of sample graph. The graphs of most semi-supervised algorithms are constructed by the similarity between labeled and unlabeled data called manifold graph. The more similar the structural information between samples, the greater probability they belong to the same class. In this paper, the label-consistency graph (LCG) and sample-similarity graph (SSG) are combined to constrain the model output. When the SSG is not accurate enough, the weight of LCG needs to be increased, and vice versa. The weight ratio of two graphs is optimized to obtain an optimal adjacency graph, and finally the best output weight vector is achieved. To verify the effectiveness of the proposed algorithm, it was validated and compared with several existing methods on two real datasets: BCI Competition IV Dataset 2a and BCI Competition III Dataset 4a. Experimental results show that our algorithm has achieved the promising results, especially when the number of labeled samples is small.},
  archive      = {J_IJMLC},
  author       = {She, Qingshan and Zou, Jie and Meng, Ming and Fan, Yingle and Luo, Zhizeng},
  doi          = {10.1007/s13042-020-01209-0},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {4},
  pages        = {903-916},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Balanced graph-based regularized semi-supervised extreme learning machine for EEG classification},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Improved TODIM method for intuitionistic fuzzy MAGDM based
on cumulative prospect theory and its application on stock investment
selection. <em>IJMLC</em>, <em>12</em>(3), 891–901. (<a
href="https://doi.org/10.1007/s13042-020-01208-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The stock investment selection could be regarded as a classical multiple attribute group decision making (MAGDM) issue. The intuitionistic fuzzy sets (IFSs) can fully describes the uncertain information for stock investment selection. Furthermore, the classical TODIM method based on the cumulative prospect theory (CPT-TODIM) is built, which is a selectable method in reflecting the DMs’ psychological behavior. Thus, in this paper, the intuitionistic fuzzy CPT-TODIM (IF-CPT-TODIM) method is proposed for MAGDM issue. At the same time, it is enhancing rationality to get the weight information of attributes by using the CRITIC method under IFSs. And focusing on hot issues in contemporary society, this article applies the discussed method for stock investment selection and demonstrates for stock investment selection based on the proposed method. Finally, through comparing the outcome of comparative analysis, we conclude that this improved approach is acceptable.},
  archive      = {J_IJMLC},
  author       = {Zhao, Mengwei and Wei, Guiwu and Wei, Cun and Wu, Jiang},
  doi          = {10.1007/s13042-020-01208-1},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {3},
  pages        = {891-901},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Improved TODIM method for intuitionistic fuzzy MAGDM based on cumulative prospect theory and its application on stock investment selection},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Towards learning line descriptors from patches: A new
paradigm and large-scale dataset. <em>IJMLC</em>, <em>12</em>(3),
877–890. (<a href="https://doi.org/10.1007/s13042-020-01207-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Line feature description is important for image matching. However, its development is much slow compared to point description, and is still in the stage of manual design, which suffers from the problem of weak distinguish ability and poor robustness under complex conditions. To improve on this situation, this paper proposes to learn the line feature description based on convolutional neural network. First, a large-scale dataset consisting of about 229,000 labeled pairs of matched lines is built for training and testing. Then, a paradigm for learning the line descriptors based on the constructed line dataset is proposed. Specifically, the line is represented uniquely by the stacked mean and standard deviation patches of the support regions of those points lying on the line, which is subsequently fed into the L2Net to output the required line descriptors directly. Based on the line matching principals, the network is also trained with the triplet loss that is widely used for learning point descriptors. Experimental results for line matching and curve matching both demonstrate the superiority and effectiveness of the proposed learning-based descriptor, especially, averaged increases of 4.66 ~ 5.7\% mAPs, 10.59 ~ 12.10\% mAPs, 0.96 ~ 3.75\% mAPs and 3.73\% mAP on testing subset, Oxford dataset, line dataset and curve dataset are obtained compared to handcrafted descriptors. As an application, we apply the learned line descriptor to image stitching and also obtain good results.},
  archive      = {J_IJMLC},
  author       = {Liu, Hongmin and Liu, Yujie and Fu, Miaomiao and Wei, Yuhui and Huo, Zhanqiang and Qiao, Yingxu},
  doi          = {10.1007/s13042-020-01207-2},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {3},
  pages        = {877-890},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Towards learning line descriptors from patches: A new paradigm and large-scale dataset},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Intuitionistic fuzzy c-means clustering algorithm based on a
novel weighted proximity measure and genetic algorithm. <em>IJMLC</em>,
<em>12</em>(3), 859–875. (<a
href="https://doi.org/10.1007/s13042-020-01206-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the era of big data, the research on clustering technologies is a popular topic because they can discover the structure of complex data sets with minimal prior knowledge. Among the existing soft clustering technologies, as an extension of fuzzy c-means (FCM) algorithm, the intuitionistic FCM (IFCM) algorithm has been widely used due to its superiority in reducing the effects of outliers/noise and improving the clustering accuracy. In the existing IFCM algorithm, the measurement of proximity degree between a pair of objects and the determination of parameters are two critical problems, which have considerable effects on the clustering results. Therefore, we propose an improved IFCM clustering technique in this paper. Firstly, a novel weighted proximity measure, which aggregates weighted similarity and correlation measures, is proposed to evaluate not only the closeness degree but also the linear relationship between two objects. Subsequently, genetic algorithms are utilized for identifying the optimal parameters. Lastly, experiments on the proposed IFCM technique are conducted on synthetic and UCI data sets. Comparisons with other approaches in cluster evaluation indexes indicate the effectiveness and superiority of our method.},
  archive      = {J_IJMLC},
  author       = {Hou, Wen-hui and Wang, Yi-ting and Wang, Jian-qiang and Cheng, Peng-Fei and Li, Lin},
  doi          = {10.1007/s13042-020-01206-3},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {3},
  pages        = {859-875},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Intuitionistic fuzzy c-means clustering algorithm based on a novel weighted proximity measure and genetic algorithm},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A knowledge discovery and visualisation method for
unearthing emotional states from physiological data. <em>IJMLC</em>,
<em>12</em>(3), 843–858. (<a
href="https://doi.org/10.1007/s13042-020-01205-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we propose a knowledge discovery and visualisation method for unearthing emotional states from physiological data typically available from wearable devices. In addition we investigate the viability of using a limited set of wearable sensors to extract decision tree rules which are representative of physiological changes taking place during emotional changes. Our method utilised a fusion of pre-processing and classification techniques using decision trees to discover logic rules relating to the valence and arousal emotional dimensions. This approach normalised the signal data in a manner that enabled accurate classification and generated logic rules for knowledge discovery. Furthermore, the use of three target classes for the emotional dimensions was effective at denoising the data and further enhancing classification and useful rule extraction. There are three key contributions in this work, firstly an exploration and validation of our knowledge discovery methodology, secondly successful extraction of high accuracy rules derived from physiological data and thirdly knowledge discovery and visualisation of relationships within-participant physiological data that can be inferred relating to emotions. Additionally, this work may be utilised in areas such as the medical sciences where interpretable rules are required for knowledge discovery.},
  archive      = {J_IJMLC},
  author       = {Costadopoulos, Nectarios and Islam, Md Zahidul and Tien, David},
  doi          = {10.1007/s13042-020-01205-4},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {3},
  pages        = {843-858},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A knowledge discovery and visualisation method for unearthing emotional states from physiological data},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Spatiotemporal attention enhanced features fusion network
for action recognition. <em>IJMLC</em>, <em>12</em>(3), 823–841. (<a
href="https://doi.org/10.1007/s13042-020-01204-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, action recognition has become a popular and challenging task in computer vision. Nowadays, two-stream networks with appearance stream and motion stream can make judgment jointly and get excellent action classification results. But many of these networks fused the features or scores simply, and the characteristics in different streams were not utilized effectively. Meanwhile, the spatial context and temporal information were not fully utilized and processed in some networks. In this paper, a novel three-stream network spatiotemporal attention enhanced features fusion network for action recognition is proposed. Firstly, features fusion stream which includes multi-level features fusion blocks, is designed to train the two streams jointly and complement the two-stream network. Secondly, we model the channel features obtained by spatial context to enhance the ability to extract useful spatial semantic features at different levels. Thirdly, a temporal attention module which can model the temporal information makes the extracted temporal features more representative. A large number of experiments are performed on UCF101 dataset and HMDB51 dataset, which verify the effectiveness of our proposed network for action recognition.},
  archive      = {J_IJMLC},
  author       = {Zhuang, Danfeng and Jiang, Min and Kong, Jun and Liu, Tianshan},
  doi          = {10.1007/s13042-020-01204-5},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {3},
  pages        = {823-841},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Spatiotemporal attention enhanced features fusion network for action recognition},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Laplacian regularized low-rank sparse representation
transfer learning. <em>IJMLC</em>, <em>12</em>(3), 807–821. (<a
href="https://doi.org/10.1007/s13042-020-01203-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In unsupervised transfer learning, it is extremely valuable to effectively extract knowledge from the vast amount of untagged data that exists by utilizing tagged data from other similar databases. In general, the data in the real world often resides in the low-dimensional manifold embedded in the high-dimensional environment space. However, the current subspace transfer learning methods do not consider the nonlinear geometry structure inside the data, so the local similarity information between the data may be lost in the learning process. In order to improve this respect, we propose a new subspace transfer learning algorithm, namely Laplacian Regularized Low-Rank Sparse Representation Transfer Learning (LRLRSR-TL). After introducing the low-rank representation and sparse constraints, the method incorporates Laplacian regularization term to represent the global low-dimensional structure and capture the inherent nonlinear geometry information of the data. Experimental investigation conducted based on five different cross-domain visual image datasets shows that the proposed method has outstanding performance compared with several state-of-the-art transfer learning methods.},
  archive      = {J_IJMLC},
  author       = {Guo, Lin and Dai, Qun},
  doi          = {10.1007/s13042-020-01203-6},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {3},
  pages        = {807-821},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Laplacian regularized low-rank sparse representation transfer learning},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A parallel hybrid krill herd algorithm for feature
selection. <em>IJMLC</em>, <em>12</em>(3), 783–806. (<a
href="https://doi.org/10.1007/s13042-020-01202-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a novel feature selection method is introduced to tackle the problem of high-dimensional features in the text clustering application. Text clustering is a prevailing direction in big text mining; in this manner, documents are grouped into cohesive groups by using neatly selected informative features. Swarm-based optimization techniques have been widely used to select the relevant text features and shown promising results on multi-sized datasets. The performance of traditional optimization algorithms tends to fail miserably when using large-scale datasets. A novel parallel membrane-inspired framework is proposed to enhance the performance of the krill herd algorithm combined with the swap mutation strategy (MHKHA). In which the krill herd algorithm is hybridized the swap mutation strategy and incorporated within the parallel membrane framework. Finally, the k-means technique is employed based on the results of feature selection-based Krill Herd Algorithm to cluster the documents. Seven benchmark datasets of various characterizations are used. The results revealed that the proposed MHKHA produced superior results compared to other optimization methods. This paper presents an alternative method for the text mining community through cohesive and informative features.},
  archive      = {J_IJMLC},
  author       = {Abualigah, Laith and Alsalibi, Bisan and Shehab, Mohammad and Alshinwan, Mohammad and Khasawneh, Ahmad M. and Alabool, Hamzeh},
  doi          = {10.1007/s13042-020-01202-7},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {3},
  pages        = {783-806},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A parallel hybrid krill herd algorithm for feature selection},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). MS-NET: Modular selective network. <em>IJMLC</em>,
<em>12</em>(3), 763–781. (<a
href="https://doi.org/10.1007/s13042-020-01201-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a modular architecture of Deep Neural Network (DNN) for multi-class classification task. The architecture consists of two parts, a router network and a set of expert networks. In this architecture, for a C-class classification problem, we have exactly C experts. The backbone network for these experts and the router are built with simple and identical DNN architecture. For each class, the modular network has a certain number $$\rho$$ of expert networks specializing in that particular class, where $$\rho$$ is called the redundancy rate in this study. We demonstrate that $$\rho$$ plays a vital role in the performance of the network. Although these experts are light weight and weak learners alone, together they match the performance of more complex DNNs. We train the network in two phase wherein, first the router is trained on the whole set of training data followed by training each expert network enforced by a new stochastic objective function that facilitates alternative training on a small subset of expert data and the whole set of data. This alternative training provides an additional form of regularization and avoids over-fitting the expert network on subset data. During the testing phase, the router dynamically selects a fixed number of experts for further evaluation of the input datum. The modular nature and low parameter requirement of the network makes it very suitable in distributed and low computational environments. Extensive empirical study and theoretical analysis on CIFAR-10, CIFAR-100 and F-MNIST substantiate the effectiveness and efficiency of our proposed modular network.},
  archive      = {J_IJMLC},
  author       = {Chowdhury, Intisar Md and Su, Kai and Zhao, Qiangfu},
  doi          = {10.1007/s13042-020-01201-8},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {3},
  pages        = {763-781},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {MS-NET: Modular selective network},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A transductive transfer learning approach for image
classification. <em>IJMLC</em>, <em>12</em>(3), 747–762. (<a
href="https://doi.org/10.1007/s13042-020-01200-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Among machine learning paradigms, unsupervised transductive transfer learning is useful when no labeled data from the target domain are available at training time, but there is accessible unlabeled target data during training phase instead. The current paper proposes a novel unsupervised transductive transfer learning method to find the specific and shared features across the source and the target domains. The proposed learning method then maps both domains into the respective subspaces with minimum marginal and conditional distribution divergences. It is shown that the discriminative learning across domains leads to boost the model performance. Hence, the proposed method discriminates the classes of both domains via maximizing the distance between each sample-pairs with different labels and via minimizing the distance between each instance-pairs of the same classes. We verified our approach using standard visual benchmarks, with the average accuracy of 46 experiments as 76.5\%, which rates rather high in comparison with other state-of-the-art transfer learning methods through various cross-domain tasks.},
  archive      = {J_IJMLC},
  author       = {Rezaei, Samaneh and Tahmoresnezhad, Jafar and Solouk, Vahid},
  doi          = {10.1007/s13042-020-01200-9},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {3},
  pages        = {747-762},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A transductive transfer learning approach for image classification},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Nonnegative representation based discriminant projection for
face recognition. <em>IJMLC</em>, <em>12</em>(3), 733–745. (<a
href="https://doi.org/10.1007/s13042-020-01199-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dimensionality reduction (DR) has been widely used to deal with high-dimensional data, and plays an important role in alleviating the so-called “curse of dimensionality”. In this paper, we propose a novel unsupervised DR method with applications to face recognition, i.e., Nonnegative Representation based Discriminant Projection (NRDP). Different with other locality or globality preserving DR methods, NRDP focuses on both locality and nonlocality of data points and learns a discriminant projection by maximizing the nonlocal scatter and minimizing the local scatter simultaneously. A nonnegative representation model is designed in NRDP to discover the local structure and nonlocal structure of data. The $$\ell _1$$ -norm is used as metric in nonnegative representation to enhance the robustness against noises, and an iterative algorithm is presented to solve the optimization model. NRDP is able to learn features with large inter-class or subspace scatter and small intra-class scatter in the case that label information is unavailable, which significantly improves the representation power and discrimination. Experimental results on several popular face datasets demonstrate the effectiveness of our proposed method.},
  archive      = {J_IJMLC},
  author       = {Zhang, Chao and Li, Huaxiong and Chen, Chunlin and Zhou, Xianzhong},
  doi          = {10.1007/s13042-020-01199-z},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {3},
  pages        = {733-745},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Nonnegative representation based discriminant projection for face recognition},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). GDPC: Generalized density peaks clustering algorithm based
on order similarity. <em>IJMLC</em>, <em>12</em>(3), 719–731. (<a
href="https://doi.org/10.1007/s13042-020-01198-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Clustering is a fundamental approach to discover the valuable information in data mining and machine learning. Density peaks clustering is a typical density based clustering and has received increasing attention in recent years. However DPC and most of its improvements still suffer from some drawbacks. For example, it is difficult to find peaks in the sparse cluster regions; assignment for the remaining points tends to cause Domino effect, especially for complicated data. To address the above two problems, we propose generalized density peaks clustering algorithm (GDPC) based on a new order similarity, which is calculated by the order rank of Euclidean distance between two samples. The order similarity can help us to find peaks in the sparse regions. In addition, a two-step assignment is used to weaken Domino effect. In general, GDPC can not only discover clusters in datasets regardless of different sizes, dimensions and shapes, but also address the above two issues. Several experiments on datasets, including Lung, COIL20, ORL, USPS, Mnist, breast and Vote, show that our algorithm is effective in most cases.},
  archive      = {J_IJMLC},
  author       = {Yang, Xiaofei and Cai, Zhiling and Li, Ruijia and Zhu, William},
  doi          = {10.1007/s13042-020-01198-0},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {3},
  pages        = {719-731},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {GDPC: Generalized density peaks clustering algorithm based on order similarity},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Intuitionistic fuzzy multi-stage multi-objective
fixed-charge solid transportation problem in a green supply chain.
<em>IJMLC</em>, <em>12</em>(3), 699–717. (<a
href="https://doi.org/10.1007/s13042-020-01197-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This research mainly focuses on presenting an innovative study of a multi-stage multi-objective fixed-charge solid transportation problem (MMFSTP) with a green supply chain network system under an intuitionistic fuzzy environment. The most controversial issue in recent years is that greenhouse gas emissions such as carbon dioxide, methane, etc. induce air pollution and global warming, thus motivating us to formulate the proposed research. In real-world situations the parameters of MMFSTP via a green supply chain network system usually have unknown quantities, and thus we assume trapezoidal intuitionistic fuzzy numbers to accommodate them and then employ the expected value operator to convert intuitionistic fuzzy MMFSTP into deterministic MMFSTP. Next, the methodologies are constructed to solve the deterministic MMFSTP by weighted Tchebycheff metrics programming and min-max goal programming, which provide Pareto-optimal solutions. A comparison is then drawn between the Pareto-optimal solutions that are extracted from the programming, and thereafter a procedure is performed to analyze the sensitivity analysis of the target values in the min–max goal programming. Finally, we incorporate an application example connected with a real-life industrial problem to display the feasibility and potentiality of the proposed model. Conclusions about the findings and future study directions are also offered.},
  archive      = {J_IJMLC},
  author       = {Midya, Sudipta and Roy, Sankar Kumar and Yu, Vincent F.},
  doi          = {10.1007/s13042-020-01197-1},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {3},
  pages        = {699-717},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Intuitionistic fuzzy multi-stage multi-objective fixed-charge solid transportation problem in a green supply chain},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Combining boundary detector and SND-SVM for fast learning.
<em>IJMLC</em>, <em>12</em>(3), 689–698. (<a
href="https://doi.org/10.1007/s13042-020-01196-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a state-of-the-art multi-class supervised novelty detection method, supervised novelty detection-support vector machine (SND-SVM) is extended from one-class support vector machine (OC-SVM). It still requires to slove a more time-consuming quadratic programming (QP) whose scale is the number of training samples multiplied by the number of normal classes. In order to speed up SND-SVM learning, we propose a down sampling framework for SND-SVM. First, the learning result of SND-SVM is only decided by minor samples that have non-zero Lagrange multipliers. We point out that the potential samples with non-zero Lagrange multipliers are located in the boundary regions of each class. Second, the samples located in boundary regions can be found by a boundary detector. Therefore, any boundary detector can be incorporated into the proposed down sampling framework for SND-SVM. In this paper, we use a classical boundary detector, local outlier factor (LOF), to illustrate the effective of our down sampling framework for SND-SVM. The experiments, conducted on several benchmark datasets and synthetic datasets, show that it becomes much faster to train SND-SVM after down sampling.},
  archive      = {J_IJMLC},
  author       = {Yi, Yugen and Shi, Yanjiao and Wang, Wenle and Lei, Gang and Dai, Jiangyan and Zheng, Hao},
  doi          = {10.1007/s13042-020-01196-2},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {3},
  pages        = {689-698},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Combining boundary detector and SND-SVM for fast learning},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-classification decision-making method for
interval-valued intuitionistic fuzzy three-way decisions and its
application in the group decision-making. <em>IJMLC</em>,
<em>12</em>(3), 661–687. (<a
href="https://doi.org/10.1007/s13042-020-01195-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the introduction of the interval-valued intuitionistic fuzzy sets, the interval-valued intuitionistic fuzzy numbers are used instead of precise numbers to provide fuzzy characterization of feature attribute values and misclassification loss function values, which is more in line with the realistic fuzzy decision-making environment. Also, the constructive covering algorithm is introduced into the three-way decisions model, which effectively solves the shortcomings of the traditional decision-theoretic rough sets model in dealing with multi-classification problems, such as too many artificial parameters, complicated computation, redundant decisions, decisional conflicts and excessively large boundary domains. At the same time, in order to avoid the one-sidedness of individual decisions, the group decision-making method is introduced into the preliminarily constructed multi-classification model in this paper to build a multi-classification group decision-making model for interval-valued intuitionistic fuzzy three-way decisions based on the constructive covering algorithm. This model determines the initial weights of feature attributes by the precise weighting method, and determines the expert weights by the grey relational precise weighting method, which effectively achieves the consistency of group decision-making. The decision-making process and rules are also deduced, which expand the model of three-way decisions as well as its practical application value and scope.},
  archive      = {J_IJMLC},
  author       = {Ye, Dajun and Liang, Decui and Li, Tao and Liang, Shujing},
  doi          = {10.1007/s13042-020-01195-3},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {3},
  pages        = {661-687},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Multi-classification decision-making method for interval-valued intuitionistic fuzzy three-way decisions and its application in the group decision-making},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multipath feature recalibration DenseNet for image
classification. <em>IJMLC</em>, <em>12</em>(3), 651–660. (<a
href="https://doi.org/10.1007/s13042-020-01194-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, deep neural networks have demonstrated their efficiency in image classification tasks, which are commonly achieved by an extended depth and width of network architecture. However, poor convergence, over-fitting and gradient disappearance might be generated with such comprehensive architectures. Therefore, DenseNet is developed to address these problems. Although DenseNet adopts bottleneck technique in DenseBlocks to avoid relearning feature-maps and decrease parameters, this operation may lead to the skip and loss of important features. Besides, it still takes oversized computational power when the depth and width of the network architecture are increased for better classification. In this paper, we propose a variate of DenseNet, named Multipath Feature Recalibration DenseNet (MFR-DenseNet), to stack convolution layers instead of adopting bottleneck for improving feature extraction. Meanwhile, we build multipath DenseBlocks with Squeeze-Excitation (SE) module to represent the interdependencies of useful feature-maps among different DenseBlocks. Experiments in CIFAR-10, CIFAR-100, MNIST and SVHN reveal the efficiency of our network, with further reduced redundancy whilst maintaining the high accuracy of DenseNet.},
  archive      = {J_IJMLC},
  author       = {Chen, Bolin and Zhao, Tiesong and Liu, Jiahui and Lin, Liqun},
  doi          = {10.1007/s13042-020-01194-4},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {3},
  pages        = {651-660},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Multipath feature recalibration DenseNet for image classification},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). DISCERN: Diversity-based selection of centroids for
k-estimation and rapid non-stochastic clustering. <em>IJMLC</em>,
<em>12</em>(3), 635–649. (<a
href="https://doi.org/10.1007/s13042-020-01193-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the applications of center-based clustering algorithms such as K-means is partitioning data points into K clusters. In some examples, the feature space relates to the underlying problem we are trying to solve, and sometimes we can obtain a suitable feature space. Nevertheless, while K-means is one of the most efficient offline clustering algorithms, it is not equipped to estimate the number of clusters, which is useful in some practical cases. Other practical methods which do are simply too complex, as they require at least one run of K-means for each possible K. In order to address this issue, we propose a K-means initialization similar to K-means++, which would be able to estimate K based on the feature space while finding suitable initial centroids for K-means in a deterministic manner. Then we compare the proposed method, DISCERN, with a few of the most practical K estimation methods, while also comparing clustering results of K-means when initialized randomly, using K-means++ and using DISCERN. The results show improvement in both the estimation and final clustering performance.},
  archive      = {J_IJMLC},
  author       = {Hassani, Ali and Iranmanesh, Amir and Eftekhari, Mahdi and Salemi, Abbas},
  doi          = {10.1007/s13042-020-01193-5},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {3},
  pages        = {635-649},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {DISCERN: Diversity-based selection of centroids for k-estimation and rapid non-stochastic clustering},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Toward better prediction of recurrence for cushing’s
disease: A factorization-machine based neural approach. <em>IJMLC</em>,
<em>12</em>(3), 625–633. (<a
href="https://doi.org/10.1007/s13042-020-01192-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cushing&#39;s disease (CD) is a rare disease that occurs in 1.2–1.4 persons per million population per year. Recurrence prediction after transsphenoidal surgery (TSS) is important for determining individual treatment and follow-up strategies. Between 2000 and 2017, 354 CD patients with initial postoperative remission and long-term follow-up data were enrolled from Peking union medical college hospital (PUMCH) to predict recurrence, and PUMCH is one of the largest CD treatment centers in the world. We first investigated the effect of a factorization machine (FM)-based neural network to predict recurrence after TSS for CD. This method could automatically reduce a portion of the cross-feature selection work with acceptable parameters. We conducted a performance comparison of various algorithms on the collected dataset. To address the lack of interpretability of neural network models, we also used the local interpretable model-agnostic explanations approach, which provides an explanation in the form of relevant features of the predicted results by approximating the model behavior of the variables in a local manner. Compared with existing methods, the DeepFM model obtained the highest AUC value (0.869) and the lowest log loss value (0.256). According to the importance of each feature, three top features for the DeepFM model were postoperative morning adrenocorticotropic hormone level, age, and postoperative morning serum cortisol nadir. In the post hoc explanation phase, the above-mentioned importance-leading features made a great contribution to the prediction probability. The results showed that deep learning-based models could better aid neurosurgeons in recurrence prediction after TTS for patients with CD, and could contribute to determining individual treatment strategies.},
  archive      = {J_IJMLC},
  author       = {Fan, Yanghua and Li, Dongfang and Liu, Yifan and Feng, Ming and Chen, Qingcai and Wang, Renzhi},
  doi          = {10.1007/s13042-020-01192-6},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {3},
  pages        = {625-633},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Toward better prediction of recurrence for cushing’s disease: A factorization-machine based neural approach},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Adaptive super-twisting sliding mode control for micro
gyroscope based on double loop fuzzy neural network structure.
<em>IJMLC</em>, <em>12</em>(3), 611–624. (<a
href="https://doi.org/10.1007/s13042-020-01191-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a new adaptive super-twisting sliding mode control (STSMC) scheme based on a double loop fuzzy neural network (DLFNN) is proposed to solve the problem of the external disturbances and approximate the unknown model for a micro gyroscopes. The STSMC algorithm can effectively suppress chattering since it can hide the high-frequency switching part in the high-order derivative of the sliding mode variable and transfer the discrete control law to the high-order sliding mode surface. Because it not only combines the advantages of fuzzy systems, but also incorporates the advantages of neural network control, the proposed double loop fuzzy neural network can better approximate the system model with excellent approximation. Moreover, it has the advantage of full adjustment, and the initial values of all parameters in the network can be arbitrarily set, then the parameters can be adjusted to the optimal stable value adaptively according to the adaptive algorithm. Finally, the superiority of the STSMC algorithm is also discussed. Simulation results verify the superiority of the STSMC algorithm, showing it can improve system performance and estimate unknown models more accurately compared with conventional neural network sliding mode control (CNNSMC).},
  archive      = {J_IJMLC},
  author       = {Fei, Juntao and Feng, Zhilin},
  doi          = {10.1007/s13042-020-01191-7},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {3},
  pages        = {611-624},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Adaptive super-twisting sliding mode control for micro gyroscope based on double loop fuzzy neural network structure},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Community detection and co-author recommendation in
co-author networks. <em>IJMLC</em>, <em>12</em>(2), 597–609. (<a
href="https://doi.org/10.1007/s13042-020-01190-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the increasing complexity of scientific research and the expanding scale of projects, scientific research cooperation is an important trend in large-scale research. The analysis of co-authorship networks is a big data problem due to the expanding scale of the literature. Without sufficient data mining, research cooperation will be limited to a similar group, namely, a “small group”, in the co-author networks. This “small group” limits the research results and openness. However, the researchers are not aware of the existence of other researchers due to insufficient big data support. Considering the importance of discovering communities and recommending potential collaborations from a large body of literature, we propose an enhanced clustering algorithm for detecting communities. It includes the selection of an initial central node and the redefinition of the distance and iteration of the central node. We also propose a method that is based on the hilltop algorithm, which is an algorithm that is used in search engines, for recommending co-authors via link analysis. The co-author candidate set is improved by screening and scoring. In screening, the expert set formation of the hilltop algorithm is added. The score is calculated from the durations and quantity of the collaborations. Via experiments, communities can be extracted, and co-authors can be recommended from the big data of the scientific research literature.},
  archive      = {J_IJMLC},
  author       = {Jin, Tian and Wu, Qiong and Ou, Xuan and Yu, Jianjun},
  doi          = {10.1007/s13042-020-01190-8},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {2},
  pages        = {597-609},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Community detection and co-author recommendation in co-author networks},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). EMoSOA: A new evolutionary multi-objective seagull
optimization algorithm for global optimization. <em>IJMLC</em>,
<em>12</em>(2), 571–596. (<a
href="https://doi.org/10.1007/s13042-020-01189-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study introduces the evolutionary multi-objective version of seagull optimization algorithm (SOA), entitled Evolutionary Multi-objective Seagull Optimization Algorithm (EMoSOA). In this algorithm, a dynamic archive concept, grid mechanism, leader selection, and genetic operators are employed with the capability to cache the solutions from the non-dominated Pareto. The roulette-wheel method is employed to find the appropriate archived solutions. The proposed algorithm is tested and compared with state-of-the-art metaheuristic algorithms over twenty-four standard benchmark test functions. Four real-world engineering design problems are validated using proposed EMoSOA algorithm to determine its adequacy. The findings of empirical research indicate that the proposed algorithm is better than other algorithms. It also takes into account those optimal solutions from the Pareto which shows high convergence.},
  archive      = {J_IJMLC},
  author       = {Dhiman, Gaurav and Singh, Krishna Kant and Slowik, Adam and Chang, Victor and Yildiz, Ali Riza and Kaur, Amandeep and Garg, Meenakshi},
  doi          = {10.1007/s13042-020-01189-1},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {2},
  pages        = {571-596},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {EMoSOA: A new evolutionary multi-objective seagull optimization algorithm for global optimization},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A novel feature learning framework for high-dimensional data
classification. <em>IJMLC</em>, <em>12</em>(2), 555–569. (<a
href="https://doi.org/10.1007/s13042-020-01188-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature extraction is an essential component in many classification tasks. Popular feature extraction approaches especially deep learning-based methods, need large training samples to achieve satisfactory performance. Although dictionary learning-based methods are successfully used for feature extraction on both small and large datasets, however, when dealing with high-dimensional datasets, a large number of dimensions also mask the discriminative information embedded in the data. To address these issues, a novel feature learning framework for high-dimensional data classification is proposed in this paper. Specially, to discard the irrelevant parts that derail the dictionary learning process, the dictionary is adaptively learnt in the low-dimensional space parameterized by a transformation matrix. To ensure that the learned features are discriminative for the classifier, the classification results in turn are used to guide the dictionary and transformation matrix learning process. Compared with other methods, the proposed method simultaneously exploits the dimension reduction, dictionary learning and classifier learning in one optimization framework, which enables the method to extract low-dimensional and discriminative features. Experimental results on several benchmark datasets demonstrate the superior performance of the proposed method for high-dimensional data classification task, particularly when the number of training samples is small.},
  archive      = {J_IJMLC},
  author       = {Li, Yanxia and Chai, Yi and Yin, Hongpeng and Chen, Bo},
  doi          = {10.1007/s13042-020-01188-2},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {2},
  pages        = {555-569},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A novel feature learning framework for high-dimensional data classification},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). M-pSC: A manifold p-spectral clustering algorithm.
<em>IJMLC</em>, <em>12</em>(2), 541–553. (<a
href="https://doi.org/10.1007/s13042-020-01187-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Since p-spectral clustering has good performance in many practical problems, it has attracted great attention. The Cheeger cut criterion is used in p-spectral clustering to do graph partition. However, due to the improper affinity measure and outliers, the original p-spectral clustering algorithm is not effective in dealing with manifold data. To solve this problem, we propose a manifold p-spectral clustering (M-pSC) using path-based affinity measure. First, we design a path-based affinity function to describe the complex structures of manifold data. This affinity function obeys the clustering assumption that the data pairs within the manifold structure share high affinities, and the data pairs between different manifold structures share low affinities. This will help us construct a good affinity matrix, which carry more category information of the points. Then we propose a M-pSC algorithm using the path-based affinity function. In the Cheeger cut criterion, the p-Laplacian matrix are constructed based on the manifold affinity function, and the final clustering results are obtained by using the eigenvectors of graph p-Laplacian. At last, the proposed algorithm is tested on several public data sets and the experiments show that our algorithm is adaptive to different manifold data. Compared with other popular clustering algorithms, our algorithm has good clustering quality and robustness.},
  archive      = {J_IJMLC},
  author       = {Ding, Ling and Ding, Shifei and Wang, Yanru and Wang, Lijuan and Jia, Hongjie},
  doi          = {10.1007/s13042-020-01187-3},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {2},
  pages        = {541-553},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {M-pSC: A manifold p-spectral clustering algorithm},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A novel randomised particle swarm optimizer. <em>IJMLC</em>,
<em>12</em>(2), 529–540. (<a
href="https://doi.org/10.1007/s13042-020-01186-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The particle swarm optimization (PSO) algorithm is a popular evolutionary computation approach that has received an ever-increasing interest in the past decade owing to its wide application potential. Despite the many variants of the PSO algorithm with improved search ability by means of both the convergence rate and the population diversity, the local optima problem remains a major obstacle that hinders the global optima from being found. In this paper, a novel randomized particle swarm optimizer (RPSO) is proposed where the Gaussian white noise with adjustable intensity is utilized to randomly perturb the acceleration coefficients in order for the problem space to be explored more thoroughly. With this new strategy, the RPSO algorithm not only maintains the population diversity but also enhances the possibility of escaping the local optima trap. Experimental results demonstrate that the proposed RPSO algorithm outperforms some existing popular variants of PSO algorithms on a series of widely used optimization benchmark functions.},
  archive      = {J_IJMLC},
  author       = {Liu, Weibo and Wang, Zidong and Zeng, Nianyin and Yuan, Yuan and Alsaadi, Fuad E. and Liu, Xiaohui},
  doi          = {10.1007/s13042-020-01186-4},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {2},
  pages        = {529-540},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A novel randomised particle swarm optimizer},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Fault diagnosis of biological systems using improved machine
learning technique. <em>IJMLC</em>, <em>12</em>(2), 515–528. (<a
href="https://doi.org/10.1007/s13042-020-01184-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fault detection and isolation (FDI) is considered as one of the most critical problems in biological processes. Therefore, in this paper, we consider a new FDI framework that aims to improve the monitoring of biological processes. To do that, a machine learning-based statistical hypothesis approach, which can identify the model, detect and isolate the faults, will be developed. In the developed approach, so-called partial Gaussian process regression (PGPR)-based generalized likelihood ratio test (GLRT), first, the GPR model that can accurately model biological processes is presented. Then, the fault detection phase is performed using the GLRT chart. Finally, the PGPR-based GLRT, which can effectively isolate the faults, is developed. The FDI performances of the developed PGPR-based GLRT approach are compared with partial support vector regression (SVR), extreme learning machines (ELM), Kernel ridge regression (KRR) and relevance vector machines (RVM)-based GLRT methods in terms of missed detection rate (MDR), false alarm rate (FAR), root mean square error (RMSE), execution time (ET) and isolation accuracy. The obtained results show that the proposed technique can reliably detect and isolate various faults using two examples: a synthetic data and a biological process representing a Cad System in E. coli (CSEC) model.},
  archive      = {J_IJMLC},
  author       = {Fezai, Radhia and Abodayeh, Kamaleldin and Mansouri, Majdi and Nounou, Hazem and Nounou, Mohamed},
  doi          = {10.1007/s13042-020-01184-6},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {2},
  pages        = {515-528},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Fault diagnosis of biological systems using improved machine learning technique},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Using multiple classifier behavior to develop a dynamic
outlier ensemble. <em>IJMLC</em>, <em>12</em>(2), 501–513. (<a
href="https://doi.org/10.1007/s13042-020-01183-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Outlier ensembles that use more base detectors recently become an attractive approach to solving problems of single detectors. However, existing outlier ensembles often assume that base detectors make independent errors, which is difficult to satisfy in practical applications. To this end, this paper proposes a dynamic outlier ensemble to loose this error independence assumption. In our method, it is desired that the most competent base detector(s) can be singled out by the dynamic selection mechanism for each test pattern. The usage of the concept of multiple classifier behavior (MCB) has two purposes. One is to generate artificial outlier examples used for competence estimates. This strategy is different from other methods since we do not make any assumption regarding the data distribution. On the other hand, MCB is used to refine validation sets initialized by the K-nearest neighbors (KNN) rule. It is desired that objects in the refined validation sets are more representative than those found by KNN. With the refined validation sets, competences of all base detectors will be estimated by a probabilistic method, before which we have transformed outputs of base detectors into a probabilistic form. Finally, a switching mechanism that determines whether one detector should be nominated to make the decision or a fusion method should be applied instead is proposed in order to achieve a robust detection result. We carry out experiments on 20 benchmark data sets to verify the effectiveness of our detection method.},
  archive      = {J_IJMLC},
  author       = {Yuan, Ping and Wang, Biao and Mao, Zhizhong},
  doi          = {10.1007/s13042-020-01183-7},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {2},
  pages        = {501-513},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Using multiple classifier behavior to develop a dynamic outlier ensemble},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Real-time human posture recognition using an adaptive hybrid
classifier. <em>IJMLC</em>, <em>12</em>(2), 489–499. (<a
href="https://doi.org/10.1007/s13042-020-01182-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A reliable adaptive hybrid classifier (hAHC), which combines a posture-based adaptive signal segmentation algorithm with a multi-layer perceptron (MLP) classifier, together with a plurality voting approach, was proposed and evaluated in this study. The hAHC model was evaluated using a real-time posture recognition framework that sought to identify five behaviours (sitting, walking, standing, running, and lying) based on simulated crowd security scenarios. It was compared to a single MLP classifier (sMLP) and a static hybrid classifier (hSHC) from three perspectives (classification precision, recall and F1-score) that used the real-time dataset collected from unfamiliar subjects. Experimental results showed that the hAHC model improved the classification accuracy and robustness slightly more than the hSHC, and significantly more compared to the sMLP (hAHC 82\%; hSHC 79\%; sMLP 71\%). Additionally, the hAHC approach displayed the real-time results as animated figures in an adaptive window, in contrast to the hSHC which used a fixed size-sliding temporal window that as our results demonstrated, was less suitable for presenting real-time results. The main research contribution from this study has been the development of an efficient software-only-based sensor calibration algorithm that can improve accelerometer precision, together with the design of a posture-based adaptive signal segmentation algorithm that cooperated with an adaptive hybrid classifier to improve the performance of real-time posture recognition.},
  archive      = {J_IJMLC},
  author       = {Zhang, Shumei and Callaghan, Victor},
  doi          = {10.1007/s13042-020-01182-8},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {2},
  pages        = {489-499},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Real-time human posture recognition using an adaptive hybrid classifier},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). InterSentiment: Combining deep neural models on interaction
and sentiment for review rating prediction. <em>IJMLC</em>,
<em>12</em>(2), 477–488. (<a
href="https://doi.org/10.1007/s13042-020-01181-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Review rating prediction is commonly approached from the perspective of either Collaborative Filtering (CF) or Sentiment Classification (SC). CF-based approach usually resorts to matrix factorization based on user–item interaction, and does not fully utilize the valuable review text features. In contrast, SC-based approach is focused on mining review content, but can just incorporate some user- and product-level features, and fails to capture sufficient interactions between them represented typically in a sparse matrix as CF can do. In this paper, we propose a novel, extensible review rating prediction model called InterSentiment by bridging the user-product interaction model and the sentiment model based on deep learning. InterSentiment is a specific instance of our proposed Deep Learning based Collaborative Filtering framework. The proposed model aims to learn the high-level representations combining user-product interaction and review sentiment, and jointly project them into the rating scores. Results of experiments conducted on IMDB and two Yelp datasets demonstrate clear advantage of our proposed approach over strong baseline methods.},
  archive      = {J_IJMLC},
  author       = {Feng, Shi and Song, Kaisong and Wang, Daling and Gao, Wei and Zhang, Yifei},
  doi          = {10.1007/s13042-020-01181-9},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {2},
  pages        = {477-488},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {InterSentiment: Combining deep neural models on interaction and sentiment for review rating prediction},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A bipartite matching-based feature selection for multi-label
learning. <em>IJMLC</em>, <em>12</em>(2), 459–475. (<a
href="https://doi.org/10.1007/s13042-020-01180-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many real-world data have multiple class labels known as multi-label data, where the labels are correlated with each other, and as such, they are not independent. Since these data are usually high-dimensional, and the current multi-label feature selection methods have not been precise enough, then a new feature selection method is necessary. In this paper, for the first time, we have modeled the problem of multi-label feature selection to a bipartite graph matching process. The proposed method constructs a bipartite graph of features (as the left vertices) and labels (as the right vertices), called Feature-Label Graph (FLG), where each feature is connected to the set of labels, where the weight of the edge between each feature and label is equal to their correlation. Then, the Hungarian algorithm estimates the best matching in FLG. The selected features in each matching are sorted by weighted correlation distance and added to the ranking vector. To select the discriminative features, the proposed method considers both the redundancy of features and the relevancy of each feature to the class labels. The results indicate the superiority of the proposed method against the other methods in classification measures.},
  archive      = {J_IJMLC},
  author       = {Hashemi, Amin and Dowlatshahi, Mohammad Bagher and Nezamabadi-Pour, Hossein},
  doi          = {10.1007/s13042-020-01180-w},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {2},
  pages        = {459-475},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A bipartite matching-based feature selection for multi-label learning},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Fuzzy entropies for class-specific and classification-based
attribute reducts in three-way probabilistic rough set models.
<em>IJMLC</em>, <em>12</em>(2), 433–457. (<a
href="https://doi.org/10.1007/s13042-020-01179-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There exist two formulations of the theory of rough sets, consisting of the conceptual formulations and the computational formulations. Class-specific and classification-based attribute reducts are two crucial notions in three-way probabilistic rough set models. In terms of conceptual formulations, the two types of attribute reducts can be defined by considering probabilistic positive or negative region preservations of a decision class and a decision classification, respectively. However, in three-way probabilistic rough set models, there are few studies on the computational formulations of the two types of attribute reducts due to the non-monotonicity of probabilistic positive and negative regions. In this paper, we examine the computational formulations of the two types of attribute reducts in three-way probabilistic rough set models based on fuzzy entropies. We construct monotonic measures based on fuzzy entropies, from which we can obtain the computational formulations of the two types of attribute reducts. On this basis, we develop algorithms for finding the two types of attribute reducts based on addition-deletion method or deletion method. Finally, the experimental results verify the monotonicity of the proposed measures with respect to the set inclusion of attributes and show that class-specific attribute reducts provide a more effective way of attribute reduction with respect to a particular decision class compared with classification-based attribute reducts.},
  archive      = {J_IJMLC},
  author       = {Ma, Xi-Ao},
  doi          = {10.1007/s13042-020-01179-3},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {2},
  pages        = {433-457},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Fuzzy entropies for class-specific and classification-based attribute reducts in three-way probabilistic rough set models},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A survey of 5G network systems: Challenges and machine
learning approaches. <em>IJMLC</em>, <em>12</em>(2), 385–431. (<a
href="https://doi.org/10.1007/s13042-020-01178-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {5G cellular networks are expected to be the key infrastructure to deliver the emerging services. These services bring new requirements and challenges that obstruct the desired goal of forthcoming networks. Mobile operators are rethinking their network design to provide more flexible, dynamic, cost-effective and intelligent solutions. This paper starts with describing the background of the 5G wireless networks then we give a deep insight into a set of 5G challenges and research opportunities for machine learning (ML) techniques to manage these challenges. The first part of the paper is devoted to overview the fifth-generation of cellular networks, explaining its requirements as well as its key technologies, their challenges and its forthcoming architecture. The second part is devoted to present a basic overview of ML techniques that are nowadays applied to cellular networks. The last part discusses the most important related works which propose ML solutions in order to overcome 5G challenges.},
  archive      = {J_IJMLC},
  author       = {Fourati, Hasna and Maaloul, Rihab and Chaari, Lamia},
  doi          = {10.1007/s13042-020-01178-4},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {2},
  pages        = {385-431},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A survey of 5G network systems: Challenges and machine learning approaches},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). CL-MAX: A clustering-based approximation algorithm for
mining maximal frequent itemsets. <em>IJMLC</em>, <em>12</em>(2),
365–383. (<a href="https://doi.org/10.1007/s13042-020-01177-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The problem of frequent itemset mining is one of the more important problems in data mining which has been extensively employed across a wide range of other relevant tasks such as market basket analysis in marketing, or text analysis in text mining applications. The majority of the deterministic frequent itemset mining algorithms which have been proposed in recent years use some sort or another of an optimal data structures to reduce the overall execution time of the algorithm. In this paper, however, we have tried instead to introduce an approximation algorithm which works by converting the problem into a clustering problem where similar transactions are grouped together. Each cluster centroid represents an itemset which may be assumed to be a candidate frequent itemsets. The validity of this assumption is simply verified by calculating the support count of these itemsets. Those who meet the min-support condition are considered to be an actual frequent itemset. As for the remaining itemsets, they are then passed to MAFIA which extract all maximal frequent itemsets therefrom. Experimentations made on several well-known and diverse datasets show that the proposed algorithm performs almost always faster, and in some cases up to 10 times faster, than the existing deterministic algorithms, and all this by retaining up to 95\% of its accuracy.},
  archive      = {J_IJMLC},
  author       = {Fatemi, Seyed Mohsen and Hosseini, Seyed Mohsen and Kamandi, Ali and Shabankhah, Mahmood},
  doi          = {10.1007/s13042-020-01177-5},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {2},
  pages        = {365-383},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {CL-MAX: A clustering-based approximation algorithm for mining maximal frequent itemsets},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Chinese medical relation extraction based on multi-hop
self-attention mechanism. <em>IJMLC</em>, <em>12</em>(2), 355–363. (<a
href="https://doi.org/10.1007/s13042-020-01176-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The medical literature is the most important way to demonstrate academic achievements and academic exchanges. Massive medical literature has become a huge treasure trove of knowledge. It is necessary to automatically extract implicit medical knowledge from the medical literature. Medical relation extraction aims to automatically extract medical relations from the medical text for various medical researches. However, there are a few kinds of research in Chinese medical literature. Currently, the popular methods are based on neural networks, which focus on semantic information on one aspect of the sentence. However, complex semantic information in the sentence determines the relation between entities, the semantic information cannot be represented by one sentence vector. In this paper, we propose an attention-based model to extract the multi-aspect semantic information for the Chinese medical relation extraction by multi-hop attention mechanism. The model could generate multiple weight vectors for the sentence through each attention step, therefore, we can generate the different semantic representation of a sentence, respectively. Our model is evaluated by using Chinese medical literature from China National Knowledge Infrastructure (CNKI). It achieves an F1 score of 93.19\% for therapeutic relation tasks and 73.47\% for causal relation tasks.},
  archive      = {J_IJMLC},
  author       = {Zhang, Tongxuan and Lin, Hongfei and Tadesse, Michael M. and Ren, Yuqi and Duan, Xiaodong and Xu, Bo},
  doi          = {10.1007/s13042-020-01176-6},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {2},
  pages        = {355-363},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Chinese medical relation extraction based on multi-hop self-attention mechanism},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Cross-domain sentiment aware word embeddings for review
sentiment analysis. <em>IJMLC</em>, <em>12</em>(2), 343–354. (<a
href="https://doi.org/10.1007/s13042-020-01175-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning low-dimensional vector representations of words from a large corpus is one of the basic tasks in natural language processing (NLP). The existing universal word embedding model learns word vectors mainly through grammar and semantic information from the context, while ignoring the sentiment information contained in the words. Some approaches, although they model sentiment information in the reviews, do not consider certain words in different domains. In a case where the emotion changes, if the general word vector is directly applied to the review sentiment analysis task, then this will inevitably affect the performance of the sentiment classification. To solve this problem, this paper extends the CBoW (continuous bag-of-words) word vector model and proposes a cross-domain sentiment aware word embedding learning model, which can capture the sentiment information and domain relevance of a word at the same time. This paper conducts several experiments on Amazon user review data in different domains to evaluate the performance of the model. The experimental results show that the proposed model can obtain a nearly 2\% accuracy improvement compared with the general word vector when modeling only the sentiment information of the context. At the same time, when the domain information and the sentiment information are both included, the accuracy and Macro-F1 value of the sentiment classification tasks are significantly improved compared with existing sentiment word embeddings.},
  archive      = {J_IJMLC},
  author       = {Liu, Jun and Zheng, Shuang and Xu, Guangxia and Lin, Mingwei},
  doi          = {10.1007/s13042-020-01175-7},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {2},
  pages        = {343-354},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Cross-domain sentiment aware word embeddings for review sentiment analysis},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Feature selection schema based on game theory and biology
migration algorithm for regression problems. <em>IJMLC</em>,
<em>12</em>(2), 303–342. (<a
href="https://doi.org/10.1007/s13042-020-01174-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many real-world datasets nowadays are of regression type, while only a few dimensionality reduction methods have been developed for regression problems. On the other hand, most existing regression methods are based on the computation of the covariance matrix, rendering them inefficient in the reduction process. Therefore, a BMA-based multi-objective feature selection method, GBMA, is introduced by incorporating the Nash equilibrium approach. GBMA is intended to maximize model accuracy and minimize the number of features through a less complex procedure. The proposed method is composed of four steps. The first step involves defining three players, each of which is trying to improve its objective function (i.e., model error, number of features, and precision adjustment). The second step includes clustering features based on the correlation therebetween and detecting the most appropriate ordering of features to enhance cluster efficiency. The third step comprises extracting a new feature from each cluster based on various weighting methods (i.e., moderate, strict, and hybrid). Finally, the fourth step encompasses updating players based on stochastic search operators. The proposed GBMA strategy explores the search space and finds optimal solutions in an acceptable amount of time without examining every possible solution. The experimental results and statistical tests based on ten well-known datasets from the UCI repository proved the high performance of GBMA in selecting features for solving regression problems.},
  archive      = {J_IJMLC},
  author       = {Javidi, Mohammad Masoud},
  doi          = {10.1007/s13042-020-01174-8},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {2},
  pages        = {303-342},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Feature selection schema based on game theory and biology migration algorithm for regression problems},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Optimal scale combination selection for multi-scale decision
tables based on three-way decision. <em>IJMLC</em>, <em>12</em>(2),
281–301. (<a href="https://doi.org/10.1007/s13042-020-01173-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optimal scale combination selection plays a critical role for knowledge discovery in multi-scale decision tables (MDTs) and has attracted considerable attention. However, searching for all optimal scale combinations from the scale collection may result in a combinatorial explosion, and the existing approaches are time-consuming. The main goal of this study is to improve the efficiency of searching for all optimal scale combinations. To this end, a sequential three-way decision model of the scale collection and an extended stepwise optimal scale selection method are proposed to quickly search for all optimal scale combinations. First, a sequential three-way decision model of the scale collection is proposed, and it can be proved that a local optimal scale combination on the boundary region is also a global optimal scale combination on the scale collection. Therefore, all optimal scale combinations of a MDT can be obtained by searching for a single local optimal scale combination on the boundary regions in a step-by-step manner. Second, an extended stepwise optimal scale selection method is introduced to quickly search for a single local optimal scale combination on the boundary region. Moreover, a necessary and sufficient condition under which a MDT has a unique optimal scale combination is given, and two efficient methods for computing the maximal elements of the boundary region are provided. Finally, an efficient optimal scale combination selection algorithm based on sequential three-way decision is presented to search for all optimal scale combinations. Experimental results demonstrate that the proposed algorithms can significantly reduce overall computational time.},
  archive      = {J_IJMLC},
  author       = {Cheng, Yunlong and Zhang, Qinghua and Wang, Guoyin},
  doi          = {10.1007/s13042-020-01173-9},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {2},
  pages        = {281-301},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Optimal scale combination selection for multi-scale decision tables based on three-way decision},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). ADET: Anomaly detection in time series with linear time.
<em>IJMLC</em>, <em>12</em>(1), 271–280. (<a
href="https://doi.org/10.1007/s13042-020-01171-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time series data is ubiquitous in financial, biomedical, and other areas. Anomaly detection in time series has been widely researched in these areas. However, most existing algorithms suffer from “curse of dimension” and may lose some information in the process of feature extraction. In this paper, we propose two new data structures named interval table (ITable) and extend interval table (EITable) for time series representation to capture more original information. We also proposed ADET: a novel Anomaly Detection algorithm based on EITable, which only needs linear time to detect meaningful anomalies. Extensive experiments on eleven data sets of UCR Repository, MIT-BIH datasets, and the BIDMC database show that ADET has overall good performance in terms of AUC-ROC and outperforms other algorithms in time complexity.},
  archive      = {J_IJMLC},
  author       = {Zhang, Chunkai and Zuo, Wei and Yin, Ao and Wang, Xuan and Liu, Chuanyi},
  doi          = {10.1007/s13042-020-01171-x},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {1},
  pages        = {271-280},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {ADET: Anomaly detection in time series with linear time},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A further study on biologically inspired feature enhancement
in zero-shot learning. <em>IJMLC</em>, <em>12</em>(1), 257–269. (<a
href="https://doi.org/10.1007/s13042-020-01170-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most of the zero-shot learning (ZSL) algorithms currently use the pre-trained models trained on ImageNet as their feature extractor, which is considered to be an effective method to improve the feature extraction ability of the ZSL models. However, our research found that this practice is difficult to work well if the training data used by the ZSL task differs greatly from ImageNet. Although one can adapt the pre-trained models to the ZSL task with fine-tuning methods, it turns out that the extractors obtained in this way cannot be guaranteed to be friendly to the unseen classes. To solve these problems, we have further studied a biologically inspired feature enhancement framework for ZSL that we proposed earlier and re-fined its biological taxonomy-based selection method for choosing auxiliary datasets. Moreover, we have proposed a word2vec-based selection strategy as a supplement to the biologically inspired selection method for the first time and experimentally proved the inherent unity of these two methods. Extensive experimental results show that our proposed method can effectively improve the generalization ability of the ZSL model and achieve state-of-the-art results on benchmarks. We have also explained the experimental phenomena through the way of feature visualization.},
  archive      = {J_IJMLC},
  author       = {Xie, Zhongwu and Cao, Weipeng and Ming, Zhong},
  doi          = {10.1007/s13042-020-01170-y},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {1},
  pages        = {257-269},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A further study on biologically inspired feature enhancement in zero-shot learning},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A new rough set model based on multi-scale covering.
<em>IJMLC</em>, <em>12</em>(1), 243–256. (<a
href="https://doi.org/10.1007/s13042-020-01169-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-scale rough set has become one of the hot research topics in rough set. In this article, from the point of view of granule, we first give the definition of the scale relationship between two coverings. Then some properties about neighborhood and approximation operators are explored based on multi-scale covering. Further, we investigate the multi-scale covering approximation space and thus construct a rough set model based on multi-scale covering. In the multi-scale covering decision approximation space, several optimal scale coverings are studied. Finally, we show the connection between multi-scale covering rough sets and multi-scale information systems, and generalize the multi-scale covering approximation space. Rough sets based on multi-scale covering are more extensive than multi-scale information systems. In addition, we design couple of algorithms and several experiments are conducted to verify the efficiency of the algorithms.},
  archive      = {J_IJMLC},
  author       = {Li, Weikang and Li, Jinjin and Huang, Jianxin and Dai, Weizhong and Zhang, Xiaoping},
  doi          = {10.1007/s13042-020-01169-5},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {1},
  pages        = {243-256},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A new rough set model based on multi-scale covering},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-agent reinforcement learning for redundant robot
control in task-space. <em>IJMLC</em>, <em>12</em>(1), 231–241. (<a
href="https://doi.org/10.1007/s13042-020-01167-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Task-space control needs the inverse kinematics solution or Jacobian matrix for the transformation from task space to joint space. However, they are not always available for redundant robots because there are more joint degrees-of-freedom than Cartesian degrees-of-freedom. Intelligent learning methods, such as neural networks (NN) and reinforcement learning (RL) can learn the inverse kinematics solution. However, NN needs big data and classical RL is not suitable for multi-link robots controlled in task space. In this paper, we propose a fully cooperative multi-agent reinforcement learning (MARL) to solve the kinematic problem of redundant robots. Each joint of the robot is regarded as one agent. The fully cooperative MARL uses a kinematic learning to avoid function approximators and large learning space. The convergence property of the proposed MARL is analyzed. The experimental results show that our MARL is much more better compared with the classic methods such as Jacobian-based methods and neural networks.},
  archive      = {J_IJMLC},
  author       = {Perrusquía, Adolfo and Yu, Wen and Li, Xiaoou},
  doi          = {10.1007/s13042-020-01167-7},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {1},
  pages        = {231-241},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Multi-agent reinforcement learning for redundant robot control in task-space},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Creating rule-based agents for artificial general
intelligence using association rules mining. <em>IJMLC</em>,
<em>12</em>(1), 223–230. (<a
href="https://doi.org/10.1007/s13042-020-01166-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, our focus is on using a rule-based approach to develop agents with artificial general intelligence. In rule-based systems, developing effective rules is a huge challenge, and coding rules for agents requires a large amount of manual work. Association rules mining (ARM) can be used for discovering specific rules from data sets and determining relationships between data sets. In this paper, we introduce a modified ARM method and use it to discover rules that analyse the surrounding environment and determine movements for an agent-guided vehicle that has been designed to achieve autonomous parking. The rules are created by our ARM-based method from training data gained during manual training in customised parking scenarios. In this system, data are represented in terms of fuzzy symbolic elements. We have tested our system by simulation in a virtual environment to demonstrate the effectiveness of this new approach.},
  archive      = {J_IJMLC},
  author       = {Yuan, Xin and Liebelt, Michael John and Shi, Peng and Phillips, Braden J.},
  doi          = {10.1007/s13042-020-01166-8},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {1},
  pages        = {223-230},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Creating rule-based agents for artificial general intelligence using association rules mining},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A hybrid grey wolf optimizer for solving the product
knapsack problem. <em>IJMLC</em>, <em>12</em>(1), 201–222. (<a
href="https://doi.org/10.1007/s13042-020-01165-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The product knapsack problem (PKP) is a new variation of the knapsack problem which arises in social choice computation. Although some deterministic algorithms have been reported to handle small-scale problems, the solution to the middle and large-scale problems is still lack of progress. For efficiently solving this problem, a new ideal of solving PKP by evolutionary algorithms is proposed in the paper. Firstly, an accelerated binary grey wolf optimizer (ABGWO) is proposed by modifying the transfer function, in which the original sigmoid function is replaced by a step function to reduce the computation and accelerate convergence. Secondly, a two-phase repair and optimize algorithm based on greedy strategy is proposed, which is used to handle the infeasible solutions when using evolutionary algorithm to solve PKP. In order to validate the performance of ABGWO, we use it to solve four kinds of PKP instances and compare with the performance of genetic algorithms, discrete particle swarm optimization, discrete differential evolution, and two existed binary grey wolf optimizers. Comparison results show that ABGWO is superior to others in terms of solution quality, robustness and convergence speed, and it is most suitable for solving PKP.},
  archive      = {J_IJMLC},
  author       = {Li, Zewen and He, Yichao and Li, Ya and Guo, Xiaohu},
  doi          = {10.1007/s13042-020-01165-9},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {1},
  pages        = {201-222},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A hybrid grey wolf optimizer for solving the product knapsack problem},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Discrete convolutional CRF networks for depth estimation
from monocular infrared images. <em>IJMLC</em>, <em>12</em>(1), 187–200.
(<a href="https://doi.org/10.1007/s13042-020-01164-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predicting the depth of a scene from monocular infrared images, which plays a crucial role in understanding three-dimensional structures, is one of the challenging tasks in machine learning and computer vision. Considering the lack of texture and color information in infrared images, a novel discrete convolutional conditional random field network is proposed for depth estimation. The proposed method inherits several merits of conditional random fields and deep learning. First, the pairwise features are automatically extracted and optimized through deep architectures. Second, the monocular-images-based depth regression is converted into a multi-class classification, in which the order information of different levels of depths is considered in the loss function. Our experiments demonstrate that this conversion achieves much higher accuracy and faster conversion. Third, to obtain fine-grained level details, we have further proposed a multi-scale discrete convolutional conditional random field network that computes the pairwise features of the discrete conditional random field at different spatial levels. Extensive experiments on the infrared image dataset NUSTMS demonstrate that the proposed method outperforms other depth estimation methods. Specifically, for the proposed method, the mean relative error is 0.181, the mean log10 error is 0.072, and the accuracy with a threshold (t = 1.253) is 95.3\%.},
  archive      = {J_IJMLC},
  author       = {Wang, Qianqian and Zhao, Haitao and Hu, Zhengwei and Chen, Yuru and Li, Yuqi},
  doi          = {10.1007/s13042-020-01164-w},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {1},
  pages        = {187-200},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Discrete convolutional CRF networks for depth estimation from monocular infrared images},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A weighted exponential discriminant analysis through
side-information for face and kinship verification using statistical
binarized image features. <em>IJMLC</em>, <em>12</em>(1), 171–185. (<a
href="https://doi.org/10.1007/s13042-020-01163-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Side-information based exponential discriminant analysis (SIEDA) is more efficient than side-information based linear discriminant analysis (SILDA) in computing the discriminant vectors because it maximizes the Fisher criterion function. In this paper, we develop a novel criterion, named side-information based weighted exponential discriminant analysis (SIWEDA), that is based on the classical SIEDA method. We reformulate and generalize the classical Fisher criterion function in order to maximize it, with the property to pull as close as possible the intra-class samples (within-class samples), and push and repulse away as far as possible the inter-class samples (between-class samples). Thus, SIWEDA selects the eigenvalues of high significance and eliminate those with less discriminative information. To reduce the feature vector dimensionality and lighten the class intra-variability, we use SIWEDA and within class covariance normalization (WCCN) using the proposed statistical binarized image features (StatBIF). Moreover, we use score fusion strategy to extract the complementarity of different weighting scales of our StatBIF descriptor. We conducted experiments to evaluate the performance of the proposed method under unconstrained environment, using five datasets namely LFW, YTF, Cornell KinFace, UB KinFace and TSKinFace datasets, in the context of matching faces and kinship verification in the wild conditions. The experiments showed that the proposed approach outperforms the current state of the art. Very interestingly, our approach showed superior performance compared to methods based on deep metric learning.},
  archive      = {J_IJMLC},
  author       = {Laiadi, Oualid and Ouamane, Abdelmalik and Benakcha, Abdelhamid and Taleb-Ahmed, Abdelmalik and Hadid, Abdenour},
  doi          = {10.1007/s13042-020-01163-x},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {1},
  pages        = {171-185},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A weighted exponential discriminant analysis through side-information for face and kinship verification using statistical binarized image features},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Two-stage multi-sided matching dispatching models based on
improved BPR function with probabilistic linguistic term sets.
<em>IJMLC</em>, <em>12</em>(1), 151–169. (<a
href="https://doi.org/10.1007/s13042-020-01162-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Disaster has great destructiveness and a wide influence on urban and rural construction, and more than one place is affected by disaster. Thus, it needs to take multiple disaster points into account. In view of different rescue missions, both medical rescue teams and search rescue teams also need to be dispatched. That is the multi-sided matching among medical rescue teams, search rescue teams and disaster points. Firstly, we describe the matching process, including the related symbols used in the process, and define a concept called multi-sided matching. Then, we aim to solve two problems: determining the competency degree of rescuers and calculating the time reliability of rescue teams arriving at disaster points. For the first one, we invite experts to evaluate pending rescue teams in terms of professional ability and collaboration ability using probabilistic linguistic term sets (PLTSs) because PLTSs not only keep original linguistic information but also give distributed expressions. For the second one, we determine the arriving time and calculating the time reliability by using the improved Bureau of Public Road (BPR) function. After that, we construct the two-stage multi-sided matching programming models based on the improved BPR function and PLTSs. Finally, a case study is used to demonstrate the proposed matching process, some comparative analyses and discussions are also conducted to validate the proposed models.},
  archive      = {J_IJMLC},
  author       = {Li, Bo and Xu, Zeshui and Zhang, Yixin},
  doi          = {10.1007/s13042-020-01162-y},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {1},
  pages        = {151-169},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Two-stage multi-sided matching dispatching models based on improved BPR function with probabilistic linguistic term sets},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Efficient image segmentation through 2D histograms and an
improved owl search algorithm. <em>IJMLC</em>, <em>12</em>(1), 131–150.
(<a href="https://doi.org/10.1007/s13042-020-01161-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optimization is used in different fields of engineering to solve complex problems. In image processing, multilevel thresholding requires to find the optimal configuration of thresholds to obtain accurate segmented images. In this case, the use of two-dimensional histograms is helpful because they permit us to combine information from the image preserving different features. This paper introduces a new method for multilevel image thresholding segmentation based on the improved version of the owl search algorithm (iOSA) and 2D histograms. The performance of the iOSA is enhanced with the inclusion of a new strategy in the optimization process. Moreover, in the initialization step, it is applied the opposition-based learning. Meanwhile, the 2D histograms permit to maintain more information of the image. Considering such modifications, the iOSA performs a better exploration of the search space during the early iterations, preserving the exploitation of the prominent regions using a self-adaptive variable. The iOSA is employed to allocate the optimal threshold values that segment the image by using the 2D Rényi entropy as an objective function. To test the efficiency of the iOSA, a set of experiments were performed which validate the quality of the segmentation and evaluate the optimization results efficacy. Moreover, to prove that the iOSA is a promising alternative for optimization and image processing problems, statistical tests and analyses were also conducted.},
  archive      = {J_IJMLC},
  author       = {del Río, Andrea H. and Aranguren, Itzel and Oliva, Diego and Elaziz, Mohamed Abd and Cuevas, Erik},
  doi          = {10.1007/s13042-020-01161-z},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {1},
  pages        = {131-150},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Efficient image segmentation through 2D histograms and an improved owl search algorithm},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Clinical quantitative information recognition and
entity-quantity association from chinese electronic medical records.
<em>IJMLC</em>, <em>12</em>(1), 117–130. (<a
href="https://doi.org/10.1007/s13042-020-01160-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Clinical quantitative information contains crucial measurable expressions of patients’ diseases and treatment conditions, which are commonly exist in free-text electronic medical records. Although the clinical quantitative information is of considerable significance in assisting the analysis of health care, few researches have yet focused on the topic and it remains an ongoing challenge. Focusing on Chinese electronic medical records, this paper proposed an extended Bi-LSTM-CRF model, which integrated domain knowledge information and position characteristics of quantitative information as external features to improve the effectiveness of clinical quantitative information recognition. In addition, to associate the extracted entities and quantities more effectively, this paper presented an automatic approach for entity-quantity association using machine learning strategy. Based on 1359 actual Chinese electronic medical records from burn department of a domestic public hospital, we compared our model with a number of widely-used baseline methods. The evaluation results showed that our model outperformed the baselines with an F1-measure of 94.27\% for quantitative information recognition and an accuracy of 94.60\% for entity-quantity association, demonstrating its effectiveness.},
  archive      = {J_IJMLC},
  author       = {Liu, Shanshan and Nie, Wenjie and Gao, Dongfa and Yang, Hao and Yan, Jun and Hao, Tianyong},
  doi          = {10.1007/s13042-020-01160-0},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {1},
  pages        = {117-130},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Clinical quantitative information recognition and entity-quantity association from chinese electronic medical records},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Causative label flip attack detection with data complexity
measures. <em>IJMLC</em>, <em>12</em>(1), 103–116. (<a
href="https://doi.org/10.1007/s13042-020-01159-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A causative attack which manipulates training samples to mislead learning is a common attack scenario. Current countermeasures reduce the influence of the attack to a classifier with the loss of generalization ability. Therefore, the collected samples should be analyzed carefully. Most countermeasures of current causative attack focus on data sanitization and robust classifier design. To our best knowledge, there is no work to determinate whether a given dataset is contaminated by a causative attack. In this study, we formulate a causative attack detection as a 2-class classification problem in which a sample represents a dataset quantified by data complexity measures, which describe the geometrical characteristics of data. As geometrical natures of a dataset are changed by a causative attack, we believe data complexity measures provide useful information for causative attack detection. Furthermore, a two-step secure classification model is proposed to demonstrate how the proposed causative attack detection improves the robustness of learning. Either a robust or traditional learning method is used according to the existence of causative attack. Experimental results illustrate that data complexity measures separate untainted datasets from attacked ones clearly, and confirm the promising performance of the proposed methods in terms of accuracy and robustness. The results consistently suggest that data complexity measures provide the crucial information to detect causative attack, and are useful to increase the robustness of learning.},
  archive      = {J_IJMLC},
  author       = {Chan, Patrick P. K. and He, Zhimin and Hu, Xian and Tsang, Eric C. C. and Yeung, Daniel S. and Ng, Wing W. Y.},
  doi          = {10.1007/s13042-020-01159-7},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {1},
  pages        = {103-116},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Causative label flip attack detection with data complexity measures},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Accelerating ELM training over data streams. <em>IJMLC</em>,
<em>12</em>(1), 87–102. (<a
href="https://doi.org/10.1007/s13042-020-01158-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the field of machine learning, offline training and online training occupy the same important position because they coexist in many real applications. The extreme learning machine (ELM) has the characteristics of fast learning speed and high accuracy for offline training, and online sequential ELM (OS-ELM) is a variant of ELM that supports online training. With the explosive growth of data volume, running these algorithms on distributed computing platforms is an unstoppable trend, but there is currently no efficient distributed framework to support both ELM and OS-ELM. Apache Flink is an open-source stream-based distributed platform for both offline processing and online data processing with good scalability, high throughput, and fault-tolerant ability, so it can be used to accelerate both ELM and OS-ELM. In this paper, we first research the characteristics of ELM, OS-ELM and distributed computing platforms, then propose an efficient stream-based distributed framework for both ELM and OS-ELM, named ELM-SDF, which is implemented on Flink. We then evaluate the algorithms in this framework with synthetic data on distributed cluster. In summary, the advantages of the proposed framework are highlighted as follows. (1) The training speed of FLELM is always faster than ELM on Hadoop and Spark, and its scalability behaves better as well. (2) Response time and throughput of FLOS-ELM achieve better performance than OS-ELM on Hadoop and Spark when the incremental training samples arrive. (3) The response time and throughput of FLOS-ELM behave better in native-stream processing mode when the incremental data samples are continuously arriving.},
  archive      = {J_IJMLC},
  author       = {Ji, Hangxu and Wu, Gang and Wang, Guoren},
  doi          = {10.1007/s13042-020-01158-8},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {1},
  pages        = {87-102},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Accelerating ELM training over data streams},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Fine-grained pornographic image recognition with multiple
feature fusion transfer learning. <em>IJMLC</em>, <em>12</em>(1), 73–86.
(<a href="https://doi.org/10.1007/s13042-020-01157-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image has become a main medium of Internet information dissemination, makes it easy for an Internet visitor to get pornographic images with just few clicks on websites. It is necessary to build pornographic image recognition systems since uncontrolled spreading of adult content could be harm to the adolescents. Previous solutions for pornographic image recognition are usually based on hand-crafted features like human skin color. Hand-crafted feature based methods are straightforward to understand and use but limited in specific situations. In this paper, we propose a deep learning based approach with multiple feature fusion transfer learning strategy. Firstly, we obtain the training data from an open data set called NSFW with 120,000+ images. Images would be classified into different levels according to its content sensitivity. Then we employ data augment methods, train a deep convolutional neural network to extract image features and conduct the classification job, without the need for hand-crafted rules. A pre-trained model is used to initialize the network and help extract the basic features. Furthermore, we propose a fusion method that makes use of multiple transfer learning models in inference, to improve the accuracy on the test set. The experimental results prove that our method achieves high accuracy on the pornographic image recognition and inspection task.},
  archive      = {J_IJMLC},
  author       = {Lin, Xinnan and Qin, Feiwei and Peng, Yong and Shao, Yanli},
  doi          = {10.1007/s13042-020-01157-9},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {1},
  pages        = {73-86},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Fine-grained pornographic image recognition with multiple feature fusion transfer learning},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A new framework of multi-objective evolutionary algorithms
for feature selection and multi-label classification of video data.
<em>IJMLC</em>, <em>12</em>(1), 53–71. (<a
href="https://doi.org/10.1007/s13042-020-01156-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There are few studies in the literature to address the multi-objective multi-label feature selection for the classification of video data using evolutionary algorithms. Selecting the most appropriate subset of features is a significant problem while maintaining/improving the accuracy of the prediction results. This study proposes a framework of parallel multi-objective Non-dominated Sorting Genetic Algorithms (NSGA-II) for exploring a Pareto set of non-dominated solutions. The subsets of non-dominated features are extracted and validated by multi-label classification techniques, Binary Relevance (BR), Classifier Chains (CC), Pruned Sets (PS), and Random k-Labelset (RAkEL). Base classifiers such as Support Vector Machines (SVM), J48-Decision Tree (J48), and Logistic Regression (LR) are performed in the classification phase of the algorithms. Comprehensive experiments are carried out with local feature descriptors extracted from two multi-label data sets, the well-known MIR-Flickr dataset and a Wireless Multimedia Sensor (WMS) dataset that we have generated from our video recordings. The prediction accuracy levels are improved by 6.36\% and 25.7\% for the MIR-Flickr and WMS datasets respectively while the number of features is significantly reduced. The results verify that the algorithms presented in this new framework outperform the state-of-the-art algorithms.},
  archive      = {J_IJMLC},
  author       = {Karagoz, Gizem Nur and Yazici, Adnan and Dokeroglu, Tansel and Cosar, Ahmet},
  doi          = {10.1007/s13042-020-01156-w},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {1},
  pages        = {53-71},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A new framework of multi-objective evolutionary algorithms for feature selection and multi-label classification of video data},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Attribute reduction in formal decision contexts and its
application to finite topological spaces. <em>IJMLC</em>,
<em>12</em>(1), 39–52. (<a
href="https://doi.org/10.1007/s13042-020-01147-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Attribute reduction in formal decision contexts has become one of the key issues in the research and development of formal concept analysis (FCA) and its applications. As far as we know, however, most of the existing reduction methods for formal decision contexts are time-consuming especially for the large-scale data. This paper investigates the attribute reduction method for large-scale formal decision contexts. The computation of a discernibility matrix is an important step in the development of the corresponding reduction method. A simple and powerful method to efficiently calculate the discernibility matrix of formal decision contexts is first presented. In addition, a heuristic algorithm for searching the optimal reduct is then proposed. Thirdly, as an application of the new results, we discuss the problem of finding the minimal subbases of finite topological spaces. It has shown that the method of attribute reduction in formal decision contexts can be used to obtain all the minimal subbases of a finite topological space. Furthermore, we present an algorithm for computing the minimal subbase of a topological space, based on the attribute reduction method proposed in this paper. Finally, two groups of experiments are carried out on some large-scale data sets to verify the effectiveness of the proposed algorithms.},
  archive      = {J_IJMLC},
  author       = {Chen, Jinkun and Mi, Jusheng and Xie, Bin and Lin, Yaojin},
  doi          = {10.1007/s13042-020-01147-x},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {1},
  pages        = {39-52},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Attribute reduction in formal decision contexts and its application to finite topological spaces},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Dynamic dominance-based multigranulation rough sets
approaches with evolving ordered data. <em>IJMLC</em>, <em>12</em>(1),
17–38. (<a href="https://doi.org/10.1007/s13042-020-01119-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In practical applications, there exist lots of ordered information systems (OISs). In the process of dealing with OISs, dominant preference, which plays a significant role in decision making, should be taken into consideration. With the increasing of data capacity, OISs often evolve with time. In order to extract updated knowledge from evolving ordered data, we have to elaborate computation efforts to re-calculate entire data, which consumes a significant computational cost. Therefore, the computational efficiency is extremely low. In response to this challenge, matrix-based dynamic dominance-based multigranulation rough sets (DMGRSs) approaches, which can improve computational efficiency for updating knowledge, are explored to update multigranulation approximations in dynamic ordered information systems with evolving data. To begin with, we present a matrix representation of dominance-based multigranulation approximations according to the dominant relation matrix and relevant column vectors of each granular structure. Afterwards, the incremental strategies to update dominance-based multigranulation approximations in OISs are proposed when adding or deleting objects. Furthermore, the corresponding dynamic algorithms, which avoid some unnecessary calculations, are explored in DMGRSs. Finally, extensive experiments carried out on nine UCI data sets indicate that the explored dynamic algorithms can achieve promising performance.},
  archive      = {J_IJMLC},
  author       = {Hu, Chengxiang and Zhang, Li},
  doi          = {10.1007/s13042-020-01119-1},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {1},
  pages        = {17-38},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Dynamic dominance-based multigranulation rough sets approaches with evolving ordered data},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-objective unit commitment optimization with ultra-low
emissions under stochastic and fuzzy uncertainties. <em>IJMLC</em>,
<em>12</em>(1), 1–15. (<a
href="https://doi.org/10.1007/s13042-020-01103-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Low cost, high reliability and low pollution are prime targets when performing current unit commitment optimization. As an extension of previous works, this study establishes a multi-objective unit commitment model which takes into account all of the above targets. The main content includes: First, the pricing support for thermal units with ultra-low emissions is involved when analyzing the operation cost of generation systems, which accords with the current policy of power markets. Second, a conditional Value-at-Risk-based measurement is formed to estimate system reliability considering the stochastic and fuzzy uncertainties existed in future load, renewable generation and equipment failures, which is sensitive to tail risks and provides easy-to-adjust conservativeness against worst-case scenarios. Third, to deal with the proposed model, a practical approach is applied to develop a multi-objective particle swarm optimization algorithm, which improves the Pareto fronts obtained by existing methods. The effectiveness of this research is exemplified by two case studies, which demonstrate that the model finds appropriate pricing support for the reformed units, and the proposed reliability measurement is able to realize a number of trade-offs between cost effective and solution robustness, thus providing decision support for system operators. Finally, the comparisons on performance metrics such as spacing and hyper-volume also justify the superiority of the algorithm.},
  archive      = {J_IJMLC},
  author       = {Li, You and Li, Huaxiong and Wang, Bo and Zhou, Min and Jin, Mei},
  doi          = {10.1007/s13042-020-01103-9},
  journal      = {International Journal of Machine Learning and Cybernetics},
  number       = {1},
  pages        = {1-15},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Multi-objective unit commitment optimization with ultra-low emissions under stochastic and fuzzy uncertainties},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
</ul>

</body>
</html>
