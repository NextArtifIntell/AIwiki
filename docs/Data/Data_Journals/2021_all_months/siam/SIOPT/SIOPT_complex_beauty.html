<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>SIOPT_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="siopt---120">SIOPT - 120</h2>
<ul>
<li><details>
<summary>
(2021). Generalized leibniz rules and lipschitzian stability for
expected-integral mappings. <em>SIOPT</em>, <em>31</em>(4), 3212–3246.
(<a href="https://doi.org/10.1137/21M1392541">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is devoted to the study of the expected-integral multifunctions given in the form ${{E}_{\Phi}}(x):=\int_T\Phi_t(x)d\mu$, where $\Phi\colon T\times\X\;{\lower {$\rightarrow$}}\kern {\raise {$\rightarrow$}}\;\Y$ is a set-valued mapping on a measure space $(T,\mathcal{A},\mu)$. Such multifunctions appear in applications to stochastic programming, which require developing efficient calculus rules of generalized differentiation. Major calculus rules are developed in this paper for coderivatives of multifunctions ${E}_{\Phi}$ and second-order subdifferentials of the corresponding expected-integral functionals with applications to constraint systems arising in stochastic programming. The paper is self-contained with presentation in the preliminaries of some needed results on sequential first-order subdifferential calculus of expected-integral functionals taken from the first paper of this series.},
  archive      = {J_SIOPT},
  author       = {Boris Mordukhovich and Pedro Pérez-Aros},
  doi          = {10.1137/21M1392541},
  journal      = {SIAM Journal on Optimization},
  number       = {4},
  pages        = {3212-3246},
  shortjournal = {SIAM J. Optim.},
  title        = {Generalized leibniz rules and lipschitzian stability for expected-integral mappings},
  volume       = {31},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Quadratic convergence of smoothing newton’s method for 0/1
loss optimization. <em>SIOPT</em>, <em>31</em>(4), 3184–3211. (<a
href="https://doi.org/10.1137/21M1409445">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It has been widely recognized that the 0/1-loss function is one of the most natural choices for modelling classification errors, and it has a wide range of applications including support vector machines and 1-bit compressed sensing. Due to the combinatorial nature of the 0/1 loss function, methods based on convex relaxations or smoothing approximations have dominated the existing research and are often able to provide approximate solutions of good quality. However, those methods are not optimizing the 0/1 loss function directly and hence no optimality has been established for the original problem. This paper aims to study the optimality conditions of the 0/1 function minimization and for the first time to develop Newton&#39;s method that directly optimizes the 0/1 function with a local quadratic convergence under reasonable conditions. Extensive numerical experiments demonstrate its superior performance as one would expect from Newton-type methods.},
  archive      = {J_SIOPT},
  author       = {Shenglong Zhou and Lili Pan and Naihua Xiu and Hou-Duo Qi},
  doi          = {10.1137/21M1409445},
  journal      = {SIAM Journal on Optimization},
  number       = {4},
  pages        = {3184-3211},
  shortjournal = {SIAM J. Optim.},
  title        = {Quadratic convergence of smoothing newton&#39;s method for 0/1 loss optimization},
  volume       = {31},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A simplex method for countably infinite linear programs.
<em>SIOPT</em>, <em>31</em>(4), 3157–3183. (<a
href="https://doi.org/10.1137/19M1303939">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce a simplex method for general countably infinite linear programs. Previous literature has focused on special cases, such as infinite network flow problems or Markov decision processes. A novel aspect of our approach is the placing of data and decision variables in a Hilbert space that elegantly encodes a “discounted” weighting to ensure the continuity of infinite sums. Under some assumptions, including that all basic feasible solutions are nondegenerate with strictly positive support and the set of bases is closed in an appropriate topology, we show convergence to the optimal value for our proposed simplex algorithm. We show that existing applications naturally fit this more general framework.},
  archive      = {J_SIOPT},
  author       = {Archis Ghate and Christopher T. Ryan and Robert L. Smith},
  doi          = {10.1137/19M1303939},
  journal      = {SIAM Journal on Optimization},
  number       = {4},
  pages        = {3157-3183},
  shortjournal = {SIAM J. Optim.},
  title        = {A simplex method for countably infinite linear programs},
  volume       = {31},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Optimization of stochastic blackboxes with adaptive
precision. <em>SIOPT</em>, <em>31</em>(4), 3127–3156. (<a
href="https://doi.org/10.1137/20M1318894">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In derivative-free and blackbox optimization, the objective function is often evaluated through the execution of a computer program seen as a blackbox. It can be stochastic, in the sense that an additive centered Gaussian random noise is present in the output. Sometimes, the distribution of the noise is tunable, and its standard deviation can be chosen at any execution of the blackbox. A common strategy to deal with such a situation is to define a sequence of standard deviation values monotonically decreasing to zero with the iterations to ensure convergence of algorithms because the noise is asymptotically dismantled. However, in practice a monotonic reduction of the standard deviation monotonically increases the computation time and makes the optimization process long. There is another strategy, which does not force the standard deviation per iteration to monotonically diminish. This work proposes an algorithmic framework adapted from the deterministic Mads algorithm, on which these two strategies can be expressed. Although these strategies are proved to be theoretically equivalent, tests on analytical problems and on an industrial blackbox with non-Gaussian noise distribution are presented to illustrate practical differences.},
  archive      = {J_SIOPT},
  author       = {Stéphane Alarie and Charles Audet and Pierre-Yves Bouchet and Sébastien Le Digabel},
  doi          = {10.1137/20M1318894},
  journal      = {SIAM Journal on Optimization},
  number       = {4},
  pages        = {3127-3156},
  shortjournal = {SIAM J. Optim.},
  title        = {Optimization of stochastic blackboxes with adaptive precision},
  volume       = {31},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Exact penalty function for <span
class="math inline"><em>ℓ</em><sub>2, 1</sub></span> norm minimization
over the stiefel manifold. <em>SIOPT</em>, <em>31</em>(4), 3097–3126.
(<a href="https://doi.org/10.1137/20M1354313">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {$\ell_{2,1}$ norm minimization with orthogonality constraints, which comprise a feasible region called the Stiefel manifold, has wide applications in statistics and data science. The state-of-the-art approaches adopt a proximal gradient technique on either the Stiefel manifold or its tangent spaces. The consequent subproblem does not have a closed-form solution and hence requires an iterative procedure to solve, which is usually time-consuming. In this paper, we discover that the Lagrangian multipliers of the orthogonality constraints in this class of problems are of closed-form expressions. By using this closed-form expression, we introduce a penalty function for this type of problem. We theoretically demonstrate the equivalence between the penalty function and the original $\ell_{2,1}$ norm minimization under mild assumptions. Based on the exact penalty function, we propose an inexact proximal gradient method in which the subproblem is of closed-form solution. The global convergence and the worst case complexity are established. Numerical experiments illustrate the advantages of our method when compared with the existing proximal-based first-order methods.},
  archive      = {J_SIOPT},
  author       = {Nachuan Xiao and Xin Liu and Ya-xiang Yuan},
  doi          = {10.1137/20M1354313},
  journal      = {SIAM Journal on Optimization},
  number       = {4},
  pages        = {3097-3126},
  shortjournal = {SIAM J. Optim.},
  title        = {Exact penalty function for $\ell_{2,1}$ norm minimization over the stiefel manifold},
  volume       = {31},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Equipping the barzilai–borwein method with the two
dimensional quadratic termination property. <em>SIOPT</em>,
<em>31</em>(4), 3068–3096. (<a
href="https://doi.org/10.1137/21M1390785">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A novel gradient stepsize is derived at the motivation of equipping the Barzilai--Borwein (BB) method with the two dimensional quadratic termination property. A remarkable feature of the novel stepsize is that its computation only depends on the BB stepsizes in previous iterations and does not require any exact line search or the Hessian, and hence it can easily be extended for nonlinear optimization. By adaptively taking long BB steps and some short steps associated with the new stepsize, we develop an efficient gradient method for quadratic optimization and general unconstrained optimization and extend it to solve extreme eigenvalue problems. The proposed method is further extended for box-constrained optimization and singly linearly box-constrained optimization by incorporating gradient projection techniques. Numerical experiments demonstrate that the proposed method outperforms the most successful gradient methods in the literature.},
  archive      = {J_SIOPT},
  author       = {Ya-Kui Huang and Yu-Hong Dai and Xin-Wei Liu},
  doi          = {10.1137/21M1390785},
  journal      = {SIAM Journal on Optimization},
  number       = {4},
  pages        = {3068-3096},
  shortjournal = {SIAM J. Optim.},
  title        = {Equipping the barzilai--borwein method with the two dimensional quadratic termination property},
  volume       = {31},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Mathematical foundations of distributionally robust
multistage optimization. <em>SIOPT</em>, <em>31</em>(4), 3044–3067. (<a
href="https://doi.org/10.1137/21M1390517">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Distributionally robust optimization involves various probability measures in its problem formulation. They can be bundled to constitute a risk functional. For this equivalence, risk functionals constitute a fundamental building block in distributionally robust stochastic programming. Multistage programming requires conditional versions of risk functionals to reassess future risk after partial realizations and after preceding decisions. This paper discusses a construction of the conditional counterpart of a risk functional by passing its genuine characteristics to its conditional counterparts. It turns out that the conditional risk functionals could be different from the nested analogues of the original (law invariant) risk measure. We also discuss an implication to formulations of distributionally robust stochastic programming and a relation to stochastic games.},
  archive      = {J_SIOPT},
  author       = {Alois Pichler and Alexander Shapiro},
  doi          = {10.1137/21M1390517},
  journal      = {SIAM Journal on Optimization},
  number       = {4},
  pages        = {3044-3067},
  shortjournal = {SIAM J. Optim.},
  title        = {Mathematical foundations of distributionally robust multistage optimization},
  volume       = {31},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). On the complexity of inverse mixed integer linear
optimization. <em>SIOPT</em>, <em>31</em>(4), 3014–3043. (<a
href="https://doi.org/10.1137/20M1377369">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inverse optimization is the problem of determining the values of missing input parameters for an associated forward problem that are closest to given estimates and that will make a given target vector optimal. This study is concerned with the relationship of a particular inverse mixed integer linear optimization problem (MILP) to both the forward problem and the separation problem associated with its feasible region. We show that a decision version of the inverse MILP in which a primal bound is verified is coNP-complete, whereas primal bound verification for the associated forward problem is NP-complete, and that the optimal value verification problems for both the inverse problem and the associated forward problem are complete for the complexity class ${\sf D}^{\sf P}$. We also describe a cutting-plane algorithm for solving inverse MILPs that illustrates the close relationship between the separation problem for the convex hull of solutions to a given MILP and the associated inverse problem. The inverse problem is shown to be equivalent to the separation problem for the radial cone defined by all inequalities that are both valid for the convex hull of solutions to the forward problem and binding at the target vector. Thus, the inverse, forward, and separation problems can be said to be equivalent.},
  archive      = {J_SIOPT},
  author       = {Aykut Bulut and Ted K. Ralphs},
  doi          = {10.1137/20M1377369},
  journal      = {SIAM Journal on Optimization},
  number       = {4},
  pages        = {3014-3043},
  shortjournal = {SIAM J. Optim.},
  title        = {On the complexity of inverse mixed integer linear optimization},
  volume       = {31},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Split-douglas–rachford algorithm for composite monotone
inclusions and split-ADMM. <em>SIOPT</em>, <em>31</em>(4), 2987–3013.
(<a href="https://doi.org/10.1137/21M1395144">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we provide a generalization of the Douglas--Rachford splitting (DRS) and the primal-dual algorithm [L. Condat, J. Optim. Theory Appl., 158 (2013), pp. 460--479; B. C. Vu͂, Adv. Comput. Math., 38 (2013), pp. 667--681] for solving monotone inclusions in a real Hilbert space involving a general linear operator. The proposed method allows for primal and dual nonstandard metrics and activates the linear operator separately from the monotone operators appearing in the inclusion. In the simplest case when the linear operator has full range, it reduces to classical DRS. Moreover, the weak convergence of primal-dual sequences to a Kuhn--Tucker point is guaranteed, generalizing the main result in [B. F. Svaiter, SIAM J. Control Optim., 49 (2011), pp. 280--287]. Inspired by [D. Gabay, Applications of the method of multipliers to variational inequalities, in Augmented Lagrangian Methods: Applications to the Numerical Solution of Boundary-Value Problems, M. Fortin and R. Glowinski, eds., Stud. Math. Appl. 15, North-Holland, Amsterdam, 1983, pp. 299--331], we also derive a new split alternating direction method of multipliers (SADMM) by applying our method to the dual of a convex optimization problem involving a linear operator which can be expressed as the composition of two linear operators. The proposed SADMM activates one linear operator implicitly and the other one explicitly, and we recover ADMM when the latter is set as the identity. Connections and comparisons of our theoretical results with respect to the literature are provided for the main algorithm and SADMM. The flexibility and efficiency of both methods is illustrated via numerical simulations in total variation image restoration and a sparse minimization problem.},
  archive      = {J_SIOPT},
  author       = {Luis M. Bricen͂o-Arias and Fernando Roldán},
  doi          = {10.1137/21M1395144},
  journal      = {SIAM Journal on Optimization},
  number       = {4},
  pages        = {2987-3013},
  shortjournal = {SIAM J. Optim.},
  title        = {Split-douglas--rachford algorithm for composite monotone inclusions and split-ADMM},
  volume       = {31},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). A proximal bundle variant with optimal iteration-complexity
for a large range of prox stepsizes. <em>SIOPT</em>, <em>31</em>(4),
2955–2986. (<a href="https://doi.org/10.1137/20M1327513">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a proximal bundle variant, namely, the relaxed proximal bundle (RPB) method, for solving convex nonsmooth composite optimization problems. Like other proximal bundle variants, RPB solves a sequence of prox bundle subproblems whose objective functions are regularized composite cutting-plane models. Moreover, RPB uses a novel condition to decide whether to perform a serious or null iteration which does not necessarily yield a function value decrease. Optimal iteration-complexity bounds for RPB are established for a large range of prox stepsizes, in both convex and strongly convex settings. To the best of our knowledge, this is the first time that a proximal bundle variant is shown to be optimal for a large range of prox stepsizes. Finally, iteration-complexity results for RPB to obtain iterates satisfying practical termination criteria, rather than near optimal solutions, are also derived.},
  archive      = {J_SIOPT},
  author       = {Jiaming Liang and Renato D. C. Monteiro},
  doi          = {10.1137/20M1327513},
  journal      = {SIAM Journal on Optimization},
  number       = {4},
  pages        = {2955-2986},
  shortjournal = {SIAM J. Optim.},
  title        = {A proximal bundle variant with optimal iteration-complexity for a large range of prox stepsizes},
  volume       = {31},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Tikhonov regularization of a perturbed heavy ball system
with vanishing damping. <em>SIOPT</em>, <em>31</em>(4), 2921–2954. (<a
href="https://doi.org/10.1137/20M1382027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper examines a perturbed heavy ball system with vanishing damping that contains a Tikhonov regularization term in connection to the minimization problem of a convex Fréchet differentiable function. We show that the value of the objective function in the generated trajectories converges in order $o(1/t^2)$ to the global minimum of the objective function. We also obtain fast convergence of the velocities towards zero. Moreover, we ascertain that the trajectories generated by the dynamical system converge weakly to a minimizer of the objective function. Finally, we show that the presence of the Tikhonov regularization term ensures strong convergence of the generated trajectories to the element of minimal norm from the $\operatorname{argmin}$ set of the objective function.},
  archive      = {J_SIOPT},
  author       = {Cristian Daniel Alecsa and Szilárd Csaba László},
  doi          = {10.1137/20M1382027},
  journal      = {SIAM Journal on Optimization},
  number       = {4},
  pages        = {2921-2954},
  shortjournal = {SIAM J. Optim.},
  title        = {Tikhonov regularization of a perturbed heavy ball system with vanishing damping},
  volume       = {31},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Probabilistic guarantees in robust optimization.
<em>SIOPT</em>, <em>31</em>(4), 2893–2920. (<a
href="https://doi.org/10.1137/21M1390967">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We develop a general methodology for deriving probabilistic guarantees for solutions of robust optimization problems. Our analysis applies broadly to any convex compact uncertainty set and to any constraint affected by uncertainty in a concave manner, under minimal assumptions on the underlying stochastic process. Namely, we assume that the coordinates of the noise vector are light-tailed (sub-Gaussian) but not necessarily independent. We introduce the notion of robust complexity of an uncertainty set, which is a robust analogue of the Rademacher and Gaussian complexities encountered in high-dimensional statistics, and which connects the geometry of the uncertainty set with an a priori probabilistic guarantee. Interestingly, the robust complexity involves the support function of the uncertainty set, which also plays a crucial role in the robust counterpart theory for robust linear and nonlinear optimization. For a variety of uncertainty sets of practical interest, we are able to compute it in closed form or derive valid approximations. Our methodology recovers most of the results available in the related literature using first principles and extends them to new uncertainty sets and nonlinear constraints. We also derive improved a posteriori bounds, i.e., significantly tighter bounds which depend on the resulting robust solution.},
  archive      = {J_SIOPT},
  author       = {Dimitris Bertsimas and Dick den Hertog and Jean Pauphilet},
  doi          = {10.1137/21M1390967},
  journal      = {SIAM Journal on Optimization},
  number       = {4},
  pages        = {2893-2920},
  shortjournal = {SIAM J. Optim.},
  title        = {Probabilistic guarantees in robust optimization},
  volume       = {31},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Infeasibility and error bound imply finite convergence of
alternating projections. <em>SIOPT</em>, <em>31</em>(4), 2863–2892. (<a
href="https://doi.org/10.1137/20M1358669">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper combines two ingredients in order to get a rather surprising result on one of the most studied, elegant, and powerful tools for solving convex feasibility problems, the method of alternating projections (MAP). Going back to names such as Kaczmarz and von Neumann, MAP has the ability to track a pair of points realizing minimum distance between two given closed convex sets. Unfortunately, MAP may suffer from arbitrarily slow convergence, and sublinear rates are essentially only surpassed in the presence of some Lipschitzian error bound, which is our first ingredient. The second one is a seemingly unfavorable and unexpected condition, namely, infeasibility. For two non-intersecting closed convex sets satisfying an error bound, we establish finite convergence of MAP. In particular, MAP converges in finitely many steps when applied to a polyhedron and a hyperplane in the case in which they have empty intersection. Moreover, the farther the target sets lie from each other, fewer are the iterations needed by MAP for finding a best approximation pair. Insightful examples and further theoretical and algorithmic discussions accompany our results, including the investigation of finite termination of other projection methods.},
  archive      = {J_SIOPT},
  author       = {Roger Behling and Yunier Bello-Cruz and Luiz-Rafael Santos},
  doi          = {10.1137/20M1358669},
  journal      = {SIAM Journal on Optimization},
  number       = {4},
  pages        = {2863-2892},
  shortjournal = {SIAM J. Optim.},
  title        = {Infeasibility and error bound imply finite convergence of alternating projections},
  volume       = {31},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Well-posedness, optimal control, and sensitivity analysis
for a class of differential variational-hemivariational inequalities.
<em>SIOPT</em>, <em>31</em>(4), 2829–2862. (<a
href="https://doi.org/10.1137/20M1351436">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The objective of the paper is to investigate a dynamical system called a differential variational-hemivariational inequality (DVHVI) which couples an abstract variational-hemivariational inequality of elliptic type and a nonlinear evolution inclusion problem in a Banach space. Under appropriate assumptions, the nonemptiness and compactness of the solution set for DVHVI are established by using the Fan--Knaster--Kuratowski--Mazurkiewicz principle, the Minty approach, and the methods of nonsmooth analysis. Then, we explore properties of solution mapping for DVHVI which involve the relative compactness, continuity, and convergence in the Kuratowski sense. Employing these properties, we prove existence of a solution to the optimal control problem driven by a DVHVI. Next, well-posedness results for DVHVI are obtained, including the existence, uniqueness, and stability of the solution. Furthermore, we study sensitivity of a perturbed problem with multiparameters corresponding to DVHVI. Finally, a comprehensive parabolic-elliptic system with obstacle effect is considered as an illustrative application.},
  archive      = {J_SIOPT},
  author       = {Shengda Zeng and Stanisław Migórski and Zhenhai Liu},
  doi          = {10.1137/20M1351436},
  journal      = {SIAM Journal on Optimization},
  number       = {4},
  pages        = {2829-2862},
  shortjournal = {SIAM J. Optim.},
  title        = {Well-posedness, optimal control, and sensitivity analysis for a class of differential variational-hemivariational inequalities},
  volume       = {31},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Inexact high-order proximal-point methods with auxiliary
search procedure. <em>SIOPT</em>, <em>31</em>(4), 2807–2828. (<a
href="https://doi.org/10.1137/20M134705X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we complement the framework of bilevel unconstrained minimization (BLUM) [Y. Nesterov, Math. Program., to appear] by a new $p$th-order proximal-point method convergent as $O(k^{-(3p+1)/2})$, where $k$ is the iteration counter. As compared with [Y. Nesterov, Math. Program., to appear], we replace the auxiliary line search by a segment search. This allows us to bound its complexity by a logarithm of the desired accuracy. Each step in this search needs an approximate computation of a high-order proximal-point operator. Under the assumption on boundedness of $(p+1)$th derivative of the objective function, this can be done by one step of the $p$th-order augmented tensor method. In this way, for $p=2$, we get a new second-order method with the rate of convergence $O(k^{-7/2})$ and logarithmic complexity of the auxiliary search at each iteration. Another possibility is to compute the proximal-point operator by lower-order minimization methods. As an example, for $p=3$, we consider the upper-level process convergent as $O(k^{-5})$. Assuming the boundedness of fourth derivative, an appropriate approximation of the proximal-point operator can be computed by a second-order method in logarithmic number of iterations. This combination gives a second-order scheme with much better complexity than the existing theoretical limits.},
  archive      = {J_SIOPT},
  author       = {Yurii Nesterov},
  doi          = {10.1137/20M134705X},
  journal      = {SIAM Journal on Optimization},
  number       = {4},
  pages        = {2807-2828},
  shortjournal = {SIAM J. Optim.},
  title        = {Inexact high-order proximal-point methods with auxiliary search procedure},
  volume       = {31},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Existence results for generalized nash equilibrium problems
under continuity-like properties of sublevel sets. <em>SIOPT</em>,
<em>31</em>(4), 2784–2806. (<a
href="https://doi.org/10.1137/20M1353629">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A generalized Nash equilibrium problem corresponds to a noncooperative interaction between a finite set of players in which the cost function and the feasible set of each player depend on the decisions of the others. The classical existence result for generalized equilibria due to Arrow and Debreu requires continuity of the cost functions. In this work, we provide an existence of solutions transferring this hypothesis to a “continuity-like” condition over the sublevel sets of the aforementioned functions. Comparison with Reny&#39;s approach for discontinuous games is also considered.},
  archive      = {J_SIOPT},
  author       = {D. Aussel and K. Cao Van and D. Salas},
  doi          = {10.1137/20M1353629},
  journal      = {SIAM Journal on Optimization},
  number       = {4},
  pages        = {2784-2806},
  shortjournal = {SIAM J. Optim.},
  title        = {Existence results for generalized nash equilibrium problems under continuity-like properties of sublevel sets},
  volume       = {31},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An optimal algorithm for decentralized finite-sum
optimization. <em>SIOPT</em>, <em>31</em>(4), 2753–2783. (<a
href="https://doi.org/10.1137/20M134842X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modern large-scale finite-sum optimization relies on two key aspects: distribution and stochastic updates. For smooth and strongly convex problems, existing decentralized algorithms are slower than modern accelerated variance-reduced stochastic algorithms when run on a single machine and are therefore not efficient. Centralized algorithms are fast, but their scaling is limited by global aggregation steps that result in communication bottlenecks. In this work, we propose an efficient accelerated decentralized stochastic algorithm for finite sums named ADFS, which uses local stochastic proximal updates (which are generally more expensive than gradient updates) and decentralized communications between nodes. On $n$ machines, ADFS minimizes the objective function with $nm$ samples in the same time it takes optimal algorithms to optimize from $m$ samples on one machine. This scaling holds until a critical network size is reached, which depends on communication delays, on the number of samples $m$, and on the network topology. We give a lower bound of complexity to show that ADFS is optimal among decentralized algorithms. To derive ADFS, we first develop an extension of the accelerated proximal coordinate gradient algorithm to arbitrary sampling. Then, we apply this coordinate descent algorithm to a well-chosen dual problem based on an augmented graph approach, leading to the general ADFS algorithm. We illustrate the improvement of ADFS over state-of-the-art decentralized approaches with experiments.},
  archive      = {J_SIOPT},
  author       = {Hadrien Hendrikx and Francis Bach and Laurent Massoulié},
  doi          = {10.1137/20M134842X},
  journal      = {SIAM Journal on Optimization},
  number       = {4},
  pages        = {2753-2783},
  shortjournal = {SIAM J. Optim.},
  title        = {An optimal algorithm for decentralized finite-sum optimization},
  volume       = {31},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Two symmetrized coordinate descent methods can be <span
class="math inline"><em>O</em>(<em>n</em><sup>2</sup>)</span> times
slower than the randomized version. <em>SIOPT</em>, <em>31</em>(4),
2726–2752. (<a href="https://doi.org/10.1137/19M1292473">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Block decomposition algorithms decompose the variable vector into multiple blocks and update a single block with other blocks fixed at each iteration. In each epoch, the blocks are updated according to a certain update order. There are at least two classes of deterministic update orders: nonsymmetric and symmetric. A basic nonsymmetric update order is the cyclic order ($1, 2,\ldots, n$); i.e., the first, second, $\ldots,$ $n$th blocks are updated sequentially in each round. A typical symmetric update order is the symmetric Gauss--Seidel rule ($1, 2, \ldots, n-1, n, n-1, \ldots, 1$). Another example is the Gaussian back substitution rule which starts with the natural order ($1, 2, \ldots, n$) as a prediction step and is followed by a correction step. Recently, coordinate descent with cyclic order was shown to be $\mathcal{O}(n^2)$ times slower than randomized versions in the worst case. A natural question arises: can the symmetrized update orders achieve faster convergence rates than the cyclic order or even get close to the randomized versions? In this paper, we give a negative answer to this question. We show that both Gaussian back substitution and symmetric Gauss--Seidel orders suffer from the same slow convergence issue as the cyclic order in the worst case. In particular, we prove that for unconstrained problems, coordinate descent with these two symmetric update orders can be $\mathcal{O}(n^2)$ times slower than randomized coordinate descent. Besides unconstrained problems, we also empirically study linearly constrained problems with a quadratic objective: we empirically demonstrate that the convergence speed of alternating direction method of multipliers (ADMM) algorithms with these two update orders can be roughly $\mathcal{O}(n^2)$ times slower than randomly permuted ADMM on some problem instances.},
  archive      = {J_SIOPT},
  author       = {Peijun Xiao and Zhisheng Xiao and Ruoyu Sun},
  doi          = {10.1137/19M1292473},
  journal      = {SIAM Journal on Optimization},
  number       = {4},
  pages        = {2726-2752},
  shortjournal = {SIAM J. Optim.},
  title        = {Two symmetrized coordinate descent methods can be $O(n^2)$ times slower than the randomized version},
  volume       = {31},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An optimal-storage approach to semidefinite programming
using approximate complementarity. <em>SIOPT</em>, <em>31</em>(4),
2695–2725. (<a href="https://doi.org/10.1137/19M1244603">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper develops a new storage-optimal algorithm that provably solves almost all semidefinite programs (SDPs). This method is particularly effective for weakly constrained SDPs under appropriate regularity conditions. The key idea is to formulate an approximate complementarity principle: Given an approximate solution to the dual SDP, the primal SDP has an approximate solution whose range is contained in the eigenspace with small eigenvalues of the dual slack matrix. For weakly constrained SDPs, this eigenspace has very low dimension, so this observation significantly reduces the search space for the primal solution. This result suggests an algorithmic strategy that can be implemented with minimal storage: (1) solve the dual SDP approximately; (2) compress the primal SDP to the eigenspace with small eigenvalues of the dual slack matrix; (3) solve the compressed primal SDP. The paper also provides numerical experiments showing that this approach is successful for a range of interesting large-scale SDPs.},
  archive      = {J_SIOPT},
  author       = {Lijun Ding and Alp Yurtsever and Volkan Cevher and Joel A. Tropp and Madeleine Udell},
  doi          = {10.1137/19M1244603},
  journal      = {SIAM Journal on Optimization},
  number       = {4},
  pages        = {2695-2725},
  shortjournal = {SIAM J. Optim.},
  title        = {An optimal-storage approach to semidefinite programming using approximate complementarity},
  volume       = {31},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Local convergence analysis of augmented lagrangian methods
for piecewise linear-quadratic composite optimization problems.
<em>SIOPT</em>, <em>31</em>(4), 2665–2694. (<a
href="https://doi.org/10.1137/20M1375188">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Second-order sufficient conditions for local optimality have been playing an important role in local convergence analysis of optimization algorithms. In this paper, we demonstrate that this condition alone suffices to justify the linear convergence of the primal-dual sequence, generated by the augmented Lagrangian method for piecewise linear-quadratic composite optimization problems, even when the Lagrange multiplier in this class of problems is not unique. Furthermore, we establish the equivalence between the second-order sufficient condition and the quadratic growth condition of the augmented Lagrangian problem for this class of composite optimization problems.},
  archive      = {J_SIOPT},
  author       = {Nguyen T. V. Hang and M. Ebrahim Sarabi},
  doi          = {10.1137/20M1375188},
  journal      = {SIAM Journal on Optimization},
  number       = {4},
  pages        = {2665-2694},
  shortjournal = {SIAM J. Optim.},
  title        = {Local convergence analysis of augmented lagrangian methods for piecewise linear-quadratic composite optimization problems},
  volume       = {31},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Manifold sampling for optimizing nonsmooth nonconvex
compositions. <em>SIOPT</em>, <em>31</em>(4), 2638–2664. (<a
href="https://doi.org/10.1137/20M1378089">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a manifold sampling algorithm for minimizing a nonsmooth composition $f= h\circ F$, where we assume $h$ is nonsmooth and may be inexpensively computed in closed form and $F$ is smooth but its Jacobian may not be available. We additionally assume that the composition $h\circ F$ defines a continuous selection. Manifold sampling algorithms can be classified as model-based derivative-free methods, in that models of $F$ are combined with particularly sampled information about $h$ to yield local models for use within a trust-region framework. We demonstrate that cluster points of the sequence of iterates generated by the manifold sampling algorithm are Clarke stationary. We consider the tractability of three particular subproblems generated by the manifold sampling algorithm and the extent to which inexact solutions to these subproblems may be tolerated. Numerical results demonstrate that manifold sampling as a derivative-free algorithm is competitive with state-of-the-art algorithms for nonsmooth optimization that utilize first-order information about $f$.},
  archive      = {J_SIOPT},
  author       = {Jeffrey Larson and Matt Menickelly and Baoyu Zhou},
  doi          = {10.1137/20M1378089},
  journal      = {SIAM Journal on Optimization},
  number       = {4},
  pages        = {2638-2664},
  shortjournal = {SIAM J. Optim.},
  title        = {Manifold sampling for optimizing nonsmooth nonconvex compositions},
  volume       = {31},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). On the simplicity and conditioning of low rank semidefinite
programs. <em>SIOPT</em>, <em>31</em>(4), 2614–2637. (<a
href="https://doi.org/10.1137/20M1346262">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Low rank matrix recovery problems appear widely in statistics, combinatorics, and imaging. One celebrated method for solving these problems is to formulate and solve a semidefinite program (SDP). It is often known that the exact solution to the SDP with perfect data recovers the solution to the original low rank matrix recovery problem. It is more challenging to show that an approximate solution to the SDP formulated with noisy problem data acceptably solves the original problem; arguments are usually ad hoc for each problem setting, and can be complex. In this paper, we identify a set of conditions that we call simplicity that limit the error due to noisy problem data or incomplete convergence. In this sense, simple SDPs are robust: Simple SDPs can be (approximately) solved efficiently at scale; and the resulting approximate solutions, even with noisy data, can be trusted. Moreover, we show that simplicity holds generically and also for many structured low rank matrix recovery problems, including the stochastic block model, $\mathbb{Z}_2$ synchronization, and matrix completion. Formally, we call an SDP simple if it has a surjective constraint map, admits a unique primal and dual solution pair, and satisfies strong duality and strict complementarity. However, simplicity is not a panacea: We show that the Burer--Monteiro formulation of the SDP may have spurious second-order critical points, even for a simple SDP with a rank 1 solution.},
  archive      = {J_SIOPT},
  author       = {Lijun Ding and Madeleine Udell},
  doi          = {10.1137/20M1346262},
  journal      = {SIAM Journal on Optimization},
  number       = {4},
  pages        = {2614-2637},
  shortjournal = {SIAM J. Optim.},
  title        = {On the simplicity and conditioning of low rank semidefinite programs},
  volume       = {31},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A newton algorithm for semidiscrete optimal transport with
storage fees. <em>SIOPT</em>, <em>31</em>(4), 2586–2613. (<a
href="https://doi.org/10.1137/20M1357226">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce and prove convergence of a damped Newton algorithm to approximate solutions of the semidiscrete optimal transport problem with storage fees, corresponding to a problem with hard capacity constraints. This is a variant of the optimal transport problem arising in queue penalization problems and has applications to data clustering. Our result is novel, as it is the first numerical method with proven convergence for this variant problem; additionally, the algorithm applies to the classical semidiscrete optimal transport problem but does not require any connectedness assumptions on the support of the source measure, in contrast with existing results. Furthermore we find some stability results of the associated Laguerre cells. All of our results come with quantitative rates. We also present some numerical examples.},
  archive      = {J_SIOPT},
  author       = {Mohit Bansil and Jun Kitagawa},
  doi          = {10.1137/20M1357226},
  journal      = {SIAM Journal on Optimization},
  number       = {4},
  pages        = {2586-2613},
  shortjournal = {SIAM J. Optim.},
  title        = {A newton algorithm for semidiscrete optimal transport with storage fees},
  volume       = {31},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An accelerated inexact proximal point method for solving
nonconvex-concave min-max problems. <em>SIOPT</em>, <em>31</em>(4),
2558–2585. (<a href="https://doi.org/10.1137/20M1313222">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents smoothing schemes for obtaining approximate stationary points of unconstrained or linearly constrained composite nonconvex-concave min-max (and hence nonsmooth) problems by applying well-known algorithms to composite smooth approximations of the original problems. More specifically, in the unconstrained (resp., constrained) case, approximate stationary points of the original problem are obtained by applying, to its composite smooth approximation, an accelerated inexact proximal point (resp., quadratic penalty) method presented in a previous paper by the authors. Iteration complexity bounds for both smoothing schemes are also established. Finally, numerical results are given to demonstrate the efficiency of the unconstrained smoothing scheme.},
  archive      = {J_SIOPT},
  author       = {Weiwei Kong and Renato D. C. Monteiro},
  doi          = {10.1137/20M1313222},
  journal      = {SIAM Journal on Optimization},
  number       = {4},
  pages        = {2558-2585},
  shortjournal = {SIAM J. Optim.},
  title        = {An accelerated inexact proximal point method for solving nonconvex-concave min-max problems},
  volume       = {31},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Lattice reformulation cuts. <em>SIOPT</em>, <em>31</em>(4),
2539–2557. (<a href="https://doi.org/10.1137/19M1291145">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Here we consider the question whether the lattice reformulation of a linear integer program can be used to produce effective cutting planes. In particular, we aim at deriving split cuts that cut off more of the integrality gap than Gomory mixed-integer (GMI) inequalities generated from LP-tableaus, while being less computationally demanding than generating the split closure. We consider integer programs (IPs) in the form $\max {{c}{x}\mid {A}{x}={b}, {x}\in{\mathbb{Z}}^n_+}\,$ where the reformulation takes the form $\max{{c}{x}^0+{c}{Q} {\mu}\mid{Q} {\mu} \geq -{x}^0,\ {\mu}\in{\mathbb{Z}}^{n-m}}\,$ where ${Q}$ is an $n \times (n-m)$ integer matrix. Working on an optimal LP-tableau in the ${\mu}$-space allows us to generate $n-m$ GMIs in addition to the $m$ GMIs associated with the optimal tableau in the ${x}$ space. These provide new cuts that can be seen as GMIs associated to $n-m$ nonelementary split directions associated with the reformulation matrix ${Q}$. On the other hand it turns out that the corner polyhedra associated to an LP basis and the GMI or split closures are the same whether working in the ${x}$ or ${\mu}$ spaces. Our theoretical derivations are accompanied by an illustrative computational study. The computations show that the effectiveness of the cuts generated by this approach depends on the quality of the reformulation obtained by the reduced basis algorithm used to generate ${Q}$ and that it is worthwhile to generate several rounds of such cuts. However, the effectiveness of the cuts deteriorates as the number of constraints is increased.},
  archive      = {J_SIOPT},
  author       = {Karen Aardal and Andrea Lodi and Andrea Tramontani and Frederik von Heymann and Laurence A. Wolsey},
  doi          = {10.1137/19M1291145},
  journal      = {SIAM Journal on Optimization},
  number       = {4},
  pages        = {2539-2557},
  shortjournal = {SIAM J. Optim.},
  title        = {Lattice reformulation cuts},
  volume       = {31},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Efficient search of first-order nash equilibria in
nonconvex-concave smooth min-max problems. <em>SIOPT</em>,
<em>31</em>(4), 2508–2538. (<a
href="https://doi.org/10.1137/20M1337600">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose an efficient algorithm for finding first-order Nash equilibria in min-max problems of the form $\textstyle\min_{x \in X}\max_{y\in Y} F(x,y)$, where the objective function is smooth in both variables and concave with respect to $y$; the sets $X$ and $Y$ are convex and “projection-friendly,” and $Y$ is compact. Our goal is to find an $(\varepsilon_{\sf x},\varepsilon_{\sf y})$-first-order Nash equilibrium with respect to a stationarity criterion that is stronger than the commonly used proximal gradient norm. The proposed approach is fairly simple: we perform approximate proximal-point iterations on the primal function, with the inexact oracle provided by Nesterov&#39;s algorithm run on the regularized function $F(x_t,\cdot)$, $x_t$ being the current primal iterate. The resulting iteration complexity is $O({\varepsilon_{\sf x}}^{-2} \, {\varepsilon_{\sf y}}^{-1/2})$ up to a logarithmic factor. As a byproduct, the choice $\varepsilon_{\sf y} = O(\varepsilon_{\sf x}^2)$ allows for the $O({\varepsilon_{\sf x}}^{-3})$ complexity of finding an $\varepsilon_{\sf x}$-stationary point for the standard Moreau envelope of the primal function. Moreover, when the objective is strongly concave with respect to $y$, the complexity estimate for our algorithm improves to $O({\varepsilon_{\sf x}}^{-2}{\kappa_{\sf y}}^{1/2})$ up to a logarithmic factor, where $\kappa_{\sf y}$ is the condition number appropriately adjusted for coupling. In both scenarios, the complexity estimates are the best known so far and are only known for the (weaker) proximal gradient norm criterion. Meanwhile, our approach is “user-friendly”: (i) the algorithm is built upon running a variant of Nesterov&#39;s accelerated algorithm as a subroutine and avoids extragradient steps; (ii) the convergence analysis recycles the well-known results on accelerated methods with an inexact oracle. Finally, we extend the approach to non-Euclidean proximal geometries.},
  archive      = {J_SIOPT},
  author       = {Dmitrii M. Ostrovskii and Andrew Lowy and Meisam Razaviyayn},
  doi          = {10.1137/20M1337600},
  journal      = {SIAM Journal on Optimization},
  number       = {4},
  pages        = {2508-2538},
  shortjournal = {SIAM J. Optim.},
  title        = {Efficient search of first-order nash equilibria in nonconvex-concave smooth min-max problems},
  volume       = {31},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Existence and approximation of continuous bayesian nash
equilibria in games with continuous type and action spaces.
<em>SIOPT</em>, <em>31</em>(4), 2481–2507. (<a
href="https://doi.org/10.1137/19M1298032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Meirowitz [Econom. Lett., 78 (2003), pp. 213--218] showed existence of the continuous Bayesian Nash equilibrium for Bayesian games with continuous type and action spaces under the condition that the best response strategies are equicontinuous. In this paper, we take a step forward by presenting some verifiable conditions for the required equicontinuity, namely, some growth conditions of the expected utility function of each player. Moreover, under some monotonicity conditions, we demonstrate uniqueness of a continuous Bayesian Nash equilibrium. We then move on to develop some computational approaches for finding an approximate continuous Bayesian Nash equilibrium. First, we restrict the response strategies to polynomial functions of certain degree over the type spaces, and consequently finding a polynomial Bayesian Nash equilibrium is reduced to solving a finite dimensional stochastic Nash equilibrium problem. Second, we apply the optimal quantization method to discretize the finite dimensional stochastic Nash equilibrium problem so that the discretized problem becomes an ordinary finite dimensional deterministic Nash equilibrium problem which can be readily solved by existing numerical methods in the literature. In the case when the discretization approach is carried out by sample average approximation, we show exponential rate of convergence with respect to sample size. Finally, we carry out numerical tests on the combined approaches through an illustration with rent-seeking games.},
  archive      = {J_SIOPT},
  author       = {Shaoyan Guo and Huifu Xu and Liwei Zhang},
  doi          = {10.1137/19M1298032},
  journal      = {SIAM Journal on Optimization},
  number       = {4},
  pages        = {2481-2507},
  shortjournal = {SIAM J. Optim.},
  title        = {Existence and approximation of continuous bayesian nash equilibria in games with continuous type and action spaces},
  volume       = {31},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Optimality conditions for convex stochastic optimization
problems in banach spaces with almost sure state constraints.
<em>SIOPT</em>, <em>31</em>(4), 2455–2480. (<a
href="https://doi.org/10.1137/20M1363558">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We analyze a convex stochastic optimization problem where the state is assumed to belong to the Bochner space of essentially bounded random variables with images in a reflexive and separable Banach space. For this problem, we obtain optimality conditions that are, with an appropriate model, necessary and sufficient. Additionally, the Lagrange multipliers associated with optimality conditions are integrable vector-valued functions and are not only measures. A model problem is given demonstrating the application to PDE-constrained optimization under uncertainty with an outlook for further applications.},
  archive      = {J_SIOPT},
  author       = {Caroline Geiersbach and Winnifried Wollner},
  doi          = {10.1137/20M1363558},
  journal      = {SIAM Journal on Optimization},
  number       = {4},
  pages        = {2455-2480},
  shortjournal = {SIAM J. Optim.},
  title        = {Optimality conditions for convex stochastic optimization problems in banach spaces with almost sure state constraints},
  volume       = {31},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Perturbation analysis of metric subregularity for
multifunctions. <em>SIOPT</em>, <em>31</em>(3), 2429–2454. (<a
href="https://doi.org/10.1137/19M1309171">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Considering a closed multifunction $\Psi$ between two Banach spaces, it is known that metric regularity and strong metric subregularity of $\Psi$ are, respectively, stable with respect to “small Lipschitz perturbations” and “small calm perturbations,” but the corresponding results are no longer true for metric subregularity of $\Psi$. This paper further deals with the stability issues of metric subregularity with respect to these two kinds of perturbations. We prove that either metric regularity or strong metric subregularity of $\Psi$ at $(\bar x,\bar y)$ is sufficient for the stability of metric subregularity of $\Psi$ at $(\bar x,\bar y)$ with respect to small calm subsmooth perturbations and that, under the convexity assumption on $\Psi$, it is also necessary for the stability of metric subregularity of $\Psi$ at $(\bar x,\bar y)$ with respect to small calm subsmooth (or Lipschitz) perturbations. Moreover, in terms of the coderivative of $\Psi$, we provide some sufficient and necessary conditions for metric subregularity of $\Psi$ to be stable with respect to small calm perturbations. Some results obtained in this paper improve and generalize the corresponding results for error bounds in the literature.},
  archive      = {J_SIOPT},
  author       = {Xi Yin Zheng and Kung Fu Ng},
  doi          = {10.1137/19M1309171},
  journal      = {SIAM Journal on Optimization},
  number       = {3},
  pages        = {2429-2454},
  shortjournal = {SIAM J. Optim.},
  title        = {Perturbation analysis of metric subregularity for multifunctions},
  volume       = {31},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Generating feasible points for mixed-integer convex
optimization problems by inner parallel cuts. <em>SIOPT</em>,
<em>31</em>(3), 2396–2428. (<a
href="https://doi.org/10.1137/20M131922X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article we introduce an inner parallel cutting plane method (IPCP) to compute good feasible points along with valid cutting planes for mixed-integer convex optimization problems. The method iteratively generates polyhedral outer approximations of an enlarged inner parallel set (EIPS) of the continuously relaxed feasible set. This EIPS possesses the crucial property that any rounding of any of its elements is feasible for the original problem. The outer approximations are refined in each iteration by using modified Kelley cutting planes, which are defined via rounded optimal points of linear optimization problems (LPs). We show that the method either computes a feasible point or certifies that the EIPS is empty. Moreover, we demonstrate how inner parallel cuts can be reversed so that they are valid for the original problem, and we provide bounds on the objective value of the generated feasible points. As there exist consistent problems which possess an empty EIPS, the IPCP is not guaranteed to find a feasible point for the latter. Yet, the crucial advantage of the method lies in the difficulty of each iteration: While other approaches need to solve a mixed-integer linear optimization problem, the IPCP only needs to solve an LP. Indeed, our computational study indicates that the IPCP is able to quickly compute feasible points and reversed inner parallel cutting planes for many practical applications. It further demonstrates that the computed points are generally of good quality and that the reversed inner parallel cuts have the potential to speed up outer approximation--based methods.},
  archive      = {J_SIOPT},
  author       = {Christoph Neumann and Oliver Stein},
  doi          = {10.1137/20M131922X},
  journal      = {SIAM Journal on Optimization},
  number       = {3},
  pages        = {2396-2428},
  shortjournal = {SIAM J. Optim.},
  title        = {Generating feasible points for mixed-integer convex optimization problems by inner parallel cuts},
  volume       = {31},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A lagrange multiplier expression method for bilevel
polynomial optimization. <em>SIOPT</em>, <em>31</em>(3), 2368–2395. (<a
href="https://doi.org/10.1137/20M1352375">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies bilevel polynomial optimization. We propose a method to solve it globally by using polynomial optimization relaxations. Each relaxation is obtained from the Karush--Kuhn--Tucker (KKT) conditions for the lower level optimization and the exchange technique for semi-infinite programming. For KKT conditions, Lagrange multipliers are represented as polynomial or rational functions. The Moment--sum-of-squares relaxations are used to solve the polynomial optimization relaxations. Under some general assumptions, we prove the convergence of the algorithm for solving bilevel polynomial optimization problems. Numerical experiments are presented to show the efficiency of the method.},
  archive      = {J_SIOPT},
  author       = {Jiawang Nie and Li Wang and Jane J. Ye and Suhan Zhong},
  doi          = {10.1137/20M1352375},
  journal      = {SIAM Journal on Optimization},
  number       = {3},
  pages        = {2368-2395},
  shortjournal = {SIAM J. Optim.},
  title        = {A lagrange multiplier expression method for bilevel polynomial optimization},
  volume       = {31},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A unified approach to mixed-integer optimization problems
with logical constraints. <em>SIOPT</em>, <em>31</em>(3), 2340–2367. (<a
href="https://doi.org/10.1137/20M1346778">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a unified framework to address a family of classical mixed-integer optimization problems with logically constrained decision variables, including network design, facility location, unit commitment, sparse portfolio selection, binary quadratic optimization, sparse principal component analysis, and sparse learning problems. These problems exhibit logical relationships between continuous and discrete variables, which are usually reformulated linearly using a big-$M$ formulation. In this work, we challenge this long-standing modeling practice and express the logical constraints in a nonlinear way. By imposing a regularization condition, we reformulate these problems as convex binary optimization problems, which are solvable using an outer-approximation procedure. In numerical experiments, we establish that a general-purpose numerical strategy, which combines cutting-plane, first-order, and local search methods, solves these problems faster and at a larger scale than state-of-the-art mixed-integer linear or second-order cone methods. Our approach successfully solves network design problems with 100s of nodes and provides solutions up to 40\% better than the state of the art, sparse portfolio selection problems with up to 3,200 securities compared with 400 securities for previous attempts, and sparse regression problems with up to 100,000 covariates.},
  archive      = {J_SIOPT},
  author       = {Dimitris Bertsimas and Ryan Cory-Wright and Jean Pauphilet},
  doi          = {10.1137/20M1346778},
  journal      = {SIAM Journal on Optimization},
  number       = {3},
  pages        = {2340-2367},
  shortjournal = {SIAM J. Optim.},
  title        = {A unified approach to mixed-integer optimization problems with logical constraints},
  volume       = {31},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Conditional gradient methods for convex optimization with
general affine and nonlinear constraints. <em>SIOPT</em>,
<em>31</em>(3), 2307–2339. (<a
href="https://doi.org/10.1137/20M1352788">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conditional gradient methods have attracted much attention in both machine learning and optimization communities recently. These simple methods can guarantee the generation of sparse solutions. In addition, without the computation of full gradients, they can handle huge-scale problems sometimes even with an exponentially increasing number of decision variables. This paper aims to significantly expand the application areas of these methods by presenting new conditional gradient methods for solving convex optimization problems with general affine and nonlinear constraints. More specifically, we first present a new constraint extrapolated condition gradient (CoexCG) method that can achieve an ${\cal O}(1/\epsilon^2)$ iteration complexity for both smooth and structured nonsmooth function constrained convex optimization. We further develop novel variants of CoexCG, namely constraint extrapolated and dual regularized conditional gradient (CoexDurCG) methods, that can achieve similar iteration complexity to CoexCG but allow adaptive selection for algorithmic parameters. We illustrate the effectiveness of these methods for solving an important class of radiation therapy treatment planning problems arising from the healthcare industry. To the best of our knowledge, all the algorithmic schemes and their complexity results are new in the area of projection-free methods.},
  archive      = {J_SIOPT},
  author       = {Guanghui Lan and Edwin Romeijn and Zhiqiang Zhou},
  doi          = {10.1137/20M1352788},
  journal      = {SIAM Journal on Optimization},
  number       = {3},
  pages        = {2307-2339},
  shortjournal = {SIAM J. Optim.},
  title        = {Conditional gradient methods for convex optimization with general affine and nonlinear constraints},
  volume       = {31},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Minimizing rational functions: A hierarchy of approximations
via pushforward measures. <em>SIOPT</em>, <em>31</em>(3), 2285–2306. (<a
href="https://doi.org/10.1137/20M138541X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is concerned with minimizing a sum of rational functions over a compact set of high dimension. Our approach relies on the second Lasserre hierarchy (also known as the upper bounds hierarchy) formulated on the pushforward measure in order to work in a space of smaller dimension. We show that in the general case, the minimum can be approximated as closely as desired from above with a hierarchy of semidefinite programs problems or, in the particular case of a single fraction, with a hierarchy of generalized eigenvalue problems. We numerically illustrate the potential of using the pushforward measure rather than the standard upper bounds hierarchy. In our opinion, this potential should be a strong incentive to investigate a related challenging problem interesting on its own, namely, integrating an arbitrary power of a given polynomial on a simple set (e.g., unit box or unit sphere) with respect to the Lebesgue or Haar measure.},
  archive      = {J_SIOPT},
  author       = {Jean Bernard Lasserre and Victor Magron and Swann Marx and Olivier Zahm},
  doi          = {10.1137/20M138541X},
  journal      = {SIAM Journal on Optimization},
  number       = {3},
  pages        = {2285-2306},
  shortjournal = {SIAM J. Optim.},
  title        = {Minimizing rational functions: A hierarchy of approximations via pushforward measures},
  volume       = {31},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An SQP method for equality constrained optimization on
hilbert manifolds. <em>SIOPT</em>, <em>31</em>(3), 2255–2284. (<a
href="https://doi.org/10.1137/20M1341325">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We extend a sequential quadratic programming method for equality constrained optimization to the setting of Hilbert manifolds. The use of retractions and linearizing maps allows us to pull back the functional and the constraint mapping to linear spaces and then linearize the problem. We study local quadratic convergence to minimizers. In addition, we present a composite step method for globalization based on cubic regularization of the objective function and affine covariant damped Newton method for feasibility and show transition to fast local convergence. We test our method on an equilibrium problem in elasticity where an inextensible elastic rod under dead loads is simulated.},
  archive      = {J_SIOPT},
  author       = {Anton Schiela and Julian Ortiz},
  doi          = {10.1137/20M1341325},
  journal      = {SIAM Journal on Optimization},
  number       = {3},
  pages        = {2255-2284},
  shortjournal = {SIAM J. Optim.},
  title        = {An SQP method for equality constrained optimization on hilbert manifolds},
  volume       = {31},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Optimizing hypergraph-based polynomials modeling
job-occupancy in queuing with redundancy scheduling. <em>SIOPT</em>,
<em>31</em>(3), 2227–2254. (<a
href="https://doi.org/10.1137/20M1369592">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We investigate two classes of multivariate polynomials with variables indexed by the edges of a uniform hypergraph and coefficients depending on certain patterns of unions of edges. These polynomials arise naturally to model job-occupancy in some queuing problems with redundancy scheduling policies. The question, posed by Cardinaels, Borst, and van Leeuwaarden in [Redundancy Scheduling with Locally Stable Compatibility Graphs, arXiv preprint, 2020], is to decide whether their global minimum over the standard simplex is attained at the uniform probability distribution. By exploiting symmetry properties of these polynomials we can give a positive answer for the first class and partial results for the second one, where we in fact show a stronger convexity property of these polynomials over the simplex.},
  archive      = {J_SIOPT},
  author       = {D. Brosch and M. Laurent and A. Steenkamp},
  doi          = {10.1137/20M1369592},
  journal      = {SIAM Journal on Optimization},
  number       = {3},
  pages        = {2227-2254},
  shortjournal = {SIAM J. Optim.},
  title        = {Optimizing hypergraph-based polynomials modeling job-occupancy in queuing with redundancy scheduling},
  volume       = {31},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Nonlinear forward-backward splitting with projection
correction. <em>SIOPT</em>, <em>31</em>(3), 2199–2226. (<a
href="https://doi.org/10.1137/20M1345062">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose and analyze a versatile and general algorithm called nonlinear forward-backward splitting (NOFOB). The algorithm consists of two steps; first an evaluation of a nonlinear forward-backward map followed by a relaxed projection onto the separating hyperplane it constructs. The key to the method is the nonlinearity in the forward-backward step, where the backward part is based on a nonlinear resolvent construction that allows for the kernel in the resolvent to be a nonlinear single-valued maximal monotone operator. This generalizes the standard resolvent as well as the Bregman resolvent, whose resolvent kernels are gradients of convex functions. This construction opens up a new understanding of many existing operator splitting methods and paves the way for devising new algorithms. In particular, we present a four-operator splitting method as a special case of NOFOB that relies on nonlinearity and nonsymmetry in the forward-backward kernel. We show that forward-backward-forward splitting (FBF), forward-backward-half-forward splitting (FBHF), and asymmetric forward-backward-adjoint splitting with its many special cases are special cases of the four-operator splitting method and hence of NOFOB. We also show that standard formulations of FB(H)F use smaller relaxations in the projections than allowed in NOFOB. Besides proving convergence for NOFOB, we show linear convergence under a metric subregularity assumption, which in a unified manner shows (in some cases new) linear convergence results for its special cases.},
  archive      = {J_SIOPT},
  author       = {Pontus Giselsson},
  doi          = {10.1137/20M1345062},
  journal      = {SIAM Journal on Optimization},
  number       = {3},
  pages        = {2199-2226},
  shortjournal = {SIAM J. Optim.},
  title        = {Nonlinear forward-backward splitting with projection correction},
  volume       = {31},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A method with convergence rates for optimization problems
with variational inequality constraints. <em>SIOPT</em>, <em>31</em>(3),
2171–2198. (<a href="https://doi.org/10.1137/20M1357378">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a class of optimization problems with Cartesian variational inequality (CVI) constraints, where the objective function is convex and the CVI is associated with a monotone mapping and a convex Cartesian product set. This mathematical formulation captures a wide range of optimization problems including those complicated by the presence of equilibrium constraints, complementarity constraints, or an inner-level large scale optimization problem. In particular, an important motivating application arises from the notion of efficiency estimation of equilibria in multi-agent networks, e.g., communication networks and power systems. In the literature, the iteration complexity of the existing solution methods for optimization problems with CVI constraints appears to be unknown. To address this shortcoming, we develop a first-order method called averaging randomized block iteratively regularized gradient (aRB-IRG). The main contributions include the following: (i) In the case where the associated set of the CVI is bounded and the objective function is nondifferentiable and convex, we derive new nonasymptotic suboptimality and infeasibility convergence rate statements in an ergodic sense. We also obtain deterministic variants of the convergence rates when we suppress the randomized block-coordinate scheme. Importantly, this paper appears to be the first work to provide these rate guarantees for this class of problems. (ii) In the case where the CVI set is unbounded and the objective function is smooth and strongly convex, utilizing the properties of the Tikhonov trajectory, we establish the global convergence of aRB-IRG in an almost sure and a mean sense. We provide the numerical experiments for computing the best Nash equilibrium in a networked Cournot competition model.},
  archive      = {J_SIOPT},
  author       = {Harshal D. Kaushik and Farzad Yousefian},
  doi          = {10.1137/20M1357378},
  journal      = {SIAM Journal on Optimization},
  number       = {3},
  pages        = {2171-2198},
  shortjournal = {SIAM J. Optim.},
  title        = {A method with convergence rates for optimization problems with variational inequality constraints},
  volume       = {31},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A smooth inexact penalty reformulation of convex problems
with linear constraints. <em>SIOPT</em>, <em>31</em>(3), 2141–2170. (<a
href="https://doi.org/10.1137/18M1209180">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we consider a constrained convex problem with linear inequalities and provide an inexact penalty reformulation of the problem. The novelty is in the choice of the penalty functions, which are smooth and can induce a nonzero penalty over some points in a feasible region of the original constrained problem. The resulting unconstrained penalized problem is parametrized by two penalty parameters which control the slope and the curvature of the penalty function. With a suitable selection of these penalty parameters, we show that the solutions of the resulting penalized unconstrained problem are feasible for the original constrained problem, under some assumptions. Also, we establish that, with suitable choices of penalty parameters, the solutions of the penalized unconstrained problem can achieve a suboptimal value which is arbitrarily close to the optimal value of the original constrained problem. For the problems with a large number of linear inequality constraints, a particular advantage of such a smooth penalty-based reformulation is that it renders a penalized problem suitable for the implementation of fast incremental gradient methods, which require only one sample from the inequality constraints at each iteration. We consider applying SAGA proposed in [A. Defazio, F. Bach, and S. Lacoste-Julien, SAGA: A fast incremental gradient method with support for non-strongly convex composite objectives, in Proceedings of NIPS, 2014, pp. 1646--1654] to solve the resulting penalized unconstrained problem. Moreover, we propose an alternative approach using a sequence of penalized problem. The approach is based on time-varying penalty parameters and, thus, does not require knowledge of some problem-specific constants that may be difficult to estimate. For a strongly convex objective function, under some conditions on the penalty parameters, we prove that a single-loop full gradient-based algorithm applied to the corresponding time-varying penalized problems converges to the solution of the original constrained problem.},
  archive      = {J_SIOPT},
  author       = {Tatiana Tatarenko and Angelia Nedich},
  doi          = {10.1137/18M1209180},
  journal      = {SIAM Journal on Optimization},
  number       = {3},
  pages        = {2141-2170},
  shortjournal = {SIAM J. Optim.},
  title        = {A smooth inexact penalty reformulation of convex problems with linear constraints},
  volume       = {31},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Stochastic dynamic linear programming: A sequential sampling
algorithm for multistage stochastic linear programming. <em>SIOPT</em>,
<em>31</em>(3), 2111–2140. (<a
href="https://doi.org/10.1137/19M1290735">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multistage stochastic programming deals with operational and planning problems that involve a sequence of decisions over time while responding to an uncertain future. Algorithms designed to address multistage stochastic linear programming (MSLP) problems often rely upon scenario trees to represent the underlying stochastic process. When this process exhibits stagewise independence, sampling-based techniques, particularly the stochastic dual dynamic programming algorithm, have received wide acceptance. However, these sampling-based methods still operate with a deterministic representation of the problem which uses the so-called sample average approximation. In this work, we present a sequential sampling approach for MSLP problems that allows the decision process to assimilate newly sampled data recursively. We refer to this method as the stochastic dynamic linear programming (SDLP) algorithm. Since we use sequential sampling, the algorithm does not necessitate a priori representation of uncertainty, through either a scenario tree or sample average approximation, both of which require a knowledge/estimation of the underlying distribution. This method constitutes a generalization of the stochastic decomposition algorithm for two-stage stochastic linear programming models. The approximations used within SDLP may be viewed either through the lens of proximal methods or via regularization. Furthermore, we introduce the notion of basic feasible policies which provide a piecewise affine solution discovery scheme, which is embedded within the optimization algorithm to identify incumbent solutions used in the context of proximal iterations. Finally, we show that the SDLP algorithm provides a sequence of decisions and corresponding value function estimates along a sequence of state trajectories that asymptotically converge to their optimal counterparts, with probability one.},
  archive      = {J_SIOPT},
  author       = {Harsha Gangammanavar and Suvrajeet Sen},
  doi          = {10.1137/19M1290735},
  journal      = {SIAM Journal on Optimization},
  number       = {3},
  pages        = {2111-2140},
  shortjournal = {SIAM J. Optim.},
  title        = {Stochastic dynamic linear programming: A sequential sampling algorithm for multistage stochastic linear programming},
  volume       = {31},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Inexact cuts in stochastic dual dynamic programming applied
to multistage stochastic nondifferentiable problems. <em>SIOPT</em>,
<em>31</em>(3), 2084–2110. (<a
href="https://doi.org/10.1137/20M1330075">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In [V. Guigues, SIAM J. Optim., 30 (2020), pp. 407--438], an inexact variant of stochastic dual dynamic programming (SDDP) called ISDDP was introduced which uses approximate (instead of exact with SDDP) primal dual solutions of the problems solved in the forward and backward passes of the method. That variant of SDDP was studied in [V. Guigues, SIAM J. Optim., 30 (2020), pp. 407--438] for linear and for differentiable nonlinear multistage stochastic programs (MSPs). In this paper, we extend ISDDP to nondifferentiable MSPs. We first provide formulas for inexact cuts for value functions of convex nondifferentiable optimization problems. We then combine these cuts with SDDP to describe ISDDP for nondifferentiable MSPs and analyze the convergence of the method. More precisely, for a problem with $T$ stages, we show that for errors bounded from above by $\varepsilon$, the limit superior and limit inferior of sequences of upper and lower bounds on the optimal value of the problem are at most at distance $3 \varepsilon T$ to the optimal value and that for asymptotically vanishing errors ISDDP converges to an optimal policy. Finally, we present the results of encouraging numerical experiments on a multistage nondifferentiable stochastic convex program solved using exact SDDP and the proposed ISDDP.},
  archive      = {J_SIOPT},
  author       = {Vincent Guigues and Renato Monteiro and Benar Svaiter},
  doi          = {10.1137/20M1330075},
  journal      = {SIAM Journal on Optimization},
  number       = {3},
  pages        = {2084-2110},
  shortjournal = {SIAM J. Optim.},
  title        = {Inexact cuts in stochastic dual dynamic programming applied to multistage stochastic nondifferentiable problems},
  volume       = {31},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The structure of conservative gradient fields.
<em>SIOPT</em>, <em>31</em>(3), 2080–2083. (<a
href="https://doi.org/10.1137/21M1393637">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The classical Clarke subdifferential alone is inadequate for understanding automatic differentiation in nonsmooth contexts. Instead, we can sometimes rely on enlarged generalized gradients called “conservative fields,” defined through the natural pathwise chain rule: one application is the convergence analysis of gradient-based deep learning algorithms. In the semialgebraic case, we show that all conservative fields are in fact just Clarke subdifferentials plus normals of manifolds in underlying Whitney stratifications.},
  archive      = {J_SIOPT},
  author       = {Adrian S. Lewis and Tonghua Tian},
  doi          = {10.1137/21M1393637},
  journal      = {SIAM Journal on Optimization},
  number       = {3},
  pages        = {2080-2083},
  shortjournal = {SIAM J. Optim.},
  title        = {The structure of conservative gradient fields},
  volume       = {31},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Genericity analysis of multi-leader-disjoint-followers game.
<em>SIOPT</em>, <em>31</em>(3), 2055–2079. (<a
href="https://doi.org/10.1137/20M1356476">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-leader-follower games are models which combine bilevel programming with generalized Nash games. Due to their many applications, they have attracted more and more attention in the last few years. We introduce here a particular case of the so-called multi-leader-disjoint-followers (MLDF) game where there are several leaders acting according to a generalized Nash game and each leader has a number of exclusive followers who interact through a standard Nash game between them. The aim of this paper is to characterize the generic properties of the solutions for an MLDF problem. We show that, generically, good properties such as constraint qualifications and nondegeneracy of the solutions are satisfied at each bilevel problem, except for a zero-Lebesgue measure set and with at most quadratic perturbations of the involved functions. We also prove that these properties will remain stable under small perturbations of the involved functions.},
  archive      = {J_SIOPT},
  author       = {Didier Aussel and Gemayqzel Bouza and Stephan Dempe and Sébastien Lepaul},
  doi          = {10.1137/20M1356476},
  journal      = {SIAM Journal on Optimization},
  number       = {3},
  pages        = {2055-2079},
  shortjournal = {SIAM J. Optim.},
  title        = {Genericity analysis of multi-leader-disjoint-followers game},
  volume       = {31},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Convergence rate analysis of a sequential convex programming
method with line search for a class of constrained difference-of-convex
optimization problems. <em>SIOPT</em>, <em>31</em>(3), 2024–2054. (<a
href="https://doi.org/10.1137/20M1314057">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study the sequential convex programming method with monotone line search (SCP$_{ls}$) in [Z. Lu, Sequential Convex Programming Methods for a Class of Structured Nonlinear Programming, ŭlhttps://arxiv.org/abs/1210.3039, 2012] for a class of difference-of-convex optimization problems with multiple smooth inequality constraints. The SCP$_{ls}$ is a representative variant of moving-ball-approximation-type algorithms [A. Auslender, R. Shefi, and M. Teboulle, SIAM J. Optim., 20 (2010), pp. 3232--3259; J. Bolte, Z. Chen, and E. Pauwels, Math. Program., 182 (2020) pp. 1--36; J. Bolte and E. Pauwels, Math. Oper. Res., 41 (2016), pp. 442--465; R. Shefi and M. Teboulle, Math. Program., 159 (2016), pp. 137--164] for constrained optimization problems. We analyze the convergence rate of the sequence generated by SCP$_{ls}$ in both nonconvex and convex settings by imposing suitable Kurdyka--Łojasiewicz (KL) assumptions. Specifically, in the nonconvex settings, we assume that a special potential function related to the objective and the constraints is a KL function, while in the convex settings we impose KL assumptions directly on the extended objective function (i.e., sum of the objective and the indicator function of the constraint set). A relationship between these two different KL assumptions is established in the convex settings under additional differentiability assumptions. We also discuss how to deduce the KL exponent of the extended objective function from its Lagrangian in the convex settings, under additional assumptions on the constraint functions. Thanks to this result, the extended objectives of some constrained optimization models such as minimizing $\ell_1$ subject to logistic/Poisson loss are found to be KL functions with exponent $\frac12$ under mild assumptions. To illustrate how our results can be applied, we consider SCP$_{ls}$ for minimizing $\ell_{1-2}$ [P. Yin, Y. Lou, Q. He, and J. Xin, SIAM J. Sci. Comput., 37 (2015), pp. A536--A563] subject to residual error measured by $\ell_2$ norm/Lorentzian norm [R. E. Carrillo, A. B. Ramirez, G. R. Arce, K. E. Barner, and B. M. Sadler, EURASIP J. Adv. Signal Process. (2016), 108]. We first discuss how the various conditions required in our analysis can be verified, and then perform numerical experiments to illustrate the convergence behaviors of SCP$_{ls}$.},
  archive      = {J_SIOPT},
  author       = {Peiran Yu and Ting Kei Pong and Zhaosong Lu},
  doi          = {10.1137/20M1314057},
  journal      = {SIAM Journal on Optimization},
  number       = {3},
  pages        = {2024-2054},
  shortjournal = {SIAM J. Optim.},
  title        = {Convergence rate analysis of a sequential convex programming method with line search for a class of constrained difference-of-convex optimization problems},
  volume       = {31},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Operator splitting for a homogeneous embedding of the linear
complementarity problem. <em>SIOPT</em>, <em>31</em>(3), 1999–2023. (<a
href="https://doi.org/10.1137/20M1366307">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a first-order quadratic cone programming algorithm that can scale to very large problem sizes and produce modest accuracy solutions quickly. Our algorithm returns primal-dual optimal solutions when available or certificates of infeasibility otherwise. It is derived by applying Douglas--Rachford splitting to a homogeneous embedding of the linear complementarity problem, which is a general set membership problem that includes quadratic cone programs (QCPs) as a special case. Each iteration of our procedure requires projecting onto a convex cone and solving a linear system with a fixed coefficient matrix. If a sequence of related problems are solved, then the procedure can easily be warm-started and make use of factorization caching of the linear system. We demonstrate on a range of public and synthetic datasets that for feasible problems our approach tends to be somewhat faster than applying operator splitting directly to the QCP, and in cases of infeasibility our approach can be significantly faster than alternative approaches based on diverging iterates. The algorithm we describe has been implemented in C and is available open-source in the solver SCS v3.0.},
  archive      = {J_SIOPT},
  author       = {Brendan O&#39;Donoghue},
  doi          = {10.1137/20M1366307},
  journal      = {SIAM Journal on Optimization},
  number       = {3},
  pages        = {1999-2023},
  shortjournal = {SIAM J. Optim.},
  title        = {Operator splitting for a homogeneous embedding of the linear complementarity problem},
  volume       = {31},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Adaptive douglas–rachford splitting algorithm from a yosida
approximation standpoint. <em>SIOPT</em>, <em>31</em>(3), 1971–1998. (<a
href="https://doi.org/10.1137/20M131388X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The adaptive Douglas--Rachford splitting algorithm iteratively applies the operator $T=\kappa_{n}Q_{A}Q_{B}+(1-\kappa_{n}){Id}$ to solve the inclusion problem $\text{zer}(A+B)$. By taking a Yosida approximation standpoint, we express in canonical form $Q_{A}Q_{B}=({Id}-(\gamma+\lambda)\ ^{\gamma}\!A)\circ({Id}-(\gamma+\lambda)\ ^{\lambda}\!B)$. We extend the domain of indices $\gamma, \lambda$ to the entire real line, so that the adaptive algorithm is able to encompass a forward-backward splitting algorithm into one unified framework. Convergence results for both primal and dual problems are proved for different combinations of (strongly and weakly) monotone and comonotone operators. Under the “monotone + comonotone” assumption, we obtain a better rate bound for linear convergence than the classical Douglas--Rachford algorithm.},
  archive      = {J_SIOPT},
  author       = {Zihan Liu and Kannan Ramchandran},
  doi          = {10.1137/20M131388X},
  journal      = {SIAM Journal on Optimization},
  number       = {3},
  pages        = {1971-1998},
  shortjournal = {SIAM J. Optim.},
  title        = {Adaptive douglas--rachford splitting algorithm from a yosida approximation standpoint},
  volume       = {31},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Method of alternating contractions and its applications to
some convex optimization problems. <em>SIOPT</em>, <em>31</em>(3),
1947–1970. (<a href="https://doi.org/10.1137/18M1217395">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article proposes an algorithm for convex programming which can be viewed as a further development of the method of alternating projections. Some combinatorial problems like the maximum matchings and the maximum simple $b$-matchings can be solved in polynomial time by this algorithm. More generally, it runs in polynomial time for any binary linear problem where the objective function is defined by a binary vector and the convex hull of the feasible set can be described by a system of the form $Ax\le b, x\ge {0},$ given by a polynomial-time separation oracle, where $A$ is a nonnegative matrix. Also, our algorithm is an Fully polynomial time approximation Scheme for a wide range of optimization problems with an exponential or infinite number of constraints given by a separation oracle.},
  archive      = {J_SIOPT},
  author       = {Sergei Chubanov},
  doi          = {10.1137/18M1217395},
  journal      = {SIAM Journal on Optimization},
  number       = {3},
  pages        = {1947-1970},
  shortjournal = {SIAM J. Optim.},
  title        = {Method of alternating contractions and its applications to some convex optimization problems},
  volume       = {31},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Attouch–théra duality, generalized cycles, and gap vectors.
<em>SIOPT</em>, <em>31</em>(3), 1926–1946. (<a
href="https://doi.org/10.1137/21M1392085">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Using the Attouch--Théra duality, we study the cycles, gap vectors, and fixed point sets of compositions of proximal mappings. Sufficient conditions are given for the existence of cycles and gap vectors. A primal-dual framework provides an exact relationship between the cycles and gap vectors. We also introduce the generalized cycle and gap vectors to tackle the case when the classical ones do not exist. Examples are given to illustrate our results.},
  archive      = {J_SIOPT},
  author       = {Salihah Alwadani and Heinz Bauschke and Xianfu Wang},
  doi          = {10.1137/21M1392085},
  journal      = {SIAM Journal on Optimization},
  number       = {3},
  pages        = {1926-1946},
  shortjournal = {SIAM J. Optim.},
  title        = {Attouch--théra duality, generalized cycles, and gap vectors},
  volume       = {31},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Outlier detection in time series via mixed-integer conic
quadratic optimization. <em>SIOPT</em>, <em>31</em>(3), 1897–1925. (<a
href="https://doi.org/10.1137/19M1306233">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the problem of estimating the true values of a Wiener process given noisy observations corrupted by outliers. In this paper we show how to improve existing mixed-integer quadratic optimization formulations for this problem. Specifically, we convexify the existing formulations via lifting, deriving new mixed-integer conic quadratic reformulations. The proposed reformulations are stronger and substantially faster when used with current mixed-integer optimization solvers. In our experiments, solution times are improved by at least two orders-of-magnitude.},
  archive      = {J_SIOPT},
  author       = {Andrés Gómez},
  doi          = {10.1137/19M1306233},
  journal      = {SIAM Journal on Optimization},
  number       = {3},
  pages        = {1897-1925},
  shortjournal = {SIAM J. Optim.},
  title        = {Outlier detection in time series via mixed-integer conic quadratic optimization},
  volume       = {31},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Dual randomized coordinate descent method for solving a
class of nonconvex problems. <em>SIOPT</em>, <em>31</em>(3), 1877–1896.
(<a href="https://doi.org/10.1137/20M133926X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a nonconvex optimization problem consisting of maximizing the difference of two convex functions. We present a randomized method that requires low computational effort at each iteration. The described method is a randomized coordinate descent method employed on the so-called Toland-dual problem. We prove subsequence convergence to dual stationarity points, a new notion that we introduce and which is shown to be tighter than standard criticality. An almost sure rate of convergence of an optimality measure of the dual sequence is proven. We demonstrate the potential of our results on three principal component analysis models resulting in extremely simple algorithms.},
  archive      = {J_SIOPT},
  author       = {Amir Beck and Marc Teboulle},
  doi          = {10.1137/20M133926X},
  journal      = {SIAM Journal on Optimization},
  number       = {3},
  pages        = {1877-1896},
  shortjournal = {SIAM J. Optim.},
  title        = {Dual randomized coordinate descent method for solving a class of nonconvex problems},
  volume       = {31},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). MG/OPT and multilevel monte carlo for robust optimization of
PDEs. <em>SIOPT</em>, <em>31</em>(3), 1850–1876. (<a
href="https://doi.org/10.1137/20M1347164">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An algorithm is proposed to solve robust control problems constrained by partial differential equations with uncertain coefficients, based on the so-called MG/OPT framework. The levels in the MG/OPT hierarchy correspond to discretization levels of the PDE, as usual. For stochastic problems, the relevant quantities (such as the gradient) contain expected value operators on each of these levels. They are estimated using a multilevel Monte Carlo method, the specifics of which depend on the MG/OPT level. Each of the optimization levels then contains multiple underlying multilevel Monte Carlo levels. The MG/OPT hierarchy allows the algorithm to exploit the structure inherent in the PDE, speeding up the convergence to the optimum. In contrast, the multilevel Monte Carlo hierarchy exists to exploit structure present in the stochastic dimensions of the problem. A statement about the asymptotic cost of the algorithm is proven, and some additional properties are discussed. The performance of the algorithm is numerically investigated for three test cases. A reduction in the number of samples required on expensive levels and therefore in computation time can be observed.},
  archive      = {J_SIOPT},
  author       = {Andreas Van Barel and Stefan Vandewalle},
  doi          = {10.1137/20M1347164},
  journal      = {SIAM Journal on Optimization},
  number       = {3},
  pages        = {1850-1876},
  shortjournal = {SIAM J. Optim.},
  title        = {MG/OPT and multilevel monte carlo for robust optimization of PDEs},
  volume       = {31},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Fundamental domains for symmetric optimization: Construction
and search. <em>SIOPT</em>, <em>31</em>(3), 1827–1849. (<a
href="https://doi.org/10.1137/20M1331627">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Symmetries of a set are linear transformations that map the set to itself. A fundamental domain of a symmetric set is a subset that contains at least one representative from each of the symmetric equivalence classes (orbits) in the set. This paper contributes a novel polynomial algorithm for constructing minimal polytopic fundamental domains of polytopic sets. Our algorithm is applicable for generic linear symmetries of the set and has linear complexity in the number of facets and dimension of the symmetric polytope, e.g., the feasible region of an optimization problem. In addition, this paper contributes a novel polynomial algorithm for mapping an element of the polytope to its representative in the fundamental domain. The algorithms are demonstrated in four examples---two illustrative and two practical. In the first practical example, we show that a minimal fundamental domain of the hypercube under the symmetric group is the set of points with sorted elements. In the second practical example, we show how the construction algorithm can be applied to the max-cut problem.},
  archive      = {J_SIOPT},
  author       = {Claus Danielson},
  doi          = {10.1137/20M1331627},
  journal      = {SIAM Journal on Optimization},
  number       = {3},
  pages        = {1827-1849},
  shortjournal = {SIAM J. Optim.},
  title        = {Fundamental domains for symmetric optimization: Construction and search},
  volume       = {31},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Unified acceleration of high-order algorithms under general
hölder continuity. <em>SIOPT</em>, <em>31</em>(3), 1797–1826. (<a
href="https://doi.org/10.1137/19M1290243">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, through an intuitive vanilla proximal method perspective, we derive a concise unified acceleration framework (UAF) for minimizing a convex function that has Hölder continuous derivatives with respect to general (non-Euclidean) norms. The UAF reconciles two different high-order acceleration approaches, one by Nesterov [Math. Program., 112 (2008), pp. 159--181] and one by Monteiro and Svaiter [SIAM J. Optim., 23 (2013), pp. 1092--1125]. As a result, the UAF unifies the high-order acceleration instances of the two approaches by only two problem-related parameters and two additional parameters for framework design. Meanwhile, the UAF (and its analysis) is the first approach to make high-order methods applicable for high-order smoothness conditions with respect to non-Euclidean norms. Furthermore, the UAF is the first approach that can match the existing lower bound of iteration complexity for minimizing a convex function with Hölder continuous derivatives. For practical implementation, we introduce a new and effective heuristic that significantly simplifies the binary search procedure required by the framework. We use experiments on logistic regression to verify the effectiveness of the heuristic. Finally, the UAF is proposed directly in the general composite convex setting and shows that the existing high-order algorithms can be naturally extended to the general composite convex setting.},
  archive      = {J_SIOPT},
  author       = {Chaobing Song and Yong Jiang and Yi Ma},
  doi          = {10.1137/19M1290243},
  journal      = {SIAM Journal on Optimization},
  number       = {3},
  pages        = {1797-1826},
  shortjournal = {SIAM J. Optim.},
  title        = {Unified acceleration of high-order algorithms under general hölder continuity},
  volume       = {31},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Characterizing convexity of images for quadratic-linear
mappings with applications in nonconvex quadratic optimization.
<em>SIOPT</em>, <em>31</em>(3), 1774–1796. (<a
href="https://doi.org/10.1137/19M1240484">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Various characterizations of convexity for images of a vector mapping where some of its components are quadratic and the remaining ones are linear are established. In a certain sense, one might conclude that convexity of the full image is reduced to the convexity of an image in a lower dimension by deleting the linear components. The latter may be considered as the analogue to the reduction of the number of constraints once the dual is associated. The cases of having one or two quadratic components while the other are linear are particularly analyzed. This allows us to formulate some (geometric) sufficient and necessary conditions for convexity. As a byproduct, a result obtained in [Xia, Wang, and Sheu, Math. Program. Ser. A, 156 (2016), pp. 513--547] is corrected. Finally, as some applications, we obtain an S-lemma (with equality and on an affine subspace) and a characterization of strong duality in terms of convexity of some image set associated to the minimization problem under consideration.},
  archive      = {J_SIOPT},
  author       = {Fabián Flores-Bazán and Felipe Opazo},
  doi          = {10.1137/19M1240484},
  journal      = {SIAM Journal on Optimization},
  number       = {3},
  pages        = {1774-1796},
  shortjournal = {SIAM J. Optim.},
  title        = {Characterizing convexity of images for quadratic-linear mappings with applications in nonconvex quadratic optimization},
  volume       = {31},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An inexact augmented lagrangian method for second-order cone
programming with applications. <em>SIOPT</em>, <em>31</em>(3),
1748–1773. (<a href="https://doi.org/10.1137/20M1374262">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we adopt the augmented Lagrangian method (ALM) to solve convex quadratic second-order cone programming problems (SOCPs). Fruitful results on the efficiency of the ALM have been established in the literature. Recently, it has been shown in [Cui, Sun, and Toh, Math. Program., 178 (2019), pp. 381--415] that if the quadratic growth condition holds at an optimal solution for the dual problem, then the KKT residual converges to zero R-superlinearly when the ALM is applied to the primal problem. Moreover, Cui, Ding, and Zhao [SIAM J. Optim., 27 (2017), pp. 2332--2355] provided sufficient conditions for the quadratic growth condition to hold under the metric subregularity and bounded linear regularity conditions for solving composite matrix optimization problems involving spectral functions. Here, we adopt these recent ideas to analyze the convergence properties of the ALM when applied to SOCPs. To the best of our knowledge, no similar work has been done for SOCPs so far. In our paper, we first provide sufficient conditions to ensure the quadratic growth condition for SOCPs. With these elegant theoretical guarantees, we then design an SOCP solver and apply it to solve various classes of SOCPs, such as minimal enclosing ball problems, classical trust-region subproblems, square-root Lasso problems, and DIMACS Challenge problems. Numerical results show that the proposed ALM based solver is efficient and robust compared to the existing highly developed solvers, such as Mosek and SDPT3.},
  archive      = {J_SIOPT},
  author       = {Ling Liang and Defeng Sun and Kim-Chuan Toh},
  doi          = {10.1137/20M1374262},
  journal      = {SIAM Journal on Optimization},
  number       = {3},
  pages        = {1748-1773},
  shortjournal = {SIAM J. Optim.},
  title        = {An inexact augmented lagrangian method for second-order cone programming with applications},
  volume       = {31},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Approximate 1-norm minimization and minimum-rank structured
sparsity for various generalized inverses via local search.
<em>SIOPT</em>, <em>31</em>(3), 1722–1747. (<a
href="https://doi.org/10.1137/19M1281514">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fundamental in matrix algebra and its applications, a generalized inverse of a real matrix $A$ is a matrix $H$ that satisfies the Moore--Penrose (M--P) property $AHA=A$. If $H$ also satisfies the additional useful M--P property, $HAH=H$, it is called a reflexive generalized inverse. Reflexivity is equivalent to minimum rank, so we are particularly interested in reflexive generalized inverses. We consider aspects of symmetry related to the calculation of a sparse reflexive generalized inverse of $A$. As is common, and following Fampa and Lee [Oper. Res. Lett., 46 (2018), pp. 605--610] for calculating sparse generalized inverses, we use (vector) 1-norm minimization for inducing sparsity and for keeping the magnitude of entries under control. When $A$ is symmetric, we may naturally desire a symmetric $H$, while generally such a restriction on $H$ may not lead to a 1-norm minimizing reflexive generalized inverse. We investigate a block construction method to produce a symmetric reflexive generalized inverse that is structured and has guaranteed sparsity. We provide a theoretically efficient and practical local-search algorithm to block construct an approximate 1-norm minimizing symmetric reflexive generalized inverse. Another aspect of symmetry that we consider relates to another M--P property: $H$ is ah-symmetric if $AH$ is symmetric. The ah-symmetry property is the key one for solving least-squares problems using $H$. Here we do not assume that $A$ is symmetric, and we do not impose symmetry on $H$. We investigate a column block construction method to produce an ah-symmetric reflexive generalized inverse that is structured and has guaranteed sparsity. We provide a theoretically efficient and practical local-search algorithm to column block construct an approximate 1-norm minimizing ah-symmetric reflexive generalized inverse.},
  archive      = {J_SIOPT},
  author       = {Luze Xu and Marcia Fampa and Jon Lee and Gabriel Ponte},
  doi          = {10.1137/19M1281514},
  journal      = {SIAM Journal on Optimization},
  number       = {3},
  pages        = {1722-1747},
  shortjournal = {SIAM J. Optim.},
  title        = {Approximate 1-norm minimization and minimum-rank structured sparsity for various generalized inverses via local search},
  volume       = {31},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Efficient algorithms for distributionally robust stochastic
optimization with discrete scenario support. <em>SIOPT</em>,
<em>31</em>(3), 1690–1721. (<a
href="https://doi.org/10.1137/19M1290115">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, there has been a growing interest in distributionally robust optimization (DRO) as a principled approach to data-driven decision making. In this paper, we consider a distributionally robust two-stage stochastic optimization problem with discrete scenario support. While much research effort has been devoted to tractable reformulations for DRO problems, especially those with continuous scenario support, few efficient numerical algorithms are developed, and most of them can neither handle the nonsmooth second-stage cost function nor the large number of scenarios $K$ effectively. We fill the gap by reformulating the DRO problem as a trilinear min-max-max saddle point problem and developing novel algorithms that can achieve an $\mathcal{O}(1/\epsilon)$ iteration complexity which only mildly depends on $K$. The major computations involved in each iteration of these algorithms can be conducted in parallel if necessary. Besides, for solving an important class of DRO problems with the Kantorovich ball ambiguity set, we propose a slight modification of our algorithms to avoid the expensive computation of the probability vector projection at the price of an $\mathcal{O}(\sqrt{K})$ times more iterations. Finally, preliminary numerical experiments are conducted to demonstrate the empirical advantages of the proposed algorithms.},
  archive      = {J_SIOPT},
  author       = {Zhe Zhang and Shabbir Ahmed and Guanghui Lan},
  doi          = {10.1137/19M1290115},
  journal      = {SIAM Journal on Optimization},
  number       = {3},
  pages        = {1690-1721},
  shortjournal = {SIAM J. Optim.},
  title        = {Efficient algorithms for distributionally robust stochastic optimization with discrete scenario support},
  volume       = {31},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Nonlinear conjugate gradient methods for PDE constrained
shape optimization based on steklov–poincaré-type metrics.
<em>SIOPT</em>, <em>31</em>(3), 1658–1689. (<a
href="https://doi.org/10.1137/20M1367738">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Shape optimization based on shape calculus has received a lot of attention in recent years, particularly regarding the development, analysis, and modification of efficient optimization algorithms. In this paper we propose and investigate nonlinear conjugate gradient methods based on Steklov--Poincaré-type metrics for the solution of shape optimization problems constrained by partial differential equations. We embed these methods into a general algorithmic framework for gradient-based shape optimization methods and discuss the numerical discretization of the algorithms. We numerically compare the proposed nonlinear conjugate gradient methods to the already established gradient descent and limited memory BFGS methods for shape optimization on several benchmark problems. The results show that the proposed nonlinear conjugate gradient methods perform well in practice and that they are an efficient and attractive addition to already established gradient-based shape optimization algorithms.},
  archive      = {J_SIOPT},
  author       = {Sebastian Blauth},
  doi          = {10.1137/20M1367738},
  journal      = {SIAM Journal on Optimization},
  number       = {3},
  pages        = {1658-1689},
  shortjournal = {SIAM J. Optim.},
  title        = {Nonlinear conjugate gradient methods for PDE constrained shape optimization based on steklov--poincaré-type metrics},
  volume       = {31},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Moreau envelope of supremum functions with applications to
infinite and stochastic programming. <em>SIOPT</em>, <em>31</em>(3),
1635–1657. (<a href="https://doi.org/10.1137/20M1373517">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we investigate the Moreau envelope of the supremum of a family of convex, proper, and lower semicontinuous functions. Under mild assumptions, we prove that the Moreau envelope of a supremum is the supremum of Moreau envelopes, which allows us to approximate possibly nonsmooth supremum functions by smooth functions that are also the suprema of functions. Consequently, we propose and study approximated optimization problems from infinite and stochastic programming for which we obtain zero-duality gap results and optimality conditions without the verification of constraint qualification conditions.},
  archive      = {J_SIOPT},
  author       = {Pedro Pérez-Aros and Emilio Vilches},
  doi          = {10.1137/20M1373517},
  journal      = {SIAM Journal on Optimization},
  number       = {3},
  pages        = {1635-1657},
  shortjournal = {SIAM J. Optim.},
  title        = {Moreau envelope of supremum functions with applications to infinite and stochastic programming},
  volume       = {31},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Weakly convex optimization over stiefel manifold using
riemannian subgradient-type methods. <em>SIOPT</em>, <em>31</em>(3),
1605–1634. (<a href="https://doi.org/10.1137/20M1321000">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a class of nonsmooth optimization problems over the Stiefel manifold, in which the objective function is weakly convex in the ambient Euclidean space. Such problems are ubiquitous in engineering applications but still largely unexplored. We present a family of Riemannian subgradient-type methods---namely Riemannian subgradient, incremental subgradient, and stochastic subgradient methods---to solve these problems and show that they all have an iteration complexity of $\mathcal{O}(\varepsilon^{-4})$ for driving a natural stationarity measure below $\varepsilon$. In addition, we establish the local linear convergence of the Riemannian subgradient and incremental subgradient methods when the problem at hand further satisfies a sharpness property and the algorithms are properly initialized and use geometrically diminishing stepsizes. To the best of our knowledge, these are the first convergence guarantees for using Riemannian subgradient-type methods to optimize a class of nonconvex nonsmooth functions over the Stiefel manifold. The fundamental ingredient in the proof of the aforementioned convergence results is a new Riemannian subgradient inequality for restrictions of weakly convex functions on the Stiefel manifold, which could be of independent interest. We also show that our convergence results can be extended to handle a class of compact embedded submanifolds of the Euclidean space. Finally, we discuss the sharpness properties of various formulations of the robust subspace recovery and orthogonal dictionary learning problems and demonstrate the convergence performance of the algorithms on both problems via numerical simulations.},
  archive      = {J_SIOPT},
  author       = {Xiao Li and Shixiang Chen and Zengde Deng and Qing Qu and Zhihui Zhu and Anthony Man-Cho So},
  doi          = {10.1137/20M1321000},
  journal      = {SIAM Journal on Optimization},
  number       = {3},
  pages        = {1605-1634},
  shortjournal = {SIAM J. Optim.},
  title        = {Weakly convex optimization over stiefel manifold using riemannian subgradient-type methods},
  volume       = {31},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Analysis and algorithms for some compressed sensing models
based on L1/L2 minimization. <em>SIOPT</em>, <em>31</em>(2), 1576–1603.
(<a href="https://doi.org/10.1137/20M1355380">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, in a series of papers [Y. Rahimi, C. Wang, H. Dong, and Y. Lou, SIAM J. Sci. Comput., 41 (2019), pp. A3649--A3672; C. Wang, M. Tao, J. Nagy, and Y. Lou, SIAM J. Imaging Sci., 14 (2021), pp. 749--777; C. Wang, M. Yan, and Y. Lou, IEEE Trans. Signal Process., 68 (2020), pp. 2660--2669; P. Yin, E. Esser, and J. Xin, Commun. Inf. Syst., 14 (2014), pp. 87--109], the ratio of $\ell_1$ and $\ell_2$ norms was proposed as a sparsity inducing function for noiseless compressed sensing. In this paper, we further study properties of such model in the noiseless setting, and propose an algorithm for minimizing $\ell_1$/$\ell_2$ subject to noise in the measurements. Specifically, we show that the extended objective function (the sum of the objective and the indicator function of the constraint set) of the model in [Y. Rahimi, C. Wang, H. Dong, and Y. Lou, SIAM J. Sci. Comput., 41 (2019), pp. A3649--A3672] satisfies the Kurdyka--Łojasiewicz (KL) property with exponent 1/2; this allows us to establish linear convergence of the algorithm proposed in [C. Wang, M. Yan, and Y. Lou, IEEE Trans. Signal Process., 68 (2020), pp. 2660--2669] (see equation 11) under mild assumptions. We next extend the $\ell_1$/$\ell_2$ model to handle compressed sensing problems with noise. We establish the solution existence for some of these models under the spherical section property [S. A. Vavasis, Derivation of Compressive Sensing Theorems from the Spherical Section Property, University of Waterloo, 2009; Y. Zhang, J. Oper. Res. Soc. China, 1 (2013), pp. 79--105] and extend the algorithm in [C. Wang, M. Yan, and Y. Lou, IEEE Trans. Signal Process., 68 (2020), pp. 2660--2669] (see equation 11) by incorporating moving-balls-approximation techniques [A. Auslender, R. Shefi, and M. Teboulle, SIAM J. Optim., 20 (2010), pp. 3232--3259] for solving these problems. We prove the subsequential convergence of our algorithm under mild conditions and establish global convergence of the whole sequence generated by our algorithm by imposing additional KL and differentiability assumptions on a specially constructed potential function. Finally, we perform numerical experiments on robust compressed sensing and basis pursuit denoising with residual error measured by $ \ell_2 $ norm or Lorentzian norm via solving the corresponding $\ell_1$/$\ell_2$ models by our algorithm. Our numerical simulations show that our algorithm is able to recover the original sparse vectors with reasonable accuracy.},
  archive      = {J_SIOPT},
  author       = {Liaoyuan Zeng and Peiran Yu and Ting Kei Pong},
  doi          = {10.1137/20M1355380},
  journal      = {SIAM Journal on Optimization},
  number       = {2},
  pages        = {1576-1603},
  shortjournal = {SIAM J. Optim.},
  title        = {Analysis and algorithms for some compressed sensing models based on L1/L2 minimization},
  volume       = {31},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Riemannian optimization on the symplectic stiefel manifold.
<em>SIOPT</em>, <em>31</em>(2), 1546–1575. (<a
href="https://doi.org/10.1137/20M1348522">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The symplectic Stiefel manifold, denoted by ${Sp}(2p,2n)$, is the set of linear symplectic maps between the standard symplectic spaces $\mathbb{R}^{2p}$ and $\mathbb{R}^{2n}$. When $p=n$, it reduces to the well-known set of $2n\times 2n$ symplectic matrices. Optimization problems on ${Sp}(2p,2n)$ find applications in various areas, such as optics, quantum physics, numerical linear algebra, and model order reduction of dynamical systems. The purpose of this paper is to propose and analyze gradient-descent methods on ${Sp}(2p,2n)$, where the notion of gradient stems from a Riemannian metric. We consider a novel Riemannian metric on ${Sp}(2p,2n)$ akin to the canonical metric of the (standard) Stiefel manifold. In order to perform a feasible step along the antigradient, we develop two types of search strategies: one is based on quasi-geodesic curves and the other one on the symplectic Cayley transform. The resulting optimization algorithms are proved to converge globally to critical points of the objective function. Numerical experiments illustrate the efficiency of the proposed methods.},
  archive      = {J_SIOPT},
  author       = {Bin Gao and Nguyen Thanh Son and P.-A. Absil and Tatjana Stykel},
  doi          = {10.1137/20M1348522},
  journal      = {SIAM Journal on Optimization},
  number       = {2},
  pages        = {1546-1575},
  shortjournal = {SIAM J. Optim.},
  title        = {Riemannian optimization on the symplectic stiefel manifold},
  volume       = {31},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An efficient quadratic programming relaxation based
algorithm for large-scale MIMO detection. <em>SIOPT</em>,
<em>31</em>(2), 1519–1545. (<a
href="https://doi.org/10.1137/20M1346912">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multiple-input multiple-output (MIMO) detection is a fundamental problem in wireless communications and it is strongly NP-hard in general. Massive MIMO has been recognized as a key technology in fifth generation (5G) and beyond communication networks, which on one hand can significantly improve the communication performance and on the other hand poses new challenges of solving the corresponding optimization problems due to the large problem size. While various efficient algorithms such as semidefinite relaxation (SDR) based approaches have been proposed for solving the small-scale MIMO detection problem, they are not suitable to solve the large-scale MIMO detection problem due to their high computational complexities. In this paper, we propose an efficient quadratic programming (QP) relaxation based algorithm for solving the large-scale MIMO detection problem. In particular, we first reformulate the MIMO detection problem as a sparse QP problem. By dropping the sparse constraint, the resulting relaxation problem shares the same global minimizer with the sparse QP problem. In sharp contrast to the SDRs for the MIMO detection problem, our relaxation does not contain any (positive semidefinite) matrix variable and the numbers of variables and constraints in our relaxation are significantly less than those in the SDRs, which makes it particularly suitable for the large-scale problem. Then we propose a projected Newton based quadratic penalty method to solve the relaxation problem, which is guaranteed to converge to the vector of transmitted signals under reasonable conditions. By extensive numerical experiments, when applied to solve small-scale problems, the proposed algorithm is demonstrated to be competitive with the state-of-the-art approaches in terms of detection accuracy and solution efficiency; when applied to solve large-scale problems, the proposed algorithm achieves better detection performance than a recently proposed generalized power method.},
  archive      = {J_SIOPT},
  author       = {Ping-Fan Zhao and Qing-Na Li and Wei-Kun Chen and Ya-Feng Liu},
  doi          = {10.1137/20M1346912},
  journal      = {SIAM Journal on Optimization},
  number       = {2},
  pages        = {1519-1545},
  shortjournal = {SIAM J. Optim.},
  title        = {An efficient quadratic programming relaxation based algorithm for large-scale MIMO detection},
  volume       = {31},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Global convergence rate analysis of a generic line search
algorithm with noise. <em>SIOPT</em>, <em>31</em>(2), 1489–1518. (<a
href="https://doi.org/10.1137/19M1291832">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we develop convergence analysis of a modified line search method for objective functions whose value is computed with noise and whose gradient estimates are inexact and possibly random. The noise is assumed to be bounded in absolute value without any additional assumptions. We extend the framework based on stochastic methods from [C. Cartis and K. Scheinberg, Math. Program., 169 (2018), pp. 337--375] which was developed to provide analysis of a standard line search method with exact function values and random gradients to the case of noisy functions. We introduce two alternative conditions on the gradient which, when satisfied with some sufficiently large probability at each iteration, guarantees convergence properties of the line search method. We derive expected complexity bounds to reach a near optimal neighborhood for convex, strongly convex and nonconvex functions. The exact dependence of the convergence neighborhood on the noise is specified.},
  archive      = {J_SIOPT},
  author       = {A. S. Berahas and L. Cao and K. Scheinberg},
  doi          = {10.1137/19M1291832},
  journal      = {SIAM Journal on Optimization},
  number       = {2},
  pages        = {1489-1518},
  shortjournal = {SIAM J. Optim.},
  title        = {Global convergence rate analysis of a generic line search algorithm with noise},
  volume       = {31},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Reformulation of the m-stationarity conditions as a system
of discontinuous equations and its solution by a semismooth newton
method. <em>SIOPT</em>, <em>31</em>(2), 1459–1488. (<a
href="https://doi.org/10.1137/20M1321413">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We show that the Mordukhovich-stationarity system associated with a mathematical program with complementarity constraints (MPCC) can be equivalently written as a system of discontinuous equations which can be tackled with a semismooth Newton method. It will be demonstrated that the resulting algorithm can be interpreted as an active set strategy for MPCCs. Local fast convergence of the method is guaranteed under validity of an MPCC-tailored version of LICQ and a suitable strong second-order condition. In case of linear-quadratic MPCCs, the LICQ-type constraint qualification can be replaced by a weaker condition which depends on the underlying multipliers. We discuss a suitable globalization strategy for our method. Some numerical results are presented in order to illustrate our theoretical findings.},
  archive      = {J_SIOPT},
  author       = {Felix Harder and Patrick Mehlitz and Gerd Wachsmuth},
  doi          = {10.1137/20M1321413},
  journal      = {SIAM Journal on Optimization},
  number       = {2},
  pages        = {1459-1488},
  shortjournal = {SIAM J. Optim.},
  title        = {Reformulation of the M-stationarity conditions as a system of discontinuous equations and its solution by a semismooth newton method},
  volume       = {31},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Exact semidefinite programming bounds for packing problems.
<em>SIOPT</em>, <em>31</em>(2), 1433–1458. (<a
href="https://doi.org/10.1137/20M1351692">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we give an algorithm to round the floating point output of a semidefinite programming solver to a solution over the rationals or a quadratic extension of the rationals. This algorithm does not require the solution to be strictly feasible and works for large problems. We apply this to get sharp bounds for packing problems, and we use these sharp bounds to prove that certain optimal packing configurations are unique up to rotations. In particular, we show that the configuration coming from the ${E}_8$ root lattice is the unique optimal code with minimal angular distance $\pi/3$ on the hemisphere in $\mathbb{R}^8$, and we prove that the three-point bound for the $(3, 8, \vartheta)$-spherical code, where $\vartheta$ is such that $\cos \vartheta = (2\sqrt{2}-1)/7$, is sharp by rounding to $\mathbb{Q}[\sqrt{2}]$. We also use our machinery to compute sharp upper bounds on the number of spheres that can be packed into a larger sphere.},
  archive      = {J_SIOPT},
  author       = {Maria Dostert and David de Laat and Philippe Moustrou},
  doi          = {10.1137/20M1351692},
  journal      = {SIAM Journal on Optimization},
  number       = {2},
  pages        = {1433-1458},
  shortjournal = {SIAM J. Optim.},
  title        = {Exact semidefinite programming bounds for packing problems},
  volume       = {31},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The FM and BCQ qualifications for inequality systems of
convex functions in normed linear spaces. <em>SIOPT</em>,
<em>31</em>(2), 1410–1432. (<a
href="https://doi.org/10.1137/20M1324259">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For an inequality system defined by an infinite family of proper lower semicontinuous convex functions in normed linear space, we consider the Farkas--Minkowski (FM for short) type qualification and the basic constraint qualification (BCQ for short). By employing a new approach based on some new results established here on the SECQ (sum of epigraphs constraint qualification) for families of closed convex sets, some sufficient conditions involving further relaxing Slater type conditions for ensuring the FM qualification are provided. As applications, new sufficient conditions for ensuring the BCQ are given. These results significantly improve the corresponding ones in [C. Li and K. F. Ng, SIAM J. Optim., 15 (2005), pp. 488--512] and [C. Li, X. P. Zhao, and Y. H. Hu, SIAM J. Optim., 23 (2013), pp. 2208--2230], and they are obtained without the key continuity assumption on the sup-function of the inequality system which the previous works depend heavily on. Some examples are also presented to illustrate the applicability of our results.},
  archive      = {J_SIOPT},
  author       = {Chong Li and Kung Fu Ng and Jen-Chih Yao and Xiaopeng Zhao},
  doi          = {10.1137/20M1324259},
  journal      = {SIAM Journal on Optimization},
  number       = {2},
  pages        = {1410-1432},
  shortjournal = {SIAM J. Optim.},
  title        = {The FM and BCQ qualifications for inequality systems of convex functions in normed linear spaces},
  volume       = {31},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Square-root metric regularity and related stability theorems
for smooth mappings. <em>SIOPT</em>, <em>31</em>(2), 1380–1409. (<a
href="https://doi.org/10.1137/20M1337697">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Metric regularity and a stability theorem with a square-root distance estimate are investigated for smooth mappings which act in Hilbert spaces. The main result concerns a sufficient condition for this type of metric regularity and stability, which is formulated without a priori normality assumptions. As an application of the obtained conditions, Lyusternik&#39;s tangent cone theorem and the inverse function theorem in a neighborhood of abnormal point are derived. Examples are constructed which demonstrate the essence of the proposed assumptions.},
  archive      = {J_SIOPT},
  author       = {Aram V. Arutyunov and Dmitry Karamzin},
  doi          = {10.1137/20M1337697},
  journal      = {SIAM Journal on Optimization},
  number       = {2},
  pages        = {1380-1409},
  shortjournal = {SIAM J. Optim.},
  title        = {Square-root metric regularity and related stability theorems for smooth mappings},
  volume       = {31},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Sequential quadratic optimization for nonlinear equality
constrained stochastic optimization. <em>SIOPT</em>, <em>31</em>(2),
1352–1379. (<a href="https://doi.org/10.1137/20M1354556">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sequential quadratic optimization algorithms are proposed for solving smooth nonlinear optimization problems with equality constraints. The main focus is an algorithm proposed for the case when the constraint functions are deterministic, and constraint function and derivative values can be computed explicitly, but the objective function is stochastic. It is assumed in this setting that it is intractable to compute objective function and derivative values explicitly, although one can compute stochastic function and gradient estimates. As a starting point for this stochastic setting, an algorithm is proposed for the deterministic setting that is modeled after a state-of-the-art line-search SQP algorithm but uses a stepsize selection scheme based on Lipschitz constants (or adaptively estimated Lipschitz constants) in place of the line search. This sets the stage for the proposed algorithm for the stochastic setting, for which it is assumed that line searches would be intractable. Under reasonable assumptions, convergence (resp., convergence in expectation) from remote starting points is proved for the proposed deterministic (resp., stochastic) algorithm. The results of numerical experiments demonstrate the practical performance of our proposed techniques.},
  archive      = {J_SIOPT},
  author       = {Albert S. Berahas and Frank E. Curtis and Daniel Robinson and Baoyu Zhou},
  doi          = {10.1137/20M1354556},
  journal      = {SIAM Journal on Optimization},
  number       = {2},
  pages        = {1352-1379},
  shortjournal = {SIAM J. Optim.},
  title        = {Sequential quadratic optimization for nonlinear equality constrained stochastic optimization},
  volume       = {31},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Horizon maps and graphical convergence revisited.
<em>SIOPT</em>, <em>31</em>(2), 1330–1351. (<a
href="https://doi.org/10.1137/20M1321632">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We obtain new properties and formulas for the horizon map and graphical convergence for set-valued maps. We calculate horizon maps and establish the graphical convergence of various important maps from variational analysis. We also establish the continuity of several operations with set-valued maps. We compare these notions with similar ones from the literature. We also study the notion of total graphical convergence. Finally, to illustrate the usefulness of the developed tools, we employ them to study the stability, asymptotic behavior, and existence of solutions of generalized equations. Our results contribute to the asymptotic analysis and convergence theory for set-valued maps.},
  archive      = {J_SIOPT},
  author       = {Rubén López and Miguel Sama},
  doi          = {10.1137/20M1321632},
  journal      = {SIAM Journal on Optimization},
  number       = {2},
  pages        = {1330-1351},
  shortjournal = {SIAM J. Optim.},
  title        = {Horizon maps and graphical convergence revisited},
  volume       = {31},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A primal-dual algorithm with line search for general
convex-concave saddle point problems. <em>SIOPT</em>, <em>31</em>(2),
1299–1329. (<a href="https://doi.org/10.1137/18M1213488">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a primal-dual algorithm with a novel momentum term using the partial gradients of the coupling function that can be viewed as a generalization of the method proposed by Chambolle and Pock in [Math. Program., 159 (2016), pp. 253--287] for solving saddle point problems defined by a convex-concave function $\mathcal{L}(x,y)=f(x)+\Phi(x,y)-h(y)$ with a general coupling term $\Phi(x,y)$ that is not assumed to be bilinear. Assuming $\nabla_x\Phi(\cdot,y)$ is Lipschitz for any fixed $y$, and $\nabla_y\Phi(\cdot,\cdot)$ is Lipschitz, we show that the iterate sequence converges to a saddle point, and for any $(x,y)$, we derive error bounds in terms of $\mathcal{L}(\bar{x}_k,y)-\mathcal{L}(x,\bar{y}_k)$ for the ergodic sequence ${\bar{x}_k,\bar{y}_k}$. In particular, we show $\mathcal{O}(1/k)$ rate when the problem is merely convex in $x$. Furthermore, assuming $\Phi(x,\cdot)$ is linear for each fixed $x$ and $f$ is strongly convex, we obtain the ergodic convergence rate of $\mathcal{O}(1/k^2)$---we are not aware of another single-loop method in the related literature achieving the same rate when $\Phi$ is not bilinear. Finally, we propose a backtracking technique which does not require knowledge of Lipschitz constants yet ensures the same convergence results. We also consider convex optimization problems with nonlinear functional constraints, and we show that by using the backtracking scheme, the optimal convergence rate can be achieved even when the dual domain is unbounded. We tested our method against other state-of-the-art first-order algorithms for solving quadratically constrained quadratic programming (QCQP): in the first set of experiments, we considered QCQPs with synthetic data, and in the second set, we focused on QCQPs with real data originating from a variant of the linear regression problem with fairness constraints arising in machine learning.},
  archive      = {J_SIOPT},
  author       = {Erfan Yazdandoost Hamedani and Necdet Serhat Aybat},
  doi          = {10.1137/18M1213488},
  journal      = {SIAM Journal on Optimization},
  number       = {2},
  pages        = {1299-1329},
  shortjournal = {SIAM J. Optim.},
  title        = {A primal-dual algorithm with line search for general convex-concave saddle point problems},
  volume       = {31},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). On the intrinsic core of convex cones in real linear spaces.
<em>SIOPT</em>, <em>31</em>(2), 1276–1298. (<a
href="https://doi.org/10.1137/19M1283148">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Convex cones play an important role in nonlinear analysis and optimization theory. In particular, specific normal cones and tangent cones are known to be convex cones, and it is a crucial fact that they are useful geometric objects for describing optimality conditions. As important applications (especially, in the fields of optimal control with PDE constraints, risk theory, duality theory, vector optimization, and order theory) show, there are many examples of convex cones with an empty (topological as well as algebraic) interior. In such situations, generalized interiority notions can be useful. In this article, we present new representations and properties of the relative algebraic interior (also known as intrinsic core) of relatively solid, convex cones in real linear spaces (which are not necessarily endowed with a topology) of both finite and infinite dimension. For proving our main results, we are using new separation theorems where relatively solid, convex sets (cones) are involved. For the intrinsic core of the dual cone of a relatively solid, convex cone, we also state new representations that involve the lineality space of the given convex cone. To emphasize the importance of the derived results, some applications in vector optimization are given.},
  archive      = {J_SIOPT},
  author       = {Bahareh Khazayel and Ali Farajzadeh and Christian Günther and Christiane Tammer},
  doi          = {10.1137/19M1283148},
  journal      = {SIAM Journal on Optimization},
  number       = {2},
  pages        = {1276-1298},
  shortjournal = {SIAM J. Optim.},
  title        = {On the intrinsic core of convex cones in real linear spaces},
  volume       = {31},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Randomized sketching algorithms for low-memory dynamic
optimization. <em>SIOPT</em>, <em>31</em>(2), 1242–1275. (<a
href="https://doi.org/10.1137/19M1272561">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper develops a novel limited-memory method to solve dynamic optimization problems. The memory requirements for such problems often present a major obstacle, particularly for problems with PDE constraints such as optimal flow control, full waveform inversion, and optical tomography. In these problems, PDE constraints uniquely determine the state of a physical system for a given control; the goal is to find the value of the control that minimizes an objective. While the control is often low dimensional, the state is typically more expensive to store. This paper suggests using randomized matrix approximation to compress the state as it is generated and shows how to use the compressed state to reliably solve the original dynamic optimization problem. Concretely, the compressed state is used to compute approximate gradients and to apply the Hessian to vectors. The approximation error in these quantities is controlled by the target rank of the sketch. This approximate first- and second-order information can readily be used in any optimization algorithm. As an example, we develop a sketched trust-region method that adaptively chooses the target rank using a posteriori error information and provably converges to a stationary point of the original problem. Numerical experiments with the sketched trust-region method show promising performance on challenging problems such as the optimal control of an advection-reaction-diffusion equation and the optimal control of fluid flow past a cylinder.},
  archive      = {J_SIOPT},
  author       = {Ramchandran Muthukumar and Drew P. Kouri and Madeleine Udell},
  doi          = {10.1137/19M1272561},
  journal      = {SIAM Journal on Optimization},
  number       = {2},
  pages        = {1242-1275},
  shortjournal = {SIAM J. Optim.},
  title        = {Randomized sketching algorithms for low-memory dynamic optimization},
  volume       = {31},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Variable metric forward-backward algorithm for composite
minimization problems. <em>SIOPT</em>, <em>31</em>(2), 1215–1241. (<a
href="https://doi.org/10.1137/19M1277552">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a forward-backward-based algorithm to minimize a sum of a differentiable function and a nonsmooth function, both being possibly nonconvex. The main contribution of this work is to consider the challenging case where the nonsmooth function corresponds to a sum of nonconvex functions, resulting from composition between a strictly increasing, concave, differentiable function and a convex nonsmooth function. The proposed variable metric composite function forward-backward (C2FB) algorithm circumvents the explicit, and often challenging, computation of the proximity operator of the composite functions through a majorize-minimize approach. Precisely, each composite function is majorized using a linear approximation of the differentiable function, which allows one to apply the proximity step only to the sum of the nonsmooth functions. We prove the convergence of the algorithm iterates to a critical point of the objective function leveraging the Kurdyka--Ł ojasiewicz inequality. The convergence is guaranteed even if the proximity operators are computed inexactly, considering relative errors. We show that the proposed approach is a generalization of reweighting methods, with convergence guarantees. In particular, applied to the log-sum function, our algorithm reduces to a generalized version of the celebrated reweighted $\ell_1$ method. Finally, we show through simulations on an image processing problem that the proposed C2FB algorithm necessitates fewer iterations to converge and leads to better critical points compared with traditional reweighting methods and classic forward-backward algorithms.},
  archive      = {J_SIOPT},
  author       = {Audrey Repetti and Yves Wiaux},
  doi          = {10.1137/19M1277552},
  journal      = {SIAM Journal on Optimization},
  number       = {2},
  pages        = {1215-1241},
  shortjournal = {SIAM J. Optim.},
  title        = {Variable metric forward-backward algorithm for composite minimization problems},
  volume       = {31},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Generalized newton algorithms for tilt-stable minimizers in
nonsmooth optimization. <em>SIOPT</em>, <em>31</em>(2), 1184–1214. (<a
href="https://doi.org/10.1137/20M1329937">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper aims at developing two versions of the generalized Newton method to compute local minimizers for nonsmooth problems of unconstrained and constrained optimization that satisfy an important stability property known as tilt stability. We start with unconstrained minimization of continuously differentiable cost functions having Lipschitzian gradients and suggest two second-order algorithms of Newton type: one involving coderivatives of Lipschitzian gradient mappings, and the other based on graphical derivatives of the latter. Then we proceed with the propagation of these algorithms to minimization of extended-real-valued prox-regular functions, while covering in this way problems of constrained optimization, by using Moreau envelopes. Employing advanced techniques of second-order variational analysis and characterizations of tilt stability allows us to establish the solvability of subproblems in both algorithms and to prove the $Q$-superlinear convergence of their iterations.},
  archive      = {J_SIOPT},
  author       = {Boris S. Mordukhovich and M. Ebrahim Sarabi},
  doi          = {10.1137/20M1329937},
  journal      = {SIAM Journal on Optimization},
  number       = {2},
  pages        = {1184-1214},
  shortjournal = {SIAM J. Optim.},
  title        = {Generalized newton algorithms for tilt-stable minimizers in nonsmooth optimization},
  volume       = {31},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Generalized penalty and regularization method for
differential variational-hemivariational inequalities. <em>SIOPT</em>,
<em>31</em>(2), 1158–1183. (<a
href="https://doi.org/10.1137/20M1330221">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The primary objective of this paper is to study a large class of differential variational-hemivariational inequalities involving history-dependent operators and constraints in a Banach space. First, we establish a well-posedness result, which includes existence, uniqueness, and continuous dependence on the initial data. Second, related penalized and regularized problems without constraints are introduced whose solutions approach the solution to the original inequality. Finally, these results are applied to an obstacle parabolic-elliptic system consisting of a nonlinear reaction-diffusion equation and a time-dependent mixed boundary value problem with generalized gradient and Volterra integral terms.},
  archive      = {J_SIOPT},
  author       = {Zhenhai Liu and Dumitru Motreanu and Shengda Zeng},
  doi          = {10.1137/20M1330221},
  journal      = {SIAM Journal on Optimization},
  number       = {2},
  pages        = {1158-1183},
  shortjournal = {SIAM J. Optim.},
  title        = {Generalized penalty and regularization method for differential variational-hemivariational inequalities},
  volume       = {31},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). MultiLevel composite stochastic optimization via nested
variance reduction. <em>SIOPT</em>, <em>31</em>(2), 1131–1157. (<a
href="https://doi.org/10.1137/19M1285457">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider multilevel composite optimization problems where each mapping in the composition is the expectation over a family of randomly chosen smooth mappings or the sum of some finite number of smooth mappings. We present a normalized proximal approximate gradient method where the approximate gradients are obtained via nested stochastic variance reduction. In order to find an approximate stationary point where the expected norm of its gradient mapping is less than $\epsilon$, the total sample complexity of our method is $O(\epsilon^{-3})$ in the expectation case and $O(N+\sqrt{N}\epsilon^{-2})$ in the finite-sum case where $N$ is the total number of functions across all composition levels. In addition, the dependence of our total sample complexity on the number of composition levels is polynomial, rather than exponential as in previous work.},
  archive      = {J_SIOPT},
  author       = {Junyu Zhang and Lin Xiao},
  doi          = {10.1137/19M1285457},
  journal      = {SIAM Journal on Optimization},
  number       = {2},
  pages        = {1131-1157},
  shortjournal = {SIAM J. Optim.},
  title        = {MultiLevel composite stochastic optimization via nested variance reduction},
  volume       = {31},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Making the last iterate of SGD information theoretically
optimal. <em>SIOPT</em>, <em>31</em>(2), 1108–1130. (<a
href="https://doi.org/10.1137/19M128908X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stochastic gradient descent (SGD) is one of the most widely used algorithms for large-scale optimization problems. While classical theoretical analysis of SGD for convex problems studies (suffix) averages of iterates and obtains information theoretically optimal bounds on suboptimality, the last point of SGD is, by far, the most preferred choice in practice. The best known results for the last point of SGD [O. Shamir and T. Zhang, Proceedings of the 30th International Conference on Machine Learning, 2013, pp. 71--79] however, are suboptimal compared to information theoretic lower bounds by a $\log T$ factor, where $T$ is the number of iterations. Harvey, Liaw, Plan, and Randhawa [Conference on Learning Theory, PMLR, 2019, pp. 1579--1613] shows that in fact, this additional $\log T$ factor is tight for standard step size sequences of $\Theta({\frac{1}{\sqrt{t}}})$ and $\Theta({\frac{1}{t}})$ for non-strongly convex and strongly convex settings, respectively. Similarly, even for subgradient descent (GD) when applied to nonsmooth, convex functions, the best known step size sequences still lead to $O(\log T)$-suboptimal convergence rates (on the final iterate). The main contribution of this work is to design new step size sequences that enjoy information theoretically optimal bounds on the suboptimality of the last point of SGD as well as GD. We achieve this by designing a modification scheme that converts one sequence of step sizes to another so that the last point of SGD/GD with modified sequence has the same suboptimality guarantees as the average of SGD/GD with original sequence. We also show that our result holds with high probability. We validate our results through simulations which demonstrate that the new step size sequence indeed improves the final iterate significantly compared to the standard step size sequences.},
  archive      = {J_SIOPT},
  author       = {Prateek Jain and Dheeraj M. Nagaraj and Praneeth Netrapalli},
  doi          = {10.1137/19M128908X},
  journal      = {SIAM Journal on Optimization},
  number       = {2},
  pages        = {1108-1130},
  shortjournal = {SIAM J. Optim.},
  title        = {Making the last iterate of SGD information theoretically optimal},
  volume       = {31},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A derivative-free method for structured optimization
problems. <em>SIOPT</em>, <em>31</em>(2), 1079–1107. (<a
href="https://doi.org/10.1137/20M1337417">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Structured optimization problems are ubiquitous in fields like data science and engineering. The goal in structured optimization is using a prescribed set of points, called atoms, to build up a solution that minimizes or maximizes a given function. In the present paper, we want to minimize a black-box function over the convex hull of a given set of atoms, a problem that can be used to model a number of real-world applications. We focus on problems whose solutions are sparse, i.e., solutions that can be obtained as a proper convex combination of just a few atoms in the set, and propose a suitable derivative-free inner approximation approach that nicely exploits the structure of the given problem. This enables us to properly handle the dimensionality issues usually connected with derivative-free algorithms, thus getting a method that scales well in terms of both the dimension of the problem and the number of atoms. We analyze global convergence to stationary points. Moreover, we show that, under suitable assumptions, the proposed algorithm identifies a specific subset of atoms with zero weight in the final solution after finitely many iterations. Finally, we report numerical results showing the effectiveness of the proposed method.},
  archive      = {J_SIOPT},
  author       = {Andrea Cristofari and Francesco Rinaldi},
  doi          = {10.1137/20M1337417},
  journal      = {SIAM Journal on Optimization},
  number       = {2},
  pages        = {1079-1107},
  shortjournal = {SIAM J. Optim.},
  title        = {A derivative-free method for structured optimization problems},
  volume       = {31},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The condition number of riemannian approximation problems.
<em>SIOPT</em>, <em>31</em>(1), 1049–1077. (<a
href="https://doi.org/10.1137/20M1323527">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the local sensitivity of least-squares formulations of inverse problems. The sets of inputs and outputs of these problems are assumed to have the structures of Riemannian manifolds. The problems we consider include the approximation problem of finding the nearest point on a Riemannian embedded submanifold from a given point in the ambient space. We characterize the first-order sensitivity, i.e., condition number, of local minimizers and critical points to arbitrary perturbations of the input of the least-squares problem. This condition number involves the Weingarten map of the input manifold, which measures the amount by which the input manifold curves in its ambient space. We validate our main results through experiments with the $n$-camera triangulation problem in computer vision.},
  archive      = {J_SIOPT},
  author       = {Paul Breiding and Nick Vannieuwenhoven},
  doi          = {10.1137/20M1323527},
  journal      = {SIAM Journal on Optimization},
  number       = {1},
  pages        = {1049-1077},
  shortjournal = {SIAM J. Optim.},
  title        = {The condition number of riemannian approximation problems},
  volume       = {31},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Adaptive sequential sample average approximation for solving
two-stage stochastic linear programs. <em>SIOPT</em>, <em>31</em>(1),
1017–1048. (<a href="https://doi.org/10.1137/19M1244469">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present adaptive sequential SAA (sample average approximation) algorithms to solve large-scale two-stage stochastic linear programs. The iterative algorithm framework we propose is organized into outer and inner iterations as follows: during each outer iteration, a sample-path problem is implicitly generated using a sample of observations or “scenarios,&quot; and solved only imprecisely, to within a tolerance that is chosen adaptively, by balancing the estimated statistical error against solution error. The solutions from prior iterations serve as warm starts to aid efficient solution of the (piecewise linear convex) sample-path optimization problems generated on subsequent iterations. The generated scenarios can be independent and identically distributed, or dependent, as in Monte Carlo generation using Latin-hypercube sampling, antithetic variates, or randomized quasi-Monte Carlo. We first characterize the almost-sure convergence (and convergence in mean) of the optimality gap and the distance of the generated stochastic iterates to the true solution set. We then characterize the corresponding iteration complexity and work complexity rates as a function of the sample size schedule, demonstrating that the best achievable work complexity rate is Monte Carlo canonical and analogous to the generic $\mathcal{O}(\epsilon^{-2})$ optimal complexity for nonsmooth convex optimization. We report extensive numerical tests that indicate favorable performance, due primarily to the use of a sequential framework with an optimal sample size schedule, and the use of warm starts. The proposed algorithm can be stopped in finite time to return a solution endowed with a probabilistic guarantee on quality.},
  archive      = {J_SIOPT},
  author       = {Raghu Pasupathy and Yongjia Song},
  doi          = {10.1137/19M1244469},
  journal      = {SIAM Journal on Optimization},
  number       = {1},
  pages        = {1017-1048},
  shortjournal = {SIAM J. Optim.},
  title        = {Adaptive sequential sample average approximation for solving two-stage stochastic linear programs},
  volume       = {31},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Dual space preconditioning for gradient descent.
<em>SIOPT</em>, <em>31</em>(1), 991–1016. (<a
href="https://doi.org/10.1137/19M130858X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The conditions of relative smoothness and relative strong convexity were recently introduced for the analysis of Bregman gradient methods for convex optimization. We introduce a generalized left-preconditioning method for gradient descent and show that its convergence on an essentially smooth convex objective function can be guaranteed via an application of relative smoothness in the dual space. Our relative smoothness assumption is between the designed preconditioner and the convex conjugate of the objective, and it generalizes the typical Lipschitz gradient assumption. Under dual relative strong convexity, we obtain linear convergence with a generalized condition number that is invariant under horizontal translations, distinguishing it from Bregman gradient methods. Thus, in principle our method is capable of improving the conditioning of gradient descent on problems with a non-Lipschitz gradient or nonstrongly convex structure. We demonstrate our method on $p$-norm regression and exponential penalty function minimization.},
  archive      = {J_SIOPT},
  author       = {Chris J. Maddison and Daniel Paulin and Yee Whye Teh and Arnaud Doucet},
  doi          = {10.1137/19M130858X},
  journal      = {SIAM Journal on Optimization},
  number       = {1},
  pages        = {991-1016},
  shortjournal = {SIAM J. Optim.},
  title        = {Dual space preconditioning for gradient descent},
  volume       = {31},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Linear-time convexity test for low-order piecewise
polynomials. <em>SIOPT</em>, <em>31</em>(1), 972–990. (<a
href="https://doi.org/10.1137/19M1290851">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given a piecewise-defined function, checking whether it is convex is a nontrivial task. While it may be easy to check whether the restriction of the function to each piece is convex, ensuring the entire function is convex seems to require global conditions. However, it is known that one only needs to ensure the (convex) subdifferential is nonempty on the boundary of the pieces thereby obtaining more local conditions. We specialize the results to quadratic and cubic piecewise defined functions and provide linear-time algorithms to check their convexity. We also provide a MATLAB implementation using an edge-list data structure and discuss two applications: checking the structure of piecewise quadratic functions and optimization problems involving convexity constraints.},
  archive      = {J_SIOPT},
  author       = {Shambhavi Singh and Yves Lucet},
  doi          = {10.1137/19M1290851},
  journal      = {SIAM Journal on Optimization},
  number       = {1},
  pages        = {972-990},
  shortjournal = {SIAM J. Optim.},
  title        = {Linear-time convexity test for low-order piecewise polynomials},
  volume       = {31},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Solution approaches to linear fractional programming and its
stochastic generalizations using second order cone approximations.
<em>SIOPT</em>, <em>31</em>(1), 945–971. (<a
href="https://doi.org/10.1137/19M1308165">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider linear fractional programming problems in a form of which the linear fractional program and its stochastic and distributionally robust counterparts with finite support are special cases. We introduce a novel reformulation that involves differences of square terms in the constraint, subsequently using a piecewise linear approximation for the concave part. Using the resulting second order cone programs (SOCPs), we develop a solution algorithm in the branch and bound framework. Our method iteratively refines the piecewise linear approximations by dividing hyper-rectangles and solves SOCPs to obtain lower bounds for the sub-hyper-rectangles. We derive a bound on the optimality gap as a function of the approximation errors at the iterate and prove that the number of iterations to attain an $\epsilon$-optimal solution is in the order of $\mathcal{O}(\sqrt{\epsilon})$. Numerical experiments show that the proposed algorithm scales better than state-of-the-art linear-programming-based algorithms and commercial solvers to solve linear fractional programs. Specifically, the proposed algorithm achieves two or more digits of accuracy in significantly less time than the time required by the known algorithms on medium to larger size problem instances. Experimental results with Wasserstein ambiguity sets reveal that our reformulation-based approach solves small size distributionally robust linear fractional programs, with the cardinality of support up to 25.},
  archive      = {J_SIOPT},
  author       = {Cheolmin Kim and Sanjay Mehrotra},
  doi          = {10.1137/19M1308165},
  journal      = {SIAM Journal on Optimization},
  number       = {1},
  pages        = {945-971},
  shortjournal = {SIAM J. Optim.},
  title        = {Solution approaches to linear fractional programming and its stochastic generalizations using second order cone approximations},
  volume       = {31},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Generalized momentum-based methods: A hamiltonian
perspective. <em>SIOPT</em>, <em>31</em>(1), 915–944. (<a
href="https://doi.org/10.1137/20M1322716">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We take a Hamiltonian-based perspective to generalize Nesterov&#39;s accelerated gradient descent and Polyak&#39;s heavy ball method to a broad class of momentum methods in the setting of (possibly) constrained minimization in Euclidean and non-Euclidean normed vector spaces. Our perspective leads to a generic and unifying nonasymptotic analysis of convergence of these methods in both the function value (in the setting of convex optimization) and in the norm of the gradient (in the setting of unconstrained, possibly nonconvex, optimization). Our approach relies upon a time-varying Hamiltonian that produces generalized momentum methods as its equations of motion. The convergence analysis for these methods is intuitive and is based on the conserved quantities of the time-dependent Hamiltonian.},
  archive      = {J_SIOPT},
  author       = {Jelena Diakonikolas and Michael I. Jordan},
  doi          = {10.1137/20M1322716},
  journal      = {SIAM Journal on Optimization},
  number       = {1},
  pages        = {915-944},
  shortjournal = {SIAM J. Optim.},
  title        = {Generalized momentum-based methods: A hamiltonian perspective},
  volume       = {31},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The convergence of the generalized lanczos trust-region
method for the trust-region subproblem. <em>SIOPT</em>, <em>31</em>(1),
887–914. (<a href="https://doi.org/10.1137/19M1279691">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Solving the trust-region subproblem (TRS) plays a key role in numerical optimization and many other applications. The generalized Lanczos trust-region (GLTR) method is a well-known Lanczos type approach for solving a large-scale TRS. The method projects the original large-scale TRS onto a sequence of lower dimensional Krylov subspaces, whose orthonormal bases are generated by the symmetric Lanczos process, and computes approximate solutions from the underlying subspaces. There have been some a priori bounds available for the errors of the approximate solutions and approximate objective values obtained by the GLTR method, but no a priori bound exists on the errors of the approximate Lagrangian multipliers and the residual norms of approximate solutions obtained by the GLTR method. In this paper, a general convergence theory of the GLTR method is established for the TRS in the easy case, showing that the a priori bounds for these four quantities are closely interrelated and the one for the computable residual norm is of crucial importance in both theory and practice as it can predict the sizes of other three uncomputable errors reliably. Numerical experiments demonstrate that our bounds are realistic and predict the convergence rates of the four quantities accurately.},
  archive      = {J_SIOPT},
  author       = {Zhongxiao Jia and Fa Wang},
  doi          = {10.1137/19M1279691},
  journal      = {SIAM Journal on Optimization},
  number       = {1},
  pages        = {887-914},
  shortjournal = {SIAM J. Optim.},
  title        = {The convergence of the generalized lanczos trust-region method for the trust-region subproblem},
  volume       = {31},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An optimality gap test for a semidefinite relaxation of a
quadratic program with two quadratic constraints. <em>SIOPT</em>,
<em>31</em>(1), 866–886. (<a
href="https://doi.org/10.1137/19M1273761">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a necessary and sufficient test to determine whether a solution for a general quadratic program with two quadratic constraints (QC2QP) can be computed from that of a specific convex semidefinite relaxation, in which case we say that there is no optimality gap. Originally intended to solve a nonconvex optimal control problem, we consider the case in which the cost and both constraints of the QC2QP may be nonconvex. We obtained our test, which also ascertains when strong duality holds, by generalizing a closely related method by Ai and Zhang. An extension was necessary because, while the method proposed by Ai and Zhang also allows for two quadratic constraints, it requires that at least one is strictly convex. In order to illustrate the usefulness of our test, we applied it to two examples that do not satisfy the assumptions required by prior methods. Our test guarantees that there is no optimality gap for the first example---a solution is also computed from the relaxation---and we used it to establish that an optimality gap exists in the second.},
  archive      = {J_SIOPT},
  author       = {Sheng Cheng and Nuno C. Martins},
  doi          = {10.1137/19M1273761},
  journal      = {SIAM Journal on Optimization},
  number       = {1},
  pages        = {866-886},
  shortjournal = {SIAM J. Optim.},
  title        = {An optimality gap test for a semidefinite relaxation of a quadratic program with two quadratic constraints},
  volume       = {31},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Necessary and sufficient optimality conditions in DC
semi-infinite programming. <em>SIOPT</em>, <em>31</em>(1), 837–865. (<a
href="https://doi.org/10.1137/19M1303320">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper deals with particular families of DC optimization problems involving suprema of convex functions. We show that the specific structure of this type of function allows us to cover a variety of problems in nonconvex programming. Necessary and sufficient optimality conditions for these families of DC optimization problems are established, where some of these structural features are conveniently exploited. More precisely, we derive necessary and sufficient conditions for (global and local) optimality in DC semi-infinite programming and DC cone-constrained optimization, under natural constraint qualifications. Finally, a penalty approach to DC abstract programming problems is developed in the last section.},
  archive      = {J_SIOPT},
  author       = {Rafael Correa and M. A. López and Pedro Pérez-Aros},
  doi          = {10.1137/19M1303320},
  journal      = {SIAM Journal on Optimization},
  number       = {1},
  pages        = {837-865},
  shortjournal = {SIAM J. Optim.},
  title        = {Necessary and sufficient optimality conditions in DC semi-infinite programming},
  volume       = {31},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Error bounds and singularity degree in semidefinite
programming. <em>SIOPT</em>, <em>31</em>(1), 812–836. (<a
href="https://doi.org/10.1137/19M1289327">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In semidefinite programming a proposed optimal solution may be quite poor in spite of having sufficiently small residual in the optimality conditions. This issue may be framed in terms of the discrepancy between forward error (the unmeasurable “true error&#39;&#39;) and backward error (the measurable violation of optimality conditions). In [SIAM J. Optim., 10 (2000), pp. 1228--1248], Sturm provided an upper bound on forward error in terms of backward error and singularity degree. In this work we provide a method to bound the maximum rank over all optimal solutions and use this result to obtain a lower bound on forward error for a class of convergent sequences. This lower bound complements the upper bound of Sturm. The results of Sturm imply that semidefinite programs with slow convergence necessarily have large singularity degree. Here we show that large singularity degree is, in some sense, also a sufficient condition for slow convergence for a family of external-type “central” paths. Our results are supported by numerical observations.},
  archive      = {J_SIOPT},
  author       = {Stefan Sremac and Hugo J. Woerdeman and Henry Wolkowicz},
  doi          = {10.1137/19M1289327},
  journal      = {SIAM Journal on Optimization},
  number       = {1},
  pages        = {812-836},
  shortjournal = {SIAM J. Optim.},
  title        = {Error bounds and singularity degree in semidefinite programming},
  volume       = {31},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Greedy quasi-newton methods with explicit superlinear
convergence. <em>SIOPT</em>, <em>31</em>(1), 785–811. (<a
href="https://doi.org/10.1137/20M1320651">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study greedy variants of quasi-Newton methods. They are based on the updating formulas from a certain subclass of the Broyden family. In particular, this subclass includes the well-known DFP, BFGS, and SR1 updates. However, in contrast to the classical quasi-Newton methods, which use the difference of successive iterates for updating the Hessian approximations, our methods apply basis vectors, greedily selected so as to maximize a certain measure of progress. For greedy quasi-Newton methods, we establish an explicit nonasymptotic bound on their rate of local superlinear convergence, as applied to minimizing strongly convex and strongly self-concordant functions (and, in particular, to strongly convex functions with Lipschitz continuous Hessian). The established superlinear convergence rate contains a contraction factor, which depends on the square of the iteration counter. We also show that greedy quasi-Newton methods produce Hessian approximations whose deviation from the exact Hessians linearly converges to zero.},
  archive      = {J_SIOPT},
  author       = {Anton Rodomanov and Yurii Nesterov},
  doi          = {10.1137/20M1320651},
  journal      = {SIAM Journal on Optimization},
  number       = {1},
  pages        = {785-811},
  shortjournal = {SIAM J. Optim.},
  title        = {Greedy quasi-newton methods with explicit superlinear convergence},
  volume       = {31},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Accelerated iterative regularization via dual diagonal
descent. <em>SIOPT</em>, <em>31</em>(1), 754–784. (<a
href="https://doi.org/10.1137/19M1308888">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose and analyze an accelerated iterative dual diagonal descent algorithm for the solution of linear inverse problems with strongly convex regularization and general data-fit functions. We develop an inertial approach of which we analyze both convergence and stability properties. Using tools from inexact proximal calculus, we prove early stopping results with optimal convergence rates for additive data terms and further consider more general cases, such as the Kullback--Leibler divergence, for which different type of proximal point approximations hold.},
  archive      = {J_SIOPT},
  author       = {Luca Calatroni and Guillaume Garrigos and Lorenzo Rosasco and Silvia Villa},
  doi          = {10.1137/19M1308888},
  journal      = {SIAM Journal on Optimization},
  number       = {1},
  pages        = {754-784},
  shortjournal = {SIAM J. Optim.},
  title        = {Accelerated iterative regularization via dual diagonal descent},
  volume       = {31},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). On the convergence of projected-gradient methods with
low-rank projections for smooth convex minimization over trace-norm
balls and related problems. <em>SIOPT</em>, <em>31</em>(1), 727–753. (<a
href="https://doi.org/10.1137/18M1233170">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Smooth convex minimization over the unit trace-norm ball is an important optimization problem in machine learning, signal processing, statistics, and other fields that underlies many tasks in which one wishes to recover a low-rank matrix given certain measurements. While first-order methods for convex optimization enjoy optimal convergence rates, they require in the worst-case to compute a full-rank SVD on each iteration, in order to compute the Euclidean projection onto the trace-norm ball. These full-rank SVD computations, however, prohibit the application of such methods to large-scale problems. A simple and natural heuristic to reduce the computational cost of such methods is to approximate the Euclidean projection using only a low-rank SVD. This raises the question if, and under what conditions, this simple heuristic can indeed result in provable convergence to the optimal solution. In this paper we show that any optimal solution is a center of a Euclidean ball inside which the projected-gradient mapping admits a rank that is at most the multiplicity of the largest singular value of the gradient vector at this optimal point. Moreover, the radius of the ball scales with the spectral gap of this gradient vector. We show how this readily implies the local convergence (i.e., from a “warm-start&quot; initialization) of standard first-order methods such as the projected-gradient method and accelerated gradient methods, using only low-rank SVD computations. We also quantify the effect of “over-parameterization,&quot; i.e., using SVD computations with higher rank, on the radius of this ball, showing it can increase dramatically with moderately larger rank. We extend our results also to the setting of smooth convex minimization with trace-norm regularization and smooth convex optimization over bounded-trace positive semidefinite matrices. Our theoretical investigation is supported by concrete empirical evidence that demonstrates the correct convergence of first-order methods with low-rank projections for the matrix completion task on real-world datasets.},
  archive      = {J_SIOPT},
  author       = {Dan Garber},
  doi          = {10.1137/18M1233170},
  journal      = {SIAM Journal on Optimization},
  number       = {1},
  pages        = {727-753},
  shortjournal = {SIAM J. Optim.},
  title        = {On the convergence of projected-gradient methods with low-rank projections for smooth convex minimization over trace-norm balls and related problems},
  volume       = {31},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A bilevel approach for identifying the worst contingencies
for nonconvex alternating current power systems. <em>SIOPT</em>,
<em>31</em>(1), 702–726. (<a
href="https://doi.org/10.1137/19M127611X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We address the bilevel optimization problem of identifying the most critical attacks to an alternating current (AC) power flow network. The upper-level binary maximization problem consists of choosing an attack that is treated as a parameter in the lower-level defender minimization problem. Instances of the lower-level global minimization problem by themselves are NP-hard due to the nonconvex AC power flow constraints, and bilevel solution approaches commonly apply a convex relaxation or approximation to allow for tractable bilevel reformulations at the cost of underestimating some power system vulnerabilities. Our main contribution is to provide an alternative branch-and-bound algorithm whose upper bounding mechanism (in a maximization context) is based on a reformulation that avoids relaxation of the AC power flow constraints in the lower-level defender problem. Lower bounding is provided with semidefinite programming (SDP) relaxed solutions to the lower-level problem. We establish finite termination with guarantees of either a globally optimal solution to the original bilevel problem, or a globally optimal solution to the SDP-relaxed bilevel problem which is included in a vetted list of upper-level attack solutions, at least one of which is a globally optimal solution to the bilevel problem. We demonstrate through computational experiments applied to IEEE case instances both the relevance of our contribution, and the effectiveness of our contributed algorithm for identifying power system vulnerabilities without resorting to convex relaxations of the lower-level problem. We conclude with a discussion of future extensions and improvements.},
  archive      = {J_SIOPT},
  author       = {Brian C. Dandurand and Kibaek Kim and Sven Leyffer},
  doi          = {10.1137/19M127611X},
  journal      = {SIAM Journal on Optimization},
  number       = {1},
  pages        = {702-726},
  shortjournal = {SIAM J. Optim.},
  title        = {A bilevel approach for identifying the worst contingencies for nonconvex alternating current power systems},
  volume       = {31},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). A generalized simplex method for integer problems given by
verification oracles. <em>SIOPT</em>, <em>31</em>(1), 686–701. (<a
href="https://doi.org/10.1137/16M1106936">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a linear problem over a finite set of integer vectors and assume that there is a verification oracle, which is an algorithm being able to verify whether a given vector optimizes a given linear function over the feasible set. Given an initial solution, the algorithm proposed in this paper finds an optimal solution of the problem together with a path, in the 1-skeleton of the convex hull of the feasible set, from the initial solution to the optimal solution found. The length of this path is bounded by the sum of distinct values which can be taken by the components of feasible solutions, minus the dimension of the problem. In particular, in the case when the feasible set is a set of binary vectors, the length of the constructed path is bounded by the number of variables, independently of the objective function.},
  archive      = {J_SIOPT},
  author       = {Sergei Chubanov},
  doi          = {10.1137/16M1106936},
  journal      = {SIAM Journal on Optimization},
  number       = {1},
  pages        = {686-701},
  shortjournal = {SIAM J. Optim.},
  title        = {A generalized simplex method for integer problems given by verification oracles},
  volume       = {31},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A bregman forward-backward linesearch algorithm for
nonconvex composite optimization: Superlinear convergence to nonisolated
local minima. <em>SIOPT</em>, <em>31</em>(1), 653–685. (<a
href="https://doi.org/10.1137/19M1264783">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce Bella, a locally superlinearly convergent Bregman forward-backward splitting method for minimizing the sum of two nonconvex functions, one of which satisfies a relative smoothness condition and the other one is possibly nonsmooth. A key tool of our methodology is the Bregman forward-backward envelope (BFBE), an exact and continuous penalty function with favorable first- and second-order properties, which enjoys a nonlinear error bound when the objective function satisfies a Łojasiewicz-type property. The proposed algorithm is of linesearch type over the BFBE along user-defined update directions and converges subsequentially to stationary points and globally under the Kurdyka--Łojasiewicz condition. Moreover, when the update directions are superlinear in the sense of Facchinei and Pang [Finite-Dimensional Variational Inequalities and Complementarity Problems, Volume I, Springer, New York, 2003], owing to the given nonlinear error bound unit stepsize is eventually always accepted and the algorithm attains superlinear convergence rates even when the limit point is a nonisolated minimum.},
  archive      = {J_SIOPT},
  author       = {Masoud Ahookhosh and Andreas Themelis and Panagiotis Patrinos},
  doi          = {10.1137/19M1264783},
  journal      = {SIAM Journal on Optimization},
  number       = {1},
  pages        = {653-685},
  shortjournal = {SIAM J. Optim.},
  title        = {A bregman forward-backward linesearch algorithm for nonconvex composite optimization: Superlinear convergence to nonisolated local minima},
  volume       = {31},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The landweber operator approach to the split equality
problem. <em>SIOPT</em>, <em>31</em>(1), 626–652. (<a
href="https://doi.org/10.1137/20M1337910">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The split equality problem (SEP) seeks a pair of points $(x^{\ast },y^{\ast })\in (C,D)$ with the property that $Ax^{\ast }=By^{\ast }$, where $C,D$ are nonempty closed convex subsets of Hilbert spaces $\mathcal{H}_{1}$ and $\% \mathcal{H}_{2}$, respectively, and $A:\mathcal{H}_{1}\rightarrow \mathcal{H}\% _{3}$ and $B:\mathcal{H}_{2}\rightarrow \mathcal{H}_{3}$ are bounded linear operators, where $\mathcal{H}_{3}$ is another Hilbert space. The SEP can equivalently be converted to a split feasibility problem in the product space $\mathcal{H}_{1}\times \mathcal{H}_{2}$. Using this equivalence, we are able to provide a Landweber operator approach to studying the convergence of several iterative methods for finding a solution to the SEP. We also discuss the linear regularity of the Landweber operator associated with the SEP and linear convergence of the iterative methods.},
  archive      = {J_SIOPT},
  author       = {Hong-Kun Xu and Andrzej Cegielski},
  doi          = {10.1137/20M1337910},
  journal      = {SIAM Journal on Optimization},
  number       = {1},
  pages        = {626-652},
  shortjournal = {SIAM J. Optim.},
  title        = {The landweber operator approach to the split equality problem},
  volume       = {31},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Approximations of countably infinite linear programs over
bounded measure spaces. <em>SIOPT</em>, <em>31</em>(1), 604–625. (<a
href="https://doi.org/10.1137/19M1268847">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study a class of countably infinite linear programs (CILPs) whose feasible sets are bounded subsets of appropriately defined spaces of measures. The optimal value, optimal points, and minimal points of these CILPs can be approximated by solving finite-dimensional linear programs. We show how to construct finite-dimensional programs that lead to approximations with easy-to-evaluate error bounds, and we prove that the errors converge to zero as the size of the finite-dimensional programs approaches that of the original problem. We discuss the use of our methods in the computation of the stationary distributions, occupation measures, and exit distributions of Markov chains.},
  archive      = {J_SIOPT},
  author       = {Juan Kuntz and Philipp Thomas and Guy-Bart Stan and Mauricio Barahona},
  doi          = {10.1137/19M1268847},
  journal      = {SIAM Journal on Optimization},
  number       = {1},
  pages        = {604-625},
  shortjournal = {SIAM J. Optim.},
  title        = {Approximations of countably infinite linear programs over bounded measure spaces},
  volume       = {31},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Variational analysis in normed spaces with applications to
constrained optimization. <em>SIOPT</em>, <em>31</em>(1), 569–603. (<a
href="https://doi.org/10.1137/20M1342215">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is devoted to developing and applications of a generalized differential theory of variational analysis that allows us to work in incomplete normed spaces, without employing conventional variational techniques based on completeness and limiting procedures. The main attention is paid to generalized derivatives and subdifferentials of the Dini--Hadamard type with the usage of mild qualification conditions revolving around metric subregularity. In this way we develop calculus rules of generalized differentiation in normed spaces without imposing restrictive normal compactness assumptions and the like and then apply them to general problems of constrained optimization. Most of the obtained results are new even in finite dimensions. Finally, we derive refined necessary optimality conditions for nonconvex problems of semi-infinite and semidefinite programming.},
  archive      = {J_SIOPT},
  author       = {Ashkan Mohammadi and Boris S. Mordukhovich},
  doi          = {10.1137/20M1342215},
  journal      = {SIAM Journal on Optimization},
  number       = {1},
  pages        = {569-603},
  shortjournal = {SIAM J. Optim.},
  title        = {Variational analysis in normed spaces with applications to constrained optimization},
  volume       = {31},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Quadratic growth and strong metric subregularity of the
subdifferential via subgradient graphical derivative. <em>SIOPT</em>,
<em>31</em>(1), 545–568. (<a
href="https://doi.org/10.1137/19M1242732">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper mainly studies the relationship between quadratic growth and strong metric subregularity of the subdifferential in finite dimensional settings by using the subgradient graphical derivative. We prove that the positive definiteness of the subgradient graphical derivative of an extended-real-valued lower semicontinuous proper function at a proximal stationary point is sufficient for the point to be a local minimizer at which the subdifferential is strongly subregular for $0.$ The latter was known to imply the quadratic growth. When the function is either subdifferentially continuous, prox-regular, twice epidifferentiable, or variationally convex, we show that the quadratic growth, the strong metric subregularity of the subdifferential at a local minimizer, and the positive definiteness of the subgradient graphical derivative at a stationary point are equivalent. For $\mathcal{C}^2$-cone reducible constrained programs satisfying the metric subregularity constraint qualification, we obtain the same results for the sum of the objective function and the indicator function of the feasible set.},
  archive      = {J_SIOPT},
  author       = {Nguyen Huy Chieu and Le Van Hien and Tran T. A. Nghia and Ha Anh Tuan},
  doi          = {10.1137/19M1242732},
  journal      = {SIAM Journal on Optimization},
  number       = {1},
  pages        = {545-568},
  shortjournal = {SIAM J. Optim.},
  title        = {Quadratic growth and strong metric subregularity of the subdifferential via subgradient graphical derivative},
  volume       = {31},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Trust-region newton-CG with strong second-order complexity
guarantees for nonconvex optimization. <em>SIOPT</em>, <em>31</em>(1),
518–544. (<a href="https://doi.org/10.1137/19M130563X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Worst-case complexity guarantees for nonconvex optimization algorithms have been a topic of growing interest. Multiple frameworks that achieve the best known complexity bounds among a broad class of first- and second-order strategies have been proposed. These methods have often been designed primarily with complexity guarantees in mind and, as a result, represent a departure from the algorithms that have proved to be the most effective in practice. In this paper, we consider trust-region Newton methods, one of the most popular classes of algorithms for solving nonconvex optimization problems. By introducing slight modifications to the original scheme, we obtain two methods---one based on exact subproblem solves and one exploiting inexact subproblem solves as in the popular “trust-region Newton-conjugate gradient” (trust-region Newton-CG) method---with iteration and operation complexity bounds that match the best known bounds for the aforementioned class of first- and second-order methods. The resulting trust-region Newton-CG method also retains the attractive practical behavior of classical trust-region Newton-CG, which we demonstrate with numerical comparisons on a standard benchmark test set.},
  archive      = {J_SIOPT},
  author       = {Frank E. Curtis and Daniel P. Robinson and Clément W. Royer and Stephen J. Wright},
  doi          = {10.1137/19M130563X},
  journal      = {SIAM Journal on Optimization},
  number       = {1},
  pages        = {518-544},
  shortjournal = {SIAM J. Optim.},
  title        = {Trust-region newton-CG with strong second-order complexity guarantees for nonconvex optimization},
  volume       = {31},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). On a semismooth* newton method for solving generalized
equations. <em>SIOPT</em>, <em>31</em>(1), 489–517. (<a
href="https://doi.org/10.1137/19M1257408">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the paper, a Newton-type method for the solution of generalized equations (GEs) is derived, where the linearization concerns both the single-valued and the multivalued part of the considered GE. The method is based on the new notion of semismoothness${}^*$, which, together with a suitable regularity condition, ensures the local superlinear convergence. An implementable version of the new method is derived for a class of GEs, frequently arising in optimization and equilibrium models.},
  archive      = {J_SIOPT},
  author       = {Helmut Gfrerer and Jiří V. Outrata},
  doi          = {10.1137/19M1257408},
  journal      = {SIAM Journal on Optimization},
  number       = {1},
  pages        = {489-517},
  shortjournal = {SIAM J. Optim.},
  title        = {On a semismooth* newton method for solving generalized equations},
  volume       = {31},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Distributionally robust partially observable markov decision
process with moment-based ambiguity. <em>SIOPT</em>, <em>31</em>(1),
461–488. (<a href="https://doi.org/10.1137/19M1268410">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a distributionally robust partially observable Markov decision process (DR-POMDP), where the distribution of the transition-observation probabilities is unknown at the beginning of each decision period, but their realizations can be inferred using side information at the end of each period after an action being taken. We build an ambiguity set of the joint distribution using bounded moments via conic constraints and seek an optimal policy to maximize the worst-case (minimum) reward for any distribution in the set. We show that the value function of DR-POMDP is piecewise linear convex with respect to the belief state and propose a heuristic search value iteration method for obtaining lower and upper bounds of the value function. We conduct numerical studies and demonstrate the computational performance of our approach via testing instances of a dynamic epidemic control problem. Our results show that DR-POMDP can produce more robust policies under misspecified distributions of transition-observation probabilities as compared to POMDP but has less costly solutions than robust POMDP. The DR-POMDP policies are also insensitive to varying parameter in the ambiguity set and to noise added to the true transition-observation probability values obtained at the end of each decision period.},
  archive      = {J_SIOPT},
  author       = {Hideaki Nakao and Ruiwei Jiang and Siqian Shen},
  doi          = {10.1137/19M1268410},
  journal      = {SIAM Journal on Optimization},
  number       = {1},
  pages        = {461-488},
  shortjournal = {SIAM J. Optim.},
  title        = {Distributionally robust partially observable markov decision process with moment-based ambiguity},
  volume       = {31},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Parallel stochastic asynchronous coordinate descent: Tight
bounds on the possible parallelism. <em>SIOPT</em>, <em>31</em>(1),
448–460. (<a href="https://doi.org/10.1137/19M129574X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Several works have shown linear speedup is achieved by an asynchronous parallel implementation of stochastic coordinate descent so long as there is not too much parallelism. More specifically, it is known that if all updates are of similar duration, then linear speedup is possible with up to $\Theta(L_{\max}\sqrt n/L_{\overline{{res}}})$ processors, where $L_{\max}$ and $L_{\overline{{res}}}$ are suitable Lipschitz parameters. This paper shows the bound is tight for almost all possible values of these parameters.},
  archive      = {J_SIOPT},
  author       = {Yun Kuen Cheung and Richard J. Cole and Yixin Tao},
  doi          = {10.1137/19M129574X},
  journal      = {SIAM Journal on Optimization},
  number       = {1},
  pages        = {448-460},
  shortjournal = {SIAM J. Optim.},
  title        = {Parallel stochastic asynchronous coordinate descent: Tight bounds on the possible parallelism},
  volume       = {31},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Optimization of quasi-convex function over product measure
sets. <em>SIOPT</em>, <em>31</em>(1), 425–447. (<a
href="https://doi.org/10.1137/19M1275322">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a generalization of the Bauer maximum principle. We work with tensorial products of convex measures set that are not necessarily compact but generated by their extreme points. We show that the maximum of a quasi-convex lower semicontinuous function on this product space is reached on the tensorial product of finite mixtures of extreme points. Our work is an extension of the Bauer maximum principle in three different aspects. First, we only assume that the objective functional is quasi-convex. Secondly, the optimization is performed over a space built as a product of measure sets. Finally, the usual compactness assumption is replaced with the existence of an integral representation on the extreme points. We focus on the product of two different types of measure sets, called the moment class and the unimodal moment class. The elements of these classes are probability measures (respectively, unimodal probability measures) satisfying generalized moment constraints. We show that an integral representation on the extreme points is available for such spaces and that it extends to their tensorial product. We give several applications of the theorem, going from robust Bayesian analysis to the optimization of a quantile of a computer code output.},
  archive      = {J_SIOPT},
  author       = {Jérôme Stenger and Fabrice Gamboa and Merlin Keller},
  doi          = {10.1137/19M1275322},
  journal      = {SIAM Journal on Optimization},
  number       = {1},
  pages        = {425-447},
  shortjournal = {SIAM J. Optim.},
  title        = {Optimization of quasi-convex function over product measure sets},
  volume       = {31},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The generalized bregman distance. <em>SIOPT</em>,
<em>31</em>(1), 404–424. (<a
href="https://doi.org/10.1137/19M1288140">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, a new kind of distance has been introduced for the graphs of two point-to-set operators, one of which is maximally monotone. When both operators are the subdifferential of a proper lower semicontinuous convex function, this kind of distance specializes under modest assumptions to the classical Bregman distance. We name this new kind of distance the generalized Bregman distance, and we shed light on it with examples that utilize the other two most natural representative functions: the Fitzpatrick function and its conjugate. We provide sufficient conditions for convexity, coercivity, and supercoercivity: properties which are essential for implementation in proximal point type algorithms. We establish these results for both the left and right variants of this new kind of distance. We construct examples closely related to the Kullback--Leibler divergence, which was previously considered in the context of Bregman distances and whose importance in information theory is well known. In so doing, we demonstrate how to compute a difficult Fitzpatrick conjugate function, and we discover natural occurrences of the Lambert ${\mathcal W}$ function, whose importance in optimization is of growing interest.},
  archive      = {J_SIOPT},
  author       = {Regina S. Burachik and Minh N. Dao and Scott B. Lindstrom},
  doi          = {10.1137/19M1288140},
  journal      = {SIAM Journal on Optimization},
  number       = {1},
  pages        = {404-424},
  shortjournal = {SIAM J. Optim.},
  title        = {The generalized bregman distance},
  volume       = {31},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). ADMM-type methods for generalized nash equilibrium problems
in hilbert spaces. <em>SIOPT</em>, <em>31</em>(1), 377–403. (<a
href="https://doi.org/10.1137/19M1284336">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the generalized Nash equilibrium problem (GNEP) with $ N $ players in a Hilbert space setting. The joint constraints are eliminated by an augmented Lagrangian-type approach, leading to an ADMM (alternating direction method of multipliers) algorithm. In contrast to standard optimization problems, however, the direct extension of ADMM to GNEPs is not necessarily convergent even for $N = 2$ players. We therefore use a regularized version of ADMM and present a global convergence result for $ N \geq 2 $ players under a partial strong monotonicity and a partial Lipschitz condition. Furthermore, also different from the optimization context, it turns out that the corresponding regularization parameters have to be sufficiently large in order to guarantee global convergence. We therefore also discuss a second ADMM-type method with an adaptive choice of the regularization parameters, with the aim of keeping the regularization parameters smaller and, hence, getting faster convergence. Numerical results are presented for some examples arising in infinite-dimensional Hilbert spaces.},
  archive      = {J_SIOPT},
  author       = {Eike Börgens and Christian Kanzow},
  doi          = {10.1137/19M1284336},
  journal      = {SIAM Journal on Optimization},
  number       = {1},
  pages        = {377-403},
  shortjournal = {SIAM J. Optim.},
  title        = {ADMM-type methods for generalized nash equilibrium problems in hilbert spaces},
  volume       = {31},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Stochastic approximation for optimization in shape spaces.
<em>SIOPT</em>, <em>31</em>(1), 348–376. (<a
href="https://doi.org/10.1137/20M1316111">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we present a novel approach for solving stochastic shape optimization problems. Our method is the extension of the classical stochastic gradient method to infinite-dimensional shape manifolds. We prove convergence of the method on Riemannian manifolds and then make the connection to shape spaces. The method is demonstrated on a model shape optimization problem from interface identification. Uncertainty arises in the form of a random partial differential equation, where underlying probability distributions of the random coefficients and inputs are assumed to be known. We verify some conditions for convergence for the model problem and demonstrate the method numerically.},
  archive      = {J_SIOPT},
  author       = {Caroline Geiersbach and Estefania Loayza-Romero and Kathrin Welker},
  doi          = {10.1137/20M1316111},
  journal      = {SIAM Journal on Optimization},
  number       = {1},
  pages        = {348-376},
  shortjournal = {SIAM J. Optim.},
  title        = {Stochastic approximation for optimization in shape spaces},
  volume       = {31},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Split cuts in the plane. <em>SIOPT</em>, <em>31</em>(1),
331–347. (<a href="https://doi.org/10.1137/20M1324521">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We provide a polynomial time cutting plane algorithm based on split cuts to solve integer programs in the plane. We also prove that the split closure of a polyhedron in the plane has polynomial size.},
  archive      = {J_SIOPT},
  author       = {Amitabh Basu and Michele Conforti and Marco Di Summa and Hongyi Jiang},
  doi          = {10.1137/20M1324521},
  journal      = {SIAM Journal on Optimization},
  number       = {1},
  pages        = {331-347},
  shortjournal = {SIAM J. Optim.},
  title        = {Split cuts in the plane},
  volume       = {31},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). On high-order multilevel optimization strategies.
<em>SIOPT</em>, <em>31</em>(1), 307–330. (<a
href="https://doi.org/10.1137/19M1255355">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a new family of multilevel methods for unconstrained minimization. The resulting strategies are multilevel extensions of high-order optimization methods based on $q$th-order Taylor models (with $q\geq 1$) that have been recently proposed in the literature. The use of high-order models, while decreasing the worst-case complexity bound, makes these methods computationally more expensive. Hence, to counteract this effect, we propose a multilevel strategy that exploits a hierarchy of problems of decreasing dimension, still approximating the original one, to reduce the global cost of the step computation. A theoretical analysis of the family of methods is proposed. Specifically, local and global convergence results are proved, and a worst-case complexity bound to reach first-order stationary points is also derived. A multilevel version of the well-known adaptive regularization by cubics (corresponding to $q=2$ in our setting) has been implemented, as well as a multilevel third-order method ($q=3$). Numerical experiments clearly highlight the relevance of the new multilevel approaches leading to considerable computational savings compared to their one-level counterparts.},
  archive      = {J_SIOPT},
  author       = {Henri Calandra and Serge Gratton and Elisa Riccietti and Xavier Vasseur},
  doi          = {10.1137/19M1255355},
  journal      = {SIAM Journal on Optimization},
  number       = {1},
  pages        = {307-330},
  shortjournal = {SIAM J. Optim.},
  title        = {On high-order multilevel optimization strategies},
  volume       = {31},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An exact algorithmic framework for a class of mixed-integer
programs with equilibrium constraints. <em>SIOPT</em>, <em>31</em>(1),
275–306. (<a href="https://doi.org/10.1137/18M1208769">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, we consider a rich class of mathematical programs with equilibrium constraints (MPECs) involving both integer and continuous variables. Such a class, which subsumes mathematical programs with complementarity constraints, as well as bilevel programs involving lower level convex programs is, in general, extremely hard to solve due to complementarity constraints and integrality requirements. For its solution, we design an (exact) algorithmic framework based on branch-and-bound (B&amp;B) that treats each node of the B&amp;B tree as a separate optimization problem and potentially changes its formulation and solution approach by designing, for example, a separate B&amp;B tree. The framework is implemented and computationally evaluated on a specific instance of MPEC, namely a competitive facility location problem that takes into account the queueing process that determines the equilibrium assignment of users to open facilities, and a generalization of models for which, to date, no exact method has been proposed.},
  archive      = {J_SIOPT},
  author       = {Teodora Dan and Andrea Lodi and Patrice Marcotte},
  doi          = {10.1137/18M1208769},
  journal      = {SIAM Journal on Optimization},
  number       = {1},
  pages        = {275-306},
  shortjournal = {SIAM J. Optim.},
  title        = {An exact algorithmic framework for a class of mixed-integer programs with equilibrium constraints},
  volume       = {31},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Convergence and dynamical behavior of the ADAM algorithm for
nonconvex stochastic optimization. <em>SIOPT</em>, <em>31</em>(1),
244–274. (<a href="https://doi.org/10.1137/19M1263443">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Adam is a popular variant of stochastic gradient descent for finding a local minimizer of a function. In the constant stepsize regime, assuming that the objective function is differentiable and nonconvex, we establish the convergence in the long run of the iterates to a stationary point under a stability condition. The key ingredient is the introduction of a continuous-time version of Adam, under the form of a nonautonomous ordinary differential equation. This continuous-time system is a relevant approximation of the Adam iterates, in the sense that the interpolated Adam process converges weakly toward the solution to the ODE. The existence and the uniqueness of the solution are established. We further show the convergence of the solution toward the critical points of the objective function and quantify its convergence rate under a Łojasiewicz assumption. Then, we introduce a novel decreasing stepsize version of Adam. Under mild assumptions, it is shown that the iterates are almost surely bounded and converge almost surely to critical points of the objective function. Finally, we analyze the fluctuations of the algorithm by means of a conditional central limit theorem.},
  archive      = {J_SIOPT},
  author       = {Anas Barakat and Pascal Bianchi},
  doi          = {10.1137/19M1263443},
  journal      = {SIAM Journal on Optimization},
  number       = {1},
  pages        = {244-274},
  shortjournal = {SIAM J. Optim.},
  title        = {Convergence and dynamical behavior of the ADAM algorithm for nonconvex stochastic optimization},
  volume       = {31},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). An average curvature accelerated composite gradient method
for nonconvex smooth composite optimization problems. <em>SIOPT</em>,
<em>31</em>(1), 217–243. (<a
href="https://doi.org/10.1137/19M1294277">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents an accelerated composite gradient (ACG) variant, referred to as the AC-ACG method, for solving nonconvex smooth composite minimization problems. As opposed to well-known ACG variants that are based on either a known Lipschitz gradient constant or a sequence of maximum observed curvatures, the current one is based on the average of all past observed curvatures. More specifically, AC-ACG uses a positive multiple of the average of all observed curvatures until the previous iteration as a way to estimate the “function curvature” at the current point and then two resolvent evaluations to compute the next iterate. In contrast to other variable Lipschitz estimation variants, e.g., the ones based on the maximum curvature, AC-ACG always accepts the aforementioned iterate regardless of how poor the Lipschitz estimation turns out to be. Finally, computational results are presented to illustrate the efficiency of AC-ACG on both randomly generated and real-world problem instances.},
  archive      = {J_SIOPT},
  author       = {Jiaming Liang and Renato D. C. Monteiro},
  doi          = {10.1137/19M1294277},
  journal      = {SIAM Journal on Optimization},
  number       = {1},
  pages        = {217-243},
  shortjournal = {SIAM J. Optim.},
  title        = {An average curvature accelerated composite gradient method for nonconvex smooth composite optimization problems},
  volume       = {31},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Distance-sparsity transference for vertices of corner
polyhedra. <em>SIOPT</em>, <em>31</em>(1), 200–216. (<a
href="https://doi.org/10.1137/20M1353228">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We obtain a transference bound for vertices of corner polyhedra that connects two well-established areas of research: proximity and sparsity of solutions to integer programs. In the knapsack scenario, it implies that for any vertex ${x}^*$ of an integer feasible knapsack polytope ${P}({a}, { b})={{x} \in {\mathbb R}^n_{\ge 0}: {a}^\top{x}={ b}}$, ${a}\in {\mathbb Z}^n_{&gt;0}$, there exists an integer point ${z}^*\in {P}({a}, { b})$ such that, denoting by $s$ the size of the support of ${z}^*$ and assuming $s&gt;0$, $ \|{x}^{*}-{z}^{*}\|_{\infty} \,{2^{s-1}}/{s} &lt; \|{a}\|_{\infty}\, $ where $\|\cdot\|_{\infty}$ stands for the $\ell_{\infty}$-norm. The bound gives an exponential in $s$ improvement on previously known proximity estimates. In addition, for general integer linear programs we obtain a resembling result that connects the minimum absolute nonzero entry of an optimal solution with the size of its support.},
  archive      = {J_SIOPT},
  author       = {Iskander Aliev and Marcel Celaya and Martin Henk and Aled Williams},
  doi          = {10.1137/20M1353228},
  journal      = {SIAM Journal on Optimization},
  number       = {1},
  pages        = {200-216},
  shortjournal = {SIAM J. Optim.},
  title        = {Distance-sparsity transference for vertices of corner polyhedra},
  volume       = {31},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Convergence analysis of gradient algorithms on riemannian
manifolds without curvature constraints and application to riemannian
mass. <em>SIOPT</em>, <em>31</em>(1), 172–199. (<a
href="https://doi.org/10.1137/19M1289285">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the convergence issue for the gradient algorithm (employing general step sizes) for optimization problems on general Riemannian manifolds (without curvature constraints). Under the assumption of the local convexity/quasi-convexity (resp., weak sharp minima), local/global convergence (resp., linear convergence) results are established. As an application, the linear convergence properties of the gradient algorithm employing the constant step sizes and the Armijo step sizes for finding the Riemannian $L^p$ ($p\in[1,+\infty)$) centers of mass are explored, respectively, which in particular extend and/or improve the corresponding results in [B. Afsari, R. Tron, and R. Vidal, SIAM J. Control Optim., 51 (2013), pp. 2230--2260; G. C. Bento et al., J. Optim. Theory Appl., 183 (2019), pp. 977--992].},
  archive      = {J_SIOPT},
  author       = {Jinhua Wang and Xiangmei Wang and Chong Li and Jen-Chih Yao},
  doi          = {10.1137/19M1289285},
  journal      = {SIAM Journal on Optimization},
  number       = {1},
  pages        = {172-199},
  shortjournal = {SIAM J. Optim.},
  title        = {Convergence analysis of gradient algorithms on riemannian manifolds without curvature constraints and application to riemannian mass},
  volume       = {31},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Spectral relaxations and branching strategies for global
optimization of mixed-integer quadratic programs. <em>SIOPT</em>,
<em>31</em>(1), 142–171. (<a
href="https://doi.org/10.1137/19M1271762">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the global optimization of nonconvex (mixed-integer) quadratic programs. We present a family of convex quadratic relaxations derived by convexifying nonconvex quadratic functions through perturbations of the quadratic matrix. We investigate the theoretical properties of these relaxations and show that they are equivalent to some particular semidefinite programs. We also introduce novel branching variable selection strategies motivated by the quadratic relaxations investigated in this paper. The proposed relaxation and branching techniques are implemented in the global optimization solver BARON and tested by conducting numerical experiments on a large collection of problems. Results demonstrate that the proposed implementation leads to very significant reductions in BARON&#39;s computational times to solve the test problems.},
  archive      = {J_SIOPT},
  author       = {Carlos J. Nohra and Arvind U. Raghunathan and Nikolaos Sahinidis},
  doi          = {10.1137/19M1271762},
  journal      = {SIAM Journal on Optimization},
  number       = {1},
  pages        = {142-171},
  shortjournal = {SIAM J. Optim.},
  title        = {Spectral relaxations and branching strategies for global optimization of mixed-integer quadratic programs},
  volume       = {31},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Chordal-TSSOS: A moment-SOS hierarchy that exploits term
sparsity with chordal extension. <em>SIOPT</em>, <em>31</em>(1),
114–141. (<a href="https://doi.org/10.1137/20M1323564">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work is a follow-up and a complement to [J. Wang, V. Magron and J. B. Lasserre, preprint, arXiv:1912.08899, 2019] where the TSSOS hierarchy was proposed for solving polynomial optimization problems (POPs). The chordal-TSSOS hierarchy that we propose is a new sparse moment-SOS framework based on term sparsity and chordal extension. By exploiting term sparsity of the input polynomials we obtain a two-level hierarchy of semidefinite programming relaxations. The novelty and distinguishing feature of such relaxations is to involve block matrices obtained in an iterative procedure that performs chordal extension of certain adjacency graphs. The graphs are related to the terms arising in the original data and not to the links between variables. Various numerical examples demonstrate the efficiency and the scalability of this new hierarchy for both unconstrained and constrained POPs. The two hierarchies are complementary. While the former TSSOS [J. Wang, V. Magron and J. B. Lasserre, preprint, arXiv:1912.08899, 2019] has a theoretical convergence guarantee (to the dense moment-SOS relaxation), the chordal-TSSOS has superior performance but lacks this theoretical guarantee.},
  archive      = {J_SIOPT},
  author       = {Jie Wang and Victor Magron and Jean-Bernard Lasserre},
  doi          = {10.1137/20M1323564},
  journal      = {SIAM Journal on Optimization},
  number       = {1},
  pages        = {114-141},
  shortjournal = {SIAM J. Optim.},
  title        = {Chordal-TSSOS: A moment-SOS hierarchy that exploits term sparsity with chordal extension},
  volume       = {31},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A globally convergent SQCQP method for multiobjective
optimization problems. <em>SIOPT</em>, <em>31</em>(1), 91–113. (<a
href="https://doi.org/10.1137/18M1182152">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, the concept of the single-objective sequential quadratically constrained quadratic programming method is extended to the multiobjective case and a new line search technique is developed for nonlinear multiobjective optimization problems. The proposed method ensures global convergence as well as spreading of the Pareto front. A descent direction is obtained by solving a quadratically constrained quadratic programming subproblem. A nondifferentiable penalty function is used to restrict the constraint violations. Convergence of the descent sequence is established under the Mangasarian--Fromovitz constraint qualification and some mild assumptions. In addition to this, a new technique is designed for selecting initial points to ensure the spreading of the Pareto front. The method is compared with existing methods using a set of test problems.},
  archive      = {J_SIOPT},
  author       = {Md Abu Talhamainuddin Ansary and Geetanjali Panda},
  doi          = {10.1137/18M1182152},
  journal      = {SIAM Journal on Optimization},
  number       = {1},
  pages        = {91-113},
  shortjournal = {SIAM J. Optim.},
  title        = {A globally convergent SQCQP method for multiobjective optimization problems},
  volume       = {31},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Convergence of newton-MR under inexact hessian information.
<em>SIOPT</em>, <em>31</em>(1), 59–90. (<a
href="https://doi.org/10.1137/19M1302211">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, there has been a surge of interest in designing variants of the classical Newton-CG in which the Hessian of a (strongly) convex function is replaced by suitable approximations. This is mainly motivated by large-scale finite-sum minimization problems that arise in many machine learning applications. Going beyond convexity, inexact Hessian information has also been recently considered in the context of algorithms such as trust-region or (adaptive) cubic regularization for general nonconvex problems. Here, we do that for Newton-MR, which extends the application range of the classical Newton-CG beyond convexity to invex problems. Unlike the convergence analysis of Newton-CG, which relies on spectrum preserving Hessian approximations in the sense of Löwner partial order, our work here draws from matrix perturbation theory to estimate the distance between the range spaces underlying the exact and approximate Hessian matrices. Numerical experiments demonstrate a great degree of resilience to such Hessian approximations, amounting to a highly efficient algorithm in large-scale problems.},
  archive      = {J_SIOPT},
  author       = {Yang Liu and Fred Roosta},
  doi          = {10.1137/19M1302211},
  journal      = {SIAM Journal on Optimization},
  number       = {1},
  pages        = {59-90},
  shortjournal = {SIAM J. Optim.},
  title        = {Convergence of newton-MR under inexact hessian information},
  volume       = {31},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). TSSOS: A moment-SOS hierarchy that exploits term sparsity.
<em>SIOPT</em>, <em>31</em>(1), 30–58. (<a
href="https://doi.org/10.1137/19M1307871">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is concerned with polynomial optimization problems. We show how to exploit term (or monomial) sparsity of the input polynomials to obtain a new converging hierarchy of semidefinite programming relaxations. The novelty (and distinguishing feature) of such relaxations is to involve block-diagonal matrices obtained in an iterative procedure performing completion of the connected components of certain adjacency graphs. The graphs are related to the terms arising in the original data and not to the links between variables. Our theoretical framework is then applied to compute lower bounds for polynomial optimization problems either randomly generated or coming from the networked system literature.},
  archive      = {J_SIOPT},
  author       = {Jie Wang and Victor Magron and Jean-Bernard Lasserre},
  doi          = {10.1137/19M1307871},
  journal      = {SIAM Journal on Optimization},
  number       = {1},
  pages        = {30-58},
  shortjournal = {SIAM J. Optim.},
  title        = {TSSOS: A moment-SOS hierarchy that exploits term sparsity},
  volume       = {31},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An interior-point approach for solving risk-averse
PDE-constrained optimization problems with coherent risk measures.
<em>SIOPT</em>, <em>31</em>(1), 1–29. (<a
href="https://doi.org/10.1137/19M125039X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The prevalence of uncertainty in models of engineering and the natural sciences necessitates the inclusion of random parameters in the underlying partial differential equations (PDEs). The resulting decision problems governed by the solution of such random PDEs are infinite dimensional stochastic optimization problems. In order to obtain risk-averse optimal decisions in the face of such uncertainty, it is common to employ risk measures in the objective function. This leads to risk-averse PDE-constrained optimization problems. We propose a method for solving such problems in which the risk measures are convex combinations of the mean and conditional value-at-risk (CVaR). Since these risk measures can be evaluated by solving a related inequality-constrained optimization problem, we suggest a log-barrier technique to approximate the risk measure. This leads to a new continuously differentiable convex risk measure: the log-barrier risk measure. We show that the log-barrier risk measure fits into the setting of optimized certainty equivalents of Ben-Tal and Teboulle and the expectation quadrangle of Rockafellar and Uryasev. Using the differentiability of the log-barrier risk measure, we derive first-order optimality conditions reminiscent of classical primal and primal-dual interior-point approaches in nonlinear programming. We derive the associated Newton system, propose a reduced symmetric system to calculate the steps, and provide a sufficient condition for local superlinear convergence in the continuous setting. Furthermore, we provide a $\Gamma$-convergence result for the log-barrier risk measures to prove convergence of the minimizers to the original nonsmooth problem. The results are illustrated by a numerical study.},
  archive      = {J_SIOPT},
  author       = {Sebastian Garreis and Thomas M. Surowiec and Michael Ulbrich},
  doi          = {10.1137/19M125039X},
  journal      = {SIAM Journal on Optimization},
  number       = {1},
  pages        = {1-29},
  shortjournal = {SIAM J. Optim.},
  title        = {An interior-point approach for solving risk-averse PDE-constrained optimization problems with coherent risk measures},
  volume       = {31},
  year         = {2021},
}
</textarea>
</details></li>
</ul>

</body>
</html>
