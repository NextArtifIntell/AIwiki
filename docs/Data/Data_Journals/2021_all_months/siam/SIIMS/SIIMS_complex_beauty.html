<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>SIIMS_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="siims---63">SIIMS - 63</h2>
<ul>
<li><details>
<summary>
(2021). A stochastic proximal alternating minimization for nonsmooth
and nonconvex optimization. <em>SIIMS</em>, <em>14</em>(4), 1932–1970.
(<a href="https://doi.org/10.1137/20M1387213">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we introduce a novel stochastic proximal alternating linearized minimization algorithm [J. Bolte, S. Sabach, and M. Teboulle, Math. Program., 146 (2014), pp. 459--494] for solving a class of nonsmooth and nonconvex optimization problems. Large-scale imaging problems are becoming increasingly prevalent due to the advances in data acquisition and computational capabilities. Motivated by the success of stochastic optimization methods, we propose a stochastic variant of proximal alternating linearized minimization. We provide global convergence guarantees, demonstrating that our proposed method with variance-reduced stochastic gradient estimators, such as SAGA [A. Defazio, F. Bach, and S. Lacoste-Julien, Advances in Neural Information Processing Systems, 2014, pp. 1646--1654] and SARAH [L. M. Nguyen, J. Liu, K. Scheinberg, and M. Takáĉ, Proceedings of the 34th International Conference on Machine Learning, PMLR 70, 2017, pp. 2613--2621], achieves state-of-the-art oracle complexities. We also demonstrate the efficacy of our algorithm via several numerical examples including sparse nonnegative matrix factorization, sparse principal component analysis, and blind image-deconvolution.},
  archive      = {J_SIIMS},
  author       = {Derek Driggs and Junqi Tang and Jingwei Liang and Mike Davies and Carola-Bibiane Schönlieb},
  doi          = {10.1137/20M1387213},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {4},
  pages        = {1932-1970},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {A stochastic proximal alternating minimization for nonsmooth and nonconvex optimization},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Diffeomorphic image registration with an optimal control
relaxation and its implementation. <em>SIIMS</em>, <em>14</em>(4),
1890–1931. (<a href="https://doi.org/10.1137/21M1391274">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image registration has played an important role in image processing problems, especially in medical imaging applications. It is well known that when the deformation is large, many variational models cannot ensure diffeomorphism. In this paper, we propose a new registration model based on an optimal control relaxation constraint for large deformation images, which can theoretically guarantee that the registration mapping is diffeomorphic. We present an analysis of optimal control relaxation for indirectly seeking the diffeomorphic transformation of the Jacobian determinant equation and its registration applications, including the construction of diffeomorphic transformation as a special space. We also provide an existence result for the control increment optimization problem in the proposed diffeomorphic image registration model with an optimal control relaxation. Furthermore, a fast iterative scheme based on the augmented Lagrangian multipliers method (ALMM) is analyzed to solve the control increment optimization problem, and a convergence analysis follows. Finally, a grid unfolding indicator is given, and a robust solving algorithm for using the deformation correction and backtrack strategy is proposed to guarantee that the solution is diffeomorphic. Numerical experiments show that the registration model we propose not only obtains a diffeomorphic mapping when the deformation is large but also achieves a state-of-the-art performance in quantitative evaluations that is comparable to that of other classical models.},
  archive      = {J_SIIMS},
  author       = {Jianping Zhang and Yanyan Li},
  doi          = {10.1137/21M1391274},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {4},
  pages        = {1890-1931},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Diffeomorphic image registration with an optimal control relaxation and its implementation},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Provably robust blind source separation of linear-quadratic
near-separable mixtures. <em>SIIMS</em>, <em>14</em>(4), 1848–1889. (<a
href="https://doi.org/10.1137/20M1382878">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we consider the problem of blind source separation (BSS) by departing from the usual linear model and focusing on the linear-quadratic (LQ) one. We propose two provably robust and computationally tractable algorithms to tackle this problem under separability assumptions which require the sources to appear as samples in the data set. The first algorithm, referred to as SNPALQ, generalizes the successive nonnegative projection algorithm (SNPA), designed for linear BSS. By explicitly modeling the product terms inherent to the LQ model along the iterations of the SNPA scheme, the nonlinear contributions of the mixing are mitigated, thus improving the separation quality. SNPALQ is shown to be able to recover the ground truth factors that generated the data, even in the presence of noise. The second algorithm is a brute force (BF) algorithm, which can be used as a postprocessing step for SNPALQ. It then enables one to discard the spurious (mixed) samples extracted by SNPALQ, thus broadening its applicability. The BF is in turn shown to be robust to noise (under potentially easier-to-check conditions than those of SNPALQ). We show that SNPALQ with and without the BF postprocessing is relevant in realistic numerical experiments.},
  archive      = {J_SIIMS},
  author       = {Christophe Kervazo and Nicolas Gillis and Nicolas Dobigeon},
  doi          = {10.1137/20M1382878},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {4},
  pages        = {1848-1889},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Provably robust blind source separation of linear-quadratic near-separable mixtures},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). DIP-VBTV: A color image restoration model combining a deep
image prior and a vector bundle total variation. <em>SIIMS</em>,
<em>14</em>(4), 1816–1847. (<a
href="https://doi.org/10.1137/20M1378697">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we introduce a new variational model for color image restoration, called DIP-VBTV, which combines two priors: a deep image prior (DIP), which assumes that the restored image can be generated through a neural network, and a vector bundle total variation (VBTV), which generalizes the vectorial total variation (VTV) on vector bundles. VBTV is determined by a geometric triplet: a Riemannian metric on the base manifold, a covariant derivative, and a metric on the vector bundle. Whereas the VTV prior encourages the restored images to be piecewise constant, the VBTV prior encourages them to be piecewise parallel with respect to a covariant derivative. For well-chosen geometric triplets, we show that the minimization of VBTV encourages the solutions of the restoration model to share some visual content with the clean image. Then, we show in experiments that DIP-VBTV benefits from this property by outperforming DIP-VTV and state-of-the-art unsupervised methods. It demonstrates the relevance of combining DIP and VBTV priors.},
  archive      = {J_SIIMS},
  author       = {Thomas Batard and Gloria Haro and Coloma Ballester},
  doi          = {10.1137/20M1378697},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {4},
  pages        = {1816-1847},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {DIP-VBTV: A color image restoration model combining a deep image prior and a vector bundle total variation},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Convergent conformal energy minimization for the computation
of disk parameterizations. <em>SIIMS</em>, <em>14</em>(4), 1790–1815.
(<a href="https://doi.org/10.1137/21M1415443">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Surface conformal parameterizations have been widely applied to various tasks in computer graphics. In this paper, we develop a convergent conformal energy minimization (CCEM) iterative algorithm via the line-search gradient descent method with a quadratic approximation for the computation of disk-shaped conformal parameterizations of simply connected open triangular meshes. In addition, we prove the global convergence of the proposed CCEM iterative algorithm. Moreover, under some mild assumptions, we prove the existence of a nontrivial solution, which is a local minimum of the conformal energy with a bijective boundary map. The numerical experiments indicate that the efficiency of the proposed CCEM algorithm is greatly improved and that the accuracy is competitive with that of state-of-the-art algorithms.},
  archive      = {J_SIIMS},
  author       = {Yueh-Cheng Kuo and Wen-Wei Lin and Mei-Heng Yueh and Shing-Tung Yau},
  doi          = {10.1137/21M1415443},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {4},
  pages        = {1790-1815},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Convergent conformal energy minimization for the computation of disk parameterizations},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A variational approach to additive image decomposition into
structure, harmonic, and oscillatory components. <em>SIIMS</em>,
<em>14</em>(4), 1749–1789. (<a
href="https://doi.org/10.1137/20M1355987">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a nonconvex variational decomposition model which separates a given image into piecewise-constant, smooth, and oscillatory components. This decomposition is motivated not only by image denoising and structure separation, but also by shadow and spot light removal. The proposed model clearly separates the piecewise-constant structure and smoothly varying harmonic part, thanks to having a separated oscillatory component. The piecewise-constant part is captured by TV-like nonconvex regularization, harmonic term via second-order regularization, and oscillatory (noise and texture) term via a $H^{-1}$-norm penalty. There are interesting interactions between these three regularization terms. We explore the effects of each regularization and the choice of parameters carefully. We propose an efficient alternating direction method of multipliers based minimization for fast numerical computation of the optimization problem. Various experiments are presented to show the robustness against a high level of noise, applications to soft spotlight and shadow removal, and the comparisons with other methods.},
  archive      = {J_SIIMS},
  author       = {Martin Huska and Sung H. Kang and Alessandro Lanza and Serena Morigi},
  doi          = {10.1137/20M1355987},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {4},
  pages        = {1749-1789},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {A variational approach to additive image decomposition into structure, harmonic, and oscillatory components},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Shared prior learning of energy-based models for image
reconstruction. <em>SIIMS</em>, <em>14</em>(4), 1706–1748. (<a
href="https://doi.org/10.1137/20M1380016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a novel learning-based framework for image reconstruction particularly designed for training without ground truth data, which has three major building blocks: energy-based learning, a patch-based Wasserstein loss functional, and shared prior learning. In energy-based learning, the parameters of an energy functional composed of a learned data fidelity term and a data-driven regularizer are computed in a mean-field optimal control problem. In the absence of ground truth data, we change the loss functional to a patch-based Wasserstein functional, in which local statistics of the output images are compared to uncorrupted reference patches. Finally, in shared prior learning, both aforementioned optimal control problems are optimized simultaneously with shared learned parameters of the regularizer to further enhance unsupervised image reconstruction. We derive several time discretization schemes of the gradient flow and verify their consistency in terms of Mosco convergence. In numerous numerical experiments, we demonstrate that the proposed method generates state-of-the-art results for various image reconstruction applications---even if no ground truth images are available for training.},
  archive      = {J_SIIMS},
  author       = {Thomas Pinetz and Erich Kobler and Thomas Pock and Alexander Effland},
  doi          = {10.1137/20M1380016},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {4},
  pages        = {1706-1748},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Shared prior learning of energy-based models for image reconstruction},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Sparse inpainting with smoothed particle hydrodynamics.
<em>SIIMS</em>, <em>14</em>(4), 1669–1705. (<a
href="https://doi.org/10.1137/20M1382179">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Digital image inpainting refers to techniques used to reconstruct a damaged or incomplete image by exploiting available image information. The main goal of this work is to perform the image inpainting process from a set of sparsely distributed image samples with the smoothed particle hydrodynamics (SPH) technique. Because, in its naive formulation, the SPH technique is not even capable of reproducing constant functions, we modify the approach to obtain an approximation which can reproduce constant and linear functions. Furthermore, we examine the use of Voronoi tessellation for defining the necessary parameters in the SPH method as well as selecting optimally located image samples. In addition to this spatial optimization, optimization of data values is also implemented in order to further improve the results. Apart from a traditional Gaussian smoothing kernel, we assess the performance of other kernels on both random and spatially optimized masks. Since the use of isotropic smoothing kernels is not optimal in the presence of objects with a clear preferred orientation in the image, we also examine anisotropic smoothing kernels. Our final algorithm can compete with well-performing sparse inpainting techniques based on homogeneous or anisotropic diffusion processes as well as with exemplar-based approaches.},
  archive      = {J_SIIMS},
  author       = {Viktor Daropoulos and Matthias Augustin and Joachim Weickert},
  doi          = {10.1137/20M1382179},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {4},
  pages        = {1669-1705},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Sparse inpainting with smoothed particle hydrodynamics},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Imaging in random media by two-point coherent
interferometry. <em>SIIMS</em>, <em>14</em>(4), 1635–1668. (<a
href="https://doi.org/10.1137/21M142068X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper considers wave-based imaging through a heterogeneous (random) scattering medium. The goal is to estimate the support of the reflectivity function of a remote scene from measurements of the backscattered wave field. The proposed imaging methodology is based on the coherent interferometric (CINT) approach that exploits the local empirical cross correlations of the measurements of the wave field. The standard CINT images are known to be robust (statistically stable) with respect to the random medium, but the stability comes at the expense of a loss of resolution. This paper shows that a two-point CINT function contains the information needed to obtain statistically stable and high-resolution images. Different methods to build such images are presented, theoretically analyzed, and compared with the standard imaging approaches using numerical simulations. The first method involves a phase retrieval step to extract the reflectivity function from the modulus of its Fourier transform. The second method involves the evaluation of the leading eigenvector of the two-point CINT imaging function seen as the kernel of a linear operator. The third method uses an optimization step to extract the reflectivity function from some cross products of its Fourier transform. The presentation is for the synthetic aperture radar data acquisition setup, where a moving sensor probes the scene with signals emitted periodically and records the resulting backscattered wave. The generalization to other imaging setups, with passive or active arrays of sensors, is discussed briefly.},
  archive      = {J_SIIMS},
  author       = {Liliana Borcea and Josselin Garnier},
  doi          = {10.1137/21M142068X},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {4},
  pages        = {1635-1668},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Imaging in random media by two-point coherent interferometry},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A sufficient condition of optimality for the relative pose
problem between cameras. <em>SIIMS</em>, <em>14</em>(4), 1617–1634. (<a
href="https://doi.org/10.1137/21M1397970">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Relative Pose problem (RPp) seeks for the relative rotation and translation between two central, calibrated cameras given a set of pairwise feature correspondences. The RPp is a fundamental block for many 3D computer vision tasks, and hence the quality of the estimated relative pose is of key importance for the correct performance of these applications. Nonetheless, the RPp is a nonconvex problem that presents multiple local minima. Recent nonminimal solvers provide relatively fast certifiable solutions, usually relying on a convex relaxation of the problem; however, there is no guarantee a priori that these relaxations return the optimal solution, i.e., are tight. This work presents a sufficient condition to guarantee that a given solution of the RPp is the global optimum in a faster way than evaluating a certifiable algorithm (up to four times faster). We state the RPp as an optimization problem that minimizes the squared normalized epipolar error over the set of normalized essential matrices. The proposed condition is derived through spectral analysis and builds up on the recently proposed certifiable algorithm in [M. Garcia-Salguero, J. Briales, and J. Gonzalez-Jimenez, Image Vis. Comput., 109 (2021), 104142]. The results of extensive experiments, with both synthetic and real data, support that by using the proposed conditions we can detect a large number of optimal solutions for most common problem instances.},
  archive      = {J_SIIMS},
  author       = {Mercedes Garcia-Salguero and Javier Gonzalez-Jimenez},
  doi          = {10.1137/21M1397970},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {4},
  pages        = {1617-1634},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {A sufficient condition of optimality for the relative pose problem between cameras},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An acousto-electric inverse source problem. <em>SIIMS</em>,
<em>14</em>(4), 1601–1616. (<a
href="https://doi.org/10.1137/21M1406568">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a method to reconstruct the electrical current density inside a conducting medium from acoustically modulated boundary measurements of the electric potential. We show that the current can be uniquely reconstructed with Lipschitz stability. We also perform numerical simulations to illustrate the analytical results, and we explore the partial data setting when measurements are taken only on part of the boundary.},
  archive      = {J_SIIMS},
  author       = {Wei Li and John C. Schotland and Yang Yang and Yimin Zhong},
  doi          = {10.1137/21M1406568},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {4},
  pages        = {1601-1616},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {An acousto-electric inverse source problem},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An inexact semismooth newton method on riemannian manifolds
with application to duality-based total variation denoising.
<em>SIIMS</em>, <em>14</em>(4), 1565–1600. (<a
href="https://doi.org/10.1137/21M1398513">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a higher-order method for solving nonsmooth optimization problems on manifolds. To obtain superlinear convergence, we apply a Riemannian semismooth Newton method to a nonsmooth nonlinear primal-dual optimality system based on a recent extension of Fenchel duality theory to Riemannian manifolds. We also propose an inexact version of the Riemannian semismooth Newton method and prove conditions for local linear and superlinear convergence that hold independent of the sign of the curvature. Numerical experiments on $\ell^2$-TV-like problems with dual regularization confirm superlinear convergence on manifolds with positive and negative curvature.},
  archive      = {J_SIIMS},
  author       = {Willem Diepeveen and Jan Lellmann},
  doi          = {10.1137/21M1398513},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {4},
  pages        = {1565-1600},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {An inexact semismooth newton method on riemannian manifolds with application to duality-based total variation denoising},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Learnable descent algorithm for nonsmooth nonconvex image
reconstruction. <em>SIIMS</em>, <em>14</em>(4), 1532–1564. (<a
href="https://doi.org/10.1137/20M1353368">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a general learning based framework for solving nonsmooth and nonconvex image reconstruction problems. We model the regularization function as the composition of the $l_{2,1}$ norm and a smooth but nonconvex feature mapping parametrized as a deep convolutional neural network. We develop a descent-type algorithm to solve the nonsmooth nonconvex minimization problem by leveraging Nesterov&#39;s smoothing technique and the idea of residual learning, and learn the network parameters such that the outputs of the algorithm match the references in training data. Our method is versatile as one can employ various modern network structures into the regularization, and the resulting network inherits the convergence properties of the algorithm. We also show that the proposed network is parameter-efficient, and its performance compares favorably to the state-of-the-art methods in a variety of image reconstruction problems in practice.},
  archive      = {J_SIIMS},
  author       = {Yunmei Chen and Hongcheng Liu and Xiaojing Ye and Qingchao Zhang},
  doi          = {10.1137/20M1353368},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {4},
  pages        = {1532-1564},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Learnable descent algorithm for nonsmooth nonconvex image reconstruction},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). On the convergence rate of projected gradient descent for a
back-projection based objective. <em>SIIMS</em>, <em>14</em>(4),
1504–1531. (<a href="https://doi.org/10.1137/21M1407902">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ill-posed linear inverse problems appear in many scientific setups and are typically addressed by solving optimization problems, which are composed of data fidelity and prior terms. Recently, several works have considered a back-projection (BP) based fidelity term as an alternative to the common least squares (LS) and demonstrated excellent results for popular inverse problems. These works have also empirically shown that using the BP term, rather than the LS term, requires fewer iterations of optimization algorithms. In this paper, we examine the convergence rate of the projected gradient descent algorithm for the BP objective. Our analysis allows us to identify an inherent source for its faster convergence compared to using the LS objective, while making only mild assumptions. We also analyze the more general proximal gradient method under a relaxed contraction condition on the proximal mapping of the prior. This analysis further highlights the advantage of BP when the linear measurement operator is badly conditioned. Numerical experiments with both $\ell_1$-norm and GAN based priors corroborate our theoretical results.},
  archive      = {J_SIIMS},
  author       = {Tom Tirer and Raja Giryes},
  doi          = {10.1137/21M1407902},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {4},
  pages        = {1504-1531},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {On the convergence rate of projected gradient descent for a back-projection based objective},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Robust CUR decomposition: Theory and imaging applications.
<em>SIIMS</em>, <em>14</em>(4), 1472–1503. (<a
href="https://doi.org/10.1137/20M1388322">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper considers the use of robust principal component analysis (RPCA) in a CUR decomposition framework and applications thereof. Our main algorithms produce a robust version of column-row factorizations of matrices $D=L+S$, where $L$ is low-rank and $S$ contains sparse outliers. These methods yield interpretable factorizations at low computational cost and provide new CUR decompositions that are robust to sparse outliers, in contrast to previous methods. We consider two key imaging applications of RPCA: video foreground-background separation and face modeling. This paper examines the qualitative behavior of our robust CUR decompositions on the benchmark videos and face datasets and finds that our method works as well as standard RPCA while being significantly faster. Additionally, we consider hybrid randomized and deterministic sampling methods which produce a compact CUR decomposition of a given matrix and apply this to video sequences to produce canonical frames thereof.},
  archive      = {J_SIIMS},
  author       = {HanQin Cai and Keaton Hamm and Longxiu Huang and Deanna Needell},
  doi          = {10.1137/20M1388322},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {4},
  pages        = {1472-1503},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Robust CUR decomposition: Theory and imaging applications},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Regularized kaczmarz algorithms for tensor recovery.
<em>SIIMS</em>, <em>14</em>(4), 1439–1471. (<a
href="https://doi.org/10.1137/21M1398562">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tensor recovery has recently arisen in a lot of application fields, such as transportation, medical imaging, and remote sensing. Under the assumption that signals possess sparse and/or low-rank structures, many tensor recovery methods have been developed to apply various regularization techniques together with the operator-splitting type of algorithms. Due to the unprecedented growth of data, it becomes increasingly desirable to use streamlined algorithms to achieve real-time computation, such as stochastic optimization algorithms that have recently emerged as an efficient family of methods in machine learning. In this work, we propose a novel algorithmic framework based on the Kaczmarz algorithm for tensor recovery. We provide thorough convergence analysis and its applications from the vector case to the tensor one. Numerical results on a variety of tensor recovery applications, including sparse signal recovery, low-rank tensor recovery, image inpainting, and deconvolution, illustrate the enormous potential of the proposed methods.},
  archive      = {J_SIIMS},
  author       = {Xuemei Chen and Jing Qin},
  doi          = {10.1137/21M1398562},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {4},
  pages        = {1439-1471},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Regularized kaczmarz algorithms for tensor recovery},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Simultaneous reconstruction of conductivity, boundary shape,
and contact impedances in electrical impedance tomography.
<em>SIIMS</em>, <em>14</em>(4), 1407–1438. (<a
href="https://doi.org/10.1137/21M1407975">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The objective of electrical impedance tomography (EIT) is to reconstruct the internal conductivity of a physical body based on current and voltage measurements at the boundary of the body. In many medical applications the exact shape of the domain boundary and contact impedances are not available. This is problematic as even small errors in the boundary shape of the computation domain or in the contact impedance values can produce large artifacts in the reconstructed images, which results in a loss of relevant information. A method is proposed that simultaneously reconstructs the conductivity, the contact impedances, and the boundary shape from EIT data. The approach consists of three steps: first, the unknown contact impedances and an anisotropic conductivity reproducing the measured EIT data in a model domain are computed. Second, using isothermal coordinates, a deformation is constructed that makes the conductivity isotropic. The final step minimizes the error of true and reconstructed known geometric properties (like the electrode lengths) using conformal deformations. The feasibility of the method is illustrated with experimental EIT data, with robust and accurate reconstructions of both conductivity and boundary shape.},
  archive      = {J_SIIMS},
  author       = {Juan P. Agnelli and Ville Kolehmainen and Matti J. Lassas and Petri Ola and Samuli Siltanen},
  doi          = {10.1137/21M1407975},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {4},
  pages        = {1407-1438},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Simultaneous reconstruction of conductivity, boundary shape, and contact impedances in electrical impedance tomography},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Regularization by denoising via fixed-point projection
(RED-PRO). <em>SIIMS</em>, <em>14</em>(3), 1374–1406. (<a
href="https://doi.org/10.1137/20M1337168">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inverse problems in image processing are typically cast as optimization tasks, consisting of data fidelity and stabilizing regularization terms. A recent regularization strategy of great interest utilizes the power of denoising engines. Two such methods are the plug-and-play prior (PnP) and regularization by denoising (RED). While both have shown state-of-the-art results in various recovery tasks, their theoretical justification is incomplete. In this paper, we aim to bridge RED and PnP, enriching the understanding of both frameworks. Toward that end, we reformulate RED as a convex optimization problem utilizing a projection (RED-PRO) onto the fixed-point set of demicontractive denoisers. We offer a simple iterative solution to this problem, by which we show that under certain conditions the PnP proximal gradient method is a special case of RED-PRO, while providing guarantees for the convergence of both frameworks to globally optimal solutions. In addition, we present relaxations of RED-PRO that allow for handling denoisers with limited fixed-point sets. Finally, we demonstrate RED-PRO for the tasks of image deblurring and superresolution, showing improved results with respect to the original RED framework.},
  archive      = {J_SIIMS},
  author       = {Regev Cohen and Michael Elad and Peyman Milanfar},
  doi          = {10.1137/20M1337168},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {3},
  pages        = {1374-1406},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Regularization by denoising via fixed-point projection (RED-PRO)},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A doubly graduated method for inference in markov random
field. <em>SIIMS</em>, <em>14</em>(3), 1354–1373. (<a
href="https://doi.org/10.1137/20M1383574">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Maximum a posteriori (MAP) inference in Markov random field (MRF) lays the foundation for many computer vision tasks, which can be formulated by a binary quadratic programming (BQP) problem. Compared with the discrete methods, the continuous relaxation scheme becomes popular due to its generality and efficiency. However, existing continuous relaxation based MAP algorithms are still limited by two problems, i.e., the highly nonconvex original objective function and the gap between the original BQP problem and the relaxed continuous optimization problem. Targeting the two problems, this paper presents a doubly graduated continuous relaxation algorithm for MAP inference in MRF, which are, respectively, the Gaussian smoothing based graduated nonconvexity process and conditional gradient ascent based graduated projection. Experiments on both synthetic data and real-world images illustrate the algorithm&#39;s state-of-the-art performance in objective function optimization and typical computer vision tasks.},
  archive      = {J_SIIMS},
  author       = {Xu Yang and Zhi-Yong Liu},
  doi          = {10.1137/20M1383574},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {3},
  pages        = {1354-1373},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {A doubly graduated method for inference in markov random field},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A stochastic variance reduced primal dual fixed point method
for linearly constrained separable optimization. <em>SIIMS</em>,
<em>14</em>(3), 1326–1353. (<a
href="https://doi.org/10.1137/20M1354398">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we combine the stochastic variance reduced gradient (SVRG) method [R. Johnson and T. Zhang, in Advances in Neural Information Processing Systems 26, 2013, pp. 315--323] with the primal dual fixed point method (PDFP) proposed in [P. Chen, J. Huang, and X. Zhang, Inverse Problems, 29 (2013)] to minimize a sum of two convex functions, one of which is linearly composite. This type of problems typically arise in sparse signal and image reconstruction. The proposed SVRG-PDFP can be seen as a generalization of Prox-SVRG [L. Xiao and T. Zhang, SIAM J. Optim., 24 (2014), pp. 2057--2075] originally designed for the minimization of a sum of two convex functions. Based on some standard assumptions, we propose two variants, one for strongly convex objective functions and the other for the general convex case. Convergence analysis shows that the convergence rate of SVRG-PDFP is $\mathcal{O}(\frac{1}{k})$ (here $k$ is the iteration number) for the general convex objective function and linear for the strongly convex case. Numerical examples on machine learning and computerized tomography image reconstruction are provided to show the effectiveness of the algorithms.},
  archive      = {J_SIIMS},
  author       = {Ya-Nan Zhu and Xiaoqun Zhang},
  doi          = {10.1137/20M1354398},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {3},
  pages        = {1326-1353},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {A stochastic variance reduced primal dual fixed point method for linearly constrained separable optimization},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Pseudo-monochromatic imaging in industrial x-ray computed
tomography. <em>SIIMS</em>, <em>14</em>(3), 1306–1325. (<a
href="https://doi.org/10.1137/20M1373761">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the most challenging issues in computed tomography (CT) is the reduction of beam-hardening artifacts (BHAs). The presence of highly attenuating materials produces BHAs in CT images because of violating the mathematical CT model assumption of the projection data (i.e., that the data is a linear transform of an image). Here, the linear assumption is violated by nonlinear characteristics depending on the polychromatic nature of the X-ray beam combined with the energy-dependent variations in the attenuation coefficients of highly attenuating materials. Very recently, a new BHA-reduction method that uses a beam-hardening filter placed in front of an X-ray beam was developed independently by the first author [Method for Calibrating Beam-hardening Artifacts of Computed Tomography Image and Computed Tomography Apparatus using Thereof, KR Patent: 10-2018-0023663, 2018] and Butzer et al. [Dual-energy in industrial CT -- How simple math can reveal structures hidden by artefacts, in Proceedings of the 6th International Conference on Image Formation in X-Ray Computed Tomography, 2020, pp. 94--97]. Experiments reveal that this new method is remarkably effective at reducing BHAs in the presence of high-attenuation materials, and it has already been applied to several industrial CT problems. However, to date, no mathematical basis for its impressive performance has been found. This paper presents this filtered method and, for the first time, provides a theoretical basis for demonstrating the effectiveness of the filter-based methodology.},
  archive      = {J_SIIMS},
  author       = {Hyoung Suk Park and Junhwa Jung and Jin Keun Seo},
  doi          = {10.1137/20M1373761},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {3},
  pages        = {1306-1325},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Pseudo-monochromatic imaging in industrial X-ray computed tomography},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Generalized intersection algorithms with fixed points for
image decomposition learning. <em>SIIMS</em>, <em>14</em>(3), 1273–1305.
(<a href="https://doi.org/10.1137/20M1375553">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In image processing, classical methods minimize a suitable functional that balances between computational feasibility (convexity of the functional is ideal) and suitable penalties reflecting the desired image decomposition. The fact that algorithms derived from such minimization problems can be used to construct (deep) learning architectures has spurred the development of algorithms that can be trained for a specifically desired image decomposition, e.g., into cartoon and texture. While many such methods are very successful, theoretical guarantees are only scarcely available. To this end, in this contribution, we formalize a general class of intersection point problems encompassing a wide range of (learned) image decomposition models, and we give an existence result for a large subclass of such problems, i.e., giving the existence of a fixed point of the corresponding algorithm. This class generalizes classical model-based variational problems, such as the TV-$\ell^2$-model or the more general TV-Hilbert model. To illustrate the potential for learned algorithms, novel (nonlearned) choices within our class show comparable results in denoising and texture removal.},
  archive      = {J_SIIMS},
  author       = {Robin Richter and Duy H. Thai and Stephan Huckemann},
  doi          = {10.1137/20M1375553},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {3},
  pages        = {1273-1305},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Generalized intersection algorithms with fixed points for image decomposition learning},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Adaptive mesh refinement in deformable image registration: A
posteriori error estimates for primal and mixed formulations.
<em>SIIMS</em>, <em>14</em>(3), 1238–1272. (<a
href="https://doi.org/10.1137/20M1364333">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deformable image registration (DIR) is a popular technique for the alignment of digital images, with highly relevant applications in medical image analysis. However, the numerical solution of DIR problems can be very challenging in computational terms, as the improvement of the DIR solution typically involves a uniform refinement of the underlying domain discretization that exponentially increases the number of degrees of freedom. In this work, we develop adaptive mesh refinement schemes particularly designed for the finite-element solution of DIR problems. We start by deriving residual-based a posteriori error estimators for the primal and mixed formulations of the DIR problem and show that they are reliable and efficient. Based on these error estimators, we implement adaptive mesh-refinement schemes into a finite-element code to register images. We assess the numerical performance of the proposed adaptive scheme on smooth synthetic images, where numerical convergence is verified. We further show that the adaptive mesh refinement scheme can deliver solutions to DIR problems with significant reductions in the number of degrees of freedom without compromising the accuracy of the solution. We also confirm that the adaptive scheme proposed for the mixed DIR formulation successfully handles volume-constrained registration problems, providing optimal convergence in analytic examples. To demonstrate the applicability of the method, we perform adaptive DIR on medical brain images and binary images and study how image noise affects the proposed refinement schemes.},
  archive      = {J_SIIMS},
  author       = {Nicolas Barnafi and Gabriel N. Gatica and Daniel E. Hurtado and Willian Miranda and Ricardo Ruiz-Baier},
  doi          = {10.1137/20M1364333},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {3},
  pages        = {1238-1272},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Adaptive mesh refinement in deformable image registration: A posteriori error estimates for primal and mixed formulations},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Learning maximally monotone operators for image recovery.
<em>SIIMS</em>, <em>14</em>(3), 1206–1237. (<a
href="https://doi.org/10.1137/20M1387961">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce a new paradigm for solving regularized variational problems. These are typically formulated to address ill-posed inverse problems encountered in signal and image processing. The objective function is traditionally defined by adding a regularization function to a data fit term, which is subsequently minimized by using iterative optimization algorithms. Recently, several works have proposed to replace the operator related to the regularization by a more sophisticated denoiser. These approaches, known as plug-and-play (PnP) methods, have shown excellent performance. Although it has been noticed that, under some Lipschitz properties on the denoisers, the convergence of the resulting algorithm is guaranteed, little is known about characterizing the asymptotically delivered solution. In the current article, we propose to address this limitation. More specifically, instead of employing a functional regularization, we perform an operator regularization, where a maximally monotone operator (MMO) is learned in a supervised manner. This formulation is flexible as it allows the solution to be characterized through a broad range of variational inequalities, and it includes convex regularizations as special cases. From an algorithmic standpoint, the proposed approach consists in replacing the resolvent of the MMO by a neural network (NN). We present a universal approximation theorem proving that nonexpansive NNs are suitable models for the resolvent of a wide class of MMOs. The proposed approach thus provides a sound theoretical framework for analyzing the asymptotic behavior of first-order PnP algorithms. In addition, we propose a numerical strategy to train NNs corresponding to resolvents of MMOs. We apply our approach to image restoration problems and demonstrate its validity in terms of both convergence and quality.},
  archive      = {J_SIIMS},
  author       = {Jean-Christophe Pesquet and Audrey Repetti and Matthieu Terris and Yves Wiaux},
  doi          = {10.1137/20M1387961},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {3},
  pages        = {1206-1237},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Learning maximally monotone operators for image recovery},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A characteristic function-based algorithm for geodesic
active contours. <em>SIIMS</em>, <em>14</em>(3), 1184–1205. (<a
href="https://doi.org/10.1137/20M1382817">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Active contour models have been widely used in image segmentation, and the level set method (LSM) is the most popular approach for solving the models, via implicitly representing the contour by a level set function. However, the LSM suffers from high computational burden and numerical instability, requiring additional regularization terms or reinitialization techniques. In this paper, we use characteristic functions to implicitly represent the contours, propose a new representation to the geodesic active contours, and derive an efficient algorithm termed the iterative convolution-thresholding method (ICTM). Compared to the LSM, the ICTM is simpler and much more efficient. In addition, the ICTM enjoys most desired features of the level set--based methods. Extensive experiments, on two-dimensional (2D) synthetic, 2D ultrasound, 3D computed tomography, and 3D magnetic resonance images for nodule, organ, and lesion segmentation demonstrate that the proposed method not only obtains comparable or even better segmentation results (compared to the LSM) but also achieves significant acceleration.},
  archive      = {J_SIIMS},
  author       = {Jun Ma and Dong Wang and Xiao-Ping Wang and Xiaoping Yang},
  doi          = {10.1137/20M1382817},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {3},
  pages        = {1184-1205},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {A characteristic function-based algorithm for geodesic active contours},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Improved recovery guarantees and sampling strategies for TV
minimization in compressive imaging. <em>SIIMS</em>, <em>14</em>(3),
1149–1183. (<a href="https://doi.org/10.1137/20M136788X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we consider the use of total variation (TV) minimization for compressive imaging, that is, image reconstruction from subsampled measurements. Focusing on two important imaging modalities---namely, Fourier imaging and structured binary imaging via the Walsh--Hadamard transform---we derive uniform recovery guarantees asserting stable and robust recovery for arbitrary random sampling strategies. Using this, we then derive a class of sampling strategies which are theoretically near-optimal for recovery of approximately gradient-sparse images. For Fourier sampling, we show recovery of such an image from $m \gtrsim_d s \cdot \log^2(s) \cdot \log^4(N)$ measurements, in $d \geq 1$ dimensions. When $d = 2$, this improves the current state-of-the-art result by a factor of $\log(s) \cdot \log(N)$. It also extends it to arbitrary dimensions $d \geq 2$. For Walsh sampling, we prove that $m \gtrsim_d s \cdot \log^2(s) \cdot \log^2(N/s) \cdot \log^3(N) $ measurements suffice in $d \geq 2$ dimensions. To the best of our knowledge, this is the first recovery guarantee for structured binary sampling with TV minimization.},
  archive      = {J_SIIMS},
  author       = {Ben Adcock and Nick Dexter and Qinghong Xu},
  doi          = {10.1137/20M136788X},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {3},
  pages        = {1149-1183},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Improved recovery guarantees and sampling strategies for TV minimization in compressive imaging},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Nonlinear power method for computing eigenvectors of
proximal operators and neural networks. <em>SIIMS</em>, <em>14</em>(3),
1114–1148. (<a href="https://doi.org/10.1137/20M1384154">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural networks have revolutionized the field of data science, yielding remarkable solutions in a data-driven manner. For instance, in the field of mathematical imaging, they have surpassed traditional methods based on convex regularization. However, a fundamental theory supporting the practical applications is still in the early stages of development. We take a fresh look at neural networks and examine them via nonlinear eigenvalue analysis. The field of nonlinear spectral theory is still emerging, providing insights about nonlinear operators and systems. In this paper we view a neural network as a complex nonlinear operator and attempt to find its nonlinear eigenvectors. We first discuss the existence of such eigenvectors and analyze the kernel of ReLU networks. Then we study a nonlinear power method for generic nonlinear operators. For proximal operators associated to absolutely one-homogeneous convex regularization functionals, we can prove convergence of the method to an eigenvector of the proximal operator. This motivates us to apply a nonlinear method to networks which are trained to act similarly as a proximal operator. In order to take the nonhomogeneity of neural networks into account we define a modified version of the power method. We perform extensive experiments for different proximal operators and on various shallow and deep neural networks designed for image denoising. Proximal eigenvectors will be used for geometric analysis of graphs, as clustering or the computation of distance functions. For simple neural nets, we observe the influence of training data on the eigenvectors. For state-of-the-art denoising networks, we show that eigenvectors can be interpreted as (un)stable modes of the network, when contaminated with noise or other degradations.},
  archive      = {J_SIIMS},
  author       = {Leon Bungert and Ester Hait-Fraenkel and Nicolas Papadakis and Guy Gilboa},
  doi          = {10.1137/20M1384154},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {3},
  pages        = {1114-1148},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Nonlinear power method for computing eigenvectors of proximal operators and neural networks},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A weighted difference of anisotropic and isotropic total
variation for relaxed mumford–shah color and multiphase image
segmentation. <em>SIIMS</em>, <em>14</em>(3), 1078–1113. (<a
href="https://doi.org/10.1137/20M1337041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In a class of piecewise-constant image segmentation models, we propose to incorporate a weighted difference of anisotropic and isotropic total variation (AITV) to regularize the partition boundaries in an image. In particular, we replace the total variation regularization in the Chan--Vese segmentation model and a fuzzy region competition model by the proposed AITV. To deal with the nonconvex nature of AITV, we apply the difference-of-convex algorithm (DCA), in which the subproblems can be minimized by the primal-dual hybrid gradient method with linesearch. The convergence of the DCA scheme is analyzed. In addition, a generalization to color image segmentation is discussed. In the numerical experiments, we compare the proposed models with the classic convex approaches and the two-stage segmentation methods (smoothing and then thresholding) on various images, showing that our models are effective in image segmentation and robust with respect to impulsive noises.},
  archive      = {J_SIIMS},
  author       = {Kevin Bui and Fredrick Park and Yifei Lou and Jack Xin},
  doi          = {10.1137/20M1337041},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {3},
  pages        = {1078-1113},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {A weighted difference of anisotropic and isotropic total variation for relaxed mumford--shah color and multiphase image segmentation},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Compressed sensing photoacoustic tomography reduces to
compressed sensing for undersampled fourier measurements.
<em>SIIMS</em>, <em>14</em>(3), 1039–1077. (<a
href="https://doi.org/10.1137/20M1375152">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Photoacoustic tomography (PAT) is an emerging imaging modality that aims at measuring the high-contrast optical properties of tissues by means of high-resolution ultrasonic measurements. The interaction between these two types of waves is based on the thermoacoustic effect. In recent years, many works have investigated the applicability of compressed sensing to PAT in order to reduce measuring times while maintaining a high reconstruction quality. However, in most cases, theoretical guarantees are missing. In this work, we show that in many measurement setups of practical interest, compressed sensing PAT reduces to compressed sensing for undersampled Fourier measurements. This is achieved by applying known reconstruction formulae in the case of the free-space model for wave propagation, and by applying the theories of Riesz bases and nonuniform Fourier series in the case of the bounded domain model. Extensive numerical simulations illustrate and validate the approach.},
  archive      = {J_SIIMS},
  author       = {Giovanni S. Alberti and Paolo Campodonico and Matteo Santacesaria},
  doi          = {10.1137/20M1375152},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {3},
  pages        = {1039-1077},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Compressed sensing photoacoustic tomography reduces to compressed sensing for undersampled fourier measurements},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A direct sampling method for the inversion of the radon
transform. <em>SIIMS</em>, <em>14</em>(3), 1004–1038. (<a
href="https://doi.org/10.1137/20M1374997">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a novel direct sampling method (DSM) for the effective and stable inversion of the Radon transform. The DSM is based on a generalization of the important almost orthogonality property in classical DSMs to fractional order Sobolev duality products and to a new family of probing functions. The fractional order duality product proves to be able to greatly enhance the robustness of the reconstructions in some practically important but severely ill-posed inverse problems associated with the Radon transform. We present a detailed analysis to better understand the performance of the new probing and index functions, which are crucial to stable and effective numerical reconstructions. The DSM can be computed in a very fast and highly parallel manner. Numerical experiments are carried out to compare the DSM with a popular existing method and to illustrate the efficiency, stability, and accuracy of the DSM.},
  archive      = {J_SIIMS},
  author       = {Yat Tin Chow and Fuqun Han and Jun Zou},
  doi          = {10.1137/20M1374997},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {3},
  pages        = {1004-1038},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {A direct sampling method for the inversion of the radon transform},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Microlocal analysis of generalized radon transforms from
scattering tomography. <em>SIIMS</em>, <em>14</em>(3), 976–1003. (<a
href="https://doi.org/10.1137/20M1357305">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Here we present a novel microlocal analysis of generalized Radon transforms which describe the integrals of $L^2$ functions of compact support over surfaces of revolution of $C^{\infty}$ curves $q$. We show that the Radon transforms are elliptic Fourier integral operators (FIO) and provide an analysis of the left projections $\Pi_L$. Our main theorem shows that $\Pi_L$ satisfies the semiglobal Bolker assumption if and only if $g=q&#39;/q$ is an immersion. An analysis of the visible singularities is presented, after which we derive novel Sobolev smoothness estimates for the generalized Radon FIO. Our theory has specific applications of interest in Emission Compton Scattering Tomography (ECST) and Bragg Scattering Tomography (BST). We show that the ECST and BST integration curves satisfy the semiglobal Bolker assumption and provide simulated reconstructions from ECST and BST data. Additionally, we give example “sinusoidal&quot; integration curves which do not satisfy Bolker and provide simulations of the image artifacts. The observed artifacts in reconstruction are shown to align exactly with our predictions.},
  archive      = {J_SIIMS},
  author       = {James W. Webber and Eric Todd Quinto},
  doi          = {10.1137/20M1357305},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {3},
  pages        = {976-1003},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Microlocal analysis of generalized radon transforms from scattering tomography},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Surface-localized transmission eigenstates, super-resolution
imaging, and pseudo surface plasmon modes. <em>SIIMS</em>,
<em>14</em>(3), 946–975. (<a
href="https://doi.org/10.1137/20M1388498">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present the discovery of a novel and intriguing global geometric structure of the (interior) transmission eigenfunctions associated with the Helmholtz system. It is shown in generic scenarios that there always exists a sequence of transmission eigenfunctions with the corresponding eigenvalues going to infinity such that those eigenfunctions are localized around the boundary of the domain. We provide a comprehensive and rigorous justification in the case within the radial geometry, whereas for the nonradial case, we conduct extensive numerical experiments to quantitatively verify the localizing behaviors. The discovery provides a new perspective on wave localization. As significant applications, we develop a novel inverse scattering scheme that can produce super-resolution imaging effects and propose a method of generating the so-called pseudo surface plasmon resonant (PSPR) modes with a potential sensing application.},
  archive      = {J_SIIMS},
  author       = {Yat Tin Chow and Youjun Deng and Youzi He and Hongyu Liu and Xianchao Wang},
  doi          = {10.1137/20M1388498},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {3},
  pages        = {946-975},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Surface-localized transmission eigenstates, super-resolution imaging, and pseudo surface plasmon modes},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Modes of homogeneous gradient flows. <em>SIIMS</em>,
<em>14</em>(3), 913–945. (<a
href="https://doi.org/10.1137/20M1388577">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Finding latent structures in data is drawing increasing attention in diverse fields such as image and signal processing, fluid dynamics, and machine learning. In this work we examine the problem of finding the main modes of gradient flows. Gradient descent is a fundamental process in optimization where its stochastic version is prominent in training of neural networks. Here our aim is to establish a consistent theory for gradient flows $\boldsymbol{\psi}_t = P(\boldsymbol{\psi})$, where $P$ is a nonlinear homogeneous operator. Our proposed framework stems from analytic solutions of homogeneous flows, previously formalized by Cohen and Gilboa, where the initial condition $\boldmath{\psi}_0$ admits the nonlinear eigenvalue problem $P(\boldsymbol{\psi}_0)=\lambda \boldsymbol{\psi}_0 $. We first present an analytic solution for dynamic mode decomposition (DMD) in such cases. We show an inherent flaw of DMD, which is unable to recover the essential dynamics of the flow. It is evident that DMD is best suited for homogeneous flows of degree one. We propose an adaptive time sampling scheme and show its dynamics are analogue to homogeneous flows of degree one with a fixed step size. Moreover, we adapt DMD to yield a real spectrum, using symmetric matrices. Our analytic solution of the proposed scheme recovers the dynamics perfectly and yields zero error. We then proceed to show the relation between the orthogonal modes ${\phi_i}$ and their decay profiles under the gradient flow. We formulate orthogonal nonlinear spectral decomposition (OrthoNS), which recovers the essential latent structures of the gradient descent process. Definitions for spectrum and filtering are given, and a Parseval-type identity is shown. Experimental results on images show the resemblance to direct computations of nonlinear spectral decomposition. A significant speedup (by about two orders of magnitude) is achieved for this application using the proposed method.},
  archive      = {J_SIIMS},
  author       = {Ido Cohen and Omri Azencot and Pavel Lifshits and Guy Gilboa},
  doi          = {10.1137/20M1388577},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {3},
  pages        = {913-945},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Modes of homogeneous gradient flows},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Variational densification and refinement of registration
maps. <em>SIIMS</em>, <em>14</em>(3), 879–912. (<a
href="https://doi.org/10.1137/20M1379113">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Local patch-based algorithms for image registration fail to accurately match points in areas not discriminative enough, mainly textureless regions. These methods normally involve a validation process and provide a non-completely dense solution. In this paper, we propose a novel refinement and completion approach for registration. The proposed model combines single image nonlocal densification with classical variational image registration. We associate a total variation regularization with a nonlocal term to provide a smooth solution leveraging the image geometry. We show experiments on public stereo and optical flow datasets to filter and densify incomplete depth maps and motion fields. Extensive comparisons against existing and state-of-the-art depth/motion fields densification approaches demonstrate the competitive performance of the introduced method. Additionally, we illustrate how our method can deal with other tasks, such as filtering and interpolation of depth maps from RGBD data and depth upsampling.},
  archive      = {J_SIIMS},
  author       = {Joan Duran and Julia Navarro and Antoni Buades},
  doi          = {10.1137/20M1379113},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {3},
  pages        = {879-912},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Variational densification and refinement of registration maps},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multiscale hierarchical image decomposition and refinements:
Qualitative and quantitative results. <em>SIIMS</em>, <em>14</em>(2),
844–877. (<a href="https://doi.org/10.1137/20M1369038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The multiscale hierarchical decomposition method (MHDM) proposed in [E. Tadmor, S. Nezzar, and L. Vese, Multiscale Model. Simul., 2 (2004), pp. 554--579] has been proven very appropriate for denoising images with features at different scales and for scale separation. Extensions of it to image deblurring or to time-dependent settings [E. Tadmor and P. Athavale, Inverse Probl. Imaging, 35 (2009), pp. 693--710] have also been considered, showing convergence properties and more applications. The recent paper [K. Modin, A. Nachman, and L. Rondi, Adv. Math., 346 (2019), pp. 1009--1066] fills in further qualitative results even for nonlinear problems and introduces a tighter version of MHDM with better convergence properties. The contribution of the present work is as follows. First, we derive novel error estimates for MHDM and its tighter version. Second, we provide rules for early stopping of the algorithms in the case of perturbed data, while still ensuring stable approximations of the true image. Last but not least, we propose a refined version of the tighter MHDM, which allows recovering structured images and promotes different features of the components, as compared to the entire image. The theoretical results are validated by numerous numerical experiments for image denoising and deblurring, which also assess the analyzed methods in terms of rate of convergence, stopping rule, and quality of restoration.},
  archive      = {J_SIIMS},
  author       = {Wen Li and Elena Resmerita and Luminita A. Vese},
  doi          = {10.1137/20M1369038},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {2},
  pages        = {844-877},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Multiscale hierarchical image decomposition and refinements: Qualitative and quantitative results},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Choose your path wisely: Gradient descent in a bregman
distance framework. <em>SIIMS</em>, <em>14</em>(2), 814–843. (<a
href="https://doi.org/10.1137/20M1357500">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose an extension of a special form of gradient descent---in the literature known as linearized Bregman iteration---to a larger class of nonconvex functions. We replace the classical (squared) two norm metric in the gradient descent setting with a generalized Bregman distance, based on a proper, convex, and lower semicontinuous function. The algorithm&#39;s global convergence is proven for functions that satisfy the Kurdyka--Łojasiewicz property. Examples illustrate that features of different scale are being introduced throughout the iteration, transitioning from coarse to fine. This coarse-to-fine approach with respect to scale allows us to recover solutions of nonconvex optimization problems that are superior to those obtained with conventional gradient descent, or even projected and proximal gradient descent. The effectiveness of the linearized Bregman iteration in combination with early stopping is illustrated for the applications of parallel magnetic resonance imaging, blind deconvolution, as well as image classification with neural networks.},
  archive      = {J_SIIMS},
  author       = {Martin Benning and Marta M. Betcke and Matthias J. Ehrhardt and Carola-Bibiane Schönlieb},
  doi          = {10.1137/20M1357500},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {2},
  pages        = {814-843},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Choose your path wisely: Gradient descent in a bregman distance framework},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Learning consistent discretizations of the total variation.
<em>SIIMS</em>, <em>14</em>(2), 778–813. (<a
href="https://doi.org/10.1137/20M1377199">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we study a general framework of discrete approximations of the total variation for image reconstruction problems. The framework, for which we can show consistency in the sense of $\Gamma$-convergence, unifies and extends several existing discretization schemes. In addition, we propose algorithms for learning discretizations of the total variation in order to achieve the best possible reconstruction quality for particular image reconstruction tasks. Interestingly, the learned discretizations significantly differ between the tasks, illustrating that there is no universal best discretization of the total variation.},
  archive      = {J_SIIMS},
  author       = {Antonin Chambolle and Thomas Pock},
  doi          = {10.1137/20M1377199},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {2},
  pages        = {778-813},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Learning consistent discretizations of the total variation},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Limited-angle CT reconstruction via the <span
class="math inline"><em>L</em><sub>1</sub>/<em>L</em><sub>2</sub></span>
minimization. <em>SIIMS</em>, <em>14</em>(2), 749–777. (<a
href="https://doi.org/10.1137/20M1341490">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we consider minimizing the $L_1/L_2$ term on the gradient for a limited-angle scanning problem in computed tomography (CT) reconstruction. We design a specific splitting framework for an unconstrained optimization model so that the alternating direction method of multipliers (ADMM) has guaranteed convergence under certain conditions. In addition, we incorporate a box constraint that is reasonable for imaging applications, and the convergence for the additional box constraint can also be established. Numerical results on both synthetic and experimental datasets demonstrate the effectiveness and efficiency of our proposed approach, showing significant improvements over the state-of-the-art methods in the limited-angle CT reconstruction.},
  archive      = {J_SIIMS},
  author       = {Chao Wang and Min Tao and James G. Nagy and Yifei Lou},
  doi          = {10.1137/20M1341490},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {2},
  pages        = {749-777},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Limited-angle CT reconstruction via the $L_1/L_2$ minimization},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A color elastica model for vector-valued image
regularization. <em>SIIMS</em>, <em>14</em>(2), 717–748. (<a
href="https://doi.org/10.1137/20M1354532">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Models related to the Euler&#39;s elastica energy have proven to be useful for many applications including image processing. Extending elastica models to color images and multichannel data is a challenging task, as stable and consistent numerical solvers for these geometric models often involve high order derivatives. Like the single channel Euler&#39;s elastica model and the total variation models, geometric measures that involve high order derivatives could help when considering image formation models that minimize elastic properties. In the past, the Polyakov action from high energy physics has been successfully applied to color image processing. Here, we introduce an addition to the Polyakov action for color images that minimizes the color manifold curvature. The color image curvature is computed by applying the Laplace--Beltrami operator to the color image channels. When reduced to gray-scale images, while selecting appropriate scaling between space and color, the proposed model minimizes Euler&#39;s elastica operating on the image level sets. Finding a minimizer for the proposed nonlinear geometric model is a challenge we address in this paper. Specifically, we present an operator-splitting method to minimize the proposed functional. The nonlinearity is decoupled by introducing three vector-valued and matrix-valued variables. The problem is then converted into solving for the steady state of an associated initial-value problem. The initial-value problem is time split into three fractional steps, such that each subproblem has a closed form solution, or can be solved by fast algorithms. The efficiency and robustness of the proposed method are demonstrated by systematic numerical experiments.},
  archive      = {J_SIIMS},
  author       = {Hao Liu and Xue-Cheng Tai and Ron Kimmel and Roland Glowinski},
  doi          = {10.1137/20M1354532},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {2},
  pages        = {717-748},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {A color elastica model for vector-valued image regularization},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Centering noisy images with application to cryo-EM.
<em>SIIMS</em>, <em>14</em>(2), 689–716. (<a
href="https://doi.org/10.1137/20M1365946">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We target the problem of estimating the center of mass of objects in noisy two-dimensional images. We assume that the noise dominates the image, and thus many standard approaches are vulnerable to estimation errors, e.g., the direct computation of the center of mass and the geometric median which is a robust alternative to the center of mass. In this paper, we define a novel surrogate function to the center of mass. We present a mathematical and numerical analysis of our method and show that it outperforms existing methods for estimating the center of mass of an object in various realistic scenarios. As a case study, we apply our centering method to data from single-particle cryo-electron microscopy (cryo-EM), where the goal is to reconstruct the three-dimensional structure of macromolecules. We show how to apply our approach for a better translational alignment of molecule images picked from experimental data. In this way, we facilitate the succeeding steps of reconstruction and streamline the entire cryo-EM pipeline, saving computational time and supporting resolution enhancement.},
  archive      = {J_SIIMS},
  author       = {Ayelet Heimowitz and Nir Sharon and Amit Singer},
  doi          = {10.1137/20M1365946},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {2},
  pages        = {689-716},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Centering noisy images with application to cryo-EM},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A class of second-order geometric quasilinear hyperbolic
PDEs and their application in imaging. <em>SIIMS</em>, <em>14</em>(2),
645–688. (<a href="https://doi.org/10.1137/20M1366277">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Motivated by important applications in image processing, we study a class of second-order geometric quasilinear hyperbolic partial differential equations (PDEs). This is inspired by the recent development of second-order damping systems associated to gradient flows for energy decaying. In numerical computations, it turns out that the second-order methods are superior to their first-order counter-parts. We concentrate on (i) a damped second-order total variation flow for, e.g., image denoising and (ii) a damped second-order mean curvature flow for level sets of scalar functions. The latter is connected to a nonconvex variational model capable of correcting displacement errors in image data (e.g., dejittering). For the former equation, we prove the existence and uniqueness of the solution and its long time behavior and provide an analytical solution given some simple initial datum. For the latter, we draw a connection between the equation and some second-order geometric PDEs evolving the hypersurfaces and show the existence and uniqueness of the solution for a regularized version of the equation. Finally, some numerical comparisons of the solution behavior for the new equations with first-order flows are presented.},
  archive      = {J_SIIMS},
  author       = {Guozhi Dong and Michael Hintermueller and Ye Zhang},
  doi          = {10.1137/20M1366277},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {2},
  pages        = {645-688},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {A class of second-order geometric quasilinear hyperbolic PDEs and their application in imaging},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Recovering missing data in coherent diffraction imaging.
<em>SIIMS</em>, <em>14</em>(2), 620–644. (<a
href="https://doi.org/10.1137/20M134767X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In coherent diffraction imaging (CDI) experiments, the intensity of the scattered wave impinging on an object is measured on an array of detectors. These measurements can be interpreted as samples of the square of the modulus of the Fourier transform of the unknown scattering density. A beamstop obstructs the forward scattered wave and, hence, the modulus Fourier data from a neighborhood of $k=0$ cannot be measured. In this note, we describe a linear method for recovering this unmeasured modulus Fourier data from the measured values and an estimate of the support of the image&#39;s autocorrelation function without consideration of phase retrieval. We analyze the effects of noise, and the conditioning of this problem, which grows exponentially with the modulus of the maximum spatial frequency not measured.},
  archive      = {J_SIIMS},
  author       = {David A. Barmherzig and Alex H. Barnett and Charles L. Epstein and Leslie F. Greengard and Jeremy F. Magland and Manas Rachh},
  doi          = {10.1137/20M134767X},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {2},
  pages        = {620-644},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Recovering missing data in coherent diffraction imaging},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Recovery of surfaces and functions in high dimensions:
Sampling theory and links to neural networks. <em>SIIMS</em>,
<em>14</em>(2), 580–619. (<a
href="https://doi.org/10.1137/20M1340654">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Several imaging algorithms including patch-based image denoising, image time series recovery, and convolutional neural networks can be thought of as methods that exploit the manifold structure of signals. While the empirical performance of these algorithms is impressive, the understanding of recovery of the signals and functions that live on the manifold is less understood. In this paper, we focus on the recovery of signals that live on a union of surfaces. In particular, we consider signals living on a union of smooth band-limited surfaces in high dimensions. We show that an exponential mapping transforms the data to a union of low-dimensional subspaces. Using this relation, we introduce a sampling theoretical framework for the recovery of smooth surfaces from few samples and the learning of functions living on smooth surfaces. The low-rank property of the features is used to determine the number of measurements needed to recover the surface. Moreover, the low-rank property of the features also provides an efficient approach, which resembles a neural network, for the local representation of multidimensional functions on the surface. The direct representation of such a function in high dimensions often suffers from the curse of dimensionality; the large number of parameters would translate to the need for extensive training data. The low-rank property of the features can significantly reduce the number of parameters, which makes the computational structure attractive for learning and inference from limited labeled training data.},
  archive      = {J_SIIMS},
  author       = {Qing Zou and Mathews Jacob},
  doi          = {10.1137/20M1340654},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {2},
  pages        = {580-619},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Recovery of surfaces and functions in high dimensions: Sampling theory and links to neural networks},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multiscale factorization of the wave equation with
application to compressed sensing photoacoustic tomography.
<em>SIIMS</em>, <em>14</em>(2), 558–579. (<a
href="https://doi.org/10.1137/20M1356154">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Performing a large number of spatial measurements enables high-resolution photoacoustic imaging without specific prior information. However, the acquisition of spatial measurements is time-consuming, costly, and technically challenging. By exploiting nonlinear prior information, compressed sensing techniques in combination with sophisticated reconstruction algorithms allow reducing the number of measurements while maintaining high spatial resolution. To this end, in this work we propose a multiscale factorization for the wave equation that decomposes the measured data into a low-frequency factor and sparse high-frequency factors. By extending the acoustic reciprocity principle, we transfer sparsity in the measurement domain into spatial sparsity of the initial pressure, which allows the use of sparse reconstruction techniques. Numerical results are presented that demonstrate the feasibility of the proposed framework.},
  archive      = {J_SIIMS},
  author       = {Gerhard Zangerl and Markus Haltmeier},
  doi          = {10.1137/20M1356154},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {2},
  pages        = {558-579},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Multiscale factorization of the wave equation with application to compressed sensing photoacoustic tomography},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). New restricted isometry property analysis for <span
class="math inline"><em>ℓ</em><sub>1</sub> − <em>ℓ</em><sub>2</sub></span>
minimization methods. <em>SIIMS</em>, <em>14</em>(2), 530–557. (<a
href="https://doi.org/10.1137/20M136517X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The $\ell_1-\ell_2$ regularization is a popular nonconvex yet Lipschitz continuous metric, which has been widely used in signal and image processing. The theory for the $\ell_1-\ell_2$ minimization method shows that it has superior sparse recovery performance over the classical $\ell_1$ minimization method. The motivation and major contribution of this paper is to provide a positive answer to the open problem posed in [T.-H. Ma, Y. Lou, and T.-Z. Huang, SIAM J. Imaging Sci., 10 (2017), pp. 1346--1380] about the sufficient conditions that can be sharpened for the $\ell_1-\ell_2$ minimization method. The novel technique used in our analysis of the $\ell_1-\ell_2$ minimization method is a crucial sparse representation adapted to the $\ell_1-\ell_2$ metric which is different from the other state-of-the-art works in the context of the $\ell_1-\ell_2$ minimization method. The new restricted isometry property (RIP) analysis is better than the existing RIP based conditions to guarantee the exact and stable recovery of signals.},
  archive      = {J_SIIMS},
  author       = {Huanmin Ge and Wengu Chen and Michael K. Ng},
  doi          = {10.1137/20M136517X},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {2},
  pages        = {530-557},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {New restricted isometry property analysis for $\ell_1-\ell_2$ minimization methods},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). On the asymptotic equivalence between the radon and the
hough transforms of digital images. <em>SIIMS</em>, <em>14</em>(2),
506–529. (<a href="https://doi.org/10.1137/20M1344159">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although characterized by two different mathematical definitions, both the Radon and the Hough transforms ultimately take an image as input and provide, as output, functions defined on a preassigned parameter space, i.e., the so-called Radon and Hough sinograms, respectively. The parameters in these two spaces describe a family of curves, which represent either the integration domains considered in the Radon transform, or the kind of curves to be detected by the Hough transform. It is heuristically known that the Hough sinogram converges to the corresponding Radon sinogram when the discretization step in the parameter space tends to zero. However, as far as we know, no formal result has been proven so far about such convergence. Therefore, by considering generalized functions in a multidimensional setting, in this paper we give an analytical proof of this heuristic rationale when the input digital image is described as a set of grayscale points, that is, as a sum of weighted Dirac delta functions. On these grounds, we also show that this asymptotic equivalence may lead to a visualization process relying on the interpretation of the Radon sinogram as a Hough sinogram.},
  archive      = {J_SIIMS},
  author       = {Riccardo Aramini and Fabrice Delbary and Mauro C. Beltrametti and Claudio Estatico and Michele Piana and Anna Maria Massone},
  doi          = {10.1137/20M1344159},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {2},
  pages        = {506-529},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {On the asymptotic equivalence between the radon and the hough transforms of digital images},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Deep neural networks for inverse problems with
pseudodifferential operators: An application to limited-angle
tomography. <em>SIIMS</em>, <em>14</em>(2), 470–505. (<a
href="https://doi.org/10.1137/20M1343075">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a novel convolutional neural network (CNN), called $\Psi$DONet, designed for learning pseudodifferential operators ($\Psi$DOs) in the context of linear inverse problems. Our starting point is the iterative soft thresholding algorithm (ISTA), a well-known algorithm to solve sparsity-promoting minimization problems. We show that, under rather general assumptions on the forward operator, the unfolded iterations of ISTA can be interpreted as the successive layers of a CNN, which in turn provides fairly general network architectures that, for a specific choice of the parameters involved, allow us to reproduce ISTA, or a perturbation of ISTA for which we can bound the coefficients of the filters. Our case study is the limited-angle X-ray transform and its application to limited-angle computed tomography (LA-CT). In particular, we prove that, in the case of LA-CT, the operations of upscaling, downscaling, and convolution, which characterize our $\Psi$DONet and most deep learning schemes, can be exactly determined by combining the convolutional nature of the limited-angle X-ray transform and basic properties defining an orthogonal wavelet system. We test two different implementations of $\Psi$DONet on simulated data from limited-angle geometry, generated from the ellipse data set. Both implementations provide equally good and noteworthy preliminary results, showing the potential of the approach we propose and paving the way to applying the same idea to other convolutional operators which are $\Psi$DOs or Fourier integral operators.},
  archive      = {J_SIIMS},
  author       = {Tatiana A. Bubba and Mathilde Galinier and Matti Lassas and Marco Prato and Luca Ratti and Samuli Siltanen},
  doi          = {10.1137/20M1343075},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {2},
  pages        = {470-505},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Deep neural networks for inverse problems with pseudodifferential operators: An application to limited-angle tomography},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A variational model for spatially weighting in image fusion.
<em>SIIMS</em>, <em>14</em>(2), 441–469. (<a
href="https://doi.org/10.1137/20M1334103">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to retain as many valuable details from the input source images as possible during the process of fusion, this paper proposes an adaptive weight based total variation model for image fusion. The main idea is to employ a nonconvex energy functional to determine simultaneously the output fused image and weight functions by maximizing the local variance of the output image and preserving the brightness of the input images. In order to minimize the differences among the weight functions at the nearby pixel locations, the total variation regularization of the weight functions is incorporated in the functional for the fusion process. The existence of minimizers to the proposed variational model is established. Furthermore, we develop an efficient algorithm to solve the model numerically by using the primal-dual method, and prove the convergence of the algorithm. Experimental results are reported to illustrate the effectiveness of the proposed method, and its performance is competitive with the other testing methods.},
  archive      = {J_SIIMS},
  author       = {Zhengmeng Jin and Junkang Zhang and Lihua Min and Michael K. Ng},
  doi          = {10.1137/20M1334103},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {2},
  pages        = {441-469},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {A variational model for spatially weighting in image fusion},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A regularized affine-scaling trust-region method for
parametric imaging of dynamic PET data. <em>SIIMS</em>, <em>14</em>(1),
418–439. (<a href="https://doi.org/10.1137/20M1336370">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Parametric imaging of nuclear medicine data exploits dynamic functional images in order to reconstruct maps of kinetic parameters related to the metabolism of a specific tracer injected in the biological tissue. Classical approaches to parametric imaging rely on linearized schemes that, on the one hand, are computationally effective but, on the other hand, provide information just on a very limited number of parameters (typically two). Possible nonlinearized approaches require the pixelwise numerical solution of compartmental nonlinear ill-posed inverse problems and therefore typically imply a notable computational burden. In the present paper we introduce a fast numerical optimization scheme for parametric imaging relying on a regularized version of the standard affine-scaling trust-region method. The main advantages of this approach are both that it is a regularization method (and therefore it reduces the numerical instabilities in the reconstructed images) and that it is significantly faster than other algorithms in the optimization market (and therefore it may be utilized for clinical applications). The validation of this approach is realized in a simulation framework for brain imaging and also in the case of an experimental set of nuclear medicine data acquired from a murine model. Comparison of performances is made with respect to a regularized Gauss--Newton scheme and a standard nonlinear bound-constrained least-squares algorithm.},
  archive      = {J_SIIMS},
  author       = {S. Crisci and M. Piana and V. Ruggiero and M. Scussolini},
  doi          = {10.1137/20M1336370},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {1},
  pages        = {418-439},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {A regularized affine-scaling trust-region method for parametric imaging of dynamic PET data},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A penalty relaxation method for image processing using
euler’s elastica model. <em>SIIMS</em>, <em>14</em>(1), 389–417. (<a
href="https://doi.org/10.1137/20M1335601">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Euler&#39;s elastica model has been widely used in image processing. Since it is a challenging nonconvex and nonsmooth optimization model, most existing algorithms do not have convergence theory for it. In this paper, we propose a penalty relaxation algorithm with mathematical guarantee to find a stationary point of Euler&#39;s elastica model. To deal with the nonsmoothness of Euler&#39;s elastica model, we first introduce a smoothing relaxation problem, and then propose an exact penalty method to solve it. We establish the relationships between Euler&#39;s elastica model, the smoothing relaxation problem, and the penalty problem in theory regarding optimal solutions and stationary points. Moreover, we propose an efficient block coordinate descent algorithm to solve the penalty problem by taking advantage of convexity of its subproblems. We prove global convergence of the algorithm to a stationary point of the penalty problem. Finally we apply the proposed algorithm to denoise the optical coherence tomography images with real data from an optometry clinic and show the efficiency of the method for image processing using Euler&#39;s elastica model.},
  archive      = {J_SIIMS},
  author       = {Fang He and Xiao Wang and Xiaojun Chen},
  doi          = {10.1137/20M1335601},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {1},
  pages        = {389-417},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {A penalty relaxation method for image processing using euler&#39;s elastica model},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A coherent framework for learning spatiotemporal
piecewise-geodesic trajectories from longitudinal manifold-valued data.
<em>SIIMS</em>, <em>14</em>(1), 349–388. (<a
href="https://doi.org/10.1137/20M1328026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper provides a coherent framework for studying longitudinal manifold-valued data for which the dynamic changes over time. We introduce a Bayesian mixed-effects model that allows estimating both a group-representative piecewise-geodesic trajectory in the Riemannian space of shape and interindividual variability. We prove the existence of the maximum a posteriori estimate and its asymptotic consistency under reasonable assumptions. Due to the nonlinearity of the proposed model, we use a stochastic version of the expectation-maximization algorithm to estimate the model parameters. Our simulations show that our model is not noise-sensitive and succeeds in explaining various paths of progression.},
  archive      = {J_SIIMS},
  author       = {Juliette Chevallier and Vianney Debavelaere and Stéphanie Allassonnière},
  doi          = {10.1137/20M1328026},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {1},
  pages        = {349-388},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {A coherent framework for learning spatiotemporal piecewise-geodesic trajectories from longitudinal manifold-valued data},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Determinantal point processes for image processing.
<em>SIIMS</em>, <em>14</em>(1), 304–348. (<a
href="https://doi.org/10.1137/20M1327306">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Determinantal point processes (DPPs) are probabilistic models of configurations that favor diversity or repulsion. They have recently gained influence in the machine learning community, mainly because of their ability to elegantly and efficiently subsample large sets of data. In this paper, we consider DPPs from an image processing perspective, meaning that the data we want to subsample are pixels or patches of a given image. To this end, our framework is discrete and finite. First, we adapt their basic definition and properties to DPPs defined on the pixels of an image, that we call determinantal pixel processes (DPixPs). We are mainly interested in the repulsion properties of such a process and we apply DPixPs to texture synthesis using shot noise models. Finally, we study DPPs on the set of patches of an image. Because of their repulsive property, DPPs provide a strong tool to subsample discrete distributions such as that of image patches.},
  archive      = {J_SIIMS},
  author       = {Claire Launay and Agnès Desolneux and Bruno Galerne},
  doi          = {10.1137/20M1327306},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {1},
  pages        = {304-348},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Determinantal point processes for image processing},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Correlation based imaging for rotating satellites.
<em>SIIMS</em>, <em>14</em>(1), 271–303. (<a
href="https://doi.org/10.1137/20M1357469">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider imaging of fast moving small objects in space, such as low Earth orbit satellites, which are also rotating around a fixed axis. The imaging system consists of ground based, asynchronous sources of radiation and several passive receivers above the dense atmosphere. We use the cross-correlation of the received signals to reduce distortions from ambient medium fluctuations. Imaging with correlations also has the advantage of not requiring any knowledge about the probing pulse, and it depends weakly on the emitter positions. We account for the target&#39;s orbital velocity by introducing the necessary Doppler compensation. In particular, we show that over limited imaging regions, a constant Doppler factor can be used, resulting in an efficient data structure for the correlations of the recorded signals. To image a fast rotating object we also need to compensate for the rotation. We show that the rotation parameters can be extracted directly from the autocorrelation of the data before the formation of the image. We then investigate and analyze an imaging method that relies on backpropagating the cross-correlation data structure to two points rather than one and thus forms an interference matrix. The proposed imaging method consists of estimating the reflectivity as the top eigenvector of the migrated cross-correlation data interference matrix. We call this the rank-1 image and show that it provides superior image resolution compared to the usual single-point migration scheme for fast moving and rotating objects. Moreover, we observe a significant improvement in resolution due to the rotation leading to a diffraction limited resolution. We carry out a theoretical analysis that illustrates the role of the two-point migration method as well as that of the inverse aperture and rotation in improving resolution. Extensive numerical simulations support the theoretical results.},
  archive      = {J_SIIMS},
  author       = {Matan Leibovich and George Papanicolaou and Chrysoula Tsogka},
  doi          = {10.1137/20M1357469},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {1},
  pages        = {271-303},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Correlation based imaging for rotating satellites},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Towards statistically provable geometric 3D human pose
recovery. <em>SIIMS</em>, <em>14</em>(1), 246–270. (<a
href="https://doi.org/10.1137/19M1299955">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recovering three-dimensional (3D) structures such as object poses from limited two-dimensional (2D) information is an important research problem in computer vision, graphics, and robotics. The estimation of object pose from single images or multiple casual images could be ill-conditioned math problems. There is a popular family of algorithms of geometric sparse representation for 3D pose recovery (GSR-3D) that pretrains an overcomplete dictionary of 3D basis poses $B$, and then matches the detected 2D object pose $Y$ by jointly estimating the transformation $R$, projection $\Pi,$ and combination coefficients $c$, assuming $Y \approx \Pi \sum_i c_i R B_i$. In this paper, we make the first step of analyzing to which extent could we solve this ill-conditioned problem, and of understanding how the recovery error is affected by fundamental factors, e.g., dictionary size, observation noise, and running time. As these factors are implicit in objective functions, we analyze with the help of various sparse regularizers and a multistage optimizer, and prove that the recovery error $\mathcal L(l)$ decays w.r.t. the number of stages $l$ with a high probability, $Prob\left(\mathcal L(l) &lt; \rho^{l-1} \mathcal L(0) + \delta \right) \geq 1- \epsilon$, where the constants $0&lt; \rho &lt;1, 0&lt;\delta, 0&lt;\epsilon \ll 1$ are related to the aforementioned factors. To the best of our knowledge, this is the first theoretical analysis in this line of research. Experiments are conducted to support our improvement upon previous regularization within the same framework. This will further characterize the trade-off between speed and accuracy towards real-time geometric inference in applications.},
  archive      = {J_SIIMS},
  author       = {Jianqiao Wangni and Dahua Lin and Ji Liu and Kostas Daniilidis and Jianbo Shi},
  doi          = {10.1137/19M1299955},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {1},
  pages        = {246-270},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Towards statistically provable geometric 3D human pose recovery},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Fast imaging of sources and scatterers in a stratified ocean
waveguide. <em>SIIMS</em>, <em>14</em>(1), 224–245. (<a
href="https://doi.org/10.1137/20M1361997">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we have studied the asymptotic behavior of Green&#39;s function and the reciprocity relation of the far-field pattern in the stratified ocean waveguide. Moreover, two direct sampling methods (DSM) are proposed to determine the marine sources and scatterers from the far-field data. The direct approaches are fast, easy to implement, and computationally efficient since they involve only scalar product but no matrix inversion. In the numerical simulations, the DSM for the source is capable of identifying the sources from very few observation data, and the DSM for the scatterer can reconstruct the scatterers in different shapes, scales, types, and positions. The effectiveness and robustness of the novel methods are also demonstrated. Thus, the DSM can be viewed as simple and efficient numerical techniques for providing reliable initial approximate locations of the marine sources and scatterers for any existing more refined and advanced but computationally more demanding algorithms to recover the accurate physical profiles.},
  archive      = {J_SIIMS},
  author       = {Keji Liu},
  doi          = {10.1137/20M1361997},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {1},
  pages        = {224-245},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Fast imaging of sources and scatterers in a stratified ocean waveguide},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Patch-based holographic image sensing. <em>SIIMS</em>,
<em>14</em>(1), 198–223. (<a
href="https://doi.org/10.1137/20M1324041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Holographic representations of data enable distributed storage with progressive refinement when the stored packets of data are made available in any arbitrary order. In this paper, we propose and test patch-based transform coding holographic sensing of image data. Our proposal is optimized for progressive recovery under random order of retrieval of the stored data. The coding of the image patches relies on the design of distributed projections ensuring best image recovery, in terms of the $\ell_2$ norm, at each retrieval stage. The performance depends only on the number of data packets that have been retrieved thus far. Several possible options to enhance the quality of the recovery while changing the size and number of data packets are discussed and tested. This leads us to examine several interesting bit-allocation and rate-distortion trade-offs, highlighted for a set of natural images with ensemble estimated statistical properties.},
  archive      = {J_SIIMS},
  author       = {Alfred Marcel Bruckstein and Martianus Frederic Ezerman and Adamas Aqsa Fahreza and San Ling},
  doi          = {10.1137/20M1324041},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {1},
  pages        = {198-223},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Patch-based holographic image sensing},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Color image restoration by saturation-value total variation
regularization on vector bundles. <em>SIIMS</em>, <em>14</em>(1),
178–197. (<a href="https://doi.org/10.1137/20M1347991">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Color image restoration is one of the important tasks in color image processing. Covariant differentiation has been applied to handle vector bundles arising from color images in the red, green, blue (RGB) color space. However, there are strong correlations among these three channels, and color image regularization in RGB color space may not be effective enough. The main aim of this paper is to study vector bundles of color images in saturation-value color space and to develop color image regularization models based on vector bundles in saturation-value color space. We develop the saturation-value metric of a vector bundle of $\mathbb{R}^5$-valued functions, and we generalize the vectorial total variation and the vector bundle-valued total variation in saturation-value color space based on the saturation-value metric via the transformation between RGB color space and saturation-value color space. We then develop a saturation-value total variation regularization on vector bundles. We study color image restoration models by using such total variation, and show numerical examples that the proposed color image restoration model outperforms existing methods in terms of visual quality, peak signal-to-noise ratio, and structural similarity.},
  archive      = {J_SIIMS},
  author       = {Wei Wang and Michael K. Ng},
  doi          = {10.1137/20M1347991},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {1},
  pages        = {178-197},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Color image restoration by saturation-value total variation regularization on vector bundles},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Compressive sampling for array cameras. <em>SIIMS</em>,
<em>14</em>(1), 156–177. (<a
href="https://doi.org/10.1137/19M1283914">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While design of high-performance lenses and image sensors has long been the focus of camera development, the size, weight, and power of image data processing components are currently the primary barriers to radical improvements in camera resolution. Here we show that deep learning--aided compressive sampling can reduce operating power on camera head electronics by 20 times or more. Traditional compressive sampling has to date been primarily applied in the physical sensor layer. We show here that with the aid of deep learning algorithms, compressive sampling is offers unique power management advantages in digital layer compression.},
  archive      = {J_SIIMS},
  author       = {Xuefei Yan and David J. Brady and Weiping Zhang and Changzhi Yu and Yulin Jiang and Jianqiang Wang and Chao Huang and Zian Li and Zhan Ma},
  doi          = {10.1137/19M1283914},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {1},
  pages        = {156-177},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Compressive sampling for array cameras},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Strong solutions for PDE-based tomography by unsupervised
learning. <em>SIIMS</em>, <em>14</em>(1), 128–155. (<a
href="https://doi.org/10.1137/20M1332827">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce a novel neural network-based PDEs solver for forward and inverse problems. The solver is grid free, mesh free, and shape free, and the solution is approximated by a neural network. We employ an unsupervised approach such that the input to the network is a point set in an arbitrary domain, and the output is the set of the corresponding function values. The network is trained to minimize deviations of the learned function from the PDE solution and satisfy the boundary conditions. The resulting solution in turn is an explicit, smooth, differentiable function with a known analytical form. We solve the forward problem (observations given the underlying model&#39;s parameters), semi-inverse problem (model&#39;s parameters given the observations in the whole domain), and full tomography inverse problem (model&#39;s parameters given the observations on the boundary) by solving the forward and semi-inverse problems at the same time. The optimized loss function consists of few elements: fidelity term of $L_2$ norm that enforces the PDE in the weak sense, an $L_\infty$ norm term that enforces pointwise fidelity and thus promotes a strong solution, and boundary and initial conditions constraints. It further accommodates regularizers for the solution and/or the model&#39;s parameters of the differential operator. This setting is flexible in the sense that regularizers can be tailored to specific problems. We demonstrate our method on several free shape two dimensional (2D) second order systems with application to electrical impedance tomography (EIT) and diffusion equation. Unlike other numerical methods such as finite differences and finite elements, the derivatives of the desired function can be analytically calculated to any order. This framework enables, in principle, the solution of high order and high dimensional nonlinear PDEs.},
  archive      = {J_SIIMS},
  author       = {Leah Bar and Nir Sochen},
  doi          = {10.1137/20M1332827},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {1},
  pages        = {128-155},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Strong solutions for PDE-based tomography by unsupervised learning},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). On learned operator correction in inverse problems.
<em>SIIMS</em>, <em>14</em>(1), 92–127. (<a
href="https://doi.org/10.1137/20M1338460">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We discuss the possibility of learning a data-driven explicit model correction for inverse problems and whether such a model correction can be used within a variational framework to obtain regularized reconstructions. This paper discusses the conceptual difficulty of learning such a forward model correction and proceeds to present a possible solution as a forward-adjoint correction that explicitly corrects in both data and solution spaces. We then derive conditions under which solutions to the variational problem with a learned correction converge to solutions obtained with the correct operator. The proposed approach is evaluated on an application to limited view photoacoustic tomography and compared to the established framework of the Bayesian approximation error method.},
  archive      = {J_SIIMS},
  author       = {Sebastian Lunz and Andreas Hauptmann and Tanja Tarvainen and Carola-Bibiane Schönlieb and Simon Arridge},
  doi          = {10.1137/20M1338460},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {1},
  pages        = {92-127},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {On learned operator correction in inverse problems},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Complex-valued imaging with total variation regularization:
An application to full-waveform inversion in visco-acoustic media.
<em>SIIMS</em>, <em>14</em>(1), 58–91. (<a
href="https://doi.org/10.1137/20M1344780">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Full-waveform inversion (FWI) is a nonlinear PDE constrained optimization problem which seeks to estimate the constitutive parameters of a medium by fitting waveforms. Among these parameters, attenuation needs to be taken into account in viscous media to exploit the full potential of FWI. Attenuation is easily implemented in the frequency domain by using complex-valued velocities in the time-harmonic wave equation. These complex velocities are frequency-dependent to guarantee causality and account for dispersion. Since estimating a complex frequency-dependent velocity at each grid point in space is not realistic, the optimization is generally performed in the real domain by processing the phase velocity (or slowness) at a reference frequency and attenuation (or quality factor) as separate real parameters. This real parametrization requires an a priori empirical relation (such as the nonlinear Kolsky--Futterman (KF) or standard linear solid (SLS) attenuation models) between the complex velocity and the two real quantities, which is prone to generate modeling errors if it does not represent accurately the attenuation behavior of the medium. Moreover, it leads to a multivariate inverse problem, which is ill-posed due to the cross-talk between the two classes of real parameters. To alleviate these issues, we solve directly the optimization problem in the complex domain by processing narrow bands of frequencies in sequence under the assumption of bandwise frequency dependence of the complex velocities. Moreover, we use a relaxation method to extend the FWI search space by processing the wave equation as a weak constraint with the alternating direction method of multipliers (ADMM) to mitigate the risk of spurious local minima. To mitigate the ill-posedness of the inversion, three total variation (TV) regularization schemes based upon ADMM and proximity algorithms are presented. In the first, regularization is applied directly on the complex velocities. In the other two, separate TV regularizations are tailored to different attributes of the complex velocities (real and imaginary parts, magnitude and phase). The real phase velocity and attenuation factor are then reconstructed a posteriori at each spatial position from the estimated complex velocity using arbitrary empirical relation. The numerical results first show that the regularization of the amplitude and phase provides the most reliable results. Moreover, they show that the band-by-band design of the inversion limits the sensitivity of the recovered phase velocity and attenuation factor to the attenuation model used for their a posteriori extraction.},
  archive      = {J_SIIMS},
  author       = {Hossein S. Aghamiry and Ali Gholami and Stéphane Operto},
  doi          = {10.1137/20M1344780},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {1},
  pages        = {58-91},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Complex-valued imaging with total variation regularization: An application to full-waveform inversion in visco-acoustic media},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-scale classification for electrosensing.
<em>SIIMS</em>, <em>14</em>(1), 26–57. (<a
href="https://doi.org/10.1137/20M1344317">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a premier and innovative (real-time) multi-scale method for target classification in electrosensing. The intent is that of mimicking the behavior of the weakly electric fish, which is able to retrieve much more information about the target by approaching it. The method is based on a family of transform-invariant shape descriptors computed from generalized polarization tensors (GPTs) reconstructed at multiple scales. The evidence provided by the different descriptors at each scale is fused using Dempster--Shafer theory. Numerical simulations show that the recognition algorithm we propose performs undoubtedly well and yields a robust classification.},
  archive      = {J_SIIMS},
  author       = {Lorenzo Baldassari and Andrea Scapin},
  doi          = {10.1137/20M1344317},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {1},
  pages        = {26-57},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Multi-scale classification for electrosensing},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Group sparse optimization for images recovery using capped
folded concave functions. <em>SIIMS</em>, <em>14</em>(1), 1–25. (<a
href="https://doi.org/10.1137/19M1304799">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper considers the image recovery problem by taking group sparsity into account as the prior knowledge. This problem is formulated as a group sparse optimization over the intersection of a polyhedron and a possibly degenerate ellipsoid. It is a convexly constrained optimization problem with a group cardinality objective function. We use a capped folded concave function to approximate the group cardinality function and show that the solution set of the continuous approximation problem and the set of group sparse solutions are the same. Moreover, we use a penalty method to replace the constraints in the approximation problem by adding a convex nonsmooth penalty function in the objective function. We show the existence of positive penalty parameters such that the solution sets of the unconstrained penalty problem and the group sparse problem are the same. We propose a smoothing penalty algorithm and show that any accumulation point of the sequence generated by the algorithm is a directional stationary point of the continuous approximation problem. Numerical experiments for recovery of group sparse image are presented to illustrate the efficiency of the smoothing penalty algorithm with adaptive capped folded concave functions.},
  archive      = {J_SIIMS},
  author       = {Lili Pan and Xiaojun Chen},
  doi          = {10.1137/19M1304799},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {1},
  pages        = {1-25},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Group sparse optimization for images recovery using capped folded concave functions},
  volume       = {14},
  year         = {2021},
}
</textarea>
</details></li>
</ul>

</body>
</html>
