<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>ECJ_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="ecj---19">ECJ - 19</h2>
<ul>
<li><details>
<summary>
(2021). The univariate marginal distribution algorithm copes well
with deception and epistasis. <em>ECJ</em>, <em>29</em>(4), 543–563. (<a
href="https://doi.org/10.1162/evco_a_00293">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In their recent work, Lehre and Nguyen ( 2019 ) show that the univariate marginal distribution algorithm (UMDA) needs time exponential in the parent populations size to optimize the DeceptiveLeadingBlocks ( DLB ) problem. They conclude from this result that univariate EDAs have difficulties with deception and epistasis. In this work, we show that this negative finding is caused by the choice of the parameters of the UMDA. When the population sizes are chosen large enough to prevent genetic drift, then the UMDA optimizes the DLB problem with high probability with at most λ ( n 2 + 2 e ln n ) fitness evaluations. Since an offspring population size λ of order n log n can prevent genetic drift, the UMDA can solve the DLB problem with O ( n 2 log n ) fitness evaluations. In contrast, for classic evolutionary algorithms no better runtime guarantee than O ( n 3 ) is known (which we prove to be tight for the ( 1 + 1 ) EA), so our result rather suggests that the UMDA can cope well with deception and epistatis. From a broader perspective, our result shows that the UMDA can cope better with local optima than many classic evolutionary algorithms; such a result was previously known only for the compact genetic algorithm. Together with the lower bound of Lehre and Nguyen, our result for the first time rigorously proves that running EDAs in the regime with genetic drift can lead to drastic performance losses.},
  archive      = {J_ECJ},
  author       = {Doerr, Benjamin and Krejca, Martin S.},
  doi          = {10.1162/evco_a_00293},
  journal      = {Evolutionary Computation},
  number       = {4},
  pages        = {543-563},
  shortjournal = {Evol. Comput.},
  title        = {The univariate marginal distribution algorithm copes well with deception and epistasis},
  volume       = {29},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Maximizing drift is not optimal for solving OneMax.
<em>ECJ</em>, <em>29</em>(4), 521–541. (<a
href="https://doi.org/10.1162/evco_a_00290">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It seems very intuitive that for the maximization of the OneMax problem O m ( x ) : = ∑ i = 1 n x i the best that an elitist unary unbiased search algorithm can do is to store a best so far solution, and to modify it with the operator that yields the best possible expected progress in function value. This assumption has been implicitly used in several empirical works. In Doerr et al. (2020), it was formally proven that this approach is indeed almost optimal. In this work, we prove that drift maximization is not optimal. More precisely, we show that for most fitness levels between n / 2 and 2 n / 3 the optimal mutation strengths are larger than the drift-maximizing ones. This implies that the optimal RLS is more risk-affine than the variant maximizing the stepwise expected progress. We show similar results for the mutation rates of the classic (1 + 1) Evolutionary Algorithm (EA) and its resampling variant, the (1 + 1) EA &gt; 0 ⁠ . As a result of independent interest we show that the optimal mutation strengths, unlike the drift-maximizing ones, can be even.},
  archive      = {J_ECJ},
  author       = {Buskulic, Nathan and Doerr, Carola},
  doi          = {10.1162/evco_a_00290},
  journal      = {Evolutionary Computation},
  number       = {4},
  pages        = {521-541},
  shortjournal = {Evol. Comput.},
  title        = {Maximizing drift is not optimal for solving OneMax},
  volume       = {29},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A self-adaptive response strategy for dynamic multiobjective
evolutionary optimization based on objective space decomposition.
<em>ECJ</em>, <em>29</em>(4), 491–519. (<a
href="https://doi.org/10.1162/evco_a_00289">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic multiobjective optimization deals with simultaneous optimization of multiple conflicting objectives that change over time. Several response strategies for dynamic optimization have been proposed, which do not work well for all types of environmental changes. In this article, we propose a new dynamic multiobjective evolutionary algorithm based on objective space decomposition, in which the maxi-min fitness function is adopted for selection and a self-adaptive response strategy integrating a number of different response strategies is designed to handle unknown environmental changes. The self-adaptive response strategy can adaptively select one of the strategies according to their contributions to the tracking performance in the previous environments. Experimental results indicate that the proposed algorithm is competitive and promising for solving different DMOPs in the presence of unknown environmental changes. Meanwhile, the proposed algorithm is applied to solve the parameter tuning problem of a proportional integral derivative (PID) controller of a dynamic system, obtaining better control effect.},
  archive      = {J_ECJ},
  author       = {Liu, Ruochen and Li, Jianxia and Jin, Yaochu and Jiao, Licheng},
  doi          = {10.1162/evco_a_00289},
  journal      = {Evolutionary Computation},
  number       = {4},
  pages        = {491-519},
  shortjournal = {Evol. Comput.},
  title        = {A self-adaptive response strategy for dynamic multiobjective evolutionary optimization based on objective space decomposition},
  volume       = {29},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multiobjective evolutionary algorithms are still good:
Maximizing monotone approximately submodular minus modular functions.
<em>ECJ</em>, <em>29</em>(4), 463–490. (<a
href="https://doi.org/10.1162/evco_a_00288">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As evolutionary algorithms (EAs) are general-purpose optimization algorithms, recent theoretical studies have tried to analyze their performance for solving general problem classes, with the goal of providing a general theoretical explanation of the behavior of EAs. Particularly, a simple multiobjective EA, that is, GSEMO, has been shown to be able to achieve good polynomial-time approximation guarantees for submodular optimization, where the objective function is only required to satisfy some properties and its explicit formulation is not needed. Submodular optimization has wide applications in diverse areas, and previous studies have considered the cases where the objective functions are monotone submodular, monotone non-submodular, or non-monotone submodular. To complement this line of research, this article studies the problem class of maximizing monotone approximately submodular minus modular functions (i.e., g - c ⁠ ) with a size constraint, where g is a so-called non-negative monotone approximately submodular function and c is a so-called non-negative modular function, resulting in the objective function ( g - c ) being non-monotone non-submodular in general. Different from previous analyses, we prove that by optimizing the original objective function ( g - c ) and the size simultaneously, the GSEMO fails to achieve a good polynomial-time approximation guarantee. However, we also prove that by optimizing a distorted objective function and the size simultaneously, the GSEMO can still achieve the best-known polynomial-time approximation guarantee. Empirical studies on the applications of Bayesian experimental design and directed vertex cover show the excellent performance of the GSEMO.},
  archive      = {J_ECJ},
  author       = {Qian, Chao},
  doi          = {10.1162/evco_a_00288},
  journal      = {Evolutionary Computation},
  number       = {4},
  pages        = {463-490},
  shortjournal = {Evol. Comput.},
  title        = {Multiobjective evolutionary algorithms are still good: Maximizing monotone approximately submodular minus modular functions},
  volume       = {29},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Environmental adaptation of robot morphology and control
through real-world evolution. <em>ECJ</em>, <em>29</em>(4), 441–461. (<a
href="https://doi.org/10.1162/evco_a_00291">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robots operating in the real world will experience a range of different environments and tasks. It is essential for the robot to have the ability to adapt to its surroundings to work efficiently in changing conditions. Evolutionary robotics aims to solve this by optimizing both the control and body (morphology) of a robot, allowing adaptation to internal, as well as external factors. Most work in this field has been done in physics simulators, which are relatively simple and not able to replicate the richness of interactions found in the real world. Solutions that rely on the complex interplay among control, body, and environment are therefore rarely found. In this article, we rely solely on real-world evaluations and apply evolutionary search to yield combinations of morphology and control for our mechanically self-reconfiguring quadruped robot. We evolve solutions on two distinct physical surfaces and analyze the results in terms of both control and morphology. We then transition to two previously unseen surfaces to demonstrate the generality of our method. We find that the evolutionary search finds high-performing and diverse morphology-controller configurations by adapting both control and body to the different properties of the physical environments. We additionally find that morphology and control vary with statistical significance between the environments. Moreover, we observe that our method allows for morphology and control parameters to transfer to previously unseen terrains, demonstrating the generality of our approach.},
  archive      = {J_ECJ},
  author       = {Nygaard, T. F. and Martin, C. P. and Howard, D. and Torresen, J. and Glette, K.},
  doi          = {10.1162/evco_a_00291},
  journal      = {Evolutionary Computation},
  number       = {4},
  pages        = {441-461},
  shortjournal = {Evol. Comput.},
  title        = {Environmental adaptation of robot morphology and control through real-world evolution},
  volume       = {29},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Iterated local search and other algorithms for buffered
two-machine permutation flow shops with constant processing times on one
machine. <em>ECJ</em>, <em>29</em>(3), 415–439. (<a
href="https://doi.org/10.1162/evco_a_00287">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The two-machine permutation flow shop scheduling problem with buffer is studied for the special case that all processing times on one of the two machines are equal to a constant c ⁠ . This case is interesting because it occurs in various applications, for example, when one machine is a packing machine or when materials have to be transported. Different types of buffers and buffer usage are considered. It is shown that all considered buffer flow shop problems remain NP -hard for the makespan criterion even with the restriction to equal processing times on one machine. However, the special case where the constant c is larger or smaller than all processing times on the other machine is shown to be polynomially solvable by presenting an algorithm (2BF-OPT) that calculates optimal schedules in O ( n log n ) steps. Two heuristics for solving the NP -hard flow shop problems are proposed: (i) a modification of the commonly used NEH heuristic (mNEH) and (ii) an Iterated Local Search heuristic (2BF-ILS) that uses the mNEH heuristic for computing its initial solution. It is shown experimentally that the proposed 2BF-ILS heuristic obtains better results than two state-of-the-art algorithms for buffered flow shop problems from the literature and an Ant Colony Optimization algorithm. In addition, it is shown experimentally that 2BF-ILS obtains the same solution quality as the standard NEH heuristic, however, with a smaller number of function evaluations.},
  archive      = {J_ECJ},
  author       = {Le, Hoang Thanh and Geser, Philine and Middendorf, Martin},
  doi          = {10.1162/evco_a_00287},
  journal      = {Evolutionary Computation},
  number       = {3},
  pages        = {415-439},
  shortjournal = {Evol. Comput.},
  title        = {Iterated local search and other algorithms for buffered two-machine permutation flow shops with constant processing times on one machine},
  volume       = {29},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Evolving plasticity for autonomous learning under changing
environmental conditions. <em>ECJ</em>, <em>29</em>(3), 391–414. (<a
href="https://doi.org/10.1162/evco_a_00286">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A fundamental aspect of learning in biological neural networks is the plasticity property which allows them to modify their configurations during their lifetime. Hebbian learning is a biologically plausible mechanism for modeling the plasticity property in artificial neural networks (ANNs), based on the local interactions of neurons. However, the emergence of a coherent global learning behavior from local Hebbian plasticity rules is not very well understood. The goal of this work is to discover interpretable local Hebbian learning rules that can provide autonomous global learning. To achieve this, we use a discrete representation to encode the learning rules in a finite search space. These rules are then used to perform synaptic changes, based on the local interactions of the neurons. We employ genetic algorithms to optimize these rules to allow learning on two separate tasks (a foraging and a prey–predator scenario) in online lifetime learning settings. The resulting evolved rules converged into a set of well-defined interpretable types, that are thoroughly discussed. Notably, the performance of these rules, while adapting the ANNs during the learning tasks, is comparable to that of offline learning methods such as hill climbing.},
  archive      = {J_ECJ},
  author       = {Yaman, Anil and Iacca, Giovanni and Mocanu, Decebal Constantin and Coler, Matt and Fletcher, George and Pechenizkiy, Mykola},
  doi          = {10.1162/evco_a_00286},
  journal      = {Evolutionary Computation},
  number       = {3},
  pages        = {391-414},
  shortjournal = {Evol. Comput.},
  title        = {Evolving plasticity for autonomous learning under changing environmental conditions},
  volume       = {29},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Interaction–transformation evolutionary algorithm for
symbolic regression. <em>ECJ</em>, <em>29</em>(3), 367–390. (<a
href="https://doi.org/10.1162/evco_a_00285">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Interaction–Transformation (IT) is a new representation for Symbolic Regression that reduces the space of solutions to a set of expressions that follow a specific structure. The potential of this representation was illustrated in prior work with the algorithm called SymTree. This algorithm starts with a simple linear model and incrementally introduces new transformed features until a stop criterion is met. While the results obtained by this algorithm were competitive with the literature, it had the drawback of not scaling well with the problem dimension. This article introduces a mutation-only Evolutionary Algorithm, called ITEA, capable of evolving a population of IT expressions. One advantage of this algorithm is that it enables the user to specify the maximum number of terms in an expression. In order to verify the competitiveness of this approach, ITEA is compared to linear, nonlinear, and Symbolic Regression models from the literature. The results indicate that ITEA is capable of finding equal or better approximations than other Symbolic Regression models while being competitive to state-of-the-art nonlinear models. Additionally, since this representation follows a specific structure, it is possible to extract the importance of each original feature of a data set as an analytical function, enabling us to automate the explanation of any prediction. In conclusion, ITEA is competitive when comparing to regression models with the additional benefit of automating the extraction of additional information of the generated models.},
  archive      = {J_ECJ},
  author       = {de Franca, F. O. and Aldeia, G. S. I.},
  doi          = {10.1162/evco_a_00285},
  journal      = {Evolutionary Computation},
  number       = {3},
  pages        = {367-390},
  shortjournal = {Evol. Comput.},
  title        = {Interaction–Transformation evolutionary algorithm for symbolic regression},
  volume       = {29},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Automatically evolving texture image descriptors using the
multitree representation in genetic programming using few instances.
<em>ECJ</em>, <em>29</em>(3), 331–366. (<a
href="https://doi.org/10.1162/evco_a_00284">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The performance of image classification is highly dependent on the quality of the extracted features that are used to build a model. Designing such features usually requires prior knowledge of the domain and is often undertaken by a domain expert who, if available, is very costly to employ. Automating the process of designing such features can largely reduce the cost and efforts associated with this task. Image descriptors, such as local binary patterns, have emerged in computer vision, and aim at detecting keypoints, for example, corners, line-segments, and shapes, in an image and extracting features from those keypoints. In this article, genetic programming (GP) is used to automatically evolve an image descriptor using only two instances per class by utilising a multitree program representation. The automatically evolved descriptor operates directly on the raw pixel values of an image and generates the corresponding feature vector. Seven well-known datasets were adapted to the few-shot setting and used to assess the performance of the proposed method and compared against six handcrafted and one evolutionary computation-based image descriptor as well as three convolutional neural network (CNN) based methods. The experimental results show that the new method has significantly outperformed the competitor image descriptors and CNN-based methods. Furthermore, different patterns have been identified from analysing the evolved programs.},
  archive      = {J_ECJ},
  author       = {Al-Sahaf, Harith and Al-Sahaf, Ausama and Xue, Bing and Zhang, Mengjie},
  doi          = {10.1162/evco_a_00284},
  journal      = {Evolutionary Computation},
  number       = {3},
  pages        = {331-366},
  shortjournal = {Evol. Comput.},
  title        = {Automatically evolving texture image descriptors using the multitree representation in genetic programming using few instances},
  volume       = {29},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Lower bounds for non-elitist evolutionary algorithms via
negative multiplicative drift. <em>ECJ</em>, <em>29</em>(2), 305–329.
(<a href="https://doi.org/10.1162/evco_a_00283">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A decent number of lower bounds for non-elitist population-based evolutionary algorithms has been shown by now. Most of them are technically demanding due to the (hard to avoid) use of negative drift theorems—general results which translate an expected movement away from the target into a high hitting time. We propose a simple negative drift theorem for multiplicative drift scenarios and show that it can simplify existing analyses. We discuss in more detail Lehre&#39;s ( 2010 ) negative drift in populations method, one of the most general tools to prove lower bounds on the runtime of non-elitist mutation-based evolutionary algorithms for discrete search spaces. Together with other arguments, we obtain an alternative and simpler proof of this result, which also strengthens and simplifies this method. In particular, now only three of the five technical conditions of the previous result have to be verified. The lower bounds we obtain are explicit instead of only asymptotic. This allows us to compute concrete lower bounds for concrete algorithms, but also enables us to show that super-polynomial runtimes appear already when the reproduction rate is only a ( 1 - ω ( n - 1 / 2 ) ) factor below the threshold. For the special case of algorithms using standard bit mutation with a random mutation rate (called uniform mixing in the language of hyper-heuristics), we prove the result stated by Dang and Lehre ( 2016b ) and extend it to mutation rates other than Θ ( 1 / n ) ⁠ , which includes the heavy-tailed mutation operator proposed by Doerr et al. ( 2017 ). We finally use our method and a novel domination argument to show an exponential lower bound for the runtime of the mutation-only simple genetic algorithm on OneMax for arbitrary population size.},
  archive      = {J_ECJ},
  author       = {Doerr, Benjamin},
  doi          = {10.1162/evco_a_00283},
  journal      = {Evolutionary Computation},
  number       = {2},
  pages        = {305-329},
  shortjournal = {Evol. Comput.},
  title        = {Lower bounds for non-elitist evolutionary algorithms via negative multiplicative drift},
  volume       = {29},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A decomposition-based evolutionary algorithm with
correlative selection mechanism for many-objective optimization.
<em>ECJ</em>, <em>29</em>(2), 269–304. (<a
href="https://doi.org/10.1162/evco_a_00279">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Decomposition-based evolutionary algorithms have been quite successful in dealing with multiobjective optimization problems. Recently, more and more researchers attempt to apply the decomposition approach to solve many-objective optimization problems. A many-objective evolutionary algorithm based on decomposition with correlative selection mechanism (MOEA/D-CSM) is also proposed to solve many-objective optimization problems in this article. Since MOEA/D-SCM is based on a decomposition approach which adopts penalty boundary intersection (PBI), a set of reference points must be generated in advance. Thus, a new concept related to the set of reference points is introduced first, namely, the correlation between an individual and a reference point. Thereafter, a new selection mechanism based on the correlation is designed and called correlative selection mechanism. The correlative selection mechanism finds its correlative individuals for each reference point as soon as possible so that the diversity among population members is maintained. However, when a reference point has two or more correlative individuals, the worse correlative individuals may be removed from a population so that the solutions can be ensured to move toward the Pareto-optimal front. In a comprehensive experimental study, we apply MOEA/D-CSM to a number of many-objective test problems with 3 to 15 objectives and make a comparison with three state-of-the-art many-objective evolutionary algorithms, namely, NSGA-III, MOEA/D, and RVEA. Experimental results show that the proposed MOEA/D-CSM can produce competitive results on most of the problems considered in this study.},
  archive      = {J_ECJ},
  author       = {Liu, Ruochen and Wang, Ruinan and Bian, Renyu and Liu, Jing and Jiao, Licheng},
  doi          = {10.1162/evco_a_00279},
  journal      = {Evolutionary Computation},
  number       = {2},
  pages        = {269-304},
  shortjournal = {Evol. Comput.},
  title        = {A decomposition-based evolutionary algorithm with correlative selection mechanism for many-objective optimization},
  volume       = {29},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Probabilistic contextual and structural dependencies
learning in grammar-based genetic programming. <em>ECJ</em>,
<em>29</em>(2), 239–268. (<a
href="https://doi.org/10.1162/evco_a_00280">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Genetic Programming is a method to automatically create computer programs based on the principles of evolution. The problem of deceptiveness caused by complex dependencies among components of programs is challenging. It is important because it can misguide Genetic Programming to create suboptimal programs. Besides, a minor modification in the programs may lead to a notable change in the program behaviours and affect the final outputs. This article presents Grammar-Based Genetic Programming with Bayesian Classifiers (GBGPBC) in which the probabilistic dependencies among components of programs are captured using a set of Bayesian network classifiers. Our system was evaluated using a set of benchmark problems (the deceptive maximum problems, the royal tree problems, and the bipolar asymmetric royal tree problems). It was shown to be often more robust and more efficient in searching the best programs than other related Genetic Programming approaches in terms of the total number of fitness evaluation. We studied what factors affect the performance of GBGPBC and discovered that robust variants of GBGPBC were consistently weakly correlated with some complexity measures. Furthermore, our approach has been applied to learn a ranking program on a set of customers in direct marketing. Our suggested solutions help companies to earn significantly more when compared with other solutions produced by several well-known machine learning algorithms, such as neural networks, logistic regression, and Bayesian networks.},
  archive      = {J_ECJ},
  author       = {Wong, Pak-Kan and Wong, Man-Leung and Leung, Kwong-Sak},
  doi          = {10.1162/evco_a_00280},
  journal      = {Evolutionary Computation},
  number       = {2},
  pages        = {239-268},
  shortjournal = {Evol. Comput.},
  title        = {Probabilistic contextual and structural dependencies learning in grammar-based genetic programming},
  volume       = {29},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Improving model-based genetic programming for symbolic
regression of small expressions. <em>ECJ</em>, <em>29</em>(2), 211–237.
(<a href="https://doi.org/10.1162/evco_a_00278">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Gene-pool Optimal Mixing Evolutionary Algorithm (GOMEA) is a model-based EA framework that has been shown to perform well in several domains, including Genetic Programming (GP). Differently from traditional EAs where variation acts blindly, GOMEA learns a model of interdependencies within the genotype, that is, the linkage, to estimate what patterns to propagate. In this article, we study the role of Linkage Learning (LL) performed by GOMEA in Symbolic Regression (SR). We show that the non-uniformity in the distribution of the genotype in GP populations negatively biases LL, and propose a method to correct for this. We also propose approaches to improve LL when ephemeral random constants are used. Furthermore, we adapt a scheme of interleaving runs to alleviate the burden of tuning the population size, a crucial parameter for LL, to SR. We run experiments on 10 real-world datasets, enforcing a strict limitation on solution size, to enable interpretability. We find that the new LL method outperforms the standard one, and that GOMEA outperforms both traditional and semantic GP. We also find that the small solutions evolved by GOMEA are competitive with tuned decision trees, making GOMEA a promising new approach to SR.},
  archive      = {J_ECJ},
  author       = {Virgolin, M. and Alderliesten, T. and Witteveen, C. and Bosman, P. A. N.},
  doi          = {10.1162/evco_a_00278},
  journal      = {Evolutionary Computation},
  number       = {2},
  pages        = {211-237},
  shortjournal = {Evol. Comput.},
  title        = {Improving model-based genetic programming for symbolic regression of small expressions},
  volume       = {29},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Offline learning with a selection hyper-heuristic: An
application to water distribution network optimisation. <em>ECJ</em>,
<em>29</em>(2), 187–210. (<a
href="https://doi.org/10.1162/evco_a_00277">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A sequence-based selection hyper-heuristic with online learning is used to optimise 12 water distribution networks of varying sizes. The hyper-heuristic results are compared with those produced by five multiobjective evolutionary algorithms. The comparison demonstrates that the hyper-heuristic is a computationally efficient alternative to a multiobjective evolutionary algorithm. An offline learning algorithm is used to enhance the optimisation performance of the hyper-heuristic. The optimisation results of the offline trained hyper-heuristic are analysed statistically, and a new offline learning methodology is proposed. The new methodology is evaluated, and shown to produce an improvement in performance on each of the 12 networks. Finally, it is demonstrated that offline learning can be usefully transferred from small, computationally inexpensive problems, to larger computationally expensive ones, and that the improvement in optimisation performance is statistically significant, with 99\% confidence.},
  archive      = {J_ECJ},
  author       = {Yates, William B. and Keedwell, Edward C.},
  doi          = {10.1162/evco_a_00277},
  journal      = {Evolutionary Computation},
  number       = {2},
  pages        = {187-210},
  shortjournal = {Evol. Comput.},
  title        = {Offline learning with a selection hyper-heuristic: An application to water distribution network optimisation},
  volume       = {29},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Effect of objective normalization and penalty parameter on
penalty boundary intersection decomposition-based evolutionary
many-objective optimization algorithms. <em>ECJ</em>, <em>29</em>(1),
157–186. (<a href="https://doi.org/10.1162/evco_a_00276">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An objective normalization strategy is essential in any evolutionary multiobjective or many-objective optimization (EMO or EMaO) algorithm, due to the distance calculations between objective vectors required to compute diversity and convergence of population members. For the decomposition-based EMO/EMaO algorithms involving the Penalty Boundary Intersection (PBI) metric, normalization is an important matter due to the computation of two distance metrics. In this article, we make a theoretical analysis of the effect of instabilities in the normalization process on the performance of PBI-based MOEA/D and a proposed PBI-based NSGA-III procedure. Although the effect is well recognized in the literature, few theoretical studies have been done so far to understand its true nature and the choice of a suitable penalty parameter value for an arbitrary problem. The developed theoretical results have been corroborated with extensive experimental results on three to 15-objective convex and non-convex instances of DTLZ and WFG problems. The article, makes important theoretical conclusions on PBI-based decomposition algorithms derived from the study.},
  archive      = {J_ECJ},
  author       = {Chen, Lei and Deb, Kalyanmoy and Liu, Hai-Lin and Zhang, Qingfu},
  doi          = {10.1162/evco_a_00276},
  journal      = {Evolutionary Computation},
  number       = {1},
  pages        = {157-186},
  shortjournal = {Evol. Comput.},
  title        = {Effect of objective normalization and penalty parameter on penalty boundary intersection decomposition-based evolutionary many-objective optimization algorithms},
  volume       = {29},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Achieving highly scalable evolutionary real-valued
optimization by exploiting partial evaluations. <em>ECJ</em>,
<em>29</em>(1), 129–155. (<a
href="https://doi.org/10.1162/evco_a_00275">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is known that to achieve efficient scalability of an Evolutionary Algorithm (EA), dependencies (also known as linkage) must be properly taken into account during variation. In a Gray-Box Optimization (GBO) setting, exploiting prior knowledge regarding these dependencies can greatly benefit optimization. We specifically consider the setting where partial evaluations are possible, meaning that the partial modification of a solution can be efficiently evaluated. Such problems are potentially very difficult, for example, non-separable, multimodal, and multiobjective. The Gene-pool Optimal Mixing Evolutionary Algorithm (GOMEA) can effectively exploit partial evaluations, leading to a substantial improvement in performance and scalability. GOMEA was recently shown to be extendable to real-valued optimization through a combination with the real-valued estimation of distribution algorithm AMaLGaM. In this article, we definitively introduce the Real-Valued GOMEA (RV-GOMEA), and introduce a new variant, constructed by combining GOMEA with what is arguably the best-known real-valued EA, the Covariance Matrix Adaptation Evolution Strategies (CMA-ES). Both variants of GOMEA are compared to L-BFGS and the Limited Memory CMA-ES (LM-CMA-ES). We show that both variants of RV-GOMEA achieve excellent performance and scalability in a GBO setting, which can be orders of magnitude better than that of EAs unable to efficiently exploit the GBO setting.},
  archive      = {J_ECJ},
  author       = {Bouter, Anton and Alderliesten, Tanja and Bosman, Peter A.N.},
  doi          = {10.1162/evco_a_00275},
  journal      = {Evolutionary Computation},
  number       = {1},
  pages        = {129-155},
  shortjournal = {Evol. Comput.},
  title        = {Achieving highly scalable evolutionary real-valued optimization by exploiting partial evaluations},
  volume       = {29},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Feature-based diversity optimization for problem instance
classification. <em>ECJ</em>, <em>29</em>(1), 107–128. (<a
href="https://doi.org/10.1162/evco_a_00274">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Understanding the behaviour of heuristic search methods is a challenge. This even holds for simple local search methods such as 2-OPT for the Travelling Salesperson Problem (TSP). In this article, we present a general framework that is able to construct a diverse set of instances which are hard or easy for a given search heuristic. Such a diverse set is obtained by using an evolutionary algorithm for constructing hard or easy instances which are diverse with respect to different features of the underlying problem. Examining the constructed instance sets, we show that many combinations of two or three features give a good classification of the TSP instances in terms of whether they are hard to be solved by 2-OPT.},
  archive      = {J_ECJ},
  author       = {Gao, Wanru and Nallaperuma, Samadhi and Neumann, Frank},
  doi          = {10.1162/evco_a_00274},
  journal      = {Evolutionary Computation},
  number       = {1},
  pages        = {107-128},
  shortjournal = {Evol. Comput.},
  title        = {Feature-based diversity optimization for problem instance classification},
  volume       = {29},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Genetic programming with delayed routing for multiobjective
dynamic flexible job shop scheduling. <em>ECJ</em>, <em>29</em>(1),
75–105. (<a href="https://doi.org/10.1162/evco_a_00273">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic Flexible Job Shop Scheduling (DFJSS) is an important and challenging problem, and can have multiple conflicting objectives. Genetic Programming Hyper-Heuristic (GPHH) is a promising approach to fast respond to the dynamic and unpredictable events in DFJSS. A GPHH algorithm evolves dispatching rules (DRs) that are used to make decisions during the scheduling process (i.e., the so-called heuristic template). In DFJSS, there are two kinds of scheduling decisions: the routing decision that allocates each operation to a machine to process it, and the sequencing decision that selects the next job to be processed by each idle machine. The traditional heuristic template makes both routing and sequencing decisions in a non-delay manner, which may have limitations in handling the dynamic environment. In this article, we propose a novel heuristic template that delays the routing decisions rather than making them immediately. This way, all the decisions can be made under the latest and most accurate information. We propose three different delayed routing strategies, and automatically evolve the rules in the heuristic template by GPHH. We evaluate the newly proposed GPHH with Delayed Routing (GPHH-DR) on a multiobjective DFJSS that optimises the energy efficiency and mean tardiness. The experimental results show that GPHH-DR significantly outperformed the state-of-the-art GPHH methods. We further demonstrated the efficacy of the proposed heuristic template with delayed routing, which suggests the importance of delaying the routing decisions.},
  archive      = {J_ECJ},
  author       = {Xu, Binzi and Mei, Yi and Wang, Yan and Ji, Zhicheng and Zhang, Mengjie},
  doi          = {10.1162/evco_a_00273},
  journal      = {Evolutionary Computation},
  number       = {1},
  pages        = {75-105},
  shortjournal = {Evol. Comput.},
  title        = {Genetic programming with delayed routing for multiobjective dynamic flexible job shop scheduling},
  volume       = {29},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A systematic literature review of the successors of
“NeuroEvolution of augmenting topologies.” <em>ECJ</em>, <em>29</em>(1),
1–73. (<a href="https://doi.org/10.1162/evco_a_00282">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {NeuroEvolution (NE) refers to a family of methods for optimizing Artificial Neural Networks (ANNs) using Evolutionary Computation (EC) algorithms. NeuroEvolution of Augmenting Topologies (NEAT) is considered one of the most influential algorithms in the field. Eighteen years after its invention, a plethora of methods have been proposed that extend NEAT in different aspects. In this article, we present a systematic literature review (SLR) to list and categorize the methods succeeding NEAT. Our review protocol identified 232 papers by merging the findings of two major electronic databases. Applying criteria that determine the paper&#39;s relevance and assess its quality, resulted in 61 methods that are presented in this article. Our review article proposes a new categorization scheme of NEAT&#39;s successors into three clusters. NEAT-based methods are categorized based on 1) whether they consider issues specific to the search space or the fitness landscape, 2) whether they combine principles from NE and another domain, or 3) the particular properties of the evolved ANNs. The clustering supports researchers 1) understanding the current state of the art that will enable them, 2) exploring new research directions or 3) benchmarking their proposed method to the state of the art, if they are interested in comparing, and 4) positioning themselves in the domain or 5) selecting a method that is most appropriate for their problem.},
  archive      = {J_ECJ},
  author       = {Papavasileiou, Evgenia and Cornelis, Jan and Jansen, Bart},
  doi          = {10.1162/evco_a_00282},
  journal      = {Evolutionary Computation},
  number       = {1},
  pages        = {1-73},
  shortjournal = {Evol. Comput.},
  title        = {A systematic literature review of the successors of “NeuroEvolution of augmenting topologies”},
  volume       = {29},
  year         = {2021},
}
</textarea>
</details></li>
</ul>

</body>
</html>
