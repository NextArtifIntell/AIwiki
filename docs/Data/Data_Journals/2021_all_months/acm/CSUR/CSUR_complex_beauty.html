<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>CSUR_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="csur---219">CSUR - 219</h2>
<ul>
<li><details>
<summary>
(2021). A comprehensive taxonomy of dynamic texture representation.
<em>CSUR</em>, <em>55</em>(1), 23:1–39. (<a
href="https://doi.org/10.1145/3487892">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Representing dynamic textures (DTs) plays an important role in many real implementations in the computer vision community. Due to the turbulent and non-directional motions of DTs along with the negative impacts of different factors (e.g., environmental changes, noise, illumination, etc.), efficiently analyzing DTs has raised considerable challenges for the state-of-the-art approaches. For 20 years, many different techniques have been introduced to handle the above well-known issues for enhancing the performance. Those methods have shown valuable contributions, but the problems have been incompletely dealt with, particularly recognizing DTs on large-scale datasets. In this article, we present a comprehensive taxonomy of DT representation in order to purposefully give a thorough overview of the existing methods along with overall evaluations of their obtained performances. Accordingly, we arrange the methods into six canonical categories. Each of them is then taken in a brief presentation of its principal methodology stream and various related variants. The effectiveness levels of the state-of-the-art methods are then investigated and thoroughly discussed with respect to quantitative and qualitative evaluations in classifying DTs on benchmark datasets. Finally, we point out several potential applications and the remaining challenges that should be addressed in further directions. In comparison with two existing shallow DT surveys (i.e., the first one is out of date as it was made in 2005, while the newer one (published in 2016) is an inadequate overview), we believe that our proposed comprehensive taxonomy not only provides a better view of DT representation for the target readers but also stimulates future research activities.},
  archive      = {J_CSUR},
  author       = {Thanh Tuan Nguyen and Thanh Phuong Nguyen},
  doi          = {10.1145/3487892},
  journal      = {ACM Computing Surveys},
  number       = {1},
  pages        = {23:1–39},
  shortjournal = {ACM Comput. Surv.},
  title        = {A comprehensive taxonomy of dynamic texture representation},
  volume       = {55},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Capturing dynamics of information diffusion in SNS: A survey
of methodology and techniques. <em>CSUR</em>, <em>55</em>(1), 22:1–51.
(<a href="https://doi.org/10.1145/3485273">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Studying information diffusion in SNS (Social Networks Service) has remarkable significance in both academia and industry. Theoretically, it boosts the development of other subjects such as statistics, sociology, and data mining. Practically, diffusion modeling provides fundamental support for many downstream applications (e.g., public opinion monitoring, rumor source identification, and viral marketing). Tremendous efforts have been devoted to this area to understand and quantify information diffusion dynamics. This survey investigates and summarizes the emerging distinguished works in diffusion modeling. We first put forward a unified information diffusion concept in terms of three components: information, user decision, and social vectors, followed by a detailed introduction of the methodologies for diffusion modeling. And then, a new taxonomy adopting hybrid philosophy (i.e., granularity and techniques) is proposed, and we made a series of comparative studies on elementary diffusion models under our taxonomy from the aspects of assumptions, methods, and pros and cons. We further summarized representative diffusion modeling in special scenarios and significant downstream tasks based on these elementary models. Finally, open issues in this field following the methodology of diffusion modeling are discussed.},
  archive      = {J_CSUR},
  author       = {Huacheng Li and Chunhe Xia and Tianbo Wang and Sheng Wen and Chao Chen and Yang Xiang},
  doi          = {10.1145/3485273},
  journal      = {ACM Computing Surveys},
  number       = {1},
  pages        = {22:1–51},
  shortjournal = {ACM Comput. Surv.},
  title        = {Capturing dynamics of information diffusion in SNS: A survey of methodology and techniques},
  volume       = {55},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Artificial intelligence security: Threats and
countermeasures. <em>CSUR</em>, <em>55</em>(1), 20:1–36. (<a
href="https://doi.org/10.1145/3487890">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, with rapid technological advancement in both computing hardware and algorithm, Artificial Intelligence (AI) has demonstrated significant advantage over human being in a wide range of fields, such as image recognition, education, autonomous vehicles, finance, and medical diagnosis. However, AI-based systems are generally vulnerable to various security threats throughout the whole process, ranging from the initial data collection and preparation to the training, inference, and final deployment. In an AI-based system, the data collection and pre-processing phase are vulnerable to sensor spoofing attacks and scaling attacks, respectively, while the training and inference phases of the model are subject to poisoning attacks and adversarial attacks, respectively. To address these severe security threats against the AI-based systems, in this article, we review the challenges and recent research advances for security issues in AI, so as to depict an overall blueprint for AI security. More specifically, we first take the lifecycle of an AI-based system as a guide to introduce the security threats that emerge at each stage, which is followed by a detailed summary for corresponding countermeasures. Finally, some of the future challenges and opportunities for the security issues in AI will also be discussed.},
  archive      = {J_CSUR},
  author       = {Yupeng Hu and Wenxin Kuang and Zheng Qin and Kenli Li and Jiliang Zhang and Yansong Gao and Wenjia Li and Keqin Li},
  doi          = {10.1145/3487890},
  journal      = {ACM Computing Surveys},
  number       = {1},
  pages        = {20:1–36},
  shortjournal = {ACM Comput. Surv.},
  title        = {Artificial intelligence security: Threats and countermeasures},
  volume       = {55},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Challenges and opportunities for practical and effective
dynamic information flow tracking. <em>CSUR</em>, <em>55</em>(1),
17:1–33. (<a href="https://doi.org/10.1145/3483790">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Information flow tracking was proposed more than 40 years ago to address the limitations of access control mechanisms to guarantee the confidentiality and integrity of information flowing within a system, but has not yet been widely applied in practice for security solutions. Here, we survey and systematize literature on dynamic information flow tracking (DIFT) to discover challenges and opportunities to make it practical and effective for security solutions. We focus on common knowledge in the literature and lingering research gaps from two dimensions— (i) the layer of abstraction where DIFT is implemented (software, software/hardware, or hardware) and (ii) the security goal (confidentiality and/or integrity). We observe that two major limitations hinder the practical application of DIFT for on-the-fly security applications: (i) high implementation overhead and (ii) incomplete information flow tracking (low accuracy). We posit, after review of the literature, that addressing these major impedances via hardware parallelism can potentially unleash DIFT’s great potential for systems security, as it can allow security policies to be implemented in a built-in and standardized fashion. Furthermore, we provide recommendations for the next generation of practical and efficient DIFT systems with an eye towards hardware-supported implementations.},
  archive      = {J_CSUR},
  author       = {Christopher Brant and Prakash Shrestha and Benjamin Mixon-Baca and Kejun Chen and Said Varlioglu and Nelly Elsayed and Yier Jin and Jedidiah Crandall and Daniela Oliveira},
  doi          = {10.1145/3483790},
  journal      = {ACM Computing Surveys},
  number       = {1},
  pages        = {17:1–33},
  shortjournal = {ACM Comput. Surv.},
  title        = {Challenges and opportunities for practical and effective dynamic information flow tracking},
  volume       = {55},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A survey on string constraint solving. <em>CSUR</em>,
<em>55</em>(1), 16:1–38. (<a
href="https://doi.org/10.1145/3484198">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {String constraint solving refers to solving combinatorial problems involving constraints over string variables. String solving approaches have become popular over the past few years given the massive use of strings in different application domains like formal analysis, automated testing, database query processing, and cybersecurity. This article reports a comprehensive survey on string constraint solving by exploring the large number of approaches that have been proposed over the past few decades to solve string constraints.},
  archive      = {J_CSUR},
  author       = {Roberto Amadini},
  doi          = {10.1145/3484198},
  journal      = {ACM Computing Surveys},
  number       = {1},
  pages        = {16:1–38},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey on string constraint solving},
  volume       = {55},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Arms race in adversarial malware detection: A survey.
<em>CSUR</em>, <em>55</em>(1), 15:1–35. (<a
href="https://doi.org/10.1145/3484491">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Malicious software (malware) is a major cyber threat that has to be tackled with Machine Learning (ML) techniques because millions of new malware examples are injected into cyberspace on a daily basis. However, ML is vulnerable to attacks known as adversarial examples. In this article, we survey and systematize the field of Adversarial Malware Detection (AMD) through the lens of a unified conceptual framework of assumptions, attacks, defenses, and security properties. This not only leads us to map attacks and defenses to partial order structures, but also allows us to clearly describe the attack-defense arms race in the AMD context. We draw a number of insights, including: knowing the defender’s feature set is critical to the success of transfer attacks; the effectiveness of practical evasion attacks largely depends on the attacker’s freedom in conducting manipulations in the problem space; knowing the attacker’s manipulation set is critical to the defender’s success; and the effectiveness of adversarial training depends on the defender’s capability in identifying the most powerful attack. We also discuss a number of future research directions.},
  archive      = {J_CSUR},
  author       = {Deqiang Li and Qianmu Li and Yanfang (Fanny) Ye and Shouhuai Xu},
  doi          = {10.1145/3484491},
  journal      = {ACM Computing Surveys},
  number       = {1},
  pages        = {15:1–35},
  shortjournal = {ACM Comput. Surv.},
  title        = {Arms race in adversarial malware detection: A survey},
  volume       = {55},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Deep learning-based face super-resolution: A survey.
<em>CSUR</em>, <em>55</em>(1), 13:1–36. (<a
href="https://doi.org/10.1145/3485132">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Face super-resolution (FSR), also known as face hallucination, which is aimed at enhancing the resolution of low-resolution (LR) face images to generate high-resolution face images, is a domain-specific image super-resolution problem. Recently, FSR has received considerable attention and witnessed dazzling advances with the development of deep learning techniques. To date, few summaries of the studies on the deep learning-based FSR are available. In this survey, we present a comprehensive review of deep learning-based FSR methods in a systematic manner. First, we summarize the problem formulation of FSR and introduce popular assessment metrics and loss functions. Second, we elaborate on the facial characteristics and popular datasets used in FSR. Third, we roughly categorize existing methods according to the utilization of facial characteristics. In each category, we start with a general description of design principles, present an overview of representative approaches, and then discuss the pros and cons among them. Fourth, we evaluate the performance of some state-of-the-art methods. Fifth, joint FSR and other tasks, and FSR-related applications are roughly introduced. Finally, we envision the prospects of further technological advancement in this field.},
  archive      = {J_CSUR},
  author       = {Junjun Jiang and Chenyang Wang and Xianming Liu and Jiayi Ma},
  doi          = {10.1145/3485132},
  journal      = {ACM Computing Surveys},
  number       = {1},
  pages        = {13:1–36},
  shortjournal = {ACM Comput. Surv.},
  title        = {Deep learning-based face super-resolution: A survey},
  volume       = {55},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A review on fact extraction and verification. <em>CSUR</em>,
<em>55</em>(1), 12:1–35. (<a
href="https://doi.org/10.1145/3485127">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the fact-checking problem, which aims to identify the veracity of a given claim. Specifically, we focus on the task of Fact Extraction and VERification (FEVER) and its accompanied dataset. The task consists of the subtasks of retrieving the relevant documents (and sentences) from Wikipedia and validating whether the information in the documents supports or refutes a given claim. This task is essential and can be the building block of applications such as fake news detection and medical claim verification. In this article, we aim at a better understanding of the challenges of the task by presenting the literature in a structured and comprehensive way. We describe the proposed methods by analyzing the technical perspectives of the different approaches and discussing the performance results on the FEVER dataset, which is the most well-studied and formally structured dataset on the fact extraction and verification task. We also conduct the largest experimental study to date on identifying beneficial loss functions for the sentence retrieval component. Our analysis indicates that sampling negative sentences is important for improving the performance and decreasing the computational complexity. Finally, we describe open issues and future challenges, and we motivate future research in the task.},
  archive      = {J_CSUR},
  author       = {Giannis Bekoulis and Christina Papagiannopoulou and Nikos Deligiannis},
  doi          = {10.1145/3485127},
  journal      = {ACM Computing Surveys},
  number       = {1},
  pages        = {12:1–35},
  shortjournal = {ACM Comput. Surv.},
  title        = {A review on fact extraction and verification},
  volume       = {55},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A survey on embedding dynamic graphs. <em>CSUR</em>,
<em>55</em>(1), 10:1–37. (<a
href="https://doi.org/10.1145/3483595">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Embedding static graphs in low-dimensional vector spaces plays a key role in network analytics and inference, supporting applications like node classification, link prediction, and graph visualization. However, many real-world networks present dynamic behavior, including topological evolution, feature evolution, and diffusion. Therefore, several methods for embedding dynamic graphs have been proposed to learn network representations over time, facing novel challenges, such as time-domain modeling, temporal features to be captured, and the temporal granularity to be embedded. In this survey, we overview dynamic graph embedding, discussing its fundamentals and the recent advances developed so far. We introduce the formal definition of dynamic graph embedding, focusing on the problem setting and introducing a novel taxonomy for dynamic graph embedding input and output. We further explore different dynamic behaviors that may be encompassed by embeddings, classifying by topological evolution, feature evolution, and processes on networks. Afterward, we describe existing techniques and propose a taxonomy for dynamic graph embedding techniques based on algorithmic approaches, from matrix and tensor factorization to deep learning, random walks, and temporal point processes. We also elucidate main applications, including dynamic link prediction, anomaly detection, and diffusion prediction, and we further state some promising research directions in the area.},
  archive      = {J_CSUR},
  author       = {Claudio D. T. Barros and Matheus R. F. Mendonça and Alex B. Vieira and Artur Ziviani},
  doi          = {10.1145/3483595},
  journal      = {ACM Computing Surveys},
  number       = {1},
  pages        = {10:1–37},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey on embedding dynamic graphs},
  volume       = {55},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A comprehensive survey on interoperability for IIoT:
Taxonomy, standards, and future directions. <em>CSUR</em>,
<em>55</em>(1), 9:1–35. (<a
href="https://doi.org/10.1145/3485130">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the era of Industry 4.0, the Internet-of-Things (IoT) performs the driving position analogous to the initial industrial metamorphosis. IoT affords the potential to couple machine-to-machine intercommunication and real-time information-gathering within the industry domain. Hence, the enactment of IoT in the industry magnifies effective optimization, authority, and data-driven judgment. However, this field undergoes several interoperable issues, including large numbers of heterogeneous IoT gadgets, tools, software, sensing, and processing components, joining through the Internet, despite the deficiency of communication protocols and standards. Recently, various interoperable protocols, platforms, standards, and technologies are enhanced and altered according to the specifications of the applicability in industrial applications. However, there are no recent survey papers that primarily examine various interoperability issues that Industrial IoT (IIoT) faces. In this review, we investigate the conventional and recent developments of relevant state-of-the-art IIoT technologies, frameworks, and solutions for facilitating interoperability between different IIoT components. We also discuss several interoperable IIoT standards, protocols, and models for digitizing the industrial revolution. Finally, we conclude this survey with an inherent discussion of open challenges and directions for future research.},
  archive      = {J_CSUR},
  author       = {Abhishek Hazra and Mainak Adhikari and Tarachand Amgoth and Satish Narayana Srirama},
  doi          = {10.1145/3485130},
  journal      = {ACM Computing Surveys},
  number       = {1},
  pages        = {9:1–35},
  shortjournal = {ACM Comput. Surv.},
  title        = {A comprehensive survey on interoperability for IIoT: Taxonomy, standards, and future directions},
  volume       = {55},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Adversarial machine learning in image classification: A
survey toward the defender’s perspective. <em>CSUR</em>, <em>55</em>(1),
8:1–38. (<a href="https://doi.org/10.1145/3485133">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep Learning algorithms have achieved state-of-the-art performance for Image Classification. For this reason, they have been used even in security-critical applications, such as biometric recognition systems and self-driving cars. However, recent works have shown those algorithms, which can even surpass human capabilities, are vulnerable to adversarial examples. In Computer Vision, adversarial examples are images containing subtle perturbations generated by malicious optimization algorithms to fool classifiers. As an attempt to mitigate these vulnerabilities, numerous countermeasures have been proposed recently in the literature. However, devising an efficient defense mechanism has proven to be a difficult task, since many approaches demonstrated to be ineffective against adaptive attackers. Thus, this article aims to provide all readerships with a review of the latest research progress on Adversarial Machine Learning in Image Classification, nevertheless, with a defender’s perspective. This article introduces novel taxonomies for categorizing adversarial attacks and defenses, as well as discuss possible reasons regarding the existence of adversarial examples. In addition, relevant guidance is also provided to assist researchers when devising and evaluating defenses. Finally, based on the reviewed literature, this article suggests some promising paths for future research.},
  archive      = {J_CSUR},
  author       = {Gabriel Resende Machado and Eugênio Silva and Ronaldo Ribeiro Goldschmidt},
  doi          = {10.1145/3485133},
  journal      = {ACM Computing Surveys},
  number       = {1},
  pages        = {8:1–38},
  shortjournal = {ACM Comput. Surv.},
  title        = {Adversarial machine learning in image classification: A survey toward the defender’s perspective},
  volume       = {55},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A survey on deep learning for human mobility. <em>CSUR</em>,
<em>55</em>(1), 7:1–44. (<a
href="https://doi.org/10.1145/3485125">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The study of human mobility is crucial due to its impact on several aspects of our society, such as disease spreading, urban planning, well-being, pollution, and more. The proliferation of digital mobility data, such as phone records, GPS traces, and social media posts, combined with the predictive power of artificial intelligence, triggered the application of deep learning to human mobility. Existing surveys focus on single tasks, data sources, mechanistic or traditional machine learning approaches, while a comprehensive description of deep learning solutions is missing. This survey provides a taxonomy of mobility tasks, a discussion on the challenges related to each task and how deep learning may overcome the limitations of traditional models, a description of the most relevant solutions to the mobility tasks described above, and the relevant challenges for the future. Our survey is a guide to the leading deep learning solutions to next-location prediction, crowd flow prediction, trajectory generation, and flow generation. At the same time, it helps deep learning scientists and practitioners understand the fundamental concepts and the open challenges of the study of human mobility.},
  archive      = {J_CSUR},
  author       = {Massimiliano Luca and Gianni Barlacchi and Bruno Lepri and Luca Pappalardo},
  doi          = {10.1145/3485125},
  journal      = {ACM Computing Surveys},
  number       = {1},
  pages        = {7:1–44},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey on deep learning for human mobility},
  volume       = {55},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A unified perspective for disinformation detection and truth
discovery in social sensing: A survey. <em>CSUR</em>, <em>55</em>(1),
6:1–33. (<a href="https://doi.org/10.1145/3477138">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the proliferation of social sensing, large amounts of observation are contributed by people or devices. However, these observations contain disinformation. Disinformation can propagate across online social networks at a relatively low cost, but result in a series of major problems in our society. In this survey, we provide a comprehensive overview of disinformation and truth discovery in social sensing under a unified perspective, including basic concepts and the taxonomy of existing methodologies. Furthermore, we summarize the mechanism of disinformation from four different perspectives (i.e., text only, text with image/multi-modal, text with propagation, and fusion models). In addition, we review existing solutions based on these requirements and compare their pros and cons and give a sort of guide to usage based on a detailed lesson learned. To facilitate future studies in this field, we summarize related publicly accessible real-world data sets and open source codes. Last but the most important, we emphasize potential future research topics and challenges in this domain through a deep analysis of most recent methods.},
  archive      = {J_CSUR},
  author       = {Fan Xu and Victor S. Sheng and Mingwen Wang},
  doi          = {10.1145/3477138},
  journal      = {ACM Computing Surveys},
  number       = {1},
  pages        = {6:1–33},
  shortjournal = {ACM Comput. Surv.},
  title        = {A unified perspective for disinformation detection and truth discovery in social sensing: A survey},
  volume       = {55},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Reinforcement learning in healthcare: A survey.
<em>CSUR</em>, <em>55</em>(1), 5:1–36. (<a
href="https://doi.org/10.1145/3477600">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a subfield of machine learning, reinforcement learning (RL) aims at optimizing decision making by using interaction samples of an agent with its environment and the potentially delayed feedbacks. In contrast to traditional supervised learning that typically relies on one-shot, exhaustive, and supervised reward signals, RL tackles sequential decision-making problems with sampled, evaluative, and delayed feedbacks simultaneously. Such a distinctive feature makes RL techniques a suitable candidate for developing powerful solutions in various healthcare domains, where diagnosing decisions or treatment regimes are usually characterized by a prolonged period with delayed feedbacks. By first briefly examining theoretical foundations and key methods in RL research, this survey provides an extensive overview of RL applications in a variety of healthcare domains, ranging from dynamic treatment regimes in chronic diseases and critical care, automated medical diagnosis, and many other control or scheduling problems that have infiltrated every aspect of the healthcare system. In addition, we discuss the challenges and open issues in the current research and highlight some potential solutions and directions for future research.},
  archive      = {J_CSUR},
  author       = {Chao Yu and Jiming Liu and Shamim Nemati and Guosheng Yin},
  doi          = {10.1145/3477600},
  journal      = {ACM Computing Surveys},
  number       = {1},
  pages        = {5:1–36},
  shortjournal = {ACM Comput. Surv.},
  title        = {Reinforcement learning in healthcare: A survey},
  volume       = {55},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Vehicular edge computing: Architecture, resource management,
security, and challenges. <em>CSUR</em>, <em>55</em>(1), 4:1–46. (<a
href="https://doi.org/10.1145/3485129">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vehicular Edge Computing (VEC), based on the Edge Computing motivation and fundamentals, is a promising technology supporting Intelligent Transport Systems services, smart city applications, and urban computing. VEC can provide and manage computational resources closer to vehicles and end-users, providing access to services at lower latency and meeting the minimum execution requirements for each service type. This survey describes VEC’s concepts and technologies; we also present an overview of existing VEC architectures, discussing them and exemplifying them through layered designs. Besides, we describe the underlying vehicular communication in supporting resource allocation mechanisms. With the intent to overview the risks, breaches, and measures in VEC, we review related security approaches and methods. Finally, we conclude this survey work with an overview and study of VEC’s main challenges. Unlike other surveys in which they are focused on content caching and data offloading, this work proposes a taxonomy based on the architectures in which VEC serves as the central element. VEC supports such architectures in capturing and disseminating data and resources to offer services aimed at a smart city through their aggregation and the allocation in a secure manner.},
  archive      = {J_CSUR},
  author       = {Rodolfo Meneguette and Robson De Grande and Jo Ueyama and Geraldo P. Rocha Filho and Edmundo Madeira},
  doi          = {10.1145/3485129},
  journal      = {ACM Computing Surveys},
  number       = {1},
  pages        = {4:1–46},
  shortjournal = {ACM Comput. Surv.},
  title        = {Vehicular edge computing: Architecture, resource management, security, and challenges},
  volume       = {55},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). PURE: A framework for analyzing proximity-based contact
tracing protocols. <em>CSUR</em>, <em>55</em>(1), 3:1–36. (<a
href="https://doi.org/10.1145/3485131">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many proximity-based tracing (PCT) protocols have been proposed and deployed to combat the spreading of COVID-19. In this article, we take a systematic approach to analyze PCT protocols. We identify a list of desired properties of a contact tracing design from the four aspects of Privacy, Utility, Resiliency, and Efficiency (PURE). We also identify two main design choices for PCT protocols: what information patients report to the server and which party performs the matching . These two choices determine most of the PURE properties and enable us to conduct a comprehensive analysis and comparison of the existing protocols.},
  archive      = {J_CSUR},
  author       = {Fabrizio Cicala and Weicheng Wang and Tianhao Wang and Ninghui Li and Elisa Bertino and Faming Liang and Yang Yang},
  doi          = {10.1145/3485131},
  journal      = {ACM Computing Surveys},
  number       = {1},
  pages        = {3:1–36},
  shortjournal = {ACM Comput. Surv.},
  title        = {PURE: A framework for analyzing proximity-based contact tracing protocols},
  volume       = {55},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A survey on privacy preservation in fog-enabled internet of
things. <em>CSUR</em>, <em>55</em>(1), 2:1–39. (<a
href="https://doi.org/10.1145/3474554">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite the rapid growth and advancement in the Internet of Things (IoT ), there are critical challenges that need to be addressed before the full adoption of the IoT. Data privacy is one of the hurdles towards the adoption of IoT as there might be potential misuse of users’ data and their identity in IoT applications. Several researchers have proposed different approaches to reduce privacy risks. However, most of the existing solutions still suffer from various drawbacks, such as huge bandwidth utilization and network latency, heavyweight cryptosystems, and policies that are applied on sensor devices and in the cloud. To address these issues, fog computing has been introduced for IoT network edges providing low latency, computation, and storage services. In this survey, we comprehensively review and classify privacy requirements for an in-depth understanding of privacy implications in IoT applications. Based on the classification, we highlight ongoing research efforts and limitations of the existing privacy-preservation techniques and map the existing IoT schemes with Fog-enabled IoT schemes to elaborate on the benefits and improvements that Fog-enabled IoT can bring to preserve data privacy in IoT applications. Lastly, we enumerate key research challenges and point out future research directions.},
  archive      = {J_CSUR},
  author       = {Kinza Sarwar and Sira Yongchareon and Jian Yu and Saeed Ur Rehman},
  doi          = {10.1145/3474554},
  journal      = {ACM Computing Surveys},
  number       = {1},
  pages        = {2:1–39},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey on privacy preservation in fog-enabled internet of things},
  volume       = {55},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A survey of orthogonal moments for image representation:
Theory, implementation, and evaluation. <em>CSUR</em>, <em>55</em>(1),
1:1–35. (<a href="https://doi.org/10.1145/3479428">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image representation is an important topic in computer vision and pattern recognition. It plays a fundamental role in a range of applications toward understanding visual contents. Moment-based image representation has been reported to be effective in satisfying the core conditions of semantic description due to its beneficial mathematical properties, especially geometric invariance and independence. This article presents a comprehensive survey of the orthogonal moments for image representation, covering recent advances in fast/accurate calculation, robustness/invariance optimization, definition extension, and application. We also create a software package for a variety of widely used orthogonal moments and evaluate such methods in a same base. The presented theory analysis, software implementation, and evaluation results can support the community, particularly in developing novel techniques and promoting real-world applications.},
  archive      = {J_CSUR},
  author       = {Shuren Qi and Yushu Zhang and Chao Wang and Jiantao Zhou and Xiaochun Cao},
  doi          = {10.1145/3479428},
  journal      = {ACM Computing Surveys},
  number       = {1},
  pages        = {1:1–35},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey of orthogonal moments for image representation: Theory, implementation, and evaluation},
  volume       = {55},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Handling iterations in distributed dataflow systems.
<em>CSUR</em>, <em>54</em>(9), 199:1–38. (<a
href="https://doi.org/10.1145/3477602">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Over the past decade, distributed dataflow systems (DDS) have become a standard technology. In these systems, users write programs in restricted dataflow programming models, such as MapReduce, which enable them to scale out program execution to a shared-nothing cluster of machines. Yet, there is no established consensus that prescribes how to extend these programming models to support iterative algorithms. In this survey, we review the research literature and identify how DDS handle control flow, such as iteration, from both the programming model and execution level perspectives. This survey will be of interest for both users and designers of DDS.},
  archive      = {J_CSUR},
  author       = {Gábor E. Gévay and Juan Soto and Volker Markl},
  doi          = {10.1145/3477602},
  journal      = {ACM Computing Surveys},
  number       = {9},
  pages        = {199:1–38},
  shortjournal = {ACM Comput. Surv.},
  title        = {Handling iterations in distributed dataflow systems},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Adversary models for mobile device authentication.
<em>CSUR</em>, <em>54</em>(9), 198:1–35. (<a
href="https://doi.org/10.1145/3477601">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile device authentication has been a highly active research topic for over 10 years, with a vast range of methods proposed and analyzed. In related areas, such as secure channel protocols, remote authentication, or desktop user authentication, strong, systematic, and increasingly formal threat models have been established and are used to qualitatively compare different methods. However, the analysis of mobile device authentication is often based on weak adversary models, suggesting overly optimistic results on their respective security. In this article, we introduce a new classification of adversaries to better analyze and compare mobile device authentication methods. We apply this classification to a systematic literature survey. The survey shows that security is still an afterthought and that most proposed protocols lack a comprehensive security analysis. The proposed classification of adversaries provides a strong and practical adversary model that offers a comparable and transparent classification of security properties in mobile device authentication.},
  archive      = {J_CSUR},
  author       = {René Mayrhofer and Stephan Sigg},
  doi          = {10.1145/3477601},
  journal      = {ACM Computing Surveys},
  number       = {9},
  pages        = {198:1–35},
  shortjournal = {ACM Comput. Surv.},
  title        = {Adversary models for mobile device authentication},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Ransomware mitigation in the modern era: A comprehensive
review, research challenges, and future directions. <em>CSUR</em>,
<em>54</em>(9), 197:1–36. (<a
href="https://doi.org/10.1145/3479393">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although ransomware has been around since the early days of personal computers, its sophistication and aggression have increased substantially over the years. Ransomware, as a type of malware to extort ransom payments from victims, has evolved to deliver payloads in different attack vectors and on multiple platforms, and creating repeated disruptions and financial loss to many victims. Many studies have performed ransomware analysis and/or presented detection, defense, or prevention techniques for ransomware. However, because the ransomware landscape has evolved aggressively, many of those studies have become less relevant or even outdated. Previous surveys on anti-ransomware studies have compared the methods and results of the studies they surveyed, but none of those surveys has attempted to critique on the internal or external validity of those studies. In this survey, we first examined the up-to-date concept of ransomware, and listed the inadequacies in current ransomware research. We then proposed a set of unified metrics to evaluate published studies on ransomware mitigation, and applied the metrics to 118 such studies to comprehensively compare and contrast their pros and cons, with the attempt to evaluate their relative strengths and weaknesses. Finally, we forecast the future trends of ransomware evolution, and propose future research directions.},
  archive      = {J_CSUR},
  author       = {Timothy McIntosh and A. S. M. Kayes and Yi-Ping Phoebe Chen and Alex Ng and Paul Watters},
  doi          = {10.1145/3479393},
  journal      = {ACM Computing Surveys},
  number       = {9},
  pages        = {197:1–36},
  shortjournal = {ACM Comput. Surv.},
  title        = {Ransomware mitigation in the modern era: A comprehensive review, research challenges, and future directions},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Opportunities and challenges in code search tools.
<em>CSUR</em>, <em>54</em>(9), 196:1–40. (<a
href="https://doi.org/10.1145/3480027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Code search is a core software engineering task. Effective code search tools can help developers substantially improve their software development efficiency and effectiveness. In recent years, many code search studies have leveraged different techniques, such as deep learning and information retrieval approaches, to retrieve expected code from a large-scale codebase. However, there is a lack of a comprehensive comparative summary of existing code search approaches. To understand the research trends in existing code search studies, we systematically reviewed 81 relevant studies. We investigated the publication trends of code search studies, analyzed key components, such as codebase, query, and modeling technique used to build code search tools, and classified existing tools into focusing on supporting seven different search tasks. Based on our findings, we identified a set of outstanding challenges in existing studies and a research roadmap for future code search research.},
  archive      = {J_CSUR},
  author       = {Chao Liu and Xin Xia and David Lo and Cuiyun Gao and Xiaohu Yang and John Grundy},
  doi          = {10.1145/3480027},
  journal      = {ACM Computing Surveys},
  number       = {9},
  pages        = {196:1–40},
  shortjournal = {ACM Comput. Surv.},
  title        = {Opportunities and challenges in code search tools},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Computing blindfolded on data homomorphically encrypted
under multiple keys: A survey. <em>CSUR</em>, <em>54</em>(9), 195:1–37.
(<a href="https://doi.org/10.1145/3477139">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With capability of performing computations on encrypted data without needing the secret key, homomorphic encryption (HE) is a promising cryptographic technique that makes outsourced computations secure and privacy-preserving. A decade after Gentry’s breakthrough discovery of how we might support arbitrary computations on encrypted data, many studies followed and improved various aspects of HE, such as faster bootstrapping and ciphertext packing. However, the topic of how to support secure computations on ciphertexts encrypted under multiple keys does not receive enough attention. This capability is crucial in many application scenarios where data owners want to engage in joint computations and are preferred to protect their sensitive data under their own secret keys. Enabling this capability is a non-trivial task. In this article, we present a comprehensive survey of the state-of-the-art multi-key techniques and schemes that target different systems and threat models. In particular, we review recent constructions based on Threshold Homomorphic Encryption (ThHE) and Multi-Key Homomorphic Encryption (MKHE). We analyze these cryptographic techniques and schemes based on a new secure outsourced computation model and examine their complexities. We share lessons learned and draw observations for designing better schemes with reduced overheads.},
  archive      = {J_CSUR},
  author       = {Asma Aloufi and Peizhao Hu and Yongsoo Song and Kristin Lauter},
  doi          = {10.1145/3477139},
  journal      = {ACM Computing Surveys},
  number       = {9},
  pages        = {195:1–37},
  shortjournal = {ACM Comput. Surv.},
  title        = {Computing blindfolded on data homomorphically encrypted under multiple keys: A survey},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A survey on client throughput prediction algorithms in wired
and wireless networks. <em>CSUR</em>, <em>54</em>(9), 194:1–33. (<a
href="https://doi.org/10.1145/3477204">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Network communication has become a part of everyday life, and the interconnection among devices and people will increase even more in the future. Nevertheless, prediction of Quality of Service parameters, particularly throughput, is quite a challenging task. In this survey, we provide an extensive insight into the literature on Transmission Control Protocol throughput prediction. The goal is to provide an overview of the used techniques and to elaborate on open aspects and white spots in this area. We assessed more than 35 approaches spanning from equation-based over various time smoothing to modern learning and location smoothing methods. In addition, different error functions for the evaluation of the approaches as well as publicly available recording tools and datasets are discussed. To conclude, we point out open challenges especially looking in the area of moving mobile network clients. The use of throughput prediction not only enables a more efficient use of the available bandwidth, the techniques shown in this work also result in more robust and stable communication.},
  archive      = {J_CSUR},
  author       = {Josef Schmid and Alfred Höss and Björn W. Schuller},
  doi          = {10.1145/3477204},
  journal      = {ACM Computing Surveys},
  number       = {9},
  pages        = {194:1–33},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey on client throughput prediction algorithms in wired and wireless networks},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A survey on uncertainty estimation in deep learning
classification systems from a bayesian perspective. <em>CSUR</em>,
<em>54</em>(9), 193:1–35. (<a
href="https://doi.org/10.1145/3477140">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Decision-making based on machine learning systems, especially when this decision-making can affect human lives, is a subject of maximum interest in the Machine Learning community. It is, therefore, necessary to equip these systems with a means of estimating uncertainty in the predictions they emit in order to help practitioners make more informed decisions. In the present work, we introduce the topic of uncertainty estimation, and we analyze the peculiarities of such estimation when applied to classification systems. We analyze different methods that have been designed to provide classification systems based on deep learning with mechanisms for measuring the uncertainty of their predictions. We will take a look at how this uncertainty can be modeled and measured using different approaches, as well as practical considerations of different applications of uncertainty. Moreover, we review some of the properties that should be borne in mind when developing such metrics. All in all, the present survey aims at providing a pragmatic overview of the estimation of uncertainty in classification systems that can be very useful for both academic research and deep learning practitioners.},
  archive      = {J_CSUR},
  author       = {José Mena and Oriol Pujol and Jordi Vitrià},
  doi          = {10.1145/3477140},
  journal      = {ACM Computing Surveys},
  number       = {9},
  pages        = {193:1–35},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey on uncertainty estimation in deep learning classification systems from a bayesian perspective},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Gotta CAPTCHA ’em all: A survey of 20 years of the
human-or-computer dilemma. <em>CSUR</em>, <em>54</em>(9), 192:1–33. (<a
href="https://doi.org/10.1145/3477142">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A recent study has found that malicious bots generated nearly a quarter of overall website traffic in 2019 [102]. These malicious bots perform activities such as price and content scraping, account creation and takeover, credit card fraud, denial of service, and so on. Thus, they represent a serious threat to all businesses in general, but are especially troublesome for e-commerce, travel, and financial services. One of the most common defense mechanisms against bots abusing online services is the introduction of Completely Automated Public Turing test to tell Computers and Humans Apart (CAPTCHA), so it is extremely important to understand which CAPTCHA schemes have been designed and their actual effectiveness against the ever-evolving bots. To this end, this work provides an overview of the current state-of-the-art in the field of CAPTCHA schemes and defines a new classification that includes all the emerging schemes. In addition, for each identified CAPTCHA category, the most successful attack methods are summarized by also describing how CAPTCHA schemes evolved to resist bot attacks, and discussing the limitations of different CAPTCHA schemes from the security, usability, and compatibility point of view. Finally, an assessment of the open issues, challenges, and opportunities for further study is provided, paving the road toward the design of the next-generation secure and user-friendly CAPTCHA schemes.},
  archive      = {J_CSUR},
  author       = {Meriem Guerar and Luca Verderame and Mauro Migliardi and Francesco Palmieri and Alessio Merlo},
  doi          = {10.1145/3477142},
  journal      = {ACM Computing Surveys},
  number       = {9},
  pages        = {192:1–33},
  shortjournal = {ACM Comput. Surv.},
  title        = {Gotta CAPTCHA ’Em all: A survey of 20 years of the human-or-computer dilemma},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Computing graph neural networks: A survey from algorithms to
accelerators. <em>CSUR</em>, <em>54</em>(9), 191:1–38. (<a
href="https://doi.org/10.1145/3477141">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph Neural Networks (GNNs) have exploded onto the machine learning scene in recent years owing to their capability to model and learn from graph-structured data. Such an ability has strong implications in a wide variety of fields whose data are inherently relational, for which conventional neural networks do not perform well. Indeed, as recent reviews can attest, research in the area of GNNs has grown rapidly and has lead to the development of a variety of GNN algorithm variants as well as to the exploration of ground-breaking applications in chemistry, neurology, electronics, or communication networks, among others. At the current stage research, however, the efficient processing of GNNs is still an open challenge for several reasons. Besides of their novelty, GNNs are hard to compute due to their dependence on the input graph, their combination of dense and very sparse operations, or the need to scale to huge graphs in some applications. In this context, this article aims to make two main contributions. On the one hand, a review of the field of GNNs is presented from the perspective of computing. This includes a brief tutorial on the GNN fundamentals, an overview of the evolution of the field in the last decade, and a summary of operations carried out in the multiple phases of different GNN algorithm variants. On the other hand, an in-depth analysis of current software and hardware acceleration schemes is provided, from which a hardware-software, graph-aware, and communication-centric vision for GNN accelerators is distilled.},
  archive      = {J_CSUR},
  author       = {Sergi Abadal and Akshay Jain and Robert Guirado and Jorge López-Alonso and Eduard Alarcón},
  doi          = {10.1145/3477141},
  journal      = {ACM Computing Surveys},
  number       = {9},
  pages        = {191:1–38},
  shortjournal = {ACM Comput. Surv.},
  title        = {Computing graph neural networks: A survey from algorithms to accelerators},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Efficiency and effectiveness of web application
vulnerability detection approaches: A review. <em>CSUR</em>,
<em>54</em>(9), 190:1–35. (<a
href="https://doi.org/10.1145/3474553">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most existing surveys and reviews on web application vulnerability detection (WAVD) approaches focus on comparing and summarizing the approaches’ technical details. Although some studies have analyzed the efficiency and effectiveness of specific methods, there is a lack of a comprehensive and systematic analysis of the efficiency and effectiveness of various WAVD approaches. We conducted a systematic literature review (SLR) of WAVD approaches and analyzed their efficiency and effectiveness. We identified 105 primary studies out of 775 WAVD articles published between January 2008 and June 2019. Our study identified 10 categories of artifacts analyzed by the WAVD approaches and 8 categories of WAVD meta-approaches for analyzing the artifacts. Our study’s results also summarized and compared the effectiveness and efficiency of different WAVD approaches on detecting specific categories of web application vulnerabilities and which web applications and test suites are used to evaluate the WAVD approaches. To our knowledge, this is the first SLR that focuses on summarizing the effectiveness and efficiencies of WAVD approaches. Our study results can help security engineers choose and compare WAVD tools and help researchers identify research gaps.},
  archive      = {J_CSUR},
  author       = {Bing Zhang and Jingyue Li and Jiadong Ren and Guoyan Huang},
  doi          = {10.1145/3474553},
  journal      = {ACM Computing Surveys},
  number       = {9},
  pages        = {190:1–35},
  shortjournal = {ACM Comput. Surv.},
  title        = {Efficiency and effectiveness of web application vulnerability detection approaches: A review},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A survey on concept drift in process mining. <em>CSUR</em>,
<em>54</em>(9), 189:1–38. (<a
href="https://doi.org/10.1145/3472752">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Concept drift in process mining (PM) is a challenge as classical methods assume processes are in a steady-state, i.e., events share the same process version. We conducted a systematic literature review on the intersection of these areas, and thus, we review concept drift in PM and bring forward a taxonomy of existing techniques for drift detection and online PM for evolving environments. Existing works depict that (i) PM still primarily focuses on offline analysis, and (ii) the assessment of concept drift techniques in processes is cumbersome due to the lack of common evaluation protocol, datasets, and metrics.},
  archive      = {J_CSUR},
  author       = {Denise Maria Vecino Sato and Sheila Cristiana De Freitas and Jean Paul Barddal and Edson Emilio Scalabrin},
  doi          = {10.1145/3472752},
  journal      = {ACM Computing Surveys},
  number       = {9},
  pages        = {189:1–38},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey on concept drift in process mining},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Service computing for industry 4.0: State of the art,
challenges, and research opportunities. <em>CSUR</em>, <em>54</em>(9),
188:1–38. (<a href="https://doi.org/10.1145/3478680">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advances in the large-scale adoption of information and communication technologies in manufacturing processes, known as Industry 4.0 or Smart Manufacturing, provide us a window into how the manufacturing sector will evolve in the coming decades. As a result of these initiatives, manufacturing firms have started to integrate a series of emerging technologies into their processes that will change the way products are designed, manufactured, and consumed. This article provides a comprehensive review of how service-oriented computing is being employed to develop the required software infrastructure for Industry 4.0 and identifies the major challenges and research opportunities that ensue. Particular attention is paid to the microservices architecture, which is increasingly recognized as offering a promising approach for developing innovative industrial applications. This literature review is based on the current state of the art on service computing for Industry 4.0 as described in a large corpus of recently published research papers, which helped us to identify and explore a series of challenges and opportunities for the development of this emerging technology frontier, with the goal of facilitating its widespread adoption.},
  archive      = {J_CSUR},
  author       = {Frank Siqueira and Joseph G. Davis},
  doi          = {10.1145/3478680},
  journal      = {ACM Computing Surveys},
  number       = {9},
  pages        = {188:1–38},
  shortjournal = {ACM Comput. Surv.},
  title        = {Service computing for industry 4.0: State of the art, challenges, and research opportunities},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Screen content quality assessment: Overview, benchmark, and
beyond. <em>CSUR</em>, <em>54</em>(9), 187:1–36. (<a
href="https://doi.org/10.1145/3470970">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Screen content, which is often computer-generated, has many characteristics distinctly different from conventional camera-captured natural scene content. Such characteristic differences impose major challenges to the corresponding content quality assessment, which plays a critical role to ensure and improve the final user-perceived quality of experience (QoE) in various screen content communication and networking systems. Quality assessment of such screen content has attracted much attention recently, primarily because the screen content grows explosively due to the prevalence of cloud and remote computing applications in recent years, and due to the fact that conventional quality assessment methods can not handle such content effectively. As the most technology-oriented part of QoE modeling, image/video content/media quality assessment has drawn wide attention from researchers, and a large amount of work has been carried out to tackle the problem of screen content quality assessment. This article is intended to provide a systematic and timely review on this emerging research field, including (1) background of natural scene vs. screen content quality assessment; (2) characteristics of natural scene vs. screen content; (3) overview of screen content quality assessment methodologies and measures; (4) relevant benchmarks and comprehensive evaluation of the state-of-the-art; (5) discussions on generalizations from screen content quality assessment to QoE assessment, and other techniques beyond QoE assessment; and (6) unresolved challenges and promising future research directions. Throughout this article, we focus on the differences and similarities between screen content and conventional natural scene content. We expect that this review article shall provide readers with an overview of the background, history, recent progress, and future of the emerging screen content quality assessment research.},
  archive      = {J_CSUR},
  author       = {Xiongkuo Min and Ke Gu and Guangtao Zhai and Xiaokang Yang and Wenjun Zhang and Patrick Le Callet and Chang Wen Chen},
  doi          = {10.1145/3470970},
  journal      = {ACM Computing Surveys},
  number       = {9},
  pages        = {187:1–36},
  shortjournal = {ACM Comput. Surv.},
  title        = {Screen content quality assessment: Overview, benchmark, and beyond},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). MEC-enabled 5G use cases: A survey on security
vulnerabilities and countermeasures. <em>CSUR</em>, <em>54</em>(9),
186:1–37. (<a href="https://doi.org/10.1145/3474552">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The future of mobile and internet technologies are manifesting advancements beyond the existing scope of science. The concepts of automated driving, augmented-reality, and machine-type-communication are quite sophisticated and require an elevation of the current mobile infrastructure for launching. The fifth-generation (5G) mobile technology serves as the solution, though it lacks a proximate networking infrastructure to satisfy the service guarantees. Multi-access Edge Computing (MEC) envisages such an edge computing platform. In this survey, we are revealing security vulnerabilities of key 5G-based use cases deployed in the MEC context. Probable security flows of each case are specified, while countermeasures are proposed for mitigating them.},
  archive      = {J_CSUR},
  author       = {Pasika Ranaweera and Anca Jurcut and Madhusanka Liyanage},
  doi          = {10.1145/3474552},
  journal      = {ACM Computing Surveys},
  number       = {9},
  pages        = {186:1–37},
  shortjournal = {ACM Comput. Surv.},
  title        = {MEC-enabled 5G use cases: A survey on security vulnerabilities and countermeasures},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Design guidelines for cooperative UAV-supported services and
applications. <em>CSUR</em>, <em>54</em>(9), 185:1–35. (<a
href="https://doi.org/10.1145/3467964">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Internet of Things (IoT) systems have advanced greatly in the past few years, especially with the support of Machine Learning (ML) and Artificial Intelligence (AI) solutions. Numerous AI-supported IoT devices are playing a significant role in providing complex and user-specific smart city services. Given the multitude of heterogeneous wireless networks, the plethora of computer and storage architectures and paradigms, and the abundance of mobile and vehicular IoT devices, true smart city experiences are only attainable through a cooperative intelligent and secure IoT framework. This article provides an extensive study on different cooperative systems and envisions a cooperative solution that supports the integration and collaboration among both centralized and distributed systems, in which intelligent AI-supported IoT devices such as smart UAVs provide support in the data collection, processing and service provisioning process. Moreover, secure and collaborative decentralized solutions such as Blockchain are considered in the service provisioning process to enable enhanced privacy and authentication features for IoT applications. As such, user-specific complex services and applications within smart city environments will be delivered and made available in a timely, secure, and efficient manner.},
  archive      = {J_CSUR},
  author       = {Ismaeel Al Ridhawi and Ouns Bouachir and Moayad Aloqaily and Azzedine Boukerche},
  doi          = {10.1145/3467964},
  journal      = {ACM Computing Surveys},
  number       = {9},
  pages        = {185:1–35},
  shortjournal = {ACM Comput. Surv.},
  title        = {Design guidelines for cooperative UAV-supported services and applications},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A survey on haptic technologies for mobile augmented
reality. <em>CSUR</em>, <em>54</em>(9), 184:1–35. (<a
href="https://doi.org/10.1145/3465396">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Augmented reality (AR) applications have gained much research and industry attention. Moreover, the mobile counterpart—mobile augmented reality (MAR) is one of the most explosive growth areas for AR applications in the mobile environment (e.g., smartphones). The technical improvements in the hardware of smartphones, tablets, and smart-glasses provide an advantage for the wide use of mobile AR in the real world and experience these AR applications anywhere. However, the mobile nature of MAR applications can limit users’ interaction capabilities, such as input and haptic feedback. In this survey, we analyze current research issues in the area of human-computer interaction for haptic technologies in MAR scenarios. The survey first presents human sensing capabilities and their applicability in AR applications. We classify haptic devices into two groups according to the triggered sense: cutaneous/tactile : touch, active surfaces, and mid-air; kinesthetic : manipulandum, grasp, and exoskeleton. Due to MAR applications’ mobile capabilities, we mainly focus our study on wearable haptic devices for each category and their AR possibilities. To conclude, we discuss the future paths that haptic feedback should follow for MAR applications and their challenges.},
  archive      = {J_CSUR},
  author       = {Carlos Bermejo and Pan Hui},
  doi          = {10.1145/3465396},
  journal      = {ACM Computing Surveys},
  number       = {9},
  pages        = {184:1–35},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey on haptic technologies for mobile augmented reality},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Weight-sharing neural architecture search: A battle to
shrink the optimization gap. <em>CSUR</em>, <em>54</em>(9), 183:1–37.
(<a href="https://doi.org/10.1145/3473330">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural architecture search (NAS) has attracted increasing attention. In recent years, individual search methods have been replaced by weight-sharing search methods for higher search efficiency, but the latter methods often suffer lower instability. This article provides a literature review on these methods and owes this issue to the optimization gap . From this perspective, we summarize existing approaches into several categories according to their efforts in bridging the gap, and we analyze both advantages and disadvantages of these methodologies. Finally, we share our opinions on the future directions of NAS and AutoML. Due to the expertise of the authors, this article mainly focuses on the application of NAS to computer vision problems.},
  archive      = {J_CSUR},
  author       = {Lingxi Xie and Xin Chen and Kaifeng Bi and Longhui Wei and Yuhui Xu and Lanfei Wang and Zhengsu Chen and An Xiao and Jianlong Chang and Xiaopeng Zhang and Qi Tian},
  doi          = {10.1145/3473330},
  journal      = {ACM Computing Surveys},
  number       = {9},
  pages        = {183:1–37},
  shortjournal = {ACM Comput. Surv.},
  title        = {Weight-sharing neural architecture search: A battle to shrink the optimization gap},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A survey on data-driven network intrusion detection.
<em>CSUR</em>, <em>54</em>(9), 182:1–36. (<a
href="https://doi.org/10.1145/3472753">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data-driven network intrusion detection (NID) has a tendency towards minority attack classes compared to normal traffic. Many datasets are collected in simulated environments rather than real-world networks. These challenges undermine the performance of intrusion detection machine learning models by fitting machine learning models to unrepresentative “sandbox” datasets. This survey presents a taxonomy with eight main challenges and explores common datasets from 1999 to 2020. Trends are analyzed on the challenges in the past decade and future directions are proposed on expanding NID into cloud-based environments, devising scalable models for large network data, and creating labeled datasets collected in real-world networks.},
  archive      = {J_CSUR},
  author       = {Dylan Chou and Meng Jiang},
  doi          = {10.1145/3472753},
  journal      = {ACM Computing Surveys},
  number       = {9},
  pages        = {182:1–36},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey on data-driven network intrusion detection},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Computer vision for autonomous UAV flight safety: An
overview and a vision-based safe landing pipeline example.
<em>CSUR</em>, <em>54</em>(9), 181:1–37. (<a
href="https://doi.org/10.1145/3472288">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent years have seen an unprecedented spread of Unmanned Aerial Vehicles (UAVs, or “drones”), which are highly useful for both civilian and military applications. Flight safety is a crucial issue in UAV navigation, having to ensure accurate compliance with recently legislated rules and regulations. The emerging use of autonomous drones and UAV swarms raises additional issues, making it necessary to transfuse safety- and regulations-awareness to relevant algorithms and architectures. Computer vision plays a pivotal role in such autonomous functionalities. Although the main aspects of autonomous UAV technologies (e.g., path planning, navigation control, landing control, mapping and localization, target detection/tracking) are already mature and well-covered, ensuring safe flying in the vicinity of crowds, avoidance of passing over persons, or guaranteed emergency landing capabilities in case of malfunctions, are generally treated as an afterthought when designing autonomous UAV platforms for unstructured environments. This fact is reflected in the fragmentary coverage of the above issues in current literature. This overview attempts to remedy this situation, from the point of view of computer vision. It examines the field from multiple aspects, including regulations across the world and relevant current technologies. Finally, since very few attempts have been made so far towards a complete UAV safety flight and landing pipeline, an example computer vision-based UAV flight safety pipeline is introduced, taking into account all issues present in current autonomous drones. The content is relevant to any kind of autonomous drone flight (e.g., for movie/TV production, news-gathering, search and rescue, surveillance, inspection, mapping, wildlife monitoring, crowd monitoring/management), making this a topic of broad interest.},
  archive      = {J_CSUR},
  author       = {Efstratios Kakaletsis and Charalampos Symeonidis and Maria Tzelepi and Ioannis Mademlis and Anastasios Tefas and Nikos Nikolaidis and Ioannis Pitas},
  doi          = {10.1145/3472288},
  journal      = {ACM Computing Surveys},
  number       = {9},
  pages        = {181:1–37},
  shortjournal = {ACM Comput. Surv.},
  title        = {Computer vision for autonomous UAV flight safety: An overview and a vision-based safe landing pipeline example},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A survey of deep active learning. <em>CSUR</em>,
<em>54</em>(9), 180:1–40. (<a
href="https://doi.org/10.1145/3472291">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Active learning (AL) attempts to maximize a model’s performance gain while annotating the fewest samples possible. Deep learning (DL) is greedy for data and requires a large amount of data supply to optimize a massive number of parameters if the model is to learn how to extract high-quality features. In recent years, due to the rapid development of internet technology, we have entered an era of information abundance characterized by massive amounts of available data. As a result, DL has attracted significant attention from researchers and has been rapidly developed. Compared with DL, however, researchers have a relatively low interest in AL. This is mainly because before the rise of DL, traditional machine learning requires relatively few labeled samples, meaning that early AL is rarely according the value it deserves. Although DL has made breakthroughs in various fields, most of this success is due to a large number of publicly available annotated datasets. However, the acquisition of a large number of high-quality annotated datasets consumes a lot of manpower, making it unfeasible in fields that require high levels of expertise (such as speech recognition, information extraction, medical images, etc.). Therefore, AL is gradually coming to receive the attention it is due. It is therefore natural to investigate whether AL can be used to reduce the cost of sample annotation while retaining the powerful learning capabilities of DL. As a result of such investigations, deep active learning (DeepAL) has emerged. Although research on this topic is quite abundant, there has not yet been a comprehensive survey of DeepAL-related works; accordingly, this article aims to fill this gap. We provide a formal classification method for the existing work, along with a comprehensive and systematic overview. In addition, we also analyze and summarize the development of DeepAL from an application perspective. Finally, we discuss the confusion and problems associated with DeepAL and provide some possible development directions.},
  archive      = {J_CSUR},
  author       = {Pengzhen Ren and Yun Xiao and Xiaojun Chang and Po-Yao Huang and Zhihui Li and Brij B. Gupta and Xiaojiang Chen and Xin Wang},
  doi          = {10.1145/3472291},
  journal      = {ACM Computing Surveys},
  number       = {9},
  pages        = {180:1–40},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey of deep active learning},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). FPGA/GPU-based acceleration for frequent itemsets mining: A
comprehensive review. <em>CSUR</em>, <em>54</em>(9), 179:1–35. (<a
href="https://doi.org/10.1145/3472289">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In data mining, Frequent Itemsets Mining is a technique used in several domains with notable results. However, the large volume of data in modern datasets increases the processing time of Frequent Itemset Mining algorithms, making them unsuitable for many real-world applications. Accordingly, proposing new methods for Frequent Itemset Mining to obtain frequent itemsets in a realistic amount of time is still an open problem. A successful alternative is to employ hardware acceleration using Graphics Processing Units (GPU) and Field Programmable Gates Arrays (FPGA). In this article, a comprehensive review of the state of the art of Frequent Itemsets Mining hardware acceleration is presented. Several approaches (FPGA and GPU based) were contrasted to show their weaknesses and strengths. This survey gathers the most relevant and the latest research efforts for improving the performance of Frequent Itemsets Mining regarding algorithms advances and modern development platforms. Furthermore, this survey organizes the current research on Frequent Itemsets Mining from the hardware perspective considering the source of the data, the development platform, and the baseline algorithm.},
  archive      = {J_CSUR},
  author       = {Lázaro Bustio-Martínez and René Cumplido and Martín Letras and Raudel Hernández-León and Claudia Feregrino-Uribe and José Hernández-Palancar},
  doi          = {10.1145/3472289},
  journal      = {ACM Computing Surveys},
  number       = {9},
  pages        = {179:1–35},
  shortjournal = {ACM Comput. Surv.},
  title        = {FPGA/GPU-based acceleration for frequent itemsets mining: A comprehensive review},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Firmware over-the-air programming techniques for IoT
networks - a survey. <em>CSUR</em>, <em>54</em>(9), 178:1–36. (<a
href="https://doi.org/10.1145/3472292">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The devices forming Internet of Things (IoT) networks need to be re-programmed over the air, so that new features are added, software bugs or security vulnerabilities are resolved, and their applications can be re-purposed. The limitations of IoT devices, such as installation in locations with limited physical access, resource-constrained nature, large scale, and high heterogeneity, should be taken into consideration for designing an efficient and reliable pipeline for over-the-air programming (OTAP). In this work, we present a survey of OTAP techniques, which can be applied to IoT networks. We highlight the main challenges and limitations of OTAP for IoT devices and analyze the essential steps of the firmware update process, along with different approaches and techniques that implement them. In addition, we discuss schemes that focus on securing the OTAP process. Finally, we present a collection of state-of-the-art open-source and commercial platforms that integrate secure and reliable OTAP.},
  archive      = {J_CSUR},
  author       = {Konstantinos Arakadakis and Pavlos Charalampidis and Antonis Makrogiannakis and Alexandros Fragkiadakis},
  doi          = {10.1145/3472292},
  journal      = {ACM Computing Surveys},
  number       = {9},
  pages        = {178:1–36},
  shortjournal = {ACM Comput. Surv.},
  title        = {Firmware over-the-air programming techniques for IoT networks - a survey},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A survey on deep learning for human activity recognition.
<em>CSUR</em>, <em>54</em>(8), 177:1–34. (<a
href="https://doi.org/10.1145/3472290">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human activity recognition is a key to a lot of applications such as healthcare and smart home. In this study, we provide a comprehensive survey on recent advances and challenges in human activity recognition (HAR) with deep learning. Although there are many surveys on HAR, they focused mainly on the taxonomy of HAR and reviewed the state-of-the-art HAR systems implemented with conventional machine learning methods. Recently, several works have also been done on reviewing studies that use deep models for HAR, whereas these works cover few deep models and their variants. There is still a need for a comprehensive and in-depth survey on HAR with recently developed deep learning methods.},
  archive      = {J_CSUR},
  author       = {Fuqiang Gu and Mu-Huan Chung and Mark Chignell and Shahrokh Valaee and Baoding Zhou and Xue Liu},
  doi          = {10.1145/3472290},
  journal      = {ACM Computing Surveys},
  number       = {8},
  pages        = {177:1–34},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey on deep learning for human activity recognition},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A systematic literature review on virtual machine
consolidation. <em>CSUR</em>, <em>54</em>(8), 176:1–38. (<a
href="https://doi.org/10.1145/3470972">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Virtual machine consolidation has been a widely explored topic in recent years due to Cloud Data Centers’ effect on global energy consumption. Thus, academia and companies made efforts to achieve green computing, reducing energy consumption to minimize environmental impact. By consolidating Virtual Machines into a fewer number of Physical Machines, resource provisioning mechanisms can shutdown idle Physical Machines to reduce energy consumption and improve resource utilization. However, there is a tradeoff between reducing energy consumption while assuring the Quality of Service established on the Service Level Agreement. This work introduces a Systematic Literature Review of one year of advances in virtual machine consolidation. It provides a discussion on methods used in each step of the virtual machine consolidation, a classification of papers according to their contribution, and a quantitative and qualitative analysis of datasets, scenarios, and metrics.},
  archive      = {J_CSUR},
  author       = {Alexandre H. T. Dias and Luiz. H. A. Correia and Neumar Malheiros},
  doi          = {10.1145/3470972},
  journal      = {ACM Computing Surveys},
  number       = {8},
  pages        = {176:1–38},
  shortjournal = {ACM Comput. Surv.},
  title        = {A systematic literature review on virtual machine consolidation},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). AutoML to date and beyond: Challenges and opportunities.
<em>CSUR</em>, <em>54</em>(8), 175:1–36. (<a
href="https://doi.org/10.1145/3470918">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As big data becomes ubiquitous across domains, and more and more stakeholders aspire to make the most of their data, demand for machine learning tools has spurred researchers to explore the possibilities of automated machine learning (AutoML). AutoML tools aim to make machine learning accessible for non-machine learning experts (domain experts), to improve the efficiency of machine learning, and to accelerate machine learning research. But although automation and efficiency are among AutoML’s main selling points, the process still requires human involvement at a number of vital steps, including understanding the attributes of domain-specific data, defining prediction problems, creating a suitable training dataset, and selecting a promising machine learning technique. These steps often require a prolonged back-and-forth that makes this process inefficient for domain experts and data scientists alike and keeps so-called AutoML systems from being truly automatic. In this review article, we introduce a new classification system for AutoML systems, using a seven-tiered schematic to distinguish these systems based on their level of autonomy. We begin by describing what an end-to-end machine learning pipeline actually looks like, and which subtasks of the machine learning pipeline have been automated so far. We highlight those subtasks that are still done manually—generally by a data scientist—and explain how this limits domain experts’ access to machine learning. Next, we introduce our novel level-based taxonomy for AutoML systems and define each level according to the scope of automation support provided. Finally, we lay out a roadmap for the future, pinpointing the research required to further automate the end-to-end machine learning pipeline and discussing important challenges that stand in the way of this ambitious goal.},
  archive      = {J_CSUR},
  author       = {Shubhra Kanti Karmaker (“Santu”) and Md. Mahadi Hassan and Micah J. Smith and Lei Xu and Chengxiang Zhai and Kalyan Veeramachaneni},
  doi          = {10.1145/3470918},
  journal      = {ACM Computing Surveys},
  number       = {8},
  pages        = {175:1–36},
  shortjournal = {ACM Comput. Surv.},
  title        = {AutoML to date and beyond: Challenges and opportunities},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Evolutionary large-scale multi-objective optimization: A
survey. <em>CSUR</em>, <em>54</em>(8), 174:1–34. (<a
href="https://doi.org/10.1145/3470971">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-objective evolutionary algorithms (MOEAs) have shown promising performance in solving various optimization problems, but their performance may deteriorate drastically when tackling problems containing a large number of decision variables. In recent years, much effort been devoted to addressing the challenges brought by large-scale multi-objective optimization problems. This article presents a comprehensive survey of stat-of-the-art MOEAs for solving large-scale multi-objective optimization problems. We start with a categorization of these MOEAs into decision variable grouping based, decision space reduction based, and novel search strategy based MOEAs, discussing their strengths and weaknesses. Then, we review the benchmark problems for performance assessment and a few important and emerging applications of MOEAs for large-scale multi-objective optimization. Last, we discuss some remaining challenges and future research directions of evolutionary large-scale multi-objective optimization.},
  archive      = {J_CSUR},
  author       = {Ye Tian and Langchun Si and Xingyi Zhang and Ran Cheng and Cheng He and Kay Chen Tan and Yaochu Jin},
  doi          = {10.1145/3470971},
  journal      = {ACM Computing Surveys},
  number       = {8},
  pages        = {174:1–34},
  shortjournal = {ACM Comput. Surv.},
  title        = {Evolutionary large-scale multi-objective optimization: A survey},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Human factors in phishing attacks: A systematic literature
review. <em>CSUR</em>, <em>54</em>(8), 173:1–35. (<a
href="https://doi.org/10.1145/3469886">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Phishing is the fraudulent attempt to obtain sensitive information by disguising oneself as a trustworthy entity in digital communication. It is a type of cyber attack often successful because users are not aware of their vulnerabilities or are unable to understand the risks. This article presents a systematic literature review conducted to draw a “big picture” of the most important research works performed on human factors and phishing. The analysis of the retrieved publications, framed along the research questions addressed in the systematic literature review, helps in understanding how human factors should be considered to defend against phishing attacks. Future research directions are also highlighted.},
  archive      = {J_CSUR},
  author       = {Giuseppe Desolda and Lauren S. Ferro and Andrea Marrella and Tiziana Catarci and Maria Francesca Costabile},
  doi          = {10.1145/3469886},
  journal      = {ACM Computing Surveys},
  number       = {8},
  pages        = {173:1–35},
  shortjournal = {ACM Comput. Surv.},
  title        = {Human factors in phishing attacks: A systematic literature review},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A survey of automated programming hint generation: The HINTS
framework. <em>CSUR</em>, <em>54</em>(8), 172:1–27. (<a
href="https://doi.org/10.1145/3469885">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automated tutoring systems offer the flexibility and scalability necessary to facilitate the provision of high-quality and universally accessible programming education. To realise the potential of these systems, recent work has proposed a diverse range of techniques for automatically generating feedback in the form of hints to assist students with programming exercises. This article integrates these apparently disparate approaches into a coherent whole. Specifically, it emphasises that all hint techniques can be understood as a series of simpler components with similar properties. Using this insight, it presents a simple framework for describing such techniques, the Hint Iteration by Narrow-down and Transformation Steps framework, and surveys recent work in the context of this framework. Findings from this survey include that (1) hint techniques share similar properties, which can be used to visualise them together, (2) the individual steps of hint techniques should be considered when designing and evaluating hint systems, (3) more work is required to develop and improve evaluation methods, and (4) interesting relationships, such as the link between automated hints and data-driven evaluation, should be further investigated. Ultimately, this article aims to facilitate the development, extension, and comparison of automated programming hint techniques to maximise their educational potential.},
  archive      = {J_CSUR},
  author       = {Jessica McBroom and Irena Koprinska and Kalina Yacef},
  doi          = {10.1145/3469885},
  journal      = {ACM Computing Surveys},
  number       = {8},
  pages        = {172:1–27},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey of automated programming hint generation: The HINTS framework},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A systematic review of API evolution literature.
<em>CSUR</em>, <em>54</em>(8), 171:1–36. (<a
href="https://doi.org/10.1145/3470133">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent software advances have led to an expansion of the development and usage of application programming interfaces (APIs). From millions of Android packages (APKs) available on Google Store to millions of open-source packages available in Maven, PyPI, and npm, APIs have become an integral part of software development. Like any software artifact, software APIs evolve and suffer from this evolution. Prior research has uncovered many challenges to the development, usage, and evolution of APIs. While some challenges have been studied and solved, many remain. These challenges are scattered in the literature, which hides advances and cloaks the remaining challenges. In this systematic literature review on APIs and API evolution, we uncover and describe publication trends and trending topics. We compile common research goals, evaluation methods, metrics, and subjects. We summarize the current state-of-the-art and outline known existing challenges as well as new challenges uncovered during this review. We conclude that the main remaining challenges related to APIs and API evolution are (1) automatically identifying and leveraging factors that drive API changes, (2) creating and using uniform benchmarks for research evaluation, and (3) understanding the impact of API evolution on API developers and users with respect to various programming languages.},
  archive      = {J_CSUR},
  author       = {Maxime Lamothe and Yann-Gaël Guéhéneuc and Weiyi Shang},
  doi          = {10.1145/3470133},
  journal      = {ACM Computing Surveys},
  number       = {8},
  pages        = {171:1–36},
  shortjournal = {ACM Comput. Surv.},
  title        = {A systematic review of API evolution literature},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Machine learning at the network edge: A survey.
<em>CSUR</em>, <em>54</em>(8), 170:1–37. (<a
href="https://doi.org/10.1145/3469029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Resource-constrained IoT devices, such as sensors and actuators, have become ubiquitous in recent years. This has led to the generation of large quantities of data in real-time, which is an appealing target for AI systems. However, deploying machine learning models on such end-devices is nearly impossible. A typical solution involves offloading data to external computing systems (such as cloud servers) for further processing but this worsens latency, leads to increased communication costs, and adds to privacy concerns. To address this issue, efforts have been made to place additional computing devices at the edge of the network, i.e., close to the IoT devices where the data is generated. Deploying machine learning systems on such edge computing devices alleviates the above issues by allowing computations to be performed close to the data sources. This survey describes major research efforts where machine learning systems have been deployed at the edge of computer networks, focusing on the operational aspects including compression techniques, tools, frameworks, and hardware used in successful applications of intelligent edge systems.},
  archive      = {J_CSUR},
  author       = {M. G. Sarwar Murshed and Christopher Murphy and Daqing Hou and Nazar Khan and Ganesh Ananthanarayanan and Faraz Hussain},
  doi          = {10.1145/3469029},
  journal      = {ACM Computing Surveys},
  number       = {8},
  pages        = {170:1–37},
  shortjournal = {ACM Comput. Surv.},
  title        = {Machine learning at the network edge: A survey},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Deep neural network–based enhancement for image and video
streaming systems: A survey and future directions. <em>CSUR</em>,
<em>54</em>(8), 169:1–30. (<a
href="https://doi.org/10.1145/3469094">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Internet-enabled smartphones and ultra-wide displays are transforming a variety of visual apps spanning from on-demand movies and 360°  videos to video-conferencing and live streaming. However, robustly delivering visual content under fluctuating networking conditions on devices of diverse capabilities remains an open problem. In recent years, advances in the field of deep learning on tasks such as super-resolution and image enhancement have led to unprecedented performance in generating high-quality images from low-quality ones, a process we refer to as neural enhancement. In this article, we survey state-of-the-art content delivery systems that employ neural enhancement as a key component in achieving both fast response time and high visual quality. We first present the components and architecture of existing content delivery systems, highlighting their challenges and motivating the use of neural enhancement models as a countermeasure. We then cover the deployment challenges of these models and analyze existing systems and their design decisions in efficiently overcoming these technical challenges. Additionally, we underline the key trends and common approaches across systems that target diverse use-cases. Finally, we present promising future directions based on the latest insights from deep learning research to further boost the quality of experience of content delivery systems.},
  archive      = {J_CSUR},
  author       = {Royson Lee and Stylianos I. Venieris and Nicholas D. Lane},
  doi          = {10.1145/3469094},
  journal      = {ACM Computing Surveys},
  number       = {8},
  pages        = {169:1–30},
  shortjournal = {ACM Comput. Surv.},
  title        = {Deep neural network–based enhancement for image and video streaming systems: A survey and future directions},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A survey on blockchain interoperability: Past, present, and
future trends. <em>CSUR</em>, <em>54</em>(8), 168:1–41. (<a
href="https://doi.org/10.1145/3471140">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Blockchain interoperability is emerging as one of the crucial features of blockchain technology, but the knowledge necessary for achieving it is fragmented. This fact makes it challenging for academics and the industry to achieve interoperability among blockchains seamlessly. Given this new domain’s novelty and potential, we conduct a literature review on blockchain interoperability by collecting 284 papers and 120 grey literature documents, constituting a corpus of 404 documents. From those 404 documents, we systematically analyzed and discussed 102 documents, including peer-reviewed papers and grey literature. Our review classifies studies in three categories: Public Connectors, Blockchain of Blockchains, and Hybrid Connectors. Each category is further divided into sub-categories based on defined criteria. We classify 67 existing solutions in one sub-category using the Blockchain Interoperability Framework, providing a holistic overview of blockchain interoperability. Our findings show that blockchain interoperability has a much broader spectrum than cryptocurrencies and cross-chain asset transfers. Finally, this article discusses supporting technologies, standards, use cases, open challenges, and future research directions, paving the way for research in the area.},
  archive      = {J_CSUR},
  author       = {Rafael Belchior and André Vasconcelos and Sérgio Guerreiro and Miguel Correia},
  doi          = {10.1145/3471140},
  journal      = {ACM Computing Surveys},
  number       = {8},
  pages        = {168:1–41},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey on blockchain interoperability: Past, present, and future trends},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Data analytics for air travel data: A survey and new
perspectives. <em>CSUR</em>, <em>54</em>(8), 167:1–35. (<a
href="https://doi.org/10.1145/3469028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {From the start, the airline industry has remarkably connected countries all over the world through rapid long-distance transportation, helping people overcome geographic barriers. Consequently, this has ushered in substantial economic growth, both nationally and internationally. The airline industry produces vast amounts of data, capturing a diverse set of information about their operations, including data related to passengers, freight, flights, and much more. Analyzing air travel data can advance the understanding of airline market dynamics, allowing companies to provide customized, efficient, and safe transportation services. Due to big data challenges in such a complex environment, the benefits of drawing insights from the air travel data in the airline industry have not yet been fully explored. This article aims to survey various components and corresponding proposed data analysis methodologies that have been identified as essential to the inner workings of the airline industry. We introduce existing data sources commonly used in the papers surveyed and summarize their availability. Finally, we discuss several potential research directions to better harness airline data in the future. We anticipate this study to be used as a comprehensive reference for both members of the airline industry and academic scholars with an interest in airline research.},
  archive      = {J_CSUR},
  author       = {Haiman Tian and Maria Presa-Reyes and Yudong Tao and Tianyi Wang and Samira Pouyanfar and Alonso Miguel and Steven Luis and Mei-Ling Shyu and Shu-Ching Chen and Sundaraja Sitharama Iyengar},
  doi          = {10.1145/3469028},
  journal      = {ACM Computing Surveys},
  number       = {8},
  pages        = {167:1–35},
  shortjournal = {ACM Comput. Surv.},
  title        = {Data analytics for air travel data: A survey and new perspectives},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Transcriptional regulatory network topology with
applications to bio-inspired networking: A survey. <em>CSUR</em>,
<em>54</em>(8), 166:1–36. (<a
href="https://doi.org/10.1145/3468266">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The advent of the edge computing network paradigm places the computational and storage resources away from the data centers and closer to the edge of the network largely comprising the heterogeneous IoT devices collecting huge volumes of data. This paradigm has led to considerable improvement in network latency and bandwidth usage over the traditional cloud-centric paradigm. However, the next generation networks continue to be stymied by their inability to achieve adaptive, energy-efficient, timely data transfer in a dynamic and failure-prone environment—the very optimization challenges that are dealt with by biological networks as a consequence of millions of years of evolution. The transcriptional regulatory network (TRN) is a biological network whose innate topological robustness is a function of its underlying graph topology. In this article, we survey these properties of TRN and the metrics derived therefrom that lend themselves to the design of smart networking protocols and architectures. We then review a body of literature on bio-inspired networking solutions that leverage the stated properties of TRN. Finally, we present a vision for specific aspects of TRNs that may inspire future research directions in the fields of large-scale social and communication networks.},
  archive      = {J_CSUR},
  author       = {Satyaki Roy and Preetam Ghosh and Nirnay Ghosh and Sajal K. Das},
  doi          = {10.1145/3468266},
  journal      = {ACM Computing Surveys},
  number       = {8},
  pages        = {166:1–36},
  shortjournal = {ACM Comput. Surv.},
  title        = {Transcriptional regulatory network topology with applications to bio-inspired networking: A survey},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Towards augmented reality driven human-city interaction:
Current research on mobile headsets and future challenges.
<em>CSUR</em>, <em>54</em>(8), 165:1–38. (<a
href="https://doi.org/10.1145/3467963">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Interaction design for Augmented Reality (AR) is gaining attention from both academia and industry. This survey discusses 260 articles (68.8\% of articles published between 2015–2019) to review the field of human interaction in connected cities with emphasis on augmented reality-driven interaction. We provide an overview of Human-City Interaction and related technological approaches, followed by reviewing the latest trends of information visualization, constrained interfaces, and embodied interaction for AR headsets. We highlight under-explored issues in interface design and input techniques that warrant further research and conjecture that AR with complementary Conversational User Interfaces (CUIs) is a crucial enabler for ubiquitous interaction with immersive systems in smart cities. Our work helps researchers understand the current potential and future needs of AR in Human-City Interaction.},
  archive      = {J_CSUR},
  author       = {Lik-Hang Lee and Tristan Braud and Simo Hosio and Pan Hui},
  doi          = {10.1145/3467963},
  journal      = {ACM Computing Surveys},
  number       = {8},
  pages        = {165:1–38},
  shortjournal = {ACM Comput. Surv.},
  title        = {Towards augmented reality driven human-city interaction: Current research on mobile headsets and future challenges},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A survey on end-user robot programming. <em>CSUR</em>,
<em>54</em>(8), 164:1–36. (<a
href="https://doi.org/10.1145/3466819">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As robots interact with a broader range of end-users, end-user robot programming has helped democratize robot programming by empowering end-users who may not have experience in robot programming to customize robots to meet their individual contextual needs. This article surveys work on end-user robot programming, with a focus on end-user program specification. It describes the primary domains, programming phases, and design choices represented by the end-user robot programming literature. The survey concludes by highlighting open directions for further investigation to enhance and widen the reach of end-user robot programming systems.},
  archive      = {J_CSUR},
  author       = {Gopika Ajaykumar and Maureen Steele and Chien-Ming Huang},
  doi          = {10.1145/3466819},
  journal      = {ACM Computing Surveys},
  number       = {8},
  pages        = {164:1–36},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey on end-user robot programming},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Measuring presence in virtual environments: A survey.
<em>CSUR</em>, <em>54</em>(8), 163:1–37. (<a
href="https://doi.org/10.1145/3466817">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The effectiveness of a virtual reality experience is strongly affected by the sense of presence of the users involved. This article reviews the different definitions of presence and the main proposed methods to measure it through the analysis of 1,214 papers published in the past 30 years. From the analysis of 239 user studies, we found that 85.8\% used subjective measures, 11.7\% used a combination of subjective and objective measures, while 2.5\% used only objective measures. We also identified, from the studies reviewed, 29 main factors to evoke presence in virtual environments, grouped into four categories: Engagement, Personal Characteristics, Interaction Fidelity, and Display Fidelity.},
  archive      = {J_CSUR},
  author       = {Vinicius Souza and Anderson Maciel and Luciana Nedel and Regis Kopper},
  doi          = {10.1145/3466817},
  journal      = {ACM Computing Surveys},
  number       = {8},
  pages        = {163:1–37},
  shortjournal = {ACM Comput. Surv.},
  title        = {Measuring presence in virtual environments: A survey},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A unified survey of treatment effect heterogeneity modelling
and uplift modelling. <em>CSUR</em>, <em>54</em>(8), 162:1–36. (<a
href="https://doi.org/10.1145/3466818">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A central question in many fields of scientific research is to determine how an outcome is affected by an action, i.e., to estimate the causal effect or treatment effect of an action. In recent years, in areas such as personalised healthcare, sociology, and online marketing, a need has emerged to estimate heterogeneous treatment effects with respect to individuals of different characteristics. To meet this need, two major approaches have been taken: treatment effect heterogeneity modelling and uplifting modelling. Researchers and practitioners in different communities have developed algorithms based on these approaches to estimate the heterogeneous treatment effects. In this article, we present a unified view of these two seemingly disconnected yet closely related approaches under the potential outcome framework. We provide a structured survey of existing methods following either of the two approaches, emphasising their inherent connections and using unified notation to facilitate comparisons. We also review the main applications of the surveyed methods in personalised marketing, personalised medicine, and sociology. Finally, we summarise and discuss the available software packages and source codes in terms of their coverage of different methods and applicability to different datasets, and we provide general guidelines for method selection.},
  archive      = {J_CSUR},
  author       = {Weijia Zhang and Jiuyong Li and Lin Liu},
  doi          = {10.1145/3466818},
  journal      = {ACM Computing Surveys},
  number       = {8},
  pages        = {162:1–36},
  shortjournal = {ACM Comput. Surv.},
  title        = {A unified survey of treatment effect heterogeneity modelling and uplift modelling},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Evolutionary machine learning: A survey. <em>CSUR</em>,
<em>54</em>(8), 161:1–35. (<a
href="https://doi.org/10.1145/3467477">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Evolutionary Computation (EC) approaches are inspired by nature and solve optimization problems in a stochastic manner. They can offer a reliable and effective approach to address complex problems in real-world applications. EC algorithms have recently been used to improve the performance of Machine Learning (ML) models and the quality of their results. Evolutionary approaches can be used in all three parts of ML: preprocessing (e.g., feature selection and resampling), learning (e.g., parameter setting, membership functions, and neural network topology), and postprocessing (e.g., rule optimization, decision tree/support vectors pruning, and ensemble learning). This article investigates the role of EC algorithms in solving different ML challenges. We do not provide a comprehensive review of evolutionary ML approaches here; instead, we discuss how EC algorithms can contribute to ML by addressing conventional challenges of the artificial intelligence and ML communities. We look at the contributions of EC to ML in nine sub-fields: feature selection, resampling, classifiers, neural networks, reinforcement learning, clustering, association rule mining, and ensemble methods. For each category, we discuss evolutionary machine learning in terms of three aspects: problem formulation, search mechanisms, and fitness value computation. We also consider open issues and challenges that should be addressed in future work.},
  archive      = {J_CSUR},
  author       = {Akbar Telikani and Amirhessam Tahmassebi and Wolfgang Banzhaf and Amir H. Gandomi},
  doi          = {10.1145/3467477},
  journal      = {ACM Computing Surveys},
  number       = {8},
  pages        = {161:1–35},
  shortjournal = {ACM Comput. Surv.},
  title        = {Evolutionary machine learning: A survey},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Integrated blockchain and cloud computing systems: A
systematic survey, solutions, and challenges. <em>CSUR</em>,
<em>54</em>(8), 160:1–36. (<a
href="https://doi.org/10.1145/3456628">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cloud computing is a network model of on-demand access for sharing configurable computing resource pools. Compared with conventional service architectures, cloud computing introduces new security challenges in secure service management and control, privacy protection, data integrity protection in distributed databases, data backup, and synchronization. Blockchain can be leveraged to address these challenges, partly due to the underlying characteristics such as transparency, traceability, decentralization, security, immutability, and automation. We present a comprehensive survey of how blockchain is applied to provide security services in the cloud computing model and we analyze the research trends of blockchain-related techniques in current cloud computing models. During the reviewing, we also briefly investigate how cloud computing can affect blockchain, especially about the performance improvements that cloud computing can provide for the blockchain. Our contributions include the following: (i) summarizing the possible architectures and models of the integration of blockchain and cloud computing and the roles of cloud computing in blockchain; (ii) classifying and discussing recent, relevant works based on different blockchain-based security services in the cloud computing model; (iii) simply investigating what improvements cloud computing can provide for the blockchain; (iv) introducing the current development status of the industry/major cloud providers in the direction of combining cloud and blockchain; (v) analyzing the main barriers and challenges of integrated blockchain and cloud computing systems; and (vi) providing recommendations for future research and improvement on the integration of blockchain and cloud systems.},
  archive      = {J_CSUR},
  author       = {Jinglin Zou and Debiao He and Sherali Zeadally and Neeraj Kumar and Huaqun Wang and Kkwang Raymond Choo},
  doi          = {10.1145/3456628},
  journal      = {ACM Computing Surveys},
  number       = {8},
  pages        = {160:1–36},
  shortjournal = {ACM Comput. Surv.},
  title        = {Integrated blockchain and cloud computing systems: A systematic survey, solutions, and challenges},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Adversarial perturbation defense on deep neural networks.
<em>CSUR</em>, <em>54</em>(8), 159:1–36. (<a
href="https://doi.org/10.1145/3465397">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neural networks (DNNs) have been verified to be easily attacked by well-designed adversarial perturbations. Image objects with small perturbations that are imperceptible to human eyes can induce DNN-based image class classifiers towards making erroneous predictions with high probability. Adversarial perturbations can also fool real-world machine learning systems and transfer between different architectures and datasets. Recently, defense methods against adversarial perturbations have become a hot topic and attracted much attention. A large number of works have been put forward to defend against adversarial perturbations, enhancing DNN robustness against potential attacks, or interpreting the origin of adversarial perturbations. In this article, we provide a comprehensive survey on classical and state-of-the-art defense methods by illuminating their main concepts, in-depth algorithms, and fundamental hypotheses regarding the origin of adversarial perturbations. In addition, we further discuss potential directions of this domain for future researchers.},
  archive      = {J_CSUR},
  author       = {Xingwei Zhang and Xiaolong Zheng and Wenji Mao},
  doi          = {10.1145/3465397},
  journal      = {ACM Computing Surveys},
  number       = {8},
  pages        = {159:1–36},
  shortjournal = {ACM Comput. Surv.},
  title        = {Adversarial perturbation defense on deep neural networks},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A survey on applications of artificial intelligence in
fighting against COVID-19. <em>CSUR</em>, <em>54</em>(8), 158:1–32. (<a
href="https://doi.org/10.1145/3465398">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The COVID-19 pandemic caused by the SARS-CoV-2 virus has spread rapidly worldwide, leading to a global outbreak. Most governments, enterprises, and scientific research institutions are participating in the COVID-19 struggle to curb the spread of the pandemic. As a powerful tool against COVID-19, artificial intelligence (AI) technologies are widely used in combating this pandemic. In this survey, we investigate the main scope and contributions of AI in combating COVID-19 from the aspects of disease detection and diagnosis, virology and pathogenesis, drug and vaccine development, and epidemic and transmission prediction. In addition, we summarize the available data and resources that can be used for AI-based COVID-19 research. Finally, the main challenges and potential directions of AI in fighting against COVID-19 are discussed. Currently, AI mainly focuses on medical image inspection, genomics, drug development, and transmission prediction, and thus AI still has great potential in this field. This survey presents medical and AI researchers with a comprehensive view of the existing and potential applications of AI technology in combating COVID-19 with the goal of inspiring researchers to continue to maximize the advantages of AI and big data to fight COVID-19.},
  archive      = {J_CSUR},
  author       = {Jianguo Chen and Kenli Li and Zhaolei Zhang and Keqin Li and Philip S. Yu},
  doi          = {10.1145/3465398},
  journal      = {ACM Computing Surveys},
  number       = {8},
  pages        = {158:1–32},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey on applications of artificial intelligence in fighting against COVID-19},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A survey on generative adversarial networks: Variants,
applications, and training. <em>CSUR</em>, <em>54</em>(8), 157:1–49. (<a
href="https://doi.org/10.1145/3463475">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Generative Models have gained considerable attention in unsupervised learning via a new and practical framework called Generative Adversarial Networks (GAN) due to their outstanding data generation capability. Many GAN models have been proposed, and several practical applications have emerged in various domains of computer vision and machine learning. Despite GANs excellent success, there are still obstacles to stable training. The problems are Nash equilibrium, internal covariate shift, mode collapse, vanishing gradient, and lack of proper evaluation metrics. Therefore, stable training is a crucial issue in different applications for the success of GANs. Herein, we survey several training solutions proposed by different researchers to stabilize GAN training. We discuss (I) the original GAN model and its modified versions, (II) a detailed analysis of various GAN applications in different domains, and (III) a detailed study about the various GAN training obstacles as well as training solutions. Finally, we reveal several issues as well as research outlines to the topic.},
  archive      = {J_CSUR},
  author       = {Abdul Jabbar and Xi Li and Bourahla Omar},
  doi          = {10.1145/3463475},
  journal      = {ACM Computing Surveys},
  number       = {8},
  pages        = {157:1–49},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey on generative adversarial networks: Variants, applications, and training},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). One-way delay measurement from traditional networks to SDN:
A survey. <em>CSUR</em>, <em>54</em>(7), 156:1–35. (<a
href="https://doi.org/10.1145/3466167">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We expose the state of the art in the topic of one-way delay measurement in both traditional and software-defined networks. A representative range of standard mechanisms and recent research works, including OpenFlow and Programming Protocol-independent Packet Processors (P4)-based schemes, are covered. We classify them, discuss their advantages and drawbacks, and compare them according to their application environment, accuracy, cost, and robustness. The discussion extends to the reuse of traditional schemes in software-defined networks and the benefits and limitations of the latter with respect to reducing the overhead of network wide measurements. We conclude with a summary of learned lessons and open challenges for future work.},
  archive      = {J_CSUR},
  author       = {Djalel Chefrour},
  doi          = {10.1145/3466167},
  journal      = {ACM Computing Surveys},
  number       = {7},
  pages        = {156:1–35},
  shortjournal = {ACM Comput. Surv.},
  title        = {One-way delay measurement from traditional networks to SDN: A survey},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Two-dimensional stroke gesture recognition: A survey.
<em>CSUR</em>, <em>54</em>(7), 155:1–36. (<a
href="https://doi.org/10.1145/3465400">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The expansion of touch-sensitive technologies, ranging from smartwatches to wall screens, triggered a wider use of gesture-based user interfaces and encouraged researchers to invent recognizers that are fast and accurate for end-users while being simple enough for practitioners. Since the pioneering work on two-dimensional (2D) stroke gesture recognition based on feature extraction and classification, numerous approaches and techniques have been introduced to classify uni- and multi-stroke gestures, satisfying various properties of articulation-, rotation-, scale-, and translation-invariance. As the domain abounds in different recognizers, it becomes difficult for the practitioner to choose the right recognizer, depending on the application and for the researcher to understand the state-of-the-art. To address these needs, a targeted literature review identified 16 significant 2D stroke gesture recognizers that were submitted to a descriptive analysis discussing their algorithm, performance, and properties, and a comparative analysis discussing their similarities and differences. Finally, some opportunities for expanding 2D stroke gesture recognition are drawn from these analyses.},
  archive      = {J_CSUR},
  author       = {Nathan Magrofuoco and Paolo Roselli and Jean Vanderdonckt},
  doi          = {10.1145/3465400},
  journal      = {ACM Computing Surveys},
  number       = {7},
  pages        = {155:1–36},
  shortjournal = {ACM Comput. Surv.},
  title        = {Two-dimensional stroke gesture recognition: A survey},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A survey on session-based recommender systems.
<em>CSUR</em>, <em>54</em>(7), 154:1–38. (<a
href="https://doi.org/10.1145/3465401">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommender systems (RSs) have been playing an increasingly important role for informed consumption, services, and decision-making in the overloaded information era and digitized economy. In recent years, session-based recommender systems (SBRSs) have emerged as a new paradigm of RSs. Different from other RSs such as content-based RSs and collaborative filtering-based RSs that usually model long-term yet static user preferences, SBRSs aim to capture short-term but dynamic user preferences to provide more timely and accurate recommendations sensitive to the evolution of their session contexts. Although SBRSs have been intensively studied, neither unified problem statements for SBRSs nor in-depth elaboration of SBRS characteristics and challenges are available. It is also unclear to what extent SBRS challenges have been addressed and what the overall research landscape of SBRSs is. This comprehensive review of SBRSs addresses the above aspects by exploring in depth the SBRS entities (e.g., sessions), behaviours (e.g., users’ clicks on items), and their properties (e.g., session length). We propose a general problem statement of SBRSs, summarize the diversified data characteristics and challenges of SBRSs, and define a taxonomy to categorize the representative SBRS research. Finally, we discuss new research opportunities in this exciting and vibrant area.},
  archive      = {J_CSUR},
  author       = {Shoujin Wang and Longbing Cao and Yan Wang and Quan Z. Sheng and Mehmet A. Orgun and Defu Lian},
  doi          = {10.1145/3465401},
  journal      = {ACM Computing Surveys},
  number       = {7},
  pages        = {154:1–38},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey on session-based recommender systems},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A comprehensive review and a taxonomy proposal of team
formation problems. <em>CSUR</em>, <em>54</em>(7), 153:1–33. (<a
href="https://doi.org/10.1145/3465399">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With a growing interest in high-performing work teams and how to form them, a new computational challenge, denominated Team Formation Problem (TFP), has emerged. After almost two decades of research on this problem, many works continue to raise particular conceptions of what a TFP is. Any new practitioner, unfamiliar with the problem, may be hindered in discerning what is essential and what is particular in each proposal. Until now, there was a lack of a document serving as a guide, synthesizing and framing what has been done to date. In this review, we mainly introduce two things: (1) a taxonomy proposal for the TFPs and (2) the description of the main components of a TFP. Additionally, we present and discuss some applications, complexity, and resolution methods. Finally, we conclude by describing some perspectives on this topic for future studies, where we give some insight into open problems and research opportunities. The main goal of this review is to facilitate the generalization of research, identify knowledge gaps, and support the development of a theory for the TFP.},
  archive      = {J_CSUR},
  author       = {Julio Juárez and Cipriano (Pano) Santos and Carlos A. Brizuela},
  doi          = {10.1145/3465399},
  journal      = {ACM Computing Surveys},
  number       = {7},
  pages        = {153:1–33},
  shortjournal = {ACM Comput. Surv.},
  title        = {A comprehensive review and a taxonomy proposal of team formation problems},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Persistent memory: A survey of programming support and
implementations. <em>CSUR</em>, <em>54</em>(7), 152:1–37. (<a
href="https://doi.org/10.1145/3465402">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The recent rise of byte-addressable non-volatile memory technologies is blurring the dichotomy between memory and storage. In particular, they allow programmers to have direct access to persistent data instead of relying on traditional interfaces, such as file and database systems. However, they also bring new challenges, as a failure may render the program in an unrecoverable and inconsistent state. Consequently, a lot of effort has been put by both industry and academia into making the task of programming with such memories easier while, at the same time, efficient from the runtime perspective. This survey summarizes such a body of research, from the abstractions to the implementation level. As persistent memory is starting to appear commercially, the state-of-the-art research condensed here will help investigators to quickly stay up to date while also motivating others to pursue research in the field.},
  archive      = {J_CSUR},
  author       = {Alexandro Baldassin and João Barreto and Daniel Castro and Paolo Romano},
  doi          = {10.1145/3465402},
  journal      = {ACM Computing Surveys},
  number       = {7},
  pages        = {152:1–37},
  shortjournal = {ACM Comput. Surv.},
  title        = {Persistent memory: A survey of programming support and implementations},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Edge learning: The enabling technology for distributed big
data analytics in the edge. <em>CSUR</em>, <em>54</em>(7), 151:1–36. (<a
href="https://doi.org/10.1145/3464419">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine Learning ( ML ) has demonstrated great promise in various fields, e.g., self-driving, smart city, which are fundamentally altering the way individuals and organizations live, work, and interact. Traditional centralized learning frameworks require uploading all training data from different sources to a remote data server, which incurs significant communication overhead, service latency, and privacy issues. To further extend the frontiers of the learning paradigm, a new learning concept, namely, Edge Learning ( EL ) is emerging. It is complementary to the cloud-based methods for big data analytics by enabling distributed edge nodes to cooperatively training models and conduct inferences with their locally cached data. To explore the new characteristics and potential prospects of EL, we conduct a comprehensive survey of the recent research efforts on EL. Specifically, we first introduce the background and motivation. We then discuss the challenging issues in EL from the aspects of data, computation, and communication. Furthermore, we provide an overview of the enabling technologies for EL, including model training, inference, security guarantee, privacy protection, and incentive mechanism. Finally, we discuss future research opportunities on EL. We believe that this survey will provide a comprehensive overview of EL and stimulate fruitful future research in this field.},
  archive      = {J_CSUR},
  author       = {Jie Zhang and Zhihao Qu and Chenxi Chen and Haozhao Wang and Yufeng Zhan and Baoliu Ye and Song Guo},
  doi          = {10.1145/3464419},
  journal      = {ACM Computing Surveys},
  number       = {7},
  pages        = {151:1–36},
  shortjournal = {ACM Comput. Surv.},
  title        = {Edge learning: The enabling technology for distributed big data analytics in the edge},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Beyond multimedia authoring: On the need for mulsemedia
authoring tools. <em>CSUR</em>, <em>54</em>(7), 150:1–31. (<a
href="https://doi.org/10.1145/3464422">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The mulsemedia (Multiple Sensorial Media (MulSeMedia)) concept has been explored to provide users with new sensations using other senses beyond sight and hearing. The demand for producing such applications has motivated various studies in the mulsemedia authoring phase. To encourage researchers to explore new solutions for enhancing the mulsemedia authoring, this survey article reviews several mulsemedia authoring tools and proposals for representing sensory effects and their characteristics. The article also outlines a set of desirable features for mulsemedia authoring tools. Additionally, a multimedia background is discussed to support the proposed study in the mulsemedia field. Open challenges and future directions regarding the mulsemedia authoring phase are also discussed.},
  archive      = {J_CSUR},
  author       = {Douglas Paulo De Mattos and Débora C. Muchaluat-Saade and Gheorghita Ghinea},
  doi          = {10.1145/3464422},
  journal      = {ACM Computing Surveys},
  number       = {7},
  pages        = {150:1–31},
  shortjournal = {ACM Comput. Surv.},
  title        = {Beyond multimedia authoring: On the need for mulsemedia authoring tools},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A survey of parametric static analysis. <em>CSUR</em>,
<em>54</em>(7), 149:1–37. (<a
href="https://doi.org/10.1145/3464457">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Understanding program behaviors is important to verify program properties or to optimize programs. Static analysis is a widely used technique to approximate program behaviors via abstract interpretation. To evaluate the quality of static analysis, researchers have used three metrics: performance, precision, and soundness. The static analysis quality depends on the analysis techniques used, but the best combination of such techniques may be different for different programs. To find the best combination of analysis techniques for specific programs, recent work has proposed parametric static analysis . It considers static analysis as black-box parameterized by analysis parameters , which are techniques that may be configured without analysis details. We formally define the parametric static analysis, and we survey analysis parameters and their parameter selection in the literature. We also discuss open challenges and future directions of the parametric static analysis.},
  archive      = {J_CSUR},
  author       = {Jihyeok Park and Hongki Lee and Sukyoung Ryu},
  doi          = {10.1145/3464457},
  journal      = {ACM Computing Surveys},
  number       = {7},
  pages        = {149:1–37},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey of parametric static analysis},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A survey of smart contract formal specification and
verification. <em>CSUR</em>, <em>54</em>(7), 148:1–38. (<a
href="https://doi.org/10.1145/3464421">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A smart contract is a computer program that allows users to automate their actions on the blockchain platform. Given the significance of smart contracts in supporting important activities across industry sectors including supply chain, finance, legal, and medical services, there is a strong demand for verification and validation techniques. Yet, the vast majority of smart contracts lack any kind of formal specification, which is essential for establishing their correctness. In this survey, we investigate formal models and specifications of smart contracts presented in the literature and present a systematic overview to understand the common trends. We also discuss the current approaches used in verifying such property specifications and identify gaps with the hope to recognize promising directions for future work.},
  archive      = {J_CSUR},
  author       = {Palina Tolmach and Yi Li and Shang-Wei Lin and Yang Liu and Zengxiang Li},
  doi          = {10.1145/3464421},
  journal      = {ACM Computing Surveys},
  number       = {7},
  pages        = {148:1–38},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey of smart contract formal specification and verification},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A survey on resilience in the IoT: Taxonomy, classification,
and discussion of resilience mechanisms. <em>CSUR</em>, <em>54</em>(7),
147:1–39. (<a href="https://doi.org/10.1145/3462513">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Internet-of-Things (IoT) ecosystems tend to grow both in scale and complexity, as they consist of a variety of heterogeneous devices that span over multiple architectural IoT layers (e.g., cloud, edge, sensors). Further, IoT systems increasingly demand the resilient operability of services, as they become part of critical infrastructures. This leads to a broad variety of research works that aim to increase the resilience of these systems. In this article, we create a systematization of knowledge about existing scientific efforts of making IoT systems resilient. In particular, we first discuss the taxonomy and classification of resilience and resilience mechanisms and subsequently survey state-of-the-art resilience mechanisms that have been proposed by research work and are applicable to IoT. As part of the survey, we also discuss questions that focus on the practical aspects of resilience, e.g., which constraints resilience mechanisms impose on developers when designing resilient systems by incorporating a specific mechanism into IoT systems.},
  archive      = {J_CSUR},
  author       = {Christian Berger and Philipp Eichhammer and Hans P. Reiser and Jörg Domaschka and Franz J. Hauck and Gerhard Habiger},
  doi          = {10.1145/3462513},
  journal      = {ACM Computing Surveys},
  number       = {7},
  pages        = {147:1–39},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey on resilience in the IoT: Taxonomy, classification, and discussion of resilience mechanisms},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Semantic information retrieval on medical texts: Research
challenges, survey, and open issues. <em>CSUR</em>, <em>54</em>(7),
146:1–38. (<a href="https://doi.org/10.1145/3462476">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The explosive growth and widespread accessibility of medical information on the Internet have led to a surge of research activity in a wide range of scientific communities including health informatics and information retrieval (IR). One of the common concerns of this research, across these disciplines, is how to design either clinical decision support systems or medical search engines capable of providing adequate support for both novices (e.g., patients and their next-of-kin) and experts (e.g., physicians, clinicians) tackling complex tasks (e.g., search for diagnosis, search for a treatment). However, despite the significant multi-disciplinary research advances, current medical search systems exhibit low levels of performance. This survey provides an overview of the state of the art in the disciplines of IR and health informatics, and bridging these disciplines shows how semantic search techniques can facilitate medical IR. First,we will give a broad picture of semantic search and medical IR and then highlight the major scientific challenges. Second, focusing on the semantic gap challenge, we will discuss representative state-of-the-art work related to feature-based as well as semantic-based representation and matching models that support medical search systems. In addition to seminal works, we will present recent works that rely on research advancements in deep learning. Third, we make a thorough cross-model analysis and provide some findings and lessons learned. Finally, we discuss some open issues and possible promising directions for future research trends.},
  archive      = {J_CSUR},
  author       = {Lynda Tamine and Lorraine Goeuriot},
  doi          = {10.1145/3462476},
  journal      = {ACM Computing Surveys},
  number       = {7},
  pages        = {146:1–38},
  shortjournal = {ACM Comput. Surv.},
  title        = {Semantic information retrieval on medical texts: Research challenges, survey, and open issues},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Topic modeling using latent dirichlet allocation: A survey.
<em>CSUR</em>, <em>54</em>(7), 145:1–35. (<a
href="https://doi.org/10.1145/3462478">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We are not able to deal with a mammoth text corpus without summarizing them into a relatively small subset. A computational tool is extremely needed to understand such a gigantic pool of text. Probabilistic Topic Modeling discovers and explains the enormous collection of documents by reducing them in a topical subspace. In this work, we study the background and advancement of topic modeling techniques. We first introduce the preliminaries of the topic modeling techniques and review its extensions and variations, such as topic modeling over various domains, hierarchical topic modeling, word embedded topic models, and topic models in multilingual perspectives. Besides, the research work for topic modeling in a distributed environment, topic visualization approaches also have been explored. We also covered the implementation and evaluation techniques for topic models in brief. Comparison matrices have been shown over the experimental results of the various categories of topic modeling. Diverse technical challenges and future directions have been discussed.},
  archive      = {J_CSUR},
  author       = {Uttam Chauhan and Apurva Shah},
  doi          = {10.1145/3462478},
  journal      = {ACM Computing Surveys},
  number       = {7},
  pages        = {145:1–35},
  shortjournal = {ACM Comput. Surv.},
  title        = {Topic modeling using latent dirichlet allocation: A survey},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Temporal relation extraction in clinical texts: A systematic
review. <em>CSUR</em>, <em>54</em>(7), 144:1–36. (<a
href="https://doi.org/10.1145/3462475">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unstructured data in electronic health records, represented by clinical texts, are a vast source of healthcare information because they describe a patient&#39;s journey, including clinical findings, procedures, and information about the continuity of care. The publication of several studies on temporal relation extraction from clinical texts during the last decade and the realization of multiple shared tasks highlight the importance of this research theme. Therefore, we propose a review of temporal relation extraction in clinical texts. We analyzed 105 articles and verified that relations between events and document creation time, a coarse temporality type, were addressed with traditional machine learning–based models with few recent initiatives to push the state-of-the-art with deep learning–based models. For temporal relations between entities (event and temporal expressions) in the document, factors such as dataset imbalance because of candidate pair generation and task complexity directly affect the system&#39;s performance. The state-of-the-art resides on attention-based models, with contextualized word representations being fine-tuned for temporal relation extraction. However, further experiments and advances in the research topic are required until real-time clinical domain applications are released. Furthermore, most of the publications mainly reside on the same dataset, hindering the need for new annotation projects that provide datasets for different medical specialties, clinical text types, and even languages.},
  archive      = {J_CSUR},
  author       = {Yohan Bonescki Gumiel and Lucas Emanuel Silva e Oliveira and Vincent Claveau and Natalia Grabar and Emerson Cabrera Paraiso and Claudia Moro and Deborah Ribeiro Carvalho},
  doi          = {10.1145/3462475},
  journal      = {ACM Computing Surveys},
  number       = {7},
  pages        = {144:1–36},
  shortjournal = {ACM Comput. Surv.},
  title        = {Temporal relation extraction in clinical texts: A systematic review},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A survey of music visualization techniques. <em>CSUR</em>,
<em>54</em>(7), 143:1–29. (<a
href="https://doi.org/10.1145/3461835">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Music Information Research (MIR) comprises all the research topics involved in modeling and understanding music. Visualizations are frequently adopted to convey better understandings about music pieces, and the association of music with visual elements has been practiced historically and extensively. We investigated papers related to music visualization and organized the proposals into categories according to their most prominent aspects: their input features, the aspects visualized, the InfoVis technique(s) used, if interaction was provided, and users’ evaluations. The MIR and the InfoVis community can benefit by identifying trends and possible new research directions within the music visualization topic.},
  archive      = {J_CSUR},
  author       = {Hugo B. Lima and Carlos G. R. Dos Santos and Bianchi S. Meiguins},
  doi          = {10.1145/3461835},
  journal      = {ACM Computing Surveys},
  number       = {7},
  pages        = {143:1–29},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey of music visualization techniques},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Benchmarking quantum computers and the impact of quantum
noise. <em>CSUR</em>, <em>54</em>(7), 142:1–35. (<a
href="https://doi.org/10.1145/3464420">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Benchmarking is how the performance of a computing system is determined. Surprisingly, even for classical computers this is not a straightforward process. One must choose the appropriate benchmark and metrics to extract meaningful results. Different benchmarks test the system in different ways, and each individual metric may or may not be of interest. Choosing the appropriate approach is tricky. The situation is even more open ended for quantum computers, where there is a wider range of hardware, fewer established guidelines, and additional complicating factors. Notably, quantum noise significantly impacts performance and is difficult to model accurately. Here, we discuss benchmarking of quantum computers from a computer architecture perspective and provide numerical simulations highlighting challenges that suggest caution.},
  archive      = {J_CSUR},
  author       = {Salonik Resch and Ulya R. Karpuzcu},
  doi          = {10.1145/3464420},
  journal      = {ACM Computing Surveys},
  number       = {7},
  pages        = {142:1–35},
  shortjournal = {ACM Comput. Surv.},
  title        = {Benchmarking quantum computers and the impact of quantum noise},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Deep learning for medical anomaly detection – a survey.
<em>CSUR</em>, <em>54</em>(7), 141:1–37. (<a
href="https://doi.org/10.1145/3464423">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning–based medical anomaly detection is an important problem that has been extensively studied. Numerous approaches have been proposed across various medical application domains and we observe several similarities across these distinct applications. Despite this comparability, we observe a lack of structured organisation of these diverse research applications such that their advantages and limitations can be studied. The principal aim of this survey is to provide a thorough theoretical analysis of popular deep learning techniques in medical anomaly detection. In particular, we contribute a coherent and systematic review of state-of-the-art techniques, comparing and contrasting their architectural differences as well as training algorithms. Furthermore, we provide a comprehensive overview of deep model interpretation strategies that can be used to interpret model decisions. In addition, we outline the key limitations of existing deep medical anomaly detection techniques and propose key research directions for further investigation.},
  archive      = {J_CSUR},
  author       = {Tharindu Fernando and Harshala Gammulle and Simon Denman and Sridha Sridharan and Clinton Fookes},
  doi          = {10.1145/3464423},
  journal      = {ACM Computing Surveys},
  number       = {7},
  pages        = {141:1–37},
  shortjournal = {ACM Comput. Surv.},
  title        = {Deep learning for medical anomaly detection – a survey},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Text mining in cybersecurity: A systematic literature
review. <em>CSUR</em>, <em>54</em>(7), 140:1–36. (<a
href="https://doi.org/10.1145/3462477">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The growth of data volume has changed cybersecurity activities, demanding a higher level of automation. In this new cybersecurity landscape, text mining emerged as an alternative to improve the efficiency of the activities involving unstructured data. This article proposes a Systematic Literature Review ( SLR ) to present the application of text mining in the cybersecurity domain. Using a systematic protocol, we identified 2,196 studies, out of which 83 were summarized. As a contribution, we propose a taxonomy to demonstrate the different activities in the cybersecurity domain supported by text mining. We also detail the strategies evaluated in the application of text mining tasks and the use of neural networks to support activities involving unstructured data. The work also discusses text classification performance aiming its application in real-world solutions. The SLR also highlights open gaps for future research, such as the analysis of non-English content and the intensification in the usage of neural networks.},
  archive      = {J_CSUR},
  author       = {Luciano Ignaczak and Guilherme Goldschmidt and Cristiano André Da Costa and Rodrigo Da Rosa Righi},
  doi          = {10.1145/3462477},
  journal      = {ACM Computing Surveys},
  number       = {7},
  pages        = {140:1–36},
  shortjournal = {ACM Comput. Surv.},
  title        = {Text mining in cybersecurity: A systematic literature review},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Machine learning–based cyber attacks targeting on controlled
information: A survey. <em>CSUR</em>, <em>54</em>(7), 139:1–36. (<a
href="https://doi.org/10.1145/3465171">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stealing attack against controlled information, along with the increasing number of information leakage incidents, has become an emerging cyber security threat in recent years. Due to the booming development and deployment of advanced analytics solutions, novel stealing attacks utilize machine learning (ML) algorithms to achieve high success rate and cause a lot of damage. Detecting and defending against such attacks is challenging and urgent so governments, organizations, and individuals should attach great importance to the ML-based stealing attacks. This survey presents the recent advances in this new type of attack and corresponding countermeasures. The ML-based stealing attack is reviewed in perspectives of three categories of targeted controlled information, including controlled user activities, controlled ML model-related information, and controlled authentication information. Recent publications are summarized to generalize an overarching attack methodology and to derive the limitations and future directions of ML-based stealing attacks. Furthermore, countermeasures are proposed towards developing effective protections from three aspects—detection, disruption, and isolation.},
  archive      = {J_CSUR},
  author       = {Yuantian Miao and Chao Chen and Lei Pan and Qing-Long Han and Jun Zhang and Yang Xiang},
  doi          = {10.1145/3465171},
  journal      = {ACM Computing Surveys},
  number       = {7},
  pages        = {139:1–36},
  shortjournal = {ACM Comput. Surv.},
  title        = {Machine learning–based cyber attacks targeting on controlled information: A survey},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Centralized, distributed, and everything in between:
Reviewing access control solutions for the IoT. <em>CSUR</em>,
<em>54</em>(7), 138:1–34. (<a
href="https://doi.org/10.1145/3465170">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Internet of Things is taking hold in our everyday life. Regrettably, the security of IoT devices is often being overlooked. Among the vast array of security issues plaguing the emerging IoT, we decide to focus on access control, as privacy, trust, and other security properties cannot be achieved without controlled access. This article classifies IoT access control solutions from the literature according to their architecture (e.g., centralized, hierarchical, federated, distributed) and examines the suitability of each one for access control purposes. Our analysis concludes that important properties such as auditability and revocation are missing from many proposals while hierarchical and federated architectures are neglected by the community. Finally, we provide an architecture-based taxonomy and future research directions: a focus on hybrid architectures, usability, flexibility, privacy, and revocation schemes in serverless authorization.},
  archive      = {J_CSUR},
  author       = {Sophie Dramé-Maigné and Maryline Laurent and Laurent Castillo and Hervé Ganem},
  doi          = {10.1145/3465170},
  journal      = {ACM Computing Surveys},
  number       = {7},
  pages        = {138:1–34},
  shortjournal = {ACM Comput. Surv.},
  title        = {Centralized, distributed, and everything in between: Reviewing access control solutions for the IoT},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Affective automotive user interfaces–reviewing the state of
driver affect research and emotion regulation in the car. <em>CSUR</em>,
<em>54</em>(7), 137:1–26. (<a
href="https://doi.org/10.1145/3460938">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Affective technology offers exciting opportunities to improve road safety by catering to human emotions. Modern car interiors enable the contactless detection of user states, paving the way for a systematic promotion of safe driver behavior through emotion regulation. We review the current literature regarding the impact of emotions on driver behavior and analyze the state of emotion regulation approaches in the car. We summarize challenges for affective interaction in the form of technological hurdles and methodological considerations, as well as opportunities to improve road safety by reinstating drivers into an emotionally balanced state. The purpose of this review is to outline the community’s combined knowledge for interested researchers, to provide a focussed introduction for practitioners, raise awareness for cultural aspects, and to identify future directions for affective interaction in the car.},
  archive      = {J_CSUR},
  author       = {Michael Braun and Florian Weber and Florian Alt},
  doi          = {10.1145/3460938},
  journal      = {ACM Computing Surveys},
  number       = {7},
  pages        = {137:1–26},
  shortjournal = {ACM Comput. Surv.},
  title        = {Affective automotive user Interfaces–Reviewing the state of driver affect research and emotion regulation in the car},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). More than privacy: Adopting differential privacy in
game-theoretic mechanism design. <em>CSUR</em>, <em>54</em>(7),
136:1–37. (<a href="https://doi.org/10.1145/3460771">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The vast majority of artificial intelligence solutions are founded on game theory, and differential privacy is emerging as perhaps the most rigorous and widely adopted privacy paradigm in the field. However, alongside all the advancements made in both these fields, there is not a single application that is not still vulnerable to privacy violations, security breaches, or manipulation by adversaries. Our understanding of the interactions between differential privacy and game theoretic solutions is limited. Hence, we undertook a comprehensive review of literature in the field, finding that differential privacy has several advantageous properties that can make more of a contribution to game theory than just privacy protection. It can also be used to build heuristic models for game-theoretic solutions, to avert strategic manipulations, and to quantify the cost of privacy protection. With a focus on mechanism design, the aim of this article is to provide a new perspective on the currently held impossibilities in game theory, potential avenues to circumvent those impossibilities, and opportunities to improve the performance of game-theoretic solutions with differentially private techniques.},
  archive      = {J_CSUR},
  author       = {Lefeng Zhang and Tianqing Zhu and Ping Xiong and Wanlei Zhou and Philip S. Yu},
  doi          = {10.1145/3460771},
  journal      = {ACM Computing Surveys},
  number       = {7},
  pages        = {136:1–37},
  shortjournal = {ACM Comput. Surv.},
  title        = {More than privacy: Adopting differential privacy in game-theoretic mechanism design},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Towards interconnected blockchains: A comprehensive review
of the role of interoperability among disparate blockchains.
<em>CSUR</em>, <em>54</em>(7), 135:1–39. (<a
href="https://doi.org/10.1145/3460287">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unprecedented attention towards blockchain technology is serving as a game-changer in fostering the development of blockchain-enabled distinctive frameworks. However, fragmentation unleashed by its underlying concepts hinders different stakeholders from effectively utilizing blockchain-supported services, resulting in the obstruction of its wide-scale adoption. To explore synergies among the isolated frameworks requires comprehensively studying inter-blockchain communication approaches. These approaches broadly come under the umbrella of Blockchain Interoperability (BI) notion, as it can facilitate a novel paradigm of an integrated blockchain ecosystem that connects state-of-the-art disparate blockchains. Currently, there is a lack of studies that comprehensively review BI, which works as a stumbling block in its development. Therefore, this article aims to articulate potential of BI by reviewing it from diverse perspectives. Beginning with a glance of blockchain architecture fundamentals, this article discusses its associated platforms, taxonomy, and consensus mechanisms. Subsequently, it argues about BI’s requirement by exemplifying its potential opportunities and application areas. Concerning BI, an architecture seems to be a missing link. Hence, this article introduces a layered architecture for the effective development of protocols and methods for interoperable blockchains. Furthermore, this article proposes an in-depth BI research taxonomy and provides an insight into the state-of-the-art projects. Finally, it determines possible open challenges and future research in the domain.},
  archive      = {J_CSUR},
  author       = {Ankur Lohachab and Saurabh Garg and Byeong Kang and Muhammad Bilal Amin and Junmin Lee and Shiping Chen and Xiwei Xu},
  doi          = {10.1145/3460287},
  journal      = {ACM Computing Surveys},
  number       = {7},
  pages        = {135:1–39},
  shortjournal = {ACM Comput. Surv.},
  title        = {Towards interconnected blockchains: A comprehensive review of the role of interoperability among disparate blockchains},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Applying machine learning for sensor data analysis in
interactive systems: Common pitfalls of pragmatic use and ways to avoid
them. <em>CSUR</em>, <em>54</em>(6), 134:1–25. (<a
href="https://doi.org/10.1145/3459666">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the widespread proliferation of (miniaturized) sensing facilities and the massive growth and popularity of the field of machine learning (ML) research, new frontiers in automated sensor data analysis have been explored that lead to paradigm shifts in many application domains. In fact, many practitioners now employ and rely more and more on ML methods as integral part of their sensor data analysis workflows—thereby not necessarily being ML experts or having an interest in becoming one. The availability of toolkits that can readily be used by practitioners has led to immense popularity and widespread adoption and, in essence, pragmatic use of ML methods. ML having become mainstream helps pushing the core agenda of practitioners, yet it comes with the danger of misusing methods and as such running the risk of leading to misguiding if not flawed results. Based on years of observations in the ubiquitous and interactive computing domain that extensively relies on sensors and automated sensor data analysis, and on having taught and worked with numerous students in the field, in this article I advocate a considerate use of ML methods by practitioners, i.e., non-ML experts, and elaborate on pitfalls of an overly pragmatic use of ML techniques. The article not only identifies and illustrates the most common issues, it also offers ways and practical guidelines to avoid these, which shall help practitioners to benefit from employing ML in their core research domains and applications.},
  archive      = {J_CSUR},
  author       = {Thomas PlÖtz},
  doi          = {10.1145/3459666},
  journal      = {ACM Computing Surveys},
  number       = {6},
  pages        = {134:1–25},
  shortjournal = {ACM Comput. Surv.},
  title        = {Applying machine learning for sensor data analysis in interactive systems: Common pitfalls of pragmatic use and ways to avoid them},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Design guidelines on deep learning–based pedestrian
detection methods for supporting autonomous vehicles. <em>CSUR</em>,
<em>54</em>(6), 133:1–36. (<a
href="https://doi.org/10.1145/3460770">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intelligent transportation systems (ITS) enable transportation participants to communicate with each other by sending and receiving messages, so that they can be aware of their surroundings and facilitate efficient transportation through better decision making. As an important part of ITS, autonomous vehicles can bring massive benefits by reducing traffic accidents. Correspondingly, much effort has been paid to the task of pedestrian detection, which is a fundamental task for supporting autonomous vehicles. With the progress of computational power in recent years, adopting deep learning–based methods has become a trend for improving the performance of pedestrian detection. In this article, we present design guidelines on deep learning–based pedestrian detection methods for supporting autonomous vehicles. First, we will introduce classic backbone models and frameworks, and we will analyze the inherent attributes of pedestrian detection. Then, we will illustrate and analyze representative pedestrian detectors from occlusion handling, multi-scale feature extraction, multi-perspective data utilization, and hard negatives handling these four aspects. Last, we will discuss the developments and trends in this area, followed by some open challenges.},
  archive      = {J_CSUR},
  author       = {Azzedine Boukerche and Mingzhi Sha},
  doi          = {10.1145/3460770},
  journal      = {ACM Computing Surveys},
  number       = {6},
  pages        = {133:1–36},
  shortjournal = {ACM Comput. Surv.},
  title        = {Design guidelines on deep learning–based pedestrian detection methods for supporting autonomous vehicles},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Generative adversarial networks: A survey toward private and
secure applications. <em>CSUR</em>, <em>54</em>(6), 132:1–38. (<a
href="https://doi.org/10.1145/3459992">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generative Adversarial Networks (GANs) have promoted a variety of applications in computer vision and natural language processing, among others, due to its generative model’s compelling ability to generate realistic examples plausibly drawn from an existing distribution of samples. GAN not only provides impressive performance on data generation-based tasks but also stimulates fertilization for privacy and security oriented research because of its game theoretic optimization strategy. Unfortunately, there are no comprehensive surveys on GAN in privacy and security, which motivates this survey to summarize systematically. The existing works are classified into proper categories based on privacy and security functions, and this survey conducts a comprehensive analysis of their advantages and drawbacks. Considering that GAN in privacy and security is still at a very initial stage and has imposed unique challenges that are yet to be well addressed, this article also sheds light on some potential privacy and security applications with GAN and elaborates on some future research directions.},
  archive      = {J_CSUR},
  author       = {Zhipeng Cai and Zuobin Xiong and Honghui Xu and Peng Wang and Wei Li and Yi Pan},
  doi          = {10.1145/3459992},
  journal      = {ACM Computing Surveys},
  number       = {6},
  pages        = {132:1–38},
  shortjournal = {ACM Comput. Surv.},
  title        = {Generative adversarial networks: A survey toward private and secure applications},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A comprehensive survey of privacy-preserving federated
learning: A taxonomy, review, and future directions. <em>CSUR</em>,
<em>54</em>(6), 131:1–36. (<a
href="https://doi.org/10.1145/3460427">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The past four years have witnessed the rapid development of federated learning (FL). However, new privacy concerns have also emerged during the aggregation of the distributed intermediate results. The emerging privacy-preserving FL (PPFL) has been heralded as a solution to generic privacy-preserving machine learning. However, the challenge of protecting data privacy while maintaining the data utility through machine learning still remains. In this article, we present a comprehensive and systematic survey on the PPFL based on our proposed 5W-scenario-based taxonomy. We analyze the privacy leakage risks in the FL from five aspects, summarize existing methods, and identify future research directions.},
  archive      = {J_CSUR},
  author       = {Xuefei Yin and Yanming Zhu and Jiankun Hu},
  doi          = {10.1145/3460427},
  journal      = {ACM Computing Surveys},
  number       = {6},
  pages        = {131:1–36},
  shortjournal = {ACM Comput. Surv.},
  title        = {A comprehensive survey of privacy-preserving federated learning: A taxonomy, review, and future directions},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A survey on automated log analysis for reliability
engineering. <em>CSUR</em>, <em>54</em>(6), 130:1–37. (<a
href="https://doi.org/10.1145/3460345">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Logs are semi-structured text generated by logging statements in software source code. In recent decades, software logs have become imperative in the reliability assurance mechanism of many software systems, because they are often the only data available that record software runtime information. As modern software is evolving into a large scale, the volume of logs has increased rapidly. To enable effective and efficient usage of modern software logs in reliability engineering, a number of studies have been conducted on automated log analysis. This survey presents a detailed overview of automated log analysis research, including how to automate and assist the writing of logging statements, how to compress logs, how to parse logs into structured event templates, and how to employ logs to detect anomalies, predict failures, and facilitate diagnosis. Additionally, we survey work that releases open-source toolkits and datasets. Based on the discussion of the recent advances, we present several promising future directions toward real-world and next-generation automated log analysis.},
  archive      = {J_CSUR},
  author       = {Shilin He and Pinjia He and Zhuangbin Chen and Tianyi Yang and Yuxin Su and Michael R. Lyu},
  doi          = {10.1145/3460345},
  journal      = {ACM Computing Surveys},
  number       = {6},
  pages        = {130:1–37},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey on automated log analysis for reliability engineering},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Machine learning into metaheuristics: A survey and
taxonomy. <em>CSUR</em>, <em>54</em>(6), 129:1–32. (<a
href="https://doi.org/10.1145/3459664">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {During the past few years, research in applying machine learning (ML) to design efficient, effective, and robust metaheuristics has become increasingly popular. Many of those machine learning-supported metaheuristics have generated high-quality results and represent state-of-the-art optimization algorithms. Although various appproaches have been proposed, there is a lack of a comprehensive survey and taxonomy on this research topic. In this article, we will investigate different opportunities for using ML into metaheuristics. We define uniformly the various ways synergies that might be achieved. A detailed taxonomy is proposed according to the concerned search component: target optimization problem and low-level and high-level components of metaheuristics. Our goal is also to motivate researchers in optimization to include ideas from ML into metaheuristics. We identify some open research issues in this topic that need further in-depth investigations.},
  archive      = {J_CSUR},
  author       = {El-Ghazali Talbi},
  doi          = {10.1145/3459664},
  journal      = {ACM Computing Surveys},
  number       = {6},
  pages        = {129:1–32},
  shortjournal = {ACM Comput. Surv.},
  title        = {Machine learning into metaheuristics: A survey and taxonomy},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). K-nearest neighbour classifiers - a tutorial. <em>CSUR</em>,
<em>54</em>(6), 128:1–25. (<a
href="https://doi.org/10.1145/3459665">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Perhaps the most straightforward classifier in the arsenal or Machine Learning techniques is the Nearest Neighbour Classifier—classification is achieved by identifying the nearest neighbours to a query example and using those neighbours to determine the class of the query. This approach to classification is of particular importance, because issues of poor runtime performance is not such a problem these days with the computational power that is available. This article presents an overview of techniques for Nearest Neighbour classification focusing on: mechanisms for assessing similarity (distance), computational issues in identifying nearest neighbours, and mechanisms for reducing the dimension of the data. This article is the second edition of a paper previously published as a technical report [16]. Sections on similarity measures for time-series, retrieval speedup, and intrinsic dimensionality have been added. An Appendix is included, providing access to Python code for the key methods.},
  archive      = {J_CSUR},
  author       = {Pádraig Cunningham and Sarah Jane Delany},
  doi          = {10.1145/3459665},
  journal      = {ACM Computing Surveys},
  number       = {6},
  pages        = {128:1–25},
  shortjournal = {ACM Comput. Surv.},
  title        = {K-nearest neighbour classifiers - a tutorial},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A survey of reinforcement learning algorithms for
dynamically varying environments. <em>CSUR</em>, <em>54</em>(6),
127:1–25. (<a href="https://doi.org/10.1145/3459991">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reinforcement learning (RL) algorithms find applications in inventory control, recommender systems, vehicular traffic management, cloud computing, and robotics. The real-world complications arising in these domains makes them difficult to solve with the basic assumptions underlying classical RL algorithms. RL agents in these applications often need to react and adapt to changing operating conditions. A significant part of research on single-agent RL techniques focuses on developing algorithms when the underlying assumption of stationary environment model is relaxed. This article provides a survey of RL methods developed for handling dynamically varying environment models. The goal of methods not limited by the stationarity assumption is to help autonomous agents adapt to varying operating conditions. This is possible either by minimizing the rewards lost during learning by RL agent or by finding a suitable policy for the RL agent that leads to efficient operation of the underlying system. A representative collection of these algorithms is discussed in detail in this work along with their categorization and their relative merits and demerits. Additionally, we also review works that are tailored to application domains. Finally, we discuss future enhancements for this field.},
  archive      = {J_CSUR},
  author       = {Sindhu Padakandla},
  doi          = {10.1145/3459991},
  journal      = {ACM Computing Surveys},
  number       = {6},
  pages        = {127:1–25},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey of reinforcement learning algorithms for dynamically varying environments},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Security vulnerabilities of SGX and countermeasures: A
survey. <em>CSUR</em>, <em>54</em>(6), 126:1–36. (<a
href="https://doi.org/10.1145/3456631">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Trusted Execution Environments (TEEs) have been widely used in many security-critical applications. The popularity of TEEs derives from its high security and trustworthiness supported by secure hardware. Intel Software Guard Extensions (SGX) is one of the most representative TEEs that creates an isolated environment on an untrusted operating system, thus providing run-time protection for the execution of security-critical code and data. However, Intel SGX is far from the acme of perfection. It has become a target of various attacks due to its security vulnerabilities. Researchers and practitioners have paid attention to the security vulnerabilities of SGX and investigated optimization solutions in real applications. Unfortunately, existing literature lacks a thorough review of security vulnerabilities of SGX and their countermeasures. In this article, we fill this gap. Specifically, we propose two sets of criteria for estimating security risks of existing attacks and evaluating defense effects brought by attack countermeasures. Furthermore, we propose a taxonomy of SGX security vulnerabilities and shed light on corresponding attack vectors. After that, we review published attacks and existing countermeasures, as well as evaluate them by employing our proposed criteria. At last, on the strength of our survey, we propose some open challenges and future directions in the research of SGX security.},
  archive      = {J_CSUR},
  author       = {Shufan Fei and Zheng Yan and Wenxiu Ding and Haomeng Xie},
  doi          = {10.1145/3456631},
  journal      = {ACM Computing Surveys},
  number       = {6},
  pages        = {126:1–36},
  shortjournal = {ACM Comput. Surv.},
  title        = {Security vulnerabilities of SGX and countermeasures: A survey},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). On the use of intelligent models towards meeting the
challenges of the edge mesh. <em>CSUR</em>, <em>54</em>(6), 125:1–42.
(<a href="https://doi.org/10.1145/3456630">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, we are witnessing the advent of the Internet of Things (IoT) with numerous devices performing interactions between them or with their environment. The huge number of devices leads to huge volumes of data that demand the appropriate processing. The “legacy” approach is to rely on Cloud where increased computational resources can realize any desired processing. However, the need for supporting real-time applications requires a reduced latency in the provision of outcomes. Edge Computing (EC) comes as the “solver” of the latency problem. Various processing activities can be performed at EC nodes having direct connection with IoT devices. A number of challenges should be met before we conclude a fully automated ecosystem where nodes can cooperate or understand their status to efficiently serve applications. In this article, we perform a survey of the relevant research activities towards the vision of Edge Mesh (EM), i.e., a “cover” of intelligence upon the EC. We present the necessary hardware and discuss research outcomes in every aspect of EC/EM nodes functioning. We present technologies and theories adopted for data, tasks, and resource management while discussing how machine learning and optimization can be adopted in the domain.},
  archive      = {J_CSUR},
  author       = {Panagiotis Oikonomou and Anna Karanika and Christos Anagnostopoulos and Kostas Kolomvatsos},
  doi          = {10.1145/3456630},
  journal      = {ACM Computing Surveys},
  number       = {6},
  pages        = {125:1–42},
  shortjournal = {ACM Comput. Surv.},
  title        = {On the use of intelligent models towards meeting the challenges of the edge mesh},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Survey of post-OCR processing approaches. <em>CSUR</em>,
<em>54</em>(6), 124:1–37. (<a
href="https://doi.org/10.1145/3453476">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optical character recognition (OCR) is one of the most popular techniques used for converting printed documents into machine-readable ones. While OCR engines can do well with modern text, their performance is unfortunately significantly reduced on historical materials. Additionally, many texts have already been processed by various out-of-date digitisation techniques. As a consequence, digitised texts are noisy and need to be post-corrected. This article clarifies the importance of enhancing quality of OCR results by studying their effects on information retrieval and natural language processing applications. We then define the post-OCR processing problem, illustrate its typical pipeline, and review the state-of-the-art post-OCR processing approaches. Evaluation metrics, accessible datasets, language resources, and useful toolkits are also reported. Furthermore, the work identifies the current trend and outlines some research directions of this field.},
  archive      = {J_CSUR},
  author       = {Thi Tuyet Hai Nguyen and Adam Jatowt and Mickael Coustaty and Antoine Doucet},
  doi          = {10.1145/3453476},
  journal      = {ACM Computing Surveys},
  number       = {6},
  pages        = {124:1–37},
  shortjournal = {ACM Comput. Surv.},
  title        = {Survey of post-OCR processing approaches},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A survey on encrypted network traffic analysis applications,
techniques, and countermeasures. <em>CSUR</em>, <em>54</em>(6),
123:1–35. (<a href="https://doi.org/10.1145/3457904">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The adoption of network traffic encryption is continually growing. Popular applications use encryption protocols to secure communications and protect the privacy of users. In addition, a large portion of malware is spread through the network traffic taking advantage of encryption protocols to hide its presence and activity. Entering into the era of completely encrypted communications over the Internet, we must rapidly start reviewing the state-of-the-art in the wide domain of network traffic analysis and inspection, to conclude if traditional traffic processing systems will be able to seamlessly adapt to the upcoming full adoption of network encryption. In this survey, we examine the literature that deals with network traffic analysis and inspection after the ascent of encryption in communication channels. We notice that the research community has already started proposing solutions on how to perform inspection even when the network traffic is encrypted and we demonstrate and review these works. In addition, we present the techniques and methods that these works use and their limitations. Finally, we examine the countermeasures that have been proposed in the literature in order to circumvent traffic analysis techniques that aim to harm user privacy.},
  archive      = {J_CSUR},
  author       = {Eva Papadogiannaki and Sotiris Ioannidis},
  doi          = {10.1145/3457904},
  journal      = {ACM Computing Surveys},
  number       = {6},
  pages        = {123:1–35},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey on encrypted network traffic analysis applications, techniques, and countermeasures},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A survey of microarchitectural side-channel vulnerabilities,
attacks, and defenses in cryptography. <em>CSUR</em>, <em>54</em>(6),
122:1–37. (<a href="https://doi.org/10.1145/3456629">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Side-channel attacks have become a severe threat to the confidentiality of computer applications and systems. One popular type of such attacks is the microarchitectural attack, where the adversary exploits the hardware features to break the protection enforced by the operating system and steal the secrets from the program. In this article, we systematize microarchitectural side channels with a focus on attacks and defenses in cryptographic applications. We make three contributions. (1) We survey past research literature to categorize microarchitectural side-channel attacks. Since these are hardware attacks targeting software, we summarize the vulnerable implementations in software, as well as flawed designs in hardware. (2) We identify common strategies to mitigate microarchitectural attacks, from the application, OS, and hardware levels. (3) We conduct a large-scale evaluation on popular cryptographic applications in the real world and analyze the severity, practicality, and impact of side-channel vulnerabilities. This survey is expected to inspire side-channel research community to discover new attacks, and more importantly, propose new defense solutions against them.},
  archive      = {J_CSUR},
  author       = {Xiaoxuan Lou and Tianwei Zhang and Jun Jiang and Yinqian Zhang},
  doi          = {10.1145/3456629},
  journal      = {ACM Computing Surveys},
  number       = {6},
  pages        = {122:1–37},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey of microarchitectural side-channel vulnerabilities, attacks, and defenses in cryptography},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Application threats to exploit northbound interface
vulnerabilities in software defined networks. <em>CSUR</em>,
<em>54</em>(6), 121:1–36. (<a
href="https://doi.org/10.1145/3453648">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Software Defined Networking (SDN) is an evolving technology that decouples the control functionality from the underlying hardware managed by the control plane. The application plane supports programmers to develop numerous applications (such as networking, management, security, etc.) that can even be executed from remote locations. Northbound interface (NBI) bridges the control and application planes to execute the third-party applications business logic. Due to the software bugs in applications and existing vulnerabilities such as illegal function calling, resource exhaustion, lack of trust, and so on, NBIs are susceptible to different attacks. Based on the extensive literature review, we have identified that the researchers and academia have mainly focused on the security of the control plane, data plane, and southbound interface (SBI). NBI, in comparison, has received far less attention. In this article, the security of the least explored, but a critical component of the SDN architecture, i.e., NBI, is analyzed. The article provides a brief overview of SDN, followed by a detailed discussion on the categories of NBI, vulnerabilities of NBI, and threats posed by malicious applications to NBI. Efforts of the researchers to counter malicious applications and NBI issues are then discussed in detail. The standardization efforts for the single acceptable NBI and security requirements of SDN by Open Networking Foundation (ONF) are also presented. The article concludes with the future research directions for the security of a single acceptable NBI.},
  archive      = {J_CSUR},
  author       = {Bilal Rauf and Haider Abbas and Muhammad Usman and Tanveer A. Zia and Waseem Iqbal and Yawar Abbas and Hammad Afzal},
  doi          = {10.1145/3453648},
  journal      = {ACM Computing Surveys},
  number       = {6},
  pages        = {121:1–36},
  shortjournal = {ACM Comput. Surv.},
  title        = {Application threats to exploit northbound interface vulnerabilities in software defined networks},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Towards indistinguishable augmented reality: A survey on
optical see-through head-mounted displays. <em>CSUR</em>,
<em>54</em>(6), 120:1–36. (<a
href="https://doi.org/10.1145/3453157">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Adding virtual information that is indistinguishable from reality has been a long-awaited goal in Augmented Reality (AR). While already demonstrated in the 1960s, only recently have Optical See-Through Head-Mounted Displays (OST-HMDs) seen a reemergence, partially thanks to large investments from industry, and are now considered to be the ultimate hardware for augmenting our visual perception. In this article, we provide a thorough review of state-of-the-art OST-HMD-related techniques that are relevant to realize the aim of an AR interface almost indistinguishable from reality. In this work, we have an initial look at human perception to define requirements and goals for implementing such an interface. We follow up by identifying three key challenges for building an OST-HMD-based AR interface that is indistinguishable from reality: spatial realism, temporal realism, and visual realism. We discuss existing works that aim to overcome these challenges while also reflecting against the goal set by human perception. Finally, we give an outlook into promising research directions and expectations for the years to come.},
  archive      = {J_CSUR},
  author       = {Yuta Itoh and Tobias Langlotz and Jonathan Sutton and Alexander Plopski},
  doi          = {10.1145/3453157},
  journal      = {ACM Computing Surveys},
  number       = {6},
  pages        = {120:1–36},
  shortjournal = {ACM Comput. Surv.},
  title        = {Towards indistinguishable augmented reality: A survey on optical see-through head-mounted displays},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The hypervolume indicator: Computational problems and
algorithms. <em>CSUR</em>, <em>54</em>(6), 119:1–42. (<a
href="https://doi.org/10.1145/3453474">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The hypervolume indicator is one of the most used set-quality indicators for the assessment of stochastic multiobjective optimizers, as well as for selection in evolutionary multiobjective optimization algorithms. Its theoretical properties justify its wide acceptance, particularly the strict monotonicity with respect to set dominance, which is still unique of hypervolume-based indicators. This article discusses the computation of hypervolume-related problems, highlighting the relations between them, providing an overview of the paradigms and techniques used, a description of the main algorithms for each problem, and a rundown of the fastest algorithms regarding asymptotic complexity and runtime. By providing a complete overview of the computational problems associated to the hypervolume indicator, this article serves as the starting point for the development of new algorithms and supports users in the identification of the most appropriate implementations available for each problem.},
  archive      = {J_CSUR},
  author       = {Andreia P. Guerreiro and Carlos M. Fonseca and Luís Paquete},
  doi          = {10.1145/3453474},
  journal      = {ACM Computing Surveys},
  number       = {6},
  pages        = {119:1–42},
  shortjournal = {ACM Comput. Surv.},
  title        = {The hypervolume indicator: Computational problems and algorithms},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Topic-based video analysis: A survey. <em>CSUR</em>,
<em>54</em>(6), 118:1–34. (<a
href="https://doi.org/10.1145/3459089">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Manual processing of a large volume of video data captured through closed-circuit television is challenging due to various reasons. First, manual analysis is highly time-consuming. Moreover, as surveillance videos are recorded in dynamic conditions such as in the presence of camera motion, varying illumination, or occlusion, conventional supervised learning may not work always. Thus, computer vision-based automatic surveillance scene analysis is carried out in unsupervised ways. Topic modelling is one of the emerging fields used in unsupervised information processing. Topic modelling is used in text analysis, computer vision applications, and other areas involving spatio-temporal data. In this article, we discuss the scope, variations, and applications of topic modelling, particularly focusing on surveillance video analysis. We have provided a methodological survey on existing topic models, their features, underlying representations, characterization, and applications in visual surveillance’s perspective. Important research papers related to topic modelling in visual surveillance have been summarized and critically analyzed in this article.},
  archive      = {J_CSUR},
  author       = {Ratnabali Pal and Arif Ahmed Sekh and Debi Prosad Dogra and Samarjit Kar and Partha Pratim Roy and Dilip K. Prasad},
  doi          = {10.1145/3459089},
  journal      = {ACM Computing Surveys},
  number       = {6},
  pages        = {118:1–34},
  shortjournal = {ACM Comput. Surv.},
  title        = {Topic-based video analysis: A survey},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A survey on windows-based ransomware taxonomy and detection
mechanisms. <em>CSUR</em>, <em>54</em>(6), 117:1–36. (<a
href="https://doi.org/10.1145/3453153">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ransomware remains an alarming threat in the 21st century. It has evolved from being a simple scare tactic into a complex malware capable of evasion. Formerly, end-users were targeted via mass infection campaigns. Nevertheless, in recent years, the attackers have focused on targeted attacks, since the latter are profitable and can induce severe damage. A vast number of detection mechanisms have been proposed in the literature. We provide a systematic review of ransomware countermeasures starting from its deployment on the victim machine until the ransom payment via cryptocurrency. We define four stages of this malware attack: Delivery, Deployment, Destruction, and Dealing. Then, we assign the corresponding countermeasures for each phase of the attack and cluster them by the techniques used. Finally, we propose a roadmap for researchers to fill the gaps found in the literature in ransomware’s battle.},
  archive      = {J_CSUR},
  author       = {Routa Moussaileb and Nora Cuppens and Jean-Louis Lanet and Hélène Le Bouder},
  doi          = {10.1145/3453153},
  journal      = {ACM Computing Surveys},
  number       = {6},
  pages        = {117:1–36},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey on windows-based ransomware taxonomy and detection mechanisms},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Data modeling and NoSQL databases - a systematic mapping
review. <em>CSUR</em>, <em>54</em>(6), 116:1–26. (<a
href="https://doi.org/10.1145/3457608">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modeling is one of the most important steps in developing a database. In traditional databases, the Entity Relationship (ER) and Unified Modeling Language (UML) models are widely used. But how are NoSQL databases being modeled? We performed a systematic mapping review to answer three research questions to identify and analyze the levels of representation, models used, and contexts where the modeling process occurred in the main categories of NoSQL databases. We found 54 primary studies where we identified that conceptual and logical levels received more attention than the physical level of representation. The UML, ER, and new notation based on ER and UML were adapted to model NoSQL databases, in the same way, formats such as JSON, XML, and XMI were used to generate schemas through the three levels of representation. New contexts such as benchmark, evaluations, migration, and schema generation were identified, as well as new features to be considered for modeling NoSQL databases, such as the number of records by entities, CRUD operations, and system requirements (availability, consistency, or scalability). Additionally, a coupling and co-citation analysis was carried out to identify relevant works and researchers.},
  archive      = {J_CSUR},
  author       = {Harley Vera-Olivera and Ruizhe Guo and Ruben Cruz Huacarpuma and Ana Paula Bernardi Da Silva and Ari Melo Mariano and Maristela Holanda},
  doi          = {10.1145/3457608},
  journal      = {ACM Computing Surveys},
  number       = {6},
  pages        = {116:1–26},
  shortjournal = {ACM Comput. Surv.},
  title        = {Data modeling and NoSQL databases - a systematic mapping review},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A survey on bias and fairness in machine learning.
<em>CSUR</em>, <em>54</em>(6), 115:1–35. (<a
href="https://doi.org/10.1145/3457607">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the widespread use of artificial intelligence (AI) systems and applications in our everyday lives, accounting for fairness has gained significant importance in designing and engineering of such systems. AI systems can be used in many sensitive environments to make important and life-changing decisions; thus, it is crucial to ensure that these decisions do not reflect discriminatory behavior toward certain groups or populations. More recently some work has been developed in traditional machine learning and deep learning that address such challenges in different subdomains. With the commercialization of these systems, researchers are becoming more aware of the biases that these applications can contain and are attempting to address them. In this survey, we investigated different real-world applications that have shown biases in various ways, and we listed different sources of biases that can affect AI applications. We then created a taxonomy for fairness definitions that machine learning researchers have defined to avoid the existing bias in AI systems. In addition to that, we examined different domains and subdomains in AI showing what researchers have observed with regard to unfair outcomes in the state-of-the-art methods and ways they have tried to address them. There are still many future directions and solutions that can be taken to mitigate the problem of bias in AI systems. We are hoping that this survey will motivate researchers to tackle these issues in the near future by observing existing work in their respective fields.},
  archive      = {J_CSUR},
  author       = {Ninareh Mehrabi and Fred Morstatter and Nripsuta Saxena and Kristina Lerman and Aram Galstyan},
  doi          = {10.1145/3457607},
  journal      = {ACM Computing Surveys},
  number       = {6},
  pages        = {115:1–35},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey on bias and fairness in machine learning},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A unified model for context-sensitive program analyses:: The
blind men and the elephant. <em>CSUR</em>, <em>54</em>(6), 114:1–37. (<a
href="https://doi.org/10.1145/3456563">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Context-sensitive methods of program analysis increase the precision of interprocedural analysis by achieving the effect of call inlining. These methods have been defined using different formalisms and hence appear as algorithms that are very different from each other. Some methods traverse a call graph top-down, whereas some others traverse it bottom-up first and then top-down. Some define contexts explicitly, whereas some do not. Some of them directly compute data flow values, while some first compute summary functions and then use them to compute data flow values. Further, different methods place different kinds of restrictions on the data flow frameworks supported by them. As a consequence, it is difficult to compare the ideas behind these methods in spite of the fact that they solve essentially the same problem. We argue that these incomparable views are similar to those of blind men describing an elephant, called context sensitivity, and make it difficult for a non-expert reader to form a coherent picture of context-sensitive data flow analysis. We bring out this whole-elephant view of context sensitivity in program analysis by proposing a unified model of context sensitivity that provides a clean separation between computation of contexts and computation of data flow values. Our model captures the essence of context sensitivity and defines simple soundness and precision criteria for context-sensitive methods. It facilitates declarative specifications of context-sensitive methods, insightful comparisons between them, and reasoning about their soundness and precision. We demonstrate this by instantiating our model to many known context-sensitive methods.},
  archive      = {J_CSUR},
  author       = {Swati Jaiswal and Uday P. Khedker and Alan Mycroft},
  doi          = {10.1145/3456563},
  journal      = {ACM Computing Surveys},
  number       = {6},
  pages        = {114:1–37},
  shortjournal = {ACM Comput. Surv.},
  title        = {A unified model for context-sensitive program analyses:: the blind men and the elephant},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Images in space and time: Real big data in healthcare.
<em>CSUR</em>, <em>54</em>(6), 113:1–38. (<a
href="https://doi.org/10.1145/3453657">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Medical imaging diagnosis is mostly subjective, as it depends on medical experts. Hence, the service provided is limited by expert opinion variations and image complexity as well. However, with the increasing advancements in deep learning field, techniques are developed to help in the diagnosis and risk assessment processes. In this article, we survey different types of images in healthcare. A review of the concept and research methodology of Radiomics will highlight the potentials of integrated diagnostics. Convolutional neural networks can play an important role in next generations of automated imaging biomarker extraction and big data analytics systems. Examples are provided of what is already feasible today and also describe additional technological components required for successful clinical implementation.},
  archive      = {J_CSUR},
  author       = {Eman Badr},
  doi          = {10.1145/3453657},
  journal      = {ACM Computing Surveys},
  number       = {6},
  pages        = {113:1–38},
  shortjournal = {ACM Comput. Surv.},
  title        = {Images in space and time: Real big data in healthcare},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A guideline on pseudorandom number generation (PRNG) in the
IoT. <em>CSUR</em>, <em>54</em>(6), 112:1–38. (<a
href="https://doi.org/10.1145/3453159">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Random numbers are an essential input to many functions on the Internet of Things (IoT). Common use cases of randomness range from low-level packet transmission to advanced algorithms of artificial intelligence as well as security and trust, which heavily rely on unpredictable random sources. In the constrained IoT, though, unpredictable random sources are a challenging desire due to limited resources, deterministic real-time operations, and frequent lack of a user interface. In this article, we revisit the generation of randomness from the perspective of an IoT operating system (OS) that needs to support general purpose or crypto-secure random numbers. We analyze the potential attack surface, derive common requirements, and discuss the potentials and shortcomings of current IoT OSs. A systematic evaluation of current IoT hardware components and popular software generators based on well-established test suits and on experiments for measuring performance give rise to a set of clear recommendations on how to build such a random subsystem and which generators to use.},
  archive      = {J_CSUR},
  author       = {Peter Kietzmann and Thomas C. Schmidt and Matthias Wählisch},
  doi          = {10.1145/3453159},
  journal      = {ACM Computing Surveys},
  number       = {6},
  pages        = {112:1–38},
  shortjournal = {ACM Comput. Surv.},
  title        = {A guideline on pseudorandom number generation (PRNG) in the IoT},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Assuring the machine learning lifecycle: Desiderata,
methods, and challenges. <em>CSUR</em>, <em>54</em>(5), 111:1–39. (<a
href="https://doi.org/10.1145/3453444">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning has evolved into an enabling technology for a wide range of highly successful applications. The potential for this success to continue and accelerate has placed machine learning (ML) at the top of research, economic, and political agendas. Such unprecedented interest is fuelled by a vision of ML applicability extending to healthcare, transportation, defence, and other domains of great societal importance. Achieving this vision requires the use of ML in safety-critical applications that demand levels of assurance beyond those needed for current ML applications. Our article provides a comprehensive survey of the state of the art in the assurance of ML , i.e., in the generation of evidence that ML is sufficiently safe for its intended use. The survey covers the methods capable of providing such evidence at different stages of the machine learning lifecycle , i.e., of the complex, iterative process that starts with the collection of the data used to train an ML component for a system, and ends with the deployment of that component within the system. The article begins with a systematic presentation of the ML lifecycle and its stages. We then define assurance desiderata for each stage, review existing methods that contribute to achieving these desiderata, and identify open challenges that require further research.},
  archive      = {J_CSUR},
  author       = {Rob Ashmore and Radu Calinescu and Colin Paterson},
  doi          = {10.1145/3453444},
  journal      = {ACM Computing Surveys},
  number       = {5},
  pages        = {111:1–39},
  shortjournal = {ACM Comput. Surv.},
  title        = {Assuring the machine learning lifecycle: Desiderata, methods, and challenges},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Legally enforceable smart-contract languages: A systematic
literature review. <em>CSUR</em>, <em>54</em>(5), 110:1–34. (<a
href="https://doi.org/10.1145/3453475">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Smart contracts are a key component of today’s blockchains. They are critical in controlling decentralized autonomous organizations (DAO). However, smart contracts are not yet legally binding nor enforceable; this makes it difficult for businesses to adopt the DAO paradigm. Therefore, this study reviews existing Smart Contract Languages (SCL) and identifies properties that are critical to any future SCL for drafting legally binding contracts. This is achieved by conducting a Systematic Literature Review (SLR) of white- and grey literature published between 2015 and 2019. Using the SLR methodology, 45 Selected and 28 Supporting Studies detailing 45 state-of-the-art SCLs are selected. Finally, 10 SCL properties that enable legally compliant DAOs are discovered, and specifications for developing SCLs are explored.},
  archive      = {J_CSUR},
  author       = {Vimal Dwivedi and Vishwajeet Pattanaik and Vipin Deval and Abhishek Dixit and Alex Norta and Dirk Draheim},
  doi          = {10.1145/3453475},
  journal      = {ACM Computing Surveys},
  number       = {5},
  pages        = {110:1–34},
  shortjournal = {ACM Comput. Surv.},
  title        = {Legally enforceable smart-contract languages: A systematic literature review},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Hierarchical reinforcement learning: A comprehensive survey.
<em>CSUR</em>, <em>54</em>(5), 109:1–35. (<a
href="https://doi.org/10.1145/3453160">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hierarchical Reinforcement Learning (HRL) enables autonomous decomposition of challenging long-horizon decision-making tasks into simpler subtasks. During the past years, the landscape of HRL research has grown profoundly, resulting in copious approaches. A comprehensive overview of this vast landscape is necessary to study HRL in an organized manner. We provide a survey of the diverse HRL approaches concerning the challenges of learning hierarchical policies, subtask discovery, transfer learning, and multi-agent learning using HRL. The survey is presented according to a novel taxonomy of the approaches. Based on the survey, a set of important open problems is proposed to motivate the future research in HRL. Furthermore, we outline a few suitable task domains for evaluating the HRL approaches and a few interesting examples of the practical applications of HRL in the Supplementary Material.},
  archive      = {J_CSUR},
  author       = {Shubham Pateria and Budhitama Subagdja and Ah-hwee Tan and Chai Quek},
  doi          = {10.1145/3453160},
  journal      = {ACM Computing Surveys},
  number       = {5},
  pages        = {109:1–35},
  shortjournal = {ACM Comput. Surv.},
  title        = {Hierarchical reinforcement learning: A comprehensive survey},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Adversarial machine learning attacks and defense methods in
the cyber security domain. <em>CSUR</em>, <em>54</em>(5), 108:1–36. (<a
href="https://doi.org/10.1145/3453158">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, machine learning algorithms, and more specifically deep learning algorithms, have been widely used in many fields, including cyber security. However, machine learning systems are vulnerable to adversarial attacks, and this limits the application of machine learning, especially in non-stationary, adversarial environments, such as the cyber security domain, where actual adversaries (e.g., malware developers) exist. This article comprehensively summarizes the latest research on adversarial attacks against security solutions based on machine learning techniques and illuminates the risks they pose. First, the adversarial attack methods are characterized based on their stage of occurrence, and the attacker’ s goals and capabilities. Then, we categorize the applications of adversarial attack and defense methods in the cyber security domain. Finally, we highlight some characteristics identified in recent research and discuss the impact of recent advancements in other adversarial learning domains on future research directions in the cyber security domain. To the best of our knowledge, this work is the first to discuss the unique challenges of implementing end-to-end adversarial attacks in the cyber security domain, map them in a unified taxonomy, and use the taxonomy to highlight future research directions.},
  archive      = {J_CSUR},
  author       = {Ishai Rosenberg and Asaf Shabtai and Yuval Elovici and Lior Rokach},
  doi          = {10.1145/3453158},
  journal      = {ACM Computing Surveys},
  number       = {5},
  pages        = {108:1–36},
  shortjournal = {ACM Comput. Surv.},
  title        = {Adversarial machine learning attacks and defense methods in the cyber security domain},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Survey on blockchain networking: Context, state-of-the-art,
challenges. <em>CSUR</em>, <em>54</em>(5), 107:1–34. (<a
href="https://doi.org/10.1145/3453161">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Blockchains, in general, and cryptocurrencies such as Bitcoin, in particular, are realized using distributed systems and hence critically rely on the performance and security of the interconnecting network. The requirements on these networks and their usage, however, can differ significantly from traditional communication networks, with implications on all layers of the protocol stack. This article is motivated by these differences and, in particular, by the observation that many fundamental design aspects of these networks are not well-understood today. To support the networking community to contribute to this emerging application domain, we present a structured overview of the field, from topology and neighbor discovery, over block and transaction propagation, to sharding and off-chain networks, also reviewing existing empirical results from different measurement studies. In particular, for each of these domains, we provide the context, highlighting differences and commonalities with traditional networks, review the state-of-the-art, and identify open research challenges. Our article can hence also be seen as a call-to-arms to improve the foundation on top of which blockchains are built.},
  archive      = {J_CSUR},
  author       = {Maya Dotan and Yvonne-Anne Pignolet and Stefan Schmid and Saar Tochner and Aviv Zohar},
  doi          = {10.1145/3453161},
  journal      = {ACM Computing Surveys},
  number       = {5},
  pages        = {107:1–34},
  shortjournal = {ACM Comput. Surv.},
  title        = {Survey on blockchain networking: Context, state-of-the-art, challenges},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Deep learning-based anomaly detection in cyber-physical
systems: Progress and opportunities. <em>CSUR</em>, <em>54</em>(5),
106:1–36. (<a href="https://doi.org/10.1145/3453155">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Anomaly detection is crucial to ensure the security of cyber-physical systems (CPS). However, due to the increasing complexity of CPSs and more sophisticated attacks, conventional anomaly detection methods, which face the growing volume of data and need domain-specific knowledge, cannot be directly applied to address these challenges. To this end, deep learning-based anomaly detection (DLAD) methods have been proposed. In this article, we review state-of-the-art DLAD methods in CPSs. We propose a taxonomy in terms of the type of anomalies, strategies, implementation, and evaluation metrics to understand the essential properties of current methods. Further, we utilize this taxonomy to identify and highlight new characteristics and designs in each CPS domain. Also, we discuss the limitations and open problems of these methods. Moreover, to give users insights into choosing proper DLAD methods in practice, we experimentally explore the characteristics of typical neural models, the workflow of DLAD methods, and the running performance of DL models. Finally, we discuss the deficiencies of DL approaches, our findings, and possible directions to improve DLAD methods and motivate future research.},
  archive      = {J_CSUR},
  author       = {Yuan Luo and Ya Xiao and Long Cheng and Guojun Peng and Danfeng (Daphne) Yao},
  doi          = {10.1145/3453155},
  journal      = {ACM Computing Surveys},
  number       = {5},
  pages        = {106:1–36},
  shortjournal = {ACM Comput. Surv.},
  title        = {Deep learning-based anomaly detection in cyber-physical systems: Progress and opportunities},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A survey on conversational recommender systems.
<em>CSUR</em>, <em>54</em>(5), 105:1–36. (<a
href="https://doi.org/10.1145/3453154">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommender systems are software applications that help users to find items of interest in situations of information overload. Current research often assumes a one-shot interaction paradigm, where the users’ preferences are estimated based on past observed behavior and where the presentation of a ranked list of suggestions is the main, one-directional form of user interaction. Conversational recommender systems (CRS) take a different approach and support a richer set of interactions. These interactions can, for example, help to improve the preference elicitation process or allow the user to ask questions about the recommendations and to give feedback. The interest in CRS has significantly increased in the past few years. This development is mainly due to the significant progress in the area of natural language processing, the emergence of new voice-controlled home assistants, and the increased use of chatbot technology. With this article, we provide a detailed survey of existing approaches to conversational recommendation. We categorize these approaches in various dimensions, e.g., in terms of the supported user intents or the knowledge they use in the background. Moreover, we discuss technological approaches, review how CRS are evaluated, and finally identify a number of gaps that deserve more research in the future.},
  archive      = {J_CSUR},
  author       = {Dietmar Jannach and Ahtsham Manzoor and Wanling Cai and Li Chen},
  doi          = {10.1145/3453154},
  journal      = {ACM Computing Surveys},
  number       = {5},
  pages        = {105:1–36},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey on conversational recommender systems},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A survey on stream-based recommender systems. <em>CSUR</em>,
<em>54</em>(5), 104:1–36. (<a
href="https://doi.org/10.1145/3453443">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommender Systems (RS) have proven to be effective tools to help users overcome information overload, and significant advances have been made in the field over the past two decades. Although addressing the recommendation problem required first a formulation that could be easily studied and evaluated, there currently exists a gap between research contributions and industrial applications where RS are actually deployed. In particular, most RS are meant to function in batch: they rely on a large static dataset and build a recommendation model that is only periodically updated. This functioning introduces several limitations in various settings, leading to considering more realistic settings where RS learn from continuous streams of interactions. Such RS are framed as Stream-Based Recommender Systems (SBRS). In this article, we review SBRS, underline their relation with time-aware RS and online adaptive learning, and present and categorize existing work that tackle the corresponding problem and its multiple facets. We discuss the methodologies used to evaluate SBRS and the adapted datasets that can be used, and finally we outline open challenges in the area.},
  archive      = {J_CSUR},
  author       = {Marie Al-Ghossein and Talel Abdessalem and Anthony BARRÉ},
  doi          = {10.1145/3453443},
  journal      = {ACM Computing Surveys},
  number       = {5},
  pages        = {104:1–36},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey on stream-based recommender systems},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Automatic story generation: A survey of approaches.
<em>CSUR</em>, <em>54</em>(5), 103:1–38. (<a
href="https://doi.org/10.1145/3453156">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Computational generation of stories is a subfield of computational creativity where artificial intelligence and psychology intersect to teach computers how to mimic humans’ creativity. It helps generate many stories with minimum effort and customize the stories for the users’ education and entertainment needs. Although the automatic generation of stories started to receive attention many decades ago, advances in this field to date are less than expected and suffer from many limitations. This survey presents an extensive study of research in the area of non-interactive textual story generation, as well as covering resources, corpora, and evaluation methods that have been used in those studies. It also shed light on factors of story interestingness.},
  archive      = {J_CSUR},
  author       = {Arwa I. Alhussain and Aqil M. Azmi},
  doi          = {10.1145/3453156},
  journal      = {ACM Computing Surveys},
  number       = {5},
  pages        = {103:1–38},
  shortjournal = {ACM Comput. Surv.},
  title        = {Automatic story generation: A survey of approaches},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Privacy laws and privacy by design schemes for the internet
of things: A developer’s perspective. <em>CSUR</em>, <em>54</em>(5),
102:1–38. (<a href="https://doi.org/10.1145/3450965">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Internet of Things applications have the potential to derive sensitive information about individuals. Therefore, developers must exercise due diligence to make sure that data are managed according to the privacy regulations and data protection laws. However, doing so can be a difficult and challenging task. Recent research has revealed that developers typically face difficulties when complying with regulations. One key reason is that, at times, regulations are vague and could be challenging to extract and enact such legal requirements. In this article, we have conducted a systematic analysis of the privacy and data protection laws that are used across different continents, namely (i) General Data Protection Regulations, (ii) the Personal Information Protection and Electronic Documents Act, (iii) the California Consumer Privacy Act, (iv) Australian Privacy Principles, and (v) New Zealand’s Privacy Act 1993. Then, we used framework analysis method to attain a comprehensive view of different privacy and data protection laws and highlighted the disparities to assist developers in adhering to the regulations across different regions, along with creating a Combined Privacy Law Framework (CPLF). After that, the key principles and individuals’ rights of the CPLF were mapped with Privacy by Design (PbD) schemes (e.g., privacy principles, strategies, guidelines, and patterns) developed previously by different researchers to investigate the gaps in existing schemes. Subsequently, we have demonstrated how to apply and map privacy patterns into IoT architectures at the design stage and have also highlighted the complexity of doing such mapping. Finally, we have identified the major challenges that should be addressed and potential research directions to take the burden off software developers when applying privacy-preserving techniques that comply with privacy and data protection laws. We have released a companion technical report [3] that comprises all definitions, detailed steps on how we developed the CPLF, and detailed mappings between CPLF and PbD schemes.},
  archive      = {J_CSUR},
  author       = {Atheer Aljeraisy and Masoud Barati and Omer Rana and Charith Perera},
  doi          = {10.1145/3450965},
  journal      = {ACM Computing Surveys},
  number       = {5},
  pages        = {102:1–38},
  shortjournal = {ACM Comput. Surv.},
  title        = {Privacy laws and privacy by design schemes for the internet of things: A developer’s perspective},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A survey of network-on-chip security attacks and
countermeasures. <em>CSUR</em>, <em>54</em>(5), 101:1–36. (<a
href="https://doi.org/10.1145/3450964">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the advances of chip manufacturing technologies, computer architects have been able to integrate an increasing number of processors and other heterogeneous components on the same chip. Network-on-Chip (NoC) is widely employed by multicore System-on-Chip (SoC) architectures to cater to their communication requirements. NoC has received significant attention from both attackers and defenders. The increased usage of NoC and its distributed nature across the chip has made it a focal point of potential security attacks. Due to its prime location in the SoC coupled with connectivity with various components, NoC can be effectively utilized to implement security countermeasures to protect the SoC from potential attacks. There is a wide variety of existing literature on NoC security attacks and countermeasures. In this article, we provide a comprehensive survey of security vulnerabilities in NoC-based SoC architectures and discuss relevant countermeasures.},
  archive      = {J_CSUR},
  author       = {Subodha Charles and Prabhat Mishra},
  doi          = {10.1145/3450964},
  journal      = {ACM Computing Surveys},
  number       = {5},
  pages        = {101:1–36},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey of network-on-chip security attacks and countermeasures},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Intermediate representations for explicitly parallel
programs. <em>CSUR</em>, <em>54</em>(5), 100:1–24. (<a
href="https://doi.org/10.1145/3452299">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While compilers generally support parallel programming languages and APIs, their internal program representations are mostly designed from the sequential programs standpoint (exceptions include source-to-source parallel compilers, for instance). This makes the integration of compilation techniques dedicated to parallel programs more challenging. In addition, parallelism has various levels and different targets, each of them with specific characteristics and constraints. With the advent of multi-core processors and general purpose accelerators, parallel computing is now a common and pervasive consideration. Thus, software support to parallel programming activities is essential to make this technical transition more realistic and beneficial. The case of compilers is fundamental as they deal with (parallel) programs at a structural level, thus the need for intermediate representations. This article surveys and discusses attempts to provide intermediate representations for the proper support of explicitly parallel programs. We highlight the gap between available contributions and their concrete implementation in compilers and then exhibit possible future research directions.},
  archive      = {J_CSUR},
  author       = {Adilla Susungi and Claude Tadonki},
  doi          = {10.1145/3452299},
  journal      = {ACM Computing Surveys},
  number       = {5},
  pages        = {100:1–24},
  shortjournal = {ACM Comput. Surv.},
  title        = {Intermediate representations for explicitly parallel programs},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A survey of unsupervised generative models for exploratory
data analysis and representation learning. <em>CSUR</em>,
<em>54</em>(5), 99:1–40. (<a
href="https://doi.org/10.1145/3450963">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For more than a century, the methods for data representation and the exploration of the intrinsic structures of data have developed remarkably and consist of supervised and unsupervised methods. However, recent years have witnessed the flourishing of big data, where typical dataset dimensions are high and the data can come in messy, incomplete, unlabeled, or corrupted forms. Consequently, discovering the hidden structure buried inside such data becomes highly challenging. From this perspective, exploratory data analysis plays a substantial role in learning the hidden structures that encompass the significant features of the data in an ordered manner by extracting patterns and testing hypotheses to identify anomalies. Unsupervised generative learning models are a class of machine learning models characterized by their potential to reduce the dimensionality, discover the exploratory factors, and learn representations without any predefined labels; moreover, such models can generate the data from the reduced factors’ domain. The beginner researchers can find in this survey the recent unsupervised generative learning models for the purpose of data exploration and learning representations; specifically, this article covers three families of methods based on their usage in the era of big data: blind source separation, manifold learning, and neural networks, from shallow to deep architectures.},
  archive      = {J_CSUR},
  author       = {Mohanad Abukmeil and Stefano Ferrari and Angelo Genovese and Vincenzo Piuri and Fabio Scotti},
  doi          = {10.1145/3450963},
  journal      = {ACM Computing Surveys},
  number       = {5},
  pages        = {99:1–40},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey of unsupervised generative models for exploratory data analysis and representation learning},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Bidirectional typing. <em>CSUR</em>, <em>54</em>(5),
98:1–38. (<a href="https://doi.org/10.1145/3450952">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bidirectional typing combines two modes of typing: type checking, which checks that a program satisfies a known type, and type synthesis, which determines a type from the program. Using checking enables bidirectional typing to support features for which inference is undecidable; using synthesis enables bidirectional typing to avoid the large annotation burden of explicitly typed languages. In addition, bidirectional typing improves error locality. We highlight the design principles that underlie bidirectional type systems, survey the development of bidirectional typing from the prehistoric period before Pierce and Turner’s local type inference to the present day, and provide guidance for future investigations.},
  archive      = {J_CSUR},
  author       = {Jana Dunfield and Neel Krishnaswami},
  doi          = {10.1145/3450952},
  journal      = {ACM Computing Surveys},
  number       = {5},
  pages        = {98:1–38},
  shortjournal = {ACM Comput. Surv.},
  title        = {Bidirectional typing},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Computer-aided design techniques for flow-based microfluidic
lab-on-a-chip systems. <em>CSUR</em>, <em>54</em>(5), 97:1–29. (<a
href="https://doi.org/10.1145/3450504">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As one of the most promising lab-on-a-chip systems, flow-based microfluidic biochips are being increasingly used for automatically executing various laboratory procedures in biology and biochemistry, such as enzyme-linked immunosorbent assay, point-of-care diagnosis, and so on. As manufacturing technology advances, the characteristic dimensions of biochip systems keep shrinking, and tens of thousands of microvalves can now be integrated into a coin-sized microfluidic platform, making the conventional manual-based chip design no longer applicable. Accordingly, computer-aided design (CAD) of microfluidics has attracted considerable research interest in the EDA community over the past decade. This review article presents recent advances in the design automation of biochips, involving CAD techniques for architectural synthesis, wash optimization, testing, fault diagnosis, and fault-tolerant design. With the help of these CAD tools, chip designers can be released from the burden of complex, large-scale design tasks. Meanwhile, new chip architectures can be explored automatically to open new doors to meet requirements from future large-scale biological experiments and medical diagnosis. We discuss key trends and directions for future research that are related to enable microfluidics to reach its full potential, thus further advancing the development and progression of the microfluidics industry.},
  archive      = {J_CSUR},
  author       = {Xing Huang and Tsung-Yi Ho and Wenzhong Guo and Bing Li and Krishnendu Chakrabarty and Ulf Schlichtmann},
  doi          = {10.1145/3450504},
  journal      = {ACM Computing Surveys},
  number       = {5},
  pages        = {97:1–29},
  shortjournal = {ACM Comput. Surv.},
  title        = {Computer-aided design techniques for flow-based microfluidic lab-on-a-chip systems},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A survey on the use of preferences for virtual machine
placement in cloud data centers. <em>CSUR</em>, <em>54</em>(5), 96:1–39.
(<a href="https://doi.org/10.1145/3450517">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of virtualization techniques, cloud data centers allow for cost-effective, flexible, and customizable deployments of applications on virtualized infrastructure. Virtual machine (VM) placement aims to assign each virtual machine to a server in the cloud environment. VM Placement is of paramount importance to the design of cloud data centers. Typically, VM placement involves complex relations and multiple design factors as well as local policies that govern the assignment decisions. It also involves different constituents including cloud administrators and customers that might have disparate preferences while opting for a placement solution. Thus, it is often valuable to return not only an optimized solution to the VM placement problem but also a solution that reflects the given preferences of the constituents. In this article, we provide a detailed review on the role of preferences in the recent literature on VM placement. We examine different preference representations found in the literature, explain their existing usage, and explain the adopted solving approaches. We further discuss key challenges and identify possible research opportunities to better incorporate preferences within the context of VM placement.},
  archive      = {J_CSUR},
  author       = {Abdulaziz Alashaikh and Eisa Alanazi and Ala Al-Fuqaha},
  doi          = {10.1145/3450517},
  journal      = {ACM Computing Surveys},
  number       = {5},
  pages        = {96:1–39},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey on the use of preferences for virtual machine placement in cloud data centers},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A systematic literature review on federated machine
learning: From a software engineering perspective. <em>CSUR</em>,
<em>54</em>(5), 95:1–39. (<a
href="https://doi.org/10.1145/3450288">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning is an emerging machine learning paradigm where clients train models locally and formulate a global model based on the local model updates. To identify the state-of-the-art in federated learning and explore how to develop federated learning systems, we perform a systematic literature review from a software engineering perspective, based on 231 primary studies. Our data synthesis covers the lifecycle of federated learning system development that includes background understanding, requirement analysis, architecture design, implementation, and evaluation. We highlight and summarise the findings from the results and identify future trends to encourage researchers to advance their current work.},
  archive      = {J_CSUR},
  author       = {Sin Kit Lo and Qinghua Lu and Chen Wang and Hye-Young Paik and Liming Zhu},
  doi          = {10.1145/3450288},
  journal      = {ACM Computing Surveys},
  number       = {5},
  pages        = {95:1–39},
  shortjournal = {ACM Comput. Surv.},
  title        = {A systematic literature review on federated machine learning: From a software engineering perspective},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Event prediction in the big data era: A systematic survey.
<em>CSUR</em>, <em>54</em>(5), 94:1–37. (<a
href="https://doi.org/10.1145/3450287">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Events are occurrences in specific locations, time, and semantics that nontrivially impact either our society or the nature, such as earthquakes, civil unrest, system failures, pandemics, and crimes. It is highly desirable to be able to anticipate the occurrence of such events in advance to reduce the potential social upheaval and damage caused. Event prediction, which has traditionally been prohibitively challenging, is now becoming a viable option in the big data era and is thus experiencing rapid growth, also thanks to advances in high performance computers and new Artificial Intelligence techniques. There is a large amount of existing work that focuses on addressing the challenges involved, including heterogeneous multi-faceted outputs, complex (e.g., spatial, temporal, and semantic) dependencies, and streaming data feeds. Due to the strong interdisciplinary nature of event prediction problems, most existing event prediction methods were initially designed to deal with specific application domains, though the techniques and evaluation procedures utilized are usually generalizable across different domains. However, it is imperative yet difficult to cross-reference the techniques across different domains, given the absence of a comprehensive literature survey for event prediction. This article aims to provide a systematic and comprehensive survey of the technologies, applications, and evaluations of event prediction in the big data era. First, systematic categorization and summary of existing techniques are presented, which facilitate domain experts’ searches for suitable techniques and help model developers consolidate their research at the frontiers. Then, comprehensive categorization and summary of major application domains are provided to introduce wider applications to model developers to help them expand the impacts of their research. Evaluation metrics and procedures are summarized and standardized to unify the understanding of model performance among stakeholders, model developers, and domain experts in various application domains. Finally, open problems and future directions are discussed. Additional resources related to event prediction are included in the paper website: http://cs.emory.edu/∼lzhao41/projects/event_prediction_site.html.},
  archive      = {J_CSUR},
  author       = {Liang Zhao},
  doi          = {10.1145/3450287},
  journal      = {ACM Computing Surveys},
  number       = {5},
  pages        = {94:1–37},
  shortjournal = {ACM Comput. Surv.},
  title        = {Event prediction in the big data era: A systematic survey},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The role of formalism in system requirements. <em>CSUR</em>,
<em>54</em>(5), 93:1–36. (<a
href="https://doi.org/10.1145/3448975">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A major determinant of the quality of software systems is the quality of their requirements, which should be both understandable and precise. Most requirements are written in natural language, which is good for understandability but lacks precision. To make requirements precise, researchers have for years advocated the use of mathematics-based notations and methods, known as “formal.” Many exist, differing in their style, scope, and applicability. The present survey discusses some of the main formal approaches and compares them to informal methods. The analysis uses a set of nine complementary criteria, such as level of abstraction, tool availability, and traceability support. It classifies the approaches into five categories based on their principal style for specifying requirements: natural-language, semi-formal, automata/graphs, mathematical, and seamless (programming-language-based). It includes examples from all of these categories, altogether 21 different approaches, including for example SysML, Relax, Eiffel, Event-B, and Alloy. The review discusses a number of open questions, including seamlessness, the role of tools and education, and how to make industrial applications benefit more from the contributions of formal approaches.},
  archive      = {J_CSUR},
  author       = {Jean-Michel Bruel and Sophie Ebersold and Florian Galinier and Manuel Mazzara and Alexandr Naumchev and Bertrand Meyer},
  doi          = {10.1145/3448975},
  journal      = {ACM Computing Surveys},
  number       = {5},
  pages        = {93:1–36},
  shortjournal = {ACM Comput. Surv.},
  title        = {The role of formalism in system requirements},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A survey of field-based testing techniques. <em>CSUR</em>,
<em>54</em>(5), 92:1–39. (<a
href="https://doi.org/10.1145/3447240">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Field testing refers to testing techniques that operate in the field to reveal those faults that escape in-house testing. Field testing techniques are becoming increasingly popular with the growing complexity of contemporary software systems. In this article, we present the first systematic survey of field testing approaches over a body of 80 collected studies, and propose their categorization based on the environment and the system on which field testing is performed. We discuss four research questions addressing how software is tested in the field, what is tested in the field, which are the requirements , and how field tests are managed , and identify many challenging research directions.},
  archive      = {J_CSUR},
  author       = {Antonia Bertolino and Pietro Braione and Guglielmo De Angelis and Luca Gazzola and Fitsum Kifetew and Leonardo Mariani and Matteo Orrù and Mauro Pezzè and Roberto Pietrantuono and Stefano Russo and Paolo Tonella},
  doi          = {10.1145/3447240},
  journal      = {ACM Computing Surveys},
  number       = {5},
  pages        = {92:1–39},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey of field-based testing techniques},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Recurrent neural networks for edge intelligence: A survey.
<em>CSUR</em>, <em>54</em>(4), 91:1–38. (<a
href="https://doi.org/10.1145/3448974">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recurrent Neural Networks are ubiquitous and pervasive in many artificial intelligence applications such as speech recognition, predictive healthcare, creative art, and so on. Although they provide accurate superior solutions, they pose a massive challenge “training havoc.” Current expansion of IoT demands intelligent models to be deployed at the edge. This is precisely to handle increasing model sizes and complex network architectures. Design efforts to meet these for greater performance have had inverse effects on portability on edge devices with real-time constraints of memory, latency, and energy. This article provides a detailed insight into various compression techniques widely disseminated in the deep learning regime. They have become key in mapping powerful RNNs onto resource-constrained devices. While compression of RNNs is the main focus of the survey, it also highlights challenges encountered while training. The training procedure directly influences model performance and compression alongside. Recent advancements to overcome the training challenges with their strengths and drawbacks are discussed. In short, the survey covers the three-step process, namely, architecture selection, efficient training process, and suitable compression technique applicable to a resource-constrained environment. It is thus one of the comprehensive survey guides a developer can adapt for a time-series problem context and an RNN solution for the edge.},
  archive      = {J_CSUR},
  author       = {Varsha S. Lalapura and J. Amudha and Hariramn Selvamuruga Satheesh},
  doi          = {10.1145/3448974},
  journal      = {ACM Computing Surveys},
  number       = {4},
  pages        = {91:1–38},
  shortjournal = {ACM Comput. Surv.},
  title        = {Recurrent neural networks for edge intelligence: A survey},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A survey of software log instrumentation. <em>CSUR</em>,
<em>54</em>(4), 90:1–34. (<a
href="https://doi.org/10.1145/3448976">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Log messages have been used widely in many software systems for a variety of purposes during software development and field operation. There are two phases in software logging: log instrumentation and log management. Log instrumentation refers to the practice that developers insert logging code into source code to record runtime information. Log management refers to the practice that operators collect the generated log messages and conduct data analysis techniques to provide valuable insights of runtime behavior. There are many open source and commercial log management tools available. However, their effectiveness highly depends on the quality of the instrumented logging code, as log messages generated by high-quality logging code can greatly ease the process of various log analysis tasks (e.g., monitoring, failure diagnosis, and auditing). Hence, in this article, we conducted a systematic survey on state-of-the-art research on log instrumentation by studying 69 papers between 1997 and 2019. In particular, we have focused on the challenges and proposed solutions used in the three steps of log instrumentation: (1) logging approach; (2) logging utility integration; and (3) logging code composition. This survey will be useful to DevOps practitioners and researchers who are interested in software logging.},
  archive      = {J_CSUR},
  author       = {Boyuan Chen and Zhen Ming (Jack) Jiang},
  doi          = {10.1145/3448976},
  journal      = {ACM Computing Surveys},
  number       = {4},
  pages        = {90:1–34},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey of software log instrumentation},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A systematic review on software robustness assessment.
<em>CSUR</em>, <em>54</em>(4), 89:1–65. (<a
href="https://doi.org/10.1145/3448977">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robustness is the degree to which a certain system or component can operate correctly in the presence of invalid inputs or stressful environmental conditions. With the increasing complexity and widespread use of computer systems, obtaining assurances regarding their robustness has become of vital importance. This survey discusses the state of the art on software robustness assessment, with emphasis on key aspects like types of systems being evaluated, assessment techniques used, the target of the techniques, the types of faults used, and how system behavior is classified. The survey concludes with the identification of gaps and open challenges related with robustness assessment.},
  archive      = {J_CSUR},
  author       = {Nuno Laranjeiro and João Agnelo and Jorge Bernardino},
  doi          = {10.1145/3448977},
  journal      = {ACM Computing Surveys},
  number       = {4},
  pages        = {89:1–65},
  shortjournal = {ACM Comput. Surv.},
  title        = {A systematic review on software robustness assessment},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Self-calibration and collaborative localization for UWB
positioning systems: A survey and future research directions.
<em>CSUR</em>, <em>54</em>(4), 88:1–27. (<a
href="https://doi.org/10.1145/3448303">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ultra-Wideband (UWB) is a Radio Frequency technology that is currently used for accurate indoor localization. However, the cost of deploying such a system is large, mainly due to the need for manually measuring the exact location of the installed infrastructure devices (“anchor nodes”). Self-calibration of UWB reduces deployment costs, because it allows for automatic updating of the coordinates of fixed nodes when they are installed or moved. Additionally, installation costs can also be reduced by using collaborative localization approaches where mobile nodes act as anchors. This article surveys the most significant research that has been done on self-calibration and collaborative localization. First, we find that often these terms are improperly used, leading to confusion for the readers. Furthermore, we find that in most of the cases, UWB-specific characteristics are not exploited, so crucial opportunities to improve performance are lost. Our classification and analysis provide the basis for further research on self-calibration and collaborative localization in the deployment of UWB indoor localization systems. Finally, we identify several research tracks that are open for investigation and can lead to better performance, e.g., machine learning and optimized physical settings.},
  archive      = {J_CSUR},
  author       = {Matteo Ridolfi and Abdil Kaya and Rafael Berkvens and Maarten Weyn and Wout Joseph and Eli De Poorter},
  doi          = {10.1145/3448303},
  journal      = {ACM Computing Surveys},
  number       = {4},
  pages        = {88:1–27},
  shortjournal = {ACM Comput. Surv.},
  title        = {Self-calibration and collaborative localization for UWB positioning systems: A survey and future research directions},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Dimensionality reduction methods for brain imaging data
analysis. <em>CSUR</em>, <em>54</em>(4), 87:1–36. (<a
href="https://doi.org/10.1145/3448302">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The past century has witnessed the grand success of brain imaging technologies, such as electroencephalography and magnetic resonance imaging, in probing cognitive states and pathological brain dynamics for neuroscience research and neurology practices. Human brain is “the most complex object in the universe,” and brain imaging data ( BID ) are routinely of multiple/many attributes and highly non-stationary. These are determined by the nature of BID as the recordings of the evolving processes of the brain(s) under examination in various views. Driven by the increasingly high demands for precision, efficiency, and reliability in neuro-science and engineering tasks, dimensionality reduction has become a priority issue in BID analysis to handle the notoriously high dimensionality and large scale of big BID sets as well as the enormously complicated interdependencies among data elements. This has become particularly urgent and challenging in this big data era. Dimensionality reduction theories and methods manifest unrivaled potential in revealing key insights to BID via offering the low-dimensional/tiny representations/features, which may preserve critical characterizations of massive neuronal activities and brain functional and/or malfunctional states of interest. This study surveys the most salient work along this direction conforming to a 3-dimensional taxonomy with respect to (1) the scale of BID , of which the design with this consideration is important for the potential applications; (2) the order of BID , in which a higher order denotes more BID attributes manipulatable by the method; and (3) linearity , in which the method’s degree of linearity largely determines the “fidelity” in BID exploration. This study defines criteria for qualitative evaluations of these works in terms of effectiveness, interpretability, efficiency, and scalability. The classifications and evaluations based on the taxonomy provide comprehensive guides to (1) how existing research and development efforts are distributed and (2) their performance, features, and potential in influential applications especially when involving big data. In the end, this study crystallizes the open technical issues and proposes research challenges that must be solved to enable further researches in this area of great potential.},
  archive      = {J_CSUR},
  author       = {Yunbo Tang and Dan Chen and Xiaoli Li},
  doi          = {10.1145/3448302},
  journal      = {ACM Computing Surveys},
  number       = {4},
  pages        = {87:1–36},
  shortjournal = {ACM Comput. Surv.},
  title        = {Dimensionality reduction methods for brain imaging data analysis},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Application layer denial-of-service attacks and defense
mechanisms: A survey. <em>CSUR</em>, <em>54</em>(4), 86:1–33. (<a
href="https://doi.org/10.1145/3448291">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Application layer Denial-of-Service (DoS) attacks are generated by exploiting vulnerabilities of the protocol implementation or its design. Unlike volumetric DoS attacks, these are stealthy in nature and target a specific application running on the victim. There are several attacks discovered against popular application layer protocols in recent years. In this article, we provide a structured and comprehensive survey of the existing application layer DoS attacks and defense mechanisms. We classify existing attacks and defense mechanisms into different categories, describe their working, and compare them based on relevant parameters. We conclude the article with directions for future research.},
  archive      = {J_CSUR},
  author       = {Nikhil Tripathi and Neminath Hubballi},
  doi          = {10.1145/3448291},
  journal      = {ACM Computing Surveys},
  number       = {4},
  pages        = {86:1–33},
  shortjournal = {ACM Comput. Surv.},
  title        = {Application layer denial-of-service attacks and defense mechanisms: A survey},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Assessing the performance of interactive multiobjective
optimization methods: A survey. <em>CSUR</em>, <em>54</em>(4), 85:1–27.
(<a href="https://doi.org/10.1145/3448301">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Interactive methods are useful decision-making tools for multiobjective optimization problems, because they allow a decision-maker to provide her/his preference information iteratively in a comfortable way at the same time as (s)he learns about all different aspects of the problem. A wide variety of interactive methods is nowadays available, and they differ from each other in both technical aspects and type of preference information employed. Therefore, assessing the performance of interactive methods can help users to choose the most appropriate one for a given problem. This is a challenging task, which has been tackled from different perspectives in the published literature. We present a bibliographic survey of papers where interactive multiobjective optimization methods have been assessed (either individually or compared to other methods). Besides other features, we collect information about the type of decision-maker involved (utility or value functions, artificial or human decision-maker), the type of preference information provided, and aspects of interactive methods that were somehow measured. Based on the survey and on our own experiences, we identify a series of desirable properties of interactive methods that we believe should be assessed.},
  archive      = {J_CSUR},
  author       = {Bekir Afsar and Kaisa Miettinen and Francisco Ruiz},
  doi          = {10.1145/3448301},
  journal      = {ACM Computing Surveys},
  number       = {4},
  pages        = {85:1–27},
  shortjournal = {ACM Comput. Surv.},
  title        = {Assessing the performance of interactive multiobjective optimization methods: A survey},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Vision-based autonomous vehicle recognition: A new challenge
for deep learning-based systems. <em>CSUR</em>, <em>54</em>(4), 84:1–37.
(<a href="https://doi.org/10.1145/3447866">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vision-based Automated Vehicle Recognition (VAVR) has attracted considerable attention recently. Particularly given the reliance on emerging deep learning methods, which have powerful feature extraction and pattern learning abilities, vehicle recognition has made significant progress. VAVR is an essential part of Intelligent Transportation Systems. The VAVR system can fast and accurately locate a target vehicle, which significantly helps improve regional security. A comprehensive VAVR system contains three components: Vehicle Detection (VD), Vehicle Make and Model Recognition (VMMR), and Vehicle Re-identification (VRe-ID). These components perform coarse-to-fine recognition tasks in three steps. In this article, we conduct a thorough review and comparison of the state-of-the-art deep learning--based models proposed for VAVR. We present a detailed introduction to different vehicle recognition datasets used for a comprehensive evaluation of the proposed models. We also critically discuss the major challenges and future research trends involved in each task. Finally, we summarize the characteristics of the methods for each task. Our comprehensive model analysis will help researchers that are interested in VD, VMMR, and VRe-ID and provide them with possible directions to solve current challenges and further improve the performance and robustness of models.},
  archive      = {J_CSUR},
  author       = {Azzedine Boukerche and Xiren Ma},
  doi          = {10.1145/3447866},
  journal      = {ACM Computing Surveys},
  number       = {4},
  pages        = {84:1–37},
  shortjournal = {ACM Comput. Surv.},
  title        = {Vision-based autonomous vehicle recognition: A new challenge for deep learning-based systems},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Hardware information flow tracking. <em>CSUR</em>,
<em>54</em>(4), 83:1–39. (<a
href="https://doi.org/10.1145/3447867">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Information flow tracking (IFT) is a fundamental computer security technique used to understand how information moves through a computing system. Hardware IFT techniques specifically target security vulnerabilities related to the design, verification, testing, manufacturing, and deployment of hardware circuits. Hardware IFT can detect unintentional design flaws, malicious circuit modifications, timing side channels, access control violations, and other insecure hardware behaviors. This article surveys the area of hardware IFT. We start with a discussion on the basics of IFT, whose foundations were introduced by Denning in the 1970s. Building upon this, we develop a taxonomy for hardware IFT. We use this to classify and differentiate hardware IFT tools and techniques. Finally, we discuss the challenges yet to be resolved. The survey shows that hardware IFT provides a powerful technique for identifying hardware security vulnerabilities, as well as verifying and enforcing hardware security properties.},
  archive      = {J_CSUR},
  author       = {Wei Hu and Armaiti Ardeshiricham and Ryan Kastner},
  doi          = {10.1145/3447867},
  journal      = {ACM Computing Surveys},
  number       = {4},
  pages        = {83:1–39},
  shortjournal = {ACM Comput. Surv.},
  title        = {Hardware information flow tracking},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The programmable data plane: Abstractions, architectures,
algorithms, and applications. <em>CSUR</em>, <em>54</em>(4), 82:1–36.
(<a href="https://doi.org/10.1145/3447868">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Programmable data plane technologies enable the systematic reconfiguration of the low-level processing steps applied to network packets and are key drivers toward realizing the next generation of network services and applications. This survey presents recent trends and issues in the design and implementation of programmable network devices, focusing on prominent abstractions, architectures, algorithms, and applications proposed, debated, and realized over the past years. We elaborate on the trends that led to the emergence of this technology and highlight the most important pointers from the literature, casting different taxonomies for the field, and identifying avenues for future research.},
  archive      = {J_CSUR},
  author       = {Oliver Michel and Roberto Bifulco and Gábor Rétvári and Stefan Schmid},
  doi          = {10.1145/3447868},
  journal      = {ACM Computing Surveys},
  number       = {4},
  pages        = {82:1–36},
  shortjournal = {ACM Comput. Surv.},
  title        = {The programmable data plane: Abstractions, architectures, algorithms, and applications},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Voice in human–agent interaction: A survey. <em>CSUR</em>,
<em>54</em>(4), 81:1–43. (<a
href="https://doi.org/10.1145/3386867">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Social robots, conversational agents, voice assistants, and other embodied AI are increasingly a feature of everyday life. What connects these various types of intelligent agents is their ability to interact with people through voice. Voice is becoming an essential modality of embodiment, communication, and interaction between computer-based agents and end-users. This survey presents a meta-synthesis on agent voice in the design and experience of agents from a human-centered perspective: voice-based human–agent interaction (vHAI). Findings emphasize the social role of voice in HAI as well as circumscribe a relationship between agent voice and body, corresponding to human models of social psychology and cognition. Additionally, changes in perceptions of and reactions to agent voice over time reveals a generational shift coinciding with the commercial proliferation of mobile voice assistants. The main contributions of this work are a vHAI classification framework for voice across various agent forms, contexts, and user groups, a critical analysis grounded in key theories, and an identification of future directions for the oncoming wave of vocal machines.},
  archive      = {J_CSUR},
  author       = {Katie Seaborn and Norihisa P. Miyake and Peter Pennefather and Mihoko Otake-Matsuura},
  doi          = {10.1145/3386867},
  journal      = {ACM Computing Surveys},
  number       = {4},
  pages        = {81:1–43},
  shortjournal = {ACM Comput. Surv.},
  title        = {Voice in Human–Agent interaction: A survey},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Recommendations on statistical randomness test batteries for
cryptographic purposes. <em>CSUR</em>, <em>54</em>(4), 80:1–34. (<a
href="https://doi.org/10.1145/3447773">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Security in different applications is closely related to the goodness of the sequences generated for such purposes. Not only in Cryptography but also in other areas, it is necessary to obtain long sequences of random numbers or that, at least, behave as such. To decide whether the generator used produces sequences that are random, unpredictable and independent, statistical checks are needed. Different batteries of hypothesis tests have been proposed for this purpose. In this work, a survey of the main test batteries is presented, indicating their pros and cons, giving some guidelines for their use and presenting some practical examples.},
  archive      = {J_CSUR},
  author       = {Elena Almaraz Luengo and Luis Javier García Villalba},
  doi          = {10.1145/3447773},
  journal      = {ACM Computing Surveys},
  number       = {4},
  pages        = {80:1–34},
  shortjournal = {ACM Comput. Surv.},
  title        = {Recommendations on statistical randomness test batteries for cryptographic purposes},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Probabilistic rule learning systems: A survey.
<em>CSUR</em>, <em>54</em>(4), 79:1–16. (<a
href="https://doi.org/10.1145/3447581">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This survey provides an overview of rule learning systems that can learn the structure of probabilistic rules for uncertain domains. These systems are very useful in such domains because they can be trained with a small amount of positive and negative examples, use declarative representations of background knowledge, and combine efficient high-level reasoning with the probability theory. The output of these systems are probabilistic rules that are easy to understand by humans, since the conditions for consequences lead to predictions that become transparent and interpretable. This survey focuses on representational approaches and system architectures, and suggests future research directions.},
  archive      = {J_CSUR},
  author       = {Abdus Salam and Rolf Schwitter and Mehmet A. Orgun},
  doi          = {10.1145/3447581},
  journal      = {ACM Computing Surveys},
  number       = {4},
  pages        = {79:1–16},
  shortjournal = {ACM Comput. Surv.},
  title        = {Probabilistic rule learning systems: A survey},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). PLS-SEM for software engineering research: An introduction
and survey. <em>CSUR</em>, <em>54</em>(4), 78:1–38. (<a
href="https://doi.org/10.1145/3447580">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Software Engineering (SE) researchers are increasingly paying attention to organizational and human factors. Rather than focusing only on variables that can be directly measured, such as lines of code, SE research studies now also consider unobservable variables, such as organizational culture and trust. To measure such latent variables, SE scholars have adopted Partial Least Squares Structural Equation Modeling (PLS-SEM), which is one member of the larger SEM family of statistical analysis techniques. As the SE field is facing the introduction of new methods such as PLS-SEM, a key issue is that not much is known about how to evaluate such studies. To help SE researchers learn about PLS-SEM, we draw on the latest methodological literature on PLS-SEM to synthesize an introduction. Further, we conducted a survey of PLS-SEM studies in the SE literature and evaluated those based on recommended guidelines.},
  archive      = {J_CSUR},
  author       = {Daniel Russo and Klaas-Jan Stol},
  doi          = {10.1145/3447580},
  journal      = {ACM Computing Surveys},
  number       = {4},
  pages        = {78:1–38},
  shortjournal = {ACM Comput. Surv.},
  title        = {PLS-SEM for software engineering research: An introduction and survey},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Deep learning for sensor-based human activity recognition:
Overview, challenges, and opportunities. <em>CSUR</em>, <em>54</em>(4),
77:1–40. (<a href="https://doi.org/10.1145/3447744">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The vast proliferation of sensor devices and Internet of Things enables the applications of sensor-based activity recognition. However, there exist substantial challenges that could influence the performance of the recognition system in practical scenarios. Recently, as deep learning has demonstrated its effectiveness in many areas, plenty of deep methods have been investigated to address the challenges in activity recognition. In this study, we present a survey of the state-of-the-art deep learning methods for sensor-based human activity recognition. We first introduce the multi-modality of the sensory data and provide information for public datasets that can be used for evaluation in different challenge tasks. We then propose a new taxonomy to structure the deep methods by challenges. Challenges and challenge-related deep methods are summarized and analyzed to form an overview of the current research progress. At the end of this work, we discuss the open issues and provide some insights for future directions.},
  archive      = {J_CSUR},
  author       = {Kaixuan Chen and Dalin Zhang and Lina Yao and Bin Guo and Zhiwen Yu and Yunhao Liu},
  doi          = {10.1145/3447744},
  journal      = {ACM Computing Surveys},
  number       = {4},
  pages        = {77:1–40},
  shortjournal = {ACM Comput. Surv.},
  title        = {Deep learning for sensor-based human activity recognition: Overview, challenges, and opportunities},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A comprehensive survey of neural architecture search:
Challenges and solutions. <em>CSUR</em>, <em>54</em>(4), 76:1–34. (<a
href="https://doi.org/10.1145/3447582">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning has made substantial breakthroughs in many fields due to its powerful automatic representation capabilities. It has been proven that neural architecture design is crucial to the feature representation of data and the final performance. However, the design of the neural architecture heavily relies on the researchers’ prior knowledge and experience. And due to the limitations of humans’ inherent knowledge, it is difficult for people to jump out of their original thinking paradigm and design an optimal model. Therefore, an intuitive idea would be to reduce human intervention as much as possible and let the algorithm automatically design the neural architecture. Neural Architecture Search ( NAS ) is just such a revolutionary algorithm, and the related research work is complicated and rich. Therefore, a comprehensive and systematic survey on the NAS is essential. Previously related surveys have begun to classify existing work mainly based on the key components of NAS: search space, search strategy, and evaluation strategy. While this classification method is more intuitive, it is difficult for readers to grasp the challenges and the landmark work involved. Therefore, in this survey, we provide a new perspective: beginning with an overview of the characteristics of the earliest NAS algorithms, summarizing the problems in these early NAS algorithms, and then providing solutions for subsequent related research work. In addition, we conduct a detailed and comprehensive analysis, comparison, and summary of these works. Finally, we provide some possible future research directions.},
  archive      = {J_CSUR},
  author       = {Pengzhen Ren and Yun Xiao and Xiaojun Chang and Po-yao Huang and Zhihui Li and Xiaojiang Chen and Xin Wang},
  doi          = {10.1145/3447582},
  journal      = {ACM Computing Surveys},
  number       = {4},
  pages        = {76:1–34},
  shortjournal = {ACM Comput. Surv.},
  title        = {A comprehensive survey of neural architecture search: Challenges and solutions},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). IoT cloud security review: A case study approach using
emerging consumer-oriented applications. <em>CSUR</em>, <em>54</em>(4),
75:1–36. (<a href="https://doi.org/10.1145/3447625">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent years have seen the rapid development and integration of the Internet of Things (IoT) and cloud computing. The market is providing various consumer-oriented smart IoT devices; the mainstream cloud service providers are building their software stacks to support IoT services. With this emerging trend even growing, the security of such smart IoT cloud systems has drawn much research attention in recent years. To better understand the emerging consumer-oriented smart IoT cloud systems for practical engineers and new researchers, this article presents a review of the most recent research efforts on existing, real, already deployed consumer-oriented IoT cloud applications in the past five years using typical case studies. Specifically, we first present a general model for the IoT cloud ecosystem. Then, using the model, we review and summarize recent, representative research works on emerging smart IoT cloud system security using 10 detailed case studies, with the aim that the case studies together provide insights into the insecurity of current emerging IoT cloud systems. We further present a systematic approach to conduct a security analysis for IoT cloud systems. Based on the proposed security analysis approach, we review and suggest potential security risk mitigation methods to protect IoT cloud systems. We also discuss future research challenges for the IoT cloud security area.},
  archive      = {J_CSUR},
  author       = {Fei Chen and Duming Luo and Tao Xiang and Ping Chen and Junfeng Fan and Hong-Linh Truong},
  doi          = {10.1145/3447625},
  journal      = {ACM Computing Surveys},
  number       = {4},
  pages        = {75:1–36},
  shortjournal = {ACM Comput. Surv.},
  title        = {IoT cloud security review: A case study approach using emerging consumer-oriented applications},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Uncertainty-aware decisions in cloud computing: Foundations
and future directions. <em>CSUR</em>, <em>54</em>(4), 74:1–30. (<a
href="https://doi.org/10.1145/3447583">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid growth of the cloud industry has increased challenges in the proper governance of the cloud infrastructure. Many intelligent systems have been developing, considering uncertainties in the cloud. Intelligent approaches with the consideration of uncertainties bring optimal management with higher profitability. Uncertainties of different levels and different types exist in various domains of cloud computing. This survey aims to discuss all types of uncertainties and their effect on different components of cloud computing. The article first presents the concept of uncertainty and its quantification. A vast number of uncertain events influence the cloud, as it is connected with the entire world through the internet. Five major uncertain parameters are identified, which are directly affected by numerous uncertain events and affect the performance of the cloud. Notable events affecting major uncertain parameters are also described. Besides, we present notable uncertainty-aware research works in cloud computing. A hype curve on uncertainty-aware approaches in the cloud is also presented to visualize current conditions and future possibilities. We expect the inauguration of numerous uncertainty-aware intelligent systems in cloud management over time. This article may provide a deeper understanding of managing cloud resources with uncertainties efficiently to future cloud researchers.},
  archive      = {J_CSUR},
  author       = {H. M. Dipu Kabir and Abbas Khosravi and Subrota K. Mondal and Mustaneer Rahman and Saeid Nahavandi and Rajkumar Buyya},
  doi          = {10.1145/3447583},
  journal      = {ACM Computing Surveys},
  number       = {4},
  pages        = {74:1–30},
  shortjournal = {ACM Comput. Surv.},
  title        = {Uncertainty-aware decisions in cloud computing: Foundations and future directions},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A survey of ambient intelligence. <em>CSUR</em>,
<em>54</em>(4), 73:1–27. (<a
href="https://doi.org/10.1145/3447242">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ambient Intelligence (AmI) is the application and embedding of artificial intelligence into everyday environments to seamlessly provide assistive and predictive support in a multitude of scenarios via an invisible user interface. These can be as diverse as autonomous vehicles, smart homes, industrial settings, and healthcare facilities—referred to as Ambient Assistive Living. This survey gives an overview of the field; defines key terms; discusses social, cultural, and ethical issues; and outlines the state of the art in AmI technology, and where opportunities for further research exist. We guide the reader through AmI from its inception more than 20 years ago, focussing on the important topics and research achievements of the past 10 years since the last major survey, before finally detailing the most recents research trends and forecasting where this technology is likely to develop. This survey covers domains, use cases, scenarios, and datasets; cultural concerns and usability issues; security, privacy, and ethics; interaction and recognition; prediction and intelligence; and hardware, infrastructure, and mobile devices. This survey serves as an introduction for researchers and the technical layperson into the topic of AmI and identifies notable opportunities for further research.},
  archive      = {J_CSUR},
  author       = {Rob Dunne and Tim Morris and Simon Harper},
  doi          = {10.1145/3447242},
  journal      = {ACM Computing Surveys},
  number       = {4},
  pages        = {73:1–27},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey of ambient intelligence},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Fashion meets computer vision: A survey. <em>CSUR</em>,
<em>54</em>(4), 72:1–41. (<a
href="https://doi.org/10.1145/3447239">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fashion is the way we present ourselves to the world and has become one of the world’s largest industries. Fashion, mainly conveyed by vision, has thus attracted much attention from computer vision researchers in recent years. Given the rapid development, this article provides a comprehensive survey of more than 200 major fashion-related works covering four main aspects for enabling intelligent fashion: (1) Fashion detection includes landmark detection, fashion parsing, and item retrieval; (2) Fashion analysis contains attribute recognition, style learning, and popularity prediction; (3) Fashion synthesis involves style transfer, pose transformation, and physical simulation; and (4) Fashion recommendation comprises fashion compatibility, outfit matching, and hairstyle suggestion. For each task, the benchmark datasets and the evaluation protocols are summarized. Furthermore, we highlight promising directions for future research.},
  archive      = {J_CSUR},
  author       = {Wen-Huang Cheng and Sijie Song and Chieh-Yun Chen and Shintami Chusnul Hidayati and Jiaying Liu},
  doi          = {10.1145/3447239},
  journal      = {ACM Computing Surveys},
  number       = {4},
  pages        = {72:1–41},
  shortjournal = {ACM Comput. Surv.},
  title        = {Fashion meets computer vision: A survey},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Knowledge graphs. <em>CSUR</em>, <em>54</em>(4), 71:1–37.
(<a href="https://doi.org/10.1145/3447772">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we provide a comprehensive introduction to knowledge graphs, which have recently garnered significant attention from both industry and academia in scenarios that require exploiting diverse, dynamic, large-scale collections of data. After some opening remarks, we motivate and contrast various graph-based data models, as well as languages used to query and validate knowledge graphs. We explain how knowledge can be represented and extracted using a combination of deductive and inductive techniques. We conclude with high-level future research directions for knowledge graphs.},
  archive      = {J_CSUR},
  author       = {Aidan Hogan and Eva Blomqvist and Michael Cochez and Claudia D’amato and Gerard De Melo and Claudio Gutierrez and Sabrina Kirrane and José Emilio Labra Gayo and Roberto Navigli and Sebastian Neumaier and Axel-Cyrille Ngonga Ngomo and Axel Polleres and Sabbir M. Rashid and Anisa Rula and Lukas Schmelzeisen and Juan Sequeda and Steffen Staab and Antoine Zimmermann},
  doi          = {10.1145/3447772},
  journal      = {ACM Computing Surveys},
  number       = {4},
  pages        = {71:1–37},
  shortjournal = {ACM Comput. Surv.},
  title        = {Knowledge graphs},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Principal component analysis: A natural approach to data
exploration. <em>CSUR</em>, <em>54</em>(4), 70:1–34. (<a
href="https://doi.org/10.1145/3447755">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Principal component analysis (PCA) is often applied for analyzing data in the most diverse areas. This work reports, in an accessible and integrated manner, several theoretical and practical aspects of PCA. The basic principles underlying PCA, data standardization, possible visualizations of the PCA results, and outlier detection are subsequently addressed. Next, the potential of using PCA for dimensionality reduction is illustrated on several real-world datasets. Finally, we summarize PCA-related approaches and other dimensionality reduction techniques. All in all, the objective of this work is to assist researchers from the most diverse areas in using and interpreting PCA.},
  archive      = {J_CSUR},
  author       = {Felipe L. Gewers and Gustavo R. Ferreira and Henrique F. De Arruda and Filipi N. Silva and Cesar H. Comin and Diego R. Amancio and Luciano Da F. Costa},
  doi          = {10.1145/3447755},
  journal      = {ACM Computing Surveys},
  number       = {4},
  pages        = {70:1–34},
  shortjournal = {ACM Comput. Surv.},
  title        = {Principal component analysis: A natural approach to data exploration},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Social media identity deception detection: A survey.
<em>CSUR</em>, <em>54</em>(3), 69:1–35. (<a
href="https://doi.org/10.1145/3446372">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Social media have been growing rapidly and become essential elements of many people’s lives. Meanwhile, social media have also come to be a popular source for identity deception. Many social media identity deception cases have arisen over the past few years. Recent studies have been conducted to prevent and detect identity deception. This survey analyzes various identity deception attacks, which can be categorized into fake profile, identity theft, and identity cloning. This survey provides a detailed review of social media identity deception detection techniques. It also identifies primary research challenges and issues in the existing detection techniques. This article is expected to benefit both researchers and social media providers.},
  archive      = {J_CSUR},
  author       = {Ahmed Alharbi and Hai Dong and Xun Yi and Zahir Tari and Ibrahim Khalil},
  doi          = {10.1145/3446372},
  journal      = {ACM Computing Surveys},
  number       = {3},
  pages        = {69:1–35},
  shortjournal = {ACM Comput. Surv.},
  title        = {Social media identity deception detection: A survey},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Fuzzy logic in surveillance big video data analysis:
Comprehensive review, challenges, and research directions.
<em>CSUR</em>, <em>54</em>(3), 68:1–33. (<a
href="https://doi.org/10.1145/3444693">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {CCTV cameras installed for continuous surveillance generate enormous amounts of data daily, forging the term Big Video Data (BVD). The active practice of BVD includes intelligent surveillance and activity recognition, among other challenging tasks. To efficiently address these tasks, the computer vision research community has provided monitoring systems, activity recognition methods, and many other computationally complex solutions for the purposeful usage of BVD. Unfortunately, the limited capabilities of these methods, higher computational complexity, and stringent installation requirements hinder their practical implementation in real-world scenarios, which still demand human operators sitting in front of cameras to monitor activities or make actionable decisions based on BVD. The usage of human-like logic, known as fuzzy logic, has been employed emerging for various data science applications such as control systems, image processing, decision making, routing, and advanced safety-critical systems. This is due to its ability to handle various sources of real-world domain and data uncertainties, generating easily adaptable and explainable data-based models. Fuzzy logic can be effectively used for surveillance as a complementary for huge-sized artificial intelligence models and tiresome training procedures. In this article, we draw researchers’ attention toward the usage of fuzzy logic for surveillance in the context of BVD. We carry out a comprehensive literature survey of methods for vision sensory data analytics that resort to fuzzy logic concepts. Our overview highlights the advantages, downsides, and challenges in existing video analysis methods based on fuzzy logic for surveillance applications. We enumerate and discuss the datasets used by these methods, and finally provide an outlook toward future research directions derived from our critical assessment of the efforts invested so far in this exciting field.},
  archive      = {J_CSUR},
  author       = {Khan Muhammad and Mohammad S. Obaidat and Tanveer Hussain and Javier Del Ser and Neeraj Kumar and Mohammad Tanveer and Faiyaz Doctor},
  doi          = {10.1145/3444693},
  journal      = {ACM Computing Surveys},
  number       = {3},
  pages        = {68:1–33},
  shortjournal = {ACM Comput. Surv.},
  title        = {Fuzzy logic in surveillance big video data analysis: Comprehensive review, challenges, and research directions},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Ultrasound medical imaging techniques: A survey.
<em>CSUR</em>, <em>54</em>(3), 67:1–38. (<a
href="https://doi.org/10.1145/3447243">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ultrasound (US) imaging for medical purposes has been increasing in popularity over the years. The US technology has some valuable strengths, such as it is harmless, very cheap, and can provide real-time feedback. At the same time, it has also some drawbacks that the research in this field is trying to mitigate, such as the high level of noise and the low quality of the images. This survey aims at presenting the advances in the techniques used for US medical imaging. It describes the studies on the different organs that the US uses the most and tries to categorize the research in this field into three groups, i.e., segmentation, classification, and miscellaneous. This latter group includes the works that either provide aid during surgical operations or try to enhance the quality of the acquired US images/volumes. To the best of our knowledge, this is the first review that analyzes the different techniques exploited on a large selection of body locations (i.e., brain, thyroid, heart, breast, fetal, and prostate) in the three sub-fields of research.},
  archive      = {J_CSUR},
  author       = {Danilo Avola and Luigi Cinque and Alessio Fagioli and Gianluca Foresti and Alessio Mecca},
  doi          = {10.1145/3447243},
  journal      = {ACM Computing Surveys},
  number       = {3},
  pages        = {67:1–38},
  shortjournal = {ACM Comput. Surv.},
  title        = {Ultrasound medical imaging techniques: A survey},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A survey on edge performance benchmarking. <em>CSUR</em>,
<em>54</em>(3), 66:1–33. (<a
href="https://doi.org/10.1145/3444692">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Edge computing is the next Internet frontier that will leverage computing resources located near users, sensors, and data stores to provide more responsive services. Therefore, it is envisioned that a large-scale, geographically dispersed, and resource-rich distributed system will emerge and play a key role in the future Internet. However, given the loosely coupled nature of such complex systems, their operational conditions are expected to change significantly over time. In this context, the performance characteristics of such systems will need to be captured rapidly, which is referred to as performance benchmarking, for application deployment, resource orchestration, and adaptive decision-making. Edge performance benchmarking is a nascent research avenue that has started gaining momentum over the past five years. This article first reviews articles published over the past three decades to trace the history of performance benchmarking from tightly coupled to loosely coupled systems. It then systematically classifies previous research to identify the system under test, techniques analyzed, and benchmark runtime in edge performance benchmarking.},
  archive      = {J_CSUR},
  author       = {Blesson Varghese and Nan Wang and David Bermbach and Cheol-Ho Hong and Eyal De Lara and Weisong Shi and Christopher Stewart},
  doi          = {10.1145/3444692},
  journal      = {ACM Computing Surveys},
  number       = {3},
  pages        = {66:1–33},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey on edge performance benchmarking},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Syntactic pattern recognition in computer vision: A
systematic review. <em>CSUR</em>, <em>54</em>(3), 65:1–35. (<a
href="https://doi.org/10.1145/3447241">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Using techniques derived from the syntactic methods for visual pattern recognition is not new and was much explored in the area called syntactical or structural pattern recognition. Syntactic methods have been useful because they are intuitively simple to understand and have transparent, interpretable, and elegant representations. Their capacity to represent patterns in a semantic, hierarchical, compositional, spatial, and temporal way have made them very popular in the research community. In this article, we try to give an overview of how syntactic methods have been employed for computer vision tasks. We conduct a systematic literature review to survey the most relevant studies that use syntactic methods for pattern recognition tasks in images and videos. Our search returned 597 papers, of which 71 papers were selected for analysis. The results indicated that in most of the studies surveyed, the syntactic methods were used as a high-level structure that makes the hierarchical or semantic relationship among objects or actions to perform the most diverse tasks.},
  archive      = {J_CSUR},
  author       = {Gilberto Astolfi and Fábio Prestes Cesar Rezende and João Vitor De Andrade Porto and Edson Takashi Matsubara and Hemerson Pistori},
  doi          = {10.1145/3447241},
  journal      = {ACM Computing Surveys},
  number       = {3},
  pages        = {65:1–35},
  shortjournal = {ACM Comput. Surv.},
  title        = {Syntactic pattern recognition in computer vision: A systematic review},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). User response prediction in online advertising.
<em>CSUR</em>, <em>54</em>(3), 64:1–43. (<a
href="https://doi.org/10.1145/3446662">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Online advertising, as a vast market, has gained significant attention in various platforms ranging from search engines, third-party websites, social media, and mobile apps. The prosperity of online campaigns is a challenge in online marketing and is usually evaluated by user response through different metrics, such as clicks on advertisement (ad) creatives, subscriptions to products, purchases of items, or explicit user feedback through online surveys. Recent years have witnessed a significant increase in the number of studies using computational approaches, including machine learning methods, for user response prediction. However, existing literature mainly focuses on algorithmic-driven designs to solve specific challenges, and no comprehensive review exists to answer many important questions. What are the parties involved in the online digital advertising eco-systems? What type of data are available for user response prediction? How do we predict user response in a reliable and/or transparent way? In this survey, we provide a comprehensive review of user response prediction in online advertising and related recommender applications. Our essential goal is to provide a thorough understanding of online advertising platforms, stakeholders, data availability, and typical ways of user response prediction. We propose a taxonomy to categorize state-of-the-art user response prediction methods, primarily focusing on the current progress of machine learning methods used in different online platforms. In addition, we also review applications of user response prediction, benchmark datasets, and open source codes in the field.},
  archive      = {J_CSUR},
  author       = {Zhabiz Gharibshah and Xingquan Zhu},
  doi          = {10.1145/3446662},
  journal      = {ACM Computing Surveys},
  number       = {3},
  pages        = {64:1–43},
  shortjournal = {ACM Comput. Surv.},
  title        = {User response prediction in online advertising},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Generative adversarial networks (GANs): Challenges,
solutions, and future directions. <em>CSUR</em>, <em>54</em>(3),
63:1–42. (<a href="https://doi.org/10.1145/3446374">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generative Adversarial Networks (GANs) is a novel class of deep generative models that has recently gained significant attention. GANs learn complex and high-dimensional distributions implicitly over images, audio, and data. However, there exist major challenges in training of GANs, i.e., mode collapse, non-convergence, and instability, due to inappropriate design of network architectre, use of objective function, and selection of optimization algorithm. Recently, to address these challenges, several solutions for better design and optimization of GANs have been investigated based on techniques of re-engineered network architectures, new objective functions, and alternative optimization algorithms. To the best of our knowledge, there is no existing survey that has particularly focused on the broad and systematic developments of these solutions. In this study, we perform a comprehensive survey of the advancements in GANs design and optimization solutions proposed to handle GANs challenges. We first identify key research issues within each design and optimization technique and then propose a new taxonomy to structure solutions by key research issues. In accordance with the taxonomy, we provide a detailed discussion on different GANs variants proposed within each solution and their relationships. Finally, based on the insights gained, we present promising research directions in this rapidly growing field.},
  archive      = {J_CSUR},
  author       = {Divya Saxena and Jiannong Cao},
  doi          = {10.1145/3446374},
  journal      = {ACM Computing Surveys},
  number       = {3},
  pages        = {63:1–42},
  shortjournal = {ACM Comput. Surv.},
  title        = {Generative adversarial networks (GANs): Challenges, solutions, and future directions},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Deep learning–based text classification: A comprehensive
review. <em>CSUR</em>, <em>54</em>(3), 62:1–40. (<a
href="https://doi.org/10.1145/3439726">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning--based models have surpassed classical machine learning--based approaches in various text classification tasks, including sentiment analysis, news categorization, question answering, and natural language inference. In this article, we provide a comprehensive review of more than 150 deep learning--based models for text classification developed in recent years, and we discuss their technical contributions, similarities, and strengths. We also provide a summary of more than 40 popular datasets widely used for text classification. Finally, we provide a quantitative analysis of the performance of different deep learning models on popular benchmarks, and we discuss future research directions.},
  archive      = {J_CSUR},
  author       = {Shervin Minaee and Nal Kalchbrenner and Erik Cambria and Narjes Nikzad and Meysam Chenaghlu and Jianfeng Gao},
  doi          = {10.1145/3439726},
  journal      = {ACM Computing Surveys},
  number       = {3},
  pages        = {62:1–40},
  shortjournal = {ACM Comput. Surv.},
  title        = {Deep learning--based text classification: A comprehensive review},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Access control mechanisms in named data networks: A
comprehensive survey. <em>CSUR</em>, <em>54</em>(3), 61:1–35. (<a
href="https://doi.org/10.1145/3442150">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Information-Centric Networking (ICN) has recently emerged as a prominent candidate for the Future Internet Architecture (FIA) that addresses existing issues with the host-centric communication model of the current TCP/IP-based Internet. Named Data Networking (NDN) is one of the most recent and active ICN architectures that provides a clean-slate approach for Internet communication. NDN provides intrinsic content security where security is directly provided to the content instead of communication channel. Among other security aspects, Access Control (AC) rules specify the privileges for the entities that can access the content. In TCP/IP-based AC systems, due to the client-server communication model, the servers control which client can access a particular content. In contrast, ICN-based networks use content names to drive communication and decouple the content from its original location. This phenomenon leads to the loss of control over the content, causing different challenges for the realization of efficient AC mechanisms. To date, considerable efforts have been made to develop various AC mechanisms in NDN. In this article, we provide a detailed and comprehensive survey of the AC mechanisms in NDN. We follow a holistic approach towards AC in NDN where we first summarize the ICN paradigm, describe the changes from channel-based security to content-based security, and highlight different cryptographic algorithms and security protocols in NDN. We then classify the existing AC mechanisms into two main categories: Encryption-based AC and Encryption-independent AC . Each category has different classes based on the working principle of AC (e.g., Attribute-based AC, Name-based AC, Identity-based AC). Finally, we present the lessons learned from the existing AC mechanisms and identify the challenges of NDN-based AC at large, highlighting future research directions for the community.},
  archive      = {J_CSUR},
  author       = {Boubakr Nour and Hakima Khelifi and Rasheed Hussain and Spyridon Mastorakis and Hassine Moungla},
  doi          = {10.1145/3442150},
  journal      = {ACM Computing Surveys},
  number       = {3},
  pages        = {61:1–35},
  shortjournal = {ACM Comput. Surv.},
  title        = {Access control mechanisms in named data networks: A comprehensive survey},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The application of the blockchain technology in voting
systems: A review. <em>CSUR</em>, <em>54</em>(3), 60:1–28. (<a
href="https://doi.org/10.1145/3439725">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Voting is a formal expression of opinion or choice, either positive or negative, made by an individual or a group of individuals. However, conventional voting systems tend to be centralized, which are known to suffer from security and efficiency limitations. Hence, there has been a trend of moving to decentralized voting systems, such as those based on blockchain. The latter is a decentralized digital ledger in a peer-to-peer network, where a copy of the append-only ledger of digitally signed and encrypted transactions is maintained by each participant. Therefore, in this article, we perform a comprehensive review of blockchain-based voting systems and classify them based on a number of features (e.g., the types of blockchain used, the consensus approaches used, and the scale of participants). By systematically analyzing and comparing the different blockchain-based voting systems, we also identify a number of limitations and research opportunities. Hopefully, this survey will provide an in-depth insight into the potential utility of blockchain in voting systems and device future research agenda.},
  archive      = {J_CSUR},
  author       = {Jun Huang and Debiao He and Mohammad S. Obaidat and Pandi Vijayakumar and Min Luo and Kim-Kwang Raymond Choo},
  doi          = {10.1145/3439725},
  journal      = {ACM Computing Surveys},
  number       = {3},
  pages        = {60:1–28},
  shortjournal = {ACM Comput. Surv.},
  title        = {The application of the blockchain technology in voting systems: A review},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Human induction in machine learning: A survey of the nexus.
<em>CSUR</em>, <em>54</em>(3), 59:1–18. (<a
href="https://doi.org/10.1145/3444691">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As our epistemic ambitions grow, the common and scientific endeavours are becoming increasingly dependent on Machine Learning (ML). The field rests on a single experimental paradigm, which consists of splitting the available data into a training and testing set and using the latter to measure how well the trained ML model generalises to unseen samples. If the model reaches acceptable accuracy, then an a posteriori contract comes into effect between humans and the model, supposedly allowing its deployment to target environments. Yet the latter part of the contract depends on human inductive predictions or generalisations, which infer a uniformity between the trained ML model and the targets. The article asks how we justify the contract between human and machine learning. It is argued that the justification becomes a pressing issue when we use ML to reach “elsewhere” in space and time or deploy ML models in non-benign environments. The article argues that the only viable version of the contract can be based on optimality (instead of on reliability, which cannot be justified without circularity) and aligns this position with Schurz&#39;s optimality justification. It is shown that when dealing with inaccessible/unstable ground-truths (“elsewhere” and non-benign targets), the optimality justification undergoes a slight change, which should reflect critically on our epistemic ambitions. Therefore, the study of ML robustness should involve not only heuristics that lead to acceptable accuracies on testing sets. The justification of human inductive predictions or generalisations about the uniformity between ML models and targets should be included as well. Without it, the assumptions about inductive risk minimisation in ML are not addressed in full.},
  archive      = {J_CSUR},
  author       = {Petr Spelda and Vit Stritecky},
  doi          = {10.1145/3444691},
  journal      = {ACM Computing Surveys},
  number       = {3},
  pages        = {59:1–18},
  shortjournal = {ACM Comput. Surv.},
  title        = {Human induction in machine learning: A survey of the nexus},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Blockchain-empowered data-driven networks: A survey and
outlook. <em>CSUR</em>, <em>54</em>(3), 58:1–38. (<a
href="https://doi.org/10.1145/3446373">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paths leading to future networks are pointing towards a data-driven paradigm to better cater to the explosive growth of mobile services as well as the increasing heterogeneity of mobile devices, many of which generate and consume large volumes and variety of data. These paths are also hampered by significant challenges in terms of security, privacy, services provisioning, and network management. Blockchain, which is a technology for building distributed ledgers that provide an immutable log of transactions recorded in a distributed network, has become prominent recently as the underlying technology of cryptocurrencies and is revolutionizing data storage and processing in computer network systems. For future data-driven networks (DDNs), blockchain is considered as a promising solution to enable the secure storage, sharing, and analytics of data, privacy protection for users, robust, trustworthy network control, and decentralized routing and resource managements. However, many important challenges and open issues remain to be addressed before blockchain can be deployed widely to enable future DDNs. In this article, we present a survey on the existing research works on the application of blockchain technologies in computer networks and identify challenges and potential solutions in the applications of blockchains in future DDNs. We identify application scenarios in which future blockchain-empowered DDNs could improve the efficiency and security, and generally the effectiveness of network services.},
  archive      = {J_CSUR},
  author       = {Xi Li and Zehua Wang and Victor C. M. Leung and Hong Ji and Yiming Liu and Heli Zhang},
  doi          = {10.1145/3446373},
  journal      = {ACM Computing Surveys},
  number       = {3},
  pages        = {58:1–38},
  shortjournal = {ACM Comput. Surv.},
  title        = {Blockchain-empowered data-driven networks: A survey and outlook},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Cybersecurity standards in the context of operating system:
Practical aspects, analysis, and comparisons. <em>CSUR</em>,
<em>54</em>(3), 57:1–36. (<a
href="https://doi.org/10.1145/3442480">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cyber threats have been growing tremendously in recent years. There are significant advancements in the threat space that have led towards an essential need for the strengthening of digital infrastructure security. Better security can be achieved by fine-tuning system parameters to the best and optimized security levels. For the protection of infrastructure and information systems, several guidelines have been provided by well-known organizations in the form of cybersecurity standards. Since security vulnerabilities incur a very high degree of financial, reputational, informational, and organizational security compromise, it is imperative that a baseline for standard compliance be established. The selection of security standards and extracting requirements from those standards in an organizational context is a tedious task. This article presents a detailed literature review, a comprehensive analysis of various cybersecurity standards, and statistics of cyber-attacks related to operating systems (OS). In addition to that, an explicit comparison between the frameworks, tools, and software available for OS compliance testing is provided. An in-depth analysis of the most common software solutions ensuring compliance with certain cybersecurity standards is also presented. Finally, based on the cybersecurity standards under consideration, a comprehensive set of minimum requirements is proposed for OS hardening and a few open research challenges are discussed.},
  archive      = {J_CSUR},
  author       = {Syed Wasif Abbas Hamdani and Haider Abbas and Abdul Rehman Janjua and Waleed Bin Shahid and Muhammad Faisal Amjad and Jahanzaib Malik and Malik Hamza Murtaza and Mohammed Atiquzzaman and Abdul Waheed Khan},
  doi          = {10.1145/3442480},
  journal      = {ACM Computing Surveys},
  number       = {3},
  pages        = {57:1–36},
  shortjournal = {ACM Comput. Surv.},
  title        = {Cybersecurity standards in the context of operating system: Practical aspects, analysis, and comparisons},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A review on outlier/anomaly detection in time series data.
<em>CSUR</em>, <em>54</em>(3), 56:1–33. (<a
href="https://doi.org/10.1145/3444690">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advances in technology have brought major breakthroughs in data collection, enabling a large amount of data to be gathered over time and thus generating time series. Mining this data has become an important task for researchers and practitioners in the past few years, including the detection of outliers or anomalies that may represent errors or events of interest. This review aims to provide a structured and comprehensive state-of-the-art on unsupervised outlier detection techniques in the context of time series. To this end, a taxonomy is presented based on the main aspects that characterize an outlier detection technique.},
  archive      = {J_CSUR},
  author       = {Ane Blázquez-García and Angel Conde and Usue Mori and Jose A. Lozano},
  doi          = {10.1145/3444690},
  journal      = {ACM Computing Surveys},
  number       = {3},
  pages        = {56:1–33},
  shortjournal = {ACM Comput. Surv.},
  title        = {A review on Outlier/Anomaly detection in time series data},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Natural language processing for requirements engineering: A
systematic mapping study. <em>CSUR</em>, <em>54</em>(3), 55:1–41. (<a
href="https://doi.org/10.1145/3444689">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Natural Language Processing for Requirements Engineering (NLP4RE) is an area of research and development that seeks to apply natural language processing (NLP) techniques, tools, and resources to the requirements engineering (RE) process, to support human analysts to carry out various linguistic analysis tasks on textual requirements documents, such as detecting language issues, identifying key domain concepts, and establishing requirements traceability links. This article reports on a mapping study that surveys the landscape of NLP4RE research to provide a holistic understanding of the field. Following the guidance of systematic review, the mapping study is directed by five research questions, cutting across five aspects of NLP4RE research, concerning the state of the literature, the state of empirical research, the research focus, the state of tool development, and the usage of NLP technologies. Our main results are as follows: (i) we identify a total of 404 primary studies relevant to NLP4RE, which were published over the past 36 years and from 170 different venues; (ii) most of these studies (67.08\%) are solution proposals, assessed by a laboratory experiment or an example application, while only a small percentage (7\%) are assessed in industrial settings; (iii) a large proportion of the studies (42.70\%) focus on the requirements analysis phase, with quality defect detection as their central task and requirements specification as their commonly processed document type; (iv) 130 NLP4RE tools (i.e., RE specific NLP tools) are extracted from these studies, but only 17 of them (13.08\%) are available for download; (v) 231 different NLP technologies are also identified, comprising 140 NLP techniques, 66 NLP tools, and 25 NLP resources, but most of them—particularly those novel NLP techniques and specialized tools—are used infrequently; by contrast, commonly used NLP technologies are traditional analysis techniques (e.g., POS tagging and tokenization), general-purpose tools (e.g., Stanford CoreNLP and GATE) and generic language lexicons (WordNet and British National Corpus). The mapping study not only provides a collection of the literature in NLP4RE but also, more importantly, establishes a structure to frame the existing literature through categorization, synthesis and conceptualization of the main theoretical concepts and relationships that encompass both RE and NLP aspects. Our work thus produces a conceptual framework of NLP4RE. The framework is used to identify research gaps and directions, highlight technology transfer needs, and encourage more synergies between the RE community, the NLP one, and the software and systems practitioners. Our results can be used as a starting point to frame future studies according to a well-defined terminology and can be expanded as new technologies and novel solutions emerge.},
  archive      = {J_CSUR},
  author       = {Liping Zhao and Waad Alhoshan and Alessio Ferrari and Keletso J. Letsholo and Muideen A. Ajagbe and Erol-Valeriu Chioasca and Riza T. Batista-Navarro},
  doi          = {10.1145/3444689},
  journal      = {ACM Computing Surveys},
  number       = {3},
  pages        = {55:1–41},
  shortjournal = {ACM Comput. Surv.},
  title        = {Natural language processing for requirements engineering: A systematic mapping study},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Survey of transient execution attacks and their mitigations.
<em>CSUR</em>, <em>54</em>(3), 54:1–36. (<a
href="https://doi.org/10.1145/3442479">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Transient execution attacks, also known as speculative execution attacks, have drawn much interest in the last few years as they can cause critical data leakage. Since the first disclosure of Spectre and Meltdown attacks in January 2018, a number of new transient execution attack types have been demonstrated targeting different processors. A transient execution attack consists of two main components: transient execution itself and a covert channel that is used to actually exfiltrate the information.Transient execution is a result of the fundamental features of modern processors that are designed to boost performance and efficiency, while covert channels are unintended information leakage channels that result from temporal and spatial sharing of the micro-architectural components. Given the severity of the transient execution attacks, they have motivated computer architects in both industry and academia to rethink the design of the processors and to propose hardware defenses. To help understand the transient execution attacks, this survey summarizes the phases of the attacks and the security boundaries across which the information is leaked in different attacks.This survey further analyzes the causes of transient execution as well as the different types of covert channels and presents a taxonomy of the attacks based on the causes and types. This survey in addition presents metrics for comparing different aspects of the transient execution attacks and uses them to evaluate the feasibility of the different attacks. This survey especially considers both existing attacks and potential new attacks suggested by our analysis. This survey finishes by discussing different mitigations that have so far been proposed at the micro-architecture level and discusses their benefits and limitations.},
  archive      = {J_CSUR},
  author       = {Wenjie Xiong and Jakub Szefer},
  doi          = {10.1145/3442479},
  journal      = {ACM Computing Surveys},
  number       = {3},
  pages        = {54:1–36},
  shortjournal = {ACM Comput. Surv.},
  title        = {Survey of transient execution attacks and their mitigations},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Software testing effort estimation and related problems: A
systematic literature review. <em>CSUR</em>, <em>54</em>(3), 53:1–38.
(<a href="https://doi.org/10.1145/3442694">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although testing effort estimation is a very important task in software project management, it is rarely described in the literature. There are many difficulties in finding any useful methods or tools for this purpose. Solutions to many other problems related to testing effort calculation are published much more often. There is also no research focusing on both testing effort estimation and all related areas of software engineering. To fill this gap, we performed a systematic literature review on both questions. Although our primary objective was to find some tools or implementable metods for test effort estimation, we have quickly discovered many other interesting topics related to the main one. The main contribution of this work is the presentation of the testing effort estimation task in a very wide context, indicating the relations with other research fields. This systematic literature review presents a detailed overview of testing effort estimation task, including challenges and approaches to automating it and the solutions proposed in the literature. It also exhaustively investigates related research topics, classifying publications that can be found in connection to the testing effort according to seven criteria formulated on the basis of our research questions. We present here both synthesis of our finding and the deep analysis of the stated research problems.},
  archive      = {J_CSUR},
  author       = {Ilona Bluemke and Agnieszka Malanowska},
  doi          = {10.1145/3442694},
  journal      = {ACM Computing Surveys},
  number       = {3},
  pages        = {53:1–38},
  shortjournal = {ACM Comput. Surv.},
  title        = {Software testing effort estimation and related problems: A systematic literature review},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Cytology image analysis techniques toward automation:
Systematically revisited. <em>CSUR</em>, <em>54</em>(3), 52:1–41. (<a
href="https://doi.org/10.1145/3447238">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cytology is a branch of pathology that deals with the microscopic examination of cells for diagnosis of carcinoma or inflammatory conditions. In the present work, the term cytology is used to indicate solid organ cytology. Automation in cytology started in the early 1950s with an aim to reduce manual efforts in the diagnosis of cancer. The influx of intelligent systems with high computational power and improved specimen collection techniques helped to achieve technological heights in the cytology automation process. In the present survey, we focus on image analysis techniques paving the way to automation in cytology. We take a short tour of 17 types of solid organ cytology to explore various segmentation and/or classification techniques that evolved during the past three decades to automate cytology image analysis. It is observed that most of the works are aligned toward three types of cytology: Cervical, Breast, and Respiratory tract cytology. These are discussed elaborately in the article. Commercial systems developed during the period are also summarized to comprehend the overall growth in respective domains. Finally, we discuss different state-of-the-art methods and related challenges to provide prolific and competent future research directions in bringing cytology-based commercial systems into the mainstream.},
  archive      = {J_CSUR},
  author       = {Shyamali Mitra and Nibaran Das and Soumyajyoti Dey and Sukanta Chakraborty and Mita Nasipuri and Mrinal Kanti Naskar},
  doi          = {10.1145/3447238},
  journal      = {ACM Computing Surveys},
  number       = {3},
  pages        = {52:1–41},
  shortjournal = {ACM Comput. Surv.},
  title        = {Cytology image analysis techniques toward automation: Systematically revisited},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A survey of binary code similarity. <em>CSUR</em>,
<em>54</em>(3), 51:1–38. (<a
href="https://doi.org/10.1145/3446371">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Binary code similarityapproaches compare two or more pieces of binary code to identify their similarities and differences. The ability to compare binary code enables many real-world applications on scenarios where source code may not be available such as patch analysis, bug search, and malware detection and analysis. Over the past 22 years numerous binary code similarity approaches have been proposed, but the research area has not yet been systematically analyzed. This article presents the first survey of binary code similarity. It analyzes 70 binary code similarity approaches, which are systematized on four aspects: (1) the applications they enable, (2) their approach characteristics, (3) how the approaches are implemented, and (4) the benchmarks and methodologies used to evaluate them. In addition, the survey discusses the scope and origins of the area, its evolution over the past two decades, and the challenges that lie ahead.},
  archive      = {J_CSUR},
  author       = {Irfan Ul Haq and Juan Caballero},
  doi          = {10.1145/3446371},
  journal      = {ACM Computing Surveys},
  number       = {3},
  pages        = {51:1–38},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey of binary code similarity},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Machine learning for detecting data exfiltration: A review.
<em>CSUR</em>, <em>54</em>(3), 50:1–47. (<a
href="https://doi.org/10.1145/3442181">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Context : Research at the intersection of cybersecurity, Machine Learning (ML), and Software Engineering (SE) has recently taken significant steps in proposing countermeasures for detecting sophisticated data exfiltration attacks. It is important to systematically review and synthesize the ML-based data exfiltration countermeasures for building a body of knowledge on this important topic. Objective : This article aims at systematically reviewing ML-based data exfiltration countermeasures to identify and classify ML approaches, feature engineering techniques, evaluation datasets, and performance metrics used for these countermeasures. This review also aims at identifying gaps in research on ML-based data exfiltration countermeasures. Method : We used Systematic Literature Review (SLR) method to select and review 92 papers. Results : The review has enabled us to: (a) classify the ML approaches used in the countermeasures into data-driven, and behavior-driven approaches; (b) categorize features into six types: behavioral, content-based, statistical, syntactical, spatial, and temporal; (c) classify the evaluation datasets into simulated, synthesized, and real datasets; and (d) identify 11 performance measures used by these studies. Conclusion : We conclude that: (i) The integration of data-driven and behavior-driven approaches should be explored; (ii) There is a need of developing high quality and large size evaluation datasets; (iii) Incremental ML model training should be incorporated in countermeasures; (iv) Resilience to adversarial learning should be considered and explored during the development of countermeasures to avoid poisoning attacks; and (v) The use of automated feature engineering should be encouraged for efficiently detecting data exfiltration attacks.},
  archive      = {J_CSUR},
  author       = {Bushra Sabir and Faheem Ullah and M. Ali Babar and Raj Gaire},
  doi          = {10.1145/3442181},
  journal      = {ACM Computing Surveys},
  number       = {3},
  pages        = {50:1–47},
  shortjournal = {ACM Comput. Surv.},
  title        = {Machine learning for detecting data exfiltration: A review},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Mobility trace analysis for intelligent vehicular networks:
Methods, models, and applications. <em>CSUR</em>, <em>54</em>(3),
49:1–38. (<a href="https://doi.org/10.1145/3446679">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intelligent vehicular networks emerge as a promising technology to provide efficient data communication in transportation systems and smart cities. At the same time, the popularization of devices with attached sensors has allowed the obtaining of a large volume of data with spatiotemporal information from different entities. In this sense, we are faced with a large volume of vehicular mobility traces being recorded. Those traces provide unprecedented opportunities to understand the dynamics of vehicular mobility and provide data-driven solutions. In this article, we give an overview of the main publicly available vehicular mobility traces; then, we present the main issues for preprocessing these traces. Also, we present the methods used to characterize and model mobility data. Finally, we review existing proposals that apply the hidden knowledge extracted from the mobility trace for vehicular networks. This article provides a survey on studies that use vehicular mobility traces and provides a guideline for the proposition of data-driven solutions in the domain of vehicular networks. Moreover, we discuss open research problems and give some directions to undertake them.},
  archive      = {J_CSUR},
  author       = {Clayson Celes and Azzedine Boukerche and Antonio A. F. Loureiro},
  doi          = {10.1145/3446679},
  journal      = {ACM Computing Surveys},
  number       = {3},
  pages        = {49:1–38},
  shortjournal = {ACM Comput. Surv.},
  title        = {Mobility trace analysis for intelligent vehicular networks: Methods, models, and applications},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Community detection in multiplex networks. <em>CSUR</em>,
<em>54</em>(3), 48:1–35. (<a
href="https://doi.org/10.1145/3444688">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A multiplex network models different modes of interaction among same-type entities. In this article, we provide a taxonomy of community detection algorithms in multiplex networks. We characterize the different algorithms based on various properties and we discuss the type of communities detected by each method. We then provide an extensive experimental evaluation of the reviewed methods to answer three main questions: to what extent the evaluated methods are able to detect ground-truth communities, to what extent different methods produce similar community structures, and to what extent the evaluated methods are scalable. One goal of this survey is to help scholars and practitioners to choose the right methods for the data and the task at hand, while also emphasizing when such choice is problematic.},
  archive      = {J_CSUR},
  author       = {Matteo Magnani and Obaida Hanteer and Roberto Interdonato and Luca Rossi and Andrea Tagarelli},
  doi          = {10.1145/3444688},
  journal      = {ACM Computing Surveys},
  number       = {3},
  pages        = {48:1–35},
  shortjournal = {ACM Comput. Surv.},
  title        = {Community detection in multiplex networks},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Visual affordance and function understanding: A survey.
<em>CSUR</em>, <em>54</em>(3), 47:1–35. (<a
href="https://doi.org/10.1145/3446370">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, robots are dominating the manufacturing, entertainment, and healthcare industries. Robot vision aims to equip robots with the capabilities to discover information, understand it, and interact with the environment, which require an agent to effectively understand object affordances and functions in complex visual domains. In this literature survey, first, “visual affordances” are focused on and current state-of-the-art approaches for solving relevant problems as well as open problems and research gaps are summarized. Then, sub-problems, such as affordance detection, categorization, segmentation, and high-level affordance reasoning, are specifically discussed. Furthermore, functional scene understanding and its prevalent descriptors used in the literature are covered. This survey also provides the necessary background to the problem, sheds light on its significance, and highlights the existing challenges for affordance and functionality learning.},
  archive      = {J_CSUR},
  author       = {Mohammed Hassanin and Salman Khan and Murat Tahtali},
  doi          = {10.1145/3446370},
  journal      = {ACM Computing Surveys},
  number       = {3},
  pages        = {47:1–35},
  shortjournal = {ACM Comput. Surv.},
  title        = {Visual affordance and function understanding: A survey},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Main memory database recovery: A survey. <em>CSUR</em>,
<em>54</em>(2), 46:1–36. (<a
href="https://doi.org/10.1145/3442197">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many of today’s applications need massive real-time data processing. In-memory database systems have become a good alternative for these requirements. These systems maintain the primary copy of the database in the main memory to achieve high throughput rates and low latency. However, a database in RAM is more vulnerable to failures than in traditional disk-oriented databases because of the memory volatility. DBMSs implement recovery activities (logging, checkpoint, and restart) for recovery proposes. Although the recovery component looks similar in disk- and memory-oriented systems, these systems differ dramatically in the way they implement their architectural components, such as data storage, indexing, concurrency control, query processing, durability, and recovery. This survey aims to provide a thorough review of in-memory database recovery techniques. To achieve this goal, we reviewed the main concepts of database recovery and architectural choices to implement an in-memory database system. Only then, we present the techniques to recover in-memory databases and discuss the recovery strategies of a representative sample of modern in-memory databases.},
  archive      = {J_CSUR},
  author       = {Arlino Magalhaes and Jose Maria Monteiro and Angelo Brayner},
  doi          = {10.1145/3442197},
  journal      = {ACM Computing Surveys},
  number       = {2},
  pages        = {46:1–36},
  shortjournal = {ACM Comput. Surv.},
  title        = {Main memory database recovery: A survey},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A survey on document-level neural machine translation:
Methods and evaluation. <em>CSUR</em>, <em>54</em>(2), 45:1–36. (<a
href="https://doi.org/10.1145/3441691">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine translation (MT) is an important task in natural language processing (NLP), as it automates the translation process and reduces the reliance on human translators. With the resurgence of neural networks, the translation quality surpasses that of the translations obtained using statistical techniques for most language-pairs. Up until a few years ago, almost all of the neural translation models translated sentences independently , without incorporating the wider document-context and inter-dependencies among the sentences. The aim of this survey article is to highlight the major works that have been undertaken in the space of document-level machine translation after the neural revolution, so researchers can recognize the current state and future directions of this field. We provide an organization of the literature based on novelties in modelling and architectures as well as training and decoding strategies. In addition, we cover evaluation strategies that have been introduced to account for the improvements in document MT, including automatic metrics and discourse-targeted test sets. We conclude by presenting possible avenues for future exploration in this research field.},
  archive      = {J_CSUR},
  author       = {Sameen Maruf and Fahimeh Saleh and Gholamreza Haffari},
  doi          = {10.1145/3441691},
  journal      = {ACM Computing Surveys},
  number       = {2},
  pages        = {45:1–36},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey on document-level neural machine translation: Methods and evaluation},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A survey of state-of-the-art on blockchains: Theories,
modelings, and tools. <em>CSUR</em>, <em>54</em>(2), 44:1–42. (<a
href="https://doi.org/10.1145/3441692">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To draw a roadmap of current research activities of the blockchain community, we first conduct a brief overview of state-of-the-art blockchain surveys published in the past 5 years. We found that those surveys are basically studying the blockchain-based applications, such as blockchain-assisted Internet of Things (IoT), business applications, security-enabled solutions, and many other applications in diverse fields. However, we think that a comprehensive survey toward the essentials of blockchains by exploiting the state-of-the-art theoretical modelings, analytic models, and useful experiment tools is still missing. To fill this gap, we perform a thorough survey by identifying and classifying the most recent high-quality research outputs that are closely related to the theoretical findings and essential mechanisms of blockchain systems and networks. Several promising open issues are also summarized for future research directions. We hope this survey can serve as a useful guideline for researchers, engineers, and educators about the cutting-edge development of blockchains in the perspectives of theories, modelings, and tools.},
  archive      = {J_CSUR},
  author       = {Huawei Huang and Wei Kong and Sicong Zhou and Zibin Zheng and Song Guo},
  doi          = {10.1145/3441692},
  journal      = {ACM Computing Surveys},
  number       = {2},
  pages        = {44:1–42},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey of state-of-the-art on blockchains: Theories, modelings, and tools},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Automated text simplification: A survey. <em>CSUR</em>,
<em>54</em>(2), 43:1–36. (<a
href="https://doi.org/10.1145/3442695">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Text simplification (TS) reduces the complexity of the text to improve its readability and understandability, while possibly retaining its original information content. Over time, TS has become an essential tool in helping those with low literacy levels, non-native learners, and those struggling with various types of reading comprehension problems. In addition, it is used in a preprocessing stage to enhance other NLP tasks. This survey presents an extensive study of current research studies in the field of TS, as well as covering resources, corpora, and evaluation methods that have been used in those studies.},
  archive      = {J_CSUR},
  author       = {Suha S. Al-Thanyyan and Aqil M. Azmi},
  doi          = {10.1145/3442695},
  journal      = {ACM Computing Surveys},
  number       = {2},
  pages        = {43:1–36},
  shortjournal = {ACM Comput. Surv.},
  title        = {Automated text simplification: A survey},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Text recognition in the wild: A survey. <em>CSUR</em>,
<em>54</em>(2), 42:1–35. (<a
href="https://doi.org/10.1145/3440756">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The history of text can be traced back over thousands of years. Rich and precise semantic information carried by text is important in a wide range of vision-based application scenarios. Therefore, text recognition in natural scenes has been an active research topic in computer vision and pattern recognition. In recent years, with the rise and development of deep learning, numerous methods have shown promising results in terms of innovation, practicality, and efficiency. This article aims to (1) summarize the fundamental problems and the state-of-the-art associated with scene text recognition, (2) introduce new insights and ideas, (3) provide a comprehensive review of publicly available resources, and (4) point out directions for future work. In summary, this literature review attempts to present an entire picture of the field of scene text recognition. It provides a comprehensive reference for people entering this field and could be helpful in inspiring future research. Related resources are available at our GitHub repository: https://github.com/HCIILAB/Scene-Text-Recognition.},
  archive      = {J_CSUR},
  author       = {Xiaoxue Chen and Lianwen Jin and Yuanzhi Zhu and Canjie Luo and Tianwei Wang},
  doi          = {10.1145/3440756},
  journal      = {ACM Computing Surveys},
  number       = {2},
  pages        = {42:1–35},
  shortjournal = {ACM Comput. Surv.},
  title        = {Text recognition in the wild: A survey},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Evolution of semantic similarity—a survey. <em>CSUR</em>,
<em>54</em>(2), 41:1–37. (<a
href="https://doi.org/10.1145/3440755">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Estimating the semantic similarity between text data is one of the challenging and open research problems in the field of Natural Language Processing (NLP). The versatility of natural language makes it difficult to define rule-based methods for determining semantic similarity measures. To address this issue, various semantic similarity methods have been proposed over the years. This survey article traces the evolution of such methods beginning from traditional NLP techniques such as kernel-based methods to the most recent research work on transformer-based models, categorizing them based on their underlying principles as knowledge-based, corpus-based, deep neural network–based methods, and hybrid methods. Discussing the strengths and weaknesses of each method, this survey provides a comprehensive view of existing systems in place for new researchers to experiment and develop innovative ideas to address the issue of semantic similarity.},
  archive      = {J_CSUR},
  author       = {Dhivya Chandrasekaran and Vijay Mago},
  doi          = {10.1145/3440755},
  journal      = {ACM Computing Surveys},
  number       = {2},
  pages        = {41:1–37},
  shortjournal = {ACM Comput. Surv.},
  title        = {Evolution of semantic Similarity—A survey},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Data protection in AI services: A survey. <em>CSUR</em>,
<em>54</em>(2), 40:1–38. (<a
href="https://doi.org/10.1145/3440754">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Advances in artificial intelligence (AI) have shaped today’s user services, enabling enhanced personalization and better support. As such AI-based services inevitably require user data, the resulting privacy implications are de facto the unacceptable face of this technology. In this article, we categorize and survey the cutting-edge research on privacy and data protection in the context of personalized AI services. We further review the different protection approaches at three different levels, namely, the management, system, and AI levels—showing that (i) not all of them meet our identified requirements of evolving AI services and that (ii) many challenges are addressed separately or fragmentarily by different research communities. Finally, we highlight open research challenges and future directions in data protection research, especially that comprehensive protection requires more interdisciplinary research and a combination of approaches at different levels.},
  archive      = {J_CSUR},
  author       = {Christian Meurisch and Max Mühlhäuser},
  doi          = {10.1145/3440754},
  journal      = {ACM Computing Surveys},
  number       = {2},
  pages        = {40:1–38},
  shortjournal = {ACM Comput. Surv.},
  title        = {Data protection in AI services: A survey},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A survey on trajectory data management, analytics, and
learning. <em>CSUR</em>, <em>54</em>(2), 39:1–36. (<a
href="https://doi.org/10.1145/3440207">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advances in sensor and mobile devices have enabled an unprecedented increase in the availability and collection of urban trajectory data, thus increasing the demand for more efficient ways to manage and analyze the data being produced. In this survey, we comprehensively review recent research trends in trajectory data management, ranging from trajectory pre-processing, storage, common trajectory analytic tools, such as querying spatial-only and spatial-textual trajectory data, and trajectory clustering. We also explore four closely related analytical tasks commonly used with trajectory data in interactive or real-time processing. Deep trajectory learning is also reviewed for the first time. Finally, we outline the essential qualities that a trajectory data management system should possess to maximize flexibility.},
  archive      = {J_CSUR},
  author       = {Sheng Wang and Zhifeng Bao and J. Shane Culpepper and Gao Cong},
  doi          = {10.1145/3440207},
  journal      = {ACM Computing Surveys},
  number       = {2},
  pages        = {39:1–36},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey on trajectory data management, analytics, and learning},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Deep learning for anomaly detection: A review.
<em>CSUR</em>, <em>54</em>(2), 38:1–38. (<a
href="https://doi.org/10.1145/3439950">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Anomaly detection, a.k.a. outlier detection or novelty detection, has been a lasting yet active research area in various research communities for several decades. There are still some unique problem complexities and challenges that require advanced approaches. In recent years, deep learning enabled anomaly detection, i.e., deep anomaly detection , has emerged as a critical direction. This article surveys the research of deep anomaly detection with a comprehensive taxonomy, covering advancements in 3 high-level categories and 11 fine-grained categories of the methods. We review their key intuitions, objective functions, underlying assumptions, advantages, and disadvantages and discuss how they address the aforementioned challenges. We further discuss a set of possible future opportunities and new perspectives on addressing the challenges.},
  archive      = {J_CSUR},
  author       = {Guansong Pang and Chunhua Shen and Longbing Cao and Anton Van Den Hengel},
  doi          = {10.1145/3439950},
  journal      = {ACM Computing Surveys},
  number       = {2},
  pages        = {38:1–38},
  shortjournal = {ACM Comput. Surv.},
  title        = {Deep learning for anomaly detection: A review},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Generative adversarial networks in computer vision: A survey
and taxonomy. <em>CSUR</em>, <em>54</em>(2), 37:1–38. (<a
href="https://doi.org/10.1145/3439723">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generative adversarial networks (GANs) have been extensively studied in the past few years. Arguably their most significant impact has been in the area of computer vision where great advances have been made in challenges such as plausible image generation, image-to-image translation, facial attribute manipulation, and similar domains. Despite the significant successes achieved to date, applying GANs to real-world problems still poses significant challenges, three of which we focus on here. These are as follows: (1) the generation of high quality images, (2) diversity of image generation, and (3) stabilizing training. Focusing on the degree to which popular GAN technologies have made progress against these challenges, we provide a detailed review of the state-of-the-art in GAN-related research in the published scientific literature. We further structure this review through a convenient taxonomy we have adopted based on variations in GAN architectures and loss functions. While several reviews for GANs have been presented to date, none have considered the status of this field based on their progress toward addressing practical challenges relevant to computer vision. Accordingly, we review and critically discuss the most popular architecture-variant, and loss-variant GANs, for tackling these challenges. Our objective is to provide an overview as well as a critical analysis of the status of GAN research in terms of relevant progress toward critical computer vision application requirements. As we do this we also discuss the most compelling applications in computer vision in which GANs have demonstrated considerable success along with some suggestions for future research directions. Codes related to the GAN-variants studied in this work is summarized on https://github.com/sheqi/GAN_Review.},
  archive      = {J_CSUR},
  author       = {Zhengwei Wang and Qi She and Tomás E. Ward},
  doi          = {10.1145/3439723},
  journal      = {ACM Computing Surveys},
  number       = {2},
  pages        = {37:1–38},
  shortjournal = {ACM Comput. Surv.},
  title        = {Generative adversarial networks in computer vision: A survey and taxonomy},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A survey on distributed graph pattern matching in massive
graphs. <em>CSUR</em>, <em>54</em>(2), 36:1–35. (<a
href="https://doi.org/10.1145/3439724">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Besides its NP-completeness, the strict constraints of subgraph isomorphism are making it impractical for graph pattern matching (GPM) in the context of big data. As a result, relaxed GPM models have emerged as they yield interesting results in a polynomial time. However, massive graphs generated by mostly social networks require a distributed storing and processing of the data over multiple machines, thus, requiring GPM to be revised by adopting new paradigms of big graphs processing, e.g., Think-Like-A-Vertex and its derivatives. This article discusses and proposes a classification of distributed GPM approaches with a narrow focus on the relaxed models.},
  archive      = {J_CSUR},
  author       = {Sarra Bouhenni and Saïd Yahiaoui and Nadia Nouali-Taboudjemat and Hamamache Kheddouci},
  doi          = {10.1145/3439724},
  journal      = {ACM Computing Surveys},
  number       = {2},
  pages        = {36:1–35},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey on distributed graph pattern matching in massive graphs},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A survey on adversarial recommender systems: From
attack/defense strategies to generative adversarial networks.
<em>CSUR</em>, <em>54</em>(2), 35:1–38. (<a
href="https://doi.org/10.1145/3439729">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Latent-factor models (LFM) based on collaborative filtering (CF), such as matrix factorization (MF) and deep CF methods, are widely used in modern recommender systems (RS) due to their excellent performance and recommendation accuracy. However, success has been accompanied with a major new arising challenge: Many applications of machine learning (ML) are adversarial in nature [146]. In recent years, it has been shown that these methods are vulnerable to adversarial examples, i.e., subtle but non-random perturbations designed to force recommendation models to produce erroneous outputs. The goal of this survey is two-fold: (i) to present recent advances on adversarial machine learning (AML) for the security of RS (i.e., attacking and defense recommendation models) and (ii) to show another successful application of AML in generative adversarial networks (GANs) for generative applications, thanks to their ability for learning (high-dimensional) data distributions. In this survey, we provide an exhaustive literature review of 76 articles published in major RS and ML journals and conferences. This review serves as a reference for the RS community working on the security of RS or on generative models using GANs to improve their quality.},
  archive      = {J_CSUR},
  author       = {Yashar Deldjoo and Tommaso Di Noia and Felice Antonio Merra},
  doi          = {10.1145/3439729},
  journal      = {ACM Computing Surveys},
  number       = {2},
  pages        = {35:1–38},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey on adversarial recommender systems: From Attack/Defense strategies to generative adversarial networks},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Automated design of deep neural networks: A survey and
unified taxonomy. <em>CSUR</em>, <em>54</em>(2), 34:1–37. (<a
href="https://doi.org/10.1145/3439730">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, research in applying optimization approaches in the automatic design of deep neural networks has become increasingly popular. Although various approaches have been proposed, there is a lack of a comprehensive survey and taxonomy on this hot research topic. In this article, we propose a unified way to describe the various optimization algorithms that focus on common and important search components of optimization algorithms: representation, objective function, constraints, initial solution(s), and variation operators. In addition to large-scale search space, the problem is characterized by its variable mixed design space, it is very expensive, and it has multiple blackbox objective functions. Hence, this unified methodology has been extended to advanced optimization approaches, such as surrogate-based, multi-objective, and parallel optimization.},
  archive      = {J_CSUR},
  author       = {El-Ghazali Talbi},
  doi          = {10.1145/3439730},
  journal      = {ACM Computing Surveys},
  number       = {2},
  pages        = {34:1–37},
  shortjournal = {ACM Comput. Surv.},
  title        = {Automated design of deep neural networks: A survey and unified taxonomy},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Information integrity: Are we there yet? <em>CSUR</em>,
<em>54</em>(2), 33:1–35. (<a
href="https://doi.org/10.1145/3436817">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The understanding and promotion of integrity in information security has traditionally been underemphasized or even ignored. From implantable medical devices and electronic voting to vehicle control, the critical importance of information integrity to our well-being has compelled review of its treatment in the literature. Through formal information flow models, the data modification view, and the relationship to data quality, information integrity will be surveyed. Illustrations are given for databases and information trustworthiness. Integrity protection is advancing but lacks standardization in terminology and application. Integrity must be better understood, and pursued, to achieve devices and systems that are beneficial and safe for the future.},
  archive      = {J_CSUR},
  author       = {Kelsey Harley and Rodney Cooper},
  doi          = {10.1145/3436817},
  journal      = {ACM Computing Surveys},
  number       = {2},
  pages        = {33:1–35},
  shortjournal = {ACM Comput. Surv.},
  title        = {Information integrity: Are we there yet?},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Deep AI enabled ubiquitous wireless sensing: A survey.
<em>CSUR</em>, <em>54</em>(2), 32:1–35. (<a
href="https://doi.org/10.1145/3436729">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of the Internet of Things (IoT), many kinds of wireless signals (e.g., Wi-Fi, LoRa, RFID) are filling our living and working spaces nowadays. Beyond communication, wireless signals can sense the status of surrounding objects, known as wireless sensing , with their reflection, scattering, and refraction while propagating in space. In the last decade, many sophisticated wireless sensing techniques and systems were widely studied for various applications (e.g., gesture recognition, localization, and object imaging). Recently, deep Artificial Intelligence (AI), also known as Deep Learning (DL), has shown great success in computer vision. And some works have initially proved that deep AI can benefit wireless sensing as well, leading to a brand-new step toward ubiquitous sensing. In this survey, we focus on the evolution of wireless sensing enhanced by deep AI techniques. We first present a general workflow of Wireless Sensing Systems (WSSs) which consists of signal pre-processing, high-level feature, and sensing model formulation. For each module, existing deep AI-based techniques are summarized, further compared with traditional approaches. Then, we provide a view of issues and challenges induced by combining deep AI and wireless sensing together. Finally, we discuss the future trends of deep AI to enable ubiquitous wireless sensing.},
  archive      = {J_CSUR},
  author       = {Chenning Li and Zhichao Cao and Yunhao Liu},
  doi          = {10.1145/3436729},
  journal      = {ACM Computing Surveys},
  number       = {2},
  pages        = {32:1–35},
  shortjournal = {ACM Comput. Surv.},
  title        = {Deep AI enabled ubiquitous wireless sensing: A survey},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). When machine learning meets privacy: A survey and outlook.
<em>CSUR</em>, <em>54</em>(2), 31:1–36. (<a
href="https://doi.org/10.1145/3436755">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The newly emerged machine learning (e.g., deep learning) methods have become a strong driving force to revolutionize a wide range of industries, such as smart healthcare, financial technology, and surveillance systems. Meanwhile, privacy has emerged as a big concern in this machine learning-based artificial intelligence era. It is important to note that the problem of privacy preservation in the context of machine learning is quite different from that in traditional data privacy protection, as machine learning can act as both friend and foe. Currently, the work on the preservation of privacy and machine learning are still in an infancy stage, as most existing solutions only focus on privacy problems during the machine learning process. Therefore, a comprehensive study on the privacy preservation problems and machine learning is required. This article surveys the state of the art in privacy issues and solutions for machine learning. The survey covers three categories of interactions between privacy and machine learning: (i) private machine learning, (ii) machine learning-aided privacy protection, and (iii) machine learning-based privacy attack and corresponding protection schemes. The current research progress in each category is reviewed and the key challenges are identified. Finally, based on our in-depth analysis of the area of privacy and machine learning, we point out future research directions in this field.},
  archive      = {J_CSUR},
  author       = {Bo Liu and Ming Ding and Sina Shaham and Wenny Rahayu and Farhad Farokhi and Zihuai Lin},
  doi          = {10.1145/3436755},
  journal      = {ACM Computing Surveys},
  number       = {2},
  pages        = {31:1–36},
  shortjournal = {ACM Comput. Surv.},
  title        = {When machine learning meets privacy: A survey and outlook},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Object detection using deep learning methods in traffic
scenarios. <em>CSUR</em>, <em>54</em>(2), 30:1–35. (<a
href="https://doi.org/10.1145/3434398">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The recent boom of autonomous driving nowadays has made object detection in traffic scenes a hot topic of research. Designed to classify and locate instances in the image, this is a basic but challenging task in the computer vision field. With its powerful feature extraction abilities, which are vital for object detection, deep learning has expanded its application areas to this field during the past several years and thus achieved breakthroughs. However, even with such powerful approaches, traffic scenarios have their own specific challenges, such as real-time detection, changeable weather, and complex lighting conditions. This survey is dedicated to summarizing research and papers on applying deep learning to the transportation environment in recent years. More than 100 research papers are covered, and different aspects such as key generic object detection frameworks, categorized object detection applications in traffic scenario, evaluation metrics, and classified datasets are included. Some open research fields are also provided. We believe that it is the first survey focusing on deep learning-based object detection in traffic scenario.},
  archive      = {J_CSUR},
  author       = {Azzedine Boukerche and Zhijun Hou},
  doi          = {10.1145/3434398},
  journal      = {ACM Computing Surveys},
  number       = {2},
  pages        = {30:1–35},
  shortjournal = {ACM Comput. Surv.},
  title        = {Object detection using deep learning methods in traffic scenarios},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Indexing highly repetitive string collections, part i:
Repetitiveness measures. <em>CSUR</em>, <em>54</em>(2), 29:1–31. (<a
href="https://doi.org/10.1145/3434399">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Two decades ago, a breakthrough in indexing string collections made it possible to represent them within their compressed space while at the same time offering indexed search functionalities. As this new technology permeated through applications like bioinformatics, the string collections experienced a growth that outperforms Moore’s Law and challenges our ability to handle them even in compressed form. It turns out, fortunately, that many of these rapidly growing string collections are highly repetitive, so that their information content is orders of magnitude lower than their plain size. The statistical compression methods used for classical collections, however, are blind to this repetitiveness, and therefore a new set of techniques has been developed to properly exploit it. The resulting indexes form a new generation of data structures able to handle the huge repetitive string collections that we are facing. In this survey, formed by two parts, we cover the algorithmic developments that have led to these data structures. In this first part, we describe the distinct compression paradigms that have been used to exploit repetitiveness, and the algorithmic techniques that provide direct access to the compressed strings. In the quest for an ideal measure of repetitiveness, we uncover a fascinating web of relations between those measures, as well as the limits up to which the data can be recovered, and up to which direct access to the compressed data can be provided. This is the basic aspect of indexability, which is covered in the second part of this survey.},
  archive      = {J_CSUR},
  author       = {Gonzalo Navarro},
  doi          = {10.1145/3434399},
  journal      = {ACM Computing Surveys},
  number       = {2},
  pages        = {29:1–31},
  shortjournal = {ACM Comput. Surv.},
  title        = {Indexing highly repetitive string collections, part i: Repetitiveness measures},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A survey on subgraph counting: Concepts, algorithms, and
applications to network motifs and graphlets. <em>CSUR</em>,
<em>54</em>(2), 28:1–36. (<a
href="https://doi.org/10.1145/3433652">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Computing subgraph frequencies is a fundamental task that lies at the core of several network analysis methodologies, such as network motifs and graphlet-based metrics, which have been widely used to categorize and compare networks from multiple domains. Counting subgraphs is, however, computationally very expensive, and there has been a large body of work on efficient algorithms and strategies to make subgraph counting feasible for larger subgraphs and networks. This survey aims precisely to provide a comprehensive overview of the existing methods for subgraph counting. Our main contribution is a general and structured review of existing algorithms, classifying them on a set of key characteristics, highlighting their main similarities and differences. We identify and describe the main conceptual approaches, giving insight on their advantages and limitations, and we provide pointers to existing implementations. We initially focus on exact sequential algorithms, but we also do a thorough survey on approximate methodologies (with a trade-off between accuracy and execution time) and parallel strategies (that need to deal with an unbalanced search space).},
  archive      = {J_CSUR},
  author       = {Pedro Ribeiro and Pedro Paredes and Miguel E. P. Silva and David Aparicio and Fernando Silva},
  doi          = {10.1145/3433652},
  journal      = {ACM Computing Surveys},
  number       = {2},
  pages        = {28:1–36},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey on subgraph counting: Concepts, algorithms, and applications to network motifs and graphlets},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A survey of information cascade analysis: Models,
predictions, and recent advances. <em>CSUR</em>, <em>54</em>(2),
27:1–36. (<a href="https://doi.org/10.1145/3433000">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The deluge of digital information in our daily life—from user-generated content, such as microblogs and scientific papers, to online business, such as viral marketing and advertising—offers unprecedented opportunities to explore and exploit the trajectories and structures of the evolution of information cascades. Abundant research efforts, both academic and industrial, have aimed to reach a better understanding of the mechanisms driving the spread of information and quantifying the outcome of information diffusion. This article presents a comprehensive review and categorization of information popularity prediction methods, from feature engineering and stochastic processes , through graph representation , to deep learning-based approaches . Specifically, we first formally define different types of information cascades and summarize the perspectives of existing studies. We then present a taxonomy that categorizes existing works into the aforementioned three main groups as well as the main subclasses in each group, and we systematically review cutting-edge research work. Finally, we summarize the pros and cons of existing research efforts and outline the open challenges and opportunities in this field.},
  archive      = {J_CSUR},
  author       = {Fan Zhou and Xovee Xu and Goce Trajcevski and Kunpeng Zhang},
  doi          = {10.1145/3433000},
  journal      = {ACM Computing Surveys},
  number       = {2},
  pages        = {27:1–36},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey of information cascade analysis: Models, predictions, and recent advances},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Indexing highly repetitive string collections, part II:
Compressed indexes. <em>CSUR</em>, <em>54</em>(2), 26:1–32. (<a
href="https://doi.org/10.1145/3432999">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Two decades ago, a breakthrough in indexing string collections made it possible to represent them within their compressed space while at the same time offering indexed search functionalities. As this new technology permeated through applications like bioinformatics, the string collections experienced a growth that outperforms Moore’s Law and challenges our ability of handling them even in compressed form. It turns out, fortunately, that many of these rapidly growing string collections are highly repetitive, so that their information content is orders of magnitude lower than their plain size. The statistical compression methods used for classical collections, however, are blind to this repetitiveness, and therefore a new set of techniques has been developed to properly exploit it. The resulting indexes form a new generation of data structures able to handle the huge repetitive string collections that we are facing. In this survey, formed by two parts, we cover the algorithmic developments that have led to these data structures. In this second part, we describe the fundamental algorithmic ideas and data structures that form the base of all the existing indexes, and the various concrete structures that have been proposed, comparing them both in theoretical and practical aspects, and uncovering some new combinations. We conclude with the current challenges in this fascinating field.},
  archive      = {J_CSUR},
  author       = {Gonzalo Navarro},
  doi          = {10.1145/3432999},
  journal      = {ACM Computing Surveys},
  number       = {2},
  pages        = {26:1–32},
  shortjournal = {ACM Comput. Surv.},
  title        = {Indexing highly repetitive string collections, part II: Compressed indexes},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Automatic vulnerability detection in embedded devices and
firmware: Survey and layered taxonomies. <em>CSUR</em>, <em>54</em>(2),
25:1–42. (<a href="https://doi.org/10.1145/3432893">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the era of the internet of things (IoT), software-enabled inter-connected devices are of paramount importance. The embedded systems are very frequently used in both security and privacy-sensitive applications. However, the underlying software (a.k.a. firmware) very often suffers from a wide range of security vulnerabilities, mainly due to their outdated systems or reusing existing vulnerable libraries; which is evident by the surprising rise in the number of attacks against embedded systems. Therefore, to protect those embedded systems, detecting the presence of vulnerabilities in the large pool of embedded devices and their firmware plays a vital role. To this end, there exist several approaches to identify and trigger potential vulnerabilities within deployed embedded systems firmware. In this survey, we provide a comprehensive review of the state-of-the-art proposals, which detect vulnerabilities in embedded systems and firmware images by employing various analysis techniques, including static analysis, dynamic analysis, symbolic execution, and hybrid approaches. Furthermore, we perform both quantitative and qualitative comparisons among the surveyed approaches. Moreover, we devise taxonomies based on the applications of those approaches, the features used in the literature, and the type of the analysis. Finally, we identify the unresolved challenges and discuss possible future directions in this field of research.},
  archive      = {J_CSUR},
  author       = {Abdullah Qasem and Paria Shirani and Mourad Debbabi and Lingyu Wang and Bernard Lebel and Basile L. Agba},
  doi          = {10.1145/3432893},
  journal      = {ACM Computing Surveys},
  number       = {2},
  pages        = {25:1–42},
  shortjournal = {ACM Comput. Surv.},
  title        = {Automatic vulnerability detection in embedded devices and firmware: Survey and layered taxonomies},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Byzantine fault-tolerant state-machine replication from a
systems perspective. <em>CSUR</em>, <em>54</em>(1), 24:1–38. (<a
href="https://doi.org/10.1145/3436728">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Byzantine fault-tolerant (BFT) state-machine replication makes it possible to design systems that are resilient against arbitrary faults, a requirement considered crucial for an increasing number of use cases such as permissioned blockchains, firewalls, and SCADA systems. Unfortunately, the strong fault-tolerance guarantees provided by BFT replication protocols come at the cost of a high complexity, which is why it is inherently difficult to correctly implement BFT systems in practice. This is all the more true with regard to the plethora of solutions and ideas that have been developed in recent years to improve performance, availability, or resource efficiency. This survey aims at facilitating the task of building BFT systems by presenting an overview of state-of-the-art techniques and analyzing their practical implications, for example, with respect to applicability and composability. In particular, this includes problems that arise in the context of concrete implementations, but which are often times passed over in literature. Starting with an in-depth discussion of the most important architectural building blocks of a BFT system (i.e., clients, agreement protocol, execution stage), the survey then focuses on selected approaches and mechanisms addressing specific tasks such as checkpointing and recovery.},
  archive      = {J_CSUR},
  author       = {Tobias Distler},
  doi          = {10.1145/3436728},
  journal      = {ACM Computing Surveys},
  number       = {1},
  pages        = {24:1–38},
  shortjournal = {ACM Comput. Surv.},
  title        = {Byzantine fault-tolerant state-machine replication from a systems perspective},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Survey on periodic scheduling for time-triggered hard
real-time systems. <em>CSUR</em>, <em>54</em>(1), 23:1–32. (<a
href="https://doi.org/10.1145/3431232">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This survey covers the basic principles and related works addressing the time-triggered scheduling of periodic tasks with deadlines. The wide range of applications and the increasing complexity of modern real-time systems result in the continually growing interest in this topic. However, the articles in this field appear without systematic notation. To address it, we extend the three-field Graham notation to cover periodic scheduling. Moreover, we formally define three example periodic scheduling problems (PSPs) and provide straightforward implementations of these examples in the Satisfiability Modulo Theories formalism with source codes. Then, we present a summary of the complexity results containing existing polynomially solvable PSPs. We also provide an overview of simple state-of-the-art methods and tricks to solve the PSPs efficiently in terms of time. Next, we survey the existing works on PSP according to the resource environment: scheduling on a single resource, on parallel identical resources, and on dedicated resources. In the survey, we indicate which works propose solution methods for more general PSPs. Finally, we present related problems that are not periodic by nature to provide inspiration for the PSP solution.},
  archive      = {J_CSUR},
  author       = {Anna Minaeva and Zdeněk Hanzálek},
  doi          = {10.1145/3431232},
  journal      = {ACM Computing Surveys},
  number       = {1},
  pages        = {23:1–32},
  shortjournal = {ACM Comput. Surv.},
  title        = {Survey on periodic scheduling for time-triggered hard real-time systems},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A survey of nature-inspired computing: Membrane computing.
<em>CSUR</em>, <em>54</em>(1), 22:1–31. (<a
href="https://doi.org/10.1145/3431234">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nature-inspired computing is a type of human-designed computing motivated by nature, which is based on the employ of paradigms, mechanisms, and principles underlying natural systems. In this article, a versatile and vigorous bio-inspired branch of natural computing, named membrane computing is discussed. This computing paradigm is aroused by the internal membrane function and the structure of biological cells. We first introduce some basic concepts and formalisms of membrane computing, and then some basic types or variants of P systems (also named membrane systems ) are presented. The state-of-the-art computability theory and a pioneering computational complexity theory are presented with P system frameworks and numerous solutions to hard computational problems (especially NP -complete problems) via P systems with membrane division are reported. Finally, a number of applications and open problems of P systems are briefly described.},
  archive      = {J_CSUR},
  author       = {Bosheng Song and Kenli Li and David Orellana-Martín and Mario J. Pérez-Jiménez and Ignacio PéRez-Hurtado},
  doi          = {10.1145/3431234},
  journal      = {ACM Computing Surveys},
  number       = {1},
  pages        = {22:1–31},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey of nature-inspired computing: Membrane computing},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Cyberattacks and countermeasures for in-vehicle networks.
<em>CSUR</em>, <em>54</em>(1), 21:1–37. (<a
href="https://doi.org/10.1145/3431233">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As connectivity between and within vehicles increases, so does concern about safety and security. Various automotive serial protocols are used inside vehicles such as Controller Area Network (CAN), Local Interconnect Network (LIN), and FlexRay. CAN Bus is the most used in-vehicle network protocol to support exchange of vehicle parameters between Electronic Control Units (ECUs). This protocol lacks security mechanisms by design and is therefore vulnerable to various attacks. Furthermore, connectivity of vehicles has made the CAN Bus vulnerable not only from within the vehicle but also from outside. With the rise of connected cars, more entry points and interfaces have been introduced on board vehicles, thereby also leading to a wider potential attack surface. Existing security mechanisms focus on the use of encryption, authentication, and vehicle Intrusion Detection Systems (IDS), which operate under various constraints such as low bandwidth, small frame size (e.g., in the CAN protocol), limited availability of computational resources, and real-time sensitivity. We survey and classify current cryptographic and IDS approaches and compare these approaches based on criteria such as real-time constraints, types of hardware used, changes in CAN Bus behaviour, types of attack mitigation, and software/ hardware used to validate these approaches. We conclude with mitigation strategies limitations and research challenges for the future.},
  archive      = {J_CSUR},
  author       = {Emad Aliwa and Omer Rana and Charith Perera and Peter Burnap},
  doi          = {10.1145/3431233},
  journal      = {ACM Computing Surveys},
  number       = {1},
  pages        = {21:1–37},
  shortjournal = {ACM Comput. Surv.},
  title        = {Cyberattacks and countermeasures for in-vehicle networks},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Named entity recognition and relation extraction:
State-of-the-art. <em>CSUR</em>, <em>54</em>(1), 20:1–39. (<a
href="https://doi.org/10.1145/3445965">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the advent of Web 2.0, there exist many online platforms that result in massive textual-data production. With ever-increasing textual data at hand, it is of immense importance to extract information nuggets from this data. One approach towards effective harnessing of this unstructured textual data could be its transformation into structured text. Hence, this study aims to present an overview of approaches that can be applied to extract key insights from textual data in a structured way. For this, Named Entity Recognition and Relation Extraction are being majorly addressed in this review study. The former deals with identification of named entities, and the latter deals with problem of extracting relation between set of entities. This study covers early approaches as well as the developments made up till now using machine learning models. Survey findings conclude that deep-learning-based hybrid and joint models are currently governing the state-of-the-art. It is also observed that annotated benchmark datasets for various textual-data generators such as Twitter and other social forums are not available. This scarcity of dataset has resulted into relatively less progress in these domains. Additionally, the majority of the state-of-the-art techniques are offline and computationally expensive. Last, with increasing focus on deep-learning frameworks, there is need to understand and explain the under-going processes in deep architectures.},
  archive      = {J_CSUR},
  author       = {Zara Nasar and Syed Waqar Jaffry and Muhammad Kamran Malik},
  doi          = {10.1145/3445965},
  journal      = {ACM Computing Surveys},
  number       = {1},
  pages        = {20:1–39},
  shortjournal = {ACM Comput. Surv.},
  title        = {Named entity recognition and relation extraction: State-of-the-art},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Coordination of autonomous vehicles: Taxonomy and survey.
<em>CSUR</em>, <em>54</em>(1), 19:1–33. (<a
href="https://doi.org/10.1145/3431231">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the near future, our streets will be populated by myriads of autonomous self-driving vehicles to serve our diverse mobility needs. This will raise the need to coordinate their movements in order to properly handle both access to shared resources (e.g., intersections and parking slots) and the execution of mobility tasks (e.g., platooning and ramp merging). The aim of this article is to provide a global view of the coordination issues and the related solutions in the field of autonomous vehicles. To this end, we firstly introduce the general problems associated with coordination of autonomous vehicles by identifying and framing the key classes of coordination problems. Then, we overview the different approaches that can be adopted to deal with such problems by classifying them in terms of the degree of autonomy in decision making that is left to autonomous vehicles during the coordination process. Finally, we overview some further research challenges to address before autonomous coordinated vehicles can safely hit our streets.},
  archive      = {J_CSUR},
  author       = {Stefano Mariani and Giacomo Cabri and Franco Zambonelli},
  doi          = {10.1145/3431231},
  journal      = {ACM Computing Surveys},
  number       = {1},
  pages        = {19:1–33},
  shortjournal = {ACM Comput. Surv.},
  title        = {Coordination of autonomous vehicles: Taxonomy and survey},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A practical tutorial for decision tree induction: Evaluation
measures for candidate splits and opportunities. <em>CSUR</em>,
<em>54</em>(1), 18:1–38. (<a
href="https://doi.org/10.1145/3429739">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Experts from different domains have resorted to machine learning techniques to produce explainable models that support decision-making. Among existing techniques, decision trees have been useful in many application domains for classification. Decision trees can make decisions in a language that is closer to that of the experts. Many researchers have attempted to create better decision tree models by improving the components of the induction algorithm. One of the main components that have been studied and improved is the evaluation measure for candidate splits. In this article, we introduce a tutorial that explains decision tree induction. Then, we present an experimental framework to assess the performance of 21 evaluation measures that produce different C4.5 variants considering 110 databases, two performance measures, and 10× 10-fold cross-validation. Furthermore, we compare and rank the evaluation measures by using a Bayesian statistical analysis. From our experimental results, we present the first two performance rankings in the literature of C4.5 variants. Moreover, we organize the evaluation measures into two groups according to their performance. Finally, we introduce meta-models that automatically determine the group of evaluation measures to produce a C4.5 variant for a new database and some further opportunities for decision tree models.},
  archive      = {J_CSUR},
  author       = {Víctor Adrián Sosa Hernández and Raúl Monroy and Miguel Angel Medina-Pérez and Octavio Loyola-González and Francisco Herrera},
  doi          = {10.1145/3429739},
  journal      = {ACM Computing Surveys},
  number       = {1},
  pages        = {18:1–38},
  shortjournal = {ACM Comput. Surv.},
  title        = {A practical tutorial for decision tree induction: Evaluation measures for candidate splits and opportunities},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Data structures to represent a set of k-long DNA sequences.
<em>CSUR</em>, <em>54</em>(1), 17:1–22. (<a
href="https://doi.org/10.1145/3445967">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The analysis of biological sequencing data has been one of the biggest applications of string algorithms. The approaches used in many such applications are based on the analysis of k -mers, which are short fixed-length strings present in a dataset. While these approaches are rather diverse, storing and querying a k -mer set has emerged as a shared underlying component. A set of k -mers has unique features and applications that, over the past 10 years, have resulted in many specialized approaches for its representation. In this survey, we give a unified presentation and comparison of the data structures that have been proposed to store and query a k -mer set. We hope this survey will serve as a resource for researchers in the field as well as make the area more accessible to researchers outside the field.},
  archive      = {J_CSUR},
  author       = {Rayan Chikhi and Jan Holub and Paul Medvedev},
  doi          = {10.1145/3445967},
  journal      = {ACM Computing Surveys},
  number       = {1},
  pages        = {17:1–22},
  shortjournal = {ACM Comput. Surv.},
  title        = {Data structures to represent a set of k-long DNA sequences},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Investigation of multiple-valued logic technologies for
beyond-binary era. <em>CSUR</em>, <em>54</em>(1), 16:1–30. (<a
href="https://doi.org/10.1145/3431230">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Computing technologies are currently based on the binary logic/number system, which is dependent on the simple on and off switching mechanism of the prevailing transistors. With the exponential increase of data processing and storage needs, there is a strong push to move to a higher radix logic/number system that can eradicate or lessen many limitations of the binary system. Anticipated saturation of Moore’s law and the necessity to increase information density and processing speed in the future micro and nanoelectronic circuits and systems provide a strong background and motivation for the beyond-binary logic system. In this review article, different technologies for Multiple-valued-Logic (MVL) devices and the associated prospects and constraints are discussed. The feasibility of the MVL system in real-world applications rests on resolving two major challenges: (i) development of an efficient mathematical approach to implement the MVL logic using available technologies, and (ii) availability of effective synthesis techniques. This review of different technologies for the MVL system is intended to perform a comprehensive investigation of various MVL technologies and a comparative analysis of the feasible approaches to implement MVL devices, especially ternary logic.},
  archive      = {J_CSUR},
  author       = {Zarin Tasnim Sandhie and Jill Arvindbhai Patel and Farid Uddin Ahmed and Masud H. Chowdhury},
  doi          = {10.1145/3431230},
  journal      = {ACM Computing Surveys},
  number       = {1},
  pages        = {16:1–30},
  shortjournal = {ACM Comput. Surv.},
  title        = {Investigation of multiple-valued logic technologies for beyond-binary era},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Decentralised learning in federated deployment environments:
A system-level survey. <em>CSUR</em>, <em>54</em>(1), 15:1–38. (<a
href="https://doi.org/10.1145/3429252">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Decentralised learning is attracting more and more interest because it embodies the principles of data minimisation and focused data collection, while favouring the transparency of purpose specification (i.e., the objective for which a model is built). Cloud-centric-only processing and deep learning are no longer strict necessities to train high-fidelity models; edge devices can actively participate in the decentralised learning process by exchanging meta-level information in place of raw data, thus paving the way for better privacy guarantees. In addition, these new possibilities can relieve the network backbone from unnecessary data transfer and allow it to meet strict low-latency requirements by leveraging on-device model inference. This survey provides a detailed and up-to-date overview of the most recent contributions available in the state-of-the-art decentralised learning literature. In particular, it originally provides the reader audience with a clear presentation of the peculiarities of federated settings, with a novel taxonomy of decentralised learning approaches, and with a detailed description of the most relevant and specific system-level contributions of the surveyed solutions for privacy, communication efficiency, non-IIDness, device heterogeneity, and poisoning defense.},
  archive      = {J_CSUR},
  author       = {Paolo Bellavista and Luca Foschini and Alessio Mora},
  doi          = {10.1145/3429252},
  journal      = {ACM Computing Surveys},
  number       = {1},
  pages        = {15:1–38},
  shortjournal = {ACM Comput. Surv.},
  title        = {Decentralised learning in federated deployment environments: A system-level survey},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Key generation for internet of things: A contemporary
survey. <em>CSUR</em>, <em>54</em>(1), 14:1–37. (<a
href="https://doi.org/10.1145/3429740">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Key generation is a promising technique to bootstrap secure communications for the Internet of Things devices that have no prior knowledge between each other. In the past few years, a variety of key generation protocols and systems have been proposed. In this survey, we review and categorise recent key generation systems based on a novel taxonomy. Then, we provide both quantitative and qualitative comparisons of existing approaches. We also discuss the security vulnerabilities of key generation schemes and possible countermeasures. Finally, we discuss the current challenges and point out several potential research directions.},
  archive      = {J_CSUR},
  author       = {Weitao Xu and Junqing Zhang and Shunqi Huang and Chengwen Luo and Wei Li},
  doi          = {10.1145/3429740},
  journal      = {ACM Computing Surveys},
  number       = {1},
  pages        = {14:1–37},
  shortjournal = {ACM Comput. Surv.},
  title        = {Key generation for internet of things: A contemporary survey},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Networking in oceans: A survey. <em>CSUR</em>,
<em>54</em>(1), 13:1–33. (<a
href="https://doi.org/10.1145/3428147">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The ocean is a huge saltwater body that is different from terrestrial environments in terms of deployment circumstance, weather conditions, and user distributions. Therefore, it is difficult to apply terrestrial networking technologies directly in oceans. The cost-effectiveness of satellites is still an issue to be addressed to increase their popularity due to their high cost in construction, launching, and maintenance and high deployment risks. Such situations stimulate many research efforts on networking technologies in the ocean space consisting of coastline, water surface, sky, and underwater. This article conducts a comprehensive survey on the related issues through reviewing the networking environments and communication networks already operating in the ocean space as well as ongoing R8D activities and results reported in the literature. These systems include coastal networks, water surface networks, sky networks, and underwater networks, which are reviewed and discussed along with summaries on the related topics and research issues necessary for further studies. This article, taking into account maritime communication networks and underwater networking together, aims to provide the reader with an overview on the state of the art and corresponding challenging issues for networking in the ocean space.},
  archive      = {J_CSUR},
  author       = {Shengming Jiang},
  doi          = {10.1145/3428147},
  journal      = {ACM Computing Surveys},
  number       = {1},
  pages        = {13:1–33},
  shortjournal = {ACM Comput. Surv.},
  title        = {Networking in oceans: A survey},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A systematic review of multimedia tools for cybersecurity
awareness and education. <em>CSUR</em>, <em>54</em>(1), 12:1–39. (<a
href="https://doi.org/10.1145/3427920">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We conduct a comprehensive review covering academic publications and industry products relating to tools for cybersecurity awareness and education aimed at non-expert end-users developed in the past 20 years. Through our search criteria, we identified 119 tools that we cataloged into five broad media categories. We explore current trends, assess their use of relevant instructional design principles, and review empirical evidence of the tools’ effectiveness. From our review, we provide an evaluation checklist and suggest that a more systematic approach to the design and evaluation of cybersecurity educational tools would be beneficial.},
  archive      = {J_CSUR},
  author       = {Leah Zhang-Kennedy and Sonia Chiasson},
  doi          = {10.1145/3427920},
  journal      = {ACM Computing Surveys},
  number       = {1},
  pages        = {12:1–39},
  shortjournal = {ACM Comput. Surv.},
  title        = {A systematic review of multimedia tools for cybersecurity awareness and education},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Security in brain-computer interfaces: State-of-the-art,
opportunities, and future challenges. <em>CSUR</em>, <em>54</em>(1),
11:1–35. (<a href="https://doi.org/10.1145/3427376">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Brain-Computer Interfaces (BCIs) have significantly improved the patients’ quality of life by restoring damaged hearing, sight, and movement capabilities. After evolving their application scenarios, the current trend of BCI is to enable new innovative brain-to-brain and brain-to-the-Internet communication paradigms. This technological advancement generates opportunities for attackers, since users’ personal information and physical integrity could be under tremendous risk. This work presents the existing versions of the BCI life-cycle and homogenizes them in a new approach that overcomes current limitations. After that, we offer a qualitative characterization of the security attacks affecting each phase of the BCI cycle to analyze their impacts and countermeasures documented in the literature. Finally, we reflect on lessons learned, highlighting research trends and future challenges concerning security on BCIs.},
  archive      = {J_CSUR},
  author       = {Sergio López Bernal and Alberto Huertas Celdrán and Gregorio Martínez Pérez and Michael Taynnan Barros and Sasitharan Balasubramaniam},
  doi          = {10.1145/3427376},
  journal      = {ACM Computing Surveys},
  number       = {1},
  pages        = {11:1–35},
  shortjournal = {ACM Comput. Surv.},
  title        = {Security in brain-computer interfaces: State-of-the-art, opportunities, and future challenges},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Potential deep learning solutions to persistent and emerging
big data challenges—a practitioners’ cookbook. <em>CSUR</em>,
<em>54</em>(1), 10:1–39. (<a
href="https://doi.org/10.1145/3427476">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The phenomenon of Big Data continues to present moving targets for the scientific and technological state-of-the-art. This work demonstrates that the solution space of these challenges has expanded with deep learning now moving beyond traditional applications in computer vision and natural language processing to diverse and core machine learning tasks such as learning with streaming and non-iid-data, partial supervision, and large volumes of distributed data while preserving privacy. We present a framework coalescing multiple deep methods and corresponding models as responses to specific Big Data challenges. First, we perform a detailed per-challenge review of existing techniques, with benchmarks and usage advice, and subsequently synthesize them together into one organic construct that we discover principally uses extensions of one underlying model, the autoencoder. This work therefore provides a synthesis where challenges at scale across the Vs of Big Data could be addressed by new algorithms and architectures being proposed in the deep learning community. The value being proposed to the reader from either community in terms of nomenclature, concepts, and techniques of the other would advance the cause of multi-disciplinary, transversal research and accelerate the advance of technology in both domains.},
  archive      = {J_CSUR},
  author       = {Behroz Mirza and Tahir Q. Syed and Behraj Khan and Yameen Malik},
  doi          = {10.1145/3427476},
  journal      = {ACM Computing Surveys},
  number       = {1},
  pages        = {10:1–39},
  shortjournal = {ACM Comput. Surv.},
  title        = {Potential deep learning solutions to persistent and emerging big data Challenges—A practitioners’ cookbook},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Lattice-based key-sharing schemes: A survey. <em>CSUR</em>,
<em>54</em>(1), 9:1–39. (<a
href="https://doi.org/10.1145/3422178">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Public-key cryptography is an indispensable component used in almost all of our present-day digital infrastructure. However, most if not all of it is predominantly built upon hardness guarantees of number theoretic problems that can be broken by large-scale quantum computers in the future. Sensing the imminent threat from continued advances in quantum computing, NIST has recently initiated a global-level standardization process for quantum resistant public-key cryptographic primitives such as public-key encryption, digital signatures, and key encapsulation mechanisms. While the process received proposals from various categories of post-quantum cryptography, lattice-based cryptography features most prominently among all the submissions. Lattice-based cryptography offers a very attractive alternative to traditional public-key cryptography mainly due to the variety of lattice-based schemes offering varying flavors of security and efficiency guarantees. In this article, we survey the evolution of lattice-based key-sharing schemes (public-key encryption and key encapsulation schemes) and cover various aspects ranging from theoretical security guarantees, general algorithmic frameworks, practical implementation aspects, and physical attack security, with special focus on lattice-based key-sharing schemes competing in the NIST’s standardization process.},
  archive      = {J_CSUR},
  author       = {Prasanna Ravi and James Howe and Anupam Chattopadhyay and Shivam Bhasin},
  doi          = {10.1145/3422178},
  journal      = {ACM Computing Surveys},
  number       = {1},
  pages        = {9:1–39},
  shortjournal = {ACM Comput. Surv.},
  title        = {Lattice-based key-sharing schemes: A survey},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Relative worst-order analysis: A survey. <em>CSUR</em>,
<em>54</em>(1), 8:1–21. (<a
href="https://doi.org/10.1145/3425910">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The standard measure for the quality of online algorithms is the competitive ratio. This measure is generally applicable, and for some problems it works well, but for others it fails to distinguish between algorithms that have very different performance. Thus, ever since its introduction, researchers have worked on improving the measure, defining variants, or defining measures based on other concepts to improve on the situation. Relative worst-order analysis (RWOA) is one of the most thoroughly tested such proposals. With RWOA, many separations of algorithms not obtainable with competitive analysis have been found. In RWOA, two algorithms are compared directly, rather than indirectly as is done in competitive analysis, where both algorithms are compared separately to an optimal offline algorithm. If, up to permutations of the request sequences, one algorithm is always at least as good and sometimes better than another, then the first algorithm is deemed the better algorithm by RWOA. We survey the most important results obtained with this technique and compare it with other quality measures. The survey includes a quite complete set of references.},
  archive      = {J_CSUR},
  author       = {Joan Boyar and Lene M. Favrholdt and Kim S. Larsen},
  doi          = {10.1145/3425910},
  journal      = {ACM Computing Surveys},
  number       = {1},
  pages        = {8:1–21},
  shortjournal = {ACM Comput. Surv.},
  title        = {Relative worst-order analysis: A survey},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The creation and detection of deepfakes: A survey.
<em>CSUR</em>, <em>54</em>(1), 7:1–41. (<a
href="https://doi.org/10.1145/3425780">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generative deep learning algorithms have progressed to a point where it is difficult to tell the difference between what is real and what is fake. In 2018, it was discovered how easy it is to use this technology for unethical and malicious applications, such as the spread of misinformation, impersonation of political leaders, and the defamation of innocent individuals. Since then, these “deepfakes” have advanced significantly. In this article, we explore the creation and detection of deepfakes and provide an in-depth view as to how these architectures work. The purpose of this survey is to provide the reader with a deeper understanding of (1) how deepfakes are created and detected, (2) the current trends and advancements in this domain, (3) the shortcomings of the current defense solutions, and (4) the areas that require further research and attention.},
  archive      = {J_CSUR},
  author       = {Yisroel Mirsky and Wenke Lee},
  doi          = {10.1145/3425780},
  journal      = {ACM Computing Surveys},
  number       = {1},
  pages        = {7:1–41},
  shortjournal = {ACM Comput. Surv.},
  title        = {The creation and detection of deepfakes: A survey},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). From server-based to client-based machine learning: A
comprehensive survey. <em>CSUR</em>, <em>54</em>(1), 6:1–36. (<a
href="https://doi.org/10.1145/3424660">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, mobile devices have gained increasing development with stronger computation capability and larger storage space. Some of the computation-intensive machine learning tasks can now be run on mobile devices. To exploit the resources available on mobile devices and preserve personal privacy, the concept of client-based machine learning has been proposed. It leverages the users’ local hardware and local data to solve machine learning sub-problems on mobile devices and only uploads computation results rather than the original data for the optimization of the global model. Such an architecture can not only relieve computation and storage burdens on servers but also protect the users’ sensitive information. Another benefit is the bandwidth reduction because various kinds of local data can be involved in the training process without being uploaded. In this article, we provide a literature review on the progressive development of machine learning from server based to client based. We revisit a number of widely used server-based and client-based machine learning methods and applications. We also extensively discuss the challenges and future directions in this area. We believe that this survey will give a clear overview of client-based machine learning and provide guidelines on applying client-based machine learning to practice.},
  archive      = {J_CSUR},
  author       = {Renjie Gu and Chaoyue Niu and Fan Wu and Guihai Chen and Chun Hu and Chengfei Lyu and Zhihua Wu},
  doi          = {10.1145/3424660},
  journal      = {ACM Computing Surveys},
  number       = {1},
  pages        = {6:1–36},
  shortjournal = {ACM Comput. Surv.},
  title        = {From server-based to client-based machine learning: A comprehensive survey},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Challenges in firmware re-hosting, emulation, and analysis.
<em>CSUR</em>, <em>54</em>(1), 5:1–36. (<a
href="https://doi.org/10.1145/3423167">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {System emulation and firmware re-hosting have become popular techniques to answer various security and performance related questions, such as determining whether a firmware contain security vulnerabilities or meet timing requirements when run on a specific hardware platform. While this motivation for emulation and binary analysis has previously been explored and reported, starting to either work or research in the field is difficult. To this end, we provide a comprehensive guide for the practitioner or system emulation researcher. We layout common challenges faced during firmware re-hosting, explaining successive steps and surveying common tools used to overcome these challenges. We provide classification techniques on five different axes, including emulator methods, system type, fidelity, emulator purpose, and control. These classifications and comparison criteria enable the practitioner to determine the appropriate tool for emulation. We use our classifications to categorize popular works in the field and present 28 common challenges faced when creating, emulating, and analyzing a system from obtaining firmwares to post emulation analysis.},
  archive      = {J_CSUR},
  author       = {Christopher Wright and William A. Moeglein and Saurabh Bagchi and Milind Kulkarni and Abraham A. Clements},
  doi          = {10.1145/3423167},
  journal      = {ACM Computing Surveys},
  number       = {1},
  pages        = {5:1–36},
  shortjournal = {ACM Comput. Surv.},
  title        = {Challenges in firmware re-hosting, emulation, and analysis},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Location privacy-preserving mechanisms in location-based
services: A comprehensive survey. <em>CSUR</em>, <em>54</em>(1), 4:1–36.
(<a href="https://doi.org/10.1145/3423165">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Location-based services (LBSs) provide enhanced functionality and convenience of ubiquitous computing, but they open up new vulnerabilities that can be utilized to violate the users’ privacy. The leakage of private location data in the LBS context has drawn significant attention from academics and industry due to its importance, leading to numerous research efforts aiming to confront the related challenges. However, to the best of our knowledge, none of relevant studies have performed a qualitative and quantitative comparison and analysis of the complex topic of designing countermeasures and discussed the viability of their use with different kinds of services and the potential elements that could be deployed to meet new challenges. Accordingly, the purpose of this survey is to examine the privacy-preserving techniques in LBSs. We categorize and provide an inside-out review of the existing techniques. Performing a retrospective analysis of several typical studies in each category, we summarize their basic principles and recent advances. Additionally, we highlight the use of privacy-preserving techniques in LBSs for enabling new research opportunities. Providing an up-to-date and comprehensive overview of existing studies, this survey may further stimulate new research efforts into this promising field.},
  archive      = {J_CSUR},
  author       = {Hongbo Jiang and Jie Li and Ping Zhao and Fanzi Zeng and Zhu Xiao and Arun Iyengar},
  doi          = {10.1145/3423165},
  journal      = {ACM Computing Surveys},
  number       = {1},
  pages        = {4:1–36},
  shortjournal = {ACM Comput. Surv.},
  title        = {Location privacy-preserving mechanisms in location-based services: A comprehensive survey},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Smart contract languages: A multivocal mapping study.
<em>CSUR</em>, <em>54</em>(1), 3:1–38. (<a
href="https://doi.org/10.1145/3423166">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Blockchain is a disruptive technology that has attracted the attention of the scientific community and companies, as proven by the exponential growth of publications on this topic in recent years. This growing interest is mainly due to the promise that the use of blockchain enables it to be verified, without including any trusted intermediaries, that the information received from the network is authentic and up-to-date. In this respect, blockchain is a distributed database that can be seen as a ledger that records all transactions that have ever been executed. In this context, smart contracts are pieces of software used to facilitate, verify, and enforce the negotiation of a transaction on a blockchain platform. These pieces of software are implemented by using programming languages, which are sometimes provided by the blockchain platforms themselves. This study aims to (1) identify and categorise the state-of-the-art related to smart contract languages, in terms of the existing languages and their main features, and (2) identify new research opportunities. The review has been conducted as a multivocal mapping study that follows the guidelines proposed by Garousi et al. for conducting multivocal literature reviews, as well as the guidelines proposed by Kitchenham and Charters for conducting mapping studies. As a result of the implementation of the review protocol, 4,119 papers were gathered, and 109 of them were selected for extraction. The contributions of this article are twofold: (1) 101 different smart contract languages have been identified and classified according to a variety of criteria; (2) a discussion on the findings and their implications for future research have been outlined. As a conclusion, it could be stated that a rigorous and replicable overview of the state-of-the-art of smart contract languages has been provided that can benefit not only researchers but also practitioners in the field, thanks to its multivocal nature.},
  archive      = {J_CSUR},
  author       = {Ángel Jesús Varela-Vaca and Antonia M. Reina Quintero},
  doi          = {10.1145/3423166},
  journal      = {ACM Computing Surveys},
  number       = {1},
  pages        = {3:1–38},
  shortjournal = {ACM Comput. Surv.},
  title        = {Smart contract languages: A multivocal mapping study},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Relay-based communications in WBANs: A comprehensive survey.
<em>CSUR</em>, <em>54</em>(1), 2:1–34. (<a
href="https://doi.org/10.1145/3423164">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wireless Body Area Networks (WBANs) constitute an emerging technology in the field of health care that makes health monitoring possible from one’s home itself. WBANs open many challenges by placing sensors on/inside human bodies for collecting various health-related information. Unlike traditional Wireless Sensor Networks (WSNs), communication in WBANs suffers from high channel fading and attenuation due to human body fat. Therefore, relay-based communication with data forwarding techniques is used to handle link failures and poor network connectivity. Accordingly, in this survey article, we present a comprehensive study of relay-based communication mechanisms in WBANs. We begin with a brief look at the multi-tiered architecture of WBANs, how direct communication works, and how relay-based communication is different. Subsequently, we present a detailed review of relay node selection approaches, which, in turn, also affects how a WBAN performs. In this context, we also look at the unique quality of service (QoS) demands of WBANs and how they can be assured.},
  archive      = {J_CSUR},
  author       = {Avani Vyas and Sujata Pal and Barun Kumar Saha},
  doi          = {10.1145/3423164},
  journal      = {ACM Computing Surveys},
  number       = {1},
  pages        = {2:1–34},
  shortjournal = {ACM Comput. Surv.},
  title        = {Relay-based communications in WBANs: A comprehensive survey},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Cyber-aggression, cyberbullying, and cyber-grooming: A
survey and research challenges. <em>CSUR</em>, <em>54</em>(1), 1:1–42.
(<a href="https://doi.org/10.1145/3424246">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cyber-aggression, cyberbullying, and cyber-grooming are distinctive and similar phenomena that represent the objectionable content appearing on online social media. Timely detection of the objectionable content is very important for its prevention and reduction. This article explores and spotlights diversity of definitions of cyber-aggression, cyberbulling, and cyber-grooming; analyzes current categorization systems and taxonomies; identifies the targets, target categories, and subcategories of the subjects of the objectionable content research; analyzes the ambiguity of the linguistic terms in the domain; reviews present databases gathered for researching the field; explores types of features used for modeling systems for automatic detection; and examines methods for automatic detection and/or prediction of the objectionable content. The results point to directions of system development for tracing transformations of objectionable content over time on different online social platforms.},
  archive      = {J_CSUR},
  author       = {Miljana Mladenović and Vera Ošmjanski and Staša Vujičić Stanković},
  doi          = {10.1145/3424246},
  journal      = {ACM Computing Surveys},
  number       = {1},
  pages        = {1:1–42},
  shortjournal = {ACM Comput. Surv.},
  title        = {Cyber-aggression, cyberbullying, and cyber-grooming: A survey and research challenges},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A review of cognitive assistants for healthcare: Trends,
prospects, and future directions. <em>CSUR</em>, <em>53</em>(6),
130:1–37. (<a href="https://doi.org/10.1145/3419368">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Healthcare cognitive assistants (HCAs) are intelligent systems or agents that interact with users in a context-aware and adaptive manner to improve their health outcomes by augmenting their cognitive abilities or complementing a cognitive impairment. They assist a wide variety of users ranging from patients to their healthcare providers (e.g., general practitioner, specialist, surgeon) in several situations (e.g., remote patient monitoring, emergency response, robotic surgery). While HCAs are critical to ensure personalized, scalable, and efficient healthcare, there exists a knowledge gap in finding the emerging trends, key challenges, design guidelines, and state-of-the-art technologies suitable for developing HCAs. This survey aims to bridge this gap for researchers from multiple domains, including but not limited to cyber-physical systems, artificial intelligence, human-computer interaction, robotics, and smart health. It provides a comprehensive definition of HCAs and outlines a novel, practical categorization of existing HCAs according to their target user role and the underlying application goals. This survey summarizes and assorts existing HCAs based on their characteristic features (i.e., interactive, context-aware, and adaptive) and enabling technological aspects (i.e., sensing, actuation, control, and computation). Finally, it identifies critical research questions and design recommendations to accelerate the development of the next generation of cognitive assistants for healthcare.},
  archive      = {J_CSUR},
  author       = {Sarah Masud Preum and Sirajum Munir and Meiyi Ma and Mohammad Samin Yasar and David J. Stone and Ronald Williams and Homa Alemzadeh and John A. Stankovic},
  doi          = {10.1145/3419368},
  journal      = {ACM Computing Surveys},
  number       = {6},
  pages        = {130:1–37},
  shortjournal = {ACM Comput. Surv.},
  title        = {A review of cognitive assistants for healthcare: Trends, prospects, and future directions},
  volume       = {53},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Working set analytics. <em>CSUR</em>, <em>53</em>(6),
113:1–36. (<a href="https://doi.org/10.1145/3399709">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The working set model for program behavior was invented in 1965. It has stood the test of time in virtual memory management for over 50 years. It is considered the ideal for managing memory in operating systems and caches. Its superior performance was based on the principle of locality, which was discovered at the same time; locality is the observed tendency of programs to use distinct subsets of their pages over extended periods of time. This tutorial traces the development of working set theory from its origins to the present day. We will discuss the principle of locality and its experimental verification. We will show why working set memory management resists thrashing and generates near-optimal system throughput. We will present the powerful, linear-time algorithms for computing working set statistics and applying them to the design of memory systems. We will debunk several myths about locality and the performance of memory systems. We will conclude with a discussion of the application of the working set model in parallel systems, modern shared CPU caches, network edge caches, and inventory and logistics management.},
  archive      = {J_CSUR},
  author       = {Peter J. Denning},
  doi          = {10.1145/3399709},
  journal      = {ACM Computing Surveys},
  number       = {6},
  pages        = {113:1–36},
  shortjournal = {ACM Comput. Surv.},
  title        = {Working set analytics},
  volume       = {53},
  year         = {2021},
}
</textarea>
</details></li>
</ul>

</body>
</html>
