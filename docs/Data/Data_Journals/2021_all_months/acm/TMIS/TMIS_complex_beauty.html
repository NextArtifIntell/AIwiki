<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>TMIS_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="tmis---48">TMIS - 48</h2>
<ul>
<li><details>
<summary>
(2021). Automating research data management using machine-actionable
data management plans. <em>TMIS</em>, <em>13</em>(2), 18:1–22. (<a
href="https://doi.org/10.1145/3490396">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many research funders mandate researchers to create and maintain data management plans (DMPs) for research projects that describe how research data is managed to ensure its reusability. A DMP, being a static textual document, is difficult to act upon and can quickly become obsolete and impractical to maintain. A new generation of machine-actionable DMPs (maDMPs) was therefore proposed by the Research Data Alliance to enable automated integration of information and updates. maDMPs open up a variety of use cases enabling interoperability of research systems and automation of data management tasks. In this article, we describe a system for machine-actionable data management planning in an institutional context. We identify common use cases within research that can be automated to benefit from machine-actionability of DMPs. We propose a reference architecture of an maDMP support system that can be embedded into an institutional research data management infrastructure. The system semi-automates creation and maintenance of DMPs, and thus eases the burden for the stakeholders responsible for various DMP elements. We evaluate the proposed system in a case study conducted at the largest technical university in Austria and quantify to what extent the DMP templates provided by the European Commission and a national funding body can be pre-filled. The proof-of-concept implementation shows that maDMP workflows can be semi-automated, thus workload on involved parties can be reduced and quality of information increased. The results are especially relevant to decision makers and infrastructure operators who want to design information systems in a systematic way that can utilize the full potential of maDMPs.},
  archive      = {J_TMIS},
  author       = {Tomasz Miksa and Simon Oblasser and Andreas Rauber},
  doi          = {10.1145/3490396},
  journal      = {ACM Transactions on Management Information Systems},
  number       = {2},
  pages        = {18:1–22},
  shortjournal = {ACM Trans. Manag. Inf. Sys.},
  title        = {Automating research data management using machine-actionable data management plans},
  volume       = {13},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An intelligent mechanism to automatically discover emerging
technology trends: Exploring regulatory technology. <em>TMIS</em>,
<em>13</em>(2), 17:1–29. (<a
href="https://doi.org/10.1145/3485187">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Technology trend analysis uses data relevant to historical performance and extrapolates it to estimate and assess the future potential of technology. Such analysis is used to analyze emerging technologies or predict the growing markets that influence the resulting social or economic development to assist in effective decision-making. Traditional trend analysis methods are time-consuming and require considerable labor. Moreover, the implemented processes may largely rely on the specific knowledge of the domain experts. With the advancement in the areas of science and technology, emerging cross-domain trends have received growing attention for its considerable influence on society and the economy. Consequently, emerging cross-domain predictions that combine or complement various technologies or integrate with diverse disciplines may be more critical than other tools and applications in the same domain. This study uses a design science research methodology, a text mining technique, and social network analysis (SNA) to analyze the development trends concerning the presentation of the product or service information on a company&#39;s website. This study applies regulatory technology (RegTech) as a case to analyze and justify the emerging cross-disciplinary trend. Furthermore, an experimental study is conducted using the Google search engine to verify and validate the proposed research mechanism at the end of this study. The study results reveal that, compared with Google Trends and Google Correlate, the research mechanism proposed in this study is more illustrative, feasible, and promising because it reduces noise and avoids the additional time and effort required to perform a further in-depth exploration to obtain the information.},
  archive      = {J_TMIS},
  author       = {Shi Ming Huang and David C. Yen and Ting Jyun Yan and Yi Ting Yang},
  doi          = {10.1145/3485187},
  journal      = {ACM Transactions on Management Information Systems},
  number       = {2},
  pages        = {17:1–29},
  shortjournal = {ACM Trans. Manag. Inf. Sys.},
  title        = {An intelligent mechanism to automatically discover emerging technology trends: Exploring regulatory technology},
  volume       = {13},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A query language for workflow logs. <em>TMIS</em>,
<em>13</em>(2), 16:1–28. (<a
href="https://doi.org/10.1145/3482968">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A business process (workflow) is an assembly of tasks to accomplish a business goal. Real-world workflow models often demanded to change due to new laws and policies, changes in the environment, and so on. To understand the inner workings of a business process to facilitate changes, workflow logs have the potential to enable inspecting, monitoring, diagnosing, analyzing, and improving the design of a complex workflow. Querying workflow logs, however, is still mostly an ad hoc practice by workflow managers. In this article, we focus on the problem of querying workflow log concerning both control flow and dataflow properties. We develop a query language based on “incident patterns” to allow the user to directly query workflow logs instead of having to transform such queries into database operations. We provide the formal semantics and a query evaluation algorithm of our language. By deriving an accurate cost model, we develop an optimization mechanism to accelerate query evaluation. Our experiment results demonstrate the effectiveness of the optimization and achieves up to 50× speedup over an adaption of existing evaluation method.},
  archive      = {J_TMIS},
  author       = {Yan Tang and Weilong Cui and Jianwen Su},
  doi          = {10.1145/3482968},
  journal      = {ACM Transactions on Management Information Systems},
  number       = {2},
  pages        = {16:1–28},
  shortjournal = {ACM Trans. Manag. Inf. Sys.},
  title        = {A query language for workflow logs},
  volume       = {13},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A multi-attention collaborative deep learning approach for
blood pressure prediction. <em>TMIS</em>, <em>13</em>(2), 15:1–20. (<a
href="https://doi.org/10.1145/3471571">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We develop a deep learning model based on Long Short-term Memory (LSTM) to predict blood pressure based on a unique data set collected from physical examination centers capturing comprehensive multi-year physical examination and lab results. In the Multi-attention Collaborative Deep Learning model (MAC-LSTM) we developed for this type of data, we incorporate three types of attention to generate more explainable and accurate results. In addition, we leverage information from similar users to enhance the predictive power of the model due to the challenges with short examination history. Our model significantly reduces predictive errors compared to several state-of-the-art baseline models. Experimental results not only demonstrate our model’s superiority but also provide us with new insights about factors influencing blood pressure. Our data is collected in a natural setting instead of a setting designed specifically to study blood pressure, and the physical examination items used to predict blood pressure are common items included in regular physical examinations for all the users. Therefore, our blood pressure prediction results can be easily used in an alert system for patients and doctors to plan prevention or intervention. The same approach can be used to predict other health-related indexes such as BMI.},
  archive      = {J_TMIS},
  author       = {Luo He and Hongyan Liu and Yinghui Yang and Bei Wang},
  doi          = {10.1145/3471571},
  journal      = {ACM Transactions on Management Information Systems},
  number       = {2},
  pages        = {15:1–20},
  shortjournal = {ACM Trans. Manag. Inf. Sys.},
  title        = {A multi-attention collaborative deep learning approach for blood pressure prediction},
  volume       = {13},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Readmission prediction for patients with heterogeneous
medical history: A trajectory-based deep learning approach.
<em>TMIS</em>, <em>13</em>(2), 14:1–27. (<a
href="https://doi.org/10.1145/3468780">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hospital readmission refers to the situation where a patient is re-hospitalized with the same primary diagnosis within a specific time interval after discharge. Hospital readmission causes $26 billion preventable expenses to the U.S. health systems annually and often indicates suboptimal patient care. To alleviate those severe financial and health consequences, it is crucial to proactively predict patients’ readmission risk. Such prediction is challenging because the evolution of patients’ medical history is dynamic and complex. The state-of-the-art studies apply statistical models which use static predictors in a period, failing to consider patients’ heterogeneous medical history. Our approach – Trajectory-BAsed DEep Learning (TADEL) – is motivated to tackle the deficiencies of the existing approaches by capturing dynamic medical history. We evaluate TADEL on a five-year national Medicare claims dataset including 3.6 million patients per year over all hospitals in the United States, reaching an F1 score of 87.3\% and an AUC of 88.4\%. Our approach significantly outperforms all the state-of-the-art methods. Our findings suggest that health status factors and insurance coverage are important predictors for readmission. This study contributes to IS literature and analytical methodology by formulating the trajectory-based readmission prediction problem and developing a novel deep-learning-based readmission risk prediction framework. From a health IT perspective, this research delivers implementable methods to assess patients’ readmission risk and take early interventions to avoid potential negative consequences.},
  archive      = {J_TMIS},
  author       = {Jiaheng Xie and Bin Zhang and Jian Ma and Daniel Zeng and Jenny Lo-Ciganic},
  doi          = {10.1145/3468780},
  journal      = {ACM Transactions on Management Information Systems},
  number       = {2},
  pages        = {14:1–27},
  shortjournal = {ACM Trans. Manag. Inf. Sys.},
  title        = {Readmission prediction for patients with heterogeneous medical history: A trajectory-based deep learning approach},
  volume       = {13},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Machine learning and survey-based predictors of InfoSec
non-compliance. <em>TMIS</em>, <em>13</em>(2), 13:1–20. (<a
href="https://doi.org/10.1145/3466689">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Survey items developed in behavioral Information Security (InfoSec) research should be practically useful in identifying individuals who are likely to create risk by failing to comply with InfoSec guidance. The literature shows that attitudes, beliefs, and perceptions drive compliance behavior and has influenced the creation of a multitude of training programs focused on improving ones’ InfoSec behaviors. While automated controls and directly observable technical indicators are generally preferred by InfoSec practitioners, difficult-to-monitor user actions can still compromise the effectiveness of automatic controls. For example, despite prohibition, doubtful or skeptical employees often increase organizational risk by using the same password to authenticate corporate and external services. Analysis of network traffic or device configurations is unlikely to provide evidence of these vulnerabilities but responses to well-designed surveys might. Guided by the relatively new IPAM model, this study administered 96 survey items from the Behavioral InfoSec literature, across three separate points in time, to 217 respondents. Using systematic feature selection techniques, manageable subsets of 29, 20, and 15 items were identified and tested as predictors of non-compliance with security policy. The feature selection process validates IPAM&#39;s innovation in using nuanced self-efficacy and planning items across multiple time frames. Prediction models were trained using several ML algorithms. Practically useful levels of prediction accuracy were achieved with, for example, ensemble tree models identifying 69\% of the riskiest individuals within the top 25\% of the sample. The findings indicate the usefulness of psychometric items from the behavioral InfoSec in guiding training programs and other cybersecurity control activities and demonstrate that they are promising as additional inputs to AI models that monitor networks for security events.},
  archive      = {J_TMIS},
  author       = {Byron Marshall and Michael Curry and Robert E. Crossler and John Correia},
  doi          = {10.1145/3466689},
  journal      = {ACM Transactions on Management Information Systems},
  number       = {2},
  pages        = {13:1–20},
  shortjournal = {ACM Trans. Manag. Inf. Sys.},
  title        = {Machine learning and survey-based predictors of InfoSec non-compliance},
  volume       = {13},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Detecting android malware and classifying its families in
large-scale datasets. <em>TMIS</em>, <em>13</em>(2), 12:1–21. (<a
href="https://doi.org/10.1145/3464323">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To relieve the burden of security analysts, Android malware detection and its family classification need to be automated. There are many previous works focusing on using machine (or deep) learning technology to tackle these two important issues, but as the number of mobile applications has increased in recent years, developing a scalable and precise solution is a new challenge that needs to be addressed in the security field. Accordingly, in this article, we propose a novel approach that not only enhances the performance of both Android malware and its family classification, but also reduces the running time of the analysis process. Using large-scale datasets obtained from different sources, we demonstrate that our method is able to output a high F-measure of 99.71\% with a low FPR of 0.37\%. Meanwhile, the computation time for processing a 300K dataset is reduced to nearly 3.3 hours. In addition, in classification evaluation, we demonstrate that the F-measure, precision, and recall are 97.5\%, 96.55\%, 98.64\%, respectively, when classifying 28 malware families. Finally, we compare our method with previous studies in both detection and classification evaluation. We observe that our method produces better performance in terms of its effectiveness and efficiency.},
  archive      = {J_TMIS},
  author       = {Bo Sun and Takeshi Takahashi and Tao Ban and Daisuke Inoue},
  doi          = {10.1145/3464323},
  journal      = {ACM Transactions on Management Information Systems},
  number       = {2},
  pages        = {12:1–21},
  shortjournal = {ACM Trans. Manag. Inf. Sys.},
  title        = {Detecting android malware and classifying its families in large-scale datasets},
  volume       = {13},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Privacy and confidentiality in process mining: Threats and
research challenges. <em>ACM Transactions on Management Information
System (TMIS)</em>, <em>13</em>(1), 11:1–17. (<a
href="https://doi.org/10.1145/3468877">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Privacy and confidentiality are very important prerequisites for applying process mining to comply with regulations and keep company secrets. This article provides a foundation for future research on privacy-preserving and confidential process mining techniques. Main threats are identified and related to a motivation application scenario in a hospital context as well as to the current body of work on privacy and confidentiality in process mining. A newly developed conceptual model structures the discussion that existing techniques leave room for improvement. This results in a number of important research challenges that should be addressed by future process mining research.},
  archive  = {J},
  author   = {Gamal Elkoumy and Stephan A. Fahrenkrog-Petersen and Mohammadreza Fani Sani and Agnes Koschmider and Felix Mannhardt and Saskia Nuñez Von Voigt and Majid Rafiei and Leopold Von Waldthausen},
  doi      = {10.1145/3468877},
  journal  = {ACM Transactions on Management Information System},
  number   = {1},
  pages    = {11:1–17},
  title    = {Privacy and confidentiality in process mining: Threats and research challenges},
  volume   = {13},
  year     = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Key factors affecting user adoption of open-access data
repositories in intelligence and security informatics: An affordance
perspective. <em>ACM Transactions on Management Information System
(TMIS)</em>, <em>13</em>(1), 10:1–24. (<a
href="https://doi.org/10.1145/3460823">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Rich, diverse cybersecurity data are critical for efforts by the intelligence and security informatics (ISI) community. Although open-access data repositories (OADRs) provide tremendous benefits for ISI researchers and practitioners, determinants of their adoption remain understudied. Drawing on affordance theory and extant ISI literature, this study proposes a factor model to explain how the essential and unique affordances of an OADR (i.e., relevance, accessibility, and integration) affect individual professionals&#39; intentions to use and collaborate with AZSecure, a major OADR. A survey study designed to test the model and hypotheses reveals that the effects of affordances on ISI professionals&#39; intentions to use and collaborate are mediated by perceived usefulness and ease of use, which then jointly determine their perceived value. This study advances ISI research by specifying three important affordances of OADRs; it also contributes to extant technology adoption literature by scrutinizing and affirming the interplay of essential user acceptance and value perceptions to explain ISI professionals&#39; adoptions of OADRs.},
  archive  = {J},
  author   = {Bo Wen and Paul Jen-Hwa Hu and Mohammadreza Ebrahimi and Hsinchun Chen},
  doi      = {10.1145/3460823},
  journal  = {ACM Transactions on Management Information System},
  number   = {1},
  pages    = {10:1–24},
  title    = {Key factors affecting user adoption of open-access data repositories in intelligence and security informatics: An affordance perspective},
  volume   = {13},
  year     = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A new approach for mining correlated frequent subgraphs.
<em>ACM Transactions on Management Information System (TMIS)</em>,
<em>13</em>(1), 9:1–28. (<a
href="https://doi.org/10.1145/3473042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Nowadays graphical datasets are having a vast amount of applications. As a result, graph mining—mining graph datasets to extract frequent subgraphs—has proven to be crucial in numerous aspects. It is important to perform correlation analysis among the subparts (i.e., elements) of the frequent subgraphs generated using graph mining to observe interesting information. However, the majority of existing works focuses on complexities in dealing with graphical structures, and not much work aims to perform correlation analysis. For instance, a previous work realized in this regard, operated with a very naive raw approach to fulfill the objective, but dealt only on a small subset of the problem. Hence, in this article, a new measure is proposed to aid in the analysis for large subgraphs, mined from various types of graph transactions in the dataset. These subgraphs are immense in terms of their structural composition, and thus parallel the entire set of graphs in real-world. A complete framework for discovering the relations among parts of a frequent subgraph is proposed using our new method. Evaluation results show the usefulness and accuracy of the newly defined measure on real-life graphical datasets.},
  archive  = {J},
  author   = {Mohammad Ehsan Shahmi Chowdhury and Chowdhury Farhan Ahmed and Carson K. Leung},
  doi      = {10.1145/3473042},
  journal  = {ACM Transactions on Management Information System},
  number   = {1},
  pages    = {9:1–28},
  title    = {A new approach for mining correlated frequent subgraphs},
  volume   = {13},
  year     = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Distance based pattern driven mining for outlier detection
in high dimensional big dataset. <em>ACM Transactions on Management
Information System (TMIS)</em>, <em>13</em>(1), 8:1–17. (<a
href="https://doi.org/10.1145/3469891">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Detection of outliers or anomalies is one of the vital issues in pattern-driven data mining. Outlier detection detects the inconsistent behavior of individual objects. It is an important sector in the data mining field with several different applications such as detecting credit card fraud, hacking discovery and discovering criminal activities. It is necessary to develop tools used to uncover the critical information established in the extensive data. This paper investigated a novel method for detecting cluster outliers in a multidimensional dataset, capable of identifying the clusters and outliers for datasets containing noise. The proposed method can detect the groups and outliers left by the clustering process, like instant irregular sets of clusters (C) and outliers (O), to boost the results. The results obtained after applying the algorithm to the dataset improved in terms of several parameters. For the comparative analysis, the accurate average value and the recall value parameters are computed. The accurate average value is 74.05\% of the existing COID algorithm, and our proposed algorithm has 77.21\%. The average recall value is 81.19\% and 89.51\% of the existing and proposed algorithm, which shows that the proposed work efficiency is better than the existing COID algorithm.},
  archive  = {J},
  author   = {Ankit Kumar and Abhishek Kumar and Ali Kashif Bashir and Mamoon Rashid and V. D. Ambeth Kumar and Rupak Kharel},
  doi      = {10.1145/3469891},
  journal  = {ACM Transactions on Management Information System},
  number   = {1},
  pages    = {8:1–17},
  title    = {Distance based pattern driven mining for outlier detection in high dimensional big dataset},
  volume   = {13},
  year     = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Novel machine learning for big data analytics in intelligent
support information management systems. <em>ACM Transactions on
Management Information System (TMIS)</em>, <em>13</em>(1), 7:1–21. (<a
href="https://doi.org/10.1145/3469890">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Two-dimensional 1 arrays of bi-component structures made of cobalt and permalloy elliptical dots with thickness of 25 nm, length 1 mm and width of 225 nm, have been prepared by a self-aligned shadow deposition technique. Brillouin light scattering has been exploited to study the frequency dependence of thermally excited magnetic eigenmodes on the intensity of the external magnetic field, applied along the easy axis of the elements. Scientific information technology has been developed rapidly. Here, the purposes are to make people&#39;s lives more convenient and ensure information management and classification. The machine learning algorithm is improved to obtain the optimized Light Gradient Boosting Machine (LightGBM) algorithm. Then, an Android-based intelligent support information management system is designed based on LightGBM for the big data analysis and classification management of information in the intelligent support information management system. The system is designed with modules of employee registration and login, company announcement notice, attendance and attendance management, self-service, and daily tools with the company as the subject. Furthermore, the performance of the constructed information management system is analyzed through simulations. Results demonstrate that the training time of the optimized LightGBM algorithm can stabilize at about 100s, and the test time can stabilize at 0.68s. Besides, its accuracy rate can reach 89.24\%, which is at least 3.6\% higher than other machine learning algorithms. Moreover, the acceleration efficiency analysis of each algorithm suggests that the optimized LightGBM algorithm is suitable for processing large amounts of data; its acceleration effect is more apparent, and its acceleration ratio is higher than other algorithms. Hence, the constructed intelligent support information management system can reach a high accuracy while ensuring the error, with apparent acceleration effect. Therefore, this model can provide an experimental reference for information classification and management in various fields.},
  archive  = {J},
  author   = {Zhihan Lv and Ranran Lou and Hailin Feng and Dongliang Chen and Haibin Lv},
  doi      = {10.1145/3469890},
  journal  = {ACM Transactions on Management Information System},
  number   = {1},
  pages    = {7:1–21},
  title    = {Novel machine learning for big data analytics in intelligent support information management systems},
  volume   = {13},
  year     = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). AI-based vehicular network toward 6G and IoT: Deep learning
approaches. <em>ACM Transactions on Management Information System
(TMIS)</em>, <em>13</em>(1), 6:1–12. (<a
href="https://doi.org/10.1145/3466691">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {In recent years, vehicular networks have become increasingly large, heterogeneous, and dynamic, making it difficult to meet strict requirements of ultralow latency, high reliability, high security, and massive connections for next generation (6G) networks. Recently, deep learning (DL ) has emerged as a powerful artificial intelligence (AI ) technique to optimize the efficiency and adaptability of vehicle and wireless communication. However, rapidly increasing absolute numbers of vehicles on the roads are leading to increased automobile accidents, many of which are attributable to drivers interacting with their mobile phones. To address potentially dangerous driver behavior, this study applies deep learning approaches to image recognition to develop an AI-based detection system that can detect potentially dangerous driving behavior. Multiple convolutional neural network (CNN )-based techniques including VGG16, VGG19, Densenet, and Openpose were compared in terms of their ability to detect and identify problematic driving.},
  archive  = {J},
  author   = {Mu-Yen Chen and Min-Hsuan Fan and Li-Xiang Huang},
  doi      = {10.1145/3466691},
  journal  = {ACM Transactions on Management Information System},
  number   = {1},
  pages    = {6:1–12},
  title    = {AI-based vehicular network toward 6G and IoT: Deep learning approaches},
  volume   = {13},
  year     = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Cross-modality transfer learning for image-text information
management. <em>ACM Transactions on Management Information System
(TMIS)</em>, <em>13</em>(1), 5:1–14. (<a
href="https://doi.org/10.1145/3464324">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {In the past decades, information from all kinds of data has been on a rapid increase. With state-of-the-art performance, machine learning algorithms have been beneficial for information management. However, insufficient supervised training data is still an adversity in many real-world applications. Therefore, transfer learning (TF) was proposed to address this issue. This article studies a not well investigated but important TL problem termed cross-modality transfer learning (CMTL). This topic is closely related to distant domain transfer learning (DDTL) and negative transfer. In general, conventional TL disciplines assume that the source domain and the target domain are in the same modality. DDTL aims to make efficient transfers even when the domains or the tasks are entirely different. As an extension of DDTL, CMTL aims to make efficient transfers between two different data modalities, such as from image to text. As the main focus of this study, we aim to improve the performance of image classification by transferring knowledge from text data. Previously, a few CMTL algorithms were proposed to deal with image classification problems. However, most existing algorithms are very task specific, and they are unstable on convergence. There are four main contributions in this study. First, we propose a novel heterogeneous CMTL algorithm, which requires only a tiny set of unlabeled target data and labeled source data with associate text tags. Second, we introduce a latent semantic information extraction method to connect the information learned from the image data and the text data. Third, the proposed method can effectively handle the information transfer across different modalities (text-image). Fourth, we examined our algorithm on a public dataset, Office-31. It has achieved up to 5\% higher classification accuracy than “non-transfer” algorithms and up to 9\% higher than existing CMTL algorithms.},
  archive  = {J},
  author   = {Shuteng Niu and Yushan Jiang and Bowen Chen and Jian Wang and Yongxin Liu and Houbing Song},
  doi      = {10.1145/3464324},
  journal  = {ACM Transactions on Management Information System},
  number   = {1},
  pages    = {5:1–14},
  title    = {Cross-modality transfer learning for image-text information management},
  volume   = {13},
  year     = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Mining high utility itemsets with hill climbing and
simulated annealing. <em>ACM Transactions on Management Information
System (TMIS)</em>, <em>13</em>(1), 4:1–22. (<a
href="https://doi.org/10.1145/3462636">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {High utility itemset mining (HUIM) is the task of finding all items set, purchased together, that generate a high profit in a transaction database. In the past, several algorithms have been developed to mine high utility itemsets (HUIs). However, most of them cannot properly handle the exponential search space while finding HUIs when the size of the database and total number of items increases. Recently, evolutionary and heuristic algorithms were designed to mine HUIs, which provided considerable performance improvement. However, they can still have a long runtime and some may miss many HUIs. To address this problem, this article proposes two algorithms for HUIM based on Hill Climbing (HUIM-HC) and Simulated Annealing (HUIM-SA). Both algorithms transform the input database into a bitmap for efficient utility computation and for search space pruning. To improve population diversity, HUIs discovered by evolution are used as target values for the next population instead of keeping the current optimal values in the next population. Through experiments on real-life datasets, it was found that the proposed algorithms are faster than state-of-the-art heuristic and evolutionary HUIM algorithms, that HUIM-SA discovers similar HUIs, and that HUIM-SA evolves linearly with the number of iterations.},
  archive  = {J},
  author   = {M. Saqib Nawaz and Philippe Fournier-Viger and Unil Yun and Youxi Wu and Wei Song},
  doi      = {10.1145/3462636},
  journal  = {ACM Transactions on Management Information System},
  number   = {1},
  pages    = {4:1–22},
  title    = {Mining high utility itemsets with hill climbing and simulated annealing},
  volume   = {13},
  year     = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). TRG-DAtt: The target relational graph and double attention
network based sentiment analysis and prediction for supporting decision
making. <em>ACM Transactions on Management Information System
(TMIS)</em>, <em>13</em>(1), 3:1–25. (<a
href="https://doi.org/10.1145/3462442">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {The management of public opinion and the use of big data monitoring to accurately judge and verify all kinds of information are valuable aspects in the enterprise management decision-making process. The sentiment analysis of reviews is a key decision-making tool for e-commerce development. Most existing review sentiment analysis methods involve sequential modeling but do not focus on the semantic relationships. However, Chinese semantics are different from English semantics in terms of the sentence structure. Irrelevant contextual words may be incorrectly identified as cues for sentiment prediction. The influence of the target words in reviews must be considered. Thus, this paper proposes the TRG-DAtt model for sentiment analysis based on target relational graph (TRG) and double attention network (DAtt) to analyze the emotional information to support decision making. First, dependency tree-based TRG is introduced to independently and fully mine the semantic relationships. We redefine and constrain the dependency and use it as the edges to connect the target and context words. Second, we design dependency graph attention network (DGAT) and interactive attention network (IAT) to form the DAtt and obtain the emotional features of the target words and reviews. DGAT models the dependency of the TRG by aggregating the semantic information. Next, the target emotional enhancement features obtained by the DGAT are input to the IAT. The influence of each target word on the review can be obtained through the interaction. Finally, the target emotional enhancement features are weighted by the impact factor to generate the review&#39;s emotional features. In this study, extensive experiments were conducted on the car and Meituan review data sets, which contain consumer reviews on cars and stores, respectively. The results demonstrate that the proposed model outperforms the existing models.},
  archive  = {J},
  author   = {Fan Chen and Jiaoxiong Xia and Honghao Gao and Huahu Xu and Wei Wei},
  doi      = {10.1145/3462442},
  journal  = {ACM Transactions on Management Information System},
  number   = {1},
  pages    = {3:1–25},
  title    = {TRG-DAtt: The target relational graph and double attention network based sentiment analysis and prediction for supporting decision making},
  volume   = {13},
  year     = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). DSSAE: Deep stacked sparse autoencoder analytical model for
COVID-19 diagnosis by fractional fourier entropy. <em>ACM Transactions
on Management Information System (TMIS)</em>, <em>13</em>(1), 2:1–20.
(<a href="https://doi.org/10.1145/3451357">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {( Aim ) COVID-19 has caused more than 2.28 million deaths till 4/Feb/2021 while it is still spreading across the world. This study proposed a novel artificial intelligence model to diagnose COVID-19 based on chest CT images. ( Methods ) First, the two-dimensional fractional Fourier entropy was used to extract features. Second, a custom deep stacked sparse autoencoder (DSSAE) model was created to serve as the classifier. Third, an improved multiple-way data augmentation was proposed to resist overfitting. ( Results ) Our DSSAE model obtains a micro-averaged F1 score of 92.32\% in handling a four-class problem (COVID-19, community-acquired pneumonia, secondary pulmonary tuberculosis, and healthy control). ( Conclusion ) Our method outperforms 10 state-of-the-art approaches.},
  archive  = {J},
  author   = {Shui-Hua Wang and Xin Zhang and Yu-Dong Zhang},
  doi      = {10.1145/3451357},
  journal  = {ACM Transactions on Management Information System},
  number   = {1},
  pages    = {2:1–20},
  title    = {DSSAE: Deep stacked sparse autoencoder analytical model for COVID-19 diagnosis by fractional fourier entropy},
  volume   = {13},
  year     = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Introduction to the special issue on pattern-driven mining,
analytics, and prediction for decision making, part 1. <em>ACM
Transactions on Management Information System (TMIS)</em>,
<em>13</em>(1), 1:1–3. (<a
href="https://doi.org/10.1145/3486960">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive = {J},
  author  = {Lin Jerry Cwei and Nachiketa Sahoo and Gautam Srivastava and Weiping Ding},
  doi     = {10.1145/3486960},
  journal = {ACM Transactions on Management Information System},
  number  = {1},
  pages   = {1:1–3},
  title   = {Introduction to the special issue on pattern-driven mining, analytics, and prediction for decision making, part 1},
  volume  = {13},
  year    = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Machine learning for automated industrial IoT attack
detection: An efficiency-complexity trade-off. <em>ACM Transactions on
Management Information System (TMIS)</em>, <em>12</em>(4), 37:1–28. (<a
href="https://doi.org/10.1145/3460822">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Critical city infrastructures that depend on smart Industrial Internet of Things (IoT) devices have been increasingly becoming a target of cyberterrorist or hacker attacks. Although this has led to multiple studies in the recent past, there exists a paucity of literature concerning real-time Industrial IoT attack detection. The goal of this article is to build a machine-learning approach using Industrial IoT sensor readings for accurately tracking down Industrial IoT attacks in real time. We analyze IoT system behavior under a lab-controlled series of attacks on a Secure Water Treatment (SWaT) system. The system is analytically challenging in that it results in sensor readings that resemble waveforms. To that end, we develop a novel early detection method using functional shape analysis (FSA) to extract features from the data that can capture the profile of the waveform. Our results show an efficiency-complexity trade-off between functional and non-functional methods in predicting IoT attacks.},
  archive  = {J},
  author   = {Saurav Chakraborty and Agnieszka Onuchowska and Sagar Samtani and Wolfgang Jank and Brandon Wolfram},
  doi      = {10.1145/3460822},
  journal  = {ACM Transactions on Management Information System},
  number   = {4},
  pages    = {37:1–28},
  title    = {Machine learning for automated industrial IoT attack detection: An efficiency-complexity trade-off},
  volume   = {12},
  year     = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Design and realisation of scalable business process
management systems for deployment in the cloud. <em>TMIS</em>,
<em>12</em>(4), 36:1–26. (<a
href="https://doi.org/10.1145/3460123">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Business Process Management Systems ( BPMSs ) provide automated support for the execution of business processes in modern organisations. With the emergence of cloud computing, BPMS deployment considerations are shifting from traditional on-premise models to the Software-as-a-Service ( SaaS ) paradigm, aiming at delivering Business Process Automation as a Service. However, scaling up a traditional BPMS to cope with simultaneous demand from multiple organisations in the cloud is challenging, since its underlying system architecture has been designed to serve a single organisation with a single process engine. Moreover, the complexity in addressing both the dynamic execution environment and the elasticity requirements of users impose further challenges to deploying a traditional BPMS in the cloud. A typical SaaS often deploys multiple instances of its core applications and distributes workload to these application instances via load balancing. But, for stateful and often long-running process instances, standard stateless load balancing strategies are inadequate. In this article, we propose a conceptual design of BPMS capable of addressing dynamically varying demands of end users in the cloud, and present a prototypical implementation using an open source traditional BPMS platform. Both the design and system realisation offer focused strategies on achieving scalability and demonstrates the system capabilities for supporting both upscaling, to address large volumes of user demand or workload, and downscaling, to release underutilised computing resources, in a cloud environment.},
  archive      = {J_TMIS},
  author       = {Chun Ouyang and Michael Adams and Arthur H. M. Ter Hofstede and Yang Yu},
  doi          = {10.1145/3460123},
  journal      = {ACM Transactions on Management Information Systems},
  number       = {4},
  pages        = {36:1–26},
  shortjournal = {ACM Trans. Manag. Inf. Sys.},
  title        = {Design and realisation of scalable business process management systems for deployment in the cloud},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). University operations during a pandemic: A flexible decision
analysis toolkit. <em>TMIS</em>, <em>12</em>(4), 35:1–24. (<a
href="https://doi.org/10.1145/3460125">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modeling infection spread during pandemics is not new, with models using past data to tune simulation parameters for predictions. These help in understanding of the healthcare burden posed by a pandemic and responding accordingly. However, the problem of how college/university campuses should function during a pandemic is new for the following reasons: (i) social contact in colleges are structured and can be engineered for chosen objectives; (ii) the last pandemic to cause such societal disruption was more than 100 years ago, when higher education was not a critical part of society; (iii) not much was known about causes of pandemics, and hence effective ways of safe operations were not known; and (iv) today with distance learning, remote operation of an academic institution is possible. As one of the first to address this problem, our approach is unique in presenting a flexible simulation system, containing a suite of model libraries, one for each major component. The system integrates agent-based modeling and the stochastic network approach, and models the interactions among individual entities (e.g., students, instructors, classrooms, residences) in great detail. For each decision to be made, the system can be used to predict the impact of various choices, and thus enables the administrator to make informed decisions. Although current approaches are good for infection modeling, they lack accuracy in social contact modeling. Our agent-based modeling approach, combined with ideas from Network Science, presents a novel approach to contact modeling. A detailed case study of the University of Minnesota’s Sunrise Plan is presented. For each decision made, its impact was assessed, and results were used to get a measure of confidence. We believe that this flexible tool can be a valuable asset for various kinds of organizations to assess their infection risks in pandemic-time operations, including middle and high schools, factories, warehouses, and small/medium-sized businesses.},
  archive      = {J_TMIS},
  author       = {Himanshu Kharkwal and Dakota Olson and Jiali Huang and Abhiraj Mohan and Ankur Mani and Jaideep Srivastava},
  doi          = {10.1145/3460125},
  journal      = {ACM Transactions on Management Information Systems},
  number       = {4},
  pages        = {35:1–24},
  shortjournal = {ACM Trans. Manag. Inf. Sys.},
  title        = {University operations during a pandemic: A flexible decision analysis toolkit},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). COVID-safe spatial occupancy monitoring using OFDM-based
features and passive WiFi samples. <em>TMIS</em>, <em>12</em>(4),
34:1–24. (<a href="https://doi.org/10.1145/3472668">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {During the COVID-19 pandemic, authorities have been asking for social distancing to prevent transmission of the virus. However, enforcing such distancing has been challenging in tight spaces such as elevators and unmonitored commercial settings such as offices. This article addresses this gap by proposing a low-cost and non-intrusive method for monitoring social distancing within a given space, using Channel State Information (CSI) from passive WiFi sensing. By exploiting the frequency selective behavior of CSI with a Support Vector Machine (SVM) classifier, we achieve an improvement in accuracy over existing crowd counting works. Our system counts the number of occupants with a 93\% accuracy rate in an elevator setting and predicts whether the COVID-Safe limit is breached with a 97\% accuracy rate. We also demonstrate the occupant counting capability of the system in a commercial office setting, achieving 97\% accuracy. Our proposed occupancy monitoring outperforms existing methods by at least 7\%. Overall, the proposed framework is inexpensive, requiring only one device that passively collects data and a lightweight supervised learning algorithm for prediction. Our lightweight model and accuracy improvements are necessary contributions for WiFi-based counting to be suitable for COVID-specific applications.},
  archive      = {J_TMIS},
  author       = {Junye Li and Aryan Sharma and Deepak Mishra and Gustavo Batista and Aruna Seneviratne},
  doi          = {10.1145/3472668},
  journal      = {ACM Transactions on Management Information Systems},
  number       = {4},
  pages        = {34:1–24},
  shortjournal = {ACM Trans. Manag. Inf. Sys.},
  title        = {COVID-safe spatial occupancy monitoring using OFDM-based features and passive WiFi samples},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). High-resolution spatio-temporal model for county-level
COVID-19 activity in the u.s. <em>TMIS</em>, <em>12</em>(4), 33:1–20.
(<a href="https://doi.org/10.1145/3468876">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present an interpretable high-resolution spatio-temporal model to estimate COVID-19 deaths together with confirmed cases 1 week ahead of the current time, at the county level and weekly aggregated, in the United States. A notable feature of our spatio-temporal model is that it considers the (1) temporal auto- and pairwise correlation of the two local time series (confirmed cases and deaths from the COVID-19), (2) correlation between locations (propagation between counties), and (3) covariates such as local within-community mobility and social demographic factors. The within-community mobility and demographic factors, such as total population and the proportion of the elderly, are included as important predictors since they are hypothesized to be important in determining the dynamics of COVID-19. To reduce the model’s high dimensionality, we impose sparsity structures as constraints and emphasize the impact of the top 10 metropolitan areas in the nation, which we refer to (and treat within our models) as hubs in spreading the disease. Our retrospective out-of-sample county-level predictions were able to forecast the subsequently observed COVID-19 activity accurately. The proposed multivariate predictive models were designed to be highly interpretable, with clear identification and quantification of the most important factors that determine the dynamics of COVID-19. Ongoing work involves incorporating more covariates, such as education and income, to improve prediction accuracy and model interpretability.},
  archive      = {J_TMIS},
  author       = {Shixiang Zhu and Alexander Bukharin and Liyan Xie and Mauricio Santillana and Shihao Yang and Yao Xie},
  doi          = {10.1145/3468876},
  journal      = {ACM Transactions on Management Information Systems},
  number       = {4},
  pages        = {33:1–20},
  shortjournal = {ACM Trans. Manag. Inf. Sys.},
  title        = {High-resolution spatio-temporal model for county-level COVID-19 activity in the U.S.},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). SymptomID: A framework for rapid symptom identification in
pandemics using news reports. <em>TMIS</em>, <em>12</em>(4), 32:1–17.
(<a href="https://doi.org/10.1145/3462441">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The ability to quickly learn fundamentals about a new infectious disease, such as how it is transmitted, the incubation period, and related symptoms, is crucial in any novel pandemic. For instance, rapid identification of symptoms can enable interventions for dampening the spread of the disease. Traditionally, symptoms are learned from research publications associated with clinical studies. However, clinical studies are often slow and time intensive, and hence delays can have dire consequences in a rapidly spreading pandemic like we have seen with COVID-19. In this article, we introduce SymptomID, a modular artificial intelligence–based framework for rapid identification of symptoms associated with novel pandemics using publicly available news reports. SymptomID is built using the state-of-the-art natural language processing model (Bidirectional Encoder Representations for Transformers) to extract symptoms from publicly available news reports and cluster-related symptoms together to remove redundancy. Our proposed framework requires minimal training data, because it builds on a pre-trained language model. In this study, we present a case study of SymptomID using news articles about the current COVID-19 pandemic. Our COVID-19 symptom extraction module, trained on 225 articles, achieves an F1 score of over 0.8. SymptomID can correctly identify well-established symptoms (e.g., “fever” and “cough”) and less-prevalent symptoms (e.g., “rashes,” “hair loss,” “brain fog”) associated with the novel coronavirus. We believe this framework can be extended and easily adapted in future pandemics to quickly learn relevant insights that are fundamental for understanding and combating a new infectious disease.},
  archive      = {J_TMIS},
  author       = {Kang Gu and Soroush Vosoughi and Temiloluwa Prioleau},
  doi          = {10.1145/3462441},
  journal      = {ACM Transactions on Management Information Systems},
  number       = {4},
  pages        = {32:1–17},
  shortjournal = {ACM Trans. Manag. Inf. Sys.},
  title        = {SymptomID: A framework for rapid symptom identification in pandemics using news reports},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Understanding the impact of COVID-19 on online mental health
forums. <em>TMIS</em>, <em>12</em>(4), 31:1–28. (<a
href="https://doi.org/10.1145/3458770">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Like many of the disasters that have preceded it, the COVID-19 pandemic is likely to have a profound impact on people’s mental health. Understanding its impact can inform strategies for mitigating negative consequences. This work seeks to better understand the impacts of COVID-19 on mental health by examining how discussions on mental health subreddits have changed in the three months following the WHO’s declaration of a global pandemic. First, the rate at which the pandemic is discussed in each community is quantified. Then, volume of activity is measured to determine whether the number of people with mental health concerns has risen, and user interactions are analyzed to determine how they have changed during the pandemic. Finally, the content of the discussions is analyzed. Each of these metrics is considered with respect to a set of control subreddits to better understand if the changes present are specific to mental health subreddits or are representative of Reddit as a whole. There are numerous changes in the three mental health subreddits that we consider, r/Anxiety, r/depression, r/SuicideWatch; there is reduced posting activity in most cases, and there are significant changes in discussion of some topics such as work and anxiety. The results suggest that there is not an overwhelming increase in online mental health support-seeking on Reddit during the pandemic, but that discussion content related to mental health has changed.},
  archive      = {J_TMIS},
  author       = {Laura Biester and Katie Matton and Janarthanan Rajendran and Emily Mower Provost and Rada Mihalcea},
  doi          = {10.1145/3458770},
  journal      = {ACM Transactions on Management Information Systems},
  number       = {4},
  pages        = {31:1–28},
  shortjournal = {ACM Trans. Manag. Inf. Sys.},
  title        = {Understanding the impact of COVID-19 on online mental health forums},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Using social media to analyze public concerns and policy
responses to COVID-19 in hong kong. <em>TMIS</em>, <em>12</em>(4),
30:1–20. (<a href="https://doi.org/10.1145/3460124">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The outbreak of COVID-19 has caused huge economic and societal disruptions. To fight against the coronavirus, it is critical for policymakers to take swift and effective actions. In this article, we take Hong Kong as a case study, aiming to leverage social media data to support policymakers’ policy-making activities in different phases. First, in the agenda setting phase, we facilitate policymakers to identify key issues to be addressed during COVID-19. In particular, we design a novel epidemic awareness index to continuously monitor public discussion hotness of COVID-19 based on large-scale data collected from social media platforms. Then we identify the key issues by analyzing the posts and comments of the extensively discussed topics. Second, in the policy evaluation phase, we enable policymakers to conduct real-time evaluation of anti-epidemic policies. Specifically, we develop an accurate Cantonese sentiment classification model to measure the public satisfaction with anti-epidemic policies and propose a keyphrase extraction technique to further extract public opinions. To the best of our knowledge, this is the first work which conducts a large-scale social media analysis of COVID-19 in Hong Kong. The analytical results reveal some interesting findings: (1) there is a very low correlation between the number of confirmed cases and the public discussion hotness of COVID-19. The major public concern in the early stage is the shortage of anti-epidemic items. (2) The top-3 anti-epidemic measures with the greatest public satisfaction are daily press conference on COVID-19 updates, border closure, and social distancing rules.},
  archive      = {J_TMIS},
  author       = {Guanqing Liang and Jingxin Zhao and Helena Yan Ping Lau and Cane Wing-Ki Leung},
  doi          = {10.1145/3460124},
  journal      = {ACM Transactions on Management Information Systems},
  number       = {4},
  pages        = {30:1–20},
  shortjournal = {ACM Trans. Manag. Inf. Sys.},
  title        = {Using social media to analyze public concerns and policy responses to COVID-19 in hong kong},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). AIDCOV: An interpretable artificial intelligence model for
detection of COVID-19 from chest radiography images. <em>ACM
Transactions on Management Information System (TMIS)</em>,
<em>12</em>(4), 29:1–20. (<a
href="https://doi.org/10.1145/3466690">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {As the Coronavirus Disease 2019 (COVID-19) pandemic continues to grow globally, testing to detect COVID-19 and isolating individuals who test positive remains the primary strategy for preventing community spread of the disease. Therefore, automatic and accurate detection of COVID-19 using medical imaging modalities, which are more widely available and accessible, can be beneficial as an alternative diagnostic tool. In this study, an Artificial Intelligence model for Detection of COVID-19 (AIDCOV) is developed to classify chest radiography images as belonging to a person with either COVID-19, other infections, or no pneumonia (i.e., normal). The hierarchical structure in AIDCOV captures the dependencies among features and improves model performance while an attention mechanism makes the model interpretable and transparent. We used several publicly available datasets of both computed tomography (CT) and X-ray modalities. The main public dataset for chest X-ray images contains 475 COVID-19 samples, 3949 samples from other viral/bacterial infections, and 1583 normal samples. Our model achieves a mean cross-validation accuracy of 98.4\%. AIDCOV has a sensitivity of 99.8\%, a specificity of 100\%, and an F1-score of 99.8\% in detecting COVID-19 from X-ray images on that dataset. Using a large dataset of CT images, our model obtained mean cross-validation accuracy and sensitivity of 98.8\% and 99.4\%, respectively. Additionally, our interpretable model can distinguish subtle signs of infection within each radiography image. Assuming these results hold up in larger datasets obtained from a variety of patients over the world, AIDCOV can be used in conjunction with or instead of RT-PCR testing (where RT-PCR testing is unavailable) to detect and isolate individuals with COVID-19, prevent onward transmission to the general population and healthcare workers, and highlight the areas in the lungs that show signs of COVID-related damage.},
  archive  = {J},
  author   = {Maryam Zokaeinikoo and Pooyan Kazemian and Prasenjit Mitra and Soundar Kumara},
  doi      = {10.1145/3466690},
  journal  = {ACM Transactions on Management Information System},
  number   = {4},
  pages    = {29:1–20},
  title    = {AIDCOV: An interpretable artificial intelligence model for detection of COVID-19 from chest radiography images},
  volume   = {12},
  year     = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). CoRSAI: A system for robust interpretation of CT scans of
COVID-19 patients using deep learning. <em>TMIS</em>, <em>12</em>(4),
28:1–16. (<a href="https://doi.org/10.1145/3467471">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Analysis of chest CT scans can be used in detecting parts of lungs that are affected by infectious diseases such as COVID-19. Determining the volume of lungs affected by lesions is essential for formulating treatment recommendations and prioritizing patients by severity of the disease. In this article we adopted an approach based on using an ensemble of deep convolutional neural networks for segmentation of slices of lung CT scans. Using our models, we are able to segment the lesions, evaluate patients’ dynamics, estimate relative volume of lungs affected by lesions, and evaluate the lung damage stage. Our models were trained on data from different medical centers. We compared predictions of our models with those of six experienced radiologists, and our segmentation model outperformed most of them. On the task of classification of disease severity, our model outperformed all the radiologists.},
  archive      = {J_TMIS},
  author       = {Manvel Avetisian and Ilya Burenko and Konstantin Egorov and Vladimir Kokh and Aleksandr Nesterov and Aleksandr Nikolaev and Alexander Ponomarchuk and Elena Sokolova and Alex Tuzhilin and Dmitry Umerenkov},
  doi          = {10.1145/3467471},
  journal      = {ACM Transactions on Management Information Systems},
  number       = {4},
  pages        = {28:1–16},
  shortjournal = {ACM Trans. Manag. Inf. Sys.},
  title        = {CoRSAI: A system for robust interpretation of CT scans of COVID-19 patients using deep learning},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Introduction to the special section on using AI and data
science to handle pandemics and related disruptions. <em>ACM
Transactions on Management Information System (TMIS)</em>,
<em>12</em>(4), 27:1–2. (<a
href="https://doi.org/10.1145/3486969">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {No abstract available.},
  archive  = {J},
  author   = {Kang Zhao and Qingpeng Zhang and Sean H. Y. Yuan and Kelvin Kam-Fai Tsoi},
  doi      = {10.1145/3486969},
  journal  = {ACM Transactions on Management Information System},
  number   = {4},
  pages    = {27:1–2},
  title    = {Introduction to the special section on using AI and data science to handle pandemics and related disruptions},
  volume   = {12},
  year     = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Anonymous blockchain-based system for consortium.
<em>TMIS</em>, <em>12</em>(3), 26:1–25. (<a
href="https://doi.org/10.1145/3459087">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Blockchain records transactions with various protection techniques against tampering. To meet the requirements on cooperation and anonymity of companies and organizations, researchers have developed a few solutions. Ring signature-based schemes allow multiple participants cooperatively to manage while preserving their individuals’ privacy. However, the solutions cannot work properly due to the increased computing complexity along with the expanded group size. In this article, we propose a Multi-center Anonymous Blockchain-based (MAB) system, with joint management for the consortium and privacy protection for the participants. To achieve that, we formalize the syntax used by the MAB system and present a general construction based on a modular design. By applying cryptographic primitives to each module, we instantiate our scheme with anonymity and decentralization. Furthermore, we carry out a comprehensive formal analysis of our exemplified scheme. A proof of concept simulation is provided to show the feasibility. The results demonstrate security and efficiency from both theoretical perspectives and practical perspectives.},
  archive      = {J_TMIS},
  author       = {Qin Wang and Shiping Chen and Yang Xiang},
  doi          = {10.1145/3459087},
  journal      = {ACM Transactions on Management Information Systems},
  number       = {3},
  pages        = {26:1–25},
  shortjournal = {ACM Trans. Manag. Inf. Sys.},
  title        = {Anonymous blockchain-based system for consortium},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An efficient deep learning paradigm for deceit
identification test on EEG signals. <em>TMIS</em>, <em>12</em>(3),
25:1–20. (<a href="https://doi.org/10.1145/3458791">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Brain-Computer Interface is the collaboration of the human brain and a device that controls the actions of a human using brain signals. Applications of brain-computer interface vary from the field of entertainment to medical. In this article, a novel Deceit Identification Test is proposed based on the Electroencephalogram signals to identify and analyze the human behavior. Deceit identification test is based on P300 signals, which have a positive peak from 300 ms to 1,000 ms of the stimulus onset. The aim of the experiment is to identify and classify P300 signals with good classification accuracy. For preprocessing, a band-pass filter is used to eliminate the artifacts. The feature extraction is carried out using “symlet” Wavelet Packet Transform (WPT). Deep Neural Network (DNN) with two autoencoders having 10 hidden layers each is applied as the classifier. A novel experiment is conducted for the collection of EEG data from the subjects. EEG signals of 30 subjects (15 guilty and 15 innocent) are recorded and analyzed during the experiment. BrainVision recorder and analyzer are used for recording and analyzing EEG signals. The model is trained for 90\% of the dataset and tested for 10\% of the dataset and accuracy of 95\% is obtained.},
  archive      = {J_TMIS},
  author       = {Damodar Reddy Edla and Shubham Dodia and Annushree Bablani and Venkatanareshbabu Kuppili},
  doi          = {10.1145/3458791},
  journal      = {ACM Transactions on Management Information Systems},
  number       = {3},
  pages        = {25:1–20},
  shortjournal = {ACM Trans. Manag. Inf. Sys.},
  title        = {An efficient deep learning paradigm for deceit identification test on EEG signals},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Write like a pro or an amateur? Effect of medical language
formality. <em>TMIS</em>, <em>12</em>(3), 24:1–25. (<a
href="https://doi.org/10.1145/3458752">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Past years have seen rising engagement among caregivers in online health communities. Although studies indicate that this caregiver-generated online health information benefits patients, how such information can be perceived easily and correctly remains unclear. This study aims to fill this gap by exploring mechanisms to improve the perceived helpfulness of online health information. We propose a multi-method framework, including a novel Medical-Enriched DEep Learning (MEDEL) feature extraction method, econometric analyses, and a randomized experiment. The results show that when the medical language of health information is informal, the senior care information is more helpful. Our findings provide a theoretical foundation to understand the influence of language formality on many other business communications. Our proposed multi-method approach can also be generalized to investigate research questions involving complex textual features. Forum sites could leverage our proposed approach to improve the helpfulness of online health information and user satisfaction.},
  archive      = {J_TMIS},
  author       = {Jiaheng Xie and Bin Zhang and Susan Brown and Daniel Zeng},
  doi          = {10.1145/3458752},
  journal      = {ACM Transactions on Management Information Systems},
  number       = {3},
  pages        = {24:1–25},
  shortjournal = {ACM Trans. Manag. Inf. Sys.},
  title        = {Write like a pro or an amateur? effect of medical language formality},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Anonymization of daily activity data by using ℓ-diversity
privacy model. <em>TMIS</em>, <em>12</em>(3), 23:1–21. (<a
href="https://doi.org/10.1145/3456876">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the age of IoT, collection of activity data has become ubiquitous. Publishing activity data can be quite useful for various purposes such as estimating the level of assistance required by older adults and facilitating early diagnosis and treatment of certain diseases. However, publishing activity data comes with privacy risks: Each dimension, i.e., the activity of a person at any given point in time can be used to identify a person as well as to reveal sensitive information about the person such as not being at home at that time. Unfortunately, conventional anonymization methods have shortcomings when it comes to anonymizing activity data. Activity datasets considered for publication are often flat with many dimensions but typically not many rows, which makes the existing anonymization techniques either inapplicable due to very few rows, or else either inefficient or ineffective in preserving utility. This article proposes novel multi-level clustering-based approaches using a non-metric weighted distance measure that enforce ℓ-diversity model. Experimental results show that the proposed methods preserve data utility and are orders more efficient than the existing methods.},
  archive      = {J_TMIS},
  author       = {Pooja Parameshwarappa and Zhiyuan Chen and Güneş Koru},
  doi          = {10.1145/3456876},
  journal      = {ACM Transactions on Management Information Systems},
  number       = {3},
  pages        = {23:1–21},
  shortjournal = {ACM Trans. Manag. Inf. Sys.},
  title        = {Anonymization of daily activity data by using ℓ-diversity privacy model},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Early exploration of MOOCs in the u.s. Higher education: An
absorptive capacity perspective. <em>TMIS</em>, <em>12</em>(3), 22:1–28.
(<a href="https://doi.org/10.1145/3456295">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Advanced information technologies have enabled Massive Open Online Courses (MOOCs) , which have the potential to transform higher education around the world. Why are some institutions eager to embrace this technology-enabled model of teaching, while others remain reluctant to jump aboard? Applying the theory of absorptive capacity, we study the role of a university&#39;s educational IT capabilities in becoming an early MOOC producer. Examining the history of MOOC offerings by U.S. colleges and universities, we find that prior IT capabilities, such as (1) the use of Web 2.0, social media and other interactive tools for teaching and (2) experience with distance education and hybrid teaching, are positively associated with the early exploration of MOOCs. Interestingly, we also find that the effect of educational IT capabilities is moderated by social integration mechanisms and activation triggers. For example, when instructional IT supporting services are highly decentralized, educational IT capabilities have a greater impact on the probability of a university offering a MOOC. In addition, for colleges facing an adverse environment, such as those experience a decline in college applications, the effect of IT capabilities on the exploration of MOOCs is much stronger.},
  archive      = {J_TMIS},
  author       = {Peng Huang and Henry C. Lucas},
  doi          = {10.1145/3456295},
  journal      = {ACM Transactions on Management Information Systems},
  number       = {3},
  pages        = {22:1–28},
  shortjournal = {ACM Trans. Manag. Inf. Sys.},
  title        = {Early exploration of MOOCs in the U.S. higher education: An absorptive capacity perspective},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Graph convolutional network-based model for incident-related
congestion prediction: A case study of shanghai expressways.
<em>TMIS</em>, <em>12</em>(3), 21:1–22. (<a
href="https://doi.org/10.1145/3451356">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traffic congestion has become a significant obstacle to the development of mega cities in China. Although local governments have used many resources in constructing road infrastructure, it is still insufficient for the increasing traffic demands. As a first step toward optimizing real-time traffic control, this study uses Shanghai Expressways as a case study to predict incident-related congestions. Our study proposes a graph convolutional network-based model to identify correlations in multi-dimensional sensor-detected data, while simultaneously taking into account environmental, spatiotemporal, and network features in predicting traffic conditions immediately after a traffic incident. The average accuracy, average AUC, and average F-1 score of the predictive model are 92.78\%, 95.98\%, and 88.78\%, respectively, on small-scale ground-truth data. Furthermore, we improve the predictive model’s performance using semi-supervised learning by including more unlabeled data instances. As a result, the accuracy, AUC, and F-1 score of the model increase by 2.69\%, 1.25\%, and 4.72\%, respectively. The findings of this article have important implications that can be used to improve the management and development of Expressways in Shanghai, as well as other metropolitan areas in China.},
  archive      = {J_TMIS},
  author       = {Xi Wang and Yibo Chai and Hui Li and Wenbin Wang and Weishan Sun},
  doi          = {10.1145/3451356},
  journal      = {ACM Transactions on Management Information Systems},
  number       = {3},
  pages        = {21:1–22},
  shortjournal = {ACM Trans. Manag. Inf. Sys.},
  title        = {Graph convolutional network-based model for incident-related congestion prediction: A case study of shanghai expressways},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Leveraging individual and collective regularity to profile
and segment user locations from mobile phone data. <em>TMIS</em>,
<em>12</em>(3), 20:1–22. (<a
href="https://doi.org/10.1145/3449042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The dynamic monitoring of home and workplace distribution is a fundamental building block for improving location-based service systems in fast-developing cities worldwide. Inferring these places is challenging; existing approaches rely on labor-intensive and untimely survey data or ad hoc heuristic assignment rules based on the frequency of appearance at given locations. Motivated by the regularities in human behavior, we propose a novel method to infer the home, workplace, and third place based on an individual’s spatial-temporal patterns inferred from Call Detail Records. To capture the individual regularity, our method develops, for each person-location, the probability distribution that the person will appear in that location at a specific time of day using geo-temporal travel patterns a panel of individuals. To reveal the collective regularity, we apply eigen-decomposition to the matrix of historical geo-temporal data. Unsupervised machine learning techniques are then used to extract commonalities across locations for different groups of travelers, making inferences, such as home and workplace. Testing the methodology on real-world data with known location labels shows that our method identifies home and workplace with significant accuracy, improving upon the best practices in the literature by 79\% and 34\%, respectively. The methodology proposed is computationally efficient and is highly scalable to other real-world applications with historical tracking data. It provides a basis to improve location-based services, such as mobile commerce, social events recommendations, and urban transit design.},
  archive      = {J_TMIS},
  author       = {Yan Leng and Jinhua Zhao and Haris Koutsopoulos},
  doi          = {10.1145/3449042},
  journal      = {ACM Transactions on Management Information Systems},
  number       = {3},
  pages        = {20:1–22},
  shortjournal = {ACM Trans. Manag. Inf. Sys.},
  title        = {Leveraging individual and collective regularity to profile and segment user locations from mobile phone data},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-disease predictive analytics: A clinical
knowledge-aware approach. <em>TMIS</em>, <em>12</em>(3), 19:1–34. (<a
href="https://doi.org/10.1145/3447942">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-Disease Predictive Analytics (MDPA) models simultaneously predict the risks of multiple diseases in patients and are valuable in early diagnoses. Patients tend to have multiple diseases simultaneously or develop multiple complications over time, and MDPA models can learn and effectively utilize such correlations between diseases. Data from large-scale Electronic Health Records (EHR) can be used through Multi-Label Learning (MLL) methods to develop MDPA models. However, data-driven approaches for MDPA face the challenge of data imbalance, because rare diseases tend to have much less data than common diseases. Insufficient data for rare diseases makes it difficult to leverage correlations with other diseases. These correlations are studied and recorded in biomedical literature but are rarely utilized in predictive analytics. This article presents a novel method called Knowledge-Aware Approach (KAA) that learns clinical correlations from the rapidly growing body of clinical knowledge. KAA can be combined with any data-driven MLL model for MDPA to refine the predictions of the model. Our extensive experiments, on real EHR data, show that the use of KAA improves the predictive performance of commonly used MDPA models, particularly for rare diseases. KAA is also found to be superior to existing general approaches of combining clinical knowledge with data-driven models. Further, a counterfactual analysis shows the efficacy of KAA in improving physicians’ ability to prescribe preventive treatments.},
  archive      = {J_TMIS},
  author       = {Lin Qiu and Sruthi Gorantla and Vaibhav Rajan and Bernard C. Y. Tan},
  doi          = {10.1145/3447942},
  journal      = {ACM Transactions on Management Information Systems},
  number       = {3},
  pages        = {19:1–34},
  shortjournal = {ACM Trans. Manag. Inf. Sys.},
  title        = {Multi-disease predictive analytics: A clinical knowledge-aware approach},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Automated feature selection for anomaly detection in network
traffic data. <em>TMIS</em>, <em>12</em>(3), 18:1–28. (<a
href="https://doi.org/10.1145/3446636">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Variable selection (also known as feature selection ) is essential to optimize the learning complexity by prioritizing features, particularly for a massive, high-dimensional dataset like network traffic data. In reality, however, it is not an easy task to effectively perform the feature selection despite the availability of the existing selection techniques. From our initial experiments, we observed that the existing selection techniques produce different sets of features even under the same condition (e.g., a static size for the resulted set). In addition, individual selection techniques perform inconsistently, sometimes showing better performance but sometimes worse than others, thereby simply relying on one of them would be risky for building models using the selected features. More critically, it is demanding to automate the selection process, since it requires laborious efforts with intensive analysis by a group of experts otherwise. In this article, we explore challenges in the automated feature selection with the application of network anomaly detection. We first present our ensemble approach that benefits from the existing feature selection techniques by incorporating them, and one of the proposed ensemble techniques based on greedy search works highly consistently showing comparable results to the existing techniques. We also address the problem of when to stop to finalize the feature elimination process and present a set of methods designed to determine the number of features for the reduced feature set. Our experimental results conducted with two recent network datasets show that the identified feature sets by the presented ensemble and stopping methods consistently yield comparable performance with a smaller number of features to conventional selection techniques.},
  archive      = {J_TMIS},
  author       = {Makiya Nakashima and Alex Sim and Youngsoo Kim and Jonghyun Kim and Jinoh Kim},
  doi          = {10.1145/3446636},
  journal      = {ACM Transactions on Management Information Systems},
  number       = {3},
  pages        = {18:1–28},
  shortjournal = {ACM Trans. Manag. Inf. Sys.},
  title        = {Automated feature selection for anomaly detection in network traffic data},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Will catastrophic cyber-risk aggregation thrive in the IoT
age? A cautionary economics tale for (re-)insurers and likes.
<em>TMIS</em>, <em>12</em>(2), 17:1–36. (<a
href="https://doi.org/10.1145/3446635">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Service liability interconnections among networked IT and IoT-driven service organizations create potential channels for cascading service disruptions due to modern cybercrimes such as DDoS, APT, and ransomware attacks. These attacks are known to inflict cascading catastrophic service disruptions worth billions of dollars across organizations and critical infrastructure around the globe. Cyber-insurance is a risk management mechanism that is gaining increasing industry popularity to cover client (organization) risks after a cyber-attack. However, there is a certain likelihood that the nature of a successful attack is of such magnitude that an organizational client’s insurance provider is not able to cover the multi-party aggregate losses incurred upon itself by its clients and their descendants in the supply chain, thereby needing to re-insure itself via other cyber-insurance firms. To this end, one question worth investigating in the first place is whether an ecosystem comprising a set of profit-minded cyber-insurance companies, each capable of providing re-insurance services for a service-networked IT environment, is economically feasible to cover the aggregate cyber-losses arising due to a cyber-attack. Our study focuses on an empirically interesting case of extreme heavy tailed cyber-risk distributions that might be presenting themselves to cyber-insurance firms in the modern Internet age in the form of catastrophic service disruptions, and could be a possible standard risk distribution to deal with in the near IoT age. Surprisingly, as a negative result for society in the event of such catastrophes, we prove via a game-theoretic analysis that it may not be economically incentive compatible , even under i.i.d. statistical conditions on catastrophic cyber-risk distributions, for limited liability-taking risk-averse cyber-insurance companies to offer cyber re-insurance solutions despite the existence of large enough market capacity to achieve full cyber-risk sharing. However, our analysis theoretically endorses the popular opinion that spreading i.i.d. cyber-risks that are not catastrophic is an effective practice for aggregate cyber-risk managers, a result established theoretically and empirically in the past. A failure to achieve a working re-insurance market in critically demanding situations after catastrophic cyber-risk events strongly calls for centralized government regulatory action/intervention to promote risk sharing through re-insurance activities for the benefit of service-networked societies in the IoT age.},
  archive      = {J_TMIS},
  author       = {Ranjan Pal and Ziyuan Huang and Sergey Lototsky and Xinlong Yin and Mingyan Liu and Jon Crowcroft and Nishanth Sastry and Swades De and Bodhibrata Nag},
  doi          = {10.1145/3446635},
  journal      = {ACM Transactions on Management Information Systems},
  number       = {2},
  pages        = {17:1–36},
  shortjournal = {ACM Trans. Manag. Inf. Sys.},
  title        = {Will catastrophic cyber-risk aggregation thrive in the IoT age? a cautionary economics tale for (Re-)Insurers and likes},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Exploiting network fusion for organizational turnover
prediction. <em>TMIS</em>, <em>12</em>(2), 16:1–18. (<a
href="https://doi.org/10.1145/3439770">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As an emerging measure of proactive talent management, talent turnover prediction is critically important for companies to attract, engage, and retain talents in order to prevent the loss of intellectual capital. While tremendous efforts have been made in this direction, it is not clear how to model the influence of employees’ turnover within multiple organizational social networks. In this article, we study how to exploit turnover contagion by developing a Turnover Influence-based Neural Network (TINN) for enhancing organizational turnover prediction. Specifically, TINN can construct the turnover similarity network which is then fused with multiple organizational social networks. The fusion is achieved either through learning a hidden turnover influence network or through integrating the turnover influence on multiple networks. Taking advantage of the Graph Convolutional Network and the Long Short-Term Memory network, TINN can dynamically model the impact of social influence on talent turnover. Meanwhile, the utilization of the attention mechanism improves the interpretability, providing insights into the impact of different networks along time on the future turnovers. Finally, we conduct extensive experiments in real-world settings to evaluate TINN. The results validate the effectiveness of our approach to enhancing organizational turnover prediction. Also, our case studies reveal some interpretable findings, such as the importance of each network or hidden state which potentially impacts future organizational turnovers.},
  archive      = {J_TMIS},
  author       = {Mingfei Teng and Hengshu Zhu and Chuanren Liu and Hui Xiong},
  doi          = {10.1145/3439770},
  journal      = {ACM Transactions on Management Information Systems},
  number       = {2},
  pages        = {16:1–18},
  shortjournal = {ACM Trans. Manag. Inf. Sys.},
  title        = {Exploiting network fusion for organizational turnover prediction},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Exploring decomposition for solving pattern mining problems.
<em>TMIS</em>, <em>12</em>(2), 15:1–36. (<a
href="https://doi.org/10.1145/3439771">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article introduces a highly efficient pattern mining technique called Clustering-based Pattern Mining (CBPM). This technique discovers relevant patterns by studying the correlation between transactions in the transaction database based on clustering techniques. The set of transactions is first clustered, such that highly correlated transactions are grouped together. Next, we derive the relevant patterns by applying a pattern mining algorithm to each cluster. We present two different pattern mining algorithms, one applying an approximation-based strategy and another based on an exact strategy. The approximation-based strategy takes into account only the clusters, whereas the exact strategy takes into account both clusters and shared items between clusters. To boost the performance of the CBPM, a GPU-based implementation is investigated. To evaluate the CBPM framework, we perform extensive experiments on several pattern mining problems. The results from the experimental evaluation show that the CBPM provides a reduction in both the runtime and memory usage. Also, CBPM based on the approximate strategy provides good accuracy, demonstrating its effectiveness and feasibility. Our GPU implementation achieves significant speedup of up to 552× on a single GPU using big transaction databases.},
  archive      = {J_TMIS},
  author       = {Youcef Djenouri and Jerry Chun-Wei Lin and Kjetil Nørvåg and Heri Ramampiaro and Philip S. Yu},
  doi          = {10.1145/3439771},
  journal      = {ACM Transactions on Management Information Systems},
  number       = {2},
  pages        = {15:1–36},
  shortjournal = {ACM Trans. Manag. Inf. Sys.},
  title        = {Exploring decomposition for solving pattern mining problems},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Optimizing ontology alignment through an interactive compact
genetic algorithm. <em>TMIS</em>, <em>12</em>(2), 14:1–17. (<a
href="https://doi.org/10.1145/3439772">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ontology provides a shared vocabulary of a domain by formally representing the meaning of its concepts, the properties they possess, and the relations among them, which is the state-of-the-art knowledge modeling technique. However, the ontologies in the same domain could differ in conceptual modeling and granularity level, which yields the ontology heterogeneity problem. To enable data and knowledge transfer, share, and reuse between two intelligent systems, it is important to bridge the semantic gap between the ontologies through the ontology matching technique. To optimize the ontology alignment’s quality, this article proposes an Interactive Compact Genetic Algorithm (ICGA)-based ontology matching technique, which consists of an automatic ontology matching process based on a Compact Genetic Algorithm (CGA) and a collaborative user validating process based on an argumentation framework. First, CGA is used to automatically match the ontologies, and when it gets stuck in the local optima, the collaborative validation based on the multi-relationship argumentation framework is activated to help CGA jump out of the local optima. In addition, we construct a discrete optimization model to define the ontology matching problem and propose a hybrid similarity measure to calculate two concepts’ similarity value. In the experiment, we test the performance of ICGA with the Ontology Alignment Evaluation Initiative’s interactive track, and the experimental results show that ICGA can effectively determine the ontology alignments with high quality.},
  archive      = {J_TMIS},
  author       = {Xingsi Xue and Xiaojing Wu and Junfeng Chen},
  doi          = {10.1145/3439772},
  journal      = {ACM Transactions on Management Information Systems},
  number       = {2},
  pages        = {14:1–17},
  shortjournal = {ACM Trans. Manag. Inf. Sys.},
  title        = {Optimizing ontology alignment through an interactive compact genetic algorithm},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Using word embeddings to deter intellectual property theft
through automated generation of fake documents. <em>TMIS</em>,
<em>12</em>(2), 13:1–22. (<a
href="https://doi.org/10.1145/3418289">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Theft of intellectual property is a growing problem—one that is exacerbated by the fact that a successful compromise of an enterprise might only become known months after the hack. A recent solution called FORGE addresses this problem by automatically generating N “fake” versions of any real document so that the attacker has to determine which of the N + 1 documents that they have exfiltrated from a compromised network is real. In this article, we remove two major drawbacks in FORGE: (i) FORGE requires ontologies in order to generate fake documents—however, in the real world, ontologies, especially good ontologies, are infrequently available. The WE-FORGE system proposed in this article completely eliminates the need for ontologies by using distance metrics on word embeddings instead. (ii) FORGE generates fake documents by first identifying “target” concepts in the original document and then substituting “replacement” concepts for them. However, we will show that this can lead to sub-optimal results (e.g., as target concepts are selected without knowing the availability and/or quality of the replacement concepts, they can sometimes lead to poor results). Our WE-FORGE system addresses this problem in two possible ways by performing a joint optimization to select concepts and replacements simultaneously. We conduct a human study involving both computer science and chemistry documents and show that WE-FORGE successfully deceives adversaries.},
  archive      = {J_TMIS},
  author       = {Almas Abdibayev and Dongkai Chen and Haipeng Chen and Deepti Poluru and V. S. Subrahmanian},
  doi          = {10.1145/3418289},
  journal      = {ACM Transactions on Management Information Systems},
  number       = {2},
  pages        = {13:1–22},
  shortjournal = {ACM Trans. Manag. Inf. Sys.},
  title        = {Using word embeddings to deter intellectual property theft through automated generation of fake documents},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Machine learning for identifying group trajectory outliers.
<em>TMIS</em>, <em>12</em>(2), 12:1–25. (<a
href="https://doi.org/10.1145/3430195">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Prior works on the trajectory outlier detection problem solely consider individual outliers. However, in real-world scenarios, trajectory outliers can often appear in groups, e.g., a group of bikes that deviates to the usual trajectory due to the maintenance of streets in the context of intelligent transportation. The current paper considers the Group Trajectory Outlier (GTO) problem and proposes three algorithms. The first and the second algorithms are extensions of the well-known DBSCAN and k NN algorithms, while the third one models the GTO problem as a feature selection problem. Furthermore, two different enhancements for the proposed algorithms are proposed. The first one is based on ensemble learning and computational intelligence, which allows for merging algorithms’ outputs to possibly improve the final result. The second is a general high-performance computing framework that deals with big trajectory databases, which we used for a GPU-based implementation. Experimental results on different real trajectory databases show the scalability of the proposed approaches.},
  archive      = {J_TMIS},
  author       = {Asma Belhadi and Youcef Djenouri and Djamel Djenouri and Tomasz Michalak and Jerry Chun-Wei Lin},
  doi          = {10.1145/3430195},
  journal      = {ACM Transactions on Management Information Systems},
  number       = {2},
  pages        = {12:1–25},
  shortjournal = {ACM Trans. Manag. Inf. Sys.},
  title        = {Machine learning for identifying group trajectory outliers},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Assessing the moderating effect of security technologies on
employees compliance with cybersecurity control procedures.
<em>TMIS</em>, <em>12</em>(2), 11:1–29. (<a
href="https://doi.org/10.1145/3424282">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increase in cybersecurity threats and the challenges for organisations to protect their information technology assets has made adherence to organisational security control processes and procedures a critical issue that needs to be adequately addressed. Drawing insight from organisational theory literature, we develop a multi-theory model, combining the elements of the theory of planned behaviour, competing value framework, and technology—organisational and environmental theory to examine how the organisational mechanisms interact with espoused cultural values and employee cognitive belief to influence cybersecurity control procedures. Using a structured questionnaire, we deployed structural equation modelling (SEM) to analyse the survey data obtained from public sector information technology organisations in Nigeria to test the hypothesis on the relationship of socio-organisational mechanisms and techno-cultural factors with other key determinants of employee security behaviour. The results showed that knowledge of cybersecurity and employee cognitive belief significantly influence the employees’ intentions to comply with organisational cybersecurity control mechanisms. The research further noted that the influence of organisational elements such as leadership on employee security behaviour is mediated by espoused cultural values while the impact of employee cognitive belief is moderated by security technologies. For effective cybersecurity compliance, leaders and policymakers are therefore to promote organisational security initiatives that ensure incorporation of cybersecurity principles and practices into job descriptions, routines, and processes. This study contributes to behavioural security research by highlighting the critical role of leadership and cultural values in fostering organisational adherence to prescribed security control mechanisms.},
  archive      = {J_TMIS},
  author       = {Aristotle Onumo and Irfan Ullah-Awan and Andrea Cullen},
  doi          = {10.1145/3424282},
  journal      = {ACM Transactions on Management Information Systems},
  number       = {2},
  pages        = {11:1–29},
  shortjournal = {ACM Trans. Manag. Inf. Sys.},
  title        = {Assessing the moderating effect of security technologies on employees compliance with cybersecurity control procedures},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A latent space modeling approach to interfirm relationship
analysis. <em>TMIS</em>, <em>12</em>(2), 10:1–44. (<a
href="https://doi.org/10.1145/3424240">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Interfirm relationships are crucial to our understanding of firms’ collective and interactive behavior. Many information systems-related phenomena, including the diffusion of innovations, standard alliances, technology collaboration, and outsourcing, involve a multitude of relationships between firms. This study proposes a latent space approach to model temporal change in a dual-view interfirm network. We assume that interfirm relationships depend on an underlying latent space; firms that are close to each other in the latent space are more likely to develop a relationship. We construct the latent space by embedding two dynamic networks of firms in an integrated manner, resulting in a more comprehensive view of an interfirm relationship. We validate our approach by introducing three business measures derived from the latent space model to study alliance formation and stock comovement. We illustrate how the trajectories of firms provide insights into alliance activities. We also show that our proposed measures have strong predictive power on stock comovement. We believe the proposed approach enriches the methodology toolbox of IS researchers in studying interfirm relationships.},
  archive      = {J_TMIS},
  author       = {Ka Chung Ng and Mike K. P. So and Kar Yan Tam},
  doi          = {10.1145/3424240},
  journal      = {ACM Transactions on Management Information Systems},
  number       = {2},
  pages        = {10:1–44},
  shortjournal = {ACM Trans. Manag. Inf. Sys.},
  title        = {A latent space modeling approach to interfirm relationship analysis},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Optimal employee recruitment in organizations under
attribute-based access control. <em>TMIS</em>, <em>12</em>(1), 6:1–24.
(<a href="https://doi.org/10.1145/3403950">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For any successful business endeavor, recruitment of a required number of appropriately qualified employees in proper positions is a key requirement. For effective utilization of human resources, reorganization of such workforce assignment is also a task of utmost importance. This includes situations when the under-performing employees have to be substituted with fresh applicants. Generally, the number of candidates applying for a position is large, and hence, the task of identifying an optimal subset becomes critical. Moreover, a human resource manager would also like to make use of the opportunity of retirement of employees to improve manpower utilization. However, the constraints enforced by the security policies prohibit any arbitrary assignment of tasks to employees. Further, the new employees should have the capabilities required to handle the assigned tasks. In this article, we formalize this problem as the Optimal Recruitment Problem (ORP), wherein the goal is to select the minimum number of fresh employees from a set of candidates to fill the vacant positions created by the outgoing employees, while ensuring satisfiability of the specified security conditions. The model used for specification of authorization policies and constraints is Attribute-Based Access Control (ABAC), since it is considered to be the de facto next-generation framework for handling organizational security policies. We show that the ORP problem is NP-hard and propose a greedy heuristic for solving it. Extensive experimental evaluation shows both the effectiveness and efficiency of the proposed solution.},
  archive      = {J_TMIS},
  author       = {Arindam Roy and Shamik Sural and Arun Kumar Majumdar and Jaideep Vaidya and Vijayalakshmi Atluri},
  doi          = {10.1145/3403950},
  journal      = {ACM Transactions on Management Information Systems},
  number       = {1},
  pages        = {6:1–24},
  shortjournal = {ACM Trans. Manag. Inf. Sys.},
  title        = {Optimal employee recruitment in organizations under attribute-based access control},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A multi-disciplinary perspective for conducting artificial
intelligence-enabled privacy analytics: Connecting data, algorithms, and
systems. <em>TMIS</em>, <em>12</em>(1), 1:1–18. (<a
href="https://doi.org/10.1145/3447507">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Events such as Facebook-Cambridge Analytica scandal and data aggregation efforts by technology providers have illustrated how fragile modern society is to privacy violations. Internationally recognized entities such as the National Science Foundation (NSF) have indicated that Artificial Intelligence (AI)-enabled models, artifacts, and systems can efficiently and effectively sift through large quantities of data from legal documents, social media, Dark Web sites, and other sources to curb privacy violations. Yet considerable efforts are still required for understanding prevailing data sources, systematically developing AI-enabled privacy analytics to tackle emerging challenges, and deploying systems to address critical privacy needs. To this end, we provide an overview of prevailing data sources that can support AI-enabled privacy analytics; a multi-disciplinary research framework that connects data, algorithms, and systems to tackle emerging AI-enabled privacy analytics challenges such as entity resolution, privacy assistance systems, privacy risk modeling, and more; a summary of selected funding sources to support high-impact privacy analytics research; and an overview of prevailing conference and journal venues that can be leveraged to share and archive privacy analytics research. We conclude this paper with an introduction of the papers included in this special issue.},
  archive      = {J_TMIS},
  author       = {Sagar Samtani and Murat Kantarcioglu and Hsinchun Chen},
  doi          = {10.1145/3447507},
  journal      = {ACM Transactions on Management Information Systems},
  number       = {1},
  pages        = {1:1–18},
  shortjournal = {ACM Trans. Manag. Inf. Sys.},
  title        = {A multi-disciplinary perspective for conducting artificial intelligence-enabled privacy analytics: Connecting data, algorithms, and systems},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
</ul>

</body>
</html>
