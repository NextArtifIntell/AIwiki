<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>TIST_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="tist---81">TIST - 81</h2>
<ul>
<li><details>
<summary>
(2021). How members of covert networks conceal the identities of
their leaders. <em>TIST</em>, <em>13</em>(1), 12:1–29. (<a
href="https://doi.org/10.1145/3490462">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Centrality measures are the most commonly advocated social network analysis tools for identifying leaders of covert organizations. While the literature has predominantly focused on studying the effectiveness of existing centrality measures or developing new ones, we study the problem from the opposite perspective, by focusing on how a group of leaders can avoid being identified by centrality measures as key members of a covert network. More specifically, we analyze the problem of choosing a set of edges to be added to a network to decrease the leaders’ ranking according to three fundamental centrality measures, namely, degree, closeness, and betweenness. We prove that this problem is NP-complete for each measure. Moreover, we study how the leaders can construct a network from scratch, designed specifically to keep them hidden from centrality measures. We identify a network structure that not only guarantees to hide the leaders to a certain extent but also allows them to spread their influence across the network.},
  archive      = {J_TIST},
  author       = {Marcin Waniek and Tomasz P. Michalak and Michael Wooldridge and Talal Rahwan},
  doi          = {10.1145/3490462},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  number       = {1},
  pages        = {12:1–29},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {How members of covert networks conceal the identities of their leaders},
  volume       = {13},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An uncertainty-based neural network for explainable
trajectory segmentation. <em>TIST</em>, <em>13</em>(1), 11:1–18. (<a
href="https://doi.org/10.1145/3467978">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a variant task of time-series segmentation, trajectory segmentation is a key task in the applications of transportation pattern recognition and traffic analysis. However, segmenting trajectory is faced with challenges of implicit patterns and sparse results. Although deep neural networks have tremendous advantages in terms of high-level feature learning performance, deploying as a blackbox seriously limits the real-world applications. Providing explainable segmentations has significance for result evaluation and decision making. Thus, in this article, we address trajectory segmentation by proposing a Bayesian Encoder-Decoder Network (BED-Net) to provide accurate detection with explainability and references for the following active-learning procedures. BED-Net consists of a segmentation module based on Monte Carlo dropout and an explanation module based on uncertainty learning that provides results evaluation and visualization. Experimental results on both benchmark and real-world datasets indicate that BED-Net outperforms the rival methods and offers excellent explainability in the applications of trajectory segmentation.},
  archive      = {J_TIST},
  author       = {Xin Bi and Chao Zhang and Fangtong Wang and Zhixun Liu and Xiangguo Zhao and Ye Yuan and Guoren Wang},
  doi          = {10.1145/3467978},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  number       = {1},
  pages        = {11:1–18},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {An uncertainty-based neural network for explainable trajectory segmentation},
  volume       = {13},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Simultaneous past and current social interaction-aware
trajectory prediction for multiple intelligent agents in dynamic scenes.
<em>TIST</em>, <em>13</em>(1), 10:1–16. (<a
href="https://doi.org/10.1145/3466182">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Trajectory prediction of multiple agents in a crowded scene is an essential component in many applications, including intelligent monitoring, autonomous robotics, and self-driving cars. Accurate agent trajectory prediction remains a significant challenge because of the complex dynamic interactions among the agents and between them and the surrounding scene. To address the challenge, we propose a decoupled attention-based spatial-temporal modeling strategy in the proposed trajectory prediction method. The past and current interactions among agents are dynamically and adaptively summarized by two separate attention-based networks and have proven powerful in improving the prediction accuracy. Moreover, it is optional in the proposed method to make use of the road map and the plan of the ego-agent for scene-compliant and accurate predictions. The road map feature is efficiently extracted by a convolutional neural network, and the features of the ego-agent’s plan is extracted by a gated recurrent network with an attention module based on the temporal characteristic. Experiments on benchmark trajectory prediction datasets demonstrate that the proposed method is effective when the ego-agent plan and the the surrounding scene information are provided and achieves state-of-the-art performance with only the observed trajectories.},
  archive      = {J_TIST},
  author       = {Yanliang Zhu and Dongchun Ren and Yi Xu and Deheng Qian and Mingyu Fan and Xin Li and Huaxia Xia},
  doi          = {10.1145/3466182},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  number       = {1},
  pages        = {10:1–16},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Simultaneous past and current social interaction-aware trajectory prediction for multiple intelligent agents in dynamic scenes},
  volume       = {13},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Exploring the risky travel area and behavior of car-hailing
service. <em>TIST</em>, <em>13</em>(1), 9:1–22. (<a
href="https://doi.org/10.1145/3465059">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent years have witnessed the rapid development of car-hailing services, which provide a convenient approach for connecting passengers and local drivers using their personal vehicles. At the same time, the concern on passenger safety has gradually emerged and attracted more and more attention. While car-hailing service providers have made considerable efforts on developing real-time trajectory tracking systems and alarm mechanisms, most of them only focus on providing rescue-supporting information rather than preventing potential crimes. Recently, the newly available large-scale car-hailing order data have provided an unparalleled chance for researchers to explore the risky travel area and behavior of car-hailing services, which can be used for building an intelligent crime early warning system. To this end, in this article, we propose a Risky Area and Risky Behavior Evaluation System (RARBEs) based on the real-world car-hailing order data. In RARBEs, we first mine massive multi-source urban data and train an effective area risk prediction model, which estimates area risk at the urban block level. Then, we propose a transverse and longitudinal double detection method, which estimates behavior risk based on two aspects, including fraud trajectory recognition and fraud patterns mining. In particular, we creatively propose a bipartite graph-based algorithm to model the implicit relationship between areas and behaviors, which collaboratively adjusts area risk and behavior risk estimation based on random walk regularization. Finally, extensive experiments on multi-source real-world urban data clearly validate the effectiveness and efficiency of our system.},
  archive      = {J_TIST},
  author       = {Hongting Niu and Hengshu Zhu and Ying Sun and Xinjiang Lu and Jing Sun and Zhiyuan Zhao and Hui Xiong and Bo Lang},
  doi          = {10.1145/3465059},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  number       = {1},
  pages        = {9:1–22},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Exploring the risky travel area and behavior of car-hailing service},
  volume       = {13},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Let trajectories speak out the traffic bottlenecks.
<em>TIST</em>, <em>13</em>(1), 8:1–21. (<a
href="https://doi.org/10.1145/3465058">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traffic bottlenecks are a set of road segments that have an unacceptable level of traffic caused by a poor balance between road capacity and traffic volume. A huge volume of trajectory data which captures realtime traffic conditions in road networks provides promising new opportunities to identify the traffic bottlenecks. In this paper, we define this problem as trajectory-driven traffic bottleneck identification : Given a road network R , a trajectory database T , find a representative set of seed edges of size K of traffic bottlenecks that influence the highest number of road segments not in the seed set. We show that this problem is NP-hard and propose a framework to find the traffic bottlenecks as follows. First, a traffic spread model is defined which represents changes in traffic volume for each road segment over time. Then, the traffic diffusion probability between two connected segments and the residual ratio of traffic volume for each segment can be computed using historical trajectory data. We then propose two different algorithmic approaches to solve the problem. The first one is a best-first algorithm BF , with an approximation ratio of 1-1/ e . To further accelerate the identification process in larger datasets, we also propose a sampling-based greedy algorithm SG . Finally, comprehensive experiments using three different datasets compare and contrast various solutions, and provide insights into important efficiency and effectiveness trade-offs among the respective methods.},
  archive      = {J_TIST},
  author       = {Hui Luo and Zhifeng Bao and Gao Cong and J. Shane Culpepper and Nguyen Lu Dang Khoa},
  doi          = {10.1145/3465058},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  number       = {1},
  pages        = {8:1–21},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Let trajectories speak out the traffic bottlenecks},
  volume       = {13},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Deep siamese metric learning: A highly scalable approach to
searching unordered sets of trajectories. <em>TIST</em>, <em>13</em>(1),
6:1–23. (<a href="https://doi.org/10.1145/3465057">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work proposes metric learning for fast similarity-based scene retrieval of unstructured ensembles of trajectory data from large databases. We present a novel representation learning approach using Siamese Metric Learning that approximates a distance preserving low-dimensional representation and that learns to estimate reasonable solutions to the assignment problem. To this end, we employ a Temporal Convolutional Network architecture that we extend with a gating mechanism to enable learning from sparse data, leading to solutions to the assignment problem exhibiting varying degrees of sparsity. Our experimental results on professional soccer tracking data provides insights on learned features and embeddings, as well as on generalization, sensitivity, and network architectural considerations. Our low approximation errors for learned representations and the interactive performance with retrieval times several magnitudes smaller shows that we outperform previous state of the art.},
  archive      = {J_TIST},
  author       = {Christoffer Löffler and Luca Reeb and Daniel Dzibela and Robert Marzilger and Nicolas Witt and Björn M. Eskofier and Christopher Mutschler},
  doi          = {10.1145/3465057},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  number       = {1},
  pages        = {6:1–23},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Deep siamese metric learning: A highly scalable approach to searching unordered sets of trajectories},
  volume       = {13},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Origin-aware location prediction based on historical vehicle
trajectories. <em>TIST</em>, <em>13</em>(1), 5:1–18. (<a
href="https://doi.org/10.1145/3462675">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Next location prediction is of great importance for many location-based applications and provides essential intelligence to various businesses. In previous studies, a common approach to next location prediction is to learn the sequential transitions with massive historical trajectories based on conditional probability. Nevertheless, due to the time and space complexity, these methods (e.g., Markov models) only utilize the just passed locations to predict next locations, neglecting earlier passed locations in the trajectory. In this work, we seek to enhance the prediction performance by incorporating the travel time from all the passed locations in the query trajectory to each candidate next location. To this end, we propose a novel prediction method, namely the Travel Time Difference Model, which exploits the difference between the shortest travel time and the actual travel time to predict next locations. Moreover, we integrate the Travel Time Difference Model with a Sequential and Temporal Predictor to yield a joint model. The joint prediction model integrates local sequential transitions, temporal regularity, and global travel time information in the trajectory for the next location prediction problem. We have conducted extensive experiments on two real-world datasets: the vehicle passage record data and the taxi trajectory data. The experimental results demonstrate significant improvements in prediction accuracy over baseline methods.},
  archive      = {J_TIST},
  author       = {Meng Chen and Qingjie Liu and Weiming Huang and Teng Zhang and Yixuan Zuo and Xiaohui Yu},
  doi          = {10.1145/3462675},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  number       = {1},
  pages        = {5:1–18},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Origin-aware location prediction based on historical vehicle trajectories},
  volume       = {13},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Contrastive trajectory learning for tour recommendation.
<em>TIST</em>, <em>13</em>(1), 4:1–25. (<a
href="https://doi.org/10.1145/3462331">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The main objective of Personalized Tour Recommendation (PTR) is to generate a sequence of point-of-interest (POIs) for a particular tourist, according to the user-specific constraints such as duration time, start and end points, the number of attractions planned to visit, and so on. Previous PTR solutions are based on either heuristics for solving the orienteering problem to maximize a global reward with a specified budget or approaches attempting to learn user visiting preferences and transition patterns with the stochastic process or recurrent neural networks. However, existing learning methodologies rely on historical trips to train the model and use the next visited POI as the supervised signal, which may not fully capture the coherence of preferences and thus recommend similar trips to different users, primarily due to the data sparsity problem and long-tailed distribution of POI popularity. This work presents a novel tour recommendation model by distilling knowledge and supervision signals from the trips in a self-supervised manner. We propose Contrastive Trajectory Learning for Tour Recommendation (CTLTR), which utilizes the intrinsic POI dependencies and traveling intent to discover extra knowledge and augments the sparse data via pre-training auxiliary self-supervised objectives. CTLTR provides a principled way to characterize the inherent data correlations while tackling the implicit feedback and weak supervision problems by learning robust representations applicable for tour planning. We introduce a hierarchical recurrent encoder-decoder to identify tourists’ intentions and use the contrastive loss to discover subsequence semantics and their sequential patterns through maximizing the mutual information. Additionally, we observe that a data augmentation step as the preliminary of contrastive learning can solve the overfitting issue resulting from data sparsity. We conduct extensive experiments on a range of real-world datasets and demonstrate that our model can significantly improve the recommendation performance over the state-of-the-art baselines in terms of both recommendation accuracy and visiting orders.},
  archive      = {J_TIST},
  author       = {Fan Zhou and Pengyu Wang and Xovee Xu and Wenxin Tai and Goce Trajcevski},
  doi          = {10.1145/3462331},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  number       = {1},
  pages        = {4:1–25},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Contrastive trajectory learning for tour recommendation},
  volume       = {13},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Instant basketball defensive trajectory generation.
<em>TIST</em>, <em>13</em>(1), 3:1–20. (<a
href="https://doi.org/10.1145/3460619">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tactic learning in virtual reality (VR) has been proven to be effective for basketball training. Endowed with the ability of generating virtual defenders in real time according to the movement of virtual offenders controlled by the user, a VR basketball training system can bring more immersive and realistic experiences for the trainee. In this article, an autoregressive generative model for instantly producing basketball defensive trajectory is introduced. We further focus on the issue of preserving the diversity of the generated trajectories. A differentiable sampling mechanism is adopted to learn the continuous Gaussian distribution of player position. Moreover, several heuristic loss functions based on the domain knowledge of basketball are designed to make the generated trajectories assemble real situations in basketball games. We compare the proposed method with the state-of-the-art works in terms of both objective and subjective manners. The objective manner compares the average position, velocity, and acceleration of the generated defensive trajectories with the real ones to evaluate the fidelity of the results. In addition, more high-level aspects such as the empty space for offender and the defensive pressure of the generated trajectory are also considered in the objective evaluation. As for the subjective manner, visual comparison questionnaires on the proposed and other methods are thoroughly conducted. The experimental results show that the proposed method can achieve better performance than previous basketball defensive trajectory generation works in terms of different evaluation metrics.},
  archive      = {J_TIST},
  author       = {Wen-Cheng Chen and Wan-Lun Tsai and Huan-Hua Chang and Min-Chun Hu and Wei-Ta Chu},
  doi          = {10.1145/3460619},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  number       = {1},
  pages        = {3:1–20},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Instant basketball defensive trajectory generation},
  volume       = {13},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Passenger mobility prediction via representation learning
for dynamic directed and weighted graphs. <em>TIST</em>, <em>13</em>(1),
2:1–25. (<a href="https://doi.org/10.1145/3446344">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, ride-hailing services have been increasingly prevalent, as they provide huge convenience for passengers. As a fundamental problem, the timely prediction of passenger demands in different regions is vital for effective traffic flow control and route planning. As both spatial and temporal patterns are indispensable passenger demand prediction, relevant research has evolved from pure time series to graph-structured data for modeling historical passenger demand data, where a snapshot graph is constructed for each time slot by connecting region nodes via different relational edges (origin-destination relationship, geographical distance, etc.). Consequently, the spatiotemporal passenger demand records naturally carry dynamic patterns in the constructed graphs, where the edges also encode important information about the directions and volume (i.e., weights) of passenger demands between two connected regions. aspects in the graph-structure data. representation for DDW is the key to solve the prediction problem. However, existing graph-based solutions fail to simultaneously consider those three crucial aspects of dynamic, directed, and weighted graphs, leading to limited expressiveness when learning graph representations for passenger demand prediction. Therefore, we propose a novel spatiotemporal graph attention network, namely Gallat ( G raph prediction with all at tention) as a solution. In Gallat, by comprehensively incorporating those three intrinsic properties of dynamic directed and weighted graphs, we build three attention layers to fully capture the spatiotemporal dependencies among different regions across all historical time slots. Moreover, the model employs a subtask to conduct pretraining so that it can obtain accurate results more quickly. We evaluate the proposed model on real-world datasets, and our experimental results demonstrate that Gallat outperforms the state-of-the-art approaches.},
  archive      = {J_TIST},
  author       = {Yuandong Wang and Hongzhi Yin and Tong Chen and Chunyang Liu and Ben Wang and Tianyu Wo and Jie Xu},
  doi          = {10.1145/3446344},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  number       = {1},
  pages        = {2:1–25},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Passenger mobility prediction via representation learning for dynamic directed and weighted graphs},
  volume       = {13},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Introduction to the special issue on intelligent trajectory
analytics: Part i. <em>TIST</em>, <em>13</em>(1), 1:1–2. (<a
href="https://doi.org/10.1145/3495230">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_TIST},
  author       = {Kai Zheng and Yong Li and Cyrus Shahabi and Hongzhi Yin},
  doi          = {10.1145/3495230},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  number       = {1},
  pages        = {1:1–2},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Introduction to the special issue on intelligent trajectory analytics: Part i},
  volume       = {13},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-stage fusion and multi-source attention network for
multi-modal remote sensing image segmentation. <em>TIST</em>,
<em>12</em>(6), 82:1–20. (<a
href="https://doi.org/10.1145/3484440">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of sensor technology, lots of remote sensing data have been collected. It effectively obtains good semantic segmentation performance by extracting feature maps based on multi-modal remote sensing images since extra modal data provides more information. How to make full use of multi-model remote sensing data for semantic segmentation is challenging. Toward this end, we propose a new network called Multi-Stage Fusion and Multi-Source Attention Network ((MS) 2 -Net) for multi-modal remote sensing data segmentation. The multi-stage fusion module fuses complementary information after calibrating the deviation information by filtering the noise from the multi-modal data. Besides, similar feature points are aggregated by the proposed multi-source attention for enhancing the discriminability of features with different modalities. The proposed model is evaluated on publicly available multi-modal remote sensing data sets, and results demonstrate the effectiveness of the proposed method.},
  archive      = {J_TIST},
  author       = {Jiaqi Zhao and Yong Zhou and Boyu Shi and Jingsong Yang and Di Zhang and Rui Yao},
  doi          = {10.1145/3484440},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  number       = {6},
  pages        = {82:1–20},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Multi-stage fusion and multi-source attention network for multi-modal remote sensing image segmentation},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A survey of AIOps methods for failure management.
<em>TIST</em>, <em>12</em>(6), 81:1–45. (<a
href="https://doi.org/10.1145/3483424">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modern society is increasingly moving toward complex and distributed computing systems. The increase in scale and complexity of these systems challenges O&amp;M teams that perform daily monitoring and repair operations, in contrast with the increasing demand for reliability and scalability of modern applications. For this reason, the study of automated and intelligent monitoring systems has recently sparked much interest across applied IT industry and academia. Artificial Intelligence for IT Operations (AIOps) has been proposed to tackle modern IT administration challenges thanks to Machine Learning, AI, and Big Data. However, AIOps as a research topic is still largely unstructured and unexplored, due to missing conventions in categorizing contributions for their data requirements, target goals, and components. In this work, we focus on AIOps for Failure Management (FM), characterizing and describing 5 different categories and 14 subcategories of contributions, based on their time intervention window and the target problem being solved. We review 100 FM solutions, focusing on applicability requirements and the quantitative results achieved, to facilitate an effective application of AIOps solutions. Finally, we discuss current development problems in the areas covered by AIOps and delineate possible future trends for AI-based failure management.},
  archive      = {J_TIST},
  author       = {Paolo Notaro and Jorge Cardoso and Michael Gerndt},
  doi          = {10.1145/3483424},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  number       = {6},
  pages        = {81:1–45},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {A survey of AIOps methods for failure management},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Causal discovery with confounding cascade nonlinear additive
noise models. <em>TIST</em>, <em>12</em>(6), 80:1–28. (<a
href="https://doi.org/10.1145/3482879">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Identification of causal direction between a causal-effect pair from observed data has recently attracted much attention. Various methods based on functional causal models have been proposed to solve this problem, by assuming the causal process satisfies some (structural) constraints and showing that the reverse direction violates such constraints. The nonlinear additive noise model has been demonstrated to be effective for this purpose, but the model class does not allow any confounding or intermediate variables between a cause pair–even if each direct causal relation follows this model. However, omitting the latent causal variables is frequently encountered in practice. After the omission, the model does not necessarily follow the model constraints. As a consequence, the nonlinear additive noise model may fail to correctly discover causal direction. In this work, we propose a confounding cascade nonlinear additive noise model to represent such causal influences–each direct causal relation follows the nonlinear additive noise model but we observe only the initial cause and final effect. We further propose a method to estimate the model, including the unmeasured confounding and intermediate variables, from data under the variational auto-encoder framework. Our theoretical results show that with our model, the causal direction is identifiable under suitable technical conditions on the data generation process. Simulation results illustrate the power of the proposed method in identifying indirect causal relations across various settings, and experimental results on real data suggest that the proposed model and method greatly extend the applicability of causal discovery based on functional causal models in nonlinear cases.},
  archive      = {J_TIST},
  author       = {Jie Qiao and Ruichu Cai and Kun Zhang and Zhenjie Zhang and Zhifeng Hao},
  doi          = {10.1145/3482879},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  number       = {6},
  pages        = {80:1–28},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Causal discovery with confounding cascade nonlinear additive noise models},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Classi-fly: Inferring aircraft categories from open data.
<em>TIST</em>, <em>12</em>(6), 79:1–23. (<a
href="https://doi.org/10.1145/3480969">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, air traffic communication data has become easy to access, enabling novel research in many fields. Exploiting this new data source, a wide range of applications have emerged, from weather forecasting to stock market prediction, or the collection of intelligence about military and government movements. Typically, these applications require knowledge about the metadata of the aircraft, specifically its operator and the aircraft category. armasuisse Science + Technology , the R&amp;D agency for the Swiss Armed Forces, has been developing Classi-Fly, a novel approach to obtain metadata about aircraft based on their movement patterns. We validate Classi-Fly using several hundred thousand flights collected through open source means, in conjunction with ground truth from publicly available aircraft registries containing more than 2 million aircraft. We show that we can obtain the correct aircraft category with an accuracy of greater than 88\%. In cases, where no metadata is available, this approach can be used to create the data necessary for applications working with air traffic communication. Finally, we show that it is feasible to automatically detect particular sensitive aircraft such as police and surveillance aircraft using this method.},
  archive      = {J_TIST},
  author       = {Martin Strohmeier and Matthew Smith and Vincent Lenders and Ivan Martinovic},
  doi          = {10.1145/3480969},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  number       = {6},
  pages        = {79:1–23},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Classi-fly: Inferring aircraft categories from open data},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Predicting human mobility with reinforcement-learning-based
long-term periodicity modeling. <em>TIST</em>, <em>12</em>(6), 78:1–23.
(<a href="https://doi.org/10.1145/3469860">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobility prediction plays an important role in a wide range of location-based applications and services. However, there are three problems in the existing literature: (1) explicit high-order interactions of spatio-temporal features are not systemically modeled; (2) most existing algorithms place attention mechanisms on top of recurrent network, so they can not allow for full parallelism and are inferior to self-attention for capturing long-range dependence; (3) most literature does not make good use of long-term historical information and do not effectively model the long-term periodicity of users. To this end, we propose MoveNet and RLMoveNet. MoveNet is a self-attention-based sequential model, predicting each user’s next destination based on her most recent visits and historical trajectory. MoveNet first introduces a cross-based learning framework for modeling feature interactions. With self-attention on both the most recent visits and historical trajectory, MoveNet can use an attention mechanism to capture the user’s long-term regularity in a more efficient way. Based on MoveNet, to model long-term periodicity more effectively, we add the reinforcement learning layer and named RLMoveNet. RLMoveNet regards the human mobility prediction as a reinforcement learning problem, using the reinforcement learning layer as the regularization part to drive the model to pay attention to the behavior with periodic actions, which can help us make the algorithm more effective. We evaluate both of them with three real-world mobility datasets. MoveNet outperforms the state-of-the-art mobility predictor by around 10\% in terms of accuracy, and simultaneously achieves faster convergence and over 4x training speedup. Moreover, RLMoveNet achieves higher prediction accuracy than MoveNet, which proves that modeling periodicity explicitly from the perspective of reinforcement learning is more effective.},
  archive      = {J_TIST},
  author       = {Shuo Tao and Jingang Jiang and Defu Lian and Kai Zheng and Enhong Chen},
  doi          = {10.1145/3469860},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  number       = {6},
  pages        = {78:1–23},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Predicting human mobility with reinforcement-learning-based long-term periodicity modeling},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Similar trajectory search with spatio-temporal deep
representation learning. <em>TIST</em>, <em>12</em>(6), 77:1–26. (<a
href="https://doi.org/10.1145/3466687">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Similar trajectory search is a crucial task that facilitates many downstream spatial data analytic applications. Despite its importance, many of the current literature focus solely on the trajectory’s spatial similarity while neglecting the temporal information. Additionally, the few papers that use both the spatial and temporal features based their approach on a traditional point-to-point comparison. These methods model the importance of the spatial and temporal aspect of the data with only a single, pre-defined balancing factor for all trajectories, even though the relative spatial and temporal balance can change from trajectory to trajectory. In this article, we propose the first spatio-temporal, deep-representation-learning-based approach to similar trajectory search. Experiments show that utilizing both features offers significant improvements over existing point-to-point comparison and deep-representation-learning approach. We also show that our deep neural network approach is faster and performs more consistently compared to the point-to-point comparison approaches.},
  archive      = {J_TIST},
  author       = {David Alexander Tedjopurnomo and Xiucheng Li and Zhifeng Bao and Gao Cong and Farhana Choudhury and A. K. Qin},
  doi          = {10.1145/3466687},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  number       = {6},
  pages        = {77:1–26},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Similar trajectory search with spatio-temporal deep representation learning},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Spatial variability aware deep neural networks (SVANN): A
general approach. <em>TIST</em>, <em>12</em>(6), 76:1–21. (<a
href="https://doi.org/10.1145/3466688">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spatial variability is a prominent feature of various geographic phenomena such as climatic zones, USDA plant hardiness zones, and terrestrial habitat types (e.g., forest, grasslands, wetlands, and deserts). However, current deep learning methods follow a spatial-one-size-fits-all (OSFA) approach to train single deep neural network models that do not account for spatial variability. Quantification of spatial variability can be challenging due to the influence of many geophysical factors. In preliminary work, we proposed a spatial variability aware neural network (SVANN-I, formerly called SVANN ) approach where weights are a function of location but the neural network architecture is location independent. In this work, we explore a more flexible SVANN-E approach where neural network architecture varies across geographic locations. In addition, we provide a taxonomy of SVANN types and a physics inspired interpretation model. Experiments with aerial imagery based wetland mapping show that SVANN-I outperforms OSFA and SVANN-E performs the best of all.},
  archive      = {J_TIST},
  author       = {Jayant Gupta and Carl Molnar and Yiqun Xie and Joe Knight and Shashi Shekhar},
  doi          = {10.1145/3466688},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  number       = {6},
  pages        = {76:1–21},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Spatial variability aware deep neural networks (SVANN): A general approach},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). TAML: A traffic-aware multi-task learning model for
estimating travel time. <em>TIST</em>, <em>12</em>(6), 75:1–14. (<a
href="https://doi.org/10.1145/3466686">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Travel time estimation has been recognized as an important research topic that can find broad applications. Existing approaches aim to explore mobility patterns via trajectory embedding for travel time estimation. Though state-of-the-art methods utilize estimated traffic condition (by explicit features such as average traffic speed) for auxiliary supervision of travel time estimation, they fail to model their mutual influence and result in inaccuracy accordingly. To this end, in this article, we propose an improved traffic-aware model, called TAML, which adopts a multi-task learning network to integrate a travel time estimator and a traffic estimator in a shared space and improves the accuracy of estimation by enhanced representation of traffic condition, such that more meaningful implicit features are fully captured. In TAML, multi-task learning is further applied for travel time estimation in multi-granularities (including road segment, sub-path, and entire path). The multiple loss functions are combined by considering the homoscedastic uncertainty of each task. Extensive experiments on two real trajectory datasets demonstrate the effectiveness of our proposed methods.},
  archive      = {J_TIST},
  author       = {Jiajie Xu and Saijun Xu and Rui Zhou and Chengfei Liu and An Liu and Lei Zhao},
  doi          = {10.1145/3466686},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  number       = {6},
  pages        = {75:1–14},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {TAML: A traffic-aware multi-task learning model for estimating travel time},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Route optimization via environment-aware deep network and
reinforcement learning. <em>TIST</em>, <em>12</em>(6), 74:1–21. (<a
href="https://doi.org/10.1145/3461645">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vehicle mobility optimization in urban areas is a long-standing problem in smart city and spatial data analysis. Given the complex urban scenario and unpredictable social events, our work focuses on developing a mobile sequential recommendation system to maximize the profitability of vehicle service providers (e.g., taxi drivers). In particular, we treat the dynamic route optimization problem as a long-term sequential decision-making task. A reinforcement-learning framework is proposed to tackle this problem, by integrating a self-check mechanism and a deep neural network for customer pick-up point monitoring. To account for unexpected situations (e.g., the COVID-19 outbreak), our method is designed to be capable of handling related environment changes with a self-adaptive parameter determination mechanism. Based on the yellow taxi data in New York City and vicinity before and after the COVID-19 outbreak, we have conducted comprehensive experiments to evaluate the effectiveness of our method. The results show consistently excellent performance, from hourly to weekly measures, to support the superiority of our method over the state-of-the-art methods (i.e., with more than 98\% improvement in terms of the profitability for taxi drivers).},
  archive      = {J_TIST},
  author       = {Pengzhan Guo and Keli Xiao and Zeyang Ye and Wei Zhu},
  doi          = {10.1145/3461645},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  number       = {6},
  pages        = {74:1–21},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Route optimization via environment-aware deep network and reinforcement learning},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). PARP: A parallel traffic condition driven route planning
model on dynamic road networks. <em>TIST</em>, <em>12</em>(6), 73:1–24.
(<a href="https://doi.org/10.1145/3459099">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The problem of route planning on road network is essential to many Location-Based Services (LBSs). Road networks are dynamic in the sense that the weights of the edges in the corresponding graph constantly change over time, representing evolving traffic conditions. Thus, a practical route planning strategy is required to supply the continuous route optimization considering the historic, current, and future traffic condition. However, few existing works comprehensively take into account these various traffic conditions during the route planning. Moreover, the LBSs usually suffer from extensive concurrent route planning requests in rush hours, which imposes a pressing need to handle numerous queries in parallel for reducing the response time of each query. However, this issue is also not involved by most existing solutions. We therefore investigate a parallel traffic condition driven route planning model on a cluster of processors. To embed the future traffic condition into the route planning, we employ a GCN model to periodically predict the travel costs of roads within a specified time period, which facilitates the robustness of the route planning model against the varying traffic condition. To reduce the response time, a Dual-Level Path (DLP) index is proposed to support a parallel route planning algorithm with the filter-and-refine principle. The bottom level of DLP partitions the entire graph into different subgraphs, and the top level is a skeleton graph that consists of all border vertices in all subgraphs. The filter step identifies a global directional path for a given query based on the skeleton graph. In the refine step, the overall route planning for this query is decomposed into multiple sub-optimizations in the subgraphs passed through by the directional path. Since the subgraphs are independently maintained by different processors, the sub-optimizations of extensive queries can be operated in parallel. Finally, extensive evaluations are conducted to confirm the effectiveness and superiority of the proposal.},
  archive      = {J_TIST},
  author       = {Tianlun Dai and Bohan Li and Ziqiang Yu and Xiangrong Tong and Meng Chen and Gang Chen},
  doi          = {10.1145/3459099},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  number       = {6},
  pages        = {73:1–24},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {PARP: A parallel traffic condition driven route planning model on dynamic road networks},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). TARA-net: A fusion network for detecting takeaway rider
accidents. <em>TIST</em>, <em>12</em>(6), 72:1–19. (<a
href="https://doi.org/10.1145/3457218">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the emerging business of food delivery, rider traffic accidents raise financial cost and social traffic burden. Although there has been much effort on traffic accident forecasting using temporal-spatial prediction models, none of the existing work studies the problem of detecting the takeaway rider accidents based on food delivery trajectory data. In this article, we aim to detect whether a takeaway rider meets an accident on a certain time period based on trajectories of food delivery and riders’ contextual information. The food delivery data has a heterogeneous information structure and carries contextual information such as weather and delivery history, and trajectory data are collected as a spatial-temporal sequence. In this article, we propose a TakeAway Rider Accident detection fusion network TARA-Net to jointly model these heterogeneous and spatial-temporal sequence data. We utilize the residual network to extract basic contextual information features and take advantage of a transformer encoder to capture trajectory features. These embedding features are concatenated into a pyramidal feed-forward neural network. We jointly train the above three components to combine the benefits of spatial-temporal trajectory data and sparse basic contextual data for early detecting traffic accidents. Furthermore, although traffic accidents rarely happen in food delivery, we propose a sampling mechanism to alleviate the imbalance of samples when training the model. We evaluate the model on a transportation mode classification dataset Geolife and a real-world Ele.me dataset with over 3 million riders. The experimental results show that the proposed model is superior to the state-of-the-art.},
  archive      = {J_TIST},
  author       = {Yifan He and Zhao Li and Lei Fu and Anhui Wang and Peng Zhang and Shuigeng Zhou and Ji Zhang and Ting Yu},
  doi          = {10.1145/3457218},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  number       = {6},
  pages        = {72:1–19},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {TARA-net: A fusion network for detecting takeaway rider accidents},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). TWIST-GAN: Towards wavelet transform and transferred GAN for
spatio-temporal single image super resolution. <em>TIST</em>,
<em>12</em>(6), 71:1–20. (<a
href="https://doi.org/10.1145/3456726">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Single Image Super-resolution (SISR) produces high-resolution images with fine spatial resolutions from a remotely sensed image with low spatial resolution. Recently, deep learning and generative adversarial networks (GANs) have made breakthroughs for the challenging task of single image super-resolution (SISR) . However, the generated image still suffers from undesirable artifacts such as the absence of texture-feature representation and high-frequency information. We propose a frequency domain-based spatio-temporal remote sensing single image super-resolution technique to reconstruct the HR image combined with generative adversarial networks (GANs) on various frequency bands (TWIST-GAN). We have introduced a new method incorporating Wavelet Transform (WT) characteristics and transferred generative adversarial network. The LR image has been split into various frequency bands by using the WT, whereas the transfer generative adversarial network predicts high-frequency components via a proposed architecture. Finally, the inverse transfer of wavelets produces a reconstructed image with super-resolution. The model is first trained on an external DIV2 K dataset and validated with the UC Merced Landsat remote sensing dataset and Set14 with each image size of 256 × 256. Following that, transferred GANs are used to process spatio-temporal remote sensing images in order to minimize computation cost differences and improve texture information. The findings are compared qualitatively and qualitatively with the current state-of-art approaches. In addition, we saved about 43\% of the GPU memory during training and accelerated the execution of our simplified version by eliminating batch normalization layers.},
  archive      = {J_TIST},
  author       = {Fayaz Ali Dharejo and Farah Deeba and Yuanchun Zhou and Bhagwan Das and Munsif Ali Jatoi and Muhammad Zawish and Yi Du and Xuezhi Wang},
  doi          = {10.1145/3456726},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  number       = {6},
  pages        = {71:1–20},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {TWIST-GAN: Towards wavelet transform and transferred GAN for spatio-temporal single image super resolution},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A dynamic convolutional neural network based shared-bike
demand forecasting model. <em>TIST</em>, <em>12</em>(6), 70:1–24. (<a
href="https://doi.org/10.1145/3447988">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bike-sharing systems are becoming popular and generate a large volume of trajectory data. In a bike-sharing system, users can borrow and return bikes at different stations. In particular, a bike-sharing system will be affected by weather, the time period, and other dynamic factors, which challenges the scheduling of shared bikes. In this article, a new shared-bike demand forecasting model based on dynamic convolutional neural networks, called SDF , is proposed to predict the demand of shared bikes. SDF chooses the most relevant weather features from real weather data by using the Pearson correlation coefficient and transforms them into a two-dimensional dynamic feature matrix, taking into account the states of stations from historical data. The feature information in the matrix is extracted, learned, and trained with a newly proposed dynamic convolutional neural network to predict the demand of shared bikes in a dynamical and intelligent fashion. The phase of parameter update is optimized from three aspects: the loss function, optimization algorithm, and learning rate. Then, an accurate shared-bike demand forecasting model is designed based on the basic idea of minimizing the loss value. By comparing with classical machine learning models, the weight sharing strategy employed by SDF reduces the complexity of the network. It allows a high prediction accuracy to be achieved within a relatively short period of time. Extensive experiments are conducted on real-world bike-sharing datasets to evaluate SDF. The results show that SDF significantly outperforms classical machine learning models in prediction accuracy and efficiency.},
  archive      = {J_TIST},
  author       = {Shaojie Qiao and Nan Han and Jianbin Huang and Kun Yue and Rui Mao and Hongping Shu and Qiang He and Xindong Wu},
  doi          = {10.1145/3447988},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  number       = {6},
  pages        = {70:1–24},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {A dynamic convolutional neural network based shared-bike demand forecasting model},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). POLLA: Enhancing the local structure awareness in long
sequence spatial-temporal modeling. <em>TIST</em>, <em>12</em>(6),
69:1–24. (<a href="https://doi.org/10.1145/3447987">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The spatial-temporal modeling on long sequences is of great importance in many real-world applications. Recent studies have shown the potential of applying the self-attention mechanism to improve capturing the complex spatial-temporal dependencies. However, the lack of underlying structure information weakens its general performance on long sequence spatial-temporal problem. To overcome this limitation, we proposed a novel method, named the Proximity-aware Long Sequence Learning framework, and apply it to the spatial-temporal forecasting task. The model substitutes the canonical self-attention by leveraging the proximity-aware attention, which enhances local structure clues in building long-range dependencies with a linear approximation of attention scores. The relief adjacency matrix technique can utilize the historical global graph information for consistent proximity learning. Meanwhile, the reduced decoder allows for fast inference in a non-autoregressive manner. Extensive experiments are conducted on five large-scale datasets, which demonstrate that our method achieves state-of-the-art performance and validates the effectiveness brought by local structure information.},
  archive      = {J_TIST},
  author       = {Haoyi Zhou and Hao Peng and Jieqi Peng and Shuai Zhang and Jianxin Li},
  doi          = {10.1145/3447987},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  number       = {6},
  pages        = {69:1–24},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {POLLA: Enhancing the local structure awareness in long sequence spatial-temporal modeling},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Temporal hierarchical graph attention network for traffic
prediction. <em>TIST</em>, <em>12</em>(6), 68:1–21. (<a
href="https://doi.org/10.1145/3446430">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a critical task in intelligent traffic systems, traffic prediction has received a large amount of attention in the past few decades. The early efforts mainly model traffic prediction as the time-series mining problem, in which the spatial dependence has been largely ignored. As the rapid development of deep learning, some attempts have been made in modeling traffic prediction as the spatio-temporal data mining problem in a road network, in which deep learning techniques can be adopted for modeling the spatial and temporal dependencies simultaneously. Despite the success, the spatial and temporal dependencies are only modeled in a regionless network without considering the underlying hierarchical regional structure of the spatial nodes, which is an important structure naturally existing in the real-world road network. Apart from the challenge of modeling the spatial and temporal dependencies like the existing studies, the extra challenge caused by considering the hierarchical regional structure of the road network lies in simultaneously modeling the spatial and temporal dependencies between nodes and regions and the spatial and temporal dependencies between regions. To this end, this article proposes a new Temporal Hierarchical Graph Attention Network (TH-GAT). The main idea lies in augmenting the original road network into a region-augmented network, in which the hierarchical regional structure can be modeled. Based on the region-augmented network, the region-aware spatial dependence model and the region-aware temporal dependence model can be constructed, which are two main components of the proposed TH-GAT model. In addition, in the region-aware spatial dependence model, the graph attention network is adopted, in which the importance of a node to another node, of a node to a region, of a region to a node, and of a region to another region, can be captured automatically by means of the attention coefficients. Extensive experiments are conducted on two real-world traffic datasets, and the results have confirmed the superiority of the proposed TH-GAT model.},
  archive      = {J_TIST},
  author       = {Ling Huang and Xing-Xing Liu and Shu-Qiang Huang and Chang-Dong Wang and Wei Tu and Jia-Meng Xie and Shuai Tang and Wendi Xie},
  doi          = {10.1145/3446430},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  number       = {6},
  pages        = {68:1–21},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Temporal hierarchical graph attention network for traffic prediction},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). ACM TIST special issue on deep learning for spatio-temporal
data: Part 1. <em>TIST</em>, <em>12</em>(6), 67:1–3. (<a
href="https://doi.org/10.1145/3495188">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_TIST},
  author       = {Senzhang Wang and Junbo Zhang and Yanjie Fu and Yong Li},
  doi          = {10.1145/3495188},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  number       = {6},
  pages        = {67:1–3},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {ACM TIST special issue on deep learning for spatio-temporal data: Part 1},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). KOMPOS: Connecting causal knots in large nonlinear time
series with non-parametric regression splines. <em>TIST</em>,
<em>12</em>(5), 66:1–27. (<a
href="https://doi.org/10.1145/3480971">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recovering causality from copious time series data beyond mere correlations has been an important contributing factor in numerous scientific fields. Most existing works assume linearity in the data that may not comply with many real-world scenarios. Moreover, it is usually not sufficient to solely infer the causal relationships. Identifying the correct time delay of cause-effect is extremely vital for further insight and effective policies in inter-disciplinary domains. To bridge this gap, we propose KOMPOS, a novel algorithmic framework that combines a powerful concept from causal discovery of additive noise models with graphical ones. We primarily build our structural causal model from multivariate adaptive regression splines with inherent additive local nonlinearities, which render the underlying causal structure more easily identifiable. In contrast to other methods, our approach is not restricted to Gaussian or non-Gaussian noise due to the non-parametric attribute of the regression method. We conduct extensive experiments on both synthetic and real-world datasets, demonstrating the superiority of the proposed algorithm over existing causal discovery methods, especially for the challenging cases of autocorrelated and non-stationary time series.},
  archive      = {J_TIST},
  author       = {Georgios Koutroulis and Leo Botler and Belgin Mutlu and Konrad Diwold and Kay Römer and Roman Kern},
  doi          = {10.1145/3480971},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  number       = {5},
  pages        = {66:1–27},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {KOMPOS: Connecting causal knots in large nonlinear time series with non-parametric regression splines},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A comprehensive survey of grammatical error correction.
<em>TIST</em>, <em>12</em>(5), 65:1–51. (<a
href="https://doi.org/10.1145/3474840">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Grammatical error correction (GEC) is an important application aspect of natural language processing techniques, and GEC system is a kind of very important intelligent system that has long been explored both in academic and industrial communities. The past decade has witnessed significant progress achieved in GEC for the sake of increasing popularity of machine learning and deep learning. However, there is not a survey that untangles the large amount of research works and progress in this field. We present the first survey in GEC for a comprehensive retrospective of the literature in this area. We first give the definition of GEC task and introduce the public datasets and data annotation schema. After that, we discuss six kinds of basic approaches, six commonly applied performance boosting techniques for GEC systems, and three data augmentation methods. Since GEC is typically viewed as a sister task of Machine Translation (MT), we put more emphasis on the statistical machine translation (SMT)-based approaches and neural machine translation (NMT)-based approaches for the sake of their importance. Similarly, some performance-boosting techniques are adapted from MT and are successfully combined with GEC systems for enhancement on the final performance. More importantly, after the introduction of the evaluation in GEC, we make an in-depth analysis based on empirical results in aspects of GEC approaches and GEC systems for a clearer pattern of progress in GEC, where error type analysis and system recapitulation are clearly presented. Finally, we discuss five prospective directions for future GEC researches.},
  archive      = {J_TIST},
  author       = {Yu Wang and Yuelin Wang and Kai Dang and Jie Liu and Zhuo Liu},
  doi          = {10.1145/3474840},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  number       = {5},
  pages        = {65:1–51},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {A comprehensive survey of grammatical error correction},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Detecting and analyzing collusive entities on YouTube.
<em>TIST</em>, <em>12</em>(5), 64:1–28. (<a
href="https://doi.org/10.1145/3477300">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {YouTube sells advertisements on the posted videos, which in turn enables the content creators to monetize their videos. As an unintended consequence, this has proliferated various illegal activities such as artificial boosting of views, likes, comments, and subscriptions. We refer to such videos (gaining likes and comments artificially) and channels (gaining subscriptions artificially) as “collusive entities.” Detecting such collusive entities is an important yet challenging task. Existing solutions mostly deal with the problem of spotting fake views, spam comments, fake content, and so on, and oftentimes ignore how such fake activities emerge via collusion. Here, we collect a large dataset consisting of two types of collusive entities on YouTube— videos submitted to gain collusive likes and comment requests and channels submitted to gain collusive subscriptions. We begin by providing an in-depth analysis of collusive entities on YouTube fostered by various blackmarket services . Following this, we propose models to detect three types of collusive YouTube entities: videos seeking collusive likes, channels seeking collusive subscriptions, and videos seeking collusive comments. The third type of entity is associated with temporal information. To detect videos and channels for collusive likes and subscriptions, respectively, we utilize one-class classifiers trained on our curated collusive entities and a set of novel features. The SVM-based model shows significant performance with a true positive rate of 0.911 and 0.910 for detecting collusive videos and collusive channels, respectively. To detect videos seeking collusive comments, we propose CollATe , a novel end-to-end neural architecture that leverages time-series information of posted comments along with static metadata of videos. CollATe is composed of three components: metadata feature extractor (which derives metadata-based features from videos), anomaly feature extractor (which utilizes the time-series data to detect sudden changes in the commenting activity), and comment feature extractor (which utilizes the text of the comments posted during collusion and computes a similarity score between the comments). Extensive experiments show the effectiveness of CollATe (with a true positive rate of 0.905) over the baselines.},
  archive      = {J_TIST},
  author       = {Hridoy Sankar Dutta and Mayank Jobanputra and Himani Negi and Tanmoy Chakraborty},
  doi          = {10.1145/3477300},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  number       = {5},
  pages        = {64:1–28},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Detecting and analyzing collusive entities on YouTube},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). “In-network ensemble”: Deep ensemble learning with
diversified knowledge distillation. <em>TIST</em>, <em>12</em>(5),
63:1–19. (<a href="https://doi.org/10.1145/3473464">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ensemble learning is a widely used technique to train deep convolutional neural networks (CNNs) for improved robustness and accuracy. While existing algorithms usually first train multiple diversified networks and then assemble these networks as an aggregated classifier, we propose a novel learning paradigm, namely, “In-Network Ensemble” ( INE ) that incorporates the diversity of multiple models through training a SINGLE deep neural network. Specifically, INE segments the outputs of the CNN into multiple independent classifiers, where each classifier is further fine-tuned with better accuracy through a so-called diversified knowledge distillation process . We then aggregate the fine-tuned independent classifiers using an Averaging-and-Softmax operator to obtain the final ensemble classifier. Note that, in the supervised learning settings, INE starts the CNN training from random, while, under the transfer learning settings, it also could start with a pre-trained model to incorporate the knowledge learned from additional datasets. Extensive experiments have been done using eight large-scale real-world datasets, including CIFAR, ImageNet, and Stanford Cars, among others, as well as common deep network architectures such as VGG, ResNet, and Wide ResNet. We have evaluated the method under two tasks: supervised learning and transfer learning. The results show that INE outperforms the state-of-the-art algorithms for deep ensemble learning with improved accuracy.},
  archive      = {J_TIST},
  author       = {Xingjian Li and Haoyi Xiong and Zeyu Chen and Jun Huan and Cheng-Zhong Xu and Dejing Dou},
  doi          = {10.1145/3473464},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  number       = {5},
  pages        = {63:1–19},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {“In-network ensemble”: Deep ensemble learning with diversified knowledge distillation},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Significant DBSCAN+: Statistically robust density-based
clustering. <em>TIST</em>, <em>12</em>(5), 62:1–26. (<a
href="https://doi.org/10.1145/3474842">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cluster detection is important and widely used in a variety of applications, including public health, public safety, transportation, and so on. Given a collection of data points, we aim to detect density-connected spatial clusters with varying geometric shapes and densities, under the constraint that the clusters are statistically significant. The problem is challenging, because many societal applications and domain science studies have low tolerance for spurious results, and clusters may have arbitrary shapes and varying densities. As a classical topic in data mining and learning, a myriad of techniques have been developed to detect clusters with both varying shapes and densities (e.g., density-based, hierarchical, spectral, or deep clustering methods). However, the vast majority of these techniques do not consider statistical rigor and are susceptible to detecting spurious clusters formed as a result of natural randomness. On the other hand, scan statistic approaches explicitly control the rate of spurious results, but they typically assume a single “hotspot” of over-density and many rely on further assumptions such as a tessellated input space. To unite the strengths of both lines of work, we propose a statistically robust formulation of a multi-scale DBSCAN, namely Significant DBSCAN+, to identify significant clusters that are density connected. As we will show, incorporation of statistical rigor is a powerful mechanism that allows the new Significant DBSCAN+ to outperform state-of-the-art clustering techniques in various scenarios. We also propose computational enhancements to speed-up the proposed approach. Experiment results show that Significant DBSCAN+ can simultaneously improve the success rate of true cluster detection (e.g., 10–20\% increases in absolute F1 scores) and substantially reduce the rate of spurious results (e.g., from thousands/hundreds of spurious detections to none or just a few across 100 datasets), and the acceleration methods can improve the efficiency for both clustered and non-clustered data.},
  archive      = {J_TIST},
  author       = {Yiqun Xie and Xiaowei Jia and Shashi Shekhar and Han Bao and Xun Zhou},
  doi          = {10.1145/3474842},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  number       = {5},
  pages        = {62:1–26},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Significant DBSCAN+: Statistically robust density-based clustering},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Local graph edge partitioning. <em>TIST</em>,
<em>12</em>(5), 61:1–25. (<a
href="https://doi.org/10.1145/3466685">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph edge partitioning, which is essential for the efficiency of distributed graph computation systems, divides a graph into several balanced partitions within a given size to minimize the number of vertices to be cut. Existing graph partitioning models can be classified into two categories: offline and streaming graph partitioning models. The former requires global graph information during the partitioning, which is expensive in terms of time and memory for large-scale graphs. The latter creates partitions based solely on the received graph information. However, the streaming model may result in a lower partitioning quality compared with the offline model. Therefore, this study introduces a Local Graph Edge Partitioning model, which considers only the local information (i.e., a portion of a graph instead of the entire graph) during the partitioning. Considering only the local graph information is meaningful because acquiring complete information for large-scale graphs is expensive. Based on the Local Graph Edge Partitioning model, two local graph edge partitioning algorithms—Two-stage Local Partitioning and Adaptive Local Partitioning—are given. Experimental results obtained on 14 real-world graphs demonstrate that the proposed algorithms outperform rival algorithms in most tested cases. Furthermore, the proposed algorithms are proven to significantly improve the efficiency of the real graph computation system GraphX.},
  archive      = {J_TIST},
  author       = {Shengwei Ji and Chenyang Bu and Lei Li and Xindong Wu},
  doi          = {10.1145/3466685},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  number       = {5},
  pages        = {61:1–25},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Local graph edge partitioning},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Fine-grained semantic image synthesis with object-attention
generative adversarial network. <em>TIST</em>, <em>12</em>(5), 60:1–18.
(<a href="https://doi.org/10.1145/3470008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semantic image synthesis is a new rising and challenging vision problem accompanied by the recent promising advances in generative adversarial networks. The existing semantic image synthesis methods only consider the global information provided by the semantic segmentation mask, such as class label, global layout, and location, so the generative models cannot capture the rich local fine-grained information of the images (e.g., object structure, contour, and texture). To address this issue, we adopt a multi-scale feature fusion algorithm to refine the generated images by learning the fine-grained information of the local objects. We propose OA-GAN, a novel object-attention generative adversarial network that allows attention-driven, multi-fusion refinement for fine-grained semantic image synthesis. Specifically, the proposed model first generates multi-scale global image features and local object features, respectively, then the local object features are fused into the global image features to improve the correlation between the local and the global. In the process of feature fusion, the global image features and the local object features are fused through the channel-spatial-wise fusion block to learn ‘what’ and ‘where’ to attend in the channel and spatial axes, respectively. The fused features are used to construct correlation filters to obtain feature response maps to determine the locations, contours, and textures of the objects. Extensive quantitative and qualitative experiments on COCO-Stuff, ADE20K and Cityscapes datasets demonstrate that our OA-GAN significantly outperforms the state-of-the-art methods.},
  archive      = {J_TIST},
  author       = {Min Wang and Congyan Lang and Liqian Liang and Songhe Feng and Tao Wang and Yutong Gao},
  doi          = {10.1145/3470008},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  number       = {5},
  pages        = {60:1–18},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Fine-grained semantic image synthesis with object-attention generative adversarial network},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Identifying illicit drug dealers on instagram with
large-scale multimodal data fusion. <em>TIST</em>, <em>12</em>(5),
59:1–23. (<a href="https://doi.org/10.1145/3472713">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Illicit drug trafficking via social media sites such as Instagram have become a severe problem, thus drawing a great deal of attention from law enforcement and public health agencies. How to identify illicit drug dealers from social media data has remained a technical challenge for the following reasons. On the one hand, the available data are limited because of privacy concerns with crawling social media sites; on the other hand, the diversity of drug dealing patterns makes it difficult to reliably distinguish drug dealers from common drug users. Unlike existing methods that focus on posting-based detection, we propose to tackle the problem of illicit drug dealer identification by constructing a large-scale multimodal dataset named Identifying Drug Dealers on Instagram (IDDIG). Nearly 4,000 user accounts, of which more than 1,400 are drug dealers, have been collected from Instagram with multiple data sources including post comments, post images, homepage bio, and homepage images. We then design a quadruple-based multimodal fusion method to combine the multiple data sources associated with each user account for drug dealer identification. Experimental results on the constructed IDDIG dataset demonstrate the effectiveness of the proposed method in identifying drug dealers (almost 95\% accuracy). Moreover, we have developed a hashtag-based community detection technique for discovering evolving patterns, especially those related to geography and drug types.},
  archive      = {J_TIST},
  author       = {Chuanbo Hu and Minglei Yin and Bin Liu and Xin Li and Yanfang Ye},
  doi          = {10.1145/3472713},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  number       = {5},
  pages        = {59:1–23},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Identifying illicit drug dealers on instagram with large-scale multimodal data fusion},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). S3-net: A fast scene understanding network by single-shot
segmentation for autonomous driving. <em>TIST</em>, <em>12</em>(5),
58:1–19. (<a href="https://doi.org/10.1145/3470660">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Real-time segmentation and understanding of driving scenes are crucial in autonomous driving. Traditional pixel-wise approaches extract scene information by segmenting all pixels in a frame, and hence are inefficient and slow. Proposal-wise approaches only learn from the proposed object candidates, but still require multiple steps on the expensive proposal methods. Instead, this work presents a fast single-shot segmentation strategy for video scene understanding. The proposed net, called S3-Net, quickly locates and segments target sub-scenes , and meanwhile extracts attention-aware time-series sub-scene features ( ats-features ) as inputs to an attention-aware spatio-temporal model (ASM) . Utilizing tensorization and quantization techniques, S3-Net is intended to be lightweight for edge computing. Experiments results on CityScapes, UCF11, HMDB51, and MOMENTS datasets demonstrate that the proposed S3-Net achieves an accuracy improvement of 8.1\% versus the 3D-CNN based approach on UCF11, a storage reduction of 6.9× and an inference speed of 22.8 FPS on CityScapes with a GTX1080Ti GPU.},
  archive      = {J_TIST},
  author       = {Yuan Cheng and Yuchao Yang and Hai-Bao Chen and Ngai Wong and Hao Yu},
  doi          = {10.1145/3470660},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  number       = {5},
  pages        = {58:1–19},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {S3-net: A fast scene understanding network by single-shot segmentation for autonomous driving},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). DhCM: Dynamic and hierarchical event categorization and
discovery for social media stream. <em>TIST</em>, <em>12</em>(5),
57:1–25. (<a href="https://doi.org/10.1145/3470888">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The online event discovery in social media based documents is useful, such as for disaster recognition and intervention. However, the diverse events incrementally identified from social media streams remain accumulated, ad hoc, and unstructured. They cannot assist users in digesting the tremendous amount of information and finding their interested events. Further, most of the existing work is challenged by jointly identifying incremental events and dynamically organizing them in an adaptive hierarchy. To address these problems, this article proposes d ynamic and h ierarchical C ategorization M odeling (dhCM) for social media stream. Instead of manually dividing the timeframe, a multimodal event miner exploits a density estimation technique to continuously capture the temporal influence between documents and incrementally identify online events in textual, temporal, and spatial spaces. At the same time, an adaptive categorization hierarchy is formed to automatically organize the documents into proper categories at multiple levels of granularities. In a nonparametric manner, dhCM accommodates the increasing complexity of data streams with automatically growing the categorization hierarchy over adaptive growth. A sequential Monte Carlo algorithm is used for the online inference of the dhCM parameters. Extensive experiments show that dhCM outperforms the state-of-the-art models in terms of term coherence, category abstraction and specialization, hierarchical affinity, and event categorization and discovery accuracy.},
  archive      = {J_TIST},
  author       = {Jinjin Guo and Zhiguo Gong and Longbing Cao},
  doi          = {10.1145/3470888},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  number       = {5},
  pages        = {57:1–25},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {DhCM: Dynamic and hierarchical event categorization and discovery for social media stream},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Quantized adam with error feedback. <em>TIST</em>,
<em>12</em>(5), 56:1–26. (<a
href="https://doi.org/10.1145/3470890">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we present a distributed variant of an adaptive stochastic gradient method for training deep neural networks in the parameter-server model. To reduce the communication cost among the workers and server, we incorporate two types of quantization schemes, i.e., gradient quantization and weight quantization, into the proposed distributed Adam. In addition, to reduce the bias introduced by quantization operations, we propose an error-feedback technique to compensate for the quantized gradient. Theoretically, in the stochastic nonconvex setting, we show that the distributed adaptive gradient method with gradient quantization and error feedback converges to the first-order stationary point, and that the distributed adaptive gradient method with weight quantization and error feedback converges to the point related to the quantized level under both the single-worker and multi-worker modes. Last, we apply the proposed distributed adaptive gradient methods to train deep neural networks. Experimental results demonstrate the efficacy of our methods.},
  archive      = {J_TIST},
  author       = {Congliang Chen and Li Shen and Haozhi Huang and Wei Liu},
  doi          = {10.1145/3470890},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  number       = {5},
  pages        = {56:1–26},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Quantized adam with error feedback},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Collaborative local-global learning for temporal action
proposal. <em>TIST</em>, <em>12</em>(5), 55:1–14. (<a
href="https://doi.org/10.1145/3466181">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Temporal action proposal generation is an essential and challenging task in video understanding, which aims to locate the temporal intervals that likely contain the actions of interest. Although great progress has been made, the problem is still far from being well solved. In particular, prevalent methods can handle well only the local dependencies (i.e., short-term dependencies) among adjacent frames but are generally powerless in dealing with the global dependencies (i.e., long-term dependencies) between distant frames. To tackle this issue, we propose CLGNet, a novel Collaborative Local-Global Learning Network for temporal action proposal. The majority of CLGNet is an integration of Temporal Convolution Network and Bidirectional Long Short-Term Memory, in which Temporal Convolution Network is responsible for local dependencies while Bidirectional Long Short-Term Memory takes charge of handling the global dependencies. Furthermore, an attention mechanism called the background suppression module is designed to guide our model to focus more on the actions. Extensive experiments on two benchmark datasets, THUMOS’14 and ActivityNet-1.3, show that the proposed method can outperform state-of-the-art methods, demonstrating the strong capability of modeling the actions with varying temporal durations.},
  archive      = {J_TIST},
  author       = {Yisheng Zhu and Hu Han and Guangcan Liu and Qingshan Liu},
  doi          = {10.1145/3466181},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  number       = {5},
  pages        = {55:1–14},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Collaborative local-global learning for temporal action proposal},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). BATS: A spectral biclustering approach to single document
topic modeling and segmentation. <em>TIST</em>, <em>12</em>(5), 54:1–29.
(<a href="https://doi.org/10.1145/3468268">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing topic modeling and text segmentation methodologies generally require large datasets for training, limiting their capabilities when only small collections of text are available. In this work, we reexamine the inter-related problems of “topic identification” and “text segmentation” for sparse document learning, when there is a single new text of interest. In developing a methodology to handle single documents, we face two major challenges. First is sparse information : with access to only one document, we cannot train traditional topic models or deep learning algorithms. Second is significant noise : a considerable portion of words in any single document will produce only noise and not help discern topics or segments. To tackle these issues, we design an unsupervised, computationally efficient methodology called Biclustering Approach to Topic modeling and Segmentation (BATS). BATS leverages three key ideas to simultaneously identify topics and segment text: (i) a new mechanism that uses word order information to reduce sample complexity, (ii) a statistically sound graph-based biclustering technique that identifies latent structures of words and sentences, and (iii) a collection of effective heuristics that remove noise words and award important words to further improve performance. Experiments on six datasets show that our approach outperforms several state-of-the-art baselines when considering topic coherence, topic diversity, segmentation, and runtime comparison metrics.},
  archive      = {J_TIST},
  author       = {Qiong Wu and Adam Hare and Sirui Wang and Yuwei Tu and Zhenming Liu and Christopher G. Brinton and Yanhua Li},
  doi          = {10.1145/3468268},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  number       = {5},
  pages        = {54:1–29},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {BATS: A spectral biclustering approach to single document topic modeling and segmentation},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An attentive survey of attention models. <em>TIST</em>,
<em>12</em>(5), 53:1–32. (<a
href="https://doi.org/10.1145/3465055">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Attention Model has now become an important concept in neural networks that has been researched within diverse application domains. This survey provides a structured and comprehensive overview of the developments in modeling attention. In particular, we propose a taxonomy that groups existing techniques into coherent categories. We review salient neural architectures in which attention has been incorporated and discuss applications in which modeling attention has shown a significant impact. We also describe how attention has been used to improve the interpretability of neural networks. Finally, we discuss some future research directions in attention. We hope this survey will provide a succinct introduction to attention models and guide practitioners while developing approaches for their applications.},
  archive      = {J_TIST},
  author       = {Sneha Chaudhari and Varun Mithal and Gungor Polatkan and Rohan Ramanath},
  doi          = {10.1145/3465055},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  number       = {5},
  pages        = {53:1–32},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {An attentive survey of attention models},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-graph cooperative learning towards distant supervised
relation extraction. <em>TIST</em>, <em>12</em>(5), 52:1–21. (<a
href="https://doi.org/10.1145/3466560">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Graph Convolutional Network (GCN) is a universal relation extraction method that can predict relations of entity pairs by capturing sentences’ syntactic features. However, existing GCN methods often use dependency parsing to generate graph matrices and learn syntactic features. The quality of the dependency parsing will directly affect the accuracy of the graph matrix and change the whole GCN’s performance. Because of the influence of noisy words and sentence length in the distant supervised dataset, using dependency parsing on sentences causes errors and leads to unreliable information. Therefore, it is difficult to obtain credible graph matrices and relational features for some special sentences. In this article, we present a Multi-Graph Cooperative Learning model (MGCL), which focuses on extracting the reliable syntactic features of relations by different graphs and harnessing them to improve the representations of sentences. We conduct experiments on a widely used real-world dataset, and the experimental results show that our model achieves the state-of-the-art performance of relation extraction.},
  archive      = {J_TIST},
  author       = {Changsen Yuan and Heyan Huang and Chong Feng},
  doi          = {10.1145/3466560},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  number       = {5},
  pages        = {52:1–21},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Multi-graph cooperative learning towards distant supervised relation extraction},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Parallel connected LSTM for matrix sequence prediction with
elusive correlations. <em>TIST</em>, <em>12</em>(4), 51:1–16. (<a
href="https://doi.org/10.1145/3469437">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article is about a challenging problem called matrix sequence prediction, which is motivated from the application of taxi order prediction. Remarkably, the problem differs greatly from previous sequence prediction tasks in the sense that the time-wise correlations are quite elusive; namely, distant entries could be strongly correlated and nearby entries are unnecessarily related. Such distinct specifics make prevalent convolution-recurrence-based methods inadequate to apply. To remedy this trouble, we propose a novel architecture called Parallel Connected LSTM (PcLSTM), which integrates two new mechanisms, Multi-channel Linearized Connection (McLC) and Adaptive Parallel Unit (APU), into the framework of LSTM. Benefiting from the strengths of McLC and APU, our PcLSTM is able to handle well both the elusive correlations within each timestamp and the temporal dependencies across different timestamps, achieving state-of-the-art performance in a set of experiments demonstrated on synthetic and real-world datasets.},
  archive      = {J_TIST},
  author       = {Qi Zhao and Chuqiao Chen and Guangcan Liu and Qingshan Liu and Shengyong Chen},
  doi          = {10.1145/3469437},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  number       = {4},
  pages        = {51:1–16},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Parallel connected LSTM for matrix sequence prediction with elusive correlations},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). TLDS: A transfer-learning-based delivery station location
selection pipeline. <em>TIST</em>, <em>12</em>(4), 50:1–24. (<a
href="https://doi.org/10.1145/3469084">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Delivery stations play important roles in logistics systems. Well-designed delivery station planning can improve delivery efficiency significantly. However, existing delivery station locations are decided by experts, which requires much preliminary research and data collection work. It is not only time consuming but also expensive for logistics companies. Therefore, in this article, we propose a data-driven pipeline that can transfer expert knowledge among cities and automatically allocate delivery stations. Based on existing well-designed station location planning in the source city, we first train a model to learn the expert knowledge about delivery range selection for each station. Then we transfer the learned knowledge to a new city and design three strategies to select delivery stations for the new city. Due to the differences in characteristics among different cities, we adopt a transfer learning method to eliminate the domain difference so that the model can be adapted to a new city well. Finally, we conduct extensive experiments based on real-world datasets and find the proposed method can solve the problem well.},
  archive      = {J_TIST},
  author       = {Chenyu Hou and Bin Cao and Sijie Ruan and Jing Fan},
  doi          = {10.1145/3469084},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  number       = {4},
  pages        = {50:1–24},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {TLDS: A transfer-learning-based delivery station location selection pipeline},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). DILSA+: Predicting urban dispersal events through deep
survival analysis with enhanced urban features. <em>TIST</em>,
<em>12</em>(4), 49:1–25. (<a
href="https://doi.org/10.1145/3469085">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Urban dispersal events occur when an unexpectedly large number of people leave an area in a relatively short period of time. It is beneficial for the city authorities, such as law enforcement and city management, to have an advance knowledge of such events, as it can help them mitigate the safety risks and handle important challenges such as managing traffic, and so forth. Predicting dispersal events is also beneficial to Taxi drivers and/or ride-sharing services, as it will help them respond to an unexpected demand and gain competitive advantage. Large urban datasets such as detailed trip records and point of interest ( POI ) data make such predictions achievable. The related literature mainly focused on taxi demand prediction. The pattern of the demand was assumed to be repetitive and proposed methods aimed at capturing those patterns. However, dispersal events are, by definition, violations of those patterns and are, understandably, missed by the methods in the literature. We proposed a different approach in our prior work [32]. We showed that dispersal events can be predicted by learning the complex patterns of arrival and other features that precede them in time. We proposed a survival analysis formulation of this problem and proposed a two-stage framework (DILSA), where a deep learning model predicted the survival function at each point in time in the future. We used that prediction to determine the time of the dispersal event in the future, or its non-occurrence. However, DILSA is subject to a few limitations. First, based on evidence from the data, mobility patterns can vary through time at a given location. DILSA does not distinguish between different mobility patterns through time. Second, mobility patterns are also different for different locations. DILSA does not have the capability to directly distinguish between different locations based on their mobility patterns. In this article, we address these limitations by proposing a method to capture the interaction between POIs and mobility patterns and we create vector representations of locations based on their mobility patterns. We call our new method DILSA+. We conduct extensive case studies and experiments on the NYC Yellow taxi dataset from 2014 to 2016. Results show that DILSA+ can predict events in the next 5 hours with an F1-score of 0.66. It is significantly better than DILSA and the state-of-the-art deep learning approaches for taxi demand prediction.},
  archive      = {J_TIST},
  author       = {Amin Vahedian Khezerlou and Xun Zhou and Xinyi Li and W. Nick Street and Yanhua Li},
  doi          = {10.1145/3469085},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  number       = {4},
  pages        = {49:1–25},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {DILSA+: Predicting urban dispersal events through deep survival analysis with enhanced urban features},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Modeling customer experience in a contact center through
process log mining. <em>TIST</em>, <em>12</em>(4), 48:1–21. (<a
href="https://doi.org/10.1145/3468269">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The use of data mining and modeling methods in service industry is a promising avenue for optimizing current processes in a targeted manner, ultimately reducing costs and improving customer experience. However, the introduction of such tools in already established pipelines often must adapt to the way data is sampled and to its content. In this study, we tackle the challenge of characterizing and predicting customer experience having available only process log data with time-stamp information, without any ground truth feedback from the customers. As a case study, we consider the context of a contact center managed by TeleWare and analyze phone call logs relative to a two months span. We develop an approach to interpret the phone call process events registered in the logs and infer concrete points of improvement in the service management. Our approach is based on latent tree modeling and multi-class Naïve Bayes classification, which jointly allow us to infer a spectrum of customer experiences and test their predictability based on the current data sampling strategy. Moreover, such approach can overcome limitations in customer feedback collection and sharing across organizations, thus having wide applicability and being complementary to tools relying on more heavily constrained data.},
  archive      = {J_TIST},
  author       = {Teng Fu and Guido Zampieri and David Hodgson and Claudio Angione and Yifeng Zeng},
  doi          = {10.1145/3468269},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  number       = {4},
  pages        = {48:1–21},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Modeling customer experience in a contact center through process log mining},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Mining customers’ changeable electricity consumption for
effective load forecasting. <em>TIST</em>, <em>12</em>(4), 47:1–26. (<a
href="https://doi.org/10.1145/3466684">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most existing approaches for electricity load forecasting perform the task based on overall electricity consumption. However, using such a global methodology can affect load forecasting accuracy, as it does not consider the possibility that customers’ consumption behavior may change at any time. Predicting customers’ electricity consumption in the presence of unstable behaviors poses challenges to existing models. In this article, we propose a principled approach capable of handling customers’ changeable electricity consumption. We devise a network-based method that first builds and tracks clusters of customer consumption patterns over time. Then, on the evolving clusters, we develop a framework that exploits long short-term memory recurrent neural network and survival analysis techniques to forecast electricity consumption. Our experiments on real electricity consumption datasets illustrate the suitability of the proposed approach.},
  archive      = {J_TIST},
  author       = {Etienne Gael Tajeuna and Mohamed Bouguessa and Shengrui Wang},
  doi          = {10.1145/3466684},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  number       = {4},
  pages        = {47:1–26},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Mining customers’ changeable electricity consumption for effective load forecasting},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A comprehensive approach to on-board autonomy verification
and validation. <em>TIST</em>, <em>12</em>(4), 46:1–29. (<a
href="https://doi.org/10.1145/3472715">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep space missions are characterized by severely constrained communication links. To meet the needs of future missions and increase their scientific return, future space systems will require an increased level of autonomy on-board. In this work, we propose a comprehensive approach to on-board autonomy. We rely on model-based reasoning, and we consider many important (on-line and off-line) reasoning capabilities such as plan generation, validation, execution and monitoring, runtime diagnosis, and fault detection, identification, and recovery. The controlled platform is represented symbolically, and the reasoning capabilities are seen as symbolic manipulation of such formal model. We have developed a prototype of our framework, and we have integrated it within an on-board Autonomous Reasoning Engine. Finally, we have evaluated our approach on three case-studies inspired by real-world projects and characterized it in terms of reliability, availability, and performance.},
  archive      = {J_TIST},
  author       = {Marco Bozzano and Alessandro Cimatti and Marco Roveri},
  doi          = {10.1145/3472715},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  number       = {4},
  pages        = {46:1–29},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {A comprehensive approach to on-board autonomy verification and validation},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Nova: Value-based negotiation of norms. <em>TIST</em>,
<em>12</em>(4), 45:1–29. (<a
href="https://doi.org/10.1145/3465054">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Specifying a normative multiagent system (nMAS) is challenging, because different agents often have conflicting requirements. Whereas existing approaches can resolve clear-cut conflicts, tradeoffs might occur in practice among alternative nMAS specifications with no apparent resolution. To produce an nMAS specification that is acceptable to each agent, we model the specification process as a negotiation over a set of norms. We propose an agent-based negotiation framework, where agents’ requirements are represented as values (e.g., patient safety, privacy, and national security), and an agent revises the nMAS specification to promote its values by executing a set of norm revision rules that incorporate ontology-based reasoning. To demonstrate that our framework supports creating a transparent and accountable nMAS specification, we conduct an experiment with human participants who negotiate against our agent. Our findings show that our negotiation agent reaches better agreements (with small p -value and large effect size) faster than a baseline strategy. Moreover, participants perceive that our agent enables more collaborative and transparent negotiations than the baseline (with small p -value and large effect size in particular settings) toward reaching an agreement.},
  archive      = {J_TIST},
  author       = {Reyhan Aydoğan and Özgür Kafali and Furkan Arslan and Catholijn M. Jonker and Munindar P. Singh},
  doi          = {10.1145/3465054},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  number       = {4},
  pages        = {45:1–29},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Nova: Value-based negotiation of norms},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multiview common subspace clustering via coupled low rank
representation. <em>TIST</em>, <em>12</em>(4), 44:1–25. (<a
href="https://doi.org/10.1145/3465056">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view subspace clustering (MVSC) finds a shared structure in latent low-dimensional subspaces of multi-view data to enhance clustering performance. Nonetheless, we observe that most existing MVSC methods neglect the diversity in multi-view data by considering only the common knowledge to find a shared structure either directly or by merging different similarity matrices learned for each view. In the presence of noise, this predefined shared structure becomes a biased representation of the different views. Thus, in this article, we propose a MVSC method based on coupled low-rank representation to address the above limitation. Our method first obtains a low-rank representation for each view, constrained to be a linear combination of the view-specific representation and the shared representation by simultaneously encouraging the sparsity of view-specific one. Then, it uses the k -block diagonal regularizer to learn a manifold recovery matrix for each view through respective low-rank matrices to recover more manifold structures from them. In this way, the proposed method can find an ideal similarity matrix by approximating clustering projection matrices obtained from the recovery structures. Hence, this similarity matrix denotes our clustering structure with exactly k connected components by applying a rank constraint on the similarity matrix’s relaxed Laplacian matrix to avoid spectral post-processing of the low-dimensional embedding matrix. The core of our idea is such that we introduce dynamic approximation into the low-rank representation to allow the clustering structure and the shared representation to guide each other to learn cleaner low-rank matrices that would lead to a better clustering structure. Therefore, our approach is notably different from existing methods in which the local manifold structure of data is captured in advance. Extensive experiments on six benchmark datasets show that our method outperforms 10 similar state-of-the-art compared methods in six evaluation metrics.},
  archive      = {J_TIST},
  author       = {Stanley Ebhohimhen Abhadiomhen and Zhiyang Wang and Xiangjun Shen and Jianping Fan},
  doi          = {10.1145/3465056},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  number       = {4},
  pages        = {44:1–25},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Multiview common subspace clustering via coupled low rank representation},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). StarFL: Hybrid federated learning architecture for smart
urban computing. <em>TIST</em>, <em>12</em>(4), 43:1–23. (<a
href="https://doi.org/10.1145/3467956">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {From facial recognition to autonomous driving, Artificial Intelligence (AI) will transform the way we live and work over the next couple of decades. Existing AI approaches for urban computing suffer from various challenges, including dealing with synchronization and processing of vast amount of data generated from the edge devices, as well as the privacy and security of individual users, including their bio-metrics, locations, and itineraries. Traditional centralized-based approaches require data in each organization be uploaded to the central database, which may be prohibited by data protection acts, such as GDPR and CCPA. To decouple model training from the need to store the data in the cloud, a new training paradigm called Federated Learning (FL) is proposed. FL enables multiple devices to collaboratively learn a shared model while keeping the training data on devices locally, which can significantly mitigate privacy leakage risk. However, under urban computing scenarios, data are often communication-heavy, high-frequent, and asynchronized, posing new challenges to FL implementation. To handle these challenges, we propose a new hybrid federated learning architecture called StarFL. By combining with Trusted Execution Environment (TEE), Secure Multi-Party Computation (MPC), and (Beidou) satellites, StarFL enables safe key distribution, encryption, and decryption, and provides a verification mechanism for each participant to ensure the security of the local data. In addition, StarFL can provide accurate timestamp matching to facilitate synchronization of multiple clients. All these improvements make StarFL more applicable to the security-sensitive scenarios for the next generation of urban computing.},
  archive      = {J_TIST},
  author       = {Anbu Huang and Yang Liu and Tianjian Chen and Yongkai Zhou and Quan Sun and Hongfeng Chai and Qiang Yang},
  doi          = {10.1145/3467956},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  number       = {4},
  pages        = {43:1–23},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {StarFL: Hybrid federated learning architecture for smart urban computing},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Modeling complementarity in behavior data with multi-type
itemset embedding. <em>TIST</em>, <em>12</em>(4), 42:1–25. (<a
href="https://doi.org/10.1145/3458724">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {People are looking for complementary contexts, such as team members of complementary skills for project team building and/or reading materials of complementary knowledge for effective student learning, to make their behaviors more likely to be successful. Complementarity has been revealed by behavioral sciences as one of the most important factors in decision making. Existing computational models that learn low-dimensional context representations from behavior data have poor scalability and recent network embedding methods only focus on preserving the similarity between the contexts. In this work, we formulate a behavior entry as a set of context items and propose a novel representation learning method, Multi-type Itemset Embedding , to learn the context representations preserving the itemset structures. We propose a measurement of complementarity between context items in the embedding space. Experiments demonstrate both effectiveness and efficiency of the proposed method over the state-of-the-art methods on behavior prediction and context recommendation. We discover that the complementary contexts and similar contexts are significantly different in human behaviors.},
  archive      = {J_TIST},
  author       = {Daheng Wang and Qingkai Zeng and Nitesh V. Chawla and Meng Jiang},
  doi          = {10.1145/3458724},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  number       = {4},
  pages        = {42:1–25},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Modeling complementarity in behavior data with multi-type itemset embedding},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). VSumVis: Interactive visual understanding and diagnosis of
video summarization model. <em>TIST</em>, <em>12</em>(4), 41:1–28. (<a
href="https://doi.org/10.1145/3458928">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of mobile Internet, the popularity of video capture devices has brought a surge in multimedia video resources. Utilizing machine learning methods combined with well-designed features, we could automatically obtain video summarization to relax video resource consumption and retrieval issues. However, there always exists a gap between the summarization obtained by the model and the ones annotated by users. How to help users understand the difference, provide insights in improving the model, and enhance the trust in the model remains challenging in the current study. To address these challenges, we propose VSumVis under a user-centered design methodology, a visual analysis system with multi-feature examination and multi-level exploration, which could help users explore and analyze video content, as well as the intrinsic relationship that existed in our video summarization model. The system contains multiple coordinated views, i.e., video view, projection view, detail view, and sequential frames view. A multi-level analysis process to integrate video events and frames are presented with clusters and nodes visualization in our system. Temporal patterns concerning the difference between the manual annotation score and the saliency score produced by our model are further investigated and distinguished with sequential frames view. Moreover, we propose a set of rich user interactions that enable an in-depth, multi-faceted analysis of the features in our video summarization model. We conduct case studies and interviews with domain experts to provide anecdotal evidence about the effectiveness of our approach. Quantitative feedback from a user study confirms the usefulness of our visual system for exploring the video summarization model.},
  archive      = {J_TIST},
  author       = {Guodao Sun and Hao Wu and Lin Zhu and Chaoqing Xu and Haoran Liang and Binwei Xu and Ronghua Liang},
  doi          = {10.1145/3458928},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  number       = {4},
  pages        = {41:1–28},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {VSumVis: Interactive visual understanding and diagnosis of video summarization model},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). MKEL: Multiple kernel ensemble learning via unified ensemble
loss for image classification. <em>TIST</em>, <em>12</em>(4), 40:1–21.
(<a href="https://doi.org/10.1145/3457217">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, a novel ensemble model, called Multiple Kernel Ensemble Learning (MKEL), is developed by introducing a unified ensemble loss. Different from the previous multiple kernel learning (MKL) methods, which attempt to seek a linear combination of basis kernels as a unified kernel, our MKEL model aims to find multiple solutions in corresponding Reproducing Kernel Hilbert Spaces (RKHSs) simultaneously. To achieve this goal, multiple individual kernel losses are integrated into a unified ensemble loss. Therefore, each model can co-optimize to learn its optimal parameters by minimizing a unified ensemble loss in multiple RKHSs. Furthermore, we apply our proposed ensemble loss into the deep network paradigm and take the sub-network as a kernel mapping from the original input space into a feature space, named Deep-MKEL (D-MKEL). Our D-MKEL model can utilize the diversified deep individual sub-networks into a whole unified network to improve the classification performance. With this unified loss design, our D-MKEL model can make our network much wider than other traditional deep kernel networks and more parameters are learned and optimized. Experimental results on several mediate UCI classification and computer vision datasets demonstrate that our MKEL model can achieve the best classification performance among comparative MKL methods, such as Simple MKL, GMKL, Spicy MKL, and Matrix-Regularized MKL. On the contrary, experimental results on large-scale CIFAR-10 and SVHN datasets concretely show the advantages and potentialities of the proposed D-MKEL approach compared to state-of-the-art deep kernel methods.},
  archive      = {J_TIST},
  author       = {Xiangjun Shen and Kou Lu and Sumet Mehta and Jianming Zhang and Weifeng Liu and Jianping Fan and Zhengjun Zha},
  doi          = {10.1145/3457217},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  number       = {4},
  pages        = {40:1–21},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {MKEL: Multiple kernel ensemble learning via unified ensemble loss for image classification},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Linking multiple user identities of multiple services from
massive mobility traces. <em>TIST</em>, <em>12</em>(4), 39:1–28. (<a
href="https://doi.org/10.1145/3439817">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Understanding the linkability of online user identifiers (IDs) is critical to both service providers (for business intelligence) and individual users (for assessing privacy risks). Existing methods are designed to match IDs across two services but face key challenges of matching multiple services in practice, particularly when users have multiple IDs per service. In this article, we propose a novel system to link IDs across multiple services by exploring the spatial-temporal features of user activities, of which the core idea is that the same user&#39;s online IDs are more likely to repeatedly appear at the same location. Specifically, we first utilize a contact graph to capture the “co-location” of all IDs across multiple services. Based on this graph, we propose a set-wise matching algorithm to discover candidate ID sets and use Bayesian inference to generate confidence scores for candidate ranking, which is proved to be optimal. We evaluate our system using two real-world ground-truth datasets from an Internet service provider (4 services, 815K IDs) and Twitter-Foursquare (2 services, 770 IDs). Extensive results show that our system significantly outperforms the state-of-the-art algorithms in accuracy (AUC is higher by 0.1–0.2), and it is highly robust against data quality, matching order, and number of services.},
  archive      = {J_TIST},
  author       = {Huandong Wang and Yong Li and Gang Wang and Depeng Jin},
  doi          = {10.1145/3439817},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  number       = {4},
  pages        = {39:1–28},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Linking multiple user identities of multiple services from massive mobility traces},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A camera identity-guided distribution consistency method for
unsupervised multi-target domain person re-identification.
<em>TIST</em>, <em>12</em>(4), 38:1–18. (<a
href="https://doi.org/10.1145/3454130">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unsupervised domain adaptation (UDA) for person re-identification (re-ID) is a challenging task due to large variations in human classes, illuminations, camera views, and so on. Currently, existing UDA methods focus on two-domain adaptation and are generally trained on one labeled source set and adapted on the other unlabeled target set. In this article, we put forward a new issue on person re-ID, namely, unsupervised multi-target domain adaptation (UMDA). It involves one labeled source set and multiple unlabeled target sets, which is more reasonable for practical real-world applications. Enabling UMDA has to learn the consistency for multiple domains, which is significantly different from the UDA problem. To ensure distribution consistency and learn the discriminative embedding, we further propose the Camera Identity-guided Distribution Consistency method that performs an alignment operation for multiple domains. The camera identities are encoded into the image semantic information to facilitate the adaptation of features. According to our knowledge, this is the first attempt on the unsupervised multi-target domain adaptation learning. Extensive experiments are executed on Market-1501, DukeMTMC-reID, MSMT17, PersonX, and CUHK03, and our method has achieved very competitive re-ID accuracy in multi-target domains against numerous state-of-the-art methods.},
  archive      = {J_TIST},
  author       = {Jiajie Tian and Qihao Tang and Rui Li and Zhu Teng and Baopeng Zhang and Jianping Fan},
  doi          = {10.1145/3454130},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  number       = {4},
  pages        = {38:1–18},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {A camera identity-guided distribution consistency method for unsupervised multi-target domain person re-identification},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A comprehensive survey of the key technologies and
challenges surrounding vehicular ad hoc networks. <em>TIST</em>,
<em>12</em>(4), 37:1–30. (<a
href="https://doi.org/10.1145/3451984">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vehicular ad hoc networks ( VANETs ) and the services they support are an essential part of intelligent transportation. Through physical technologies, applications, protocols, and standards, they help to ensure traffic moves efficiently and vehicles operate safely. This article surveys the current state of play in VANETs development. The summarized and classified include the key technologies critical to the field, the resource-management and safety applications needed for smooth operations, the communications and data transmission protocols that support networking, and the theoretical and environmental constructs underpinning research and development, such as graph neural networks and the Internet of Things. Additionally, we identify and discuss several challenges facing VANETs, including poor safety, poor reliability, non-uniform standards, and low intelligence levels. Finally, we touch on hot technologies and techniques, such as reinforcement learning and 5G communications, to provide an outlook for the future of intelligent transportation systems.},
  archive      = {J_TIST},
  author       = {Zhenchang Xia and Jia Wu and Libing Wu and Yanjiao Chen and Jian Yang and Philip S. Yu},
  doi          = {10.1145/3451984},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  number       = {4},
  pages        = {37:1–30},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {A comprehensive survey of the key technologies and challenges surrounding vehicular ad hoc networks},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A scale and rotational invariant key-point detector based on
sparse coding. <em>TIST</em>, <em>12</em>(3), 36:1–19. (<a
href="https://doi.org/10.1145/3452009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most popular hand-crafted key-point detectors such as Harris corner, SIFT, SURF aim to detect corners, blobs, junctions, or other human-defined structures in images. Though being robust with some geometric transformations, unintended scenarios or non-uniform lighting variations could significantly degrade their performance. Hence, a new detector that is flexible with context change and simultaneously robust with both geometric and non-uniform illumination variations is very desirable. In this article, we propose a solution to this challenging problem by incorporating Scale and Rotation Invariant design (named SRI-SCK) into a recently developed Sparse Coding based Key-point detector (SCK). The SCK detector is flexible in different scenarios and fully invariant to affine intensity change, yet it is not designed to handle images with drastic scale and rotation changes. In SRI-SCK, the scale invariance is implemented with an image pyramid technique, while the rotation invariance is realized by combining multiple rotated versions of the dictionary used in the sparse coding step of SCK. Techniques for calculation of key-points’ characteristic scales and their sub-pixel accuracy positions are also proposed. Experimental results on three public datasets demonstrate that significantly high repeatability and matching score are achieved.},
  archive      = {J_TIST},
  author       = {Thanh Phuoc Hong and Ling Guan},
  doi          = {10.1145/3452009},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  number       = {3},
  pages        = {36:1–19},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {A scale and rotational invariant key-point detector based on sparse coding},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). PP-PG: Combining parameter perturbation with policy gradient
methods for effective and efficient explorations in deep reinforcement
learning. <em>TIST</em>, <em>12</em>(3), 35:1–21. (<a
href="https://doi.org/10.1145/3452008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Efficient and stable exploration remains a key challenge for deep reinforcement learning (DRL) operating in high-dimensional action and state spaces. Recently, a more promising approach by combining the exploration in the action space with the exploration in the parameters space has been proposed to get the best of both methods. In this article, we propose a new iterative and close-loop framework by combining the evolutionary algorithm (EA), which does explorations in a gradient-free manner directly in the parameters space with an actor-critic, and the deep deterministic policy gradient (DDPG) reinforcement learning algorithm, which does explorations in a gradient-based manner in the action space to make these two methods cooperate in a more balanced and efficient way. In our framework, the policies represented by the EA population (the parametric perturbation part) can evolve in a guided manner by utilizing the gradient information provided by the DDPG and the policy gradient part (DDPG) is used only as a fine-tuning tool for the best individual in the EA population to improve the sample efficiency. In particular, we propose a criterion to determine the training steps required for the DDPG to ensure that useful gradient information can be generated from the EA generated samples and the DDPG and EA part can work together in a more balanced way during each generation. Furthermore, within the DDPG part, our algorithm can flexibly switch between fine-tuning the same previous RL-Actor and fine-tuning a new one generated by the EA according to different situations to further improve the efficiency. Experiments on a range of challenging continuous control benchmarks demonstrate that our algorithm outperforms related works and offers a satisfactory trade-off between stability and sample efficiency.},
  archive      = {J_TIST},
  author       = {Shilei Li and Meng Li and Jiongming Su and Shaofei Chen and Zhimin Yuan and Qing Ye},
  doi          = {10.1145/3452008},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  number       = {3},
  pages        = {35:1–21},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {PP-PG: Combining parameter perturbation with policy gradient methods for effective and efficient explorations in deep reinforcement learning},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Vector-quantization-based topic modeling. <em>TIST</em>,
<em>12</em>(3), 34:1–30. (<a
href="https://doi.org/10.1145/3450946">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the purpose of learning and utilizing explicit and dense topic embeddings, we propose three variations of novel vector-quantization-based topic models (VQ-TMs): (1) Hard VQ-TM, (2) Soft VQ-TM, and (3) Multi-View Soft VQ-TM. The model family capitalize on vector quantization techniques, embedded input documents, and viewing words as mixtures of topics. Guided by a comprehensive set of evaluation metrics, we conduct systematic quantitative and qualitative empirical studies, and demonstrate the superior performance of VQ-TMs compared to important baseline models. Through a unique case study on code generation from natural language descriptions, we further illustrate the power of VQ-TMs in downstream tasks.},
  archive      = {J_TIST},
  author       = {Amulya Gupta and Zhu Zhang},
  doi          = {10.1145/3450946},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  number       = {3},
  pages        = {34:1–30},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Vector-quantization-based topic modeling},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Improved fake reviews detection model based on vertical
ensemble tri-training and active learning. <em>TIST</em>,
<em>12</em>(3), 33:1–19. (<a
href="https://doi.org/10.1145/3450285">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {People’s increasingly frequent online activity has generated a large number of reviews, whereas fake reviews can mislead users and harm their personal interests. In addition, it is not feasible to label reviews on a large scale because of the high cost of manual labeling. Therefore, to improve the detection performance by utilizing the unlabeled reviews, this article proposes a fake reviews detection model based on vertical ensemble tri-training and active learning (VETT-AL). The model combines the features of review text with the user behavior features as feature extraction. In the VETT-AL algorithm, the iterative process is divided into two parts: vertical integration within the group and horizontal integration among the groups. The intra-group integration is to integrate three original classifiers by using the previous iterative models of the classifiers. The inter-group integration is to adopt the active learning based on entropy to select the data with the highest confidence and label it, and as the result of that, the second generation classifiers are trained by the traditional process to improve the accuracy of the label. Experimental results show that the proposed model has a good classification performance.},
  archive      = {J_TIST},
  author       = {Chunyong Yin and Haoqi Cuan and Yuhang Zhu and Zhichao Yin},
  doi          = {10.1145/3450285},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  number       = {3},
  pages        = {33:1–19},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Improved fake reviews detection model based on vertical ensemble tri-training and active learning},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). GTAE: Graph transformer–based auto-encoders for
linguistic-constrained text style transfer. <em>TIST</em>,
<em>12</em>(3), 32:1–16. (<a
href="https://doi.org/10.1145/3448733">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Non-parallel text style transfer has attracted increasing research interests in recent years. Despite successes in transferring the style based on the encoder-decoder framework, current approaches still lack the ability to preserve the content and even logic of original sentences, mainly due to the large unconstrained model space or too simplified assumptions on latent embedding space. Since language itself is an intelligent product of humans with certain grammars and has a limited rule-based model space by its nature, relieving this problem requires reconciling the model capacity of deep neural networks with the intrinsic model constraints from human linguistic rules. To this end, we propose a method called Graph Transformer–based Auto-Encoder, which models a sentence as a linguistic graph and performs feature extraction and style transfer at the graph level, to maximally retain the content and the linguistic structure of original sentences. Quantitative experiment results on three non-parallel text style transfer tasks show that our model outperforms state-of-the-art methods in content preservation, while achieving comparable performance on transfer accuracy and sentence naturalness.},
  archive      = {J_TIST},
  author       = {Yukai Shi and Sen Zhang and Chenxing Zhou and Xiaodan Liang and Xiaojun Yang and Liang Lin},
  doi          = {10.1145/3448733},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  number       = {3},
  pages        = {32:1–16},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {GTAE: Graph Transformer–Based auto-encoders for linguistic-constrained text style transfer},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Improving action recognition via temporal and complementary
learning. <em>TIST</em>, <em>12</em>(3), 31:1–24. (<a
href="https://doi.org/10.1145/3447686">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we study the problem of video-based action recognition. We improve the action recognition performance by finding an effective temporal and appearance representation. For capturing the temporal representation, we introduce two temporal learning techniques for improving long-term temporal information modeling, specifically Temporal Relational Network and Temporal Second-Order Pooling-based Network. Moreover, we harness the representation using complementary learning techniques, specifically Global-Local Network and Fuse-Inception Network. Performance evaluation on three datasets (UCF101, HMDB-51, and Mini-Kinetics-200) demonstrated the superiority of the proposed framework compared to the 2D Deep ConvNets-based state-of-the-art techniques.},
  archive      = {J_TIST},
  author       = {Nour Eldin Elmadany and Yifeng He and Ling Guan},
  doi          = {10.1145/3447686},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  number       = {3},
  pages        = {31:1–24},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Improving action recognition via temporal and complementary learning},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A GDPR-compliant ecosystem for speech recognition with
transfer, federated, and evolutionary learning. <em>TIST</em>,
<em>12</em>(3), 30:1–19. (<a
href="https://doi.org/10.1145/3447687">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic Speech Recognition (ASR) is playing a vital role in a wide range of real-world applications. However, Commercial ASR solutions are typically “one-size-fits-all” products and clients are inevitably faced with the risk of severe performance degradation in field test. Meanwhile, with new data regulations such as the European Union’s General Data Protection Regulation (GDPR) coming into force, ASR vendors, which traditionally utilize the speech training data in a centralized approach, are becoming increasingly helpless to solve this problem, since accessing clients’ speech data is prohibited. Here, we show that by seamlessly integrating three machine learning paradigms (i.e., T ransfer learning, F ederated learning, and E volutionary learning (TFE)), we can successfully build a win-win ecosystem for ASR clients and vendors and solve all the aforementioned problems plaguing them. Through large-scale quantitative experiments, we show that with TFE, the clients can enjoy far better ASR solutions than the “one-size-fits-all” counterpart, and the vendors can exploit the abundance of clients’ data to effectively refine their own ASR products.},
  archive      = {J_TIST},
  author       = {Di Jiang and Conghui Tan and Jinhua Peng and Chaotao Chen and Xueyang Wu and Weiwei Zhao and Yuanfeng Song and Yongxin Tong and Chang Liu and Qian Xu and Qiang Yang and Li Deng},
  doi          = {10.1145/3447687},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  number       = {3},
  pages        = {30:1–19},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {A GDPR-compliant ecosystem for speech recognition with transfer, federated, and evolutionary learning},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Intelligent system of game-theory-based decision making in
smart sports industry. <em>TIST</em>, <em>12</em>(3), 29:1–23. (<a
href="https://doi.org/10.1145/3447986">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Internet of Things (IoT) technology backed by Artificial Intelligence (AI) techniques has been increasingly utilized for the realization of the Industry 4.0 vision. Conspicuously, this work provides a novel notion of the smart sports industry for provisioning efficient services in the sports arena. Specifically, an IoT-inspired framework has been proposed for real-time analysis of athlete performance. IoT data is utilized to quantify athlete performance in the terms of probability parameters of Probabilistic Measure of Performance (PMP) and Level of Performance Measure (LoPM). Moreover, a two-player game-theory-based mathematical framework has been presented for efficient decision modeling by the monitoring officials. The presented model is validated experimentally by deployment in District Sports Academy (DSA) for 60 days over four players. Based on the comparative analysis with state-of-the-art decision-modeling approaches, the proposed model acquired enhanced performance values in terms of Temporal Delay, Classification Efficiency, Statistical Efficacy, Correlation Analysis, and Reliability.},
  archive      = {J_TIST},
  author       = {Munish Bhatia},
  doi          = {10.1145/3447986},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  number       = {3},
  pages        = {29:1–23},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Intelligent system of game-theory-based decision making in smart sports industry},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). MetaStore: A task-adaptative meta-learning model for optimal
store placement with multi-city knowledge transfer. <em>TIST</em>,
<em>12</em>(3), 28:1–23. (<a
href="https://doi.org/10.1145/3447271">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optimal store placement aims to identify the optimal location for a new brick-and-mortar store that can maximize its sale by analyzing and mining users’ preferences from large-scale urban data. In recent years, the expansion of chain enterprises in new cities brings some challenges because of two aspects: (1) data scarcity in new cities, so most existing models tend to not work (i.e., overfitting), because the superior performance of these works is conditioned on large-scale training samples; (2) data distribution discrepancy among different cities, so knowledge learned from other cities cannot be utilized directly in new cities. In this article, we propose a task-adaptative model-agnostic meta-learning framework, namely, MetaStore, to tackle these two challenges and improve the prediction performance in new cities with insufficient data for optimal store placement, by transferring prior knowledge learned from multiple data-rich cities. Specifically, we develop a task-adaptative meta-learning algorithm to learn city-specific prior initializations from multiple cities, which is capable of handling the multimodal data distribution and accelerating the adaptation in new cities compared to other methods. In addition, we design an effective learning strategy for MetaStore to promote faster convergence and optimization by sampling high-quality data for each training batch in view of noisy data in practical applications. The extensive experimental results demonstrate that our proposed method leads to state-of-the-art performance compared with various baselines.},
  archive      = {J_TIST},
  author       = {Yan Liu and Bin Guo and Daqing Zhang and Djamal Zeghlache and Jingmin Chen and Sizhe Zhang and Dan Zhou and Xinlei Shi and Zhiwen Yu},
  doi          = {10.1145/3447271},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  number       = {3},
  pages        = {28:1–23},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {MetaStore: A task-adaptative meta-learning model for optimal store placement with multi-city knowledge transfer},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). MVGAN: Multi-view graph attention network for social event
detection. <em>TIST</em>, <em>12</em>(3), 27:1–24. (<a
href="https://doi.org/10.1145/3447270">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Social networks are critical sources for event detection thanks to the characteristics of publicity and dissemination. Unfortunately, the randomness and semantic sparsity of the social network text bring significant challenges to the event detection task. In addition to text, time is another vital element in reflecting events since events are often followed for a while. Therefore, in this article, we propose a novel method named Multi-View Graph Attention Network (MVGAN) for event detection in social networks. It enriches event semantics through both neighbor aggregation and multi-view fusion in a heterogeneous social event graph. Specifically, we first construct a heterogeneous graph by adding the hashtag to associate the isolated short texts and describe events comprehensively. Then, we learn view-specific representations of events through graph convolutional networks from the perspectives of text semantics and time distribution, respectively. Finally, we design a hashtag-based multi-view graph attention mechanism to capture the intrinsic interaction across different views and integrate the feature representations to discover events. Extensive experiments on public benchmark datasets demonstrate that MVGAN performs favorably against many state-of-the-art social network event detection algorithms. It also proves that more meaningful signals can contribute to improving the event detection effect in social networks, such as published time and hashtags.},
  archive      = {J_TIST},
  author       = {Wanqiu Cui and Junping Du and Dawei Wang and Feifei Kou and Zhe Xue},
  doi          = {10.1145/3447270},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  number       = {3},
  pages        = {27:1–24},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {MVGAN: Multi-view graph attention network for social event detection},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Attentive excitation and aggregation for bilingual referring
image segmentation. <em>TIST</em>, <em>12</em>(2), 26:1–17. (<a
href="https://doi.org/10.1145/3446345">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The goal of referring image segmentation is to identify the object matched with an input natural language expression. Previous methods only support English descriptions, whereas Chinese is also broadly used around the world, which limits the potential application of this task. Therefore, we propose to extend existing datasets with Chinese descriptions and preprocessing tools for training and evaluating bilingual referring segmentation models. In addition, previous methods also lack the ability to collaboratively learn channel-wise and spatial-wise cross-modal attention to well align visual and linguistic modalities. To tackle these limitations, we propose a Linguistic Excitation module to excite image channels guided by language information and a Linguistic Aggregation module to aggregate multimodal information based on image-language relationships. Since different levels of features from the visual backbone encode rich visual information, we also propose a Cross-Level Attentive Fusion module to fuse multilevel features gated by language information. Extensive experiments on four English and Chinese benchmarks show that our bilingual referring image segmentation model outperforms previous methods.},
  archive      = {J_TIST},
  author       = {Qianli Zhou and Tianrui Hui and Rong Wang and Haimiao Hu and Si Liu},
  doi          = {10.1145/3446345},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  number       = {2},
  pages        = {26:1–17},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Attentive excitation and aggregation for bilingual referring image segmentation},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Dynamic planning of bicycle stations in dockless public
bicycle-sharing system using gated graph neural network. <em>TIST</em>,
<em>12</em>(2), 25:1–22. (<a
href="https://doi.org/10.1145/3446342">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Benefiting from convenient cycling and flexible parking locations, the Dockless Public Bicycle-sharing (DL-PBS) network becomes increasingly popular in many countries. However, redundant and low-utility stations waste public urban space and maintenance costs of DL-PBS vendors. In this article, we propose a Bicycle Station Dynamic Planning (BSDP) system to dynamically provide the optimal bicycle station layout for the DL-PBS network. The BSDP system contains four modules: bicycle drop-off location clustering, bicycle-station graph modeling, bicycle-station location prediction, and bicycle-station layout recommendation. In the bicycle drop-off location clustering module, candidate bicycle stations are clustered from each spatio-temporal subset of the large-scale cycling trajectory records. In the bicycle-station graph modeling module, a weighted digraph model is built based on the clustering results and inferior stations with low station revenue and utility are filtered. Then, graph models across time periods are combined to create a graph sequence model. In the bicycle-station location prediction module, the GGNN model is used to train the graph sequence data and dynamically predict bicycle stations in the next period. In the bicycle-station layout recommendation module, the predicted bicycle stations are fine-tuned according to the government urban management plan, which ensures that the recommended station layout is conducive to city management, vendor revenue, and user convenience. Experiments on actual DL-PBS networks verify the effectiveness, accuracy, and feasibility of the proposed BSDP system.},
  archive      = {J_TIST},
  author       = {Jianguo Chen and Kenli Li and Keqin Li and Philip S. Yu and Zeng Zeng},
  doi          = {10.1145/3446342},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  number       = {2},
  pages        = {25:1–22},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Dynamic planning of bicycle stations in dockless public bicycle-sharing system using gated graph neural network},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Active learning for effectively fine-tuning transfer
learning to downstream task. <em>TIST</em>, <em>12</em>(2), 24:1–24. (<a
href="https://doi.org/10.1145/3446343">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Language model (LM) has become a common method of transfer learning in Natural Language Processing (NLP) tasks when working with small labeled datasets. An LM is pretrained using an easily available large unlabelled text corpus and is fine-tuned with the labelled data to apply to the target (i.e., downstream) task. As an LM is designed to capture the linguistic aspects of semantics, it can be biased to linguistic features. We argue that exposing an LM model during fine-tuning to instances that capture diverse semantic aspects (e.g., topical, linguistic, semantic relations) present in the dataset will improve its performance on the underlying task. We propose a Mixed Aspect Sampling (MAS) framework to sample instances that capture different semantic aspects of the dataset and use the ensemble classifier to improve the classification performance. Experimental results show that MAS performs better than random sampling as well as the state-of-the-art active learning models to abuse detection tasks where it is hard to collect the labelled data for building an accurate classifier.},
  archive      = {J_TIST},
  author       = {Md Abul Bashar and Richi Nayak},
  doi          = {10.1145/3446343},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  number       = {2},
  pages        = {24:1–24},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Active learning for effectively fine-tuning transfer learning to downstream task},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Causal mechanism transfer network for time series domain
adaptation in mechanical systems. <em>TIST</em>, <em>12</em>(2),
23:1–21. (<a href="https://doi.org/10.1145/3445033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data-driven models are becoming essential parts in modern mechanical systems, commonly used to capture the behavior of various equipment and varying environmental characteristics. Despite the advantages of these data-driven models on excellent adaptivity to high dynamics and aging equipment, they are usually hungry for massive labels, mostly contributed by human engineers at a high cost. Fortunately, domain adaptation enhances the model generalization by utilizing the labeled source data and the unlabeled target data. However, the mainstream domain adaptation methods cannot achieve ideal performance on time series data, since they assume that the conditional distributions are equal. This assumption works well in the static data but is inapplicable for the time series data. Even the first-order Markov dependence assumption requires the dependence between any two consecutive time steps. In this article, we assume that the causal mechanism is invariant and present our Causal Mechanism Transfer Network (CMTN) for time series domain adaptation. By capturing causal mechanisms of time series data, CMTN allows the data-driven models to exploit existing data and labels from similar systems, such that the resulting model on a new system is highly reliable even with limited data. We report our empirical results and lessons learned from two real-world case studies, on chiller plant energy optimization and boiler fault detection, which outperform the existing state-of-the-art method.},
  archive      = {J_TIST},
  author       = {Zijian Li and Ruichu Cai and Hong Wei Ng and Marianne Winslett and Tom Z. J. Fu and Boyan Xu and Xiaoyan Yang and Zhenjie Zhang},
  doi          = {10.1145/3445033},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  number       = {2},
  pages        = {23:1–21},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Causal mechanism transfer network for time series domain adaptation in mechanical systems},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Feature grouping–based trajectory outlier detection over
distributed streams. <em>TIST</em>, <em>12</em>(2), 22:1–23. (<a
href="https://doi.org/10.1145/3444753">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Owing to a wide variety of deployment of GPS -enabled devices, tremendous amounts of trajectories have been generated in distributed stream manner. It opens up new opportunities to track and analyze the moving behaviors of the entities. In this work, we focus on the issue of outlier detection over distributed trajectory streams, where the outliers refer to a few entities whose motion behaviors are significantly different from their local neighbors. In view of skewed distribution property and evolving nature of trajectory data, and on-the-fly detection requirement over distributed streams, we first design a high-efficiency outlier detection solution. It consists of identifying abnormal trajectory fragment and exceptional fragment cluster at the remote sites and then detecting abnormal evolving object at the coordinator site. Further, given that outlier detection accuracy would be damaged due to using inappropriate proximity thresholds or a few trajectory data not having sufficient neighbors at the remote sites, we extract proximity thresholds of different regions and spatial context relationship of each region from historical data to improve the precision. Built upon this is an improved version consisting of off-line modeling phase and on-line detection phase. During the on-line phase, the proximity thresholds that are derived from historical trajectories during the off-line phase are leveraged to assist in detecting abnormal trajectory fragments and exceptional fragment clusters at the remote sites. Additionally, at the coordinator site, the detection results of some remote sites can be refined by incorporating those of other remote sites with neighborhood relationship. Extensive experimental results on real data demonstrate that our proposed methods own high detection validity, less communication cost and linear scalability for online identifying outliers over distributed trajectory streams.},
  archive      = {J_TIST},
  author       = {Jiali Mao and Jiaye Liu and Cheqing Jin and Aoying Zhou},
  doi          = {10.1145/3444753},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  number       = {2},
  pages        = {22:1–23},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Feature grouping–based trajectory outlier detection over distributed streams},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Predicting attributes of nodes using network structure.
<em>TIST</em>, <em>12</em>(2), 21:1–23. (<a
href="https://doi.org/10.1145/3442390">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In many graphs such as social networks, nodes have associated attributes representing their behavior. Predicting node attributes in such graphs is an important task with applications in many domains like recommendation systems, privacy preservation, and targeted advertisement. Attribute values can be predicted by treating each node as a data point described by attributes and employing classification/regression algorithms. However, in social networks, there is complex interdependence between node attributes and pairwise interaction. For instance, attributes of nodes are influenced by their neighbors (social influence), and neighborhoods (friendships) between nodes are established based on pairwise (dis)similarity between their attributes (social selection). In this article, we establish that information in network topology is extremely useful in determining node attributes. In particular, we use self- and cross-proclivity measures (quantitative measures of how much a node attribute depends on the same and other attributes of its neighbors) to predict node attributes. We propose a feature map to represent a node with respect to a specific attribute a , using all attributes of its h -hop neighbors. Different classifiers are then learned on these feature vectors to predict the value of attribute a . We perform extensive experimentation on 10 real-world datasets and show that the proposed method significantly outperforms known approaches in terms of prediction accuracy.},
  archive      = {J_TIST},
  author       = {Sarwan Ali and Muhammad Haroon Shakeel and Imdadullah Khan and Safiullah Faizullah and Muhammad Asad Khan},
  doi          = {10.1145/3442390},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  number       = {2},
  pages        = {21:1–23},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Predicting attributes of nodes using network structure},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Disentangled item representation for recommender systems.
<em>TIST</em>, <em>12</em>(2), 20:1–20. (<a
href="https://doi.org/10.1145/3445811">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Item representations in recommendation systems are expected to reveal the properties of items. Collaborative recommender methods usually represent an item as one single latent vector. Nowadays the e-commercial platforms provide various kinds of attribute information for items (e.g., category, price, and style of clothing). Utilizing this attribute information for better item representations is popular in recent years. Some studies use the given attribute information as side information, which is concatenated with the item latent vector to augment representations. However, the mixed item representations fail to fully exploit the rich attribute information or provide explanation in recommender systems. To this end, we propose a fine-grained Disentangled Item Representation (DIR) for recommender systems in this article, where the items are represented as several separated attribute vectors instead of a single latent vector. In this way, the items are represented at the attribute level, which can provide fine-grained information of items in recommendation. We introduce a learning strategy, LearnDIR, which can allocate the corresponding attribute vectors to items. We show how DIR can be applied to two typical models, Matrix Factorization (MF) and Recurrent Neural Network (RNN). Experimental results on two real-world datasets show that the models developed under the framework of DIR are effective and efficient. Even using fewer parameters, the proposed model can outperform the state-of-the-art methods, especially in the cold-start situation. In addition, we make visualizations to show that our proposition can provide explanation for users in real-world applications.},
  archive      = {J_TIST},
  author       = {Zeyu Cui and Feng Yu and Shu Wu and Qiang Liu and Liang Wang},
  doi          = {10.1145/3445811},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  number       = {2},
  pages        = {20:1–20},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Disentangled item representation for recommender systems},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Flatter is better: Percentile transformations for
recommender systems. <em>TIST</em>, <em>12</em>(2), 19:1–16. (<a
href="https://doi.org/10.1145/3437910">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is well known that explicit user ratings in recommender systems are biased toward high ratings and that users differ significantly in their usage of the rating scale. Implementers usually compensate for these issues through rating normalization or the inclusion of a user bias term in factorization models. However, these methods adjust only for the central tendency of users’ distributions. In this work, we demonstrate that a lack of flatness in rating distributions is negatively correlated with recommendation performance. We propose a rating transformation model that compensates for skew in the rating distribution as well as its central tendency by converting ratings into percentile values as a pre-processing step before recommendation generation. This transformation flattens the rating distribution, better compensates for differences in rating distributions, and improves recommendation performance. We also show that a smoothed version of this transformation can yield more intuitive results for users with very narrow rating distributions. A comprehensive set of experiments, with state-of-the-art recommendation algorithms in four real-world datasets, show improved ranking performance for these percentile transformations.},
  archive      = {J_TIST},
  author       = {Masoud Mansoury and Robin Burke and Bamshad Mobasher},
  doi          = {10.1145/3437910},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  number       = {2},
  pages        = {19:1–16},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Flatter is better: Percentile transformations for recommender systems},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Indirectly supervised anomaly detection of clinically
meaningful health events from smart home data. <em>TIST</em>,
<em>12</em>(2), 18:1–18. (<a
href="https://doi.org/10.1145/3439870">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Anomaly detection techniques can extract a wealth of information about unusual events. Unfortunately, these methods yield an abundance of findings that are not of interest, obscuring relevant anomalies. In this work, we improve upon traditional anomaly detection methods by introducing Isudra, an Indirectly Supervised Detector of Relevant Anomalies from time series data. Isudra employs Bayesian optimization to select time scales, features, base detector algorithms, and algorithm hyperparameters that increase true positive and decrease false positive detection. This optimization is driven by a small amount of example anomalies, driving an indirectly supervised approach to anomaly detection. Additionally, we enhance the approach by introducing a warm-start method that reduces optimization time between similar problems. We validate the feasibility of Isudra to detect clinically relevant behavior anomalies from over 2M sensor readings collected in five smart homes, reflecting 26 health events. Results indicate that indirectly supervised anomaly detection outperforms both supervised and unsupervised algorithms at detecting instances of health-related anomalies such as falls, nocturia, depression, and weakness.},
  archive      = {J_TIST},
  author       = {Jessamyn Dahmen and Diane J. Cook},
  doi          = {10.1145/3439870},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  number       = {2},
  pages        = {18:1–18},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Indirectly supervised anomaly detection of clinically meaningful health events from smart home data},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Constraint-based scheduling for paint shops in the
automotive supply industry. <em>TIST</em>, <em>12</em>(2), 17:1–25. (<a
href="https://doi.org/10.1145/3430710">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Factories in the automotive supply industry paint a large number of items requested by car manufacturing companies on a daily basis. As these factories face numerous constraints and optimization objectives, finding a good schedule becomes a challenging task in practice, and full-time employees are expected to manually create feasible production plans. In this study, we propose novel constraint programming models for a real-life paint shop scheduling problem. We evaluate and compare our models experimentally by performing a series of benchmark experiments using real-life instances in the industry. We also show that the decision variant of the paint shop scheduling problem is NP-complete.},
  archive      = {J_TIST},
  author       = {Felix Winter and Nysret Musliu},
  doi          = {10.1145/3430710},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  number       = {2},
  pages        = {17:1–25},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Constraint-based scheduling for paint shops in the automotive supply industry},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). RHUPS: Mining recent high utility patterns with sliding
window–based arrival time control over data streams. <em>TIST</em>,
<em>12</em>(2), 16:1–27. (<a
href="https://doi.org/10.1145/3430767">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Databases that deal with the real world have various characteristics. New data is continuously inserted over time without limiting the length of the database, and a variety of information about the items constituting the database is contained. Recently generated data has a greater influence than the previously generated data. These are called the time-sensitive non-binary stream databases, and they include databases such as web-server click data, market sales data, data from sensor networks, and network traffic measurement. Many high utility pattern mining and stream pattern mining methods have been proposed so far. However, they have a limitation that they are not suitable to analyze these databases, because they find valid patterns by analyzing a database with only some of the features described above. Therefore, knowledge-based software about how to find meaningful information efficiently by analyzing databases with these characteristics is required. In this article, we propose an intelligent information system that calculates the influence of the insertion time of each batch in a large-scale stream database by applying the sliding window model and mines recent high utility patterns without generating candidate patterns. In addition, a novel list-based data structure is suggested for a fast and efficient management of the time-sensitive stream databases. Moreover, our technique is compared with state-of-the-art algorithms through various experiments using real datasets and synthetic datasets. The experimental results show that our approach outperforms the previously proposed methods in terms of runtime, memory usage, and scalability.},
  archive      = {J_TIST},
  author       = {Yoonji Baek and Unil Yun and Heonho Kim and Hyoju Nam and Hyunsoo Kim and Jerry Chun-Wei Lin and Bay Vo and Witold Pedrycz},
  doi          = {10.1145/3430767},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  number       = {2},
  pages        = {16:1–27},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {RHUPS: Mining recent high utility patterns with sliding window–based arrival time control over data streams},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Aspect-aware response generation for multimodal dialogue
system. <em>TIST</em>, <em>12</em>(2), 15:1–33. (<a
href="https://doi.org/10.1145/3430752">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodality in dialogue systems has opened up new frontiers for the creation of robust conversational agents. Any multimodal system aims at bridging the gap between language and vision by leveraging diverse and often complementary information from image, audio, and video, as well as text. For every task-oriented dialog system, different aspects of the product or service are crucial for satisfying the user’s demands. Based upon the aspect, the user decides upon selecting the product or service. The ability to generate responses with the specified aspects in a goal-oriented dialogue setup facilitates user satisfaction by fulfilling the user’s goals. Therefore, in our current work, we propose the task of aspect controlled response generation in a multimodal task-oriented dialog system. We employ a multimodal hierarchical memory network for generating responses that utilize information from both text and images. As there was no readily available data for building such multimodal systems, we create a Multi-Domain Multi-Modal Dialog (MDMMD++) dataset. The dataset comprises the conversations having both text and images belonging to the four different domains, such as hotels, restaurants, electronics, and furniture. Quantitative and qualitative analysis on the newly created MDMMD++ dataset shows that the proposed methodology outperforms the baseline models for the proposed task of aspect controlled response generation.},
  archive      = {J_TIST},
  author       = {Mauajama Firdaus and Nidhi Thakur and Asif Ekbal},
  doi          = {10.1145/3430752},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  number       = {2},
  pages        = {15:1–33},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Aspect-aware response generation for multimodal dialogue system},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Conditional text generation for harmonious human-machine
interaction. <em>TIST</em>, <em>12</em>(2), 14:1–50. (<a
href="https://doi.org/10.1145/3439816">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, with the development of deep learning, text-generation technology has undergone great changes and provided many kinds of services for human beings, such as restaurant reservation and daily communication. The automatically generated text is becoming more and more fluent so researchers begin to consider more anthropomorphic text-generation technology, that is, the conditional text generation, including emotional text generation, personalized text generation, and so on. Conditional Text Generation (CTG) has thus become a research hotspot. As a promising research field, we find that much attention has been paid to exploring it. Therefore, we aim to give a comprehensive review of the new research trends of CTG. We first summarize several key techniques and illustrate the technical evolution route in the field of neural text generation, based on the concept model of CTG. We further make an investigation of existing CTG fields and propose several general learning models for CTG. Finally, we discuss the open issues and promising research directions of CTG.},
  archive      = {J_TIST},
  author       = {Bin Guo and Hao Wang and Yasan Ding and Wei Wu and Shaoyang Hao and Yueqi Sun and Zhiwen Yu},
  doi          = {10.1145/3439816},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  number       = {2},
  pages        = {14:1–50},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Conditional text generation for harmonious human-machine interaction},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Industrial federated topic modeling. <em>TIST</em>,
<em>12</em>(1), 2:1–22. (<a
href="https://doi.org/10.1145/3418283">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Probabilistic topic modeling has been applied in a variety of industrial applications. Training a high-quality model usually requires a massive amount of data to provide comprehensive co-occurrence information for the model to learn. However, industrial data such as medical or financial records are often proprietary or sensitive, which precludes uploading to data centers. Hence, training topic models in industrial scenarios using conventional approaches faces a dilemma: A party (i.e., a company or institute) has to either tolerate data scarcity or sacrifice data privacy. In this article, we propose a framework named Industrial Federated Topic Modeling (iFTM), in which multiple parties collaboratively train a high-quality topic model by simultaneously alleviating data scarcity and maintaining immunity to privacy adversaries. iFTM is inspired by federated learning, supports two representative topic models (i.e., Latent Dirichlet Allocation and SentenceLDA) in industrial applications, and consists of novel techniques such as private Metropolis-Hastings, topic-wise normalization, and heterogeneous model integration. We conduct quantitative evaluations to verify the effectiveness of iFTM and deploy iFTM in two real-life applications to demonstrate its utility. Experimental results verify iFTM’s superiority over conventional topic modeling.},
  archive      = {J_TIST},
  author       = {Di Jiang and Yongxin Tong and Yuanfeng Song and Xueyang Wu and Weiwei Zhao and Jinhua Peng and Rongzhong Lian and Qian Xu and Qiang Yang},
  doi          = {10.1145/3418283},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  number       = {1},
  pages        = {2:1–22},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Industrial federated topic modeling},
  volume       = {12},
  year         = {2021},
}
</textarea>
</details></li>
</ul>

</body>
</html>
