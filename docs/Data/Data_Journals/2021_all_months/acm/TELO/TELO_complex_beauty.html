<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>TELO_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="telo---18">TELO - 18</h2>
<ul>
<li><details>
<summary>
(2021). A learning-based innovized progress operator for faster
convergence in evolutionary multi-objective optimization. <em>TELO</em>,
<em>2</em>(1), 1:1–29. (<a
href="https://doi.org/10.1145/3474059">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning effective problem information from already explored search space in an optimization run, and utilizing it to improve the convergence of subsequent solutions, have represented important directions in Evolutionary Multi-objective Optimization (EMO) research. In this article, a machine learning (ML)-assisted approach is proposed that: (a) maps the solutions from earlier generations of an EMO run to the current non-dominated solutions in the decision space ; (b) learns the salient patterns in the mapping using an ML method, here an artificial neural network (ANN); and (c) uses the learned ML model to advance some of the subsequent offspring solutions in an adaptive manner. Such a multi-pronged approach, quite different from the popular surrogate-modeling methods, leads to what is here referred to as the Innovized Progress (IP) operator. On several test and engineering problems involving two and three objectives, with and without constraints, it is shown that an EMO algorithm assisted by the IP operator offers faster convergence behavior, compared to its base version independent of the IP operator. The results are encouraging, pave a new path for the performance improvement of EMO algorithms, and set the motivation for further exploration on more challenging problems.},
  archive      = {J_TELO},
  author       = {Sukrit Mittal and Dhish Kumar Saxena and Kalyanmoy Deb and Erik D. Goodman},
  doi          = {10.1145/3474059},
  journal      = {ACM Transactions on Evolutionary Learning and Optimization},
  number       = {1},
  pages        = {1:1–29},
  shortjournal = {ACM Trans. Evol. Learn. Optim.},
  title        = {A learning-based innovized progress operator for faster convergence in evolutionary multi-objective optimization},
  volume       = {2},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A survey on recent progress in the theory of evolutionary
algorithms for discrete optimization. <em>TELO</em>, <em>1</em>(4),
16:1–43. (<a href="https://doi.org/10.1145/3472304">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The theory of evolutionary computation for discrete search spaces has made significant progress since the early 2010s. This survey summarizes some of the most important recent results in this research area. It discusses fine-grained models of runtime analysis of evolutionary algorithms, highlights recent theoretical insights on parameter tuning and parameter control, and summarizes the latest advances for stochastic and dynamic problems. We regard how evolutionary algorithms optimize submodular functions, and we give an overview over the large body of recent results on estimation of distribution algorithms. Finally, we present the state of the art of drift analysis, one of the most powerful analysis technique developed in this field.},
  archive      = {J_TELO},
  author       = {Benjamin Doerr and Frank Neumann},
  doi          = {10.1145/3472304},
  journal      = {ACM Transactions on Evolutionary Learning and Optimization},
  number       = {4},
  pages        = {16:1–43},
  shortjournal = {ACM Trans. Evol. Learn. Optim.},
  title        = {A survey on recent progress in the theory of evolutionary algorithms for discrete optimization},
  volume       = {1},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Efficient computation of probabilistic dominance in
multi-objective optimization. <em>TELO</em>, <em>1</em>(4), 15:1–26. (<a
href="https://doi.org/10.1145/3469801">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Real-world problems typically require the simultaneous optimization of multiple, often conflicting objectives. Many of these multi-objective optimization problems are characterized by wide ranges of uncertainties in their decision variables or objective functions. To cope with such uncertainties, stochastic and robust optimization techniques are widely studied aiming to distinguish candidate solutions with uncertain objectives specified by confidence intervals, probability distributions, sampled data, or uncertainty sets. In this scope, this article first introduces a novel empirical approach for the comparison of candidate solutions with uncertain objectives that can follow arbitrary distributions. The comparison is performed through accurate and efficient calculations of the probability that one solution dominates the other in terms of each uncertain objective. Second, such an operator can be flexibly used and combined with many existing multi-objective optimization frameworks and techniques by just substituting their standard comparison operator, thus easily enabling the Pareto front optimization of problems with multiple uncertain objectives. Third, a new benchmark for evaluating uncertainty-aware optimization techniques is introduced by incorporating different types of uncertainties into a well-known benchmark for multi-objective optimization problems. Fourth, the new comparison operator and benchmark suite are integrated into an existing multi-objective optimization framework that features a selection of multi-objective optimization problems and algorithms. Fifth, the efficiency in terms of performance and execution time of the proposed comparison operator is evaluated on the introduced uncertainty benchmark. Finally, statistical tests are applied giving evidence of the superiority of the new comparison operator in terms of \(\epsilon\)-dominance and attainment surfaces in comparison to previously proposed approaches.},
  archive      = {J_TELO},
  author       = {Faramarz Khosravi and Alexander Rass and Jürgen Teich},
  doi          = {10.1145/3469801},
  journal      = {ACM Transactions on Evolutionary Learning and Optimization},
  number       = {4},
  pages        = {15:1–26},
  shortjournal = {ACM Trans. Evol. Learn. Optim.},
  title        = {Efficient computation of probabilistic dominance in multi-objective optimization},
  volume       = {1},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Reproducibility in evolutionary computation. <em>TELO</em>,
<em>1</em>(4), 14:1–21. (<a
href="https://doi.org/10.1145/3466624">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Experimental studies are prevalent in Evolutionary Computation ( EC ), and concerns about the reproducibility and replicability of such studies have increased in recent times, reflecting similar concerns in other scientific fields. In this article, we discuss, within the context of EC, the different types of reproducibility and suggest a classification that refines the badge system of the Association of Computing Machinery ( ACM ) adopted by ACM Transactions on Evolutionary Learning and Optimization ( TELO ). We identify cultural and technical obstacles to reproducibility in the EC field. Finally, we provide guidelines and suggest tools that may help to overcome some of these reproducibility obstacles.},
  archive      = {J_TELO},
  author       = {Manuel López-ibáñez and Juergen Branke and Luís Paquete},
  doi          = {10.1145/3466624},
  journal      = {ACM Transactions on Evolutionary Learning and Optimization},
  number       = {4},
  pages        = {14:1–21},
  shortjournal = {ACM Trans. Evol. Learn. Optim.},
  title        = {Reproducibility in evolutionary computation},
  volume       = {1},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Precise runtime analysis for plateau functions.
<em>TELO</em>, <em>1</em>(4), 13:1–28. (<a
href="https://doi.org/10.1145/3469800">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To gain a better theoretical understanding of how evolutionary algorithms (EAs) cope with plateaus of constant fitness, we propose the n -dimensional Plateau k function as natural benchmark and analyze how different variants of the (1 + 1) EA optimize it. The Plateau k function has a plateau of second-best fitness in a ball of radius k around the optimum. As evolutionary algorithm, we regard the (1 + 1) EA using an arbitrary unbiased mutation operator. Denoting by α the random number of bits flipped in an application of this operator and assuming that Pr [α = 1] has at least some small sub-constant value, we show the surprising result that for all constant k ≥ 2, the runtime T follows a distribution close to the geometric one with success probability equal to the probability to flip between 1 and k bits divided by the size of the plateau. Consequently, the expected runtime is the inverse of this number, and thus only depends on the probability to flip between 1 and k bits, but not on other characteristics of the mutation operator. Our result also implies that the optimal mutation rate for standard bit mutation here is approximately k/(en) . Our main analysis tool is a combined analysis of the Markov chains on the search point space and on the Hamming level space, an approach that promises to be useful also for other plateau problems.},
  archive      = {J_TELO},
  author       = {Denis Antipov and Benjamin Doerr},
  doi          = {10.1145/3469800},
  journal      = {ACM Transactions on Evolutionary Learning and Optimization},
  number       = {4},
  pages        = {13:1–28},
  shortjournal = {ACM Trans. Evol. Learn. Optim.},
  title        = {Precise runtime analysis for plateau functions},
  volume       = {1},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Constraint-objective cooperative coevolution for large-scale
constrained optimization. <em>TELO</em>, <em>1</em>(3), 12:1–26. (<a
href="https://doi.org/10.1145/3469036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large-scale optimization problems and constrained optimization problems have attracted considerable attention in the swarm and evolutionary intelligence communities and exemplify two common features of real problems, i.e., a large scale and constraint limitations. However, only a little work on solving large-scale continuous constrained optimization problems exists. Moreover, the types of benchmarks proposed for large-scale continuous constrained optimization algorithms are not comprehensive at present. In this article, first, a constraint-objective cooperative coevolution (COCC) framework is proposed for large-scale continuous constrained optimization problems, which is based on the dual nature of the objective and constraint functions: modular and imbalanced components. The COCC framework allocates the computing resources to different components according to the impact of objective values and constraint violations. Second, a benchmark for large-scale continuous constrained optimization is presented, which takes into account the modular nature, as well as both imbalanced and overlapping characteristics of components. Finally, three different evolutionary algorithms are embedded into the COCC framework for experiments, and the experimental results show that COCC performs competitively.},
  archive      = {J_TELO},
  author       = {Peilan Xu and Wenjian Luo and Xin Lin and Jiajia Zhang and Yingying Qiao and Xuan Wang},
  doi          = {10.1145/3469036},
  journal      = {ACM Transactions on Evolutionary Learning and Optimization},
  number       = {3},
  pages        = {12:1–26},
  shortjournal = {ACM Trans. Evol. Learn. Optim.},
  title        = {Constraint-objective cooperative coevolution for large-scale constrained optimization},
  volume       = {1},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Emergent tangled program graphs in partially observable
recursive forecasting and ViZDoom navigation tasks. <em>TELO</em>,
<em>1</em>(3), 11:1–41. (<a
href="https://doi.org/10.1145/3468857">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modularity represents a recurring theme in the attempt to scale evolution to the design of complex systems. However, modularity rarely forms the central theme of an artificial approach to evolution. In this work, we report on progress with the recently proposed Tangled Program Graph (TPG) framework in which programs are modules. The combination of the TPG representation and its variation operators enable both teams of programs and graphs of teams of programs to appear in an emergent process. The original development of TPG was limited to tasks with, for the most part, complete information. This work details two recent approaches for scaling TPG to tasks that are dominated by partially observable sources of information using different formulations of indexed memory. One formulation emphasizes the incremental construction of memory, again as an emergent process, resulting in a distributed view of state. The second formulation assumes a single global instance of memory and develops it as a communication medium, thus a single global view of state. The resulting empirical evaluation demonstrates that TPG equipped with memory is able to solve multi-task recursive time-series forecasting problems and visual navigation tasks expressed in two levels of a commercial first-person shooter environment.},
  archive      = {J_TELO},
  author       = {Stephen Kelly and Robert J. Smith and Malcolm I. Heywood and Wolfgang Banzhaf},
  doi          = {10.1145/3468857},
  journal      = {ACM Transactions on Evolutionary Learning and Optimization},
  number       = {3},
  pages        = {11:1–41},
  shortjournal = {ACM Trans. Evol. Learn. Optim.},
  title        = {Emergent tangled program graphs in partially observable recursive forecasting and ViZDoom navigation tasks},
  volume       = {1},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A comparison of learning classifier systems’ rule compaction
algorithms for knowledge visualization. <em>TELO</em>, <em>1</em>(3),
10:1–38. (<a href="https://doi.org/10.1145/3468166">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning Classifier Systems (LCSs) are a paradigm of rule-based evolutionary computation (EC). LCSs excel in data-mining tasks regarding helping humans to understand the explored problem, often through visualizing the discovered patterns linking features to classes. Due to the stochastic nature of EC, LCSs unavoidably produce and keep redundant rules, which obscure the patterns. Thus, rule compaction methods are invoked to produce a better population by removing problematic rules. Previously, compaction methods have neither been tested on large-scale problems nor been assessed on the performance of capturing patterns. We review and test the most popular compaction algorithms, finding that across multiple LCSs’ populations for the same task, although the redundant rules can be different, the accurate rules are common. Furthermore, the patterns contained consistently refer to the nature of the explored domain, e.g., the data distribution or the importance of features for determining actions. This extends the [ O ] set hypothesis proposed by Butz et al. [1], in which an LCS is expected to evolve a minimal number of non-overlapped rules to represent an addressed domain. Two new compaction algorithms are introduced to search at the rule level and the population level by compacting multiple LCSs’ populations. Two visualization methods are employed for verifying the interpretability of these populations. Successful compaction is demonstrated on complex and real problems with clean datasets, e.g., the 11-bits Majority-On problem that requires 924 different interacting rules in the optimal solution to be uniquely identified to enable correct visualization. For the first time, the patterns contained in learned models for the large-scale 70-bits Multiplexer problem are visualized successfully.},
  archive      = {J_TELO},
  author       = {Yi Liu and Will N. Browne and Bing Xue},
  doi          = {10.1145/3468166},
  journal      = {ACM Transactions on Evolutionary Learning and Optimization},
  number       = {3},
  pages        = {10:1–38},
  shortjournal = {ACM Trans. Evol. Learn. Optim.},
  title        = {A comparison of learning classifier systems’ rule compaction algorithms for knowledge visualization},
  volume       = {1},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Is our archiving reliable? Multiobjective archiving methods
on “simple” artificial input sequences. <em>TELO</em>, <em>1</em>(3),
9:1–19. (<a href="https://doi.org/10.1145/3465335">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In evolutionary multiobjective optimisation ( EMO ), archiving is a common component that maintains an (external or internal) set during the search process, typically with a fixed size, in order to provide a good representation of high-quality solutions produced. Such an archive set can be used solely to store the final results shown to the decision maker, but in many cases may participate in the process of producing solutions (e.g., as a solution pool where the parental solutions are selected). Over the last three decades, archiving stands as an important issue in EMO, leading to the emergence of various methods such as those based on Pareto, indicator, or decomposition criteria. Such methods have demonstrated their effectiveness in literature and have been believed to be good options to many problems, particularly those having a regular Pareto front shape, e.g., a simplex shape. In this article, we challenge this belief. We do this through artificially constructing several sequences with extremely simple shapes, i.e., 1D/2D simplex Pareto front. We show the struggle of predominantly used archiving methods which have been deemed to well handle such shapes. This reveals that the order of solutions entering the archive matters, and that current EMO algorithms may not be fully capable of maintaining a representative population on problems with linear Pareto fronts even in the case that all of their optimal solutions can be found.},
  archive      = {J_TELO},
  author       = {Miqing Li},
  doi          = {10.1145/3465335},
  journal      = {ACM Transactions on Evolutionary Learning and Optimization},
  number       = {3},
  pages        = {9:1–19},
  shortjournal = {ACM Trans. Evol. Learn. Optim.},
  title        = {Is our archiving reliable? multiobjective archiving methods on “Simple” artificial input sequences},
  volume       = {1},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Evolution of activation functions: An empirical
investigation. <em>TELO</em>, <em>1</em>(2), 8:1–36. (<a
href="https://doi.org/10.1145/3464384">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The hyper-parameters of a neural network are traditionally designed through a time-consuming process of trial and error that requires substantial expert knowledge. Neural Architecture Search algorithms aim to take the human out of the loop by automatically finding a good set of hyper-parameters for the problem at hand. These algorithms have mostly focused on hyper-parameters such as the architectural configurations of the hidden layers and the connectivity of the hidden neurons, but there has been relatively little work on automating the search for completely new activation functions, which are one of the most crucial hyperparameters to choose. There are some widely used activation functions nowadays that are simple and work well, but nonetheless, there has been some interest in finding better activation functions. The work in the literature has mostly focused on designing new activation functions by hand or choosing from a set of predefined functions while this work presents an evolutionary algorithm to automate the search for completely new activation functions. We compare these new evolved activation functions to other existing and commonly used activation functions. The results are favorable and are obtained from averaging the performance of the activation functions found over 30 runs, with experiments being conducted on 10 different datasets and architectures to ensure the statistical robustness of the study.},
  archive      = {J_TELO},
  author       = {Andrew Nader and Danielle Azar},
  doi          = {10.1145/3464384},
  journal      = {ACM Transactions on Evolutionary Learning and Optimization},
  number       = {2},
  pages        = {8:1–36},
  shortjournal = {ACM Trans. Evol. Learn. Optim.},
  title        = {Evolution of activation functions: An empirical investigation},
  volume       = {1},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Genetic improvement of data for maths functions.
<em>TELO</em>, <em>1</em>(2), 7:1–30. (<a
href="https://doi.org/10.1145/3461016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We use continuous optimisation and manual code changes to evolve up to 1024 Newton-Raphson numerical values embedded in an open source GNU C library glibc square root sqrt to implement a double precision cube root routine cbrt, binary logarithm log2 and reciprocal square root function for C in seconds. The GI inverted square root x -1/2 is far more accurate than Quake’s InvSqrt, Quare root. GI shows potential for automatically creating mobile or low resource mote smart dust bespoke custom mathematical libraries with new functionality.},
  archive      = {J_TELO},
  author       = {William B. Langdon and Oliver Krauss},
  doi          = {10.1145/3461016},
  journal      = {ACM Transactions on Evolutionary Learning and Optimization},
  number       = {2},
  pages        = {7:1–30},
  shortjournal = {ACM Trans. Evol. Learn. Optim.},
  title        = {Genetic improvement of data for maths functions},
  volume       = {1},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Spatial coevolution for generative adversarial network
training. <em>TELO</em>, <em>1</em>(2), 6:1–28. (<a
href="https://doi.org/10.1145/3458845">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generative Adversarial Networks (GANs) are difficult to train because of pathologies such as mode and discriminator collapse. Similar pathologies have been studied and addressed in competitive evolutionary computation by increased diversity. We study a system, Lipizzaner, that combines spatial coevolution with gradient-based learning to improve the robustness and scalability of GAN training. We study different features of Lipizzaner’s evolutionary computation methodology. Our ablation experiments determine that communication, selection, parameter optimization, and ensemble optimization each, as well as in combination, play critical roles. Lipizzaner succumbs less frequently to critical collapses and, as a side benefit, demonstrates improved performance. In addition, we show a GAN-training feature of Lipizzaner: the ability to train simultaneously with different loss functions in the gradient descent parameter learning framework of each GAN at each cell. We use an image generation problem to show that different loss function combinations result in models with better accuracy and more diversity in comparison to other existing evolutionary GAN models. Finally, Lipizzaner with multiple loss function options promotes the best model diversity while requiring a large grid size for adequate accuracy.},
  archive      = {J_TELO},
  author       = {Erik Hemberg and Jamal Toutouh and Abdullah Al-Dujaili and Tom Schmiedlechner and Una-May O’Reilly},
  doi          = {10.1145/3458845},
  journal      = {ACM Transactions on Evolutionary Learning and Optimization},
  number       = {2},
  pages        = {6:1–28},
  shortjournal = {ACM Trans. Evol. Learn. Optim.},
  title        = {Spatial coevolution for generative adversarial network training},
  volume       = {1},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A novel approach to designing surrogate-assisted genetic
algorithms by combining efficient learning of walsh coefficients and
dependencies. <em>TELO</em>, <em>1</em>(2), 5:1–23. (<a
href="https://doi.org/10.1145/3453141">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Surrogate-assisted evolutionary algorithms have the potential to be of high value for real-world optimization problems when fitness evaluations are expensive, limiting the number of evaluations that can be performed. In this article, we consider the domain of pseudo-Boolean functions in a black-box setting. Moreover, instead of using a surrogate model as an approximation of a fitness function, we propose to precisely learn the coefficients of the Walsh decomposition of a fitness function and use the Walsh decomposition as a surrogate. If the coefficients are learned correctly, then the Walsh decomposition values perfectly match with the fitness function, and, thus, the optimal solution to the problem can be found by optimizing the surrogate without any additional evaluations of the original fitness function. It is known that the Walsh coefficients can be efficiently learned for pseudo-Boolean functions with k -bounded epistasis and known problem structure. We propose to learn dependencies between variables first and, therefore, substantially reduce the number of Walsh coefficients to be calculated. After the accurate Walsh decomposition is obtained, the surrogate model is optimized using GOMEA, which is considered to be a state-of-the-art binary optimization algorithm. We compare the proposed approach with standard GOMEA and two other Walsh decomposition-based algorithms. The benchmark functions in the experiments are well-known trap functions, NK-landscapes, MaxCut, and MAX3SAT problems. The experimental results demonstrate that the proposed approach is scalable at the supposed complexity of O (ℓ log ℓ) function evaluations when the number of subfunctions is O (ℓ) and all subfunctions are k -bounded, outperforming all considered algorithms.},
  archive      = {J_TELO},
  author       = {Arkadiy Dushatskiy and Tanja Alderliesten and Peter A. N. Bosman},
  doi          = {10.1145/3453141},
  journal      = {ACM Transactions on Evolutionary Learning and Optimization},
  number       = {2},
  pages        = {5:1–23},
  shortjournal = {ACM Trans. Evol. Learn. Optim.},
  title        = {A novel approach to designing surrogate-assisted genetic algorithms by combining efficient learning of walsh coefficients and dependencies},
  volume       = {1},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Genetic improvement of routing protocols for delay tolerant
networks. <em>TELO</em>, <em>1</em>(1), 4:1–37. (<a
href="https://doi.org/10.1145/3453683">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Routing plays a fundamental role in network applications, but it is especially challenging in Delay Tolerant Networks (DTNs). These are a kind of mobile ad hoc networks made of, e.g., (possibly, unmanned) vehicles and humans where, despite a lack of continuous connectivity, data must be transmitted while the network conditions change due to the nodes’ mobility. In these contexts, routing is NP-hard and is usually solved by heuristic “store and forward” replication-based approaches, where multiple copies of the same message are moved and stored across nodes in the hope that at least one will reach its destination. Still, the existing routing protocols produce relatively low delivery probabilities. Here, we genetically improve two routing protocols widely adopted in DTNs, namely, Epidemic and PRoPHET, in the attempt to optimize their delivery probability. First, we dissect them into their fundamental components, i.e., functionalities such as checking if a node can transfer data, or sending messages to all connections. Then, we apply Genetic Improvement (GI) to manipulate these components as terminal nodes of evolving trees. We apply this methodology, in silico, to six test cases of urban networks made of hundreds of nodes and find that GI produces consistent gains in delivery probability in four cases. We then verify if this improvement entails a worsening of other relevant network metrics, such as latency and buffer time. Finally, we compare the logics of the best evolved protocols with those of the baseline protocols, and we discuss the generalizability of the results across test cases.},
  archive      = {J_TELO},
  author       = {Michela Lorandi and Leonardo Lucio Custode and Giovanni Iacca},
  doi          = {10.1145/3453683},
  journal      = {ACM Transactions on Evolutionary Learning and Optimization},
  number       = {1},
  pages        = {4:1–37},
  shortjournal = {ACM Trans. Evol. Learn. Optim.},
  title        = {Genetic improvement of routing protocols for delay tolerant networks},
  volume       = {1},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Feature construction for meta-heuristic algorithm
recommendation of capacitated vehicle routing problems. <em>TELO</em>,
<em>1</em>(1), 3:1–28. (<a
href="https://doi.org/10.1145/3447540">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The algorithm recommendation is attracting increasing attention in solving real-world capacitated vehicle routing problems (CVRPs), due to the fact that existing meta-heuristic algorithms often show different performances on different CVRPs. To effectively perform algorithm recommendation for CVRPs, it becomes vital to extract suitable features to characterize the CVRPs accurately. To this end, in this article three groups of penetrating features are proposed to capture the characteristics of CVRPs. The first group consists of some basic features of CVRPs, where several features are suggested to capture the distribution of customer demand, the relationship between customer demand and vehicle capacity, besides some common attributes widely used in CVRPs. The second group is composed of the features extracted from some CVRP solutions generated by local search, where in addition to the feasible and better solutions, the worse solutions and the distribution of travel cost are also used to measure the sensitivity of CVRPs to local search operations. The third group is made up of image features obtained by depicting CVRP instances through images, which is first introduced by us to enhance the generalization of algorithm recommendation. Furthermore, based on the three groups of features, an algorithm recommendation method called ARM-I is built on the basis of a KNN classifier to recommend suitable algorithm for CVRPs. Experimental results on several selected benchmarks demonstrate the effectiveness of the designed features. More interestingly, the proposed ARM-I shows high generalization on real-world instances.},
  archive      = {J_TELO},
  author       = {Hao Jiang and Yuhang Wang and Ye Tian and Xingyi Zhang and Jianhua Xiao},
  doi          = {10.1145/3447540},
  journal      = {ACM Transactions on Evolutionary Learning and Optimization},
  number       = {1},
  pages        = {3:1–28},
  shortjournal = {ACM Trans. Evol. Learn. Optim.},
  title        = {Feature construction for meta-heuristic algorithm recommendation of capacitated vehicle routing problems},
  volume       = {1},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). On steady-state evolutionary algorithms and selective
pressure: Why inverse rank-based allocation of reproductive trials is
best. <em>TELO</em>, <em>1</em>(1), 2:1–38. (<a
href="https://doi.org/10.1145/3427474">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We analyse the impact of the selective pressure for the global optimisation capabilities of steady-state evolutionary algorithms (EAs). For the standard bimodal benchmark function TwoMax , we rigorously prove that using uniform parent selection leads to exponential runtimes with high probability to locate both optima for the standard ( \(\)+1) EA and ( \(\)+1) RLS with any polynomial population sizes. However, we prove that selecting the worst individual as parent leads to efficient global optimisation with overwhelming probability for reasonable population sizes. Since always selecting the worst individual may have detrimental effects for escaping from local optima, we consider the performance of stochastic parent selection operators with low selective pressure for a function class called TruncatedTwoMax, where one slope is shorter than the other. An experimental analysis shows that the EAs equipped with inverse tournament selection, where the loser is selected for reproduction and small tournament sizes, globally optimise TwoMax efficiently and effectively escape from local optima of TruncatedTwoMax with high probability. Thus, they identify both optima efficiently while uniform (or stronger) selection fails in theory and in practice. We then show the power of inverse selection on function classes from the literature where populations are essential by providing rigorous proofs or experimental evidence that it outperforms uniform selection equipped with or without a restart strategy. We conclude the article by confirming our theoretical insights with an empirical analysis of the different selective pressures on standard benchmarks of the classical MaxSat and multidimensional knapsack problems.},
  archive      = {J_TELO},
  author       = {Dogan Corus and Andrei Lissovoi and Pietro S. Oliveto and Carsten Witt},
  doi          = {10.1145/3427474},
  journal      = {ACM Transactions on Evolutionary Learning and Optimization},
  number       = {1},
  pages        = {2:1–38},
  shortjournal = {ACM Trans. Evol. Learn. Optim.},
  title        = {On steady-state evolutionary algorithms and selective pressure: Why inverse rank-based allocation of reproductive trials is best},
  volume       = {1},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). ACM transactions on evolutionary learning and optimization
inaugural issue editorial. <em>TELO</em>, <em>1</em>(1), 1e:1–2. (<a
href="https://doi.org/10.1145/3449277">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {No abstract available.},
  archive      = {J_TELO},
  author       = {Juergen Branke and Darrell Whitley},
  doi          = {10.1145/3449277},
  journal      = {ACM Transactions on Evolutionary Learning and Optimization},
  number       = {1},
  pages        = {1e:1–2},
  shortjournal = {ACM Trans. Evol. Learn. Optim.},
  title        = {ACM transactions on evolutionary learning and optimization inaugural issue editorial},
  volume       = {1},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Greed is good: Exploration and exploitation trade-offs in
bayesian optimisation. <em>TELO</em>, <em>1</em>(1), 1:1–22. (<a
href="https://doi.org/10.1145/3425501">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The performance of acquisition functions for Bayesian optimisation to locate the global optimum of continuous functions is investigated in terms of the Pareto front between exploration and exploitation. We show that Expected Improvement (EI) and the Upper Confidence Bound (UCB) always select solutions to be expensively evaluated on the Pareto front, but Probability of Improvement is not guaranteed to do so and Weighted Expected Improvement does so only for a restricted range of weights. We introduce two novel \(\)-greedy acquisition functions. Extensive empirical evaluation of these together with random search, purely exploratory, and purely exploitative search on 10 benchmark problems in 1 to 10 dimensions shows that \(\)-greedy algorithms are generally at least as effective as conventional acquisition functions (e.g., EI and UCB), particularly with a limited budget. In higher dimensions, \(\)-greedy approaches are shown to have improved performance over conventional approaches. These results are borne out on a real-world computational fluid dynamics optimisation problem and a robotics active learning problem. Our analysis and experiments suggest that the most effective strategy, particularly in higher dimensions, is to be mostly greedy, occasionally selecting a random exploratory solution.},
  archive      = {J_TELO},
  author       = {George De Ath and Richard M. Everson and Alma A. M. Rahat and Jonathan E. Fieldsend},
  doi          = {10.1145/3425501},
  journal      = {ACM Transactions on Evolutionary Learning and Optimization},
  number       = {1},
  pages        = {1:1–22},
  shortjournal = {ACM Trans. Evol. Learn. Optim.},
  title        = {Greed is good: Exploration and exploitation trade-offs in bayesian optimisation},
  volume       = {1},
  year         = {2021},
}
</textarea>
</details></li>
</ul>

</body>
</html>
