<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>TODAES_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="todaes---55">TODAES - 55</h2>
<ul>
<li><details>
<summary>
(2021). Implementation, characterization and application of path
changing switch based arbiter PUF on FPGA as a lightweight security
primitive for IoT. <em>TODAES</em>, <em>27</em>(3), 26:1–26. (<a
href="https://doi.org/10.1145/3491212">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Secure authentication of any Internet-of-Things (IoT) device becomes the utmost necessity due to the lack of specifically designed IoT standards and intrinsic vulnerabilities with limited resources and heterogeneous technologies. Despite the suitability of arbiter physically unclonable function (APUF) among other PUF variants for the IoT applications, implementing it on field-programmable gate arrays (FPGAs) is challenging. This work presents the complete characterization of the path changing switch (PCS) 1 based APUF on two different families of FPGA, like Spartan-3E (90 nm CMOS) and Artix-7 (28 nm CMOS). A comprehensive study of the existing tuning concept for programmable delay logic (PDL) based APUF implemented on FPGA is presented, leading to establishment of its practical infeasibility. We investigate the entropy, randomness properties of the PCS based APUF suitable for practical applications, and the effect of temperature variation signifying the adequate tolerance against environmental variation. The XOR composition of PCS based APUF is introduced to boost performance and security. The robustness of the PCS based APUF against machine learning based modeling attack is evaluated, showing similar characteristics as the conventional APUF. Experimental results validate the efficacy of PCS based APUF with a little hardware footprint removing the paucity of lightweight security primitive for IoT.},
  archive      = {J_TODAES},
  author       = {Mahabub Hasan Mahalat and Suraj Mandal and Anindan Mondal and Bibhash Sen and Rajat Subhra Chakraborty},
  doi          = {10.1145/3491212},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  number       = {3},
  pages        = {26:1–26},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {Implementation, characterization and application of path changing switch based arbiter PUF on FPGA as a lightweight security primitive for IoT},
  volume       = {27},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Toward taming the overhead monster for data-flow integrity.
<em>TODAES</em>, <em>27</em>(3), 25:1–24. (<a
href="https://doi.org/10.1145/3490176">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data-Flow Integrity (DFI) is a well-known approach to effectively detecting a wide range of software attacks. However, its real-world application has been quite limited so far because of the prohibitive performance overhead it incurs. Moreover, the overhead is enormously difficult to overcome without substantially lowering the DFI criterion. In this work, an analysis is performed to understand the main factors contributing to the overhead. Accordingly, a hardware-assisted parallel approach is proposed to tackle the overhead challenge. Simulations on SPEC CPU 2006 benchmark show that the proposed approach can completely enforce the DFI defined in the original seminal work while reducing performance overhead by 4×, on average.},
  archive      = {J_TODAES},
  author       = {Lang Feng and Jiayi Huang and Jeff Huang and Jiang Hu},
  doi          = {10.1145/3490176},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  number       = {3},
  pages        = {25:1–24},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {Toward taming the overhead monster for data-flow integrity},
  volume       = {27},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). FPGAPRO: A defense framework against crosstalk-induced
secret leakage in FPGA. <em>TODAES</em>, <em>27</em>(3), 24:1–31. (<a
href="https://doi.org/10.1145/3491214">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the emerging cloud-computing development, FPGAs are being integrated with cloud servers for higher performance. Recently, it has been explored to enable multiple users to share the hardware resources of a remote FPGA, i.e., to execute their own applications simultaneously. Although being a promising technique, multi-tenant FPGA unfortunately brings its unique security concerns. It has been demonstrated that the capacitive crosstalk between FPGA long-wires can be a side-channel to extract secret information, giving adversaries the opportunity to implement crosstalk-based side-channel attacks. Moreover, recent work reveals that medium-wires and multiplexers in configurable logic block (CLB) are also vulnerable to crosstalk-based information leakage. In this work, we propose FPGAPRO: a defense framework leveraging P lacement, R outing, and O bfuscation to mitigate the secret leakage on FPGA components, including long-wires, medium-wires, and logic elements in CLB. As a user-friendly defense strategy, FPGAPRO focuses on protecting the security-sensitive instances meanwhile considering critical path delay for performance maintenance. As the proof-of-concept, the experimental result demonstrates that FPGAPRO can effectively reduce the crosstalk-caused side-channel leakage by 138 times. Besides, the performance analysis shows that this strategy prevents the maximum frequency from timing violation.},
  archive      = {J_TODAES},
  author       = {Yukui Luo and Shijin Duan and Xiaolin Xu},
  doi          = {10.1145/3491214},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  number       = {3},
  pages        = {24:1–31},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {FPGAPRO: A defense framework against crosstalk-induced secret leakage in FPGA},
  volume       = {27},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Uncertainty theory based partitioning for cyber-physical
systems with uncertain reliability analysis. <em>TODAES</em>,
<em>27</em>(3), 23:1–19. (<a
href="https://doi.org/10.1145/3490177">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reasonable partitioning is a critical issue for cyber-physical system (CPS) design. Traditional CPS partitioning methods run in a determined context and depend on the parameter pre-estimations, but they ignore the uncertainty of parameters and hardly consider reliability. The state-of-the-art work proposed an uncertainty theory based CPS partitioning method, which includes parameter uncertainty and reliability analysis, but it only considers linear uncertainty distributions for variables and ignores the uncertainty of reliability. In this paper, we propose an uncertainty theory based CPS partitioning method with uncertain reliability analysis. We convert the uncertain objective and constraint into determined forms; such conversion methods can be applied to all forms of uncertain variables, not just for linear. By applying uncertain reliability analysis in the uncertainty model, we for the first time include the uncertainty of reliability into the CPS partitioning, where the reliability enhancement algorithm is proposed. We study the performance of the reliability obtained through uncertain reliability analysis, and experimental results show that the system reliability with uncertainty does not change significantly with the growth of task module numbers.},
  archive      = {J_TODAES},
  author       = {Si Chen and Guoqi Xie and Renfa Li and Keqin Li},
  doi          = {10.1145/3490177},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  number       = {3},
  pages        = {23:1–19},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {Uncertainty theory based partitioning for cyber-physical systems with uncertain reliability analysis},
  volume       = {27},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Hierarchical scheduling of an SDF/l graph onto multiple
processors. <em>TODAES</em>, <em>27</em>(3), 22:1–23. (<a
href="https://doi.org/10.1145/3489469">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although dataflow models are known to thrive at exploiting task-level parallelism of an application, it is difficult to exploit the parallelism of data, represented well with loop structures, since these structures are not explicitly specified in existing dataflow models. SDF/L model overcomes this shortcoming by specifying the loop structures explicitly in a hierarchical fashion. We introduce a scheduling technique of an application represented by the SDF/L model onto heterogeneous processors. In the proposed method, we explore the mapping of tasks using an evolutionary meta-heuristic and schedule hierarchically in a bottom-up fashion, creating parallel loop schedules at lower levels first and then re-using them when constructing the schedule at a higher level. The efficiency of the proposed scheduling methodology is verified with benchmark examples and randomly generated SDF/L graphs.},
  archive      = {J_TODAES},
  author       = {Mari-Liis Oldja and Jangryul Kim and Dowhan Jeong and Soonhoi Ha},
  doi          = {10.1145/3489469},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  number       = {3},
  pages        = {22:1–23},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {Hierarchical scheduling of an SDF/L graph onto multiple processors},
  volume       = {27},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Energy efficient error resilient multiplier using low-power
compressors. <em>TODAES</em>, <em>27</em>(3), 21:1–26. (<a
href="https://doi.org/10.1145/3488837">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The approximate hardware design can save huge energy at the cost of errors incurred in the design. This article proposes the approximate algorithm for low-power compressors, utilized to build approximate multiplier with low energy and acceptable error profiles. This article presents two design approaches (DA1 and DA2) for higher bit size approximate multipliers. The proposed multiplier of DA1 have no propagation of carry signal from LSB to MSB, resulted in a very high-speed design. The increment in delay, power, and energy are not exponential with increment of multiplier size ( n ) for DA1 multiplier. It can be observed that the maximum combinations lie in the threshold Error Distance of 5\% of the maximum value possible for any particular multiplier of size n . The proposed 4-bit DA1 multiplier consumes only 1.3 fJ of energy, which is 87.9\%, 78\%, 94\%, 67.5\%, and 58.9\% less when compared to M1, M2, LxA, MxA, accurate designs respectively. The DA2 approach is recursive method, i.e., n -bit multiplier built with n/2-bit sub-multipliers. The proposed 8-bit multiplication has 92\% energy savings with Mean Relative Error Distance (MRED) of 0.3 for the DA1 approach and at least 11\% to 40\% of energy savings with MRED of 0.08 for the DA2 approach. The proposed multipliers are employed in the image processing algorithm of DCT, and the quality is evaluated. The standard PSNR metric is 55 dB for less approximation and 35 dB for maximum approximation.},
  archive      = {J_TODAES},
  author       = {Skandha Deepsita S and Dhayala Kumar M and Noor Mahammad SK},
  doi          = {10.1145/3488837},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  number       = {3},
  pages        = {21:1–26},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {Energy efficient error resilient multiplier using low-power compressors},
  volume       = {27},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A compact high-dimensional yield analysis method using
low-rank tensor approximation. <em>TODAES</em>, <em>27</em>(2), 19:1–23.
(<a href="https://doi.org/10.1145/3483941">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {“Curse of dimensionality” has become the major challenge for existing high-sigma yield analysis methods. In this article, we develop a meta-model using Low-Rank Tensor Approximation (LRTA) to substitute expensive SPICE simulation. The polynomial degree of our LRTA model grows linearly with the circuit dimension. This makes it especially promising for high-dimensional circuit problems. Our LRTA meta-model is solved efficiently with a robust greedy algorithm and calibrated iteratively with a bootstrap-assisted adaptive sampling method. We also develop a novel global sensitivity analysis approach to generate a reduced LRTA meta-model which is more compact. It further accelerates the procedure of model calibration and yield estimation. Experiments on memory and analog circuits validate that the proposed LRTA method outperforms other state-of-the-art approaches in terms of accuracy and efficiency.},
  archive      = {J_TODAES},
  author       = {Xiao Shi and Hao Yan and Qiancun Huang and Chengzhen Xuan and Lei He and Longxing Shi},
  doi          = {10.1145/3483941},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  number       = {2},
  pages        = {19:1–23},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {A compact high-dimensional yield analysis method using low-rank tensor approximation},
  volume       = {27},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). MeF-RAM: A new non-volatile cache memory based on
magneto-electric FET. <em>TODAES</em>, <em>27</em>(2), 18:1–18. (<a
href="https://doi.org/10.1145/3484222">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Magneto-Electric FET ( MEFET ) is a recently developed post-CMOS FET, which offers intriguing characteristics for high-speed and low-power design in both logic and memory applications. In this article, we present MeF-RAM , a non-volatile cache memory design based on 2-Transistor-1-MEFET ( 2T1M ) memory bit-cell with separate read and write paths. We show that with proper co-design across MEFET device, memory cell circuit, and array architecture, MeF-RAM is a promising candidate for fast non-volatile memory ( NVM ). To evaluate its cache performance in the memory system, we, for the first time, build a device-to-architecture cross-layer evaluation framework to quantitatively analyze and benchmark the MeF-RAM design with other memory technologies, including both volatile memory (i.e., SRAM, eDRAM) and other popular non-volatile emerging memory (i.e., ReRAM, STT-MRAM, and SOT-MRAM). The experiment results for the PARSEC benchmark suite indicate that, as an L2 cache memory, MeF-RAM reduces Energy Area Latency ( EAT ) product on average by ~98\% and ~70\% compared with typical 6T-SRAM and 2T1R SOT-MRAM counterparts, respectively.},
  archive      = {J_TODAES},
  author       = {Shaahin Angizi and Navid Khoshavi and Andrew Marshall and Peter Dowben and Deliang Fan},
  doi          = {10.1145/3484222},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  number       = {2},
  pages        = {18:1–18},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {MeF-RAM: A new non-volatile cache memory based on magneto-electric FET},
  volume       = {27},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Distance-aware approximate nanophotonic interconnect.
<em>TODAES</em>, <em>27</em>(2), 17:1–30. (<a
href="https://doi.org/10.1145/3484309">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The energy consumption of manycore architectures is dominated by data movement, which calls for energy-efficient and high-bandwidth interconnects. To overcome the bandwidth limitation of electrical interconnects, integrated optics appear as a promising technology. However, it suffers from high power overhead related to low laser efficiency, which calls for the use of techniques and methods to improve its energy costs. Besides, approximate computing is emerging as an efficient method to reduce energy consumption and improve execution speed of embedded computing systems. It relies on allowing accuracy reduction on data at the cost of tolerable application output error. In this context, the work presented in this article exploits both features by defining approximate communications for error-tolerant applications. We propose a method to design realistic and scalable nanophotonic interconnect supporting approximate data transmission and power adaption according to the communication distance to improve the energy efficiency. For this purpose, the data can be sent by mixing low optical power signal and truncation for the Least Significant Bits (LSB) of the floating-point numbers, while the overall power is adapted according to the communication distance. We define two ranges of communications, short and long, which require only four power levels. This reduces area and power overhead to control the laser output power. A transmission model allows estimating the laser power according to the targeted BER and the number of truncated bits, while the optical network interface allows configuring, at runtime, the number of approximated and truncated bits and the laser output powers. We explore the energy efficiency provided by each communication scheme, and we investigate the error resilience of the benchmarks over several approximation and truncation schemes. The simulation results of ApproxBench applications show that, compared to an interconnect involving only robust communications, approximations in the optical transmission led to up to 53\% laser power reduction with a limited degradation at the application level with less than 9\% of output error. Finally, we show that our solution is scalable and leads to 10\% reduction in the total energy consumption, 35× reduction in the laser driver size, and 10× reduction in the laser controller compared to state-of-the-art solution.},
  archive      = {J_TODAES},
  author       = {Jaechul Lee and Cédric Killian and Sebastien Le Beux and Daniel Chillet},
  doi          = {10.1145/3484309},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  number       = {2},
  pages        = {17:1–30},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {Distance-aware approximate nanophotonic interconnect},
  volume       = {27},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Plasticine: A cross-layer approximation methodology for
multi-kernel applications through minimally biased, high-throughput, and
energy-efficient SIMD soft multiplier-divider. <em>TODAES</em>,
<em>27</em>(2), 16:1–33. (<a
href="https://doi.org/10.1145/3486616">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid evolution of error-resilient programs intertwined with their quest for high throughput has motivated the use of Single Instruction, Multiple Data (SIMD) components in Field-Programmable Gate Arrays (FPGAs). Particularly, to exploit the error-resiliency of such applications, Cross-layer approximation paradigm has recently gained traction, the ultimate goal of which is to efficiently exploit approximation potentials across layers of abstraction. From circuit- to application-level, valuable studies have proposed various approximation techniques, albeit linked to four drawbacks: First, most of approximate multipliers and dividers operate only in SISD mode. Second, imprecise units are often substituted, merely in a single kernel of a multi-kernel application, with an end-to-end analysis in Quality of Results (QoR) and not in the gained performance. Third, state-of-the-art (SoA) strategies neglect the fact that each kernel contributes differently to the end-to-end QoR and performance metrics. Therefore, they lack in adopting a generic methodology for adjusting the approximation knobs to maximize performance gains for a user-defined quality constraint. Finally, multi-level techniques lack in being efficiently supported, from application-, to architecture-, to circuit-level, in a cohesive cross-layer hierarchy. In this article, we propose Plasticine , a cross-layer methodology for multi-kernel applications, which addresses the aforementioned challenges by efficiently utilizing the synergistic effects of a chain of techniques across layers of abstraction. To this end, we propose an application sensitivity analysis and a heuristic that tailor the precision at constituent kernels of the application by finding the most tolerable degree of approximations for each of consecutive kernels, while also satisfying the ultimate user-defined QoR. The chain of approximations is also effectively enabled in a cross-layer hierarchy, from application- to architecture- to circuit-level, through the plasticity of SIMD multiplier-dividers, each supporting dynamic precision variability along with hybrid functionality. The end-to-end evaluations of Plasticine  on three multi-kernel applications employed in bio-signal processing, image processing, and moving object tracking for Unmanned Air Vehicles (UAV) demonstrate 41\%–64\%, 39\%–62\%, and 70\%–86\% improvements in area, latency, and Area-Delay-Product (ADP), respectively, over 32-bit fixed precision, with negligible loss in QoR. To springboard future research in reconfigurable and approximate computing communities, our implementations will be available and open-sourced at https://cfaed.tu-dresden.de/pd-downloads.},
  archive      = {J_TODAES},
  author       = {Zahra Ebrahimi and Dennis Klar and Mohammad Aasim Ekhtiyar and Akash Kumar},
  doi          = {10.1145/3486616},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  number       = {2},
  pages        = {16:1–33},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {Plasticine: A cross-layer approximation methodology for multi-kernel applications through minimally biased, high-throughput, and energy-efficient SIMD soft multiplier-divider},
  volume       = {27},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Double-shift: A low-power DNN weights storage and access
framework based on approximate decomposition and quantization.
<em>TODAES</em>, <em>27</em>(2), 15:1–16. (<a
href="https://doi.org/10.1145/3477047">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One major challenge in deploying Deep Neural Network (DNN) in resource-constrained applications, such as edge nodes, mobile embedded systems, and IoT devices, is its high energy cost. The emerging approximate computing methodology can effectively reduce the energy consumption during the computing process in DNN. However, a recent study shows that the weight storage and access operations can dominate DNN&#39;s energy consumption due to the fact that the huge size of DNN weights must be stored in the high-energy-cost DRAM. In this paper, we propose Double-Shift, a low-power DNN weight storage and access framework, to solve this problem. Enabled by approximate decomposition and quantization, Double-Shift can reduce the data size of the weights effectively. By designing a novel weight storage allocation strategy, Double-Shift can boost the energy efficiency by trading the energy consuming weight storage and access operations for low-energy-cost computations. Our experimental results show that Double-Shift can reduce DNN weights to 3.96\%–6.38\% of the original size and achieve an energy saving of 86.47\%–93.62\%, while introducing a DNN classification error within 2\%.},
  archive      = {J_TODAES},
  author       = {Ming Han and Ye Wang and Jian Dong and Gang Qu},
  doi          = {10.1145/3477047},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  number       = {2},
  pages        = {15:1–16},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {Double-shift: A low-power DNN weights storage and access framework based on approximate decomposition and quantization},
  volume       = {27},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Leveraging automatic high-level synthesis resource sharing
to maximize dynamical voltage overscaling with error control.
<em>TODAES</em>, <em>27</em>(2), 14:1–18. (<a
href="https://doi.org/10.1145/3473909">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Approximate Computing has emerged as an alternative way to further reduce the power consumption of integrated circuits (ICs) by trading off errors at the output with simpler, more efficient logic. So far the main approaches in approximate computing have been to simplify the hardware circuit by pruning the circuit until the maximum error threshold is met. One of the critical issues, though, is the training data used to prune the circuit. The output error can significantly exceed the maximum error if the final workload does not match the training data. Thus, most previous work typically assumes that training data matches with the workload data distribution. In this work, we present a method that dynamically overscales the supply voltage based on different workload distribution at runtime. This allows to adaptively select the supply voltage that leads to the largest power savings while ensuring that the error will never exceed the maximum error threshold. This approach also allows restoring of the original error-free circuit if no matching workload distribution is found. The proposed method also leverages the ability of High-Level Synthesis (HLS) to automatically generate circuits with different properties by setting different synthesis constraints to maximize the available timing slack and, hence, maximize the power savings. Experimental results show that our proposed method works very well, saving on average 47.08\% of power as compared to the exact output circuit and 20.25\% more than a traditional approximation method.},
  archive      = {J_TODAES},
  author       = {Prattay Chowdhury and Benjamin Carrion Schafer},
  doi          = {10.1145/3473909},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  number       = {2},
  pages        = {14:1–18},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {Leveraging automatic high-level synthesis resource sharing to maximize dynamical voltage overscaling with error control},
  volume       = {27},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An adaptive application framework with customizable quality
metrics. <em>TODAES</em>, <em>27</em>(2), 13:1–33. (<a
href="https://doi.org/10.1145/3477428">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many embedded environments require applications to produce outcomes under different, potentially changing, resource constraints. Relaxing application semantics through approximations enables trading off resource usage for outcome quality. Although quality is a highly subjective notion, previous work assumes given, fixed low-level quality metrics that often lack a strong correlation to a user’s higher-level quality experience. Users may also change their minds with respect to their quality expectations depending on the resource budgets they are willing to dedicate to an execution. This motivates the need for an adaptive application framework where users provide execution budgets and a customized quality notion. This article presents a novel adaptive program graph representation that enables user-level, customizable quality based on basic quality aspects defined by application developers. Developers also define application configuration spaces, with possible customization to eliminate undesirable configurations. At runtime, the graph enables the dynamic selection of the configuration with maximal customized quality within the user-provided resource budget. An adaptive application framework based on our novel graph representation has been implemented on Android and Linux platforms and evaluated on eight benchmark programs, four with fully customizable quality. Using custom quality instead of the default quality, users may improve their subjective quality experience value by up to 3.59×, with 1.76× on average under different resource constraints. Developers are able to exploit their application structure knowledge to define configuration spaces that are on average 68.7\% smaller as compared to existing, structure-oblivious approaches. The overhead of dynamic reconfiguration averages less than 1.84\% of the overall application execution time.},
  archive      = {J_TODAES},
  author       = {Liu Liu and Sibren Isaacman and Ulrich Kremer},
  doi          = {10.1145/3477428},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  number       = {2},
  pages        = {13:1–33},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {An adaptive application framework with customizable quality metrics},
  volume       = {27},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). ParTBC: Faster estimation of top-k betweenness centrality
vertices on GPU. <em>TODAES</em>, <em>27</em>(2), 12:1–25. (<a
href="https://doi.org/10.1145/3486613">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Betweenness centrality (BC) is a popular centrality measure, based on shortest paths, used to quantify the importance of vertices in networks. It is used in a wide array of applications including social network analysis, community detection, clustering, biological network analysis, and several others. The state-of-the-art Brandes’ algorithm for computing BC has time complexities of and for unweighted and weighted graphs, respectively. Brandes’ algorithm has been successfully parallelized on multicore and manycore platforms. However, the computation of vertex BC continues to be time-consuming for large real-world graphs. Often, in practical applications, it suffices to identify the most important vertices in a network; that is, those having the highest BC values. Such applications demand only the top vertices in the network as per their BC values but do not demand their actual BC values. In such scenarios, not only is computing the BC of all the vertices unnecessary but also exact BC values need not be computed. In this work, we attempt to marry controlled approximations with parallelization to estimate the k -highest BC vertices faster, without having to compute the exact BC scores of the vertices. We present a host of techniques to determine the top- k vertices faster , with a small inaccuracy, by computing approximate BC scores of the vertices. Aiding our techniques is a novel vertex-renumbering scheme to make the graph layout more structured , which results in faster execution of parallel Brandes’ algorithm on GPU. Our experimental results, on a suite of real-world and synthetic graphs, show that our best performing technique computes the top- k vertices with an average speedup of 2.5× compared to the exact parallel Brandes’ algorithm on GPU, with an error of less than 6\%. Our techniques also exhibit high precision and recall, both in excess of 94\%.},
  archive      = {J_TODAES},
  author       = {Somesh Singh and Tejas Shah and Rupesh Nasre},
  doi          = {10.1145/3486613},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  number       = {2},
  pages        = {12:1–25},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {ParTBC: Faster estimation of top-k betweenness centrality vertices on GPU},
  volume       = {27},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Towards fine-grained online adaptive approximation control
for dense SLAM on embedded GPUs. <em>TODAES</em>, <em>27</em>(2),
11:1–19. (<a href="https://doi.org/10.1145/3486612">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dense SLAM is an important application on an embedded environment. However, embedded platforms usually fail to provide enough computation resources for high-accuracy real-time dense SLAM, even with high-parallelism architecture such as GPUs. To tackle this problem, one solution is to design proper approximation techniques for dense SLAM on embedded GPUs. In this work, we propose two novel approximation techniques, critical data identification and redundant branch elimination. We also analyze the error characteristics of the other two techniques—loop skipping and thread approximation. Then, we propose SLaPP, an online adaptive approximation controller, which aims to control the error to be under an acceptable threshold. The evaluation shows SLaPP can achieve 2.0× performance speedup and 30\% energy saving on average compared to the case without approximation.},
  archive      = {J_TODAES},
  author       = {Tiancong Bu and Kaige Yan and Jingweijia Tan},
  doi          = {10.1145/3486612},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  number       = {2},
  pages        = {11:1–19},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {Towards fine-grained online adaptive approximation control for dense SLAM on embedded GPUs},
  volume       = {27},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Synthesizing brain-network-inspired interconnections for
large-scale network-on-chips. <em>TODAES</em>, <em>27</em>(1), 9:1–30.
(<a href="https://doi.org/10.1145/3480961">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Brain network is a large-scale complex network with scale-free, small-world, and modularity properties, which largely supports this high-efficiency massive system. In this article, we propose to synthesize brain-network-inspired interconnections for large-scale network-on-chips. First, we propose a method to generate brain-network-inspired topologies with limited scale-free and power-law small-world properties, which have a low total link length and extremely low average hop count approximately proportional to the logarithm of the network size. In addition, given the large-scale applications, considering the modularity of the brain-network-inspired topologies, we present an application mapping method, including task mapping and deterministic deadlock-free routing, to minimize the power consumption and hop count. Finally, a cycle-accurate simulator \(BookSim2\) is used to validate the architecture performance with different synthetic traffic patterns and large-scale test cases, including real-world communication networks for the graph processing application. Experiments show that, compared with other topologies and methods, the brain-network-inspired network-on-chips (NoCs) generated by the proposed method present significantly lower average hop count and lower average latency. Especially in graph processing applications with a power-law and tightly coupled inter-core communication, the brain-network-inspired NoC has up to 70\% lower average hop count and 75\% lower average latency than mesh-based NoCs.},
  archive      = {J_TODAES},
  author       = {Mengke Ge and Xiaobing Ni and Xu Qi and Song Chen and Jinglei Huang and Yi Kang and Feng Wu},
  doi          = {10.1145/3480961},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  number       = {1},
  pages        = {9:1–30},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {Synthesizing brain-network-inspired interconnections for large-scale network-on-chips},
  volume       = {27},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Fault injection attack emulation framework for early
evaluation of IC designs. <em>TODAES</em>, <em>27</em>(1), 8:1–25. (<a
href="https://doi.org/10.1145/3480962">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fault injection attack (FIA) has become a serious threat to the confidentiality and fault tolerance of integrated circuits (ICs). Circuit designers need an effective method to evaluate the countermeasures of the IC designs against the FIAs at the design stage. To address the need, this article, based on FPGA emulation, proposes an in-circuit early evaluation framework, in which FIAs are emulated with parameterized fault models. To mimic FIAs, an efficient scan approach is proposed to inject faults at any time at any circuit nodes, while both the time and area overhead of fault injection are reduced. After the circuit design under test (CUT) is submitted to the framework, the scan chains insertion, fault generation, and fault injection are executed automatically, and the evaluation result of the CUT is generated, making the evaluation a transparent process to the designers. Based on the framework, the confidentiality and fault-tolerance evaluations are demonstrated with an information-based evaluation approach. Experiment results on a set of ISCAS89 benchmark circuits show that on average, our approach reduces the area overhead by 41.08\% compared with the full scan approach and by over 20.00\% compared with existing approaches. The confidentiality evaluation experiments on AES-128 and DES-56 and the fault-tolerance evaluation experiments on two CNN circuits, a RISC-V core, a Cordic core, and the float point arithmetic units show the effectiveness of the proposed framework.},
  archive      = {J_TODAES},
  author       = {Qiang Liu and Honghui Tang and Peiran Zhang},
  doi          = {10.1145/3480962},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  number       = {1},
  pages        = {8:1–25},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {Fault injection attack emulation framework for early evaluation of IC designs},
  volume       = {27},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Demand-driven multi-target sample preparation on
resource-constrained digital microfluidic biochips. <em>TODAES</em>,
<em>27</em>(1), 7:1–21. (<a
href="https://doi.org/10.1145/3474392">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Microfluidic lab-on-chips offer promising technology for the automation of various biochemical laboratory protocols on a minuscule chip. Sample preparation (SP) is an essential part of any biochemical experiments, which aims to produce dilution of a sample or a mixture of multiple reagents in a certain ratio. One major objective in this area is to prepare dilutions of a given fluid with different concentration factors, each with certain volume, which is referred to as the demand-driven multiple-target (DDMT) generation problem. SP with microfluidic biochips requires proper sequencing of mix-split steps on fluid volumes and needs storage units to save intermediate fluids while producing the desired target ratio. The performance of SP depends on the underlying mixing algorithm and the availability of on-chip storage, and the latter is often limited by the constraints imposed during physical design. Since DDMT involves several target ratios, solving it under storage constraints becomes even harder. Furthermore, reduction of mix-split steps is desirable from the viewpoint of accuracy of SP, as every such step is a potential source of volumetric split error. In this article, we propose a storage-aware DDMT algorithm that reduces the number of mix-split operations on a digital microfluidic lab-on-chip. We also present the layout of the biochip with \(\)-storage cells and their allocation technique for \(\). Simulation results reveal the superiority of the proposed method compared to the state-of-the-art multi-target SP algorithms.},
  archive      = {J_TODAES},
  author       = {Sudip Poddar and Sukanta Bhattacharjee and Shao-Yun Fang and Tsung-Yi Ho and B. B. Bhattacharya},
  doi          = {10.1145/3474392},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  number       = {1},
  pages        = {7:1–21},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {Demand-driven multi-target sample preparation on resource-constrained digital microfluidic biochips},
  volume       = {27},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A native SPICE implementation of memristor models for
simulation of neuromorphic analog signal processing circuits.
<em>TODAES</em>, <em>27</em>(1), 6:1–24. (<a
href="https://doi.org/10.1145/3474364">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Since the memristor emerged as a programmable analog storage device, it has stimulated research on the design of analog/mixed-signal circuits with the memristor as the enabler of in-memory computation. Due to the difficulty in evaluating the circuit-level nonidealities of both memristors and CMOS devices, SPICE-accuracy simulation tools are necessary for perfecting the art of neuromorphic analog/mixed-signal circuit design. This article is dedicated to a native SPICE implementation of the memristor device models published in the open literature and develops case studies of applying such a circuit simulation with MOSFET models to study how device-level imperfections can make adversarial effects on the analog circuits that implement neuromorphic analog signal processing. Methods on memristor stamping in the framework of modified nodal analysis formulation are presented, and implementation results are reported. Furthermore, functional simulations on neuromorphic signal processing circuits including memristors and CMOS devices are carried out to validate the effectiveness of the native SPICE implementation of memristor models from the perspectives of simulation accuracy, efficiency, and convergence for large-scale simulation tasks.},
  archive      = {J_TODAES},
  author       = {Bo Li and Guoyong Shi},
  doi          = {10.1145/3474364},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  number       = {1},
  pages        = {6:1–24},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {A native SPICE implementation of memristor models for simulation of neuromorphic analog signal processing circuits},
  volume       = {27},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Improving LDPC decoding performance for 3D TLC NAND flash by
LLR optimization scheme for hard and soft decision. <em>TODAES</em>,
<em>27</em>(1), 5:1–20. (<a
href="https://doi.org/10.1145/3473305">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Low-density parity-check (LDPC) codes have been widely adopted in NAND flash in recent years to enhance data reliability. There are two types of decoding, hard-decision and soft-decision decoding. However, for the two types, their error correction capability degrades due to inaccurate log-likelihood ratio (LLR) . To improve the LLR accuracy of LDPC decoding, this article proposes LLR optimization schemes, which can be utilized for both hard-decision and soft-decision decoding. First, we build a threshold voltage distribution model for 3D floating gate (FG) triple level cell (TLC) NAND flash. Then, by exploiting the model, we introduce a scheme to quantize LLR during hard-decision and soft-decision decoding. And by amplifying a portion of small LLRs, which is essential in the layer min-sum decoder, more precise LLR can be obtained. For hard-decision decoding, the proposed new modes can significantly improve the decoder’s error correction capability compared with traditional solutions. Soft-decision decoding starts when hard-decision decoding fails. For this part, we study the influence of the reference voltage arrangement of LLR calculation and apply the quantization scheme. The simulation shows that the proposed approach can reduce frame error rate (FER) for several orders of magnitude.},
  archive      = {J_TODAES},
  author       = {Lanlan Cui and Fei Wu and Xiaojian Liu and Meng Zhang and Renzhi Xiao and Changsheng Xie},
  doi          = {10.1145/3473305},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  number       = {1},
  pages        = {5:1–20},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {Improving LDPC decoding performance for 3D TLC NAND flash by LLR optimization scheme for hard and soft decision},
  volume       = {27},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A design methodology for energy-aware processing in unmanned
aerial vehicles. <em>TODAES</em>, <em>27</em>(1), 4:1–20. (<a
href="https://doi.org/10.1145/3470451">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unmanned Aerial Vehicles (UAVs) have rapidly become popular for monitoring, delivery, and actuation in many application domains such as environmental management, disaster mitigation, homeland security, energy, transportation, and manufacturing. However, the UAV perception and navigation intelligence (PNI) designs are still in their infancy and demand fundamental performance and energy optimizations to be eligible for mass adoption. In this article, we present a generalizable three-stage optimization framework for PNI systems that (i) abstracts the high-level programs representing the perception, mining, processing, and decision making of UAVs into complex weighted networks tracking the interdependencies between universal low-level intermediate representations; (ii) exploits a differential geometry approach to schedule and map the discovered PNI tasks onto an underlying manycore architecture. To mine the complexity of optimal parallelization of perception and decision modules in UAVs, this proposed design methodology relies on an Ollivier-Ricci curvature-based load-balancing strategy that detects the parallel communities of the PNI applications for maximum parallel execution, while minimizing the inter-core communication; and (iii) relies on an energy-aware mapping scheme to minimize the energy dissipation when assigning the communities onto tile-based networks-on-chip. We validate this approach based on various drone PNI designs including flight controller, path planning, and visual navigation. The experimental results confirm that the proposed framework achieves 23\% flight time reduction and up to 34\% energy savings for the flight controller application. In addition, the optimization on a 16-core platform improves the on-time visit rate of the path planning algorithm by 14\% while reducing 81\% of run time for ConvNet visual navigation.},
  archive      = {J_TODAES},
  author       = {Jingyu He and Yao Xiao and Corina Bogdan and Shahin Nazarian and Paul Bogdan},
  doi          = {10.1145/3470451},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  number       = {1},
  pages        = {4:1–20},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {A design methodology for energy-aware processing in unmanned aerial vehicles},
  volume       = {27},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An efficient execution framework of two-part execution
scenario analysis. <em>TODAES</em>, <em>27</em>(1), 3:1–24. (<a
href="https://doi.org/10.1145/3465474">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Response Time Analysis ( RTA ) is an important and promising technique for analyzing the schedulability of real-time tasks under both Global Fixed-Priority ( G-FP ) scheduling and Global Earliest Deadline First ( G-EDF ) scheduling. Most existing RTA methods for tasks under global scheduling are dominated by partitioned scheduling, due to the pessimism of the \(\)-based interference calculation where \(\) is the number of processors. Two-part execution scenario is an effective technique that addresses this pessimism at the cost of efficiency. The major idea of two-part execution scenario is to calculate a more accurate upper bound of the interference by dividing the execution of the target job into two parts and calculating the interference on the target job in each part. This article proposes a novel RTA execution framework that improves two-part execution scenario by reducing some unnecessary calculation, without sacrificing accuracy of the schedulability test. The key observation is that, after the division of the execution of the target job, two-part execution scenario enumerates all possible execution time of the target job in the first part for calculating the final Worst-Case Response Time ( WCRT ). However, only some special execution time can cause the final result. A set of experiments is conducted to test the performance of the proposed execution framework and the result shows that the proposed execution framework can improve the efficiency of two-part execution scenario analysis by up to \(\) in terms of the execution time.},
  archive      = {J_TODAES},
  author       = {Ding Han and Guohui Li and Quan Zhou and Jianjun Li and Yong Yang and Xiaofei Hu},
  doi          = {10.1145/3465474},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  number       = {1},
  pages        = {3:1–24},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {An efficient execution framework of two-part execution scenario analysis},
  volume       = {27},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A novel hybrid cache coherence with global snooping for
many-core architectures. <em>TODAES</em>, <em>27</em>(1), 2:1–31. (<a
href="https://doi.org/10.1145/3462775">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cache coherence ensures correctness of cached data in multi-core processors. Traditional implementations of existing protocols make them unscalable for many core architectures. While snoopy coherence requires unscalable ordered networks, directory coherence is weighed down by high area and energy overheads. In this work, we propose Wireless-enabled Share-aware Hybrid (WiSH) to provide scalable coherence in many core processors. WiSH implements a novel Snoopy over Directory protocol using on-chip wireless links and hierarchical, clustered Network-on-Chip to achieve low-overhead and highly efficient coherence. A local directory protocol maintains coherence within a cluster of cores, while coherence among such clusters is achieved through global snoopy protocol. The ordered network for global snooping is provided through low-latency and low-energy broadcast wireless links. The overheads are further reduced through share-aware cache segmentation to eliminate coherence for private blocks. Evaluations show that WiSH reduces traffic by \(\) and runtime by \(\), while requiring \(\) smaller storage and \(\) lower energy as compared to existing hierarchical and hybrid coherence protocols. Owing to its modularity, WiSH provides highly efficient and scalable coherence for many core processors.},
  archive      = {J_TODAES},
  author       = {Sri Harsha Gade and Sujay Deb},
  doi          = {10.1145/3462775},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  number       = {1},
  pages        = {2:1–31},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {A novel hybrid cache coherence with global snooping for many-core architectures},
  volume       = {27},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A comprehensive survey of attacks without physical access
targeting hardware vulnerabilities in IoT/IIoT devices, and their
detection mechanisms. <em>TODAES</em>, <em>27</em>(1), 1:1–35. (<a
href="https://doi.org/10.1145/3471936">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the advances in the field of the Internet of Things (IoT) and Industrial IoT (IIoT), these devices are increasingly used in daily life or industry. To reduce costs related to the time required to develop these devices, security features are usually not considered. This situation creates a major security concern. Many solutions have been proposed to protect IoT/IIoT against various attacks, most of which are based on attacks involving physical access. However, a new class of attacks has emerged targeting hardware vulnerabilities in the micro-architecture that do not require physical access. We present attacks based on micro-architectural hardware vulnerabilities and the side effects they produce in the system. In addition, we present security mechanisms that can be implemented to address some of these attacks. Most of the security mechanisms target a small set of attack vectors or a single specific attack vector. As many attack vectors exist, solutions must be found to protect against a wide variety of threats. This survey aims to inform designers about the side effects related to attacks and detection mechanisms that have been described in the literature. For this purpose, we present two tables listing and classifying the side effects and detection mechanisms based on the given criteria.},
  archive      = {J_TODAES},
  author       = {Nikolaos-Foivos Polychronou and Pierre-Henri Thevenon and Maxime Puys and Vincent Beroulle},
  doi          = {10.1145/3471936},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  number       = {1},
  pages        = {1:1–35},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {A comprehensive survey of attacks without physical access targeting hardware vulnerabilities in IoT/IIoT devices, and their detection mechanisms},
  volume       = {27},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A delay-adjustable, self-testable flip-flop for soft-error
tolerability and delay-fault testability. <em>TODAES</em>,
<em>26</em>(6), 50:1–12. (<a
href="https://doi.org/10.1145/3462171">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the demand of safety-critical applications (e.g., automobile electronics) increases, various radiation-hardened flip-flops are proposed for enhancing design reliability. Among all flip-flops, Delay-Adjustable D-Flip-Flop (DAD-FF) is specialized in arbitrarily adjusting delay in the design to tolerate soft errors induced by different energy levels. However, due to a lack of testability on DAD-FF, its soft-error tolerability is not yet verified, leading to uncertain design reliability. Therefore, this work proposes Delay-Adjustable, Self-Testable Flip-Flop (DAST-FF), built on top of DAD-FF with two extra MUXs (one for scan test and the other for latching-delay verification) to achieve both soft-error tolerability and testability. Meanwhile, a built-in self-test method is also developed on DAST-FFs to verify the cumulative latching delay before operation. The experimental result shows that for a design with 8,802 DAST-FFs, the built-in self-test method only takes 946 ns to ensure the soft-error tolerability. As to the testability, the enhanced scan capability can be enabled by inserting one extra transmission gate into DAST-FF with only 4.5 area overhead.},
  archive      = {J_TODAES},
  author       = {Dave Y.-W. Lin and Charles H.-P. Wen},
  doi          = {10.1145/3462171},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  number       = {6},
  pages        = {50:1–12},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {A delay-adjustable, self-testable flip-flop for soft-error tolerability and delay-fault testability},
  volume       = {26},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An energy-efficient inference method in convolutional neural
networks based on dynamic adjustment of the pruning level.
<em>TODAES</em>, <em>26</em>(6), 49:1–20. (<a
href="https://doi.org/10.1145/3460972">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we present a low-energy inference method for convolutional neural networks in image classification applications. The lower energy consumption is achieved by using a highly pruned (lower-energy) network if the resulting network can provide a correct output. More specifically, the proposed inference method makes use of two pruned neural networks (NNs), namely mildly and aggressively pruned networks, which are both designed offline. In the system, a third NN makes use of the input data for the online selection of the appropriate pruned network. The third network, for its feature extraction, employs the same convolutional layers as those of the aggressively pruned NN, thereby reducing the overhead of the online management. There is some accuracy loss induced by the proposed method where, for a given level of accuracy, the energy gain of the proposed method is considerably larger than the case of employing any one pruning level. The proposed method is independent of both the pruning method and the network architecture. The efficacy of the proposed inference method is assessed on Eyeriss hardware accelerator platform for some of the state-of-the-art NN architectures. Our studies show that this method may provide, on average, 70\% energy reduction compared to the original NN at the cost of about 3\% accuracy loss on the CIFAR-10 dataset.},
  archive      = {J_TODAES},
  author       = {Mohammad-Ali Maleki and Alireza Nabipour-Meybodi and Mehdi Kamal and Ali Afzali-Kusha and Massoud Pedram},
  doi          = {10.1145/3460972},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  number       = {6},
  pages        = {49:1–20},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {An energy-efficient inference method in convolutional neural networks based on dynamic adjustment of the pruning level},
  volume       = {26},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). High-throughput near-memory processing on CNNs with 3D
HBM-like memory. <em>TODAES</em>, <em>26</em>(6), 48:1–20. (<a
href="https://doi.org/10.1145/3460971">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article discusses the high-performance near-memory neural network (NN) accelerator architecture utilizing the logic die in three-dimensional (3D) High Bandwidth Memory– (HBM) like memory. As most of the previously reported 3D memory-based near-memory NN accelerator designs used the Hybrid Memory Cube (HMC) memory, we first focus on identifying the key differences between HBM and HMC in terms of near-memory NN accelerator design. One of the major differences between the two 3D memories is that HBM has the centralized through- silicon-via (TSV) channels while HMC has distributed TSV channels for separate vaults. Based on the observation, we introduce the Round-Robin Data Fetching and Groupwise Broadcast schemes to exploit the centralized TSV channels for improvement of the data feeding rate for the processing elements. Using synthesized designs in a 28-nm CMOS technology, performance and energy consumption of the proposed architectures with various dataflow models are evaluated. Experimental results show that the proposed schemes reduce the runtime by 16.4–39.3\% on average and the energy consumption by 2.1–5.1\% on average compared to conventional data fetching schemes.},
  archive      = {J_TODAES},
  author       = {Naebeom Park and Sungju Ryu and Jaeha Kung and Jae-Joon Kim},
  doi          = {10.1145/3460971},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  number       = {6},
  pages        = {48:1–20},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {High-throughput near-memory processing on CNNs with 3D HBM-like memory},
  volume       = {26},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A variation-aware hold time fixing methodology for single
flux quantum logic circuits. <em>TODAES</em>, <em>26</em>(6), 47:1–17.
(<a href="https://doi.org/10.1145/3460289">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Single flux quantum (SFQ) logic is a promising technology to replace complementary metal-oxide-semiconductor logic for future exa-scale supercomputing but requires the development of reliable EDA tools that are tailored to the unique characteristics of SFQ circuits, including the need for active splitters to support fanout and clocked logic gates. This article is the first work to present a physical design methodology for inserting hold buffers in SFQ circuits. Our approach is variation-aware, uses common path pessimism removal and incremental placement to minimize the overhead of timing fixes, and can trade off layout area and timing yield. Compared to a previously proposed approach using fixed hold time margins, Monte Carlo simulations show that, averaging across 10 ISCAS’85 benchmark circuits, our proposed method can reduce the number of inserted hold buffers by 8.4\% with a 6.2\% improvement in timing yield and by 21.9\% with a 1.7\% improvement in timing yield.},
  archive      = {J_TODAES},
  author       = {Xi Li and Soheil Nazar Shahsavani and Xuan Zhou and Massoud Pedram and Peter A. Beerel},
  doi          = {10.1145/3460289},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  number       = {6},
  pages        = {47:1–17},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {A variation-aware hold time fixing methodology for single flux quantum logic circuits},
  volume       = {26},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A framework for validation of synthesized MicroElectrode dot
array actuations for digital microfluidic biochips. <em>TODAES</em>,
<em>26</em>(6), 46:1–36. (<a
href="https://doi.org/10.1145/3460437">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Digital Microfluidics is an emerging technology for automating laboratory procedures in biochemistry. With more and more complex biochemical protocols getting mapped to biochip devices and microfluidics receiving a wide adoption, it is becoming indispensable to develop automated tools and synthesis platforms that can enable a smooth transformation from complex cumbersome benchtop laboratory procedures to biochip execution. Given an informal/semi-formal assay description and a target microfluidic grid architecture on which the assay has to be implemented, a synthesis tool typically translates the high-level assay operations to low-level actuation sequences that can drive the assay realization on the grid. With more and more complex biochemical assay protocols being taken up for synthesis and biochips supporting a wider variety of operations (e.g., MicroElectrode Dot Arrays (MEDAs)), the task of assay synthesis is getting intricately complex. Errors in the synthesized assay descriptions may have undesirable consequences in assay operations, leading to unacceptable outcomes after execution on the biochips. In this work, we focus on the challenge of examining the correctness of synthesized protocol descriptions, before they are taken up for realization on a microfluidic biochip. In particular, we take up a protocol description synthesized for a MEDA biochip and adopt a formal analysis method to derive correctness proofs or a violation thereof, pointing to the exact operation in the erroneous translation. We present experimental results on a few bioassay protocols and show the utility of our framework for verifiable protocol synthesis.},
  archive      = {J_TODAES},
  author       = {Pushpita Roy and Ansuman Banerjee},
  doi          = {10.1145/3460437},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  number       = {6},
  pages        = {46:1–36},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {A framework for validation of synthesized MicroElectrode dot array actuations for digital microfluidic biochips},
  volume       = {26},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A runtime reconfigurable design of compute-in-memory–based
hardware accelerator for deep learning inference. <em>TODAES</em>,
<em>26</em>(6), 45:1–18. (<a
href="https://doi.org/10.1145/3460436">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Compute-in-memory (CIM) is an attractive solution to address the “memory wall” challenges for the extensive computation in deep learning hardware accelerators. For custom ASIC design, a specific chip instance is restricted to a specific network during runtime. However, the development cycle of the hardware is normally far behind the emergence of new algorithms. Although some of the reported CIM-based architectures can adapt to different deep neural network (DNN) models, few details about the dataflow or control were disclosed to enable such an assumption. Instruction set architecture (ISA) could support high flexibility, but its complexity would be an obstacle to efficiency. In this article, a runtime reconfigurable design methodology of CIM-based accelerators is proposed to support a class of convolutional neural networks running on one prefabricated chip instance with ASIC-like efficiency. First, several design aspects are investigated: (1) the reconfigurable weight mapping method; (2) the input side of data transmission, mainly about the weight reloading; and (3) the output side of data processing, mainly about the reconfigurable accumulation. Then, a system-level performance benchmark is performed for the inference of different DNN models, such as VGG-8 on a CIFAR-10 dataset and AlexNet GoogLeNet, ResNet-18, and DenseNet-121 on an ImageNet dataset to measure the trade-offs between runtime reconfigurability, chip area, memory utilization, throughput, and energy efficiency.},
  archive      = {J_TODAES},
  author       = {Anni Lu and Xiaochen Peng and Yandong Luo and Shanshi Huang and Shimeng Yu},
  doi          = {10.1145/3460436},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  number       = {6},
  pages        = {45:1–18},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {A runtime reconfigurable design of compute-in-Memory–Based hardware accelerator for deep learning inference},
  volume       = {26},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). FTT-NAS: Discovering fault-tolerant convolutional neural
architecture. <em>TODAES</em>, <em>26</em>(6), 44:1–24. (<a
href="https://doi.org/10.1145/3460288">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the fast evolvement of embedded deep-learning computing systems, applications powered by deep learning are moving from the cloud to the edge. When deploying neural networks (NNs) onto the devices under complex environments, there are various types of possible faults: soft errors caused by cosmic radiation and radioactive impurities, voltage instability, aging, temperature variations, malicious attackers, and so on. Thus, the safety risk of deploying NNs is now drawing much attention. In this article, after the analysis of the possible faults in various types of NN accelerators, we formalize and implement various fault models from the algorithmic perspective. We propose Fault-Tolerant Neural Architecture Search (FT-NAS) to automatically discover convolutional neural network (CNN) architectures that are reliable to various faults in nowadays devices. Then, we incorporate fault-tolerant training (FTT) in the search process to achieve better results, which is referred to as FTT-NAS. Experiments on CIFAR-10 show that the discovered architectures outperform other manually designed baseline architectures significantly, with comparable or fewer floating-point operations (FLOPs) and parameters. Specifically, with the same fault settings, F-FTT-Net discovered under the feature fault model achieves an accuracy of 86.2\% (VS. 68.1\% achieved by MobileNet-V2), and W-FTT-Net discovered under the weight fault model achieves an accuracy of 69.6\% (VS. 60.8\% achieved by ResNet-18). By inspecting the discovered architectures, we find that the operation primitives, the weight quantization range, the capacity of the model, and the connection pattern have influences on the fault resilience capability of NN models.},
  archive      = {J_TODAES},
  author       = {Xuefei Ning and Guangjun Ge and Wenshuo Li and Zhenhua Zhu and Yin Zheng and Xiaoming Chen and Zhen Gao and Yu Wang and Huazhong Yang},
  doi          = {10.1145/3460288},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  number       = {6},
  pages        = {44:1–24},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {FTT-NAS: Discovering fault-tolerant convolutional neural architecture},
  volume       = {26},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Voltage-based covert channels using FPGAs. <em>TODAES</em>,
<em>26</em>(6), 43:1–25. (<a
href="https://doi.org/10.1145/3460229">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Field Programmable Gate Arrays ( FPGAs ) are increasingly used in cloud applications and being integrated into Systems-on-Chip. For these systems, various side-channel attacks on cryptographic implementations have been reported, motivating one to apply proper countermeasures. Beyond cryptographic implementations, maliciously introduced covert channel receivers and transmitters can allow one to exfiltrate other secret information from the FPGA. In this article, we present a fast covert channel on FPGAs, which exploits the on-chip power distribution network. This can be achieved without any logical connection between the transmitter and receiver blocks. Compared to a recently published covert channel with an estimated 4.8 Mbit/s transmission speed, we show 8 Mbit/s transmission and reduced errors from around 3\% to less than 0.003\%. Furthermore, we demonstrate proper transmissions of word-size messages and test the channel in the presence of noise generated from other residing tenants’ modules in the FPGA. When we place and operate other co-tenant modules that require 85\% of the total FPGA area, the error rate increases to 0.02\%, depending on the platform and setup. This error rate is still reasonably low for a covert channel. Overall, the transmitter and receiver work with less than 3–5\% FPGA LUT resources together. We also show the feasibility of other types of covert channel transmitters, in the form of synchronous circuits within the FPGA.},
  archive      = {J_TODAES},
  author       = {Dennis R. E. Gnad and Cong Dang Khoa Nguyen and Syed Hashim Gillani and Mehdi B. Tahoori},
  doi          = {10.1145/3460229},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  number       = {6},
  pages        = {43:1–25},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {Voltage-based covert channels using FPGAs},
  volume       = {26},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Placement of digital microfluidic biochips via a new
evolutionary algorithm. <em>TODAES</em>, <em>26</em>(6), 42:1–22. (<a
href="https://doi.org/10.1145/3460230">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Digital microfluidic biochips (DMFBs) have been a revolutionary platform for automating and miniaturizing laboratory procedures with the advantages of flexibility and reconfigurability. The placement problem is one of the most challenging issues in the design automation of DMFBs. It contains three interacting NP-hard sub-problems: resource binding, operation scheduling, and module placement. Besides, during the optimization of placement, complex constraints must be satisfied to guarantee feasible solutions, such as precedence constraints, storage constraints, and resource constraints. In this article, a new placement method for DMFB is proposed based on an evolutionary algorithm with novel heuristic-based decoding strategies for both operation scheduling and module placement. Specifically, instead of using the previous list scheduler and path scheduler for decoding operation scheduling chromosomes, we introduce a new heuristic scheduling algorithm (called order scheduler) with fewer limitations on the search space for operation scheduling solutions. Besides, a new 3D placer that combines both scheduling and placement is proposed where the usage of the microfluidic array over time in the chip is recorded flexibly, which is able to represent more feasible solutions for module placement. Compared with the state-of-the-art placement methods (T-tree and 3D-DDM), the experimental results demonstrate the superiority of the proposed method based on several real-world bioassay benchmarks. The proposed method can find the optimal results with the minimum assay completion time for all test cases.},
  archive      = {J_TODAES},
  author       = {Chen Jiang and Bo Yuan and Tsung-Yi Ho and Xin Yao},
  doi          = {10.1145/3460230},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  number       = {6},
  pages        = {42:1–22},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {Placement of digital microfluidic biochips via a new evolutionary algorithm},
  volume       = {26},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A conditionally chaotic physically unclonable function
design framework with high reliability. <em>TODAES</em>, <em>26</em>(6),
41:1–24. (<a href="https://doi.org/10.1145/3460004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Physically Unclonable Function (PUF) circuits are promising low-overhead hardware security primitives, but are often gravely susceptible to machine learning–based modeling attacks. Recently, chaotic PUF circuits have been proposed that show greater robustness to modeling attacks. However, they often suffer from unacceptable overhead, and their analog components are susceptible to low reliability. In this article, we propose the concept of a conditionally chaotic PUF that enhances the reliability of the analog components of a chaotic PUF circuit to a level at par with their digital counterparts. A conditionally chaotic PUF has two modes of operation: bistable and chaotic , and switching between these two modes is conveniently achieved by setting a mode-control bit (at a secret position) in an applied input challenge. We exemplify our PUF design framework for two different PUF variants—the CMOS Arbiter PUF and a previously proposed hybrid CMOS-memristor PUF, combined with a hardware realization of the Lorenz system as the chaotic component. Through detailed circuit simulation and modeling attack experiments, we demonstrate that the proposed PUF circuits are highly robust to modeling and cryptanalytic attacks, without degrading the reliability of the original PUF that was combined with the chaotic circuit, and incurs acceptable hardware footprint.},
  archive      = {J_TODAES},
  author       = {Saranyu Chattopadhyay and Pranesh Santikellur and Rajat Subhra Chakraborty and Jimson Mathew and Marco Ottavi},
  doi          = {10.1145/3460004},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  number       = {6},
  pages        = {41:1–24},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {A conditionally chaotic physically unclonable function design framework with high reliability},
  volume       = {26},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Machine learning for electronic design automation: A survey.
<em>TODAES</em>, <em>26</em>(5), 40:1–46. (<a
href="https://doi.org/10.1145/3451179">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the down-scaling of CMOS technology, the design complexity of very large-scale integrated is increasing. Although the application of machine learning (ML) techniques in electronic design automation (EDA) can trace its history back to the 1990s, the recent breakthrough of ML and the increasing complexity of EDA tasks have aroused more interest in incorporating ML to solve EDA tasks. In this article, we present a comprehensive review of existing ML for EDA studies, organized following the EDA hierarchy.},
  archive      = {J_TODAES},
  author       = {Guyue Huang and Jingbo Hu and Yifan He and Jialong Liu and Mingyuan Ma and Zhaoyang Shen and Juejian Wu and Yuanfan Xu and Hengrui Zhang and Kai Zhong and Xuefei Ning and Yuzhe Ma and Haoyu Yang and Bei Yu and Huazhong Yang and Yu Wang},
  doi          = {10.1145/3451179},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  number       = {5},
  pages        = {40:1–46},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {Machine learning for electronic design automation: A survey},
  volume       = {26},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). FastCFI: Real-time control-flow integrity using FPGA without
code instrumentation. <em>TODAES</em>, <em>26</em>(5), 39:1–39. (<a
href="https://doi.org/10.1145/3458471">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Control-Flow Integrity (CFI) is an effective defense technique against a variety of memory-based cyber attacks. CFI is usually enforced through software methods, which entail considerable performance overhead. Hardware-based CFI techniques can largely avoid performance overhead, but typically rely on code instrumentation, forming a non-trivial hurdle to the application of CFI. Taking advantage of the tradeoff between computing efficiency and flexibility of FPGA, we develop FastCFI, an FPGA-based CFI system that can perform fine-grained and stateful checking without code instrumentation. We also propose an automated Verilog generation technique that facilitates fast deployment of FastCFI, and a compression algorithm for reducing the hardware expense. Experiments on popular benchmarks confirm that FastCFI can detect fine-grained CFI violations over unmodified binaries. When using FastCFI on prevalent benchmarks, we demonstrate its capability to detect fine-grained CFI violations in unmodified binaries, while incurring an average of 0.36\% overhead and a maximum of 2.93\% overhead.},
  archive      = {J_TODAES},
  author       = {Lang Feng and Jeff Huang and Jiang Hu and Abhijith Reddy},
  doi          = {10.1145/3458471},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  number       = {5},
  pages        = {39:1–39},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {FastCFI: Real-time control-flow integrity using FPGA without code instrumentation},
  volume       = {26},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A module-linking graph assisted hybrid optimization
framework for custom analog and mixed-signal circuit parameter
synthesis. <em>TODAES</em>, <em>26</em>(5), 38:1–22. (<a
href="https://doi.org/10.1145/3456722">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Analog and mixed-signal (AMS) computer-aided design tools are of increasing interest owing to demand for the wide range of AMS circuit specifications in the modern system on a chip and faster time to market requirement. Traditionally, to accelerate the design process, the AMS system is decomposed into smaller components (called modules ) such that the complexity and evaluation of each module are more manageable. However, this decomposition poses an interface problem, where the module’s input-output states deviate from when combined to construct the AMS system, and thus degrades the system expected performance. In this article, we develop a tool module-linking-graph assisted hybrid parameter search engine with neural networks (MOHSENN) to overcome these obstacles. We propose a module-linking-graph that enforces equality of the modules’ interfaces during the parameter search process and apply surrogate modeling of the AMS circuit via neural networks. Further, we propose a hybrid search consisting of a global optimization with fast neural network models and a local optimization with accurate SPICE models to expedite the parameter search process while maintaining the accuracy. To validate the effectiveness of the proposed approach, we apply MOHSENN to design a successive approximation register analog-to-digital converter in 65-nm CMOS technology. This demonstrated that the search time improves by a factor of 5 and 700 compared to conventional hierarchical and flat design approaches, respectively, with improved performance.},
  archive      = {J_TODAES},
  author       = {Mohsen Hassanpourghadi and Rezwan A. Rasul and Mike Shuo-Wei Chen},
  doi          = {10.1145/3456722},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  number       = {5},
  pages        = {38:1–22},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {A module-linking graph assisted hybrid optimization framework for custom analog and mixed-signal circuit parameter synthesis},
  volume       = {26},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Pseudo-3D physical design flow for monolithic 3D ICs:
Comparisons and enhancements. <em>TODAES</em>, <em>26</em>(5), 37:1–25.
(<a href="https://doi.org/10.1145/3453480">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Studies have shown that monolithic 3D ( M3D ) ICs outperform the existing through-silicon-via ( TSV ) -based 3D ICs in terms of power, performance, and area ( PPA ) metrics, primarily due to the orders of magnitude denser vertical interconnections offered by the nano-scale monolithic inter-tier vias. In order to facilitate faster industry adoption of the M3D technologies, physical design tools and methodologies are essential. Recent academic efforts in developing an EDA algorithm for 3D ICs, mainly targeting placement using TSVs, are inadequate to provide commercial-quality GDS layouts. Lately, pseudo-3D approaches have been devised, which utilize commercial 2D IC EDA engines with tricks that help them operate as an efficient 3D IC CAD tool. In this article, we provide thorough discussions and fair comparisons (both qualitative and quantitative) of the state-of-the-art pseudo-3D design flows, with analysis of limitations in each design flow and solutions to improve their PPA metrics. Moreover, we suggest a hybrid pseudo-3D design flow that achieves both benefits. Our enhancements and the inter-mixed design flow, provide up to an additional 26\% wirelength, 10\% power consumption, and 23\% of power-delay-product improvements.},
  archive      = {J_TODAES},
  author       = {Heechun Park and Bon Woong Ku and Kyungwook Chang and Da Eun Shim and Sung Kyu Lim},
  doi          = {10.1145/3453480},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  number       = {5},
  pages        = {37:1–25},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {Pseudo-3D physical design flow for monolithic 3D ICs: Comparisons and enhancements},
  volume       = {26},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Design flow and methodology for dynamic and static
energy-constrained scheduling framework in heterogeneous multicore
embedded devices. <em>TODAES</em>, <em>26</em>(5), 36:1–18. (<a
href="https://doi.org/10.1145/3450448">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With Internet of things technologies, billions of embedded devices, including smart gateways, smart phones, and mobile robots, are connected and deeply integrated. Almost all these embedded devices are battery-constrained and energy-limited systems. In recent years, several works used energy pre-assignment techniques to study the dynamic energy-constrained scheduling of a parallel application in heterogeneous multicore embedded systems. However, the existing energy pre-assignment techniques cannot satisfy the actual energy constraint, because it is the joint constraint on dynamic energy and static energy. Further, the modeling and verification of these works are based on the simulations, which have not been verified in real embedded devices. This study aims to propose a dynamic and static energy-constrained scheduling framework in heterogeneous multicore embedded devices. Solving this problem can utilize existing energy pre-assignment techniques, but it requires a deeply integrated design flow and methodology. The design flow consists of four processes: (1) power and energy modeling; (2) power parameter measurement; (3) basic framework design including energy pre-assignment; and (4) framework optimization. Each design flow has corresponding design methodology. Both our theoretical analysis and practical verification using the low-power ODROID-XU4 device confirm the effectiveness of the proposed framework.},
  archive      = {J_TODAES},
  author       = {Guoqi Xie and Hao Peng and Xiongren Xiao and Yao Liu and Renfa Li},
  doi          = {10.1145/3450448},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  number       = {5},
  pages        = {36:1–18},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {Design flow and methodology for dynamic and static energy-constrained scheduling framework in heterogeneous multicore embedded devices},
  volume       = {26},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Dataflow model–based software synthesis framework for
parallel and distributed embedded systems. <em>TODAES</em>,
<em>26</em>(5), 35:1–38. (<a
href="https://doi.org/10.1145/3447680">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing software development methodologies mostly assume that an application runs on a single device without concern about the non-functional requirements of an embedded system such as latency and resource consumption. Besides, embedded software is usually developed after the hardware platform is determined, since a non-negligible portion of the code depends on the hardware platform. In this article, we present a novel model-based software synthesis framework for parallel and distributed embedded systems. An application is specified as a set of tasks with the given rules for execution and communication. Having such rules enables us to perform static analysis to check some software errors at compile-time to reduce the verification difficulty. Platform-specific programs are synthesized automatically after the mapping of tasks onto processing elements is determined. The proposed framework is expandable to support new hardware platforms easily. The proposed communication code synthesis method is extensible and flexible to support various communication methods between devices. In addition, the fault-tolerant feature can be added by modifying the task graph automatically according to the selected fault-tolerance configurations by the user. The viability of the proposed software development methodology is evaluated with a real-life surveillance application that runs on six processing elements.},
  archive      = {J_TODAES},
  author       = {Eunjin Jeong and Dowhan Jeong and Soonhoi Ha},
  doi          = {10.1145/3447680},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  number       = {5},
  pages        = {35:1–38},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {Dataflow model–based software synthesis framework for parallel and distributed embedded systems},
  volume       = {26},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A dynamic huffman coding method for reliable TLC NAND flash
memory. <em>TODAES</em>, <em>26</em>(5), 34:1–25. (<a
href="https://doi.org/10.1145/3446771">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the progress of the manufacturing process, NAND flash memory has evolved from the single-level cell and multi-level cell into the triple-level cell (TLC). NAND flash memory has physical problems such as the characteristic of erase-before-write and the limitation of program/erase cycles. Moreover, TLC NAND flash memory has low reliability and short lifetime. Thus, we propose a dynamic Huffman coding method that can apply to the write operations of NAND flash memory. The proposed method exploits observations from a Huffman tree and machine learning from data patterns to dynamically select a suitable Huffman coding. According to the experimental results, the proposed method can improve the reliability of TLC NAND flash memory and also consider the compression performance for those applications that require the Huffman coding.},
  archive      = {J_TODAES},
  author       = {Chin-Hsien Wu and Hao-Wei Zhang and Chia-Wei Liu and Ta-Ching Yu and Chi-Yen Yang},
  doi          = {10.1145/3446771},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  number       = {5},
  pages        = {34:1–25},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {A dynamic huffman coding method for reliable TLC NAND flash memory},
  volume       = {26},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). QuadSeal: Quadruple balancing to mitigate power analysis
attacks with variability effects and electromagnetic fault injection
attacks. <em>TODAES</em>, <em>26</em>(5), 33:1–36. (<a
href="https://doi.org/10.1145/3443706">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Side channel analysis attacks employ the emanated side channel information to deduce the secret keys from cryptographic implementations by analyzing the power traces during execution or scrutinizing faulty outputs. To be effective, a countermeasure must remove or conceal as many as possible side channels. However, many of the countermeasures against side channel attacks are applied independently. In this article, the authors present a novel countermeasure (referred to as QuadSeal ) against Power Analysis Attacks and Electromagentic Fault Injection Attacks (FIAs), which is an extension of the work proposed in Reference [27]. The proposed solution relies on algorithmically balancing both Hamming distances and Hamming weights (where the bit transitions on the registers and gates are balanced, and the total number of 1s and 0s are balanced) by the use of four identical circuits with differing inputs and modified SubByte tables. By randomly rotating the four encryptions, the system is protected against variations, path imbalances, and aging effects. After generating the ciphertext, the output of each circuit is compared against each other to detect any fault injections or to correct the faulty ciphertext to gain reliability. The proposed countermeasure allows components to be switched off to save power or to run four executions in parallel for high performance when resistance against power analysis attacks is not of high priority, which is not available with the existing countermeasures (except software based where source code can be changed). The proposed countermeasure is implemented for Advanced Encryption Standard (AES) and tested against Correlation Power Analysis and Mutual Information Attacks attacks (for up to a million traces), and none of the secret keys was found even after one million power traces (the unprotected AES circuit is vulnerable for power analysis attacks within 5,000 power traces). A detection circuit (referred to as C-FIA circuit) is operated using the algorithmic redundancy presented in four circuits of QuadSeal to mitigate Electromagnetic Fault Injection Attacks. Using Synopsys PrimeTime, we measured the power dissipation of QuadSeal registers and XOR gates to test the effectiveness of Quadruple balancing methodology. We tested the QuadSeal countermeasure with C-FIA circuit against Differential Fault Analysis Attacks up to one million traces; no bytes of the secret key were found. This is the smallest known circuit that is capable of withstanding power-based side channel attacks when electromagnetic injection attack resistance, process variations, path imbalances, and aging effects are considered.},
  archive      = {J_TODAES},
  author       = {Darshana Jayasinghe and Aleksandar Ignjatovic and Roshan Ragel and Jude Angelo Ambrose and Sri Parameswaran},
  doi          = {10.1145/3443706},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  number       = {5},
  pages        = {33:1–36},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {QuadSeal: Quadruple balancing to mitigate power analysis attacks with variability effects and electromagnetic fault injection attacks},
  volume       = {26},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Security threat analyses and attack models for approximate
computing systems: From hardware and micro-architecture perspectives.
<em>TODAES</em>, <em>26</em>(4), 32:1–31. (<a
href="https://doi.org/10.1145/3442380">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Approximate computing (AC) represents a paradigm shift from conventional precise processing to inexact computation but still satisfying the system requirement on accuracy. The rapid progress on the development of diverse AC techniques allows us to apply approximate computing to many computation-intensive applications. However, the utilization of AC techniques could bring in new unique security threats to computing systems. This work does a survey on existing circuit-, architecture-, and compiler-level approximate mechanisms/algorithms, with special emphasis on potential security vulnerabilities. Qualitative and quantitative analyses are performed to assess the impact of the new security threats on AC systems. Moreover, this work proposes four unique visionary attack models, which systematically cover the attacks that build covert channels, compensate approximation errors, terminate normal error resilience mechanisms, and propagate additional errors. To thwart those attacks, this work further offers the guideline of countermeasure designs. Several case studies are provided to illustrate the implementation of the suggested countermeasures.},
  archive      = {J_TODAES},
  author       = {Pruthvy Yellu and Landon Buell and Miguel Mark and Michel A. Kinsy and Dongpeng Xu and Qiaoyan Yu},
  doi          = {10.1145/3442380},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  number       = {4},
  pages        = {32:1–31},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {Security threat analyses and attack models for approximate computing systems: From hardware and micro-architecture perspectives},
  volume       = {26},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Design automation for tree-based nearest neighborhood–aware
placement of high-speed cellular automata on FPGA with scan path
insertion. <em>TODAES</em>, <em>26</em>(4), 31:1–34. (<a
href="https://doi.org/10.1145/3446206">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cellular Automata (CA) is attractive for high-speed VLSI implementation due to modularity, cascadability, and locality of interconnections confined to neighboring logic cells. However, this outcome is not easily transferable to tree-structured CA, since the neighbors having half and double the index value of the current CA cell under question can be sufficiently distanced apart on the FPGA floor. Challenges to meet throughput requirements, seamlessly translate algorithmic modifications for changing application specifications to gate level architectures and to address reliability challenges of semiconductor chips are ever increasing. Thus, a proper design framework assisting automation of synthesizable, delay-optimized VLSI architecture descriptions facilitating testability is desirable. In this article, we have automated the generation of hardware description of tree-structured CA that includes a built-in scan path realized with zero area and delay overhead. The scan path facilitates seeding the CA, state modification, and fault localization on the FPGA fabric. Three placement algorithms were proposed to ensure maximum physical adjacency amongst neighboring CA cells, arranged in a multi-columnar fashion on the FPGA grid. Our proposed architectures outperform implementations arising out of standard placers and behavioral designs, existing tree mapping strategies, and state-of-the-art FPGA centric error detection architectures in area and speed.},
  archive      = {J_TODAES},
  author       = {Ayan Palchaudhuri and Sandeep Sharma and Anindya Sundar Dhar},
  doi          = {10.1145/3446206},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  number       = {4},
  pages        = {31:1–34},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {Design automation for tree-based nearest neighborhood–aware placement of high-speed cellular automata on FPGA with scan path insertion},
  volume       = {26},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Design space optimization of shared memory architecture in
accelerator-rich systems. <em>TODAES</em>, <em>26</em>(4), 30:1–31. (<a
href="https://doi.org/10.1145/3446001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Shared memory architectures, as opposed to private-only memories, provide a viable alternative to meet the ever-increasing memory requirements of multi-accelerator systems to achieve high performance under stringent area and energy constraints. However, an impulsive memory sharing degrades performance due to network contention and latency to access shared memory. We propose the Accelerator Shared Memory (ASM) framework to provide an optimal private/shared memory configuration and shared data allocation under a system’s resource and network constraints. Evaluations show ASM provides up to 34.35\% and 31.34\% improvement in performance and energy, respectively, over baseline systems.},
  archive      = {J_TODAES},
  author       = {Mitali Sinha and Gade Sri Harsha and Pramit Bhattacharyya and Sujay Deb},
  doi          = {10.1145/3446001},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  number       = {4},
  pages        = {30:1–31},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {Design space optimization of shared memory architecture in accelerator-rich systems},
  volume       = {26},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Security assessment of dynamically obfuscated scan chain
against oracle-guided attacks. <em>TODAES</em>, <em>26</em>(4), 29:1–27.
(<a href="https://doi.org/10.1145/3444960">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Logic locking has emerged as a promising solution to protect integrated circuits against piracy and tampering. However, the security provided by existing logic locking techniques is often thwarted by Boolean satisfiability (SAT)-based oracle-guided attacks. Criteria for successful SAT attacks on locked circuits include: (i) the circuit under attack is fully combinational, or (ii) the attacker has scan chain access. To address the threat posed by SAT-based attacks, we adopt the dynamically obfuscated scan chain (DOSC) architecture and illustrate its resiliency against the SAT attacks when inserted into the scan chain of an obfuscated design. We demonstrate, both mathematically and experimentally, that DOSC exponentially increases the resiliency against key extraction by SAT attack and its variants. Our results show that the mathematical estimation of attack complexity correlates to the experimental results with an accuracy of 95\% or better. Along with the formal proof, we model DOSC architecture to its equivalent combinational circuit and perform SAT attack to evaluate its resiliency empirically. Our experiments demonstrate that SAT attack on DOSC-inserted benchmark circuits timeout at minimal test time overhead, and while DOSC requires less than 1\% area and power overhead.},
  archive      = {J_TODAES},
  author       = {M Sazadur Rahman and Adib Nahiyan and Fahim Rahman and Saverio Fazzari and Kenneth Plaks and Farimah Farahmandi and Domenic Forte and Mark Tehranipoor},
  doi          = {10.1145/3444960},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  number       = {4},
  pages        = {29:1–27},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {Security assessment of dynamically obfuscated scan chain against oracle-guided attacks},
  volume       = {26},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). TAAL: Tampering attack on any key-based logic locked
circuits. <em>TODAES</em>, <em>26</em>(4), 28:1–22. (<a
href="https://doi.org/10.1145/3442379">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the globalization of semiconductor manufacturing and test processes, the system-on-a-chip (SoC) designers no longer design the complete SoC and manufacture chips on their own. This outsourcing of the design and manufacturing of Integrated Circuits (ICs) has resulted in several threats, such as overproduction of ICs, sale of out-of-specification/rejected ICs, and piracy of Intellectual Properties (IPs). Logic locking has emerged as a promising defense strategy against these threats. However, various attacks about the extraction of secret keys have undermined the security of logic locking techniques. Over the years, researchers have proposed different techniques to prevent existing attacks. In this article, we propose a novel attack that can break any logic locking techniques that rely on the stored secret key. This proposed TAAL attack is based on implanting a hardware Trojan in the netlist, which leaks the secret key to an adversary once activated. As an untrusted foundry can extract the netlist of a design from the layout/mask information, it is feasible to implement such a hardware Trojan. All three proposed types of TAAL attacks can be used for extracting secret keys. We have introduced the models for both the combinational and sequential hardware Trojans that evade manufacturing tests. An adversary only needs to choose one hardware Trojan out of a large set of all possible Trojans to launch the TAAL attack.},
  archive      = {J_TODAES},
  author       = {Ayush Jain and Ziqi Zhou and Ujjwal Guin},
  doi          = {10.1145/3442379},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  number       = {4},
  pages        = {28:1–22},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {TAAL: Tampering attack on any key-based logic locked circuits},
  volume       = {26},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Efficient one-pass synthesis for digital microfluidic
biochips. <em>TODAES</em>, <em>26</em>(4), 27:1–21. (<a
href="https://doi.org/10.1145/3446880">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Digital microfluidics biochips are a promising emerging technology that provides fluidic experimental capabilities on a chip (i.e., following the lab-on-a-chip paradigm). However, the design of such biochips still constitutes a challenging task that is usually tackled by multiple individual design steps, such as binding, scheduling, placement, and routing. Performing these steps consecutively may lead to design gaps and infeasible results. To address these shortcomings, the concept of one-pass design for digital microfluidics biochips has recently been proposed—a holistic approach avoiding the design gaps by considering the whole synthesis process as large. But implementations of this concept available thus far suffer from either high computational effort or costly results. In this article, we present an efficient one-pass solution that is runtime efficient (i.e., rarely needing more than a second to successfully synthesize a design) while, at the same time, producing better results than previously published heuristic approaches. Experimental results confirm the benefits of the proposed solution and allow for realizing really large assays composed of thousands of operations in reasonable runtime.},
  archive      = {J_TODAES},
  author       = {Naser Mohammadzadeh and Robert Wille and Oliver Keszocze},
  doi          = {10.1145/3446880},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  number       = {4},
  pages        = {27:1–21},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {Efficient one-pass synthesis for digital microfluidic biochips},
  volume       = {26},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Directed test generation for activation of security
assertions in RTL models. <em>TODAES</em>, <em>26</em>(4), 26:1–28. (<a
href="https://doi.org/10.1145/3441297">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Assertions are widely used for functional validation as well as coverage analysis for both software and hardware designs. Assertions enable runtime error detection as well as faster localization of errors. While there is a vast literature on both software and hardware assertions for monitoring functional scenarios, there is limited effort in utilizing assertions to monitor System-on-Chip (SoC) security vulnerabilities. We have identified common SoC security vulnerabilities and defined several classes of assertions to enable runtime checking of security vulnerabilities. A major challenge in assertion-based validation is how to activate the security assertions to ensure that they are valid. While existing test generation using model checking is promising, it cannot generate directed tests for large designs due to state space explosion. We propose an automated and scalable mechanism to generate directed tests using a combination of symbolic execution and concrete simulation of RTL models. Experimental results on diverse benchmarks demonstrate that the directed tests are able to activate security assertions non-vacuously.},
  archive      = {J_TODAES},
  author       = {Hasini Witharana and Yangdi Lyu and Prabhat Mishra},
  doi          = {10.1145/3441297},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  number       = {4},
  pages        = {26:1–28},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {Directed test generation for activation of security assertions in RTL models},
  volume       = {26},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Equivalent faults under launch-on-shift (LOS) tests with
equal primary input vectors. <em>TODAES</em>, <em>26</em>(4), 25:1–15.
(<a href="https://doi.org/10.1145/3440013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A recent work showed that it is possible to transform a single-cycle test for stuck-at faults into a launch-on-shift (LOS) test that is guaranteed to detect the same stuck-at faults without any logic or fault simulation. The LOS test also detects transition faults. This was used for obtaining a compact LOS test set that detects both types of faults. In the scenario where LOS tests are used for both stuck-at and transition faults, this article observes that, under certain conditions, the detection of a stuck-at fault guarantees the detection of a corresponding transition fault. This implies that the two faults are equivalent under LOS tests. Equivalence can be used for reducing the set of target faults for test generation and test compaction. The article develops this notion of equivalence under LOS tests with equal primary input vectors and provides an efficient procedure for identifying it. It presents experimental results to demonstrate that such equivalences exist in benchmark circuits, and shows an unexpected effect on a test compaction procedure.},
  archive      = {J_TODAES},
  author       = {Irith Pomeranz},
  doi          = {10.1145/3440013},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  number       = {4},
  pages        = {25:1–15},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {Equivalent faults under launch-on-shift (LOS) tests with equal primary input vectors},
  volume       = {26},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Machine learning for statistical modeling: The case of
perpendicular spin-transfer-torque random access memory.
<em>TODAES</em>, <em>26</em>(3), 24:1–17. (<a
href="https://doi.org/10.1145/3440014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a methodology to perform process variation-aware device and circuit design using fully physics-based simulations within limited computational resources, without developing a compact model. Machine learning (ML), specifically a support vector regression (SVR) model, has been used. The SVR model has been trained using a dataset of devices simulated a priori, and the accuracy of prediction by the trained SVR model has been demonstrated. To produce a switching time distribution from the trained ML model, we only had to generate the dataset to train and validate the model, which needed ∼500 hours of computation. On the other hand, if 10 6 samples were to be simulated using the same computation resources to generate a switching time distribution from micromagnetic simulations, it would have taken ∼250 days. Spin-transfer-torque random access memory (STTRAM) has been used to demonstrate the method. However, different physical systems may be considered, different ML models can be used for different physical systems and/or different device parameter sets, and similar ends could be achieved by training the ML model using measured device data.},
  archive      = {J_TODAES},
  author       = {Urmimala Roy and Tanmoy Pramanik and Subhendu Roy and Avhishek Chatterjee and Leonard F. Register and Sanjay K. Banerjee},
  doi          = {10.1145/3440014},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  number       = {3},
  pages        = {24:1–17},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {Machine learning for statistical modeling: The case of perpendicular spin-transfer-torque random access memory},
  volume       = {26},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Covering test holes of functional broadside tests.
<em>TODAES</em>, <em>26</em>(3), 23:1–15. (<a
href="https://doi.org/10.1145/3441282">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Functional broadside tests were developed to avoid overtesting of delay faults. The tests achieve this goal by creating functional operation conditions during their functional capture cycles. To increase the achievable fault coverage, close-to-functional scan-based tests are allowed to deviate from functional operation conditions. This article suggests that a more comprehensive functional broadside test set can be obtained by replacing target faults that cannot be detected with faults that have similar (but not identical) detection conditions. A more comprehensive functional broadside test set has the advantage that it still maintains functional operation conditions. It covers the test holes created when target faults cannot be detected by detecting similar faults. The article considers the case where the target faults are transition faults. When a standard transition fault, with an extra delay of a single clock cycle, cannot be detected, an unspecified transition fault is used instead. An unspecified transition fault captures the behaviors of transition faults with different extra delays. When this fault cannot be detected, a stuck-at fault is used instead. A stuck-at fault has some of the detection conditions of a transition fault. Multicycle functional broadside tests are used to allow unspecified transition faults to be detected. As a by-product, test compaction also occurs. The structure of the test generation procedure accommodates the complexity of producing functional broadside tests by considering the target as well as replacement faults together. Experimental results for benchmark circuits demonstrate the fault coverage improvements achieved, and the effect on the number of tests.},
  archive      = {J_TODAES},
  author       = {Irith Pomeranz},
  doi          = {10.1145/3441282},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  number       = {3},
  pages        = {23:1–15},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {Covering test holes of functional broadside tests},
  volume       = {26},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). MaxSense: Side-channel sensitivity maximization for trojan
detection using statistical test patterns. <em>TODAES</em>,
<em>26</em>(3), 22:1–21. (<a
href="https://doi.org/10.1145/3436820">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Detection of hardware Trojans is vital to ensure the security and trustworthiness of System-on-Chip (SoC) designs. Side-channel analysis is effective for Trojan detection by analyzing various side-channel signatures such as power, current, and delay. In this article, we propose an efficient test generation technique to facilitate side-channel analysis utilizing dynamic current. While early work on current-aware test generation has proposed several promising ideas, there are two major challenges in applying it on large designs: (i) The test generation time grows exponentially with the design complexity, and (ii) it is infeasible to detect Trojans, since the side-channel sensitivity is marginal compared to the noise and process variations. Our proposed work addresses both challenges by effectively exploiting the affinity between the inputs and rare (suspicious) nodes. The basic idea is to quickly find the profitable ordered pairs of test vectors that can maximize side-channel sensitivity. This article makes two important contributions: (i) It proposed an efficient test generation algorithm that can produce the first patterns in the test vectors to maximize activation of suspicious nodes using an SMT solver, and (ii) it developed a genetic-algorithm based test generation technique to produce the second patterns in the test vectors to maximize the switching in the suspicious regions while minimizing the switching in the rest of the design. Our experimental results demonstrate that we can drastically improve both the side-channel sensitivity (62× on average) and time complexity (13× on average) compared to the state-of-the-art test generation techniques.},
  archive      = {J_TODAES},
  author       = {Yangdi Lyu and Prabhat Mishra},
  doi          = {10.1145/3436820},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  number       = {3},
  pages        = {22:1–21},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {MaxSense: Side-channel sensitivity maximization for trojan detection using statistical test patterns},
  volume       = {26},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Fault-based built-in self-test and evaluation of phase
locked loops. <em>TODAES</em>, <em>26</em>(3), 20:1–18. (<a
href="https://doi.org/10.1145/3427911">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the increasing pressure to obtain near-zero defect rates for the automotive industry, there is a need to explore built-in self-test and other non-traditional test techniques for embedded mixed-signal components, such as PLLs, DC-DC converters, and data converters. This article presents a very low-cost built-in self-test technique for PLLs specifically designed for fault detection. The methodology relies on exciting the PLL loop in one location via a pseudo-random signal with noise characteristics and observing the response from another location in the loop via all digital circuitry, thereby inducing low area and performance overhead. The BIST circuit along with a PLL under test is designed in 65 nm technology. Fault simulations performed at the transistor and system-level show that the majority of non-catastrophic faults that result in parametric failures can be detected with the proposed approach.},
  archive      = {J_TODAES},
  author       = {Mehmet Ince and Ender Yilmaz and Wei Fu and Joonsung Park and Krishnaswamy Nagaraj and Leroy Winemberg and Sule Ozev},
  doi          = {10.1145/3427911},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  number       = {3},
  pages        = {20:1–18},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {Fault-based built-in self-test and evaluation of phase locked loops},
  volume       = {26},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). HeM3D: Heterogeneous manycore architecture based on
monolithic 3D vertical integration. <em>TODAES</em>, <em>26</em>(2),
16:1–21. (<a href="https://doi.org/10.1145/3424239">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Heterogeneous manycore architectures are the key to efficiently execute compute- and data-intensive applications. Through-silicon-via (TSV)-based 3D manycore system is a promising solution in this direction as it enables the integration of disparate computing cores on a single system. Recent industry trends show the viability of 3D integration in real products (e.g., Intel Lakefield SoC Architecture, the AMD Radeon R9 Fury X graphics card, and Xilinx Virtex-7 2000T/H580T, etc.). However, the achievable performance of conventional TSV-based 3D systems is ultimately bottlenecked by the horizontal wires (wires in each planar die). Moreover, current TSV 3D architectures suffer from thermal limitations. Hence, TSV-based architectures do not realize the full potential of 3D integration. Monolithic 3D (M3D) integration, a breakthrough technology to achieve “More Moore and More Than Moore,” opens up the possibility of designing cores and associated network routers using multiple layers by utilizing monolithic inter-tier vias (MIVs) and hence, reducing the effective wire length. Compared to TSV-based 3D integrated circuits (ICs), M3D offers the “true” benefits of vertical dimension for system integration: the size of an MIV used in M3D is over 100 × smaller than a TSV. This dramatic reduction in via size and the resulting increase in density opens up numerous opportunities for design optimizations in 3D manycore systems: designers can use up to millions of MIVs for ultra-fine-grained 3D optimization, where individual cores and routers can be spread across multiple tiers for extreme power and performance optimization. In this work, we demonstrate how M3D-enabled vertical core and uncore elements offer significant performance and thermal improvements in manycore heterogeneous architectures compared to its TSV-based counterpart. To overcome the difficult optimization challenges due to the large design space and complex interactions among the heterogeneous components (CPU, GPU, Last Level Cache, etc.) in a M3D-based manycore chip, we leverage novel design-space exploration algorithms to trade off different objectives. The proposed M3D-enabled heterogeneous architecture, called HeM3D , outperforms its state-of-the-art TSV-equivalent counterpart by up to 18.3\% in execution time while being up to 19°C cooler.},
  archive      = {J_TODAES},
  author       = {Aqeeb Iqbal Arka and Biresh Kumar Joardar and Ryan Gary Kim and Dae Hyun Kim and Janardhan Rao Doppa and Partha Pratim Pande},
  doi          = {10.1145/3424239},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  number       = {2},
  pages        = {16:1–21},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {HeM3D: Heterogeneous manycore architecture based on monolithic 3D vertical integration},
  volume       = {26},
  year         = {2021},
}
</textarea>
</details></li>
</ul>

</body>
</html>
