<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>TKDD_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="tkdd---161">TKDD - 161</h2>
<ul>
<li><details>
<summary>
(2021). Overlapping graph clustering in attributed networks via
generalized cluster potential game. <em>TKDD</em>, <em>18</em>(1), 1–26.
(<a href="https://doi.org/10.1145/3597436">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Overlapping graph clustering is essential to understand the nature and behavior of real complex systems including human interactions, technical systems and transportation network. However, in addition of topological structure, many real-world networked systems contain spare factors, i.e., attributes of networks. Despite the considerable efforts that have been made in graph clustering, they only concentrate on the topological structure, which lack a profound understanding of cluster configuration on attributed graphs. To address this great challenge, in this article, we propose a new overlapping graph clustering algorithm by integrating the topological and attributive information into a cluster potential game (CPG). Firstly, a generalized definition of the utility function is provided, which measures the payoff of each node based on different node-to-cluster distance functions. It is worth mentioning that the model we proposed is able to associate with the classic ordinal potential game well. Then, we define the measures of both tightness and the homogeneity in each cluster, and introduce a novel two-way selection mechanism. The goal is to extend the flexibility of the cluster potential game, so that one can achieve a win-win situation between nodes and clusters. Finally, a distributed and heterogeneous multiagent system (DHMAS) is carefully designed based on a fast self-learning algorithm (SLA) for attributed overlapping graph clustering. Two series of experiments are implemented in multi-types datasets and the results verify the effectiveness and the scalability after the comparison with the most advanced approaches of literature.},
  archive      = {J_TKDD},
  doi          = {10.1145/3597436},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {11},
  number       = {1},
  pages        = {1-26},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Overlapping graph clustering in attributed networks via generalized cluster potential game},
  volume       = {18},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Graph community infomax. <em>TKDD</em>, <em>16</em>(3),
1–21. (<a href="https://doi.org/10.1145/3480244">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph representation learning aims at learning low-dimension representations for nodes in graphs, and has been proven very useful in several downstream tasks. In this article, we propose a new model, Graph Community Infomax (GCI), that can adversarial learn representations for nodes in attributed networks. Different from other adversarial network embedding models, which would assume that the data follow some prior distributions and generate fake examples, GCI utilizes the community information of networks, using nodes as positive(or real) examples and negative(or fake) examples at the same time. An autoencoder is applied to learn the embedding vectors for nodes and reconstruct the adjacency matrix, and a discriminator is used to maximize the mutual information between nodes and communities. Experiments on several real-world and synthetic networks have shown that GCI outperforms various network embedding methods on community detection tasks.},
  archive      = {J_TKDD},
  doi          = {10.1145/3480244},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {11},
  number       = {3},
  pages        = {1-21},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Graph community infomax},
  volume       = {16},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Toward understanding and evaluating structural node
embeddings. <em>TKDD</em>, <em>16</em>(3), 1–32. (<a
href="https://doi.org/10.1145/3481639">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While most network embedding techniques model the proximity between nodes in a network, recently there has been significant interest in structural embeddings that are based on node equivalences , a notion rooted in sociology: equivalences or positions are collections of nodes that have similar roles—i.e., similar functions, ties or interactions with nodes in other positions—irrespective of their distance or reachability in the network. Unlike the proximity-based methods that are rigorously evaluated in the literature, the evaluation of structural embeddings is less mature. It relies on small synthetic or real networks with labels that are not perfectly defined, and its connection to sociological equivalences has hitherto been vague and tenuous. With new node embedding methods being developed at a breakneck pace, proper evaluation, and systematic characterization of existing approaches will be essential to progress. To fill in this gap, we set out to understand what types of equivalences structural embeddings capture. We are the first to contribute rigorous intrinsic and extrinsic evaluation methodology for structural embeddings, along with carefully-designed, diverse datasets of varying sizes. We observe a number of different evaluation variables that can lead to different results (e.g., choice of similarity measure, classifier, and label definitions). We find that degree distributions within nodes’ local neighborhoods can lead to simple yet effective baselines in their own right and guide the future development of structural embedding. We hope that our findings can influence the design of further node embedding methods and also pave the way for more comprehensive and fair evaluation of structural embedding methods.},
  archive      = {J_TKDD},
  doi          = {10.1145/3481639},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {11},
  number       = {3},
  pages        = {1-32},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Toward understanding and evaluating structural node embeddings},
  volume       = {16},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Scalable mining of high-utility sequential patterns with
three-tier MapReduce model. <em>TKDD</em>, <em>16</em>(3), 1–26. (<a
href="https://doi.org/10.1145/3487046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High-utility sequential pattern mining (HUSPM) is a hot research topic in recent decades since it combines both sequential and utility properties to reveal more information and knowledge rather than the traditional frequent itemset mining or sequential pattern mining. Several works of HUSPM have been presented but most of them are based on main memory to speed up mining performance. However, this assumption is not realistic and not suitable in large-scale environments since in real industry, the size of the collected data is very huge and it is impossible to fit the data into the main memory of a single machine. In this article, we first develop a parallel and distributed three-stage MapReduce model for mining high-utility sequential patterns based on large-scale databases. Two properties are then developed to hold the correctness and completeness of the discovered patterns in the developed framework. In addition, two data structures called sidset and utility-linked list are utilized in the developed framework to accelerate the computation for mining the required patterns. From the results, we can observe that the designed model has good performance in large-scale datasets in terms of runtime, memory, efficiency of the number of distributed nodes, and scalability compared to the serial HUSP-Span approach.},
  archive      = {J_TKDD},
  doi          = {10.1145/3487046},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {11},
  number       = {3},
  pages        = {1-26},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Scalable mining of high-utility sequential patterns with three-tier MapReduce model},
  volume       = {16},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). HCBST: An efficient hybrid sampling technique for class
imbalance problems. <em>TKDD</em>, <em>16</em>(3), 1–37. (<a
href="https://doi.org/10.1145/3488280">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Class imbalance problem is prevalent in many real-world domains. It has become an active area of research. In binary classification problems, imbalance learning refers to learning from a dataset with a high degree of skewness to the negative class. This phenomenon causes classification algorithms to perform woefully when predicting positive classes with new examples. Data resampling, which involves manipulating the training data before applying standard classification techniques, is among the most commonly used techniques to deal with the class imbalance problem. This article presents a new hybrid sampling technique that improves the overall performance of classification algorithms for solving the class imbalance problem significantly. The proposed method called the Hybrid Cluster-Based Undersampling Technique (HCBST) uses a combination of the cluster undersampling technique to under-sample the majority instances and an oversampling technique derived from Sigma Nearest Oversampling based on Convex Combination, to oversample the minority instances to solve the class imbalance problem with a high degree of accuracy and reliability. The performance of the proposed algorithm was tested using 11 datasets from the National Aeronautics and Space Administration Metric Data Program data repository and University of California Irvine Machine Learning data repository with varying degrees of imbalance. Results were compared with classification algorithms such as the K-nearest neighbours, support vector machines, decision tree, random forest, neural network, AdaBoost, naïve Bayes, and quadratic discriminant analysis. Tests results revealed that for the same datasets, the HCBST performed better with average performances of 0.73, 0.67, and 0.35 in terms of performance measures of area under curve, geometric mean, and Matthews Correlation Coefficient, respectively, across all the classifiers used for this study. The HCBST has the potential of improving the performance of the class imbalance problem, which by extension, will improve on the various applications that rely on the concept for a solution.},
  archive      = {J_TKDD},
  doi          = {10.1145/3488280},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {11},
  number       = {3},
  pages        = {1-37},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {HCBST: An efficient hybrid sampling technique for class imbalance problems},
  volume       = {16},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Online and distributed robust regressions with extremely
noisy labels. <em>TKDD</em>, <em>16</em>(3), 1–24. (<a
href="https://doi.org/10.1145/3473038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In today’s era of big data, robust least-squares regression becomes a more challenging problem when considering the extremely corrupted labels along with explosive growth of datasets. Traditional robust methods can handle the noise but suffer from several challenges when applied in huge dataset including (1) computational infeasibility of handling an entire dataset at once, (2) existence of heterogeneously distributed corruption, and (3) difficulty in corruption estimation when data cannot be entirely loaded. This article proposes online and distributed robust regression approaches, both of which can concurrently address all the above challenges. Specifically, the distributed algorithm optimizes the regression coefficients of each data block via heuristic hard thresholding and combines all the estimates in a distributed robust consolidation. In addition, an online version of the distributed algorithm is proposed to incrementally update the existing estimates with new incoming data. Furthermore, a novel online robust regression method is proposed to estimate under a biased-batch corruption. We also prove that our algorithms benefit from strong robustness guarantees in terms of regression coefficient recovery with a constant upper bound on the error of state-of-the-art batch methods. Extensive experiments on synthetic and real datasets demonstrate that our approaches are superior to those of existing methods in effectiveness, with competitive efficiency.},
  archive      = {J_TKDD},
  doi          = {10.1145/3473038},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {10},
  number       = {3},
  pages        = {1-24},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Online and distributed robust regressions with extremely noisy labels},
  volume       = {16},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Semi-supervised ensemble learning for dealing with
inaccurate and incomplete supervision. <em>TKDD</em>, <em>16</em>(3),
1–33. (<a href="https://doi.org/10.1145/3473910">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In real-world tasks, obtaining a large set of noise-free data can be prohibitively expensive. Therefore, recent research tries to enable machine learning to work with weakly supervised datasets, such as inaccurate or incomplete data. However, the previous literature treats each type of weak supervision individually, although, in most cases, different types of weak supervision tend to occur simultaneously. Therefore, in this article, we present Smart MEnDR, a Classification Model that applies Ensemble Learning and Data-driven Rectification to deal with inaccurate and incomplete supervised datasets. The model first applies a preliminary phase of ensemble learning in which the noisy data points are detected while exploiting the unlabelled data. The phase employs a semi-supervised technique with maximum likelihood estimation to decide on the disagreement rate. Second, the proposed approach applies an iterative meta-learning step to tackle the problem of knowing which points should be made correct to improve the performance of the final classifier. To evaluate the proposed framework, we report the classification performance, noise detection, and the labelling accuracy of the proposed method against state-of-the-art techniques. The experimental results demonstrate the effectiveness of the proposed framework in detecting noise, providing correct labels, and attaining high classification performance.},
  archive      = {J_TKDD},
  doi          = {10.1145/3473910},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {10},
  number       = {3},
  pages        = {1-33},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Semi-supervised ensemble learning for dealing with inaccurate and incomplete supervision},
  volume       = {16},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Network embedding via motifs. <em>TKDD</em>, <em>16</em>(3),
1–20. (<a href="https://doi.org/10.1145/3473911">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Network embedding has emerged as an effective way to deal with downstream tasks, such as node classification  [ 16 , 31 , 42 ]. Most existing methods leverage multi-similarities between nodes such as connectivity, which considers vertices that are closely connected to be similar and structural similarity, which is measured by assessing their relations to neighbors; while these methods only focus on static graphs. In this work, we bridge connectivity and structural similarity in a uniform representation via motifs, and consequently present an algorithm for Learning Embeddings by leveraging Motifs Of Networks (LEMON), which aims to learn embeddings for vertices and various motifs. Moreover, LEMON is inherently capable of dealing with inductive learning tasks for dynamic graphs. To validate the effectiveness and efficiency, we conduct various experiments on two real-world datasets and five public datasets from diverse domains. Through comparison with state-of-the-art baseline models, we find that LEMON achieves significant improvements in downstream tasks. We release our code on Github at https://github.com/larry2020626/LEMON.},
  archive      = {J_TKDD},
  doi          = {10.1145/3473911},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {10},
  number       = {3},
  pages        = {1-20},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Network embedding via motifs},
  volume       = {16},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Knowledge distillation with attention for deep transfer
learning of convolutional networks. <em>TKDD</em>, <em>16</em>(3), 1–20.
(<a href="https://doi.org/10.1145/3473912">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Transfer learning through fine-tuning a pre-trained neural network with an extremely large dataset, such as ImageNet, can significantly improve and accelerate training while the accuracy is frequently bottlenecked by the limited dataset size of the new target task. To solve the problem, some regularization methods, constraining the outer layer weights of the target network using the starting point as references (SPAR), have been studied. In this article, we propose a novel regularized transfer learning framework \( \operatorname{DELTA} \) , namely DE ep L earning T ransfer using Feature Map with A ttention . Instead of constraining the weights of neural network, \( \operatorname{DELTA} \) aims at preserving the outer layer outputs of the source network. Specifically, in addition to minimizing the empirical loss, \( \operatorname{DELTA} \) aligns the outer layer outputs of two networks, through constraining a subset of feature maps that are precisely selected by attention that has been learned in a supervised learning manner. We evaluate \( \operatorname{DELTA} \) with the state-of-the-art algorithms, including \( L^2 \) and \( \emph {L}^2\text{-}SP \) . The experiment results show that our method outperforms these baselines with higher accuracy for new tasks. Code has been made publicly available. 1},
  archive      = {J_TKDD},
  doi          = {10.1145/3473912},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {10},
  number       = {3},
  pages        = {1-20},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Knowledge distillation with attention for deep transfer learning of convolutional networks},
  volume       = {16},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Context-aware semantic annotation of mobility records.
<em>TKDD</em>, <em>16</em>(3), 1–20. (<a
href="https://doi.org/10.1145/3477048">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The wide adoption of mobile devices has provided us with a massive volume of human mobility records. However, a large portion of these records is unlabeled, i.e., only have GPS coordinates without semantic information (e.g., Point of Interest (POI)). To make those unlabeled records associate with more information for further applications, it is of great importance to annotate the original data with POIs information based on the external context. Nevertheless, semantic annotation of mobility records is challenging due to three aspects: the complex relationship among multiple domains of context, the sparsity of mobility records, and difficulties in balancing personal preference and crowd preference. To address these challenges, we propose CAP, a context-aware personalized semantic annotation model, where we use a Bayesian mixture model to model the complex relationship among five domains of context—location, time, POI category, personal preference, and crowd preference. We evaluate our model on two real-world datasets, and demonstrate that our proposed method significantly outperforms the state-of-the-art algorithms by over 11.8%.},
  archive      = {J_TKDD},
  doi          = {10.1145/3477048},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {10},
  number       = {3},
  pages        = {1-20},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Context-aware semantic annotation of mobility records},
  volume       = {16},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A normalizing flow-based co-embedding model for attributed
networks. <em>TKDD</em>, <em>16</em>(3), 1–31. (<a
href="https://doi.org/10.1145/3477049">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Network embedding is a technique that aims at inferring the low-dimensional representations of nodes in a semantic space. In this article, we study the problem of inferring the low-dimensional representations of both nodes and attributes for attributed networks in the same semantic space such that the affinity between a node and an attribute can be effectively measured. Intuitively, this problem can be addressed by simply utilizing existing variational auto-encoder (VAE) based network embedding algorithms. However, the variational posterior distribution in previous VAE based network embedding algorithms is often assumed and restricted to be a mean-field Gaussian distribution or other simple distribution families, which results in poor inference of the embeddings. To alleviate the above defect, we propose a novel VAE-based co-embedding method for attributed network, F-CAN, where posterior distributions are flexible, complex, and scalable distributions constructed through the normalizing flow. We evaluate our proposed models on a number of network tasks with several benchmark datasets. Experimental results demonstrate that there are clear improvements in the qualities of embeddings generated by our model to the state-of-the-art attributed network embedding methods.},
  archive      = {J_TKDD},
  doi          = {10.1145/3477049},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {10},
  number       = {3},
  pages        = {1-31},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {A normalizing flow-based co-embedding model for attributed networks},
  volume       = {16},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Unsupervised adversarial network alignment with
reinforcement learning. <em>TKDD</em>, <em>16</em>(3), 1–29. (<a
href="https://doi.org/10.1145/3477050">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Network alignment, which aims at learning a matching between the same entities across multiple information networks, often suffers challenges from feature inconsistency, high-dimensional features, to unstable alignment results. This article presents a novel network alignment framework, Unsupervised Adversarial learning based Network Alignment(UANA), that combines generative adversarial network (GAN) and reinforcement learning (RL) techniques to tackle the above critical challenges. First, we propose a bidirectional adversarial network distribution matching model to perform the bidirectional cross-network alignment translations between two networks, such that the distributions of real and translated networks completely overlap together. In addition, two cross-network alignment translation cycles are constructed for training the unsupervised alignment without the need of prior alignment knowledge. Second, in order to address the feature inconsistency issue, we integrate a dual adversarial autoencoder module with an adversarial binary classification model together to project two copies of the same vertices with high-dimensional inconsistent features into the same low-dimensional embedding space. This facilitates the translations of the distributions of two networks in the adversarial network distribution matching model. Finally, we develop an RL based optimization approach to solve the vertex matching problem in the discrete space of the GAN model, i.e., directly select the vertices in target networks most relevant to the vertices in source networks, without unstable similarity computation that is sensitive to discriminative features and similarity metrics. Extensive evaluation on real-world graph datasets demonstrates the outstanding capability of UANA to address the unsupervised network alignment problem, in terms of both effectiveness and scalability.},
  archive      = {J_TKDD},
  doi          = {10.1145/3477050},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {10},
  number       = {3},
  pages        = {1-29},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Unsupervised adversarial network alignment with reinforcement learning},
  volume       = {16},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). DACHA: A dual graph convolution based temporal knowledge
graph representation learning method using historical relation.
<em>TKDD</em>, <em>16</em>(3), 1–18. (<a
href="https://doi.org/10.1145/3477051">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Temporal knowledge graph (TKG) representation learning embeds relations and entities into a continuous low-dimensional vector space by incorporating temporal information. Latest studies mainly aim at learning entity representations by modeling entity interactions from the neighbor structure of the graph. However, the interactions of relations from the neighbor structure of the graph are neglected, which are also of significance for learning informative representations. In addition, there still lacks an effective historical relation encoder to model the multi-range temporal dependencies. In this article, we propose a d ual gr a ph c onvolution network based TKG representation learning method using h istorical rel a tions (DACHA). Specifically, we first construct the primal graph according to historical relations, as well as the edge graph by regarding historical relations as nodes. Then, we employ the dual graph convolution network to capture the interactions of both entities and historical relations from the neighbor structure of the graph. In addition, the temporal self-attentive historical relation encoder is proposed to explicitly model both local and global temporal dependencies. Extensive experiments on two event based TKG datasets demonstrate that DACHA achieves the state-of-the-art results.},
  archive      = {J_TKDD},
  doi          = {10.1145/3477051},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {10},
  number       = {3},
  pages        = {1-18},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {DACHA: A dual graph convolution based temporal knowledge graph representation learning method using historical relation},
  volume       = {16},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Balance-subsampled stable prediction across unknown test
data. <em>TKDD</em>, <em>16</em>(3), 1–21. (<a
href="https://doi.org/10.1145/3477052">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In data mining and machine learning, it is commonly assumed that training and test data share the same population distribution. However, this assumption is often violated in practice because of the sample selection bias, which might induce the distribution shift from training data to test data. Such a model-agnostic distribution shift usually leads to prediction instability across unknown test data. This article proposes a novel balance-subsampled stable prediction (BSSP) algorithm based on the theory of fractional factorial design. It isolates the clear effect of each predictor from the confounding variables. A design-theoretic analysis shows that the proposed method can reduce the confounding effects among predictors induced by the distribution shift, improving both the accuracy of parameter estimation and the stability of prediction across unknown test data. Numerical experiments on synthetic and real-world datasets demonstrate that our BSSP algorithm can significantly outperform the baseline methods for stable prediction across unknown test data.},
  archive      = {J_TKDD},
  doi          = {10.1145/3477052},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {10},
  number       = {3},
  pages        = {1-21},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Balance-subsampled stable prediction across unknown test data},
  volume       = {16},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Corpus-level and concept-based explanations for
interpretable document classification. <em>TKDD</em>, <em>16</em>(3),
1–17. (<a href="https://doi.org/10.1145/3477539">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Using attention weights to identify information that is important for models’ decision making is a popular approach to interpret attention-based neural networks. This is commonly realized in practice through the generation of a heat-map for every single document based on attention weights. However, this interpretation method is fragile and it is easy to find contradictory examples. In this article, we propose a corpus-level explanation approach, which aims at capturing causal relationships between keywords and model predictions via learning the importance of keywords for predicted labels across a training corpus based on attention weights. Based on this idea, we further propose a concept-based explanation method that can automatically learn higher level concepts and their importance to model prediction tasks. Our concept-based explanation method is built upon a novel Abstraction-Aggregation Network (AAN), which can automatically cluster important keywords during an end-to-end training process. We apply these methods to the document classification task and show that they are powerful in extracting semantically meaningful keywords and concepts. Our consistency analysis results based on an attention-based Naïve Bayes classifier (NBC) also demonstrate that these keywords and concepts are important for model predictions.},
  archive      = {J_TKDD},
  doi          = {10.1145/3477539},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {10},
  number       = {3},
  pages        = {1-17},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Corpus-level and concept-based explanations for interpretable document classification},
  volume       = {16},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Context-aware spatial-temporal neural network for citywide
crowd flow prediction via modeling long-range spatial dependency.
<em>TKDD</em>, <em>16</em>(3), 1–21. (<a
href="https://doi.org/10.1145/3477577">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Crowd flow prediction is of great importance in a wide range of applications from urban planning, traffic control to public safety. It aims at predicting the inflow (the traffic of crowds entering a region in a given time interval) and outflow (the traffic of crowds leaving a region for other places) of each region in the city with knowing the historical flow data. In this article, we propose DeepSTN+, a deep learning-based convolutional model, to predict crowd flows in the metropolis. First, DeepSTN+ employs the ConvPlus structure to model the long-range spatial dependence among crowd flows in different regions. Further, PoI distributions and time factor are combined to express the effect of location attributes to introduce prior knowledge of the crowd movements. Finally, we propose a temporal attention-based fusion mechanism to stabilize the training process, which further improves the performance. Extensive experimental results based on four real-life datasets demonstrate the superiority of our model, i.e., DeepSTN+ reduces the error of the crowd flow prediction by approximately 10%–21% compared with the state-of-the-art baselines.},
  archive      = {J_TKDD},
  doi          = {10.1145/3477577},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {10},
  number       = {3},
  pages        = {1-21},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Context-aware spatial-temporal neural network for citywide crowd flow prediction via modeling long-range spatial dependency},
  volume       = {16},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Time-aware graph embedding: A temporal smoothness and
task-oriented approach. <em>TKDD</em>, <em>16</em>(3), 1–23. (<a
href="https://doi.org/10.1145/3480243">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge graph embedding, which aims at learning the low-dimensional representations of entities and relationships, has attracted considerable research efforts recently. However, most knowledge graph embedding methods focus on the structural relationships in fixed triples while ignoring the temporal information. Currently, existing time-aware graph embedding methods only focus on the factual plausibility, while ignoring the temporal smoothness, which models the interactions between a fact and its contexts, and thus can capture fine-granularity temporal relationships. This leads to the limited performance of embedding related applications. To solve this problem, this article presents a Robustly Time-aware Graph Embedding (RTGE) method by incorporating temporal smoothness. Two major innovations of our article are presented here. At first, RTGE integrates a measure of temporal smoothness in the learning process of the time-aware graph embedding. Via the proposed additional smoothing factor, RTGE can preserve both structural information and evolutionary patterns of a given graph. Secondly, RTGE provides a general task-oriented negative sampling strategy associated with temporally aware information, which further improves the adaptive ability of the proposed algorithm and plays an essential role in obtaining superior performance in various tasks. Extensive experiments conducted on multiple benchmark tasks show that RTGE can increase performance in entity/relationship/temporal scoping prediction tasks.},
  archive      = {J_TKDD},
  doi          = {10.1145/3480243},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {10},
  number       = {3},
  pages        = {1-23},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Time-aware graph embedding: A temporal smoothness and task-oriented approach},
  volume       = {16},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). NTP-miner: Nonoverlapping three-way sequential pattern
mining. <em>TKDD</em>, <em>16</em>(3), 1–21. (<a
href="https://doi.org/10.1145/3480245">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nonoverlapping sequential pattern mining is an important type of sequential pattern mining (SPM) with gap constraints, which not only can reveal interesting patterns to users but also can effectively reduce the search space using the Apriori (anti-monotonicity) property. However, the existing algorithms do not focus on attributes of interest to users, meaning that existing methods may discover many frequent patterns that are redundant. To solve this problem, this article proposes a task called nonoverlapping three-way sequential pattern (NTP) mining, where attributes are categorized according to three levels of interest: strong, medium, and weak interest. NTP mining can effectively avoid mining redundant patterns since the NTPs are composed of strong and medium interest items. Moreover, NTPs can avoid serious deviations (the occurrence is significantly different from its pattern) since gap constraints cannot match with strong interest patterns. To mine NTPs, an effective algorithm is put forward, called NTP-Miner, which applies two main steps: support (frequency occurrence) calculation and candidate pattern generation. To calculate the support of an NTP, depth-first and backtracking strategies are adopted, which do not require creating a whole Nettree structure, meaning that many redundant nodes and parent–child relationships do not need to be created. Hence, time and space efficiency is improved. To generate candidate patterns while reducing their number, NTP-Miner employs a pattern join strategy and only mines patterns of strong and medium interest. Experimental results on stock market and protein datasets show that NTP-Miner not only is more efficient than other competitive approaches but can also help users find more valuable patterns. More importantly, NTP mining has achieved better performance than other competitive methods in clustering tasks. Algorithms and data are available at: https://github.com/wuc567/Pattern-Mining/tree/master/NTP-Miner .},
  archive      = {J_TKDD},
  doi          = {10.1145/3480245},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {10},
  number       = {3},
  pages        = {1-21},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {NTP-miner: Nonoverlapping three-way sequential pattern mining},
  volume       = {16},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Network public opinion detection during the coronavirus
pandemic: A short-text relational topic model. <em>TKDD</em>,
<em>16</em>(3), 1–27. (<a
href="https://doi.org/10.1145/3480246">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Online social media provides rich and varied information reflecting the significant concerns of the public during the coronavirus pandemic. Analyzing what the public is concerned with from social media information can support policy-makers to maintain the stability of the social economy and life of the society. In this article, we focus on the detection of the network public opinions during the coronavirus pandemic. We propose a novel Relational Topic Model for Short texts (RTMS) to draw opinion topics from social media data. RTMS exploits the feature of texts in online social media and the opinion propagation patterns among individuals. Moreover, a dynamic version of RTMS (DRTMS) is proposed to capture the evolution of public opinions. Our experiment is conducted on a real-world dataset which includes 67,592 comments from 14,992 users. The results demonstrate that, compared with the benchmark methods, the proposed RTMS and DRTMS models can detect meaningful public opinions by leveraging the feature of social media data. It can also effectively capture the evolution of public concerns during different phases of the coronavirus pandemic.},
  archive      = {J_TKDD},
  doi          = {10.1145/3480246},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {10},
  number       = {3},
  pages        = {1-27},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Network public opinion detection during the coronavirus pandemic: A short-text relational topic model},
  volume       = {16},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Social group query based on multi-fuzzy-constrained strong
simulation. <em>TKDD</em>, <em>16</em>(3), 1–27. (<a
href="https://doi.org/10.1145/3481640">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional social group analysis mostly uses interaction models, event models, or other social network analysis methods to identify and distinguish groups. This type of method can divide social participants into different groups based on their geographic location, social relationships, and/or related events. However, in some applications, it is necessary to make more specific restrictions on the members and the interactions between members of the group. Generally, Graph Pattern Matching (GPM) technique is used to solve this problem. However, the existing GPM methods rarely consider the rich contextual information of nodes and edges to measure the credibility between members. In this article, first, a social group query problem that needs to consider the trust between members of the group is proposed. Then, to solve this problem, a multi-fuzzy-constrained strong simulation matching model is proposed based on multi-constrained simulation, and a Strong Simulation GPM algorithm (NTSS) based on the exploration of pattern Node Topological ordered sequence is proposed. Aiming at the inefficiency of the NTSS algorithm when pattern graph with multiple nodes with zero in-degree and the problem of repeated calculation of matching edges shared by multiple matching subgraphs, two optimization strategies are proposed. Finally, we conduct verification experiments on the effectiveness and efficiency of the NTSS algorithm and the algorithms with the optimization strategies on four social network datasets in real applications. Experimental results show that the NTSS algorithm is significantly better than the existing multi-constrained GPM algorithm, and the NTSS_Inv_EdgC algorithm, which combines two optimization strategies, greatly improves the efficiency of the NTSS algorithm.},
  archive      = {J_TKDD},
  doi          = {10.1145/3481640},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {10},
  number       = {3},
  pages        = {1-27},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Social group query based on multi-fuzzy-constrained strong simulation},
  volume       = {16},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Deciphering feature effects on decision-making in ordinal
regression problems: An explainable ordinal factorization model.
<em>TKDD</em>, <em>16</em>(3), 1–26. (<a
href="https://doi.org/10.1145/3487048">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ordinal regression predicts the objects’ labels that exhibit a natural ordering, which is vital to decision-making problems such as credit scoring and clinical diagnosis. In these problems, the ability to explain how the individual features and their interactions affect the decisions is as critical as model performance. Unfortunately, the existing ordinal regression models in the machine learning community aim at improving prediction accuracy rather than explore explainability. To achieve high accuracy while explaining the relationships between the features and the predictions, we propose a new method for ordinal regression problems, namely the Explainable Ordinal Factorization Model (XOFM). XOFM uses piecewise linear functions to approximate the shape functions of individual features, and renders the pairwise features interaction effects as heat-maps. The proposed XOFM captures the nonlinearity in the main effects and ensures the interaction effects’ same flexibility. Therefore, the underlying model yields comparable performance while remaining explainable by explicitly describing the main and interaction effects. To address the potential sparsity problem caused by discretizing the whole feature scale into several sub-intervals, XOFM integrates the Factorization Machines (FMs) to factorize the model parameters. Comprehensive experiments with benchmark real-world and synthetic datasets demonstrate that the proposed XOFM leads to state-of-the-art prediction performance while preserving an easy-to-understand explainability.},
  archive      = {J_TKDD},
  doi          = {10.1145/3487048},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {10},
  number       = {3},
  pages        = {1-26},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Deciphering feature effects on decision-making in ordinal regression problems: An explainable ordinal factorization model},
  volume       = {16},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Exploiting heterogeneous graph neural networks with latent
worker/task correlation information for label aggregation in
crowdsourcing. <em>TKDD</em>, <em>16</em>(2), 1–18. (<a
href="https://doi.org/10.1145/3460865">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Crowdsourcing has attracted much attention for its convenience to collect labels from non-expert workers instead of experts. However, due to the high level of noise from the non-experts, a label aggregation model that infers the true label from noisy crowdsourced labels is required. In this article, we propose a novel framework based on graph neural networks for aggregating crowd labels. We construct a heterogeneous graph between workers and tasks and derive a new graph neural network to learn the representations of nodes and the true labels. Besides, we exploit the unknown latent interaction between the same type of nodes (workers or tasks) by adding a homogeneous attention layer in the graph neural networks. Experimental results on 13 real-world datasets show superior performance over state-of-the-art models.},
  archive      = {J_TKDD},
  doi          = {10.1145/3460865},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {9},
  number       = {2},
  pages        = {1-18},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Exploiting heterogeneous graph neural networks with latent Worker/Task correlation information for label aggregation in crowdsourcing},
  volume       = {16},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Wealth flow model: Online portfolio selection based on
learning wealth flow matrices. <em>TKDD</em>, <em>16</em>(2), 1–27. (<a
href="https://doi.org/10.1145/3464308">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article proposes a deep learning solution to the online portfolio selection problem based on learning a latent structure directly from a price time series. It introduces a novel wealth flow matrix for representing a latent structure that has special regular conditions to encode the knowledge about the relative strengths of assets in portfolios. Therefore, a wealth flow model (WFM) is proposed to learn wealth flow matrices and maximize portfolio wealth simultaneously. Compared with existing approaches, our work has several distinctive benefits: (1) the learning of wealth flow matrices makes our model more generalizable than models that only predict wealth proportion vectors, and (2) the exploitation of wealth flow matrices and the exploration of wealth growth are integrated into our deep reinforcement algorithm for the WFM. These benefits, in combination, lead to a highly-effective approach for generating reasonable investment behavior, including short-term trend following, the following of a few losers, no self-investment, and sparse portfolios. Extensive experiments on five benchmark datasets from real-world stock markets confirm the theoretical advantage of the WFM, which achieves the Pareto improvements in terms of multiple performance indicators and the steady growth of wealth over the state-of-the-art algorithms.},
  archive      = {J_TKDD},
  doi          = {10.1145/3464308},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {9},
  number       = {2},
  pages        = {1-27},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Wealth flow model: Online portfolio selection based on learning wealth flow matrices},
  volume       = {16},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Spatio-temporal event forecasting using incremental
multi-source feature learning. <em>TKDD</em>, <em>16</em>(2), 1–28. (<a
href="https://doi.org/10.1145/3464976">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The forecasting of significant societal events such as civil unrest and economic crisis is an interesting and challenging problem which requires both timeliness, precision, and comprehensiveness. Significant societal events are influenced and indicated jointly by multiple aspects of a society, including its economics, politics, and culture. Traditional forecasting methods based on a single data source find it hard to cover all these aspects comprehensively, thus limiting model performance. Multi-source event forecasting has proven promising but still suffers from several challenges, including (1) geographical hierarchies in multi-source data features, (2) hierarchical missing values, (3) characterization of structured feature sparsity, and (4) difficulty in model’s online update with incomplete multiple sources. This article proposes a novel feature learning model that concurrently addresses all the above challenges. Specifically, given multi-source data from different geographical levels, we design a new forecasting model by characterizing the lower-level features’ dependence on higher-level features. To handle the correlations amidst structured feature sets and deal with missing values among the coupled features, we propose a novel feature learning model based on an \(N\) th-order strong hierarchy and fused-overlapping group Lasso. An efficient algorithm is developed to optimize model parameters and ensure global optima. More importantly, to enable the model update in real time, the online learning algorithm is formulated and active set techniques are leveraged to resolve the crucial challenge when new patterns of missing features appear in real time. Extensive experiments on 10 datasets in different domains demonstrate the effectiveness and efficiency of the proposed models.},
  archive      = {J_TKDD},
  doi          = {10.1145/3464976},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {9},
  number       = {2},
  pages        = {1-28},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Spatio-temporal event forecasting using incremental multi-source feature learning},
  volume       = {16},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Learning sentence-to-hashtags semantic mapping for hashtag
recommendation on microblogs. <em>TKDD</em>, <em>16</em>(2), 1–26. (<a
href="https://doi.org/10.1145/3466876">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The growing use of microblogging platforms is generating a huge amount of posts that need effective methods to be classified and searched. In Twitter and other social media platforms, hashtags are exploited by users to facilitate the search, categorization, and spread of posts. Choosing the appropriate hashtags for a post is not always easy for users, and therefore posts are often published without hashtags or with hashtags not well defined. To deal with this issue, we propose a new model, called HASHET ( HAshtag recommendation using Sentence-to-Hashtag Embedding Translation ), aimed at suggesting a relevant set of hashtags for a given post. HASHET is based on two independent latent spaces for embedding the text of a post and the hashtags it contains. A mapping process based on a multi-layer perceptron is then used for learning a translation from the semantic features of the text to the latent representation of its hashtags. We evaluated the effectiveness of two language representation models for sentence embedding and tested different search strategies for semantic expansion, finding out that the combined use of BERT ( Bidirectional Encoder Representation from Transformer ) and a global expansion strategy leads to the best recommendation results. HASHET has been evaluated on two real-world case studies related to the 2016 United States presidential election and COVID-19 pandemic. The results reveal the effectiveness of HASHET in predicting one or more correct hashtags, with an average F -score up to 0.82 and a recommendation hit-rate up to 0.92. Our approach has been compared to the most relevant techniques used in the literature ( generative models , unsupervised models, and attention-based supervised models ) by achieving up to 15% improvement in F -score for the hashtag recommendation task and 9% for the topic discovery task.},
  archive      = {J_TKDD},
  doi          = {10.1145/3466876},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {9},
  number       = {2},
  pages        = {1-26},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Learning sentence-to-hashtags semantic mapping for hashtag recommendation on microblogs},
  volume       = {16},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Embedding heterogeneous information network in hyperbolic
spaces. <em>TKDD</em>, <em>16</em>(2), 1–23. (<a
href="https://doi.org/10.1145/3468674">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Heterogeneous information network (HIN) embedding, aiming to project HIN into a low-dimensional space, has attracted considerable research attention. Most of the existing HIN embedding methods focus on preserving the inherent network structure and semantic correlations in Euclidean spaces. However, one fundamental problem is whether the Euclidean spaces are the intrinsic spaces of HIN? Recent researches find the complex network with hyperbolic geometry can naturally reflect some properties, e.g., hierarchical and power-law structure. In this article, we make an effort toward embedding HIN in hyperbolic spaces. We analyze the structures of three HINs and discover some properties, e.g., the power-law distribution, also exist in HINs. Therefore, we propose a novel HIN embedding model HHNE. Specifically, to capture the structure and semantic relations between nodes, HHNE employs the meta-path guided random walk to sample the sequences for each node. Then HHNE exploits the hyperbolic distance as the proximity measurement. We also derive an effective optimization strategy to update the hyperbolic embeddings iteratively. Since HHNE optimizes different relations in a single space, we further propose the extended model HHNE++. HHNE++ models different relations in different spaces, which enables it to learn complex interactions in HINs. The optimization strategy of HHNE++ is also derived to update the parameters of HHNE++ in a principle manner. The experimental results demonstrate the effectiveness of our proposed models.},
  archive      = {J_TKDD},
  doi          = {10.1145/3468674},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {9},
  number       = {2},
  pages        = {1-23},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Embedding heterogeneous information network in hyperbolic spaces},
  volume       = {16},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). S2OSC: A holistic semi-supervised approach for open set
classification. <em>TKDD</em>, <em>16</em>(2), 1–27. (<a
href="https://doi.org/10.1145/3468675">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Open set classification (OSC) tackles the problem of determining whether the data are in-class or out-of-class during inference, when only provided with a set of in-class examples at training time. Traditional OSC methods usually train discriminative or generative models with the owned in-class data, and then utilize the pre-trained models to classify test data directly. However, these methods always suffer from the embedding confusion problem, i.e., partial out-of-class instances are mixed with in-class ones of similar semantics, making it difficult to classify. To solve this problem, we unify semi-supervised learning to develop a novel OSC algorithm, S2OSC, which incorporates out-of-class instances filtering and model re-training in a transductive manner. In detail, given a pool of newly coming test data, S2OSC firstly filters the mostly distinct out-of-class instances using the pre-trained model, and annotates super-class for them. Then, S2OSC trains a holistic classification model by combing in-class and out-of-class labeled data with the remaining unlabeled test data in a semi-supervised paradigm. Furthermore, considering that data are usually in the streaming form in real applications, we extend S2OSC into an incremental update framework (I-S2OSC), and adopt a knowledge memory regularization to mitigate the catastrophic forgetting problem in incremental update. Despite the simplicity of proposed models, the experimental results show that S2OSC achieves state-of-the-art performance across a variety of OSC tasks, including 85.4% of F1 on CIFAR-10 with only 300 pseudo-labels. We also demonstrate how S2OSC can be expanded to incremental OSC setting effectively with streaming data.},
  archive      = {J_TKDD},
  doi          = {10.1145/3468675},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {9},
  number       = {2},
  pages        = {1-27},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {S2OSC: A holistic semi-supervised approach for open set classification},
  volume       = {16},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Con&amp;net: A cross-network anchor link discovery method
based on embedding representation. <em>TKDD</em>, <em>16</em>(2), 1–18.
(<a href="https://doi.org/10.1145/3469083">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cross-network anchor link discovery is an important research problem and has many applications in heterogeneous social network. Existing schemes of cross-network anchor link discovery can provide reasonable link discovery results, but the quality of these results depends on the features of the platform. Therefore, there is no theoretical guarantee to the stability. This article employs user embedding feature to model the relationship between cross-platform accounts, that is, the more similar the user embedding features are, the more similar the two accounts are. The similarity of user embedding features is determined by the distance of the user features in the latent space. Based on the user embedding features, this article proposes an embedding representation-based method Con&amp;Net(Content and Network) to solve cross-network anchor link discovery problem. Con&amp;Net combines the user’s profile features, user-generated content (UGC) features, and user’s social structure features to measure the similarity of two user accounts. Con&amp;Net first trains the user’s profile features to get profile embedding. Then it trains the network structure of the nodes to get structure embedding. It connects the two features through vector concatenating, and calculates the cosine similarity of the vector based on the embedding vector. This cosine similarity is used to measure the similarity of the user accounts. Finally, Con&amp;Net predicts the link based on similarity for account pairs across the two networks. A large number of experiments in Sina Weibo and Twitter networks show that the proposed method Con&amp;Net is better than state-of-the-art method. The area under the curve (AUC) value of the receiver operating characteristic (ROC) curve predicted by the anchor link is 11% higher than the baseline method, and Precision@30 is 25% higher than the baseline method.},
  archive      = {J_TKDD},
  doi          = {10.1145/3469083},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {9},
  number       = {2},
  pages        = {1-18},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Con&amp;Net: A cross-network anchor link discovery method based on embedding representation},
  volume       = {16},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Hybrid variational autoencoder for recommender systems.
<em>TKDD</em>, <em>16</em>(2), 1–37. (<a
href="https://doi.org/10.1145/3470659">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {E-commerce platforms heavily rely on automatic personalized recommender systems, e.g., collaborative filtering models, to improve customer experience. Some hybrid models have been proposed recently to address the deficiency of existing models. However, their performances drop significantly when the dataset is sparse. Most of the recent works failed to fully address this shortcoming. At most, some of them only tried to alleviate the problem by considering either user side or item side content information. In this article, we propose a novel recommender model called Hybrid Variational Autoencoder (HVAE) to improve the performance on sparse datasets. Different from the existing approaches, we encode both user and item information into a latent space for semantic relevance measurement. In parallel, we utilize collaborative filtering to find the implicit factors of users and items, and combine their outputs to deliver a hybrid solution. In addition, we compare the performance of Gaussian distribution and multinomial distribution in learning the representations of the textual data. Our experiment results show that HVAE is able to significantly outperform state-of-the-art models with robust performance.},
  archive      = {J_TKDD},
  doi          = {10.1145/3470659},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {9},
  number       = {2},
  pages        = {1-37},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Hybrid variational autoencoder for recommender systems},
  volume       = {16},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Assessing large-scale power relations among locations from
mobility data. <em>TKDD</em>, <em>16</em>(2), 1–31. (<a
href="https://doi.org/10.1145/3470770">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The pervasiveness of smartphones has shaped our lives, social norms, and the structure that dictates human behavior. They now directly influence how individuals demand resources or interact with network services. From this scenario, identifying key locations in cities is fundamental for the investigation of human mobility and also for the understanding of social problems. In this context, we propose the first graph-based methodology in the literature to quantify the power of Point-of-Interests (POIs) over its vicinity by means of user mobility trajectories. Different from literature, we consider the flow of people in our analysis, instead of the number of neighbor POIs or their structural locations in the city. Thus, we modeled POI’s visits using the multiflow graph model where each POI is a node and the transitions of users among POIs are a weighted direct edge. Using this multiflow graph model, we compute the attract, support, and independence powers . The attract power and support power measure how many visits a POI gathers from and disseminate over its neighborhood, respectively. Moreover, the independence power captures the capacity of a POI to receive visitors independently from other POIs. We tested our methodology on well-known university campus mobility datasets and validated on Location-Based Social Networks (LBSNs) datasets from various cities around the world. Our findings show that in university campus: (i) buildings have low support power and attract power ; (ii) people tend to move over a few buildings and spend most of their time in the same building; and (iii) there is a slight dependence among buildings, even those with high independence power receive user visits from other buildings on campus. Globally, we reveal that (i) our metrics capture places that impact the number of visits in their neighborhood; (ii) cities in the same continent have similar independence patterns; and (iii) places with a high number of visitation and city central areas are the regions with the highest degree of independence.},
  archive      = {J_TKDD},
  doi          = {10.1145/3470770},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {9},
  number       = {2},
  pages        = {1-31},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Assessing large-scale power relations among locations from mobility data},
  volume       = {16},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). KRAN: Knowledge refining attention network for
recommendation. <em>TKDD</em>, <em>16</em>(2), 1–20. (<a
href="https://doi.org/10.1145/3470783">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommender algorithms combining knowledge graph and graph convolutional network are becoming more and more popular recently. Specifically, attributes describing the items to be recommended are often used as additional information. These attributes along with items are highly interconnected, intrinsically forming a Knowledge Graph (KG). These algorithms use KGs as an auxiliary data source to alleviate the negative impact of data sparsity. However, these graph convolutional network based algorithms do not distinguish the importance of different neighbors of entities in the KG, and according to Pareto’s principle, the important neighbors only account for a small proportion. These traditional algorithms can not fully mine the useful information in the KG. To fully release the power of KGs for building recommender systems, we propose in this article KRAN, a Knowledge Refining Attention Network, which can subtly capture the characteristics of the KG and thus boost recommendation performance. We first introduce a traditional attention mechanism into the KG processing, making the knowledge extraction more targeted, and then propose a refining mechanism to improve the traditional attention mechanism to extract the knowledge in the KG more effectively. More precisely, KRAN is designed to use our proposed knowledge-refining attention mechanism to aggregate and obtain the representations of the entities (both attributes and items) in the KG. Our knowledge-refining attention mechanism first measures the relevance between an entity and it’s neighbors in the KG by attention coefficients, and then further refines the attention coefficients using a “richer-get-richer” principle, in order to focus on highly relevant neighbors while eliminating less relevant neighbors for noise reduction. In addition, for the item cold start problem, we propose KRAN-CD, a variant of KRAN, which further incorporates pre-trained KG embeddings to handle cold start items. Experiments show that KRAN and KRAN-CD consistently outperform state-of-the-art baselines across different settings.},
  archive      = {J_TKDD},
  doi          = {10.1145/3470783},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {9},
  number       = {2},
  pages        = {1-20},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {KRAN: Knowledge refining attention network for recommendation},
  volume       = {16},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). High-value token-blocking: Efficient blocking method for
record linkage. <em>TKDD</em>, <em>16</em>(2), 1–17. (<a
href="https://doi.org/10.1145/3450527">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data integration is an important component of Big Data analytics. One of the key challenges in data integration is record linkage, that is, matching records that represent the same real-world entity. Because of computational costs, methods referred to as blocking are employed as a part of the record linkage pipeline in order to reduce the number of comparisons among records. In the past decade, a range of blocking techniques have been proposed. Real-world applications require approaches that can handle heterogeneous data sources and do not rely on labelled data. We propose high-value token-blocking (HVTB), a simple and efficient approach for blocking that is unsupervised and schema-agnostic, based on a crafted use of Term Frequency-Inverse Document Frequency. We compare HVTB with multiple methods and over a range of datasets, including a novel unstructured dataset composed of titles and abstracts of scientific papers. We thoroughly discuss results in terms of accuracy, use of computational resources, and different characteristics of datasets and records. The simplicity of HVTB yields fast computations and does not harm its accuracy when compared with existing approaches. It is shown to be significantly superior to other methods, suggesting that simpler methods for blocking should be considered before resorting to more sophisticated methods.},
  archive      = {J_TKDD},
  doi          = {10.1145/3450527},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {7},
  number       = {2},
  pages        = {1-17},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {High-value token-blocking: Efficient blocking method for record linkage},
  volume       = {16},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). On-shelf utility mining of sequence data. <em>TKDD</em>,
<em>16</em>(2), 1–31. (<a
href="https://doi.org/10.1145/3457570">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Utility mining has emerged as an important and interesting topic owing to its wide application and considerable popularity. However, conventional utility mining methods have a bias toward items that have longer on-shelf time as they have a greater chance to generate a high utility. To eliminate the bias, the problem of on-shelf utility mining (OSUM) is introduced. In this article, we focus on the task of OSUM of sequence data, where the sequential database is divided into several partitions according to time periods and items are associated with utilities and several on-shelf time periods. To address the problem, we propose two methods, OSUM of sequence data (OSUMS) and OSUMS + , to extract on-shelf high-utility sequential patterns. For further efficiency, we also design several strategies to reduce the search space and avoid redundant calculation with two upper bounds time prefix extension utility ( TPEU ) and time reduced sequence utility ( TRSU ). In addition, two novel data structures are developed for facilitating the calculation of upper bounds and utilities. Substantial experimental results on certain real and synthetic datasets show that the two methods outperform the state-of-the-art algorithm. In conclusion, OSUMS may consume a large amount of memory and is unsuitable for cases with limited memory, while OSUMS + has wider real-life applications owing to its high efficiency.},
  archive      = {J_TKDD},
  doi          = {10.1145/3457570},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {7},
  number       = {2},
  pages        = {1-31},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {On-shelf utility mining of sequence data},
  volume       = {16},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Community detection in partially observable social networks.
<em>TKDD</em>, <em>16</em>(2), 1–24. (<a
href="https://doi.org/10.1145/3461339">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The discovery of community structures in social networks has gained significant attention since it is a fundamental problem in understanding the networks’ topology and functions. However, most social network data are collected from partially observable networks with both missing nodes and edges . In this article, we address a new problem of detecting overlapping community structures in the context of such an incomplete network, where communities in the network are allowed to overlap since nodes belong to multiple communities at once. To solve this problem, we introduce KroMFac , a new framework that conducts community detection via regularized nonnegative matrix factorization (NMF) based on the Kronecker graph model. Specifically, from an inferred Kronecker generative parameter matrix, we first estimate the missing part of the network. As our major contribution to the proposed framework, to improve community detection accuracy, we then characterize and select influential nodes (which tend to have high degrees) by ranking, and add them to the existing graph. Finally, we uncover the community structures by solving the regularized NMF-aided optimization problem in terms of maximizing the likelihood of the underlying graph. Furthermore, adopting normalized mutual information (NMI), we empirically show superiority of our KroMFac approach over two baseline schemes by using both synthetic and real-world networks.},
  archive      = {J_TKDD},
  doi          = {10.1145/3461339},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {7},
  number       = {2},
  pages        = {1-24},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Community detection in partially observable social networks},
  volume       = {16},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Constrained dual-level bandit for personalized impression
regulation in online ranking systems. <em>TKDD</em>, <em>16</em>(2),
1–23. (<a href="https://doi.org/10.1145/3461340">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Impression regulation plays an important role in various online ranking systems, e.g. , e-commerce ranking systems always need to achieve local commercial demands on some pre-labeled target items like fresh item cultivation and fraudulent item counteracting while maximizing its global revenue. However, local impression regulation may cause “butterfly effects” on the global scale, e.g. , in e-commerce, the price preference fluctuation in initial conditions (overpriced or underpriced items) may create a significantly different outcome, thus affecting shopping experience and bringing economic losses to platforms. To prevent “butterfly effects”, some researchers define their regulation objectives with global constraints, by using contextual bandit at the page-level that requires all items on one page sharing the same regulation action, which fails to conduct impression regulation on individual items. To address this problem, in this article, we propose a personalized impression regulation method that can directly makes regulation decisions for each user-item pair. Specifically, we model the regulation problem as a C onstrained D ual-level B andit (CDB) problem, where the local regulation action and reward signals are at the item-level while the global effect constraint on the platform impression can be calculated at the page-level only. To handle the asynchronous signals, we first expand the page-level constraint to the item-level and then derive the policy updating as a second-order cone optimization problem. Our CDB approaches the optimal policy by iteratively solving the optimization problem. Experiments are performed on both offline and online datasets, and the results, theoretically and empirically, demonstrate CDB outperforms state-of-the-art algorithms.},
  archive      = {J_TKDD},
  doi          = {10.1145/3461340},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {7},
  number       = {2},
  pages        = {1-23},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Constrained dual-level bandit for personalized impression regulation in online ranking systems},
  volume       = {16},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Establishing smartphone user behavior model based on energy
consumption data. <em>TKDD</em>, <em>16</em>(2), 1–40. (<a
href="https://doi.org/10.1145/3461459">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In smartphone data analysis, both energy consumption modeling and user behavior mining have been explored extensively, but the relationship between energy consumption and user behavior has been rarely studied. Such a relationship is explored over large-scale users in this article. Based on energy consumption data, where each users’ feature vector is represented by energy breakdown on hardware components of different apps, User Behavior Models (UBM) are established to capture user behavior patterns (i.e., app preference, usage time). The challenge lies in the high diversity of user behaviors (i.e., massive apps and usage ways), which leads to high dimension and dispersion of data. To overcome the challenge, three mechanisms are designed. First, to reduce the dimension, apps are ranked with the top ones identified as typical apps to represent all. Second, the dispersion is reduced by scaling each users’ feature vector with typical apps to unit ℓ 1 norm. The scaled vector becomes Usage Pattern, while the ℓ 1 norm of vector before scaling is treated as Usage Intensity. Third, the usage pattern is analyzed with a two-layer clustering approach to further reduce data dispersion. In the upper layer, each typical app is studied across its users with respect to hardware components to identify Typical Hardware Usage Patterns (THUP). In the lower layer, users are studied with respect to these THUPs to identify Typical App Usage Patterns (TAUP). The analytical results of these two layers are consolidated into Usage Pattern Models (UPM), and UBMs are finally established by a union of UPMs and Usage Intensity Distributions (UID). By carrying out experiments on energy consumption data from 18,308 distinct users over 10 days, 33 UBMs are extracted from training data. With the test data, it is proven that these UBMs cover 94% user behaviors and achieve up to 20% improvement in accuracy of energy representation, as compared with the baseline method, PCA. Besides, potential applications and implications of these UBMs are illustrated for smartphone manufacturers, app developers, network providers, and so on.},
  archive      = {J_TKDD},
  doi          = {10.1145/3461459},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {7},
  number       = {2},
  pages        = {1-40},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Establishing smartphone user behavior model based on energy consumption data},
  volume       = {16},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A robust reputation-based group ranking system and its
resistance to bribery. <em>TKDD</em>, <em>16</em>(2), 1–35. (<a
href="https://doi.org/10.1145/3462210">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The spread of online reviews and opinions and its growing influence on people’s behavior and decisions boosted the interest to extract meaningful information from this data deluge. Hence, crowdsourced ratings of products and services gained a critical role in business and governments. Current state-of-the-art solutions rank the items with an average of the ratings expressed for an item, with a consequent lack of personalization for the users, and the exposure to attacks and spamming/spurious users. Using these ratings to group users with similar preferences might be useful to present users with items that reflect their preferences and overcome those vulnerabilities. In this article, we propose a new reputation-based ranking system, utilizing multipartite rating subnetworks, which clusters users by their similarities using three measures, two of them based on Kolmogorov complexity. We also study its resistance to bribery and how to design optimal bribing strategies. Our system is novel in that it reflects the diversity of preferences by (possibly) assigning distinct rankings to the same item, for different groups of users. We prove the convergence and efficiency of the system. By testing it on synthetic and real data, we see that it copes better with spamming/spurious users, being more robust to attacks than state-of-the-art approaches. Also, by clustering users, the effect of bribery in the proposed multipartite ranking system is dimmed, comparing to the bipartite case.},
  archive      = {J_TKDD},
  doi          = {10.1145/3462210},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {7},
  number       = {2},
  pages        = {1-35},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {A robust reputation-based group ranking system and its resistance to bribery},
  volume       = {16},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Communication from the editor-in-chief: State of the ACM
transactions on knowledge discovery from data. <em>TKDD</em>,
<em>16</em>(2), 1–2. (<a href="https://doi.org/10.1145/3463950">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {No abstract available.},
  archive      = {J_TKDD},
  doi          = {10.1145/3463950},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {7},
  number       = {2},
  pages        = {1-2},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Communication from the editor-in-chief: State of the ACM transactions on knowledge discovery from data},
  volume       = {16},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Measuring the network vulnerability based on markov
criticality. <em>TKDD</em>, <em>16</em>(2), 1–24. (<a
href="https://doi.org/10.1145/3464390">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vulnerability assessment—a critical issue for networks—attempts to foresee unexpected destructive events or hostile attacks in the whole system. In this article, we consider a new Markov global connectivity metric—Kemeny constant, and take its derivative called Markov criticality to identify critical links. Markov criticality allows us to find links that are most influential on the derivative of Kemeny constant. Thus, we can utilize it to identity a critical link ( i , j ) from node i to node j , such that removing it leads to a minimization of networks’ global connectivity, i.e., the Kemeny constant. Furthermore, we also define a novel vulnerability index to measure the average speed by which we can disconnect a specified ratio of links with network decomposition. Our method is of high efficiency, which can be easily employed to calculate the Markov criticality in real-life networks. Comprehensive experiments on several synthetic and real-life networks have demonstrated our method’s better performance by comparing it with state-of-the-art baseline approaches.},
  archive      = {J_TKDD},
  doi          = {10.1145/3464390},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {7},
  number       = {2},
  pages        = {1-24},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Measuring the network vulnerability based on markov criticality},
  volume       = {16},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A synopsis based approach for itemset frequency estimation
over massive multi-transaction stream. <em>TKDD</em>, <em>16</em>(2),
1–30. (<a href="https://doi.org/10.1145/3465238">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The streams where multiple transactions are associated with the same key are prevalent in practice, e.g., a customer has multiple shopping records arriving at different time. Itemset frequency estimation on such streams is very challenging since sampling based methods, such as the popularly used reservoir sampling, cannot be used. In this article, we propose a novel k -Minimum Value (KMV) synopsis based method to estimate the frequency of itemsets over multi-transaction streams. First, we extract the KMV synopses for each item from the stream. Then, we propose a novel estimator to estimate the frequency of an itemset over the KMV synopses. Comparing to the existing estimator, our method is not only more accurate and efficient to calculate but also follows the downward-closure property. These properties enable the incorporation of our new estimator with existing frequent itemset mining (FIM) algorithm (e.g., FP-Growth) to mine frequent itemsets over multi-transaction streams. To demonstrate this, we implement a KMV synopsis based FIM algorithm by integrating our estimator into existing FIM algorithms, and we prove it is capable of guaranteeing the accuracy of FIM with a bounded size of KMV synopsis. Experimental results on massive streams show our estimator can significantly improve on the accuracy for both estimating itemset frequency and FIM compared to the existing estimators.},
  archive      = {J_TKDD},
  doi          = {10.1145/3465238},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {7},
  number       = {2},
  pages        = {1-30},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {A synopsis based approach for itemset frequency estimation over massive multi-transaction stream},
  volume       = {16},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Dynamically adjusting diversity in ensembles for the
classification of data streams with concept drift. <em>TKDD</em>,
<em>16</em>(2), 1–20. (<a
href="https://doi.org/10.1145/3466616">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A data stream can be defined as a system that continually generates a lot of data over time. Today, processing data streams requires new demands and challenging tasks in the data mining and machine learning areas. Concept Drift is a problem commonly characterized as changes in the distribution of the data within a data stream. The implementation of new methods for dealing with data streams where concept drifts occur requires algorithms that can adapt to several scenarios to improve its performance in the different experimental situations where they are tested. This research proposes a strategy for dynamic parameter adjustment in the presence of concept drifts. Parameter Estimation Procedure (PEP) is a general method proposed for dynamically adjusting parameters which is applied to the diversity parameter (λ) of several classification ensembles commonly used in the area. To this end, the proposed estimation method (PEP) was used to create Boosting-like Online Learning Ensemble with Parameter Estimation (BOLE-PE), Online AdaBoost-based M1 with Parameter Estimation (OABM1-PE), and Oza and Russell’s Online Bagging with Parameter Estimation (OzaBag-PE), based on the existing ensembles BOLE, OABM1, and OzaBag, respectively. To validate them, experiments were performed with artificial and real-world datasets using Hoeffding Tree (HT) as base classifier. The accuracy results were statistically evaluated using a variation of the Friedman test and the Nemenyi post-hoc test. The experimental results showed that the application of the dynamic estimation in the diversity parameter (λ) produced good results in most scenarios, i.e., the modified methods have improved accuracy in the experiments with both artificial and real-world datasets.},
  archive      = {J_TKDD},
  doi          = {10.1145/3466616},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {7},
  number       = {2},
  pages        = {1-20},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Dynamically adjusting diversity in ensembles for the classification of data streams with concept drift},
  volume       = {16},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Opinion dynamics optimization by varying susceptibility to
persuasion via non-convex local search. <em>TKDD</em>, <em>16</em>(2),
1–34. (<a href="https://doi.org/10.1145/3466617">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A long line of work in social psychology has studied variations in people’s susceptibility to persuasion—the extent to which they are willing to modify their opinions on a topic. This body of literature suggests an interesting perspective on theoretical models of opinion formation by interacting parties in a network: in addition to considering interventions that directly modify people’s intrinsic opinions, it is also natural to consider interventions that modify people’s susceptibility to persuasion. In this work, motivated by this fact, we propose an influence optimization problem. Specifically, we adopt a popular model for social opinion dynamics, where each agent has some fixed innate opinion, and a resistance that measures the importance it places on its innate opinion; agents influence one another’s opinions through an iterative process. Under certain conditions, this iterative process converges to some equilibrium opinion vector. For the unbudgeted variant of the problem, the goal is to modify the resistance of any number of agents (within some given range) such that the sum of the equilibrium opinions is minimized; for the budgeted variant, in addition the algorithm is given upfront a restriction on the number of agents whose resistance may be modified. We prove that the objective function is in general non-convex. Hence, formulating the problem as a convex program as in an early version of this work (Abebe et al., KDD’18) might have potential correctness issues. We instead analyze the structure of the objective function, and show that any local optimum is also a global optimum, which is somehow surprising as the objective function might not be convex. Furthermore, we combine the iterative process and the local search paradigm to design very efficient algorithms that can solve the unbudgeted variant of the problem optimally on large-scale graphs containing millions of nodes. Finally, we propose and evaluate experimentally a family of heuristics for the budgeted variant of the problem.},
  archive      = {J_TKDD},
  doi          = {10.1145/3466617},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {7},
  number       = {2},
  pages        = {1-34},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Opinion dynamics optimization by varying susceptibility to persuasion via non-convex local search},
  volume       = {16},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Cross-domain recommendation with bridge-item embeddings.
<em>TKDD</em>, <em>16</em>(1), 1–23. (<a
href="https://doi.org/10.1145/3447683">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Web systems that provide the same functionality usually share a certain amount of items. This makes it possible to combine data from different websites to improve recommendation quality, known as the cross-domain recommendation task. Despite many research efforts on this task, the main drawback is that they largely assume the data of different systems can be fully shared . Such an assumption is unrealistic different systems are typically operated by different companies, and it may violate business privacy policy to directly share user behavior data since it is highly sensitive. In this work, we consider a more practical scenario to perform cross-domain recommendation. To avoid the leak of user privacy during the data sharing process, we consider sharing only the information of the item side, rather than user behavior data. Specifically, we transfer the item embeddings across domains, making it easier for two companies to reach a consensus (e.g., legal policy) on data sharing since the data to be shared is user-irrelevant and has no explicit semantics. To distill useful signals from transferred item embeddings, we rely on the strong representation power of neural networks and develop a new method named as NATR (short for N eural A ttentive T ransfer R ecommendation ). We perform extensive experiments on two real-world datasets, demonstrating that NATR achieves similar or even better performance than traditional cross-domain recommendation methods that directly share user-relevant data. Further insights are provided on the efficacy of NATR in using the transferred item embeddings to alleviate the data sparsity issue.},
  archive      = {J_TKDD},
  doi          = {10.1145/3447683},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {7},
  number       = {1},
  pages        = {1-23},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Cross-domain recommendation with bridge-item embeddings},
  volume       = {16},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). DiMBERT: Learning vision-language grounded representations
with disentangled multimodal-attention. <em>TKDD</em>, <em>16</em>(1),
1–19. (<a href="https://doi.org/10.1145/3447685">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vision-and-language (V-L) tasks require the system to understand both vision content and natural language, thus learning fine-grained joint representations of vision and language (a.k.a. V-L representations) is of paramount importance. Recently, various pre-trained V-L models are proposed to learn V-L representations and achieve improved results in many tasks. However, the mainstream models process both vision and language inputs with the same set of attention matrices. As a result, the generated V-L representations are entangled in one common latent space . To tackle this problem, we propose DiMBERT (short for Di sentangled M ultimodal-Attention BERT ), which is a novel framework that applies separated attention spaces for vision and language, and the representations of multi-modalities can thus be disentangled explicitly. To enhance the correlation between vision and language in disentangled spaces, we introduce the visual concepts to DiMBERT which represent visual information in textual format. In this manner, visual concepts help to bridge the gap between the two modalities. We pre-train DiMBERT on a large amount of image–sentence pairs on two tasks: bidirectional language modeling and sequence-to-sequence language modeling. After pre-train, DiMBERT is further fine-tuned for the downstream tasks. Experiments show that DiMBERT sets new state-of-the-art performance on three tasks (over four datasets), including both generation tasks (image captioning and visual storytelling) and classification tasks (referring expressions). The proposed DiM (short for Di sentangled M ultimodal-Attention) module can be easily incorporated into existing pre-trained V-L models to boost their performance, up to a 5% increase on the representative task. Finally, we conduct a systematic analysis and demonstrate the effectiveness of our DiM and the introduced visual concepts.},
  archive      = {J_TKDD},
  doi          = {10.1145/3447685},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {7},
  number       = {1},
  pages        = {1-19},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {DiMBERT: Learning vision-language grounded representations with disentangled multimodal-attention},
  volume       = {16},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A latent variable augmentation method for image
categorization with insufficient training samples. <em>TKDD</em>,
<em>16</em>(1), 1–35. (<a
href="https://doi.org/10.1145/3451165">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Over the past few years, we have made great progress in image categorization based on convolutional neural networks (CNNs). These CNNs are always trained based on a large-scale image data set; however, people may only have limited training samples for training CNN in the real-world applications. To solve this problem, one intuition is augmenting training samples. In this article, we propose an algorithm called Lavagan ( La tent V ariables A ugmentation Method based on G enerative A dversarial N ets) to improve the performance of CNN with insufficient training samples. The proposed Lavagan method is mainly composed of two tasks. The first task is that we augment a number latent variables (LVs) from a set of adaptive and constrained LVs distributions. In the second task, we take the augmented LVs into the training procedure of the image classifier. By taking these two tasks into account, we propose a uniform objective function to incorporate the two tasks into the learning. We then put forward an alternative two-play minimization game to minimize this uniform loss function such that we can obtain the predictive classifier. Moreover, based on Hoeffding’s Inequality and Chernoff Bounding method, we analyze the feasibility and efficiency of the proposed Lavagan method, which manifests that the LV augmentation method is able to improve the performance of Lavagan with insufficient training samples. Finally, the experiment has shown that the proposed Lavagan method is able to deliver more accurate performance than the existing state-of-the-art methods.},
  archive      = {J_TKDD},
  doi          = {10.1145/3451165},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {7},
  number       = {1},
  pages        = {1-35},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {A latent variable augmentation method for image categorization with insufficient training samples},
  volume       = {16},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Bayesian additive matrix approximation for social
recommendation. <em>TKDD</em>, <em>16</em>(1), 1–34. (<a
href="https://doi.org/10.1145/3451391">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Social relations between users have been proven to be a good type of auxiliary information to improve the recommendation performance. However, it is a challenging issue to sufficiently exploit the social relations and correctly determine the user preference from both social and rating information. In this article, we propose a unified Bayesian Additive Matrix Approximation model (BAMA), which takes advantage of rating preference and social network to provide high-quality recommendation. The basic idea of BAMA is to extract social influence from social networks, integrate them to Bayesian additive co-clustering for effectively determining the user clusters and item clusters, and provide an accurate rating prediction. In addition, an efficient algorithm with collapsed Gibbs Sampling is designed to inference the proposed model. A series of experiments were conducted on six real-world social datasets. The results demonstrate the superiority of the proposed BAMA by comparing with the state-of-the-art methods from three views, all users, cold-start users, and users with few social relations. With the aid of social information, furthermore, BAMA has ability to provide the explainable recommendation.},
  archive      = {J_TKDD},
  doi          = {10.1145/3451391},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {7},
  number       = {1},
  pages        = {1-34},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Bayesian additive matrix approximation for social recommendation},
  volume       = {16},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). MULFE: Multi-label learning via label-specific feature space
ensemble. <em>TKDD</em>, <em>16</em>(1), 1–24. (<a
href="https://doi.org/10.1145/3451392">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In multi-label learning, label correlations commonly exist in the data. Such correlation not only provides useful information, but also imposes significant challenges for multi-label learning. Recently, label-specific feature embedding has been proposed to explore label-specific features from the training data, and uses feature highly customized to the multi-label set for learning. While such feature embedding methods have demonstrated good performance, the creation of the feature embedding space is only based on a single label, without considering label correlations in the data. In this article, we propose to combine multiple label-specific feature spaces, using label correlation, for multi-label learning. The proposed algorithm, mu lti- l abel-specific f eature space e nsemble (MULFE), takes consideration label-specific features, label correlation, and weighted ensemble principle to form a learning framework. By conducting clustering analysis on each label’s negative and positive instances, MULFE first creates features customized to each label. After that, MULFE utilizes the label correlation to optimize the margin distribution of the base classifiers which are induced by the related label-specific feature spaces. By combining multiple label-specific features, label correlation based weighting, and ensemble learning, MULFE achieves maximum margin multi-label classification goal through the underlying optimization framework. Empirical studies on 10 public data sets manifest the effectiveness of MULFE.},
  archive      = {J_TKDD},
  doi          = {10.1145/3451392},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {7},
  number       = {1},
  pages        = {1-24},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {MULFE: Multi-label learning via label-specific feature space ensemble},
  volume       = {16},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A joint passenger flow inference and path recommender system
for deploying new routes and stations of mass transit transportation.
<em>TKDD</em>, <em>16</em>(1), 1–36. (<a
href="https://doi.org/10.1145/3451393">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, a novel decision assistant system for urban transportation, called Route Scheme Assistant (RSA), is proposed to address two crucial issues that few former researches have focused on: route-based passenger flow (PF) inference and multivariant high-PF route recommendation. First, RSA can estimate the PF of arbitrary user-designated routes effectively by utilizing Deep Neural Network (DNN) for regression based on geographical information and spatial-temporal urban informatics. Second, our proposed Bidirectional Prioritized Spanning Tree (BDPST) intelligently combines the parallel computing concept and Gaussian mixture model (GMM) for route recommendation under users’ constraints running in a timely manner. We did experiments on bus-ticket data of Tainan and Chicago and the experimental results show that the PF inference model outperforms baseline and comparative methods from 41% to 57%. Moreover, the proposed BDPST algorithm&#39;s performance is not far away from the optimal PF and outperforms other comparative methods from 39% to 71% in large-scale route recommendations.},
  archive      = {J_TKDD},
  doi          = {10.1145/3451393},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {7},
  number       = {1},
  pages        = {1-36},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {A joint passenger flow inference and path recommender system for deploying new routes and stations of mass transit transportation},
  volume       = {16},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Graph-based stock recommendation by time-aware relational
attention network. <em>TKDD</em>, <em>16</em>(1), 1–21. (<a
href="https://doi.org/10.1145/3451397">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The stock market investors aim at maximizing their investment returns. Stock recommendation task is to recommend stocks with higher return ratios for the investors. Most stock prediction methods study the historical sequence patterns to predict stock trend or price in the near future. In fact, the future price of a stock is correlated not only with its historical price, but also with other stocks. In this article, we take into account the relationships between stocks (corporations) by stock relation graph. Furthermore, we propose a Time-aware Relational Attention Network (TRAN) for graph-based stock recommendation according to return ratio ranking. In TRAN, the time-aware relational attention mechanism is designed to capture time-varying correlation strengths between stocks by the interaction of historical sequences and stock description documents. With the dynamic strengths, the nodes of the stock relation graph aggregate the features of neighbor stock nodes by graph convolution operation. For a given group of stocks, the proposed TRAN model can output the ranking results of stocks according to their return ratios. The experimental results on several real-world datasets demonstrate the effectiveness of our TRAN for stock recommendation.},
  archive      = {J_TKDD},
  doi          = {10.1145/3451397},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {7},
  number       = {1},
  pages        = {1-21},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Graph-based stock recommendation by time-aware relational attention network},
  volume       = {16},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). MCS+: An efficient algorithm for crawling the community
structure in multiplex networks. <em>TKDD</em>, <em>16</em>(1), 1–32.
(<a href="https://doi.org/10.1145/3451527">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we consider the problem of crawling a multiplex network to identify the community structure of a layer-of-interest. A multiplex network is one where there are multiple types of relationships between the nodes. In many multiplex networks, some layers might be easier to explore (in terms of time, money etc.). We propose MCS+ , an algorithm that can use the information from the easier to explore layers to help in the exploration of a layer-of-interest that is expensive to explore. We consider the goal of exploration to be generating a sample that is representative of the communities in the complete layer-of-interest. This work has practical applications in areas such as exploration of dark (e.g., criminal) networks, online social networks, biological networks, and so on. For example, in a terrorist network, relationships such as phone records, e-mail records, and so on are easier to collect; in contrast, data on the face-to-face communications are much harder to collect, but also potentially more valuable. We perform extensive experimental evaluations on real-world networks, and we observe that MCS+ consistently outperforms the best baseline—the similarity of the sample that MCS+ generates to the real network is up to three times that of the best baseline in some networks. We also perform theoretical and experimental evaluations on the scalability of MCS+ to network properties, and find that it scales well with the budget, number of layers in the multiplex network, and the average degree in the original network.},
  archive      = {J_TKDD},
  doi          = {10.1145/3451527},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {7},
  number       = {1},
  pages        = {1-32},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {MCS+: An efficient algorithm for crawling the community structure in multiplex networks},
  volume       = {16},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Distributed latent dirichlet allocation on streams.
<em>TKDD</em>, <em>16</em>(1), 1–20. (<a
href="https://doi.org/10.1145/3451528">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Latent Dirichlet Allocation (LDA) has been widely used for topic modeling, with applications spanning various areas such as natural language processing and information retrieval. While LDA on small and static datasets has been extensively studied, several real-world challenges are posed in practical scenarios where datasets are often huge and are gathered in a streaming fashion. As the state-of-the-art LDA algorithm on streams, Streaming Variational Bayes (SVB) introduced Bayesian updating to provide a streaming procedure. However, the utility of SVB is limited in applications since it ignored three challenges of processing real-world streams: topic evolution , data turbulence , and real-time inference . In this article, we propose a novel distributed LDA algorithm—referred to as StreamFed-LDA— to deal with challenges on streams. For topic modeling of streaming data, the ability to capture evolving topics is essential for practical online inference. To achieve this goal, StreamFed-LDA is based on a specialized framework that supports lifelong (continual) learning of evolving topics. On the other hand, data turbulence is commonly present in streams due to real-life events. In that case, the design of StreamFed-LDA allows the model to learn new characteristics from the most recent data while maintaining the historical information. On massive streaming data, it is difficult and crucial to provide real-time inference results. To increase the throughput and reduce the latency, StreamFed-LDA introduces additional techniques that substantially reduce both computation and communication costs in distributed systems. Experiments on four real-world datasets show that the proposed framework achieves significantly better performance of online inference compared with the baselines. At the same time, StreamFed-LDA also reduces the latency by orders of magnitudes in real-world datasets.},
  archive      = {J_TKDD},
  doi          = {10.1145/3451528},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {7},
  number       = {1},
  pages        = {1-20},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Distributed latent dirichlet allocation on streams},
  volume       = {16},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Explainable artificial intelligence-based competitive factor
identification. <em>TKDD</em>, <em>16</em>(1), 1–11. (<a
href="https://doi.org/10.1145/3451529">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Competitor analysis is an essential component of corporate strategy, providing both offensive and defensive strategic contexts to identify opportunities and threats. The rapid development of social media has recently led to several methodologies and frameworks facilitating competitor analysis through online reviews. Existing studies only focused on detecting comparative sentences in review comments or utilized low-performance models. However, this study proposes a novel approach to identifying the competitive factors using a recent explainable artificial intelligence approach at the comprehensive product feature level. We establish a model to classify the review comments for each corresponding product and evaluate the relevance of each keyword in such comments during the classification process. We then extract and prioritize the keywords and determine their competitiveness based on relevance. Our experiment results show that the proposed method can effectively extract the competitive factors both qualitatively and quantitatively.},
  archive      = {J_TKDD},
  doi          = {10.1145/3451529},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {7},
  number       = {1},
  pages        = {1-11},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Explainable artificial intelligence-based competitive factor identification},
  volume       = {16},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Recurrent coupled topic modeling over sequential documents.
<em>TKDD</em>, <em>16</em>(1), 1–32. (<a
href="https://doi.org/10.1145/3451530">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The abundant sequential documents such as online archival, social media, and news feeds are streamingly updated, where each chunk of documents is incorporated with smoothly evolving yet dependent topics. Such digital texts have attracted extensive research on dynamic topic modeling to infer hidden evolving topics and their temporal dependencies. However, most of the existing approaches focus on single-topic-thread evolution and ignore the fact that a current topic may be coupled with multiple relevant prior topics. In addition, these approaches also incur the intractable inference problem when inferring latent parameters, resulting in a high computational cost and performance degradation. In this work, we assume that a current topic evolves from all prior topics with corresponding coupling weights, forming the multi-topic-thread evolution . Our method models the dependencies between evolving topics and thoroughly encodes their complex multi-couplings across time steps. To conquer the intractable inference challenge, a new solution with a set of novel data augmentation techniques is proposed, which successfully discomposes the multi-couplings between evolving topics. A fully conjugate model is thus obtained to guarantee the effectiveness and efficiency of the inference technique. A novel Gibbs sampler with a backward–forward filter algorithm efficiently learns latent time-evolving parameters in a closed-form. In addition, the latent Indian Buffet Process compound distribution is exploited to automatically infer the overall topic number and customize the sparse topic proportions for each sequential document without bias. The proposed method is evaluated on both synthetic and real-world datasets against the competitive baselines, demonstrating its superiority over the baselines in terms of the low per-word perplexity, high coherent topics, and better document time prediction.},
  archive      = {J_TKDD},
  doi          = {10.1145/3451530},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {7},
  number       = {1},
  pages        = {1-32},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Recurrent coupled topic modeling over sequential documents},
  volume       = {16},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Generic multi-label annotation via adaptive graph and
marginalized augmentation. <em>TKDD</em>, <em>16</em>(1), 1–20. (<a
href="https://doi.org/10.1145/3451884">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-label learning recovers multiple labels from a single instance. It is a more challenging task compared with single-label manner. Most multi-label learning approaches need large-scale well-labeled samples to achieve high accurate performance. However, it is expensive to build such a dataset. In this work, we propose a generic multi-label learning framework based on Adaptive Graph and Marginalized Augmentation (AGMA) in a semi-supervised scenario. Generally speaking, AGMA makes use of a small amount of labeled data associated with a lot of unlabeled data to boost the learning performance. First, an adaptive similarity graph is learned to effectively capture the intrinsic structure within the data. Second, marginalized augmentation strategy is explored to enhance the model generalization and robustness. Third, a feature-label autoencoder is further deployed to improve inferring efficiency. All the modules are jointly trained to benefit each other. State-of-the-art benchmarks in both traditional and zero-shot multi-label learning scenarios are evaluated. Experiments and ablation studies illustrate the accuracy and efficiency of our AGMA method.},
  archive      = {J_TKDD},
  doi          = {10.1145/3451884},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {7},
  number       = {1},
  pages        = {1-20},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Generic multi-label annotation via adaptive graph and marginalized augmentation},
  volume       = {16},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Lost in transduction: Transductive transfer learning in text
classification. <em>TKDD</em>, <em>16</em>(1), 1–21. (<a
href="https://doi.org/10.1145/3453146">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Obtaining high-quality labelled data for training a classifier in a new application domain is often costly. Transfer Learning (a.k.a. “Inductive Transfer”) tries to alleviate these costs by transferring, to the “target” domain of interest, knowledge available from a different “source” domain. In transfer learning the lack of labelled information from the target domain is compensated by the availability at training time of a set of unlabelled examples from the target distribution. Transductive Transfer Learning denotes the transfer learning setting in which the only set of target documents that we are interested in classifying is known and available at training time. Although this definition is indeed in line with Vapnik’s original definition of “transduction”, current terminology in the field is confused. In this article, we discuss how the term “transduction” has been misused in the transfer learning literature, and propose a clarification consistent with the original characterization of this term given by Vapnik. We go on to observe that the above terminology misuse has brought about misleading experimental comparisons, with inductive transfer learning methods that have been incorrectly compared with transductive transfer learning methods. We then, give empirical evidence that the difference in performance between the inductive version and the transductive version of a transfer learning method can indeed be statistically significant (i.e., that knowing at training time the only data one needs to classify indeed gives an advantage). Our clarification allows a reassessment of the field, and of the relative merits of the major, state-of-the-art algorithms for transfer learning in text classification.},
  archive      = {J_TKDD},
  doi          = {10.1145/3453146},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {7},
  number       = {1},
  pages        = {1-21},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Lost in transduction: Transductive transfer learning in text classification},
  volume       = {16},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Modeling temporal patterns with dilated convolutions for
time-series forecasting. <em>TKDD</em>, <em>16</em>(1), 1–22. (<a
href="https://doi.org/10.1145/3453724">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time-series forecasting is an important problem across a wide range of domains. Designing accurate and prompt forecasting algorithms is a non-trivial task, as temporal data that arise in real applications often involve both non-linear dynamics and linear dependencies, and always have some mixtures of sequential and periodic patterns, such as daily, weekly repetitions, and so on. At this point, however, most recent deep models often use Recurrent Neural Networks (RNNs) to capture these temporal patterns, which is hard to parallelize and not fast enough for real-world applications especially when a huge amount of user requests are coming. Recently, CNNs have demonstrated significant advantages for sequence modeling tasks over the de-facto RNNs, while providing high computational efficiency due to the inherent parallelism. In this work, we propose HyDCNN, a novel hybrid framework based on fully Dilated CNN for time-series forecasting tasks. The core component in HyDCNN is a proposed hybrid module, in which our proposed position-aware dilated CNNs are utilized to capture the sequential non-linear dynamics and an autoregressive model is leveraged to capture the sequential linear dependencies. To further capture the periodic temporal patterns, a novel hop scheme is introduced in the hybrid module. HyDCNN is then composed of multiple hybrid modules to capture the sequential and periodic patterns. Each of these hybrid modules targets on either the sequential pattern or one kind of periodic patterns. Extensive experiments on five real-world datasets have shown that the proposed HyDCNN is better compared with state-of-the-art baselines and is at least 200% better than RNN baselines. The datasets and source code will be published in Github to facilitate more future work.},
  archive      = {J_TKDD},
  doi          = {10.1145/3453724},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {7},
  number       = {1},
  pages        = {1-22},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Modeling temporal patterns with dilated convolutions for time-series forecasting},
  volume       = {16},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). CrowdTC: Crowd-powered learning for text classification.
<em>TKDD</em>, <em>16</em>(1), 1–23. (<a
href="https://doi.org/10.1145/3457216">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Text classification is a fundamental task in content analysis. Nowadays, deep learning has demonstrated promising performance in text classification compared with shallow models. However, almost all the existing models do not take advantage of the wisdom of human beings to help text classification. Human beings are more intelligent and capable than machine learning models in terms of understanding and capturing the implicit semantic information from text. In this article, we try to take guidance from human beings to classify text. We propose Crowd-powered learning for Text Classification (CrowdTC for short). We design and post the questions on a crowdsourcing platform to extract keywords in text. Sampling and clustering techniques are utilized to reduce the cost of crowdsourcing. Also, we present an attention-based neural network and a hybrid neural network to incorporate the extracted keywords as human guidance into deep neural networks. Extensive experiments on public datasets confirm that CrowdTC improves the text classification accuracy of neural networks by using the crowd-powered keyword guidance.},
  archive      = {J_TKDD},
  doi          = {10.1145/3457216},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {7},
  number       = {1},
  pages        = {1-23},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {CrowdTC: Crowd-powered learning for text classification},
  volume       = {16},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Jointly modeling heterogeneous student behaviors and
interactions among multiple prediction tasks. <em>TKDD</em>,
<em>16</em>(1), 1–24. (<a
href="https://doi.org/10.1145/3458023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Prediction tasks about students have practical significance for both student and college. Making multiple predictions about students is an important part of a smart campus. For instance, predicting whether a student will fail to graduate can alert the student affairs office to take predictive measures to help the student improve his/her academic performance. With the development of information technology in colleges, we can collect digital footprints that encode heterogeneous behaviors continuously. In this article, we focus on modeling heterogeneous behaviors and making multiple predictions together, since some prediction tasks are related and learning the model for a specific task may have the data sparsity problem. To this end, we propose a variant of Long-Short Term Memory (LSTM) and a soft-attention mechanism. The proposed LSTM is able to learn the student profile-aware representation from heterogeneous behavior sequences. The proposed soft-attention mechanism can dynamically learn different importance degrees of different days for every student. In this way, heterogeneous behaviors can be well modeled. In order to model interactions among multiple prediction tasks, we propose a co-attention mechanism based unit. With the help of the stacked units, we can explicitly control the knowledge transfer among multiple tasks. We design three motivating behavior prediction tasks based on a real-world dataset collected from a college. Qualitative and quantitative experiments on the three prediction tasks have demonstrated the effectiveness of our model.},
  archive      = {J_TKDD},
  doi          = {10.1145/3458023},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {7},
  number       = {1},
  pages        = {1-24},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Jointly modeling heterogeneous student behaviors and interactions among multiple prediction tasks},
  volume       = {16},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). New multi-view classification method with uncertain data.
<em>TKDD</em>, <em>16</em>(1), 1–23. (<a
href="https://doi.org/10.1145/3458282">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view classification aims at designing a multi-view learning strategy to train a classifier from multi-view data, which are easily collected in practice. Most of the existing works focus on multi-view classification by assuming the multi-view data are collected with precise information. However, we always collect the uncertain multi-view data due to the collection process is corrupted with noise in real-life application. In this case, this article proposes a novel approach, called uncertain multi-view learning with support vector machine (UMV-SVM) to cope with the problem of multi-view learning with uncertain data. The method first enforces the agreement among all the views to seek complementary information of multi-view data and takes the uncertainty of the multi-view data into consideration by modeling reachability area of the noise. Then it proposes an iterative framework to solve the proposed UMV-SVM model such that we can obtain the multi-view classifier for prediction. Extensive experiments on real-life datasets have shown that the proposed UMV-SVM can achieve a better performance for uncertain multi-view classification in comparison to the state-of-the-art multi-view classification methods.},
  archive      = {J_TKDD},
  doi          = {10.1145/3458282},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {7},
  number       = {1},
  pages        = {1-23},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {New multi-view classification method with uncertain data},
  volume       = {16},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). BiLabel-specific features for multi-label classification.
<em>TKDD</em>, <em>16</em>(1), 1–23. (<a
href="https://doi.org/10.1145/3458283">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In multi-label classification, the task is to induce predictive models which can assign a set of relevant labels for the unseen instance. The strategy of label-specific features has been widely employed in learning from multi-label examples, where the classification model for predicting the relevancy of each class label is induced based on its tailored features rather than the original features. Existing approaches work by generating a group of tailored features for each class label independently, where label correlations are not fully considered in the label-specific features generation process. In this article, we extend existing strategy by proposing a simple yet effective approach based on BiLabel-specific features. Specifically, a group of tailored features is generated for a pair of class labels with heuristic prototype selection and embedding. Thereafter, predictions of classifiers induced by BiLabel-specific features are ensembled to determine the relevancy of each class label for unseen instance. To thoroughly evaluate the BiLabel-specific features strategy, extensive experiments are conducted over a total of 35 benchmark datasets. Comparative studies against state-of-the-art label-specific features techniques clearly validate the superiority of utilizing BiLabel-specific features to yield stronger generalization performance for multi-label classification.},
  archive      = {J_TKDD},
  doi          = {10.1145/3458283},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {7},
  number       = {1},
  pages        = {1-23},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {BiLabel-specific features for multi-label classification},
  volume       = {16},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). MSIPA: Multi-scale interval pattern-aware network for ICU
transfer prediction. <em>TKDD</em>, <em>16</em>(1), 1–17. (<a
href="https://doi.org/10.1145/3458284">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate prediction of patients’ ICU transfer events is of great significance for improving ICU treatment efficiency. ICU transition prediction task based on Electronic Health Records (EHR) is a temporal mining task like many other health informatics mining tasks. In the EHR-based temporal mining task, existing approaches are usually unable to mine and exploit patterns used to improve model performance. This article proposes a network based on Interval Pattern-Aware, Multi-Scale Interval Pattern-Aware (MSIPA) network. MSIPA mines different interval patterns in temporal EHR data according to the short, medium, and long intervals. MSIPA utilizes the Scaled Dot-Product Attention mechanism to query the contexts corresponding to the three scale patterns. Furthermore, Transformer will use all three types of contextual information simultaneously for ICU transfer prediction. Extensive experiments on real-world data demonstrate that an MSIPA network outperforms state-of-the-art methods.},
  archive      = {J_TKDD},
  doi          = {10.1145/3458284},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {7},
  number       = {1},
  pages        = {1-17},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {MSIPA: Multi-scale interval pattern-aware network for ICU transfer prediction},
  volume       = {16},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Unsupervised subspace extraction via deep kernelized
clustering. <em>TKDD</em>, <em>16</em>(1), 1–15. (<a
href="https://doi.org/10.1145/3459082">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature extraction has been widely studied to find informative latent features and reduce the dimensionality of data. In particular, due to the difficulty in obtaining labeled data, unsupervised feature extraction has received much attention in data mining. However, widely used unsupervised feature extraction methods require side information about data or rigid assumptions on the latent feature space. Furthermore, most feature extraction methods require predefined dimensionality of the latent feature space,which should be manually tuned as a hyperparameter. In this article, we propose a new unsupervised feature extraction method called Unsupervised Subspace Extractor ( USE ), which does not require any side information and rigid assumptions on data. Furthermore, USE can find a subspace generated by a nonlinear combination of the input feature and automatically determine the optimal dimensionality of the subspace for the given nonlinear combination. The feature extraction process of USE is well justified mathematically, and we also empirically demonstrate the effectiveness of USE for several benchmark datasets.},
  archive      = {J_TKDD},
  doi          = {10.1145/3459082},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {7},
  number       = {1},
  pages        = {1-15},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Unsupervised subspace extraction via deep kernelized clustering},
  volume       = {16},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Demarcating endogenous and exogenous opinion dynamics: An
experimental design approach. <em>TKDD</em>, <em>15</em>(6), 1–25. (<a
href="https://doi.org/10.1145/3449361">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The networked opinion diffusion in online social networks is often governed by the two genres of opinions— endogenous opinions that are driven by the influence of social contacts among users, and exogenous opinions which are formed by external effects like news and feeds. Accurate demarcation of endogenous and exogenous messages offers an important cue to opinion modeling, thereby enhancing its predictive performance. In this article, we design a suite of unsupervised classification methods based on experimental design approaches, in which, we aim to select the subsets of events which minimize different measures of mean estimation error. In more detail, we first show that these subset selection tasks are NP-Hard. Then we show that the associated objective functions are weakly submodular, which allows us to cast efficient approximation algorithms with guarantees. Finally, we validate the efficacy of our proposal on various real-world datasets crawled from Twitter as well as diverse synthetic datasets. Our experiments range from validating prediction performance on unsanitized and sanitized events to checking the effect of selecting optimal subsets of various sizes. Through various experiments, we have found that our method offers a significant improvement in accuracy in terms of opinion forecasting, against several competitors.},
  archive      = {J_TKDD},
  doi          = {10.1145/3449361},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {6},
  number       = {6},
  pages        = {1-25},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Demarcating endogenous and exogenous opinion dynamics: An experimental design approach},
  volume       = {15},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Learning graph neural networks with positive and unlabeled
nodes. <em>TKDD</em>, <em>15</em>(6), 1–25. (<a
href="https://doi.org/10.1145/3450316">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph neural networks (GNNs) are important tools for transductive learning tasks, such as node classification in graphs, due to their expressive power in capturing complex interdependency between nodes. To enable GNN learning, existing works typically assume that labeled nodes, from two or multiple classes, are provided, so that a discriminative classifier can be learned from the labeled data. In reality, this assumption might be too restrictive for applications, as users may only provide labels of interest in a single class for a small number of nodes. In addition, most GNN models only aggregate information from short distances ( e.g. , 1-hop neighbors) in each round, and fail to capture long-distance relationship in graphs. In this article, we propose a novel GNN framework, long-short distance aggregation networks, to overcome these limitations. By generating multiple graphs at different distance levels, based on the adjacency matrix, we develop a long-short distance attention model to model these graphs. The direct neighbors are captured via a short-distance attention mechanism, and neighbors with long distance are captured by a long-distance attention mechanism. Two novel risk estimators are further employed to aggregate long-short-distance networks, for PU learning and the loss is back-propagated for model learning. Experimental results on real-world datasets demonstrate the effectiveness of our algorithm.},
  archive      = {J_TKDD},
  doi          = {10.1145/3450316},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {6},
  number       = {6},
  pages        = {1-25},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Learning graph neural networks with positive and unlabeled nodes},
  volume       = {15},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Page-level main content extraction from heterogeneous
webpages. <em>TKDD</em>, <em>15</em>(6), 1–105. (<a
href="https://doi.org/10.1145/3451168">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The main content of a webpage is often surrounded by other boilerplate elements related to the template, such as menus, advertisements, copyright notices, and comments. For crawlers and indexers, isolating the main content from the template and other noisy information is an essential task, because processing and storing noisy information produce a waste of resources such as bandwidth, storage space, and computing time. Besides, the detection and extraction of the main content is useful in different areas, such as data mining, web summarization, and content adaptation to low resolutions. This work introduces a new technique for main content extraction. In contrast to most techniques, this technique not only extracts text, but also other types of content, such as images, and animations. It is a Document Object Model-based page-level technique, thus it only needs to load one single webpage to extract the main content. As a consequence, it is efficient enough as to be used online (in real-time). We have empirically evaluated the technique using a suite of real heterogeneous benchmarks producing very good results compared with other well-known content extraction techniques.},
  archive      = {J_TKDD},
  doi          = {10.1145/3451168},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {6},
  number       = {6},
  pages        = {1-105},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Page-level main content extraction from heterogeneous webpages},
  volume       = {15},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). 3DGCN: 3-dimensional dynamic graph convolutional network for
citywide crowd flow prediction. <em>TKDD</em>, <em>15</em>(6), 1–21. (<a
href="https://doi.org/10.1145/3451394">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Crowd flow prediction is an essential task benefiting a wide range of applications for the transportation system and public safety. However, it is a challenging problem due to the complex spatio-temporal dependence and the complicated impact of urban structure on the crowd flow patterns. In this article, we propose a novel framework, 3- D imensional G raph C onvolution N etwork (3DGCN), to predict citywide crowd flow. We first model it as a dynamic spatio-temporal graph prediction problem, where each node represents a region with time-varying flows, and each edge represents the origin–destination (OD) flow between its corresponding regions. As such, OD flows among regions are treated as a proxy for the spatial interactions among regions. To tackle the complex spatio-temporal dependence, our proposed 3DGCN can model the correlation among graph spatial and temporal neighbors simultaneously. To learn and incorporate urban structures in crowd flow prediction, we design the GCN aggregator to be learned from both crowd flow prediction and region function inference at the same time. Extensive experiments with real-world datasets in two cities demonstrate that our model outperforms state-of-the-art baselines by 9.6%∼19.5% for the next-time-interval prediction.},
  archive      = {J_TKDD},
  doi          = {10.1145/3451394},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {6},
  number       = {6},
  pages        = {1-21},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {3DGCN: 3-dimensional dynamic graph convolutional network for citywide crowd flow prediction},
  volume       = {15},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). App2Vec: Context-aware application usage prediction.
<em>TKDD</em>, <em>15</em>(6), 1–21. (<a
href="https://doi.org/10.1145/3451396">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Both app developers and service providers have strong motivations to understand when and where certain apps are used by users. However, it has been a challenging problem due to the highly skewed and noisy app usage data. Moreover, apps are regarded as independent items in existing studies, which fail to capture the hidden semantics in app usage traces. In this article, we propose App2Vec, a powerful representation learning model to learn the semantic embedding of apps with the consideration of spatio-temporal context. Based on the obtained semantic embeddings, we develop a probabilistic model based on the Bayesian mixture model and Dirichlet process to capture when , where , and what semantics of apps are used to predict the future usage. We evaluate our model using two different app usage datasets, which involve over 1.7 million users and 2,000+ apps. Evaluation results show that our proposed App2Vec algorithm outperforms the state-of-the-art algorithms in app usage prediction with a performance gap of over 17.0%.},
  archive      = {J_TKDD},
  doi          = {10.1145/3451396},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {6},
  number       = {6},
  pages        = {1-21},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {App2Vec: Context-aware application usage prediction},
  volume       = {15},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Faster motif counting via succinct color coding and adaptive
sampling. <em>TKDD</em>, <em>15</em>(6), 1–27. (<a
href="https://doi.org/10.1145/3447397">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We address the problem of computing the distribution of induced connected subgraphs, aka graphlets or motifs , in large graphs. The current state-of-the-art algorithms estimate the motif counts via uniform sampling by leveraging the color coding technique by Alon, Yuster, and Zwick. In this work, we extend the applicability of this approach by introducing a set of algorithmic optimizations and techniques that reduce the running time and space usage of color coding and improve the accuracy of the counts. To this end, we first show how to optimize color coding to efficiently build a compact table of a representative subsample of all graphlets in the input graph. For 8-node motifs, we can build such a table in one hour for a graph with 65M nodes and 1.8B edges, which is times larger than the state of the art. We then introduce a novel adaptive sampling scheme that breaks the “additive error barrier” of uniform sampling, guaranteeing multiplicative approximations instead of just additive ones. This allows us to count not only the most frequent motifs, but also extremely rare ones. For instance, on one graph we accurately count nearly 10.000 distinct 8-node motifs whose relative frequency is so small that uniform sampling would literally take centuries to find them. Our results show that color coding is still the most promising approach to scalable motif counting.},
  archive      = {J_TKDD},
  doi          = {10.1145/3447397},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {5},
  number       = {6},
  pages        = {1-27},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Faster motif counting via succinct color coding and adaptive sampling},
  volume       = {15},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-objective cuckoo search-based streaming feature
selection for multi-label dataset. <em>TKDD</em>, <em>15</em>(6), 1–24.
(<a href="https://doi.org/10.1145/3447586">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The feature selection method is the process of selecting only relevant features by removing irrelevant or redundant features amongst the large number of features that are used to represent data. Nowadays, many application domains especially social media networks, generate new features continuously at different time stamps. In such a scenario, when the features are arriving in an online fashion, to cope up with the continuous arrival of features, the selection task must also have to be a continuous process. Therefore, the streaming feature selection based approach has to be incorporated, i.e., every time a new feature or a group of features arrives, the feature selection process has to be invoked. Again, in recent years, there are many application domains that generate data where samples may belong to more than one classes called multi-label dataset. The multiple labels that the instances are being associated with, may have some dependencies amongst themselves. Finding the co-relation amongst the class labels helps to select the discriminative features across multiple labels. In this article, we develop streaming feature selection methods for multi-label data where the multiple labels are reduced to a lower-dimensional space. The similar labels are grouped together before performing the selection method to improve the selection quality and to make the model time efficient. The multi-objective version of the cuckoo search-based approach is used to select the optimal feature set. The proposed method develops two versions of the streaming feature selection method: ) when the features arrive individually and ) when the features arrive in the form of a batch. Various multi-label datasets from various domains such as text, biology, and audio have been used to test the developed streaming feature selection methods. The proposed methods are compared with many previous feature selection methods and from the comparison, the superiority of using multiple objectives and label co-relation in the feature selection process can be established.},
  archive      = {J_TKDD},
  doi          = {10.1145/3447586},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {5},
  number       = {6},
  pages        = {1-24},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Multi-objective cuckoo search-based streaming feature selection for multi-label dataset},
  volume       = {15},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Trust prediction for online social networks with integrated
time-aware similarity. <em>TKDD</em>, <em>15</em>(6), 1–30. (<a
href="https://doi.org/10.1145/3447682">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Online social networks gain increasing popularity in recent years. In online social networks, trust prediction is significant for recommendations of high reputation users as well as in many other applications. In the literature, trust prediction problem can be solved by several strategies, such as matrix factorization, trust propagation, and -NN search. However, most of the existing works have not considered the possible complementarity among these mainstream strategies to optimize their effectiveness and efficiency. In this article, we propose a novel trust prediction approach named iSim : an integrated time-aware similarity-based collaborative filtering approach leveraging on user similarity, which integrates three kinds of factors to measure user similarity, including vector space similarity, time-aware matrix factorization, and propagated trust. This article is the first work in the literature employing time-aware matrix factorization and propagated trust in the study of similarity. Additionally, we use several methods like adding inverted index to reduce the time complexity of iSim , and provide its theoretical time bound. Moreover, we also provide the detailed overview and theoretical analysis of the existing works. Finally, the extensive experiments with real-world datasets show that iSim achieves great improvement for both efficiency and effectiveness over the state-of-the-art approaches.},
  archive      = {J_TKDD},
  doi          = {10.1145/3447682},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {5},
  number       = {6},
  pages        = {1-30},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Trust prediction for online social networks with integrated time-aware similarity},
  volume       = {15},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Similarity embedding networks for robust human activity
recognition. <em>TKDD</em>, <em>15</em>(6), 1–17. (<a
href="https://doi.org/10.1145/3448021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning models for human activity recognition (HAR) based on sensor data have been heavily studied recently. However, the generalization ability of deep models on complex real-world HAR data is limited by the availability of high-quality labeled activity data, which are hard to obtain. In this article, we design a similarity embedding neural network that maps input sensor signals onto real vectors through carefully designed convolutional and Long Short-Term Memory (LSTM) layers. The embedding network is trained with a pairwise similarity loss, encouraging the clustering of samples from the same class in the embedded real space, and can be effectively trained on a small dataset and even on a noisy dataset with mislabeled samples. Based on the learned embeddings, we further propose both nonparametric and parametric approaches for activity recognition. Extensive evaluation based on two public datasets has shown that the proposed similarity embedding network significantly outperforms state-of-the-art deep models on HAR classification tasks, is robust to mislabeled samples in the training set, and can also be used to effectively denoise a noisy dataset.},
  archive      = {J_TKDD},
  doi          = {10.1145/3448021},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {5},
  number       = {6},
  pages        = {1-17},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Similarity embedding networks for robust human activity recognition},
  volume       = {15},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Link recommendation for social influence maximization.
<em>TKDD</em>, <em>15</em>(6), 1–23. (<a
href="https://doi.org/10.1145/3449023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Social link recommendation systems, like “People-you-may-know” on Facebook, “Who-to-follow” on Twitter, and “Suggested-Accounts” on Instagram assist the users of a social network in establishing new connections with other users. While these systems are becoming more and more important in the growth of social media, they tend to increase the popularity of users that are already popular. Indeed, since link recommenders aim to predict user behavior, they accelerate the creation of links that are likely to be created in the future and, consequently, reinforce social bias by suggesting few (popular) users, giving few chances to most users to create new connections and increase their popularity. In this article, we measure the popularity of a user by means of her social influence, which is her capability to influence other users’ opinions, and we propose a link recommendation algorithm that evaluates the links to suggest according to their increment in social influence instead of their likelihood of being created. In detail, we give a factor approximation algorithm for the problem of maximizing the social influence of a given set of target users by suggesting a fixed number of new connections considering the Linear Threshold model as model for diffusion. We experimentally show that, with few new links and small computational time, our algorithm is able to increase by far the social influence of the target users. We compare our algorithm with several baselines and show that it is the most effective one in terms of increased influence.},
  archive      = {J_TKDD},
  doi          = {10.1145/3449023},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {5},
  number       = {6},
  pages        = {1-23},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Link recommendation for social influence maximization},
  volume       = {15},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Fast and robust dictionary-based classification for image
data. <em>TKDD</em>, <em>15</em>(6), 1–22. (<a
href="https://doi.org/10.1145/3449360">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dictionary-based classification has been promising in knowledge discovery from image data, due to its good performance and interpretable theoretical system. Dictionary learning effectively supports both small- and large-scale datasets, while its robustness and performance depends on the atoms of the dictionary most of the time. Empirically, using a large number of atoms is helpful to obtain a robust classification, while robustness cannot be ensured when setting a small number of atoms. However, learning a huge dictionary dramatically slows down the speed of classification, which is especially worse on the large-scale datasets. To address the problem, we propose a Fast and Robust Dictionary-based Classification (FRDC) framework, which fully utilizes the learned dictionary for classification by staging - and -norms to obtain a robust sparse representation. The new objective function, on the one hand, introduces an additional -norm term upon the conventional -norm optimization, which generates a more robust classification. On the other hand, the optimization based on both - and -norms is solved in two stages, which is much easier and faster than current solutions. In this way, even when using a limited size of dictionary, which makes sure the classification runs very fast, it still can gain higher robustness for multiple types of image data. The optimization is then theoretically analyzed in a new formulation, close but distinct to elastic-net, to prove it is crucial to improve the performance under the premise of robustness. According to our extensive experiments conducted on four image datasets for face and object classification, FRDC keeps generating a robust classification no matter whether using a small or large number of atoms. This guarantees a fast and robust dictionary-based image classification. Furthermore, when simply using deep features extracted via some popular pre-trained neural networks, it outperforms many state-of-the-art methods on the specific datasets.},
  archive      = {J_TKDD},
  doi          = {10.1145/3449360},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {5},
  number       = {6},
  pages        = {1-22},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Fast and robust dictionary-based classification for image data},
  volume       = {15},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). SIR-GN: A fast structural iterative representation learning
approach for graph nodes. <em>TKDD</em>, <em>15</em>(6), 1–39. (<a
href="https://doi.org/10.1145/3450315">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph representation learning methods have attracted an increasing amount of attention in recent years. These methods focus on learning a numerical representation of the nodes in a graph. Learning these representations is a powerful instrument for tasks such as graph mining, visualization, and hashing. They are of particular interest because they facilitate the direct use of standard machine learning models on graphs. Graph representation learning methods can be divided into two main categories: methods preserving the connectivity information of the nodes and methods preserving nodes’ structural information. Connectivity-based methods focus on encoding relationships between nodes, with connected nodes being closer together in the resulting latent space. While methods preserving structure generate a latent space where nodes serving a similar structural function in the network are encoded close to each other, independently of them being connected or even close to each other in the graph. While there are a lot of works that focus on preserving node connectivity, only a few works focus on preserving nodes’ structure. Properly encoding nodes’ structural information is fundamental for many real-world applications as it has been demonstrated that this information can be leveraged to successfully solve many tasks where connectivity-based methods usually fail. A typical example is the task of node classification, i.e., the assignment or prediction of a particular label for a node. Current limitations of structural representation methods are their scalability, representation meaning, and no formal proof that guaranteed the preservation of structural properties. We propose a new graph representation learning method, called Structural Iterative Representation learning approach for Graph Nodes ( SIR-GN ). In this work, we propose two variations ( SIR-GN: GMM and SIR-GN: K-Means ) and show how our best variation SIR-GN: K-Means : (1) theoretically guarantees the preservation of graph structural similarities, (2) provides a clear meaning about its representation and a way to interpret it with a specifically designed attribution procedure, and (3) is scalable and fast to compute. In addition, from our experiment, we show that SIR-GN: K-Means is often better or, in the worst-case comparable than the existing structural graph representation learning methods present in the literature. Also, we empirically show its superior scalability and computational performance when compared to other existing approaches.},
  archive      = {J_TKDD},
  doi          = {10.1145/3450315},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {5},
  number       = {6},
  pages        = {1-39},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {SIR-GN: A fast structural iterative representation learning approach for graph nodes},
  volume       = {15},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). NeuSE: A neural snapshot ensemble method for collaborative
filtering. <em>TKDD</em>, <em>15</em>(6), 1–20. (<a
href="https://doi.org/10.1145/3450526">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In collaborative filtering (CF) algorithms, the optimal models are usually learned by globally minimizing the empirical risks averaged over all the observed data. However, the global models are often obtained via a performance tradeoff among users/items, i.e., not all users/items are perfectly fitted by the global models due to the hard non-convex optimization problems in CF algorithms. Ensemble learning can address this issue by learning multiple diverse models but usually suffer from efficiency issue on large datasets or complex algorithms. In this article, we keep the intermediate models obtained during global model learning as the snapshot models, and then adaptively combine the snapshot models for individual user-item pairs using a memory network-based method. Empirical studies on three real-world datasets show that the proposed method can extensively and significantly improve the accuracy (up to 15.9% relatively) when applied to a variety of existing collaborative filtering methods.},
  archive      = {J_TKDD},
  doi          = {10.1145/3450526},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {5},
  number       = {6},
  pages        = {1-20},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {NeuSE: A neural snapshot ensemble method for collaborative filtering},
  volume       = {15},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The pulse of urban transport: Exploring the co-evolving
pattern for spatio-temporal forecasting. <em>TKDD</em>, <em>15</em>(6),
1–25. (<a href="https://doi.org/10.1145/3450528">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Transportation demand forecasting is a topic of large practical value. However, the model that fits the demand of one transportation by only considering the historical data of its own could be vulnerable since random fluctuations could easily impact the modeling. On the other hand, common factors like time and region attribute, drive the evolution demand of different transportation, leading to a co-evolving intrinsic property between different kinds of transportation. In this work, we focus on exploring the co-evolution between different modes of transport, e.g., taxi demand and shared-bike demand. Two significant challenges impede the discovery of the co-evolving pattern: (1) diversity of the co-evolving correlation, which varies from region to region and time to time. (2) Multi-modal data fusion. Taxi demand and shared-bike demand are time-series data, which have different representations with the external factors. Moreover, the distribution of taxi demand and bike demand are not identical. To overcome these challenges, we propose a novel method, known as co-evolving spatial temporal neural network (CEST). CEST learns a multi-view demand representation for each mode of transport, extracts the co-evolving pattern, then predicts the demand for the target transportation based on multi-scale representation, which includes fine-scale demand information and coarse-scale pattern information. We conduct extensive experiments to validate the superiority of our model over the state-of-art models.},
  archive      = {J_TKDD},
  doi          = {10.1145/3450528},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {5},
  number       = {6},
  pages        = {1-25},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {The pulse of urban transport: Exploring the co-evolving pattern for spatio-temporal forecasting},
  volume       = {15},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Maximum likelihood estimation of power-law degree
distributions via friendship paradox-based sampling. <em>TKDD</em>,
<em>15</em>(6), 1–28. (<a
href="https://doi.org/10.1145/3451166">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article considers the problem of estimating a power-law degree distribution of an undirected network using sampled data. Although power-law degree distributions are ubiquitous in nature, the widely used parametric methods for estimating them (e.g., linear regression on double-logarithmic axes and maximum likelihood estimation with uniformly sampled nodes) suffer from the large variance introduced by the lack of data-points from the tail portion of the power-law degree distribution. As a solution, we present a novel maximum likelihood estimation approach that exploits the friendship paradox to sample more efficiently from the tail of the degree distribution. We analytically show that the proposed method results in a smaller bias, variance and a Cramèr–Rao lower bound compared to the vanilla maximum likelihood estimate obtained with uniformly sampled nodes (which is the most commonly used method in literature). Detailed numerical and empirical results are presented to illustrate the performance of the proposed method under different conditions and how it compares with alternative methods. We also show that the proposed method and its desirable properties (i.e., smaller bias, variance, and Cramèr–Rao lower bound compared to vanilla method based on uniform samples) extend to parametric degree distributions other than the power-law such as exponential degree distributions as well. All the numerical and empirical results are reproducible and the code is publicly available on Github.},
  archive      = {J_TKDD},
  doi          = {10.1145/3451166},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {5},
  number       = {6},
  pages        = {1-28},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Maximum likelihood estimation of power-law degree distributions via friendship paradox-based sampling},
  volume       = {15},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Hierarchical concept-driven language model. <em>TKDD</em>,
<em>15</em>(6), 1–22. (<a
href="https://doi.org/10.1145/3451167">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For guiding natural language generation, many semantic-driven methods have been proposed. While clearly improving the performance of the end-to-end training task, these existing semantic-driven methods still have clear limitations: for example, (i) they only utilize shallow semantic signals (e.g., from topic models) with only a single stochastic hidden layer in their data generation process, which suffer easily from noise (especially adapted for short-text etc.) and lack of interpretation; (ii) they ignore the sentence order and document context, as they treat each document as a bag of sentences, and fail to capture the long-distance dependencies and global semantic meaning of a document. To overcome these problems, we propose a novel semantic-driven language modeling framework, which is a method to learn a Hierarchical Language Model and a Recurrent Conceptualization-enhanced Gamma Belief Network, simultaneously. For scalable inference, we develop the auto-encoding Variational Recurrent Inference, allowing efficient end-to-end training and simultaneously capturing global semantics from a text corpus. Especially, this article introduces concept information derived from high-quality lexical knowledge graph Probase, which leverages strong interpretability and anti-nose capability for the proposed model. Moreover, the proposed model captures not only intra-sentence word dependencies, but also temporal transitions between sentences and inter-sentence concept dependence. Experiments conducted on several NLP tasks validate the superiority of the proposed approach, which could effectively infer meaningful hierarchical concept structure of document and hierarchical multi-scale structures of sequences, even compared with latest state-of-the-art Transformer-based models.},
  archive      = {J_TKDD},
  doi          = {10.1145/3451167},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {5},
  number       = {6},
  pages        = {1-22},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Hierarchical concept-driven language model},
  volume       = {15},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Incremental community detection on large complex attributed
network. <em>TKDD</em>, <em>15</em>(6), 1–20. (<a
href="https://doi.org/10.1145/3451216">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Community detection on network data is a fundamental task, and has many applications in industry. Network data in industry can be very large, with incomplete and complex attributes, and more importantly, growing. This calls for a community detection technique that is able to handle both attribute and topological information on large scale networks, and also is incremental. In this article, we propose inc-AGGMMR, an incremental community detection framework that is able to effectively address the challenges that come from scalability, mixed attributes, incomplete values, and evolving of the network. Through construction of augmented graph, we map attributes into the network by introducing attribute centers and belongingness edges. The communities are then detected by modularity maximization. During this process, we adjust the weights of belongingness edges to balance the contribution between attribute and topological information to the detection of communities. The weight adjustment mechanism enables incremental updates of community membership of all vertices. We evaluate inc-AGGMMR on five benchmark datasets against eight strong baselines. We also provide a case study to incrementally detect communities on a PayPal payment network which contains users with transactions. The results demonstrate inc-AGGMMR’s effectiveness and practicability.},
  archive      = {J_TKDD},
  doi          = {10.1145/3451216},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {5},
  number       = {6},
  pages        = {1-20},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Incremental community detection on large complex attributed network},
  volume       = {15},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Online tensor-based learning model for structural damage
detection. <em>TKDD</em>, <em>15</em>(6), 1–18. (<a
href="https://doi.org/10.1145/3451217">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The online analysis of multi-way data stored in a tensor has become an essential tool for capturing the underlying structures and extracting the sensitive features that can be used to learn a predictive model. However, data distributions often evolve with time and a current predictive model may not be sufficiently representative in the future. Therefore, incrementally updating the tensor-based features and model coefficients are required in such situations. A new efficient tensor-based feature extraction, named Nesterov Stochastic Gradient Descent (NeSGD), is proposed for online (CP) decomposition. According to the new features obtained from the resultant matrices of NeSGD, a new criterion is triggered for the updated process of the online predictive model. Experimental evaluation in the field of structural health monitoring using laboratory-based and real-life structural datasets shows that our methods provide more accurate results compared with existing online tensor analysis and model learning. The results showed that the proposed methods significantly improved the classification error rates, were able to assimilate the changes in the positive data distribution over time, and maintained a high predictive accuracy in all case studies.},
  archive      = {J_TKDD},
  doi          = {10.1145/3451217},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {5},
  number       = {6},
  pages        = {1-18},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Online tensor-based learning model for structural damage detection},
  volume       = {15},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). On modeling influence maximization in social activity
networks under general settings. <em>TKDD</em>, <em>15</em>(6), 1–28.
(<a href="https://doi.org/10.1145/3451218">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Finding the set of most influential users in online social networks (OSNs) to trigger the largest influence cascade is meaningful, e.g., companies may leverage the “word-of-mouth” effect to trigger a large cascade of purchases by offering free samples/discounts to those most influential users. This task is usually modeled as an influence maximization problem, and it has been widely studied in the past decade. However, considering that users in OSNs may participate in various online activities, e.g., joining discussion groups and commenting on same pages or products, influence diffusion through online activities becomes even more significant. In this article, we study the impact of online activities by formulating social-activity networks which contain both users and online activities, and thus induce two types of weighted edges, i.e., edges between users and edges between users and activities. To address the computation challenge, we define an influence centrality via random walks, and use the Monte Carlo framework to efficiently estimate the centrality. Furthermore, we develop a greedy-based algorithm with novel optimizations to find the most influential users for node recommendation. Experiments on real-world datasets show that our approach is very computationally efficient under different influence models, and also achieves larger influence spread by considering online activities.},
  archive      = {J_TKDD},
  doi          = {10.1145/3451218},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {5},
  number       = {6},
  pages        = {1-28},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {On modeling influence maximization in social activity networks under general settings},
  volume       = {15},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Factor-bounded nonnegative matrix factorization.
<em>TKDD</em>, <em>15</em>(6), 1–18. (<a
href="https://doi.org/10.1145/3451395">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nonnegative Matrix Factorization (NMF) is broadly used to determine class membership in a variety of clustering applications. From movie recommendations and image clustering to visual feature extractions, NMF has applications to solve a large number of knowledge discovery and data mining problems. Traditional optimization methods, such as the Multiplicative Updating Algorithm (MUA), solves the NMF problem by utilizing an auxiliary function to ensure that the objective monotonically decreases. Although the objective in MUA converges, there exists no proof to show that the learned matrix factors converge as well. Without this rigorous analysis, the clustering performance and stability of the NMF algorithms cannot be guaranteed. To address this knowledge gap, in this article, we study the factor-bounded NMF problem and provide a solution algorithm with proven convergence by rigorous mathematical analysis, which ensures that both the objective and matrix factors converge. In addition, we show the relationship between MUA and our solution followed by an analysis of the convergence of MUA. Experiments on both toy data and real-world datasets validate the correctness of our proposed method and its utility as an effective clustering algorithm.},
  archive      = {J_TKDD},
  doi          = {10.1145/3451395},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {5},
  number       = {6},
  pages        = {1-18},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Factor-bounded nonnegative matrix factorization},
  volume       = {15},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). DeepDepict: Enabling information rich, personalized product
description generation with the deep multiple pointer generator network.
<em>TKDD</em>, <em>15</em>(5), 1–16. (<a
href="https://doi.org/10.1145/3446982">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In e-commerce platforms, the online descriptive information of products shows significant impacts on the purchase behaviors. To attract potential buyers for product promotion, numerous workers are employed to write the impressive product descriptions. The hand-crafted product descriptions are less-efficient with great labor costs and huge time consumption. Meanwhile, the generated product descriptions do not take consideration into the customization and the diversity to meet users’ interests. To address these problems, we propose one generic framework, namely DeepDepict, to automatically generate the information-rich and personalized product descriptive information. Specifically, DeepDepict leverages the graph attention to retrieve the product-related knowledge from external knowledge base to enrich the diversity of products, constructs the personalized lexicon to capture the linguistic traits of individuals for the personalization of product descriptions, and utilizes multiple pointer-generator network to fuse heterogeneous data from multi-sources to generate informative and personalized product descriptions. We conduct intensive experiments on one public dataset. The experimental results show that DeepDepict outperforms existing solutions in terms of description diversity, BLEU, and personalized degree with significant margin gain, and is able to generate product descriptions with comprehensive knowledge and personalized linguistic traits.},
  archive      = {J_TKDD},
  doi          = {10.1145/3446982},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {6},
  number       = {5},
  pages        = {1-16},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {DeepDepict: Enabling information rich, personalized product description generation with the deep multiple pointer generator network},
  volume       = {15},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Tiered sampling: An efficient method for counting sparse
motifs in massive graph streams. <em>TKDD</em>, <em>15</em>(5), 1–52.
(<a href="https://doi.org/10.1145/3441299">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce Tiered Sampling , a novel technique for estimating the count of sparse motifs in massive graphs whose edges are observed in a stream. Our technique requires only a single pass on the data and uses a memory of fixed size M , which can be magnitudes smaller than the number of edges. Our methods address the challenging task of counting sparse motifs—sub-graph patterns—that have a low probability of appearing in a sample of M edges in the graph, which is the maximum amount of data available to the algorithms in each step. To obtain an unbiased and low variance estimate of the count, we partition the available memory into tiers (layers) of reservoir samples. While the base layer is a standard reservoir sample of edges, other layers are reservoir samples of sub-structures of the desired motif. By storing more frequent sub-structures of the motif, we increase the probability of detecting an occurrence of the sparse motif we are counting, thus decreasing the variance and error of the estimate. While we focus on the designing and analysis of algorithms for counting 4-cliques, we present a method which allows generalizing Tiered Sampling to obtain high-quality estimates for the number of occurrence of any sub-graph of interest, while reducing the analysis effort due to specific properties of the pattern of interest. We present a complete analytical analysis and extensive experimental evaluation of our proposed method using both synthetic and real-world data. Our results demonstrate the advantage of our method in obtaining high-quality approximations for the number of 4 and 5-cliques for large graphs using a very limited amount of memory, significantly outperforming the single edge sample approach for counting sparse motifs in large scale graphs.},
  archive      = {J_TKDD},
  doi          = {10.1145/3441299},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {5},
  number       = {5},
  pages        = {1-52},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Tiered sampling: An efficient method for counting sparse motifs in massive graph streams},
  volume       = {15},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Improved customer lifetime value prediction with
sequence-to-sequence learning and feature-based models. <em>TKDD</em>,
<em>15</em>(5), 1–37. (<a
href="https://doi.org/10.1145/3441444">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The prediction of the Customer Lifetime Value (CLV) is an important asset for tool-supported marketing by customer relationship managers. Since standard methods based on purchase recency, frequency, and past profit and revenue statistics often have limited predictive power, advanced machine learning (ML) techniques were applied to this task in recent years. However, existing approaches are often not fully capable of modeling certain temporal patterns that can be commonly found in practice, such as periodic purchasing behavior of customers. To address these shortcomings, we propose a novel method for CLV prediction based on a combination of several ML techniques. At its core, our method consists of a tailored deep learning approach based on encoder–decoder sequence-to-sequence recurrent neural networks with augmented temporal convolutions. This model is then combined with gradient boosting machines (GBMs) and a set of novel features in a hybrid framework. Empirical evaluations based on real-world data from a larger e-commerce company and a public dataset from the domain of online retail show that already the sequence-based model leads to competitive performance results. Stacking it with the GBM model is synergistic and further improves accuracy, indicating that the two models capture different patterns in the data.},
  archive      = {J_TKDD},
  doi          = {10.1145/3441444},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {5},
  number       = {5},
  pages        = {1-37},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Improved customer lifetime value prediction with sequence-to-sequence learning and feature-based models},
  volume       = {15},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A survey on causal inference. <em>TKDD</em>, <em>15</em>(5),
1–46. (<a href="https://doi.org/10.1145/3444944">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Causal inference is a critical research topic across many domains, such as statistics, computer science, education, public policy, and economics, for decades. Nowadays, estimating causal effect from observational data has become an appealing research direction owing to the large amount of available data and low budget requirement, compared with randomized controlled trials. Embraced with the rapidly developed machine learning area, various causal effect estimation methods for observational data have sprung up. In this survey, we provide a comprehensive review of causal inference methods under the potential outcome framework, one of the well-known causal inference frameworks. The methods are divided into two categories depending on whether they require all three assumptions of the potential outcome framework or not. For each category, both the traditional statistical methods and the recent machine learning enhanced methods are discussed and compared. The plausible applications of these methods are also presented, including the applications in advertising, recommendation, medicine, and so on. Moreover, the commonly used benchmark datasets as well as the open-source codes are also summarized, which facilitate researchers and practitioners to explore, evaluate and apply the causal inference methods.},
  archive      = {J_TKDD},
  doi          = {10.1145/3444944},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {5},
  number       = {5},
  pages        = {1-46},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {A survey on causal inference},
  volume       = {15},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Optimal algebraic breadth-first search for sparse graphs.
<em>TKDD</em>, <em>15</em>(5), 1–19. (<a
href="https://doi.org/10.1145/3446216">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There has been a rise in the popularity of algebraic methods for graph algorithms given the development of the GraphBLAS library and other sparse matrix methods. An exemplar for these approaches is Breadth-First Search (BFS). The algebraic BFS algorithm is simply a recurrence of matrix-vector multiplications with the n × n adjacency matrix, but the many redundant operations over nonzeros ultimately lead to suboptimal performance. Therefore an optimal algebraic BFS should be of keen interest especially if it is easily integrated with existing matrix methods. Current methods, notably in the GraphBLAS, use a Sparse Matrix masked-Sparse Vector multiplication in which the input vector is kept in a sparse representation in each step of the BFS, and nonzeros in the vector are masked in subsequent steps. This has been an area of recent research in GraphBLAS and other libraries. While in theory, these masking methods are asymptotically optimal on sparse graphs, many add work that leads to suboptimal runtime. We give a new optimal, algebraic BFS for sparse graphs, thus closing a gap in the literature. Our method multiplies progressively smaller submatrices of the adjacency matrix at each step. Let n and m refer to the number of vertices and edges, respectively. On a sparse graph, our method takes O ( n ) algebraic operations as opposed to O ( m ) operations needed by theoretically optimal sparse matrix approaches. Thus, for sparse graphs, it matches the bounds of the best-known sequential algorithm, and on a Parallel Random Access Machine, it is work-optimal. Our result holds for both directed and undirected graphs. Compared to a leading GraphBLAS library, our method achieves up to 24x faster sequential time, and for parallel computation, it can be 17x faster on large graphs and 12x faster on large-diameter graphs.},
  archive      = {J_TKDD},
  doi          = {10.1145/3446216},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {5},
  number       = {5},
  pages        = {1-19},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Optimal algebraic breadth-first search for sparse graphs},
  volume       = {15},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Graph neural networks for fast node ranking approximation.
<em>TKDD</em>, <em>15</em>(5), 1–32. (<a
href="https://doi.org/10.1145/3446217">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graphs arise naturally in numerous situations, including social graphs, transportation graphs, web graphs, protein graphs, etc. One of the important problems in these settings is to identify which nodes are important in the graph and how they affect the graph structure as a whole. Betweenness centrality and closeness centrality are two commonly used node ranking measures to find out influential nodes in the graphs in terms of information spread and connectivity. Both of these are considered as shortest path based measures as the calculations require the assumption that the information flows between the nodes via the shortest paths. However, exact calculations of these centrality measures are computationally expensive and prohibitive, especially for large graphs. Although researchers have proposed approximation methods, they are either less efficient or suboptimal or both. We propose the first graph neural network (GNN) based model to approximate betweenness and closeness centrality. In GNN, each node aggregates features of the nodes in multihop neighborhood. We use this feature aggregation scheme to model paths and learn how many nodes are reachable to a specific node. We demonstrate that our approach significantly outperforms current techniques while taking less amount of time through extensive experiments on a series of synthetic and real-world datasets. A benefit of our approach is that the model is inductive, which means it can be trained on one set of graphs and evaluated on another set of graphs with varying structures. Thus, the model is useful for both static graphs and dynamic graphs. Source code is available at https://github.com/sunilkmaurya/GNN_Ranking},
  archive      = {J_TKDD},
  doi          = {10.1145/3446217},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {5},
  number       = {5},
  pages        = {1-32},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Graph neural networks for fast node ranking approximation},
  volume       = {15},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Density guarantee on finding multiple subgraphs and
subtensors. <em>TKDD</em>, <em>15</em>(5), 1–32. (<a
href="https://doi.org/10.1145/3446668">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dense subregion (subgraph &amp; subtensor) detection is a well-studied area, with a wide range of applications, and numerous efficient approaches and algorithms have been proposed. Approximation approaches are commonly used for detecting dense subregions due to the complexity of the exact methods. Existing algorithms are generally efficient for dense subtensor and subgraph detection, and can perform well in many applications. However, most of the existing works utilize the state-or-the-art greedy 2-approximation algorithm to capably provide solutions with a loose theoretical density guarantee. The main drawback of most of these algorithms is that they can estimate only one subtensor, or subgraph, at a time, with a low guarantee on its density. While some methods can, on the other hand, estimate multiple subtensors, they can give a guarantee on the density with respect to the input tensor for the first estimated subsensor only. We address these drawbacks by providing both theoretical and practical solution for estimating multiple dense subtensors in tensor data and giving a higher lower bound of the density. In particular, we guarantee and prove a higher bound of the lower-bound density of the estimated subgraph and subtensors. We also propose a novel approach to show that there are multiple dense subtensors with a guarantee on its density that is greater than the lower bound used in the state-of-the-art algorithms. We evaluate our approach with extensive experiments on several real-world datasets, which demonstrates its efficiency and feasibility.},
  archive      = {J_TKDD},
  doi          = {10.1145/3446668},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {5},
  number       = {5},
  pages        = {1-32},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Density guarantee on finding multiple subgraphs and subtensors},
  volume       = {15},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Utility mining across multi-dimensional sequences.
<em>TKDD</em>, <em>15</em>(5), 1–24. (<a
href="https://doi.org/10.1145/3446938">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge extraction from database is the fundamental task in database and data mining community, which has been applied to a wide range of real-world applications and situations. Different from the support-based mining models, the utility-oriented mining framework integrates the utility theory to provide more informative and useful patterns. Time-dependent sequence data are commonly seen in real life. Sequence data have been widely utilized in many applications, such as analyzing sequential user behavior on the Web, influence maximization, route planning, and targeted marketing. Unfortunately, all the existing algorithms lose sight of the fact that the processed data not only contain rich features (e.g., occur quantity, risk, and profit), but also may be associated with multi-dimensional auxiliary information, e.g., transaction sequence can be associated with purchaser profile information. In this article, we first formulate the problem of utility mining across multi-dimensional sequences, and propose a novel framework named MDUS to extract Multi-Dimensional Utility-oriented Sequential useful patterns. To the best of our knowledge, this is the first study that incorporates the time-dependent sequence-order, quantitative information, utility factor, and auxiliary dimension. Two algorithms respectively named MDUS EM and MDUS SD are presented to address the formulated problem. The former algorithm is based on database transformation, and the later one performs pattern joins and a searching method to identify desired patterns across multi-dimensional sequences. Extensive experiments are carried on six real-life datasets and one synthetic dataset to show that the proposed algorithms can effectively and efficiently discover the useful knowledge from multi-dimensional sequential databases. Moreover, the MDUS framework can provide better insight, and it is more adaptable to real-life situations than the current existing models.},
  archive      = {J_TKDD},
  doi          = {10.1145/3446938},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {5},
  number       = {5},
  pages        = {1-24},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Utility mining across multi-dimensional sequences},
  volume       = {15},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Sequential transform learning. <em>TKDD</em>,
<em>15</em>(5), 1–18. (<a
href="https://doi.org/10.1145/3447394">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work proposes a new approach for dynamical modeling; we call it sequential transform learning. This is loosely based on the transform (analysis dictionary) learning formulation. This is the first work on this topic. Transform learning, was originally developed for static problems; we modify it to model dynamical systems by introducing a feedback loop. The learnt transform coefficients for the t th instant are fed back along with the t + 1st sample, thereby establishing a Markovian relationship. Furthermore, the formulation is made supervised by the label consistency cost. Our approach keeps the best of two worlds, marrying the interpretability and uncertainty measure of signal processing with the function approximation ability of neural networks. We have carried out experiments on one of the most challenging problems in dynamical modeling - stock forecasting. Benchmarking with the state-of-the-art has shown that our method excels over the rest.},
  archive      = {J_TKDD},
  doi          = {10.1145/3447394},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {5},
  number       = {5},
  pages        = {1-18},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Sequential transform learning},
  volume       = {15},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Adaptive influence maximization: If influential node
unwilling to be the seed. <em>TKDD</em>, <em>15</em>(5), 1–23. (<a
href="https://doi.org/10.1145/3447396">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Influence maximization problem attempts to find a small subset of nodes that makes the expected influence spread maximized, which has been researched intensively before. They all assumed that each user in the seed set we select is activated successfully and then spread the influence. However, in the real scenario, not all users in the seed set are willing to be an influencer. Based on that, we consider each user associated with a probability with which we can activate her as a seed, and we can attempt to activate her many times. In this article, we study the adaptive influence maximization with multiple activations (Adaptive-IMMA) problem, where we select a node in each iteration, observe whether she accepts to be a seed, if yes, wait to observe the influence diffusion process; if no, we can attempt to activate her again with a higher cost or select another node as a seed. We model the multiple activations mathematically and define it on the domain of integer lattice. We propose a new concept, adaptive dr-submodularity, and show our Adaptive-IMMA is the problem that maximizing an adaptive monotone and dr-submodular function under the expected knapsack constraint. Adaptive dr-submodular maximization problem is never covered by any existing studies. Thus, we summarize its properties and study its approximability comprehensively, which is a non-trivial generalization of existing analysis about adaptive submodularity. Besides, to overcome the difficulty to estimate the expected influence spread, we combine our adaptive greedy policy with sampling techniques without losing the approximation ratio but reducing the time complexity. Finally, we conduct experiments on several real datasets to evaluate the effectiveness and efficiency of our proposed policies.},
  archive      = {J_TKDD},
  doi          = {10.1145/3447396},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {5},
  number       = {5},
  pages        = {1-23},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Adaptive influence maximization: If influential node unwilling to be the seed},
  volume       = {15},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Self-adaptive skeleton approaches to detect self-organized
coalitions from brain functional networks through probabilistic mixture
models. <em>TKDD</em>, <em>15</em>(5), 1–26. (<a
href="https://doi.org/10.1145/3447570">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Detecting self-organized coalitions from functional networks is one of the most important ways to uncover functional mechanisms in the brain. Determining these raises well-known technical challenges in terms of scale imbalance, outliers and hard-examples. In this article, we propose a novel self-adaptive skeleton approach to detect coalitions through an approximation method based on probabilistic mixture models. The nodes in the networks are characterized in terms of robust k -order complete subgraphs ( k -clique ) as essential substructures. The k -clique enumeration algorithm quickly enumerates all k -cliques in a parallel manner for a given network. Then, the cliques, from max -clique down to min -clique, of each order k , are hierarchically embedded into a probabilistic mixture model. They are self-adapted to the corresponding structure density of coalitions in the brain functional networks through different order k . All the cliques are merged and evolved into robust skeletons to sustain each unbalanced coalition by eliminating outliers and separating overlaps. We call this the k -CLIque Merging Evolution (CLIME) algorithm. The experimental results illustrate that the proposed approaches are robust to density variation and coalition mixture and can enable the effective detection of coalitions from real brain functional networks. There exist potential cognitive functional relations between the regions of interest in the coalitions revealed by our methods, which suggests the approach can be usefully applied in neuroscientific studies.},
  archive      = {J_TKDD},
  doi          = {10.1145/3447570},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {5},
  number       = {5},
  pages        = {1-26},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Self-adaptive skeleton approaches to detect self-organized coalitions from brain functional networks through probabilistic mixture models},
  volume       = {15},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Deep graph matching and searching for semantic code
retrieval. <em>TKDD</em>, <em>15</em>(5), 1–21. (<a
href="https://doi.org/10.1145/3447571">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Code retrieval is to find the code snippet from a large corpus of source code repositories that highly matches the query of natural language description. Recent work mainly uses natural language processing techniques to process both query texts (i.e., human natural language) and code snippets (i.e., machine programming language), however, neglecting the deep structured features of query texts and source codes, both of which contain rich semantic information. In this article, we propose an end-to-end deep graph matching and searching (DGMS) model based on graph neural networks for the task of semantic code retrieval. To this end, we first represent both natural language query texts and programming language code snippets with the unified graph-structured data, and then use the proposed graph matching and searching model to retrieve the best matching code snippet. In particular, DGMS not only captures more structural information for individual query texts or code snippets, but also learns the fine-grained similarity between them by cross-attention based semantic matching operations. We evaluate the proposed DGMS model on two public code retrieval datasets with two representative programming languages (i.e., Java and Python). Experiment results demonstrate that DGMS significantly outperforms state-of-the-art baseline models by a large margin on both datasets. Moreover, our extensive ablation studies systematically investigate and illustrate the impact of each part of DGMS.},
  archive      = {J_TKDD},
  doi          = {10.1145/3447571},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {5},
  number       = {5},
  pages        = {1-21},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Deep graph matching and searching for semantic code retrieval},
  volume       = {15},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Streaming social event detection and evolution discovery in
heterogeneous information networks. <em>TKDD</em>, <em>15</em>(5), 1–33.
(<a href="https://doi.org/10.1145/3447585">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Events are happening in real world and real time, which can be planned and organized for occasions, such as social gatherings, festival celebrations, influential meetings, or sports activities. Social media platforms generate a lot of real-time text information regarding public events with different topics. However, mining social events is challenging because events typically exhibit heterogeneous texture and metadata are often ambiguous. In this article, we first design a novel event-based meta-schema to characterize the semantic relatedness of social events and then build an event-based heterogeneous information network (HIN) integrating information from external knowledge base. Second, we propose a novel Pairwise Popularity Graph Convolutional Network, named as PP-GCN, based on weighted meta-path instance similarity and textual semantic representation as inputs, to perform fine-grained social event categorization and learn the optimal weights of meta-paths in different tasks. Third, we propose a streaming social event detection and evolution discovery framework for HINs based on meta-path similarity search, historical information about meta-paths, and heterogeneous DBSCAN clustering method. Comprehensive experiments on real-world streaming social text data are conducted to compare various social event detection and evolution discovery algorithms. Experimental results demonstrate that our proposed framework outperforms other alternative social event detection and evolution discovery techniques.},
  archive      = {J_TKDD},
  doi          = {10.1145/3447585},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {5},
  number       = {5},
  pages        = {1-33},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Streaming social event detection and evolution discovery in heterogeneous information networks},
  volume       = {15},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A method for mining granger causality relationship on
atmospheric visibility. <em>TKDD</em>, <em>15</em>(5), 1–16. (<a
href="https://doi.org/10.1145/3447681">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Atmospheric visibility is an indicator of atmospheric transparency and its range directly reflects the quality of the atmospheric environment. With the acceleration of industrialization and urbanization, the natural environment has suffered some damages. In recent decades, the level of atmospheric visibility shows an overall downward trend. A decrease in atmospheric visibility will lead to a higher frequency of haze, which will seriously affect people&#39;s normal life, and also have a significant negative economic impact. The causal relationship mining of atmospheric visibility can reveal the potential relation between visibility and other influencing factors, which is very important in environmental management, air pollution control and haze control. However, causality mining based on statistical methods and traditional machine learning techniques usually achieve qualitative results that are hard to measure the degree of causality accurately. This article proposed the seq2seq-LSTM Granger causality analysis method for mining the causality relationship between atmospheric visibility and its influencing factors. In the experimental part, by comparing with methods such as linear regression, random forest, gradient boosting decision tree, light gradient boosting machine, and extreme gradient boosting, it turns out that the visibility prediction accuracy based on the seq2seq-LSTM model is about 10% higher than traditional machine learning methods. Therefore, the causal relationship mining based on this method can deeply reveal the implicit relationship between them and provide theoretical support for air pollution control.},
  archive      = {J_TKDD},
  doi          = {10.1145/3447681},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {5},
  number       = {5},
  pages        = {1-16},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {A method for mining granger causality relationship on atmospheric visibility},
  volume       = {15},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Anomaly detection with kernel preserving embedding.
<em>TKDD</em>, <em>15</em>(5), 1–18. (<a
href="https://doi.org/10.1145/3447684">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Similarity representation plays a central role in increasingly popular anomaly detection techniques, which have been successfully applied in various realistic scenes. Until now, many low-rank representation techniques have been introduced to measure the similarity relations of data; yet, they only concern to minimize reconstruction errors, without involving the structural information of data. Besides, the traditional low-rank representation methods often take nuclear norm as their low-rank constraints, easily yielding a suboptimal solution. To address the problems above, in this article, we propose a novel anomaly detection method, which exploits kernel preserving embedding, as well as the double nuclear norm, to explore the similarity relations of data. Based on the similarity relations, a kind of probability transition matrix is derived, and a tailored random walk is further adopted to reveal anomalies. The proposed method can not only preserve the manifold structural properties of the data, but also alleviate the suboptimal problem. To validate the superiority of our method, extensive experiments with eight popular anomaly detection algorithms were conducted on 12 widely used datasets. The experimental results show that our detection method outperformed the state-of-the-art anomaly detection algorithms in most cases.},
  archive      = {J_TKDD},
  doi          = {10.1145/3447684},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {5},
  number       = {5},
  pages        = {1-18},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Anomaly detection with kernel preserving embedding},
  volume       = {15},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Critique on natural noise in recommender systems.
<em>TKDD</em>, <em>15</em>(5), 1–30. (<a
href="https://doi.org/10.1145/3447780">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommender systems have been upgraded, tested, and applied in many, often incomparable ways. In attempts to diligently understand user behavior in certain environments, those systems have been frequently utilized in domains like e-commerce, e-learning, and tourism. Their increasing need and popularity have allowed the existence of numerous research paths on major issues like data sparsity, cold start, malicious noise, and natural noise, which immensely limit their performance. It is typical that the quality of the data that fuel those systems should be extremely reliable. Inconsistent user information in datasets can alter the performance of recommenders, albeit running advanced personalizing algorithms. The consequences of this can be costly as such systems are employed in abundant online businesses. Successfully managing these inconsistencies results in more personalized user experiences. In this article, the previous works conducted on natural noise management in recommender datasets are thoroughly analyzed. We adequately explore the ways in which the proposed methods measure improved performances and touch on the different natural noise management techniques and the attributes of the solutions. Additionally, we test the evaluation methods employed to assess the approaches and discuss several key gaps and other improvements the field should realize in the future. Our work considers the likelihood of a modern research branch on natural noise management and recommender assessment.},
  archive      = {J_TKDD},
  doi          = {10.1145/3447780},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {5},
  number       = {5},
  pages        = {1-30},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Critique on natural noise in recommender systems},
  volume       = {15},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Exploring BCI control in smart environments: Intention
recognition via EEG representation enhancement learning. <em>TKDD</em>,
<em>15</em>(5), 1–20. (<a
href="https://doi.org/10.1145/3450449">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The brain–computer interface (BCI) control technology that utilizes motor imagery to perform the desired action instead of manual operation will be widely used in smart environments. However, most of the research lacks robust feature representation of multi-channel EEG series, resulting in low intention recognition accuracy. This article proposes an EEG2Image based Denoised-ConvNets (called EID) to enhance feature representation of the intention recognition task. Specifically, we perform signal decomposition, slicing, and image mapping to decrease the noise from the irrelevant frequency bands. After that, we construct the Denoised-ConvNets structure to learn the colorspace and spatial variations of image objects without cropping new training images precisely. Toward further utilizing the color and spatial transformation layers, the colorspace and colored area of image objects have been enhanced and enlarged, respectively. In the multi-classification scenario, extensive experiments on publicly available EEG datasets confirm that the proposed method has better performance than state-of-the-art methods.},
  archive      = {J_TKDD},
  doi          = {10.1145/3450449},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {5},
  number       = {5},
  pages        = {1-20},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Exploring BCI control in smart environments: Intention recognition via EEG representation enhancement learning},
  volume       = {15},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Mining largest maximal quasi-cliques. <em>TKDD</em>,
<em>15</em>(5), 1–21. (<a
href="https://doi.org/10.1145/3446637">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quasi-cliques are dense incomplete subgraphs of a graph that generalize the notion of cliques. Enumerating quasi-cliques from a graph is a robust way to detect densely connected structures with applications in bioinformatics and social network analysis. However, enumerating quasi-cliques in a graph is a challenging problem, even harder than the problem of enumerating cliques. We consider the enumeration of top- k degree-based quasi-cliques and make the following contributions: (1) we show that even the problem of detecting whether a given quasi-clique is maximal (i.e., not contained within another quasi-clique) is NP-hard. (2) We present a novel heuristic algorithm K ernel QC to enumerate the k largest quasi-cliques in a graph. Our method is based on identifying kernels of extremely dense subgraphs within a graph, followed by growing subgraphs around these kernels, to arrive at quasi-cliques with the required densities. (3) Experimental results show that our algorithm accurately enumerates quasi-cliques from a graph, is much faster than current state-of-the-art methods for quasi-clique enumeration (often more than three orders of magnitude faster), and can scale to larger graphs than current methods.},
  archive      = {J_TKDD},
  doi          = {10.1145/3446637},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {4},
  number       = {5},
  pages        = {1-21},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Mining largest maximal quasi-cliques},
  volume       = {15},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Dual-embedding based deep latent factor models for
recommendation. <em>TKDD</em>, <em>15</em>(5), 1–24. (<a
href="https://doi.org/10.1145/3447395">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Among various recommendation methods, latent factor models are usually considered to be state-of-the-art techniques, which aim to learn user and item embeddings for predicting user-item preferences. When applying latent factor models to the recommendation with implicit feedback, the quality of embeddings always suffers from inadequate positive feedback and noisy negative feedback. Inspired by the idea of NSVD that represents users based on their interacted items, this article proposes a dual-embedding based deep latent factor method for recommendation with implicit feedback. In addition to learning a primitive embedding for a user (resp. item), we represent each user (resp. item) with an additional embedding from the perspective of the interacted items (resp. users) and propose attentive neural methods to discriminate the importance of interacted users/items for dual-embedding learning. We design two dual-embedding based deep latent factor models, DELF and DESEQ, for pure collaborative filtering and temporal collaborative filtering (i.e., sequential recommendation), respectively. The novel attempt of the proposed models is to capture each user-item interaction with four deep representations that are subtly fused for preference prediction. We conducted extensive experiments on four real-world datasets. The results verify the effectiveness of user/item dual embeddings and the superior performance of our methods on item recommendation.},
  archive      = {J_TKDD},
  doi          = {10.1145/3447395},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {4},
  number       = {5},
  pages        = {1-24},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Dual-embedding based deep latent factor models for recommendation},
  volume       = {15},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Robust image representation via low rank locality preserving
projection. <em>TKDD</em>, <em>15</em>(4), 1–22. (<a
href="https://doi.org/10.1145/3434768">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Locality preserving projection (LPP) is a dimensionality reduction algorithm preserving the neighhorhood graph structure of data. However, the conventional LPP is sensitive to outliers existing in data. This article proposes a novel low-rank LPP model called LR-LPP. In this new model, original data are decomposed into the clean intrinsic component and noise component. Then the projective matrix is learned based on the clean intrinsic component which is encoded in low-rank features. The noise component is constrained by the ℓ 1 -norm which is more robust to outliers. Finally, LR-LPP model is extended to LR-FLPP in which low-dimensional feature is measured by F-norm. LR-FLPP will reduce aggregated error and weaken the effect of outliers, which will make the proposed LR-FLPP even more robust for outliers. The experimental results on public image databases demonstrate the effectiveness of the proposed LR-LPP and LR-FLPP.},
  archive      = {J_TKDD},
  doi          = {10.1145/3434768},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {6},
  number       = {4},
  pages        = {1-22},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Robust image representation via low rank locality preserving projection},
  volume       = {15},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Side information fusion for recommender systems over
heterogeneous information network. <em>TKDD</em>, <em>15</em>(4), 1–32.
(<a href="https://doi.org/10.1145/3441446">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Collaborative filtering (CF) has been one of the most important and popular recommendation methods, which aims at predicting users’ preferences (ratings) based on their past behaviors. Recently, various types of side information beyond the explicit ratings users give to items, such as social connections among users and metadata of items, have been introduced into CF and shown to be useful for improving recommendation performance. However, previous works process different types of information separately, thus failing to capture the correlations that might exist across them. To address this problem, in this work, we study the application of heterogeneous information network (HIN), which offers a unifying and flexible representation of different types of side information, to enhance CF-based recommendation methods. However, we face challenging issues in HIN-based recommendation, i.e., how to capture similarities of complex semantics between users and items in a HIN, and how to effectively fuse these similarities to improve final recommendation performance. To address these issues, we apply metagraph to similarity computation and solve the information fusion problem with a “matrix factorization (MF) + factorization machine (FM)” framework. For the MF part, we obtain the user-item similarity matrix from each metagraph and then apply low-rank matrix approximation to obtain latent features for both users and items. For the FM part, we apply FM with Group lasso (FMG) on the features obtained from the MF part to train the recommending model and, at the same time, identify the useful metagraphs. Besides FMG, a two-stage method, we further propose an end-to-end method, hierarchical attention fusing, to fuse metagraph-based similarities for the final recommendation. Experimental results on four large real-world datasets show that the two proposed frameworks significantly outperform existing state-of-the-art methods in terms of recommendation performance.},
  archive      = {J_TKDD},
  doi          = {10.1145/3441446},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {6},
  number       = {4},
  pages        = {1-32},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Side information fusion for recommender systems over heterogeneous information network},
  volume       = {15},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Clustering heterogeneous information network by joint graph
embedding and nonnegative matrix factorization. <em>TKDD</em>,
<em>15</em>(4), 1–25. (<a
href="https://doi.org/10.1145/3441449">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many complex systems derived from nature and society consist of multiple types of entities and heterogeneous interactions, which can be effectively modeled as heterogeneous information network (HIN). Structural analysis of heterogeneous networks is of great significance by leveraging the rich semantic information of objects and links in the heterogeneous networks. And, clustering heterogeneous networks aims to group vertices into classes, which sheds light on revealing the structure–function relations of the underlying systems. The current algorithms independently perform the feature extraction and clustering, which are criticized for not fully characterizing the structure of clusters. In this study, we propose a learning model by joint Graph Embedding and Nonnegative Matrix Factorization (aka GEjNMF ), where feature extraction and clustering are simultaneously learned by exploiting the graph embedding and latent structure of networks. We formulate the objective function of GEjNMF and transform the heterogeneous network clustering problem into a constrained optimization problem, which is effectively solved by l 0 -norm optimization. The advantage of GEjNMF is that features are selected under the guidance of clustering, which improves the performance and saves the running time of algorithms at the same time. The experimental results on three benchmark heterogeneous networks demonstrate that GEjNMF achieves the best performance with the least running time compared with the best state-of-the-art methods. Furthermore, the proposed algorithm is robust across heterogeneous networks from various fields. The proposed model and method provide an effective alternative for heterogeneous network clustering.},
  archive      = {J_TKDD},
  doi          = {10.1145/3441449},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {6},
  number       = {4},
  pages        = {1-25},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Clustering heterogeneous information network by joint graph embedding and nonnegative matrix factorization},
  volume       = {15},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Network embedding on hierarchical community structure
network. <em>TKDD</em>, <em>15</em>(4), 1–23. (<a
href="https://doi.org/10.1145/3434747">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Network embedding is a method of learning a low-dimensional vector representation of network vertices under the condition of preserving different types of network properties. Previous studies mainly focus on preserving structural information of vertices at a particular scale, like neighbor information or community information, but cannot preserve the hierarchical community structure, which would enable the network to be easily analyzed at various scales. Inspired by the hierarchical structure of galaxies, we propose the Galaxy Network Embedding (GNE) model, which formulates an optimization problem with spherical constraints to describe the hierarchical community structure preserving network embedding. More specifically, we present an approach of embedding communities into a low-dimensional spherical surface, the center of which represents the parent community they belong to. Our experiments reveal that the representations from GNE preserve the hierarchical community structure and show advantages in several applications such as vertex multi-class classification, network visualization, and link prediction. The source code of GNE is available online.},
  archive      = {J_TKDD},
  doi          = {10.1145/3434747},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {5},
  number       = {4},
  pages        = {1-23},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Network embedding on hierarchical community structure network},
  volume       = {15},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Search efficient binary network embedding. <em>TKDD</em>,
<em>15</em>(4), 1–27. (<a
href="https://doi.org/10.1145/3436892">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional network embedding primarily focuses on learning a continuous vector representation for each node, preserving network structure and/or node content information, such that off-the-shelf machine learning algorithms can be easily applied to the vector-format node representations for network analysis. However, the learned continuous vector representations are inefficient for large-scale similarity search, which often involves finding nearest neighbors measured by distance or similarity in a continuous vector space. In this article, we propose a search efficient binary network embedding algorithm called BinaryNE to learn a binary code for each node, by simultaneously modeling node context relations and node attribute relations through a three-layer neural network. BinaryNE learns binary node representations using a stochastic gradient descent-based online learning algorithm. The learned binary encoding not only reduces memory usage to represent each node, but also allows fast bit-wise comparisons to support faster node similarity search than using Euclidean or other distance measures. Extensive experiments and comparisons demonstrate that BinaryNE not only delivers more than 25 times faster search speed, but also provides comparable or better search quality than traditional continuous vector based network embedding methods. The binary codes learned by BinaryNE also render competitive performance on node classification and node clustering tasks. The source code of the BinaryNE algorithm is available at https://github.com/daokunzhang/BinaryNE.},
  archive      = {J_TKDD},
  doi          = {10.1145/3436892},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {5},
  number       = {4},
  pages        = {1-27},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Search efficient binary network embedding},
  volume       = {15},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Variable-lag granger causality and transfer entropy for time
series analysis. <em>TKDD</em>, <em>15</em>(4), 1–30. (<a
href="https://doi.org/10.1145/3441452">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Granger causality is a fundamental technique for causal inference in time series data, commonly used in the social and biological sciences. Typical operationalizations of Granger causality make a strong assumption that every time point of the effect time series is influenced by a combination of other time series with a fixed time delay. The assumption of fixed time delay also exists in Transfer Entropy, which is considered to be a non-linear version of Granger causality. However, the assumption of the fixed time delay does not hold in many applications, such as collective behavior, financial markets, and many natural phenomena. To address this issue, we develop Variable-lag Granger causality and Variable-lag Transfer Entropy, generalizations of both Granger causality and Transfer Entropy that relax the assumption of the fixed time delay and allow causes to influence effects with arbitrary time delays. In addition, we propose methods for inferring both Variable-lag Granger causality and Transfer Entropy relations. In our approaches, we utilize an optimal warping path of Dynamic Time Warping to infer variable-lag causal relations. We demonstrate our approaches on an application for studying coordinated collective behavior and other real-world casual-inference datasets and show that our proposed approaches perform better than several existing methods in both simulated and real-world datasets. Our approaches can be applied in any domain of time series analysis. The software of this work is available in the R-CRAN package: VLTimeCausality.},
  archive      = {J_TKDD},
  doi          = {10.1145/3441452},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {5},
  number       = {4},
  pages        = {1-30},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Variable-lag granger causality and transfer entropy for time series analysis},
  volume       = {15},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A unified view of causal and non-causal feature selection.
<em>TKDD</em>, <em>15</em>(4), 1–46. (<a
href="https://doi.org/10.1145/3436891">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we aim to develop a unified view of causal and non-causal feature selection methods. The unified view will fill in the gap in the research of the relation between the two types of methods. Based on the Bayesian network framework and information theory, we first show that causal and non-causal feature selection methods share the same objective. That is to find the Markov blanket of a class attribute, the theoretically optimal feature set for classification. We then examine the assumptions made by causal and non-causal feature selection methods when searching for the optimal feature set, and unify the assumptions by mapping them to the restrictions on the structure of the Bayesian network model of the studied problem. We further analyze in detail how the structural assumptions lead to the different levels of approximations employed by the methods in their search, which then result in the approximations in the feature sets found by the methods with respect to the optimal feature set. With the unified view, we can interpret the output of non-causal methods from a causal perspective and derive the error bounds of both types of methods. Finally, we present practical understanding of the relation between causal and non-causal methods using extensive experiments with synthetic data and various types of real-world data.},
  archive      = {J_TKDD},
  doi          = {10.1145/3436891},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {4},
  number       = {4},
  pages        = {1-46},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {A unified view of causal and non-causal feature selection},
  volume       = {15},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Attribute-guided network sampling mechanisms. <em>TKDD</em>,
<em>15</em>(4), 1–24. (<a
href="https://doi.org/10.1145/3441445">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article introduces a novel task-independent sampler for attributed networks. The problem is important because while data mining tasks on network content are common, sampling on internet-scale networks is costly. Link-trace samplers such as Snowball sampling, Forest Fire, Random Walk, and Metropolis–Hastings Random Walk are widely used for sampling from networks. The design of these attribute-agnostic samplers focuses on preserving salient properties of network structure, and are not optimized for tasks on node content. This article has three contributions. First, we propose a task-independent, attribute aware link-trace sampler grounded in Information Theory. Our sampler greedily adds to the sample the node with the most informative (i.e., surprising) neighborhood. The sampler tends to rapidly explore the attribute space, maximally reducing the surprise of unseen nodes. Second, we prove that content sampling is an NP-hard problem. A well-known algorithm best approximates the optimization solution within 1 − 1/ e , but requires full access to the entire graph. Third, we show through empirical counterfactual analysis that in many real-world datasets, network structure does not hinder the performance of surprise based link-trace samplers. Experimental results over 18 real-world datasets reveal: surprise-based samplers are sample efficient and outperform the state-of-the-art attribute-agnostic samplers by a wide margin (e.g., 45% performance improvement in clustering tasks).},
  archive      = {J_TKDD},
  doi          = {10.1145/3441445},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {4},
  number       = {4},
  pages        = {1-24},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Attribute-guided network sampling mechanisms},
  volume       = {15},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Exploiting temporal dynamics in product reviews for dynamic
sentiment prediction at the aspect level. <em>TKDD</em>, <em>15</em>(4),
1–29. (<a href="https://doi.org/10.1145/3441451">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Online reviews and ratings play an important role in shaping the purchase decisions of customers in e-commerce. Many researches have been done to make proper recommendations for users, by exploiting reviews, ratings, user profiles, or behaviors. However, the dynamic evolution of user preferences and item properties haven’t been fully exploited. Moreover, it lacks fine-grained studies at the aspect level. To address the above issues, we define two concepts of user maturity and item popularity, to better explore the dynamic changes for users and items. We strive to exploit fine-grained information at the aspect level and the evolution of users and items, for dynamic sentiment prediction. First, we analyze three real datasets from both the overall level and the aspect level, to discover the dynamic changes (i.e., gradual changes and sudden changes) in user aspect preferences and item aspect properties. Next, we propose a novel model of Aspect-based Sentiment Dynamic Prediction (ASDP), to dynamically capture and exploit the change patterns with uniform time intervals. We further propose the improved model ASDP+ with a bin segmentation algorithm to set the time intervals non-uniformly based on the sudden changes. Experimental results on three real-world datasets show that our work leads to significant improvements.},
  archive      = {J_TKDD},
  doi          = {10.1145/3441451},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {4},
  number       = {4},
  pages        = {1-29},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Exploiting temporal dynamics in product reviews for dynamic sentiment prediction at the aspect level},
  volume       = {15},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Benchmarking unsupervised outlier detection with realistic
synthetic data. <em>TKDD</em>, <em>15</em>(4), 1–20. (<a
href="https://doi.org/10.1145/3441453">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Benchmarking unsupervised outlier detection is difficult. Outliers are rare, and existing benchmark data contains outliers with various and unknown characteristics. Fully synthetic data usually consists of outliers and regular instances with clear characteristics and thus allows for a more meaningful evaluation of detection methods in principle. Nonetheless, there have only been few attempts to include synthetic data in benchmarks for outlier detection. This might be due to the imprecise notion of outliers or to the difficulty to arrive at a good coverage of different domains with synthetic data. In this work, we propose a generic process for the generation of datasets for such benchmarking. The core idea is to reconstruct regular instances from existing real-world benchmark data while generating outliers so that they exhibit insightful characteristics. We propose and describe a generic process for the benchmarking of unsupervised outlier detection, as sketched so far. We then describe three instantiations of this generic process that generate outliers with specific characteristics, like local outliers. To validate our process, we perform a benchmark with state-of-the-art detection methods and carry out experiments to study the quality of data reconstructed in this way. Next to showcasing the workflow, this confirms the usefulness of our proposed process. In particular, our process yields regular instances close to the ones from real data. Summing up, we propose and validate a new and practical process for the benchmarking of unsupervised outlier detection.},
  archive      = {J_TKDD},
  doi          = {10.1145/3441453},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {4},
  number       = {4},
  pages        = {1-20},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Benchmarking unsupervised outlier detection with realistic synthetic data},
  volume       = {15},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Attributed network embedding with micro-meso structure.
<em>TKDD</em>, <em>15</em>(4), 1–26. (<a
href="https://doi.org/10.1145/3441486">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, network embedding has received a large amount of attention in network analysis. Although some network embedding methods have been developed from different perspectives, on one hand, most of the existing methods only focus on leveraging the plain network structure, ignoring the abundant attribute information of nodes. On the other hand, for some methods integrating the attribute information, only the lower-order proximities (e.g., microscopic proximity structure) are taken into account, which may suffer if there exists the sparsity issue and the attribute information is noisy. To overcome this problem, the attribute information and mesoscopic community structure are utilized. In this article, we propose a novel network embedding method termed Attributed Network Embedding with Micro-Meso structure, which is capable of preserving both the attribute information and the structural information including the microscopic proximity structure and mesoscopic community structure. In particular, both the microscopic proximity structure and node attributes are factorized by Nonnegative Matrix Factorization (NMF), from which the low-dimensional node representations can be obtained. For the mesoscopic community structure, a community membership strength matrix is inferred by a generative model (i.e., BigCLAM) or modularity from the linkage structure, which is then factorized by NMF to obtain the low-dimensional node representations. The three components are jointly correlated by the low-dimensional node representations, from which two objective functions (i.e., ANEM_B and ANEM_M) can be defined. Two efficient alternating optimization schemes are proposed to solve the optimization problems. Extensive experiments have been conducted to confirm the superior performance of the proposed models over the state-of-the-art network embedding methods.},
  archive      = {J_TKDD},
  doi          = {10.1145/3441486},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {4},
  number       = {4},
  pages        = {1-26},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Attributed network embedding with micro-meso structure},
  volume       = {15},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). SAKE: Estimating katz centrality based on sampling for
large-scale social networks. <em>TKDD</em>, <em>15</em>(4), 1–21. (<a
href="https://doi.org/10.1145/3441646">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Katz centrality is a fundamental concept to measure the influence of a vertex in a social network. However, existing approaches to calculating Katz centrality in a large-scale network are unpractical and computationally expensive. In this article, we propose a novel method to estimate Katz centrality based on graph sampling techniques, which object to achieve comparable estimation accuracy of the state-of-the-arts with much lower computational complexity. Specifically, we develop a Horvitz–Thompson estimate for Katz centrality by using a multi-round sampling approach and deriving an unbiased mean value estimator. We further propose SAKE , a S ampling-based A lgorithm for fast K atz centrality E stimation. We prove that the estimator calculated by SAKE is probabilistically guaranteed to be within an additive error from the exact value. Extensive evaluation experiments based on four real-world networks show that the proposed algorithm can estimate Katz centralities for partial vertices with low sampling rate, low computation time, and it works well in identifying high influence vertices in social networks.},
  archive      = {J_TKDD},
  doi          = {10.1145/3441646},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {4},
  number       = {4},
  pages        = {1-21},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {SAKE: Estimating katz centrality based on sampling for large-scale social networks},
  volume       = {15},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Mobile app cross-domain recommendation with multi-graph
neural network. <em>TKDD</em>, <em>15</em>(4), 1–21. (<a
href="https://doi.org/10.1145/3442201">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of mobile app ecosystem, mobile apps have grown greatly popular. The explosive growth of apps makes it difficult for users to find apps that meet their interests. Therefore, it is necessary to recommend user with a personalized set of apps. However, one of the challenges is data sparsity, as users’ historical behavior data are usually insufficient. In fact, user’s behaviors from different domains in app store regarding the same apps are usually relevant. Therefore, we can alleviate the sparsity using complementary information from correlated domains. It is intuitive to model users’ behaviors using graph, and graph neural networks have shown the great power for representation learning. In this article, we propose a novel model, Deep Multi-Graph Embedding (DMGE), to learn cross-domain app embedding. Specifically, we first construct a multi-graph based on users’ behaviors from different domains, and then propose a multi-graph neural network to learn cross-domain app embedding. Particularly, we present an adaptive method to balance the weight of each domain and efficiently train the model. Finally, we achieve cross-domain app recommendation based on the learned app embedding. Extensive experiments on real-world datasets show that DMGE outperforms other state-of-art embedding methods.},
  archive      = {J_TKDD},
  doi          = {10.1145/3442201},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {4},
  number       = {4},
  pages        = {1-21},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Mobile app cross-domain recommendation with multi-graph neural network},
  volume       = {15},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Online sampling of temporal networks. <em>TKDD</em>,
<em>15</em>(4), 1–27. (<a
href="https://doi.org/10.1145/3442202">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Temporal networks representing a stream of timestamped edges are seemingly ubiquitous in the real world. However, the massive size and continuous nature of these networks make them fundamentally challenging to analyze and leverage for descriptive and predictive modeling tasks. In this work, we propose a general framework for temporal network sampling with unbiased estimation. We develop online, single-pass sampling algorithms, and unbiased estimators for temporal network sampling. The proposed algorithms enable fast, accurate, and memory-efficient statistical estimation of temporal network patterns and properties. In addition, we propose a temporally decaying sampling algorithm with unbiased estimators for studying networks that evolve in continuous time, where the strength of links is a function of time, and the motif patterns are temporally weighted. In contrast to the prior notion of a △ t -temporal motif, the proposed formulation and algorithms for counting temporally weighted motifs are useful for forecasting tasks in networks such as predicting future links, or a future time-series variable of nodes and links. Finally, extensive experiments on a variety of temporal networks from different domains demonstrate the effectiveness of the proposed algorithms. A detailed ablation study is provided to understand the impact of the various components of the proposed framework.},
  archive      = {J_TKDD},
  doi          = {10.1145/3442202},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {4},
  number       = {4},
  pages        = {1-27},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Online sampling of temporal networks},
  volume       = {15},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Jointly modeling spatio–temporal dependencies and daily flow
correlations for crowd flow prediction. <em>TKDD</em>, <em>15</em>(4),
1–20. (<a href="https://doi.org/10.1145/3439346">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Crowd flow prediction is a vital problem for an intelligent transportation system construction in a smart city. It plays a crucial role in traffic management and behavioral analysis, thus it has raised great attention from many researchers. However, predicting crowd flows timely and accurately is a challenging task that is affected by many complex factors such as the dependencies of adjacent regions or recent crowd flows. Existing models mainly focus on capturing such dependencies in spatial or temporal domains and fail to model relations between crowd flows of distant regions. We notice that each region has a relatively fixed daily flow and some regions (even very far away from each other) may share similar flow patterns which show strong correlations among them. In this article, we propose a novel model named Double-Encoder which follows a general encoder–decoder framework for multi-step citywide crowd flow prediction. The model consists of two encoder modules named ST-Encoder and FR-Encoder to model spatial-temporal dependencies and daily flow correlations, respectively. We conduct extensive experiments on two real-world datasets to evaluate the performance of the proposed model and show that our model consistently outperforms state-of-the-art methods.},
  archive      = {J_TKDD},
  doi          = {10.1145/3439346},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {3},
  number       = {4},
  pages        = {1-20},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Jointly modeling Spatio–Temporal dependencies and daily flow correlations for crowd flow prediction},
  volume       = {15},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A layout-based classification method for visualizing
time-varying graphs. <em>TKDD</em>, <em>15</em>(4), 1–24. (<a
href="https://doi.org/10.1145/3441301">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Connectivity analysis between the components of large evolving systems can reveal significant patterns of interaction. The systems can be simulated by topological graph structures. However, such analysis becomes challenging on large and complex graphs. Tasks such as comparing, searching, and summarizing structures, are difficult due to the enormous number of calculations required. For time-varying graphs, the temporal dimension even intensifies the difficulty. In this article, we propose to reduce the complexity of analysis by focusing on subgraphs that are induced by closely related entities. To summarize the diverse structures of subgraphs, we build a supervised layout-based classification model. The main premise is that the graph structures can induce a unique appearance of the layout. In contrast to traditional graph theory-based and contemporary neural network-based methods of graph classification, our approach generates low costs and there is no need to learn informative graph representations. Combined with temporally stable visualizations, we can also facilitate the understanding of sub-structures and the tracking of graph evolution. The method is evaluated on two real-world datasets. The results show that our system is highly effective in carrying out visual-based analytics of large graphs.},
  archive      = {J_TKDD},
  doi          = {10.1145/3441301},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {3},
  number       = {4},
  pages        = {1-24},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {A layout-based classification method for visualizing time-varying graphs},
  volume       = {15},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). User embedding for expert finding in community question
answering. <em>TKDD</em>, <em>15</em>(4), 1–16. (<a
href="https://doi.org/10.1145/3441302">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The number of users who have the appropriate knowledge to answer asked questions in community question answering is lower than those who ask questions. Therefore, finding expert users who can answer the questions is very crucial and useful. In this article, we propose a framework to find experts for given questions and assign them the related questions. The proposed model benefits from users’ relations in a community along with the lexical and semantic similarities between new question and existing answers. Node embedding is applied to the community graph to find similar users. Our experiments on four different Stack Exchange datasets show that adding community relations improves the performance of expert finding models.},
  archive      = {J_TKDD},
  doi          = {10.1145/3441302},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {3},
  number       = {4},
  pages        = {1-16},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {User embedding for expert finding in community question answering},
  volume       = {15},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A stochastic algorithm based on reverse sampling technique
to fight against the cyberbullying. <em>TKDD</em>, <em>15</em>(4), 1–22.
(<a href="https://doi.org/10.1145/3441455">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cyberbullying has caused serious consequences especially for social network users in recent years. However, the challenge is how to fight against the cyberbullying effectively from the algorithmic perspective. In this article, we study the fighting against the cyberbullying problem, i.e., identify an initial witness set with a budget to spread the positive influence to protect the users in a specific target set such that the number of cybervictim users in the target set being activated by the seed set of cyberbullying is minimized. We first formulate this problem and show its NP-hardness. We further prove that the objective function is submodular with respect to the size of witnesses set when we convert the original problem into the maximal version. Then we propose a stochastic approach to solve this maximal version problem based on the Reverse Sampling Technique with a constant factor guarantee. In addition, we provide theoretical analysis and discuss the relationship between the optimal value and the value returned by the proposed algorithm. To evaluate the proposed approach, we implement extensive experiments on synthetic and real datasets. The experimental results show our approach is superior to the comparison methods.},
  archive      = {J_TKDD},
  doi          = {10.1145/3441455},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {3},
  number       = {4},
  pages        = {1-22},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {A stochastic algorithm based on reverse sampling technique to fight against the cyberbullying},
  volume       = {15},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Elastic embedding through graph convolution-based regression
for semi-supervised classification. <em>TKDD</em>, <em>15</em>(4), 1–11.
(<a href="https://doi.org/10.1145/3441456">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article introduces a scheme for semi-supervised learning by estimating a flexible non-linear data representation that exploits Spectral Graph Convolutions structure. Structured data are exploited in order to determine non-linear and linear models. The introduced scheme takes advantage of data-driven graphs at two levels. First, it incorporates manifold smoothness that is naturally encoded by the graph itself. Second, the regression model is built on the convolved data samples that are derived from the data and their associated graph. The proposed semi-supervised embedding can tackle the problem of over-fitting on neighborhood structures for image data. The proposed Graph Convolution-based Semi-supervised Embedding paves the way to new theoretical and application perspectives related to the non-linear embedding. Indeed, building flexible models that adopt convolved data samples can enhance both the data representation and the final performance of the learning system. Several experiments are conducted on six image datasets for comparing the introduced scheme with some state-of-the-art semi-supervised approaches. This empirical evaluation shows the effectiveness of the proposed embedding scheme.},
  archive      = {J_TKDD},
  doi          = {10.1145/3441456},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {3},
  number       = {4},
  pages        = {1-11},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Elastic embedding through graph convolution-based regression for semi-supervised classification},
  volume       = {15},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). 3E-LDA: Three enhancements to linear discriminant analysis.
<em>TKDD</em>, <em>15</em>(4), 1–20. (<a
href="https://doi.org/10.1145/3442347">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Linear discriminant analysis (LDA) is one of the important techniques for dimensionality reduction, machine learning, and pattern recognition. However, in many applications, applying the classical LDA often faces the following problems: (1) sensitivity to outliers, (2) absence of local geometric information, and (3) small sample size or matrix singularity that can result in weak robustness and efficiency. Although several researchers have attempted to address one or more of the problems, little work has been done to address all of them together to produce a more effective and efficient LDA algorithm. This article proposes 3E-LDA, an enhanced LDA algorithm, that deals with all three problems as an attempt to further improve LDA. It proposes to learn a weighted median rather than the mean of the samples to deal with (1), to embed both between-class and within-class local geometric information to deal with (2), and to calculate the projection vectors in the null space of the matrix to deal with (3). Experiments on six benchmark datasets show that these three enhancements enable 3E-LDA to markedly outperform state-of-the-art LDA baselines in both accuracy and efficiency.},
  archive      = {J_TKDD},
  doi          = {10.1145/3442347},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {3},
  number       = {4},
  pages        = {1-20},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {3E-LDA: Three enhancements to linear discriminant analysis},
  volume       = {15},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Deep learning-based energy disaggregation and on/off
detection of household appliances. <em>TKDD</em>, <em>15</em>(3), 1–21.
(<a href="https://doi.org/10.1145/3441300">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Energy disaggregation, a.k.a. Non-Intrusive Load Monitoring, aims to separate the energy consumption of individual appliances from the readings of a mains power meter measuring the total energy consumption of, e.g., a whole house. Energy consumption of individual appliances can be useful in many applications, e.g., providing appliance-level feedback to the end users to help them understand their energy consumption and ultimately save energy. Recently, with the availability of large-scale energy consumption datasets, various neural network models such as convolutional neural networks and recurrent neural networks have been investigated to solve the energy disaggregation problem. Neural network models can learn complex patterns from large amounts of data and have been shown to outperform the traditional machine learning methods such as variants of hidden Markov models. However, current neural network methods for energy disaggregation are either computational expensive or are not capable of handling long-term dependencies. In this article, we investigate the application of the recently developed WaveNet models for the task of energy disaggregation. Based on a real-world energy dataset collected from 20 households over 2 years, we show that WaveNet models outperforms the state-of-the-art deep learning methods proposed in the literature for energy disaggregation in terms of both error measures and computational cost. On the basis of energy disaggregation, we then investigate the performance of two deep-learning based frameworks for the task of on/off detection which aims at estimating whether an appliance is in operation or not. The first framework obtains the on/off states of an appliance by binarising the predictions of a regression model trained for energy disaggregation, while the second framework obtains the on/off states of an appliance by directly training a binary classifier with binarised energy readings of the appliance serving as the target values. Based on the same dataset, we show that for the task of on/off detection the second framework, i.e., directly training a binary classifier, achieves better performance in terms of F1 score.},
  archive      = {J_TKDD},
  doi          = {10.1145/3441300},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {5},
  number       = {3},
  pages        = {1-21},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Deep learning-based energy disaggregation and On/Off detection of household appliances},
  volume       = {15},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). GGATB-LSTM: Grouping and global attention-based time-aware
bidirectional LSTM medical treatment behavior prediction. <em>TKDD</em>,
<em>15</em>(3), 1–16. (<a
href="https://doi.org/10.1145/3441454">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In China, with the continuous development of national health insurance policies, more and more people have joined the health insurance. How to accurately predict patients future medical treatment behavior becomes a hotspot issue. The biggest challenge in this issue is how to improve the prediction performance by modeling health insurance data with high-dimensional time characteristics. At present, most of the research is to solve this issue by using Recurrent Neural Networks (RNNs) to construct an overall prediction model for the medical visit sequences. However, RNNs can not effectively solve the long-term dependence, and RNNs ignores the importance of time interval of the medical visit sequence. Additionally, the global model may lose some important content to different groups. In order to solve these problems, we propose a Grouping and Global Attention based Time-aware Bidirectional Long Short-Term Memory (GGATB-LSTM) model to achieve medical treatment behavior prediction. The model first constructs a heterogeneous information network based on health insurance data, and uses a tensor CANDECOMP/PARAFAC decomposition method to achieve similarity grouping. In terms of group prediction, a global attention and time factor are introduced to extend the bidirectional LSTM. Finally, the proposed model is evaluated by using real dataset, and conclude that GGATB-LSTM is better than other methods.},
  archive      = {J_TKDD},
  doi          = {10.1145/3441454},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {5},
  number       = {3},
  pages        = {1-16},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {GGATB-LSTM: Grouping and global attention-based time-aware bidirectional LSTM medical treatment behavior prediction},
  volume       = {15},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Efficient and high-quality seeded graph matching: Employing
higher-order structural information. <em>TKDD</em>, <em>15</em>(3),
1–31. (<a href="https://doi.org/10.1145/3442340">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Driven by many real applications, we study the problem of seeded graph matching. Given two graphs and , and a small set of pre-matched node pairs where and , the problem is to identify a matching between and growing from , such that each pair in the matching corresponds to the same underlying entity. Recent studies on efficient and effective seeded graph matching have drawn a great deal of attention and many popular methods are largely based on exploring the similarity between local structures to identify matching pairs. While these recent techniques work provably well on random graphs, their accuracy is low over many real networks. In this work, we propose to utilize higher-order neighboring information to improve the matching accuracy and efficiency. As a result, a new framework of seeded graph matching is proposed, which employs Personalized PageRank (PPR) to quantify the matching score of each node pair. To further boost the matching accuracy, we propose a novel postponing strategy, which postpones the selection of pairs that have competitors with similar matching scores. We show that the postpone strategy indeed significantly improves the matching accuracy. To improve the scalability of matching large graphs, we also propose efficient approximation techniques based on algorithms for computing PPR heavy hitters. Our comprehensive experimental studies on large-scale real datasets demonstrate that, compared with state-of-the-art approaches, our framework not only increases the precision and recall both by a significant margin but also achieves speed-up up to more than one order of magnitude.},
  archive      = {J_TKDD},
  doi          = {10.1145/3442340},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {5},
  number       = {3},
  pages        = {1-31},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Efficient and high-quality seeded graph matching: Employing higher-order structural information},
  volume       = {15},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Fast connectivity minimization on large-scale networks.
<em>TKDD</em>, <em>15</em>(3), 1–25. (<a
href="https://doi.org/10.1145/3442342">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The connectivity of networks has been widely studied in many high-impact applications, ranging from immunization, critical infrastructure analysis, social network mining, to bioinformatic system studies. Regardless of the end application domains, connectivity minimization has always been a fundamental task to effectively control the functioning of the underlying system. The combinatorial nature of the connectivity minimization problem imposes an exponential computational complexity to find the optimal solution, which is intractable in large systems. To tackle the computational barrier, greedy algorithm is extensively used to ensure a near-optimal solution by exploiting the diminishing returns property of the problem. Despite the empirical success, the theoretical and algorithmic challenges of the problems still remain wide open. On the theoretical side, the intrinsic hardness and the approximability of the general connectivity minimization problem are still unknown except for a few special cases. On the algorithmic side, existing algorithms are hard to balance between the optimization quality and computational efficiency. In this article, we address the two challenges by (1) proving that the general connectivity minimization problem is NP-hard and is the best approximation ratio for any polynomial algorithms, and (2) proposing the algorithm CONTAIN and its variant CONTAIN + that can well balance optimization effectiveness and computational efficiency for eigen-function based connectivity minimization problems in large networks.},
  archive      = {J_TKDD},
  doi          = {10.1145/3442342},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {5},
  number       = {3},
  pages        = {1-25},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Fast connectivity minimization on large-scale networks},
  volume       = {15},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Preserve integrity in realtime event summarization.
<em>TKDD</em>, <em>15</em>(3), 1–29. (<a
href="https://doi.org/10.1145/3442344">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Online text streams such as Twitter are the major information source for users when they are looking for ongoing events. Realtime event summarization aims to generate and update coherent and concise summaries to describe the state of a given event. Due to the enormous volume of continuously coming texts, realtime event summarization has become the de facto tool to facilitate information acquisition. However, there exists a challenging yet unexplored issue in current text summarization techniques: how to preserve the integrity, i.e., the accuracy and consistency of summaries during the update process. The issue is critical since online text stream is dynamic and conflicting information could spread during the event period. For example, conflicting numbers of death and injuries might be reported after an earthquake. Such misleading information should not appear in the earthquake summary at any timestamp. In this article, we present a novel realtime event summarization framework called IAEA (i.e., Integrity-Aware Extractive-Abstractive realtime event summarization). Our key idea is to integrate an inconsistency detection module into a unified extractive–abstractive framework. In each update, important new tweets are first extracted in an extractive module, and the extraction is refined by explicitly detecting inconsistency between new tweets and previous summaries. The extractive module is able to capture the sentence-level attention which is later used by an abstractive module to obtain the word-level attention. Finally, the word-level attention is leveraged to rephrase words. We conduct comprehensive experiments on real-world datasets. To reduce efforts required for building sufficient training data, we also provide automatic labeling steps of which the effectiveness has been empirically verified. Through experiments, we demonstrate that IAEA can generate better summaries with consistent information than state-of-the-art approaches.},
  archive      = {J_TKDD},
  doi          = {10.1145/3442344},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {5},
  number       = {3},
  pages        = {1-29},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Preserve integrity in realtime event summarization},
  volume       = {15},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Understanding persuasion cascades in online product rating
systems: Modeling, analysis, and inference. <em>TKDD</em>,
<em>15</em>(3), 1–29. (<a
href="https://doi.org/10.1145/3440887">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Online product rating systems have become an indispensable component for numerous web services such as Amazon, eBay, Google Play Store, and TripAdvisor. One functionality of such systems is to uncover the product quality via product ratings (or reviews) contributed by consumers. However, a well-known psychological phenomenon called “ message-based persuasion ” lead to “ biased ” product ratings in a cascading manner (we call this the persuasion cascade ). This article investigates: (1) How does the persuasion cascade influence the product quality estimation accuracy? (2) Given a real-world product rating dataset, how to infer the persuasion cascade and analyze it to draw practical insights? We first develop a mathematical model to capture key factors of a persuasion cascade. We formulate a high-order Markov chain to characterize the opinion dynamics of a persuasion cascade and prove the convergence of opinions. We further bound the product quality estimation error for a class of rating aggregation rules including the averaging scoring rule, via the matrix perturbation theory and the Chernoff bound. We also design a maximum likelihood algorithm to infer parameters of the persuasion cascade. We conduct experiments on both synthetic data and real-world data from Amazon and TripAdvisor. Experiment results show that our inference algorithm has a high accuracy. Furthermore, persuasion cascades notably exist, but the average scoring rule has a small product quality estimation error under practical scenarios.},
  archive      = {J_TKDD},
  doi          = {10.1145/3440887},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {4},
  number       = {3},
  pages        = {1-29},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Understanding persuasion cascades in online product rating systems: Modeling, analysis, and inference},
  volume       = {15},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Predicting influential users in online social network
groups. <em>TKDD</em>, <em>15</em>(3), 1–50. (<a
href="https://doi.org/10.1145/3441447">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The widespread adoption of Online Social Networks (OSNs), the ever-increasing amount of information produced by their users, and the corresponding capacity to influence markets, politics, and society, have led both industrial and academic researchers to focus on how such systems could be influenced . While previous work has mainly focused on measuring current influential users, contents, or pages on the overall OSNs, the problem of predicting influencers in OSNs has remained relatively unexplored from a research perspective. Indeed, one of the main characteristics of OSNs is the ability of users to create different groups types, as well as to join groups defined by other users, in order to share information and opinions. In this article, we formulate the Influencers Prediction problem in the context of groups created in OSNs, and we define a general framework and an effective methodology to predict which users will be able to influence the behavior of the other ones in a future time period, based on historical interactions that occurred within the group. Our contribution, while rooted in solid rationale and established analytical tools, is also supported by an extensive experimental campaign. We investigate the accuracy of the predictions collecting data concerning the interactions among about 800,000 users from 18 Facebook groups belonging to different categories (i.e., News, Education, Sport, Entertainment, and Work). The achieved results show the quality and viability of our approach. For instance, we are able to predict, on average, for each group, around a third of what an ex-post analysis will show being the 10 most influential members of that group. While our contribution is interesting on its own and—to the best of our knowledge—unique, it is worth noticing that it also paves the way for further research in this field.},
  archive      = {J_TKDD},
  doi          = {10.1145/3441447},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {4},
  number       = {3},
  pages        = {1-50},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Predicting influential users in online social network groups},
  volume       = {15},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An improved KNN-based efficient log anomaly detection method
with automatically labeled samples. <em>TKDD</em>, <em>15</em>(3), 1–22.
(<a href="https://doi.org/10.1145/3441448">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Logs that record system abnormal states (anomaly logs) can be regarded as outliers, and the k-Nearest Neighbor (kNN) algorithm has relatively high accuracy in outlier detection methods. Therefore, we use the kNN algorithm to detect anomalies in the log data. However, there are some problems when using the kNN algorithm to detect anomalies, three of which are: excessive vector dimension leads to inefficient kNN algorithm, unlabeled log data cannot support the kNN algorithm, and the imbalance of the number of log data distorts the classification decision of kNN algorithm. In order to solve these three problems, we propose an efficient log anomaly detection method based on an improved kNN algorithm with an automatically labeled sample set. This method first proposes a log parsing method based on N-gram and frequent pattern mining (FPM) method, which reduces the dimension of the log vector converted with Term frequency.Inverse Document Frequency (TF-IDF) technology. Then we use clustering and self-training method to get labeled log data sample set from historical logs automatically. Finally, we improve the kNN algorithm using average weighting technology, which improves the accuracy of the kNN algorithm on unbalanced samples. The method in this article is validated on six log datasets with different types.},
  archive      = {J_TKDD},
  doi          = {10.1145/3441448},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {4},
  number       = {3},
  pages        = {1-22},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {An improved KNN-based efficient log anomaly detection method with automatically labeled samples},
  volume       = {15},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-view collaborative network embedding. <em>TKDD</em>,
<em>15</em>(3), 1–18. (<a
href="https://doi.org/10.1145/3441450">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Real-world networks often exist with multiple views, where each view describes one type of interaction among a common set of nodes. For example, on a video-sharing network, while two user nodes are linked, if they have common favorite videos in one view, then they can also be linked in another view if they share common subscribers. Unlike traditional single-view networks, multiple views maintain different semantics to complement each other. In this article, we propose M ulti-view coll A borative N etwork E mbedding (MANE), a multi-view network embedding approach to learn low-dimensional representations. Similar to existing studies, MANE hinges on diversity and collaboration—while diversity enables views to maintain their individual semantics, collaboration enables views to work together. However, we also discover a novel form of second-order collaboration that has not been explored previously, and further unify it into our framework to attain superior node representations. Furthermore, as each view often has varying importance w.r.t. different nodes, we propose MANE , an attention -based extension of MANE, to model node-wise view importance. Finally, we conduct comprehensive experiments on three public, real-world multi-view networks, and the results demonstrate that our models consistently outperform state-of-the-art approaches.},
  archive      = {J_TKDD},
  doi          = {10.1145/3441450},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {4},
  number       = {3},
  pages        = {1-18},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Multi-view collaborative network embedding},
  volume       = {15},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). CoCoS: Fast and accurate distributed triangle counting in
graph streams. <em>TKDD</em>, <em>15</em>(3), 1–30. (<a
href="https://doi.org/10.1145/3441487">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given a graph stream, how can we estimate the number of triangles in it using multiple machines with limited storage? Specifically, how should edges be processed and sampled across the machines for rapid and accurate estimation? The count of triangles (i.e., cliques of size three) has proven useful in numerous applications, including anomaly detection, community detection, and link recommendation. For triangle counting in large and dynamic graphs, recent work has focused largely on streaming algorithms and distributed algorithms but little on their combinations for “the best of both worlds.” In this work, we propose CoCoS , a fast and accurate distributed streaming algorithm for estimating the counts of global triangles (i.e., all triangles) and local triangles incident to each node. Making one pass over the input stream, CoCoS carefully processes and stores the edges across multiple machines so that the redundant use of computational and storage resources is minimized. Compared to baselines, CoCoS is: (a) accurate: giving up to smaller estimation error; (b) fast : up to faster, scaling linearly with the size of the input stream; and (c) theoretically sound : yielding unbiased estimates.},
  archive      = {J_TKDD},
  doi          = {10.1145/3441487},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {4},
  number       = {3},
  pages        = {1-30},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {CoCoS: Fast and accurate distributed triangle counting in graph streams},
  volume       = {15},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Reducing cumulative errors of incremental CP decomposition
in dynamic online social networks. <em>TKDD</em>, <em>15</em>(3), 1–33.
(<a href="https://doi.org/10.1145/3441645">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {CANDECOMP/PARAFAC (CP) decomposition is widely used in various online social network (OSN) applications. However, it is inefficient when dealing with massive and incremental data. Some incremental CP decomposition (ICP) methods have been proposed to improve the efficiency and process evolving data, by updating decomposition results according to the newly added data. The ICP methods are efficient, but inaccurate because of serious error accumulation caused by approximation in the incremental updating. To promote the wide use of ICP, we strive to reduce its cumulative errors while keeping high efficiency. We first differentiate all possible errors in ICP into two types: the cumulative reconstruction error and the prediction error. Next, we formulate two optimization problems for reducing the two errors. Then, we propose several restarting strategies to address the two problems. Finally, we test the effectiveness in three typical dynamic OSN applications. To the best of our knowledge, this is the first work on reducing the cumulative errors of the ICP methods in dynamic OSNs.},
  archive      = {J_TKDD},
  doi          = {10.1145/3441645},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {4},
  number       = {3},
  pages        = {1-33},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Reducing cumulative errors of incremental CP decomposition in dynamic online social networks},
  volume       = {15},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Scholar2vec: Vector representation of scholars for lifetime
collaborator prediction. <em>TKDD</em>, <em>15</em>(3), 1–19. (<a
href="https://doi.org/10.1145/3442199">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While scientific collaboration is critical for a scholar, some collaborators can be more significant than others, e.g., lifetime collaborators. It has been shown that lifetime collaborators are more influential on a scholar’s academic performance. However, little research has been done on investigating predicting such special relationships in academic networks. To this end, we propose Scholar2vec, a novel neural network embedding for representing scholar profiles. First, our approach creates scholars’ research interest vector from textual information, such as demographics, research, and influence. After bridging research interests with a collaboration network, vector representations of scholars can be gained with graph learning. Meanwhile, since scholars are occupied with various attributes, we propose to incorporate four types of scholar attributes for learning scholar vectors. Finally, the early-stage similarity sequence based on Scholar2vec is used to predict lifetime collaborators with machine learning methods. Extensive experiments on two real-world datasets show that Scholar2vec outperforms state-of-the-art methods in lifetime collaborator prediction. Our work presents a new way to measure the similarity between two scholars by vector representation, which tackles the knowledge between network embedding and academic relationship mining.},
  archive      = {J_TKDD},
  doi          = {10.1145/3442199},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {4},
  number       = {3},
  pages        = {1-19},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Scholar2vec: Vector representation of scholars for lifetime collaborator prediction},
  volume       = {15},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Neural networks for entity matching: A survey.
<em>TKDD</em>, <em>15</em>(3), 1–37. (<a
href="https://doi.org/10.1145/3442200">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Entity matching is the problem of identifying which records refer to the same real-world entity. It has been actively researched for decades, and a variety of different approaches have been developed. Even today, it remains a challenging problem, and there is still generous room for improvement. In recent years, we have seen new methods based upon deep learning techniques for natural language processing emerge. In this survey, we present how neural networks have been used for entity matching. Specifically, we identify which steps of the entity matching process existing work have targeted using neural networks, and provide an overview of the different techniques used at each step. We also discuss contributions from deep learning in entity matching compared to traditional methods, and propose a taxonomy of deep neural networks for entity matching.},
  archive      = {J_TKDD},
  doi          = {10.1145/3442200},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {4},
  number       = {3},
  pages        = {1-37},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Neural networks for entity matching: A survey},
  volume       = {15},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Knowledge transfer with weighted adversarial network for
cold-start store site recommendation. <em>TKDD</em>, <em>15</em>(3),
1–27. (<a href="https://doi.org/10.1145/3442203">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Store site recommendation aims to predict the value of the store at candidate locations and then recommend the optimal location to the company for placing a new brick-and-mortar store. Most existing studies focus on learning machine learning or deep learning models based on large-scale training data of existing chain stores in the same city. However, the expansion of chain enterprises in new cities suffers from data scarcity issues, and these models do not work in the new city where no chain store has been placed (i.e., cold-start problem). In this article, we propose a unified approach for cold-start store site recommendation, Weighted Adversarial Network with Transferability weighting scheme (WANT), to transfer knowledge learned from a data-rich source city to a target city with no labeled data. In particular, to promote positive transfer, we develop a discriminator to diminish distribution discrepancy between source city and target city with different data distributions, which plays the minimax game with the feature extractor to learn transferable representations across cities by adversarial learning. In addition, to further reduce the risk of negative transfer, we design a transferability weighting scheme to quantify the transferability of examples in source city and reweight the contribution of relevant source examples to transfer useful knowledge. We validate WANT using a real-world dataset, and experimental results demonstrate the effectiveness of our proposed model over several state-of-the-art baseline models.},
  archive      = {J_TKDD},
  doi          = {10.1145/3442203},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {4},
  number       = {3},
  pages        = {1-27},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Knowledge transfer with weighted adversarial network for cold-start store site recommendation},
  volume       = {15},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Probability ordinal-preserving semantic hashing for
large-scale image retrieval. <em>TKDD</em>, <em>15</em>(3), 1–22. (<a
href="https://doi.org/10.1145/3442204">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semantic hashing enables computation and memory-efficient image retrieval through learning similarity-preserving binary representations. Most existing hashing methods mainly focus on preserving the piecewise class information or pairwise correlations of samples into the learned binary codes while failing to capture the mutual triplet-level ordinal structure in similarity preservation. In this article, we propose a novel Probability Ordinal-preserving Semantic Hashing (POSH) framework, which for the first time defines the ordinal-preserving hashing concept under a non-parametric Bayesian theory. Specifically, we derive the whole learning framework of the ordinal similarity-preserving hashing based on the maximum posteriori estimation, where the probabilistic ordinal similarity preservation, probabilistic quantization function, and probabilistic semantic-preserving function are jointly considered into one unified learning framework. In particular, the proposed triplet-ordering correlation preservation scheme can effectively improve the interpretation of the learned hash codes under an economical anchor-induced asymmetric graph learning model. Moreover, the sparsity-guided selective quantization function is designed to minimize the loss of space transformation, and the regressive semantic function is explored to promote the flexibility of the formulated semantics in hash code learning. The final joint learning objective is formulated to concurrently preserve the ordinal locality of original data and explore potentials of semantics for producing discriminative hash codes. Importantly, an efficient alternating optimization algorithm with the strictly proof convergence guarantee is developed to solve the resulting objective problem. Extensive experiments on several large-scale datasets validate the superiority of the proposed method against state-of-the-art hashing-based retrieval methods.},
  archive      = {J_TKDD},
  doi          = {10.1145/3442204},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {4},
  number       = {3},
  pages        = {1-22},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Probability ordinal-preserving semantic hashing for large-scale image retrieval},
  volume       = {15},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Parallel greedy algorithm to multiple influence maximization
in social network. <em>TKDD</em>, <em>15</em>(3), 1–21. (<a
href="https://doi.org/10.1145/3442341">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Influence Maximization (IM) problem is to select influential users to maximize the influence spread, which plays an important role in many real-world applications such as product recommendation, epidemic control, and network monitoring. Nowadays multiple kinds of information can propagate in online social networks simultaneously, but current literature seldom discuss about this phenomenon. Accordingly, in this article, we propose Multiple Influence Maximization (MIM) problem where multiple information can propagate in a single network with different propagation probabilities. The goal of MIM problems is to maximize the overall accumulative influence spreads of different information with the limit of seed budget . To solve MIM problems, we first propose a greedy framework to solve MIM problems which maintains an -approximate ratio. We further propose parallel algorithms based on semaphores, an inter-thread communication mechanism, which significantly improves our algorithms efficiency. Then we conduct experiments for our framework using complex social network datasets with 12k, 154k, 317k, and 1.1m nodes, and the experimental results show that our greedy framework outperforms other heuristic algorithms greatly for large influence spread and parallelization of algorithms reduces running time observably with acceptable memory overhead.},
  archive      = {J_TKDD},
  doi          = {10.1145/3442341},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {4},
  number       = {3},
  pages        = {1-21},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Parallel greedy algorithm to multiple influence maximization in social network},
  volume       = {15},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Exploring deep reinforcement learning for task dispatching
in autonomous on-demand services. <em>TKDD</em>, <em>15</em>(3), 1–23.
(<a href="https://doi.org/10.1145/3442343">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autonomous on-demand services, such as GOGOX (formerly GoGoVan) in Hong Kong, provide a platform for users to request services and for suppliers to meet such demands. In such a platform, the suppliers have autonomy to accept or reject the demands to be dispatched to him/her, so it is challenging to make an online matching between demands and suppliers. Existing methods use round-based approaches to dispatch demands. In these works, the dispatching decision is based on the predicted response patterns of suppliers to demands in the current round, but they all fail to consider the impact of future demands and suppliers on the current dispatching decision. This could lead to taking a suboptimal dispatching decision from the future perspective. To solve this problem, we propose a novel demand dispatching model using deep reinforcement learning. In this model, we make each demand as an agent. The action of each agent, i.e., the dispatching decision of each demand, is determined by a centralized algorithm in a coordinated way. The model works in the following two steps. (1) It learns the demand’s expected value in each spatiotemporal state using historical transition data. (2) Based on the learned values, it conducts a Many-To-Many dispatching using a combinatorial optimization algorithm by considering both immediate rewards and expected values of demands in the next round. In order to get a higher total reward, the demands with a high expected value (short response time) in the future may be delayed to the next round. On the contrary, the demands with a low expected value (long response time) in the future would be dispatched immediately. Through extensive experiments using real-world datasets, we show that the proposed model outperforms the existing models in terms of Cancellation Rate and Average Response Time.},
  archive      = {J_TKDD},
  doi          = {10.1145/3442343},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {4},
  number       = {3},
  pages        = {1-23},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Exploring deep reinforcement learning for task dispatching in autonomous on-demand services},
  volume       = {15},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A scalable redefined stochastic blockmodel. <em>TKDD</em>,
<em>15</em>(3), 1–28. (<a
href="https://doi.org/10.1145/3442589">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stochastic blockmodel (SBM) is a widely used statistical network representation model, with good interpretability, expressiveness, generalization, and flexibility, which has become prevalent and important in the field of network science over the last years. However, learning an optimal SBM for a given network is an NP-hard problem. This results in significant limitations when it comes to applications of SBMs in large-scale networks, because of the significant computational overhead of existing SBM models, as well as their learning methods. Reducing the cost of SBM learning and making it scalable for handling large-scale networks, while maintaining the good theoretical properties of SBM, remains an unresolved problem. In this work, we address this challenging task from a novel perspective of model redefinition. We propose a novel redefined SBM with Poisson distribution and its block-wise learning algorithm that can efficiently analyse large-scale networks. Extensive validation conducted on both artificial and real-world data shows that our proposed method significantly outperforms the state-of-the-art methods in terms of a reasonable trade-off between accuracy and scalability. 1},
  archive      = {J_TKDD},
  doi          = {10.1145/3442589},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {4},
  number       = {3},
  pages        = {1-28},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {A scalable redefined stochastic blockmodel},
  volume       = {15},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). TipTap: Approximate mining of frequent k-subgraph patterns
in evolving graphs. <em>TKDD</em>, <em>15</em>(3), 1–35. (<a
href="https://doi.org/10.1145/3442590">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {“Perhaps he could dance first and think afterwards, if it isn’t too much to ask him.” S. Beckett, Waiting for Godot Given a labeled graph, the collection of k -vertex induced connected subgraph patterns that appear in the graph more frequently than a user-specified minimum threshold provides a compact summary of the characteristics of the graph, and finds applications ranging from biology to network science. However, finding these patterns is challenging, even more so for dynamic graphs that evolve over time, due to the streaming nature of the input and the exponential time complexity of the problem. We study this task in both incremental and fully-dynamic streaming settings, where arbitrary edges can be added or removed from the graph. We present TipTap , a suite of algorithms to compute high-quality approximations of the frequent k -vertex subgraphs w.r.t. a given threshold, at any time (i.e., point of the stream), with high probability. In contrast to existing state-of-the-art solutions that require iterating over the entire set of subgraphs in the vicinity of the updated edge, TipTap operates by efficiently maintaining a uniform sample of connected k -vertex subgraphs, thanks to an optimized neighborhood-exploration procedure. We provide a theoretical analysis of the proposed algorithms in terms of their unbiasedness and of the sample size needed to obtain a desired approximation quality. Our analysis relies on sample-complexity bounds that use Vapnik–Chervonenkis dimension, a key concept from statistical learning theory, which allows us to derive a sufficient sample size that is independent from the size of the graph. The results of our empirical evaluation demonstrates that TipTap returns high-quality results more efficiently and accurately than existing baselines.},
  archive      = {J_TKDD},
  doi          = {10.1145/3442590},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {4},
  number       = {3},
  pages        = {1-35},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {TipTap: Approximate mining of frequent k-subgraph patterns in evolving graphs},
  volume       = {15},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). TPmod: A tendency-guided prediction model for temporal
knowledge graph completion. <em>TKDD</em>, <em>15</em>(3), 1–17. (<a
href="https://doi.org/10.1145/3443687">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Temporal knowledge graphs (TKGs) have become useful resources for numerous Artificial Intelligence applications, but they are far from completeness. Inferring missing events in temporal knowledge graphs is a fundamental and challenging task. However, most existing methods solely focus on entity features or consider the entities and relations in a disjoint manner. They do not integrate the features of entities and relations in their modeling process. In this paper, we propose TPmod, a tendency-guided prediction model, to predict the missing events for TKGs (extrapolation). Differing from existing works, we propose two definitions for TKGs: the Goodness of relations and the Closeness of entity pairs. More importantly, inspired by the attention mechanism, we propose a novel tendency strategy to guide our aggregated process. It integrates the features of entities and relations, and assigns varying weights to different past events. What is more, we select the Gate Recurrent Unit (GRU) as our sequential encoder to model the temporal dependency in TKGs. Besides, the Softmax function is employed to generate the final decreasing group of candidate entities. We evaluate our model on two TKG datasets: GDELT-5 and ICEWS-250. Experimental results show that our method has a significant and consistent improvement compared to state-of-the-art baselines.},
  archive      = {J_TKDD},
  doi          = {10.1145/3443687},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {4},
  number       = {3},
  pages        = {1-17},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {TPmod: A tendency-guided prediction model for temporal knowledge graph completion},
  volume       = {15},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Heterogeneous network approach to predict individuals’
mental health. <em>TKDD</em>, <em>15</em>(2), 1–26. (<a
href="https://doi.org/10.1145/3429446">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Depression and anxiety are critical public health issues affecting millions of people around the world. To identify individuals who are vulnerable to depression and anxiety, predictive models have been built that typically utilize data from one source. Unlike these traditional models, in this study, we leverage a rich heterogeneous dataset from the University of Notre Dame’s NetHealth study that collected individuals’ (student participants’) social interaction data via smartphones, health-related behavioral data via wearables (Fitbit), and trait data from surveys. To integrate the different types of information, we model the NetHealth data as a heterogeneous information network (HIN). Then, we redefine the problem of predicting individuals’ mental health conditions (depression or anxiety) in a novel manner, as applying to our HIN a popular paradigm of a recommender system (RS), which is typically used to predict the preference that a person would give to an item (e.g., a movie or book). In our case, the items are the individuals’ different mental health states. We evaluate four state-of-the-art RS approaches. Also, we model the prediction of individuals’ mental health as another problem type—that of node classification (NC) in our HIN, evaluating in the process four node features under logistic regression as a proof-of-concept classifier. We find that our RS and NC network methods produce more accurate predictions than a logistic regression model using the same NetHealth data in the traditional non-network fashion as well as a random-approach. Also, we find that the best of the considered RS approaches outperforms all considered NC approaches. This is the first study to integrate smartphone, wearable sensor, and survey data in a HIN manner and use RS or NC on the HIN to predict individuals’ mental health conditions.},
  archive      = {J_TKDD},
  doi          = {10.1145/3429446},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {4},
  number       = {2},
  pages        = {1-26},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Heterogeneous network approach to predict individuals’ mental health},
  volume       = {15},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Mitigating class-boundary label uncertainty to reduce both
model bias and variance. <em>TKDD</em>, <em>15</em>(2), 1–18. (<a
href="https://doi.org/10.1145/3429447">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The study of model bias and variance with respect to decision boundaries is critically important in supervised learning and artificial intelligence. There is generally a tradeoff between the two, as fine-tuning of the decision boundary of a classification model to accommodate more boundary training samples (i.e., higher model complexity) may improve training accuracy (i.e., lower bias) but hurt generalization against unseen data (i.e., higher variance). By focusing on just classification boundary fine-tuning and model complexity, it is difficult to reduce both bias and variance. To overcome this dilemma, we take a different perspective and investigate a new approach to handle inaccuracy and uncertainty in the training data labels, which are inevitable in many applications where labels are conceptual entities and labeling is performed by human annotators. The process of classification can be undermined by uncertainty in the labels of the training data; extending a boundary to accommodate an inaccurately labeled point will increase both bias and variance. Our novel method can reduce both bias and variance by estimating the pointwise label uncertainty of the training set and accordingly adjusting the training sample weights such that those samples with high uncertainty are weighted down and those with low uncertainty are weighted up. In this way, uncertain samples have a smaller contribution to the objective function of the model’s learning algorithm and exert less pull on the decision boundary. In a real-world physical activity recognition case study, the data present many labeling challenges, and we show that this new approach improves model performance and reduces model variance.},
  archive      = {J_TKDD},
  doi          = {10.1145/3429447},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {3},
  number       = {2},
  pages        = {1-18},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Mitigating class-boundary label uncertainty to reduce both model bias and variance},
  volume       = {15},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Joint transferable dictionary learning and view adaptation
for multi-view human action recognition. <em>TKDD</em>, <em>15</em>(2),
1–23. (<a href="https://doi.org/10.1145/3434746">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view human action recognition remains a challenging problem due to large view changes. In this article, we propose a transfer learning-based framework called transferable dictionary learning and view adaptation (TDVA) model for multi-view human action recognition. In the transferable dictionary learning phase, TDVA learns a set of view-specific transferable dictionaries enabling the same actions from different views to share the same sparse representations, which can transfer features of actions from different views to an intermediate domain. In the view adaptation phase, TDVA comprehensively analyzes global, local, and individual characteristics of samples, and jointly learns balanced distribution adaptation, locality preservation, and discrimination preservation, aiming at transferring sparse features of actions of different views from the intermediate domain to a common domain. In other words, TDVA progressively bridges the distribution gap among actions from various views by these two phases. Experimental results on IXMAS, ACT4 2 , and NUCLA action datasets demonstrate that TDVA outperforms state-of-the-art methods.},
  archive      = {J_TKDD},
  doi          = {10.1145/3434746},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {3},
  number       = {2},
  pages        = {1-23},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Joint transferable dictionary learning and view adaptation for multi-view human action recognition},
  volume       = {15},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Towards automatic construction of multi-network models for
heterogeneous multi-task learning. <em>TKDD</em>, <em>15</em>(2), 1–23.
(<a href="https://doi.org/10.1145/3434748">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-task learning, as it is understood nowadays, consists of using one single model to carry out several similar tasks. From classifying hand-written characters of different alphabets to figuring out how to play several Atari games using reinforcement learning, multi-task models have been able to widen their performance range across different tasks, although these tasks are usually of a similar nature. In this work, we attempt to expand this range even further, by including heterogeneous tasks in a single learning procedure. To do so, we firstly formally define a multi-network model, identifying the necessary components and characteristics to allow different adaptations of said model depending on the tasks it is required to fulfill. Secondly, employing the formal definition as a starting point, we develop an illustrative model example consisting of three different tasks (classification, regression, and data sampling). The performance of this illustrative model is then analyzed, showing its capabilities. Motivated by the results of the analysis, we enumerate a set of open challenges and future research lines over which the full potential of the proposed model definition can be exploited.},
  archive      = {J_TKDD},
  doi          = {10.1145/3434748},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {3},
  number       = {2},
  pages        = {1-23},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Towards automatic construction of multi-network models for heterogeneous multi-task learning},
  volume       = {15},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Noise corrected sampling of online social networks.
<em>TKDD</em>, <em>15</em>(2), 1–21. (<a
href="https://doi.org/10.1145/3434749">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we propose a new method to perform topological network sampling. Topological network sampling is a process for extracting a subset of nodes and edges from a network, such that analyses on the sample provide results and conclusions comparable to the ones they would return if run on whole structure. We need network sampling because the largest online network datasets are accessed through low-throughput application programming interface (API) systems, rendering the collection of the whole network infeasible. Our method is inspired by the literature on network backboning, specifically the noise-corrected backbone. We select the next node to explore by following the edge we identify as the one providing the largest information gain, given the topology of the sample explored so far. We evaluate our method against the most commonly used sampling methods. We do so in a realistic framework, considering a wide array of network topologies, network analysis, and features of API systems. There is no method that can provide the best sample in all possible scenarios, thus in our results section, we show the cases in which our method performs best and the cases in which it performs worst. Overall, the noise-corrected network sampling performs well: it has the best rank average among the tested methods across a wide range of applications.},
  archive      = {J_TKDD},
  doi          = {10.1145/3434749},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {3},
  number       = {2},
  pages        = {1-21},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Noise corrected sampling of online social networks},
  volume       = {15},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Stacked convolutional sparse auto-encoders for
representation learning. <em>TKDD</em>, <em>15</em>(2), 1–21. (<a
href="https://doi.org/10.1145/3434767">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning seeks to achieve excellent performance for representation learning in image datasets. However, supervised deep learning models such as convolutional neural networks require a large number of labeled image data, which is intractable in applications, while unsupervised deep learning models like stacked denoising auto-encoder cannot employ label information. Meanwhile, the redundancy of image data incurs performance degradation on representation learning for aforementioned models. To address these problems, we propose a semi-supervised deep learning framework called stacked convolutional sparse auto-encoder, which can learn robust and sparse representations from image data with fewer labeled data records. More specifically, the framework is constructed by stacking layers. In each layer, higher layer feature representations are generated by features of lower layers in a convolutional way with kernels learned by a sparse auto-encoder. Meanwhile, to solve the data redundance problem, the algorithm of Reconstruction Independent Component Analysis is designed to train on patches for sphering the input data. The label information is encoded using a Softmax Regression model for semi-supervised learning. With this framework, higher level representations are learned by layers mapping from image data. It can boost the performance of the base subsequent classifiers such as support vector machines. Extensive experiments demonstrate the superior classification performance of our framework compared to several state-of-the-art representation learning methods.},
  archive      = {J_TKDD},
  doi          = {10.1145/3434767},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {3},
  number       = {2},
  pages        = {1-21},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Stacked convolutional sparse auto-encoders for representation learning},
  volume       = {15},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An instance space analysis of regression problems.
<em>TKDD</em>, <em>15</em>(2), 1–25. (<a
href="https://doi.org/10.1145/3436893">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The quest for greater insights into algorithm strengths and weaknesses, as revealed when studying algorithm performance on large collections of test problems, is supported by interactive visual analytics tools. A recent advance is Instance Space Analysis, which presents a visualization of the space occupied by the test datasets, and the performance of algorithms across the instance space. The strengths and weaknesses of algorithms can be visually assessed, and the adequacy of the test datasets can be scrutinized through visual analytics. This article presents the first Instance Space Analysis of regression problems in Machine Learning, considering the performance of 14 popular algorithms on 4,855 test datasets from a variety of sources. The two-dimensional instance space is defined by measurable characteristics of regression problems, selected from over 26 candidate features. It enables the similarities and differences between test instances to be visualized, along with the predictive performance of regression algorithms across the entire instance space. The purpose of creating this framework for visual analysis of an instance space is twofold: one may assess the capability and suitability of various regression techniques; meanwhile the bias, diversity, and level of difficulty of the regression problems popularly used by the community can be visually revealed. This article shows the applicability of the created regression instance space to provide insights into the strengths and weaknesses of regression algorithms, and the opportunities to diversify the benchmark test instances to support greater insights.},
  archive      = {J_TKDD},
  doi          = {10.1145/3436893},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {3},
  number       = {2},
  pages        = {1-25},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {An instance space analysis of regression problems},
  volume       = {15},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Generating artificial outliers in the absence of genuine
ones — a survey. <em>TKDD</em>, <em>15</em>(2), 1–37. (<a
href="https://doi.org/10.1145/3447822">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {By definition, outliers are rarely observed in reality, making them difficult to detect or analyze. Artificial outliers approximate such genuine outliers and can, for instance, help with the detection of genuine outliers or with benchmarking outlier-detection algorithms. The literature features different approaches to generate artificial outliers. However, systematic comparison of these approaches remains absent. This surveys and compares these approaches. We start by clarifying the terminology in the field, which varies from publication to publication, and we propose a general problem formulation. Our description of the connection of generating outliers to other research fields like experimental design or generative models frames the field of artificial outliers. Along with offering a concise description, we group the approaches by their general concepts and how they make use of genuine instances. An extensive experimental study reveals the differences between the generation approaches when ultimately being used for outlier detection. This survey shows that the existing approaches already cover a wide range of concepts underlying the generation, but also that the field still has potential for further development. Our experimental study does confirm the expectation that the quality of the generation approaches varies widely, for example, in terms of the dataset they are used on. Ultimately, to guide the choice of the generation approach in a specific context, we propose an appropriate general-decision process. In summary, this survey comprises, describes, and connects all relevant work regarding the generation of artificial outliers and may serve as a basis to guide further research in the field.},
  archive      = {J_TKDD},
  doi          = {10.1145/3447822},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {3},
  number       = {2},
  pages        = {1-37},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Generating artificial outliers in the absence of genuine ones — a survey},
  volume       = {15},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Trajectory outlier detection: New problems and solutions for
smart cities. <em>TKDD</em>, <em>15</em>(2), 1–28. (<a
href="https://doi.org/10.1145/3425867">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article introduces two new problems related to trajectory outlier detection: (1) group trajectory outlier (GTO) detection and (2) deviation point detection for both individual and group of trajectory outliers. Five algorithms are proposed for the first problem by adapting DBSCAN , k nearest neighbors (kNN) , and feature selection (FS) . DBSCAN-GTO first applies DBSCAN to derive the micro clusters , which are considered as potential candidates. A pruning strategy based on density computation measure is then suggested to find the group of trajectory outliers. kNN-GTO recursively derives the trajectory candidates from the individual trajectory outliers and prunes them based on their density. The overall process is repeated for all individual trajectory outliers. FS-GTO considers the set of individual trajectory outliers as the set of all features, while the FS process is used to retrieve the group of trajectory outliers. The proposed algorithms are improved by incorporating ensemble learning and high-performance computing during the detection process. Moreover, we propose a general two-phase-based algorithm for detecting the deviation points, as well as a version for graphic processing units implementation using sliding windows. Experiments on a real trajectory dataset have been carried out to demonstrate the performance of the proposed approaches. The results show that they can efficiently identify useful patterns represented by group of trajectory outliers, deviation points, and that they outperform the baseline group detection algorithms.},
  archive      = {J_TKDD},
  doi          = {10.1145/3425867},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {2},
  number       = {2},
  pages        = {1-28},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Trajectory outlier detection: New problems and solutions for smart cities},
  volume       = {15},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Sampling sparse representations with randomized measurement
langevin dynamics. <em>TKDD</em>, <em>15</em>(2), 1–21. (<a
href="https://doi.org/10.1145/3427585">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stochastic Gradient Langevin Dynamics (SGLD) have been widely used for Bayesian sampling from certain probability distributions, incorporating derivatives of the log-posterior. With the derivative evaluation of the log-posterior distribution, SGLD methods generate samples from the distribution through performing as a thermostats dynamics that traverses over gradient flows of the log-posterior with certainly controllable perturbation. Even when the density is not known, existing solutions still can first learn the kernel density models from the given datasets, then produce new samples using the SGLD over the kernel density derivatives. In this work, instead of exploring new samples from kernel spaces, a novel SGLD sampler, namely, Randomized Measurement Langevin Dynamics (RMLD) is proposed to sample the high-dimensional sparse representations from the spectral domain of a given dataset. Specifically, given a random measurement matrix for sparse coding, RMLD first derives a novel likelihood evaluator of the probability distribution from the loss function of LASSO, then samples from the high-dimensional distribution using stochastic Langevin dynamics with derivatives of the logarithm likelihood and Metropolis–Hastings sampling. In addition, new samples in low-dimensional measuring spaces can be regenerated using the sampled high-dimensional vectors and the measurement matrix. The algorithm analysis shows that RMLD indeed projects a given dataset into a high-dimensional Gaussian distribution with Laplacian prior, then draw new sparse representation from the dataset through performing SGLD over the distribution. Extensive experiments have been conducted to evaluate the proposed algorithm using real-world datasets. The performance comparisons on three real-world applications demonstrate the superior performance of RMLD beyond baseline methods.},
  archive      = {J_TKDD},
  doi          = {10.1145/3427585},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {2},
  number       = {2},
  pages        = {1-21},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Sampling sparse representations with randomized measurement langevin dynamics},
  volume       = {15},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Identifying linear models in multi-resolution population
data using minimum description length principle to predict household
income. <em>TKDD</em>, <em>15</em>(2), 1–30. (<a
href="https://doi.org/10.1145/3424670">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One shirt size cannot fit everybody, while we cannot make a unique shirt that fits perfectly for everyone because of resource limitations. This analogy is true for policy making as well. Policy makers cannot make a single policy to solve all problems for all regions because each region has its own unique issue. At the other extreme, policy makers also cannot make a policy for each small village due to resource limitations. Would it be better if we can find a set of largest regions such that the population of each region within this set has common issues and we can make a single policy for them? In this work, we propose a framework using regression analysis and Minimum Description Length (MDL) to find a set of largest areas that have common indicators, which can be used to predict household incomes efficiently. Given a set of household features, and a multi-resolution partition that represents administrative divisions, our framework reports a set C * of largest subdivisions that have a common predictive model for population-income prediction. We formalize the problem of finding C * and propose an algorithm that can find C * correctly. We use both simulation datasets as well as a real-world dataset of Thailand’s population household information to demonstrate our framework performance and application. The results show that our framework performance is better than the baseline methods. Moreover, we demonstrate that the results of our method can be used to find indicators of income prediction for many areas in Thailand. By adjusting these indicator values via policies, we expect people in these areas to gain more incomes. Hence, the policy makers will be able to make policies by using these indicators in our results as a guideline to solve low-income issues. Our framework can be used to support policy makers in making policies regarding any other dependent variable beyond income in order to combat poverty and other issues. We provide the R package, MRReg, which is the implementation of our framework in the R language. The MRReg package comes with a documentation for anyone who is interested in analyzing linear regression on multi-resolution population data.},
  archive      = {J_TKDD},
  doi          = {10.1145/3424670},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {1},
  number       = {2},
  pages        = {1-30},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Identifying linear models in multi-resolution population data using minimum description length principle to predict household income},
  volume       = {15},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Recommending statutes: A portable method based on neural
networks. <em>TKDD</em>, <em>15</em>(2), 1–22. (<a
href="https://doi.org/10.1145/3424671">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Legal judgment prediction, which aims at predicting judgment results such as penalty, charges, and statutes for cases, has attracted much attention recently. In this article, we focus on building a recommender system to predict the associated statutes for a case given the facts of the case as input. For this purpose, we propose a two-step neural network-based machine learning framework to assist judges as well as ordinary people to reduce their effort in finding applicable statutes. The proposed model takes advantage of recurrent neural networks with a max-pooling layer to obtain contextual representations of documents, i.e., the facts associated with the cases. Moreover, an attention mechanism is used to automatically focus on the important words contributing to the prediction of statutes. In addition, we apply an encoder--decoder ranking approach to extract correlations between statutes to achieve more accurate recommendation results. We evaluate our model on a real-world dataset. Experimental results show that, compared with existing baseline methods, our method can predict statutes that are more likely to appear in real judgments.},
  archive      = {J_TKDD},
  doi          = {10.1145/3424671},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {1},
  number       = {2},
  pages        = {1-22},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Recommending statutes: A portable method based on neural networks},
  volume       = {15},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Knowledge graph embedding for link prediction: A comparative
analysis. <em>TKDD</em>, <em>15</em>(2), 1–49. (<a
href="https://doi.org/10.1145/3424672">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge Graphs (KGs) have found many applications in industrial and in academic settings, which in turn, have motivated considerable research efforts towards large-scale information extraction from a variety of sources. Despite such efforts, it is well known that even the largest KGs suffer from incompleteness; Link Prediction (LP) techniques address this issue by identifying missing facts among entities already in the KG. Among the recent LP techniques, those based on KG embeddings have achieved very promising performance in some benchmarks. Despite the fast-growing literature on the subject, insufficient attention has been paid to the effect of the design choices in those methods. Moreover, the standard practice in this area is to report accuracy by aggregating over a large number of test facts in which some entities are vastly more represented than others; this allows LP methods to exhibit good results by just attending to structural properties that include such entities, while ignoring the remaining majority of the KG. This analysis provides a comprehensive comparison of embedding-based LP methods, extending the dimensions of analysis beyond what is commonly available in the literature. We experimentally compare the effectiveness and efficiency of 18 state-of-the-art methods, consider a rule-based baseline, and report detailed analysis over the most popular benchmarks in the literature.},
  archive      = {J_TKDD},
  doi          = {10.1145/3424672},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {1},
  number       = {2},
  pages        = {1-49},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Knowledge graph embedding for link prediction: A comparative analysis},
  volume       = {15},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). HARP: A novel hierarchical attention model for relation
prediction. <em>TKDD</em>, <em>15</em>(2), 1–22. (<a
href="https://doi.org/10.1145/3424673">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent years have witnessed great advancement of representation learning (RL)-based models for the knowledge graph relation prediction task. However, they generally rely on structure information embedded in the encyclopedic knowledge graph, while the beneficial semantic information provided by lexical knowledge graph is ignored, leading the problem of shallow understanding and coarse-grained analysis for knowledge acquisition. Therefore, this article introduces concept information derived from the lexical knowledge graph (e.g., Probase), and proposes a novel Hierarchical Attention model for Relation Prediction, which consists of entity-level attention mechanism and concept-level attention mechanism, to throughly integrate multiple semantic signals. Experimental results demonstrate the efficiency of the proposed method on two benchmark datasets.},
  archive      = {J_TKDD},
  doi          = {10.1145/3424673},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {1},
  number       = {2},
  pages        = {1-22},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {HARP: A novel hierarchical attention model for relation prediction},
  volume       = {15},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). High-order structure exploration on massive graphs: A local
graph clustering perspective. <em>TKDD</em>, <em>15</em>(2), 1–26. (<a
href="https://doi.org/10.1145/3425637">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modeling and exploring high-order connectivity patterns, also called network motifs, are essential for understanding the fundamental structures that control and mediate the behavior of many complex systems. For example, in social networks, triangles have been proven to play the fundamental role in understanding social network communities; in online transaction networks, detecting directed looped transactions helps identify money laundering activities; in personally identifiable information networks, the star-shaped structures may correspond to a set of synthetic identities. Despite the ubiquity of such high-order structures, many existing graph clustering methods are either not designed for the high-order connectivity patterns, or suffer from the prohibitive computational cost when modeling high-order structures in the large-scale networks. This article generalizes the challenges in multiple dimensions. First ( Model ), we introduce the notion of high-order conductance, and define the high-order diffusion core, which is based on a high-order random walk induced by the user-specified high-order network structure. Second ( Algorithm ), we propose a novel high-order structure-preserving graph clustering framework named HOSGRAP , which partitions the graph into structure-rich clusters in polylogarithmic time with respect to the number of edges in the graph. Third ( Generalization ), we generalize our proposed algorithm to solve the real-world problems on various types of graphs, such as signed graphs, bipartite graphs, and multi-partite graphs. Experimental results on both synthetic and real graphs demonstrate the effectiveness and efficiency of the proposed algorithms.},
  archive      = {J_TKDD},
  doi          = {10.1145/3425637},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {1},
  number       = {2},
  pages        = {1-26},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {High-order structure exploration on massive graphs: A local graph clustering perspective},
  volume       = {15},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An exponential factorization machine with percentage error
minimization to retail sales forecasting. <em>TKDD</em>, <em>15</em>(2),
1–32. (<a href="https://doi.org/10.1145/3426238">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article proposes a new approach to sales forecasting for new products (stock-keeping units [SKUs]) with long lead time but short product life cycle. These SKUs are usually sold for one season only, without any replenishments. An exponential factorization machine (EFM) sales forecast model is developed to solve this problem which not only takes into account SKU attributes, but also pairwise interactions. The EFM model is significantly different from the original Factorization Machines (FM) from two fold: (1) the attribute-level formulation for explanatory/input variables; and (2) exponential formulation for the positive response/output/target variable. The attribute-level formation excludes infeasible intra-attribute interactions and results in more efficient feature engineering comparing with the conventional one-hot encoding, while the exponential formulation is demonstrated more effective than the log-transformation for the positive but not skewed distributed responses. In order to estimate the parameters, percentage error squares (PES) and error squares (ES) are minimized by a proposed adaptive batch gradient descent method over the training set. To overcome the over-fitting problem, a greedy forward stepwise feature selection method is proposed to select the most useful attributes and interactions. Real-world data provided by a footwear retailer in Singapore are used for testing the proposed approach. The forecasting performance in terms of both mean absolute percentage error (MAPE) and mean absolute error (MAE) compares favorably with not only off-the-shelf models but also results reported by extant sales and demand forecasting studies. The effectiveness of the proposed approach is also demonstrated by two external public datasets. Moreover, we prove the theoretical relationships between PES and ES minimization, and present an important property of the PES minimization for regression models; that it trains models to underestimate data. This property fits the situation of sales forecasting where unit-holding cost is much greater than the unit-shortage cost (e.g., perishable products).},
  archive      = {J_TKDD},
  doi          = {10.1145/3426238},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {1},
  number       = {2},
  pages        = {1-32},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {An exponential factorization machine with percentage error minimization to retail sales forecasting},
  volume       = {15},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Context-based evaluation of dimensionality reduction
algorithms—experiments and statistical significance analysis.
<em>TKDD</em>, <em>15</em>(2), 1–40. (<a
href="https://doi.org/10.1145/3428077">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dimensionality reduction is a commonly used technique in data analytics. Reducing the dimensionality of datasets helps not only with managing their analytical complexity but also with removing redundancy. Over the years, several such algorithms have been proposed with their aims ranging from generating simple linear projections to complex non-linear transformations of the input data. Subsequently, researchers have defined several quality metrics in order to evaluate the performances of different algorithms. Hence, given a plethora of dimensionality reduction algorithms and metrics for their quality analysis, there is a long-existing need for guidelines on how to select the most appropriate algorithm in a given scenario. In order to bridge this gap, in this article, we have compiled 12 state-of-the-art quality metrics and categorized them into 5 identified analytical contexts. Furthermore, we assessed 15 most popular dimensionality reduction algorithms on the chosen quality metrics using a large-scale and systematic experimental study. Later, using a set of robust non-parametric statistical tests, we assessed the generalizability of our evaluation on 40 real-world datasets. Finally, based on our results, we present practitioners’ guidelines for the selection of an appropriate dimensionally reduction algorithm in the present analytical contexts.},
  archive      = {J_TKDD},
  doi          = {10.1145/3428077},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {1},
  number       = {2},
  pages        = {1-40},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Context-based evaluation of dimensionality reduction Algorithms—Experiments and statistical significance analysis},
  volume       = {15},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The 8M algorithm from today’s perspective. <em>TKDD</em>,
<em>15</em>(2), 1–22. (<a
href="https://doi.org/10.1145/3428078">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We provide a detailed analysis and a first complete description of 8M—an old but virtually unknown algorithm for Boolean matrix factorization. Even though the algorithm uses a rather limited insight into the factorization problem from today’s perspective, we demonstrate that its performance is reasonably good compared to the currently available algorithms. Our analysis reveals that this is due to certain concepts employed by 8M that are not exploited by the current algorithms. We discuss the prospect of these concepts, utilize them to improve two well-known current factorization algorithms, and, furthermore, propose an improvement of 8M itself, which significantly enhances the performance of the original 8M. Our findings are illustrated by experimental evaluation.},
  archive      = {J_TKDD},
  doi          = {10.1145/3428078},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {1},
  number       = {2},
  pages        = {1-22},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {The 8M algorithm from today’s perspective},
  volume       = {15},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Core interest network for click-through rate prediction.
<em>TKDD</em>, <em>15</em>(2), 1–16. (<a
href="https://doi.org/10.1145/3428079">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In modern online advertising systems, the click-through rate (CTR) is an important index to measure the popularity of an item. It refers to the ratio of users who click on a specific advertisement to the number of total users who view it. Predicting the CTR of an item in advance can improve the accuracy of the advertisement recommendation. And it is commonly calculated based on users’ interests. Thus, extracting users’ interests is of great importance in CTR prediction tasks. In the literature, a lot of studies treat the interaction between users and items as sequential data and apply the recurrent neural network (RNN) model to extract users’ interests. However, these solutions cannot handle the case when the sequence length is relatively long, e.g., over 100. This is because of the vanishing gradient problem of RNN, i.e., the model cannot learn a users’ previous behaviors that are too far away from the current moment. To address this problem, we propose a new Core Interest Network (CIN) model to mitigate the problem of a long sequence in the CTR prediction task with sequential data. In brief, we first extract the core interests of users and then use the refined data as the input of subsequent learning tasks. Extensive evaluations on real dataset show that our CIN model can outperform the state-of-the-art solutions in terms of prediction accuracy.},
  archive      = {J_TKDD},
  doi          = {10.1145/3428079},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {1},
  number       = {2},
  pages        = {1-16},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Core interest network for click-through rate prediction},
  volume       = {15},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Unbiased measurement of feature importance in tree-based
methods. <em>TKDD</em>, <em>15</em>(2), 1–21. (<a
href="https://doi.org/10.1145/3429445">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a modification that corrects for split-improvement variable importance measures in Random Forests and other tree-based methods. These methods have been shown to be biased towards increasing the importance of features with more potential splits. We show that by appropriately incorporating split-improvement as measured on out of sample data, this bias can be corrected yielding better summaries and screening tools.},
  archive      = {J_TKDD},
  doi          = {10.1145/3429445},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {1},
  number       = {2},
  pages        = {1-21},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Unbiased measurement of feature importance in tree-based methods},
  volume       = {15},
  year         = {2021},
}
</textarea>
</details></li>
</ul>

</body>
</html>
