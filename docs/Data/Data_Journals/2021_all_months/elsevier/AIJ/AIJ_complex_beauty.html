<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>AIJ_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="aij---100">AIJ - 100</h2>
<ul>
<li><details>
<summary>
(2021). Picking sequences and monotonicity in weighted fair
division. <em>AIJ</em>, <em>301</em>, 103578. (<a
href="https://doi.org/10.1016/j.artint.2021.103578">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the problem of fairly allocating indivisible items to agents with different entitlements, which captures, for example, the distribution of ministries among political parties in a coalition government. Our focus is on picking sequences derived from common apportionment methods, including five traditional divisor methods and the quota method. We paint a complete picture of these methods in relation to known envy-freeness and proportionality relaxations for indivisible items as well as monotonicity properties with respect to the resource, population, and weights. In addition, we provide characterizations of picking sequences satisfying each of the fairness notions, and show that the well-studied maximum Nash welfare solution fails resource- and population-monotonicity even in the unweighted setting. Our results serve as an argument in favor of using picking sequences in weighted fair division problems.},
  archive      = {J_AIJ},
  author       = {Mithun Chakraborty and Ulrike Schmidt-Kraepelin and Warut Suksompong},
  doi          = {10.1016/j.artint.2021.103578},
  journal      = {Artificial Intelligence},
  pages        = {103578},
  shortjournal = {Artif. Intell.},
  title        = {Picking sequences and monotonicity in weighted fair division},
  volume       = {301},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Coalitional permutation manipulations in the gale-shapley
algorithm. <em>AIJ</em>, <em>301</em>, 103577. (<a
href="https://doi.org/10.1016/j.artint.2021.103577">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we consider permutation manipulations by any subset of women in the men-proposing version of the Gale-Shapley algorithm. This paper is motivated by the college admissions process in China. Our results also answer an open problem on what can be achieved by permutation manipulations. We present an efficient algorithm to find a strategy profile such that the induced matching is stable and Pareto-optimal (in the set of all achievable stable matchings) while the strategy profile itself is inconspicuous. Surprisingly, we show that such a strategy profile actually forms a Nash equilibrium of the manipulation game. In the end, we show that it is NP-complete to find a manipulation that is strictly better for all members of the coalition. This result demonstrates a sharp contrast between weakly better off outcomes and strictly better-off outcomes.},
  archive      = {J_AIJ},
  author       = {Weiran Shen and Yuan Deng and Pingzhong Tang},
  doi          = {10.1016/j.artint.2021.103577},
  journal      = {Artificial Intelligence},
  pages        = {103577},
  shortjournal = {Artif. Intell.},
  title        = {Coalitional permutation manipulations in the gale-shapley algorithm},
  volume       = {301},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Schelling games on graphs. <em>AIJ</em>, <em>301</em>,
103576. (<a href="https://doi.org/10.1016/j.artint.2021.103576">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study strategic games inspired by Schelling&#39;s seminal model of residential segregation . These games are played on undirected graphs , with the set of agents partitioned into multiple types; each agent either aims to maximize the fraction of her neighbors who are of her own type, or occupies a node of the graph and never moves away. We consider two natural variants of this model: in jump games agents can jump to empty nodes of the graph to increase their utility, while in swap games they can swap positions with other agents. We investigate the existence, computational complexity , and quality of equilibrium assignments in these games, both from a social welfare perspective and from a diversity perspective. Some of our results extend to a more general setting where the preferences of the agents over their neighbors are defined by a social network rather than a partition into types.},
  archive      = {J_AIJ},
  author       = {Aishwarya Agarwal and Edith Elkind and Jiarui Gan and Ayumi Igarashi and Warut Suksompong and Alexandros A. Voudouris},
  doi          = {10.1016/j.artint.2021.103576},
  journal      = {Artificial Intelligence},
  pages        = {103576},
  shortjournal = {Artif. Intell.},
  title        = {Schelling games on graphs},
  volume       = {301},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Distributed optimization for degenerate loss functions
arising from over-parameterization. <em>AIJ</em>, <em>301</em>, 103575.
(<a href="https://doi.org/10.1016/j.artint.2021.103575">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider distributed optimization with degenerate loss functions, where the optimal sets of local loss functions have a non-empty intersection. This regime often arises in optimizing large-scale multi-agent AI systems (e.g., deep learning systems), where the number of trainable weights far exceeds the number of training samples, leading to highly degenerate loss surfaces. Under appropriate conditions, we prove that distributed gradient descent in this case converges even when communication is arbitrarily less frequent, which is not the case for non-degenerate loss functions. Moreover, we quantitatively analyze the convergence rate, as well as the communication and computation trade-off, providing insights into designing efficient distributed optimization algorithms. Our theoretical findings are confirmed by both distributed convex optimization and deep learning experiments.},
  archive      = {J_AIJ},
  author       = {Chi Zhang and Qianxiao Li},
  doi          = {10.1016/j.artint.2021.103575},
  journal      = {Artificial Intelligence},
  pages        = {103575},
  shortjournal = {Artif. Intell.},
  title        = {Distributed optimization for degenerate loss functions arising from over-parameterization},
  volume       = {301},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Pairwise symmetry reasoning for multi-agent path finding
search. <em>AIJ</em>, <em>301</em>, 103574. (<a
href="https://doi.org/10.1016/j.artint.2021.103574">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-Agent Path Finding (MAPF) is a challenging combinatorial problem that asks us to plan collision-free paths for a team of cooperative agents. In this work, we show that one of the reasons why MAPF is so hard to solve is due to a phenomenon called pairwise symmetry, which occurs when two agents have many different paths to their target locations, all of which appear promising, but every combination of them results in a collision. We identify several classes of pairwise symmetries and show that each one arises commonly in practice and can produce an exponential explosion in the space of possible collision resolutions , leading to unacceptable runtimes for current state-of-the-art (bounded-sub)optimal MAPF algorithms. We propose a variety of reasoning techniques that detect the symmetries efficiently as they arise and resolve them by using specialized constraints to eliminate all permutations of pairwise colliding paths in a single branching step. We implement these ideas in the context of a leading optimal MAPF algorithm CBS and show that the addition of the symmetry reasoning techniques can have a dramatic positive effect on its performance — we report a reduction in the number of node expansions by up to four orders of magnitude and an increase in scalability by up to thirty times. These gains allow us to solve to optimality a variety of challenging MAPF instances previously considered out of reach for CBS.},
  archive      = {J_AIJ},
  author       = {Jiaoyang Li and Daniel Harabor and Peter J. Stuckey and Hang Ma and Graeme Gange and Sven Koenig},
  doi          = {10.1016/j.artint.2021.103574},
  journal      = {Artificial Intelligence},
  pages        = {103574},
  shortjournal = {Artif. Intell.},
  title        = {Pairwise symmetry reasoning for multi-agent path finding search},
  volume       = {301},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). SAT competition 2020. <em>AIJ</em>, <em>301</em>, 103572.
(<a href="https://doi.org/10.1016/j.artint.2021.103572">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The SAT Competitions constitute a well-established series of yearly open international algorithm implementation competitions, focusing on the Boolean satisfiability (or propositional satisfiability, SAT) problem. In this article, we provide a detailed account on the 2020 instantiation of the SAT Competition, including the new competition tracks and benchmark selection procedures, overview of solving strategies implemented in top-performing solvers, and a detailed analysis of the empirical data obtained from running the competition.},
  archive      = {J_AIJ},
  author       = {Nils Froleyks and Marijn Heule and Markus Iser and Matti Järvisalo and Martin Suda},
  doi          = {10.1016/j.artint.2021.103572},
  journal      = {Artificial Intelligence},
  pages        = {103572},
  shortjournal = {Artif. Intell.},
  title        = {SAT competition 2020},
  volume       = {301},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Local and global explanations of agent behavior: Integrating
strategy summaries with saliency maps. <em>AIJ</em>, <em>301</em>,
103571. (<a href="https://doi.org/10.1016/j.artint.2021.103571">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With advances in reinforcement learning (RL), agents are now being developed in high-stakes application domains such as healthcare and transportation. Explaining the behavior of these agents is challenging, as the environments in which they act have large state spaces, and their decision-making can be affected by delayed rewards, making it difficult to analyze their behavior. To address this problem, several approaches have been developed. Some approaches attempt to convey the global behavior of the agent, describing the actions it takes in different states. Other approaches devised local explanations which provide information regarding the agent&#39;s decision-making in a particular state. In this paper, we combine global and local explanation methods, and evaluate their joint and separate contributions, providing (to the best of our knowledge) the first user study of combined local and global explanations for RL agents. Specifically, we augment strategy summaries that extract important trajectories of states from simulations of the agent with saliency maps which show what information the agent attends to. Our results show that the choice of what states to include in the summary (global information) strongly affects people&#39;s understanding of agents: participants shown summaries that included important states significantly outperformed participants who were presented with agent behavior in a set of world-states that are likely to appear during gameplay. We find mixed results with respect to augmenting demonstrations with saliency maps (local information), as the addition of saliency maps, in the form of raw heat maps, did not significantly improve performance in most cases. However, we do find some evidence that saliency maps can help users better understand what information the agent relies on during its decision-making, suggesting avenues for future work that can further improve explanations of RL agents.},
  archive      = {J_AIJ},
  author       = {Tobias Huber and Katharina Weitz and Elisabeth André and Ofra Amir},
  doi          = {10.1016/j.artint.2021.103571},
  journal      = {Artificial Intelligence},
  pages        = {103571},
  shortjournal = {Artif. Intell.},
  title        = {Local and global explanations of agent behavior: Integrating strategy summaries with saliency maps},
  volume       = {301},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Using state abstractions to compute personalized contrastive
explanations for AI agent behavior. <em>AIJ</em>, <em>301</em>, 103570.
(<a href="https://doi.org/10.1016/j.artint.2021.103570">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There is a growing interest within the AI research community in developing autonomous systems capable of explaining their behavior to users. However, the problem of computing explanations for users of different levels of expertise has received little research attention. We propose an approach for addressing this problem by representing the user&#39;s understanding of the task as an abstraction of the domain model that the planner uses. We present algorithms for generating minimal explanations in cases where this abstract human model is not known. We reduce the problem of generating an explanation to a search over the space of abstract models and show that while the complete problem is NP-hard, a greedy algorithm can provide good approximations of the optimal solution. We empirically show that our approach can efficiently compute explanations for a variety of problems and also perform user studies to test the utility of state abstractions in explanations.},
  archive      = {J_AIJ},
  author       = {Sarath Sreedharan and Siddharth Srivastava and Subbarao Kambhampati},
  doi          = {10.1016/j.artint.2021.103570},
  journal      = {Artificial Intelligence},
  pages        = {103570},
  shortjournal = {Artif. Intell.},
  title        = {Using state abstractions to compute personalized contrastive explanations for AI agent behavior},
  volume       = {301},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A general multi-agent epistemic planner based on
higher-order belief change. <em>AIJ</em>, <em>301</em>, 103562. (<a
href="https://doi.org/10.1016/j.artint.2021.103562">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, multi-agent epistemic planning has received attention from both dynamic logic and planning communities. Existing implementations of multi-agent epistemic planning are based on compilation into classical planning and suffer from various limitations, such as generating only linear plans, restriction to public actions, and incapability to handle disjunctive beliefs. In this paper, we consider centralized multi-agent epistemic planning from the viewpoint of a third person who coordinates all the agents to achieve the goal. We treat contingent planning, resulting in nonlinear plans. We model private actions and hence handle beliefs, formalized with the multi-agent KD45 logic. We handle static propositional common knowledge, which we call constraints. For such planning settings, we propose a general representation framework where the initial knowledge base (KB) and the goal, the preconditions and effects of actions can be arbitrary KD45 n formulas, and the solution is an action tree branching on sensing results. In this framework, the progression of KBs w.r.t. actions is achieved through the operation of belief revision or update on KD45 n formulas, that is, higher-order belief revision or update. To support efficient reasoning and progression, we make use of a normal form for KD45 n called alternating cover disjunctive formulas (ACDFs). We propose reasoning, revision and update algorithms for ACDFs. Based on these algorithms, adapting the PrAO algorithm for contingent planning from the literature, we implemented a multi-agent epistemic planner called MEPK. Our experimental results show the viability of our approach.},
  archive      = {J_AIJ},
  author       = {Hai Wan and Biqing Fang and Yongmei Liu},
  doi          = {10.1016/j.artint.2021.103562},
  journal      = {Artificial Intelligence},
  pages        = {103562},
  shortjournal = {Artif. Intell.},
  title        = {A general multi-agent epistemic planner based on higher-order belief change},
  volume       = {301},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Path-length analysis for grid-based path planning.
<em>AIJ</em>, <em>301</em>, 103560. (<a
href="https://doi.org/10.1016/j.artint.2021.103560">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In video games and robotics, one often discretizes a continuous 2D environment into a regular grid with blocked and unblocked cells and then finds shortest paths for the agents on the resulting grid graph. Shortest grid paths, of course, are not necessarily true shortest paths in the continuous 2D environment. In this article, we therefore study how much longer a shortest grid path can be than a corresponding true shortest path on all regular grids with blocked and unblocked cells that tessellate continuous 2D environments. We study 5 different vertex connectivities that result from both different tessellations and different definitions of the neighbors of a vertex. Our path-length analysis yields either tight or asymptotically tight worst-case bounds in a unified framework. Our results show that the percentage by which a shortest grid path can be longer than a corresponding true shortest path decreases as the vertex connectivity increases. Our path-length analysis is topical because it determines the largest path-length reduction possible for any-angle path-planning algorithms (and thus their benefit), a class of path-planning algorithms in artificial intelligence and robotics that has become popular.},
  archive      = {J_AIJ},
  author       = {James P. Bailey and Alex Nash and Craig A. Tovey and Sven Koenig},
  doi          = {10.1016/j.artint.2021.103560},
  journal      = {Artificial Intelligence},
  pages        = {103560},
  shortjournal = {Artif. Intell.},
  title        = {Path-length analysis for grid-based path planning},
  volume       = {301},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Foundations of explanations as model reconciliation.
<em>AIJ</em>, <em>301</em>, 103558. (<a
href="https://doi.org/10.1016/j.artint.2021.103558">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Past work on plan explanations primarily involved the AI system explaining the correctness of its plan and the rationale for its decision in terms of its own model. Such soliloquy is wholly inadequate in most realistic scenarios where users have domain and task models that differ from that used by the AI system. We posit that the explanations are best studied in light of these differing models. In particular, we show how explanation can be seen as a “model reconciliation problem” (MRP), where the AI system in effect suggests changes to the user&#39;s mental model so as to make its plan be optimal with respect to that changed user model. We will study the properties of such explanations, present algorithms for automatically computing them, discuss relevant extensions to the basic framework, and evaluate the performance of the proposed algorithms both empirically and through controlled user studies.},
  archive      = {J_AIJ},
  author       = {Sarath Sreedharan and Tathagata Chakraborti and Subbarao Kambhampati},
  doi          = {10.1016/j.artint.2021.103558},
  journal      = {Artificial Intelligence},
  pages        = {103558},
  shortjournal = {Artif. Intell.},
  title        = {Foundations of explanations as model reconciliation},
  volume       = {301},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-instance learning of pretopological spaces to model
complex propagation phenomena: Application to lexical taxonomy learning.
<em>AIJ</em>, <em>301</em>, 103556. (<a
href="https://doi.org/10.1016/j.artint.2021.103556">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the problem of learning the concept of propagation in the theoretical formalism of pretopology, and then applying this methodology for the well-known problem of learning Lexical Taxonomy. The theory of pretopology, among others, aims at modeling complex relations between sets of entities. The use of such fine-grained modeling implies limitations in terms of scalability. However, it allows for a more accurate capture of real-world relationships, such as the hypernymy relation, by modeling the task of relation extraction as a propagation model under certain structuring constraints, as opposed to traditional approaches that are limited to detecting relations between pairs of elements without considering knowledge on the expected structuring. Our proposal is to define the pseudo-closure operator (modeling the concept of propagation) as a logical combination of heterogeneous neighborhoods, or sources. It allows the learning of models that exploit, for example, the knowledge acquired by both statistical and numerical approaches. We show that the learning of such an operator falls into the Multiple Instance (MI) framework, where the learning process is performed on bags of instances instead of individual instances. Although this framework is well suited for this task, using it for learning a pretopological space leads to a set of bags whose size is exponential. To overcome this problem, we propose a learning method (LPSMI) based on a low estimate of the bags covered by a concept under construction. We first propose an experimental validation of our method, through the simulation of percolation processes (typically forest fires) learned with pretopological propagation models. It reveals that the proposed MI approach is particularly efficient on propagation model recognition task. We then provide a real-world contribution to the Lexical Taxonomy learning task, by modeling this task as a complex (semantic) propagation problem. We propose a very generic framework for training models combining various existing methods for learning Lexical Taxonomies (statistical, pattern-based and embedding-based).},
  archive      = {J_AIJ},
  author       = {G. Caillaut and G. Cleuziou},
  doi          = {10.1016/j.artint.2021.103556},
  journal      = {Artificial Intelligence},
  pages        = {103556},
  shortjournal = {Artif. Intell.},
  title        = {Multi-instance learning of pretopological spaces to model complex propagation phenomena: Application to lexical taxonomy learning},
  volume       = {301},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Abstraction for non-ground answer set programs.
<em>AIJ</em>, <em>300</em>, 103563. (<a
href="https://doi.org/10.1016/j.artint.2021.103563">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstraction is an important technique utilized by humans in model building and problem solving, in order to figure out key elements and relevant details of a world of interest. This naturally has led to investigations of using abstraction in AI and Computer Science to simplify problems, especially in the design of intelligent agents and automated problem solving. By omitting details, scenarios are reduced to ones that are easier to deal with and to understand, where further details are added back only when they matter. Despite the fact that abstraction is a powerful technique, it has not been considered much in the context of nonmonotonic knowledge representation and reasoning , and specifically not in Answer Set Programming (ASP), apart from some related simplification methods. In this work, we introduce a notion for abstracting from the domain of an ASP program such that the domain size shrinks while the set of answer sets (i.e., models) of the program is over-approximated. To achieve the latter, the program is transformed into an abstract program over the abstract domain while preserving the structure of the rules. We show in elaboration how this can be also achieved for single or multiple sub-domains (sorts) of a domain, and in case of structured domains like grid environments in which structure should be preserved. Furthermore, we introduce an abstraction-&amp;-refinement methodology that makes it possible to start with an initial abstraction and to achieve automatically an abstraction with an associated abstract answer set that matches an answer set of the original program, provided that the program is satisfiable. Experiments based on prototypical implementations reveal the potential of the approach for problem analysis, by its ability to focus on the parts of the program that cause unsatisfiability and by achieving concrete abstract answer sets that merely reflect relevant details. This makes domain abstraction an interesting topic of research whose further use in important areas like Explainable AI remains to be explored.},
  archive      = {J_AIJ},
  author       = {Zeynep G. Saribatur and Thomas Eiter and Peter Schüller},
  doi          = {10.1016/j.artint.2021.103563},
  journal      = {Artificial Intelligence},
  pages        = {103563},
  shortjournal = {Artif. Intell.},
  title        = {Abstraction for non-ground answer set programs},
  volume       = {300},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The complexity landscape of decompositional parameters for
ILP: Programs with few global variables and constraints. <em>AIJ</em>,
<em>300</em>, 103561. (<a
href="https://doi.org/10.1016/j.artint.2021.103561">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Integer Linear Programming (ILP) has a broad range of applications in various areas of artificial intelligence . Yet in spite of recent advances, we still lack a thorough understanding of which structural restrictions make ILP tractable. Here we study ILP instances consisting of a small number of “global” variables and/or constraints such that the remaining part of the instance consists of small and otherwise independent components; this is captured in terms of a structural measure we call fracture backdoors which generalizes, for instance, the well-studied class of N -fold ILP instances. Our main contributions can be divided into three parts. First, we formally develop fracture backdoors and obtain exact and approximation algorithms for computing these. Second, we exploit these backdoors to develop several new parameterized algorithms for ILP; the performance of these algorithms will naturally scale based on the number of global variables or constraints in the instance. Finally, we complement the developed algorithms with matching lower bounds. Altogether, our results paint a near-complete complexity landscape of ILP with respect to fracture backdoors. 1},
  archive      = {J_AIJ},
  author       = {Pavel Dvořák and Eduard Eiben and Robert Ganian and Dušan Knop and Sebastian Ordyniak},
  doi          = {10.1016/j.artint.2021.103561},
  journal      = {Artificial Intelligence},
  pages        = {103561},
  shortjournal = {Artif. Intell.},
  title        = {The complexity landscape of decompositional parameters for ILP: Programs with few global variables and constraints},
  volume       = {300},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Strategic reasoning with a bounded number of resources: The
quest for tractability. <em>AIJ</em>, <em>300</em>, 103557. (<a
href="https://doi.org/10.1016/j.artint.2021.103557">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The resource-bounded alternating-time temporal logic RB ± ATL combines strategic reasoning with reasoning about resources. Its model-checking problem is known to be 2exptime -complete (the same as its proper extension RB ± ATL ⁎ ) and fragments have been identified to lower the complexity. In this work, we consider the variant RB ± ATL + that allows for Boolean combinations of path formulae starting with single temporal operators, but restricted to a single resource, providing an interesting trade-off between temporal expressivity and resource analysis. We show that the model-checking problem for RB ± ATL + restricted to a single agent and a single resource is Δ 2 P Δ2P -complete, hence the same as for the standard branching-time temporal logic CTL + . In this case reasoning about resources comes at no extra computational cost. When a fixed finite set of linear-time temporal operators is considered, the model-checking problem drops to ptime , which includes the special case of RB ± ATL restricted to a single agent and a single resource. Furthermore, we show that, with an arbitrary number of agents and a fixed number of resources, the model-checking problem for RB ± ATL + can be solved in exptime using a sophisticated Turing reduction to the parity game problem for alternating vector addition systems with states (AVASS).},
  archive      = {J_AIJ},
  author       = {Francesco Belardinelli and Stéphane Demri},
  doi          = {10.1016/j.artint.2021.103557},
  journal      = {Artificial Intelligence},
  pages        = {103557},
  shortjournal = {Artif. Intell.},
  title        = {Strategic reasoning with a bounded number of resources: The quest for tractability},
  volume       = {300},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Hard choices in artificial intelligence. <em>AIJ</em>,
<em>300</em>, 103555. (<a
href="https://doi.org/10.1016/j.artint.2021.103555">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As AI systems are integrated into high stakes social domains, researchers now examine how to design and operate them in a safe and ethical manner. However, the criteria for identifying and diagnosing safety risks in complex social contexts remain unclear and contested. In this paper, we examine the vagueness in debates about the safety and ethical behavior of AI systems. We show how this vagueness cannot be resolved through mathematical formalism alone, instead requiring deliberation about the politics of development as well as the context of deployment. Drawing from a new sociotechnical lexicon, we redefine vagueness in terms of distinct design challenges at key stages in AI system development. The resulting framework of Hard Choices in Artificial Intelligence (HCAI) empowers developers by 1) identifying points of overlap between design decisions and major sociotechnical challenges; 2) motivating the creation of stakeholder feedback channels so that safety issues can be exhaustively addressed. As such, HCAI contributes to a timely debate about the status of AI development in democratic societies, arguing that deliberation should be the goal of AI Safety, not just the procedure by which it is ensured.},
  archive      = {J_AIJ},
  author       = {Roel Dobbe and Thomas Krendl Gilbert and Yonatan Mintz},
  doi          = {10.1016/j.artint.2021.103555},
  journal      = {Artificial Intelligence},
  pages        = {103555},
  shortjournal = {Artif. Intell.},
  title        = {Hard choices in artificial intelligence},
  volume       = {300},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Why bad coffee? Explaining BDI agent behaviour with
valuings. <em>AIJ</em>, <em>300</em>, 103554. (<a
href="https://doi.org/10.1016/j.artint.2021.103554">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An important issue in deploying an autonomous system is how to enable human users and stakeholders to develop an appropriate level of trust in the system. It has been argued that a crucial mechanism to enable appropriate trust is the ability of a system to explain its behaviour. Obviously, such explanations need to be comprehensible to humans. Due to the perceived similarity in functioning between humans and autonomous systems, we argue that it makes sense to build on the results of extensive research in social sciences that explores how humans explain their behaviour. Using similar concepts for explanation is argued to help with comprehensibility , since the concepts are familiar. Following work in the social sciences, we propose the use of a folk-psychological model that utilises beliefs, desires, and “valuings”. We propose a formal framework for constructing explanations of the behaviour of an autonomous system , present an (implemented) algorithm for giving explanations, and present evaluation results.},
  archive      = {J_AIJ},
  author       = {Michael Winikoff and Galina Sidorenko and Virginia Dignum and Frank Dignum},
  doi          = {10.1016/j.artint.2021.103554},
  journal      = {Artificial Intelligence},
  pages        = {103554},
  shortjournal = {Artif. Intell.},
  title        = {Why bad coffee? explaining BDI agent behaviour with valuings},
  volume       = {300},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Incremental computation for structured argumentation over
dynamic DeLP knowledge bases. <em>AIJ</em>, <em>300</em>, 103553. (<a
href="https://doi.org/10.1016/j.artint.2021.103553">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Structured argumentation systems, and their implementation, represent an important research subject in the area of Knowledge Representation and Reasoning . Structured argumentation advances over abstract argumentation frameworks by providing the internal construction of the arguments that are usually defined by a set of (strict and defeasible) rules. By considering the structure of arguments, it becomes possible to analyze reasons for and against a conclusion, and the warrant status of such a claim in the context of a knowledge base represents the main output of a dialectical process. Computing such statuses is a costly process, and any update to the knowledge base could potentially have a huge impact if done naively. In this work, we investigate the case of updates consisting of both additions and removals of pieces of knowledge in the Defeasible Logic Programming (DeLP) framework, first analyzing the complexity of the problem and then identifying conditions under which we can avoid unnecessary computations—central to this is the development of structures ( e.g. graphs) to keep track of which results can potentially be affected by a given update. We introduce a technique for the incremental computation of the warrant statuses of conclusions in DeLP knowledge bases that evolve due to the application of (sets of) updates. We present the results of a thorough experimental evaluation showing that our incremental approach yields significantly faster running times in practice, as well as overall fewer recomputations , even in the case of sets of updates performed simultaneously.},
  archive      = {J_AIJ},
  author       = {Gianvincenzo Alfano and Sergio Greco and Francesco Parisi and Gerardo I. Simari and Guillermo R. Simari},
  doi          = {10.1016/j.artint.2021.103553},
  journal      = {Artificial Intelligence},
  pages        = {103553},
  shortjournal = {Artif. Intell.},
  title        = {Incremental computation for structured argumentation over dynamic DeLP knowledge bases},
  volume       = {300},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Propositional proof systems based on maximum satisfiability.
<em>AIJ</em>, <em>300</em>, 103552. (<a
href="https://doi.org/10.1016/j.artint.2021.103552">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paper describes the use of dual-rail MaxSAT systems to solve Boolean satisfiability (SAT), namely to determine if a set of clauses is satisfiable. The MaxSAT problem is the problem of satisfying the maximum number of clauses in an instance of SAT. The dual-rail encoding adds extra variables for the complements of variables, and allows encoding an instance of SAT as a Horn MaxSAT problem. We discuss three implementations of dual-rail MaxSAT: core-guided systems, minimal hitting set (MaxHS) systems, and MaxSAT resolution inference systems. All three of these can be more efficient than resolution and thus than conflict-driven clause learning (CDCL). All three systems can give polynomial size refutations for the pigeonhole principle, the doubled pigeonhole principle and the mutilated chessboard principles. The dual-rail MaxHS MaxSat system can give polynomial size proofs of the parity principle. However, dual-rail MaxSAT resolution requires exponential size proofs for the parity principle; this is proved by showing that constant depth Frege augmented with the pigeonhole principle can polynomially simulate dual-rail MaxSAT resolution. Consequently, dual-rail MaxSAT resolution does not simulate cutting planes. We further show that core-guided dual-rail MaxSAT and weighted dual-rail MaxSAT resolution polynomially simulate resolution. Finally, we report the results of experiments with core-guided dual-rail MaxSAT and MaxHS dual-rail MaxSAT showing strong performance by these systems.},
  archive      = {J_AIJ},
  author       = {Maria Luisa Bonet and Sam Buss and Alexey Ignatiev and Antonio Morgado and Joao Marques-Silva},
  doi          = {10.1016/j.artint.2021.103552},
  journal      = {Artificial Intelligence},
  pages        = {103552},
  shortjournal = {Artif. Intell.},
  title        = {Propositional proof systems based on maximum satisfiability},
  volume       = {300},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Abstraction in data-sparse task transfer. <em>AIJ</em>,
<em>300</em>, 103551. (<a
href="https://doi.org/10.1016/j.artint.2021.103551">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When a robot adapts a learned task for a novel environment, any changes to objects in the novel environment have an unknown effect on its task execution. For example, replacing an object in a pick-and-place task affects where the robot should target its actions, but does not necessarily affect the underlying action model. In contrast, replacing a tool that the robot will use to complete a task will effectively alter its end-effector pose with respect to the robot&#39;s base coordinate system, and thus the robot&#39;s motion must be replanned accordingly. These examples highlight the relationship among (i) differences between the source and target environments, (ii) the level of abstraction at which a robot&#39;s task model should be represented to enable transfer to the target environment, and (iii) the information needed to ground the abstracted task representation in the target environment. In this article, we present a taxonomy of transfer problems based on this relationship. We also describe a knowledge representation called the Tiered Task Abstraction (TTA) and demonstrate its applicability to a variety of transfer problems in the taxonomy. Our experimental results indicate a trade-off between the generality and data requirements of a task representation, and reinforce the need for multiple transfer methods that operate at different levels of abstraction.},
  archive      = {J_AIJ},
  author       = {Tesca Fitzgerald and Ashok Goel and Andrea Thomaz},
  doi          = {10.1016/j.artint.2021.103551},
  journal      = {Artificial Intelligence},
  pages        = {103551},
  shortjournal = {Artif. Intell.},
  title        = {Abstraction in data-sparse task transfer},
  volume       = {300},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A framework for step-wise explaining how to solve constraint
satisfaction problems. <em>AIJ</em>, <em>300</em>, 103550. (<a
href="https://doi.org/10.1016/j.artint.2021.103550">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We explore the problem of step-wise explaining how to solve constraint satisfaction problems , with a use case on logic grid puzzles. More specifically, we study the problem of explaining the inference steps that one can take during propagation, in a way that is easy to interpret for a person. Thereby, we aim to give the constraint solver explainable agency, which can help in building trust in the solver by being able to understand and even learn from the explanations. The main challenge is that of finding a sequence of simple explanations, where each explanation should aim to be as cognitively easy as possible for a human to verify and understand. This contrasts with the arbitrary combination of facts and constraints that the solver may use when propagating. We propose the use of a cost function to quantify how simple an individual explanation of an inference step is, and identify the explanation-production problem of finding the best sequence of explanations of a CSP. Our approach is agnostic of the underlying constraint propagation mechanisms , and can provide explanations even for inference steps resulting from combinations of constraints. In case multiple constraints are involved, we also develop a mechanism that allows to break the most difficult steps up and thus gives the user the ability to zoom in on specific parts of the explanation. Our proposed algorithm iteratively constructs the explanation sequence by using an optimistic estimate of the cost function to guide the search for the best explanation at each step. Our experiments on logic grid puzzles show the feasibility of the approach in terms of the quality of the individual explanations and the resulting explanation sequences obtained.},
  archive      = {J_AIJ},
  author       = {Bart Bogaerts and Emilio Gamba and Tias Guns},
  doi          = {10.1016/j.artint.2021.103550},
  journal      = {Artificial Intelligence},
  pages        = {103550},
  shortjournal = {Artif. Intell.},
  title        = {A framework for step-wise explaining how to solve constraint satisfaction problems},
  volume       = {300},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Committing to correlated strategies with multiple leaders.
<em>AIJ</em>, <em>300</em>, 103549. (<a
href="https://doi.org/10.1016/j.artint.2021.103549">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We address multi-agent Stackelberg settings involving many leaders and followers. In order to effectively model this kind of interactions, we extend the idea of commitment to correlated strategies to Stackelberg games with multiple leaders and followers. Correlation can be easily implemented by resorting to a device that sends signals to the players, and it also enables the leaders to reach better solutions than those achieved by committing independently. In this setting, a crucial question is how the leaders agree on a correlated-strategy commitment. To this end, we introduce a preliminary agreement stage that implements a natural non-cooperative negotiation protocol. The protocol proposes a correlated strategy to the leaders, who can then decide, in turn, whether to participate in the commitment or defect from it by losing the possibility of being part of the agreement. The goal is to design stable agreements in which no leader defects. We distinguish three solution concepts on the basis of the constraints that they enforce on the agreement reached by the leaders. We provide a comprehensive study of the properties of our solution concepts, in terms of existence, relation with other solution concepts, and computational complexity . As for the computational analysis, we prove that our solutions can be computed in polynomial time for certain classes of succinctly represented games. Interestingly, our results show that, in these games, introducing the agreement stage does not make computing equilibria a more challenging task, as finding a solution in our setting is as hard as computing an optimal correlated equilibrium .},
  archive      = {J_AIJ},
  author       = {Matteo Castiglioni and Alberto Marchesi and Nicola Gatti},
  doi          = {10.1016/j.artint.2021.103549},
  journal      = {Artificial Intelligence},
  pages        = {103549},
  shortjournal = {Artif. Intell.},
  title        = {Committing to correlated strategies with multiple leaders},
  volume       = {300},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Strongly budget balanced auctions for multi-sided markets.
<em>AIJ</em>, <em>300</em>, 103548. (<a
href="https://doi.org/10.1016/j.artint.2021.103548">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In two-sided markets, Myerson and Satterthwaite&#39;s impossibility theorem states that one can not maximize the gain-from-trade while also satisfying truthfulness, individual-rationality and no deficit. Attempts have been made to circumvent Myerson and Satterthwaite&#39;s result by attaining approximately-maximum gain-from-trade: the double-sided auction of McAfee (1992) [35] is truthful and has no deficit — it is weakly-budget-balanced, and the one by Segal-Halevi et al.&#39;s (2016) [38] additionally has no surplus — it is strongly-budget-balanced. They consider two categories of agents — buyers and sellers, where each trade set is composed of a single buyer and a single seller. The practical complexity of applications in areas such as supply chain requires one to look beyond two-sided markets. Common requirements are for: buyers trading with multiple sellers of different or identical items, buyers trading with sellers through transporters and mediators, and sellers trading with multiple buyers. We attempt to address these settings. We generalize Segal-Halevi et al. (2016)&#39;s [38] strongly-budget-balanced double-sided auction setting to a multilateral market where each trade set is composed of any number of agent categories. Our generalization refines the notion of competition in multi-sided auctions by introducing the concepts of external competition and trade reduction. We also show an obviously-truthful implementation of our auction using multiple ascending prices.},
  archive      = {J_AIJ},
  author       = {Dvir Gilor and Rica Gonen and Erel Segal-Halevi},
  doi          = {10.1016/j.artint.2021.103548},
  journal      = {Artificial Intelligence},
  pages        = {103548},
  shortjournal = {Artif. Intell.},
  title        = {Strongly budget balanced auctions for multi-sided markets},
  volume       = {300},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An improved approximation algorithm for maximin shares.
<em>AIJ</em>, <em>300</em>, 103547. (<a
href="https://doi.org/10.1016/j.artint.2021.103547">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fair division is a fundamental problem in various multi-agent settings, where the goal is to divide a set of resources among agents in a fair manner. We study the case where m indivisible items need to be divided among n agents with additive valuations using the popular fairness notion of maximin share (MMS). An MMS allocation provides each agent a bundle worth at least her maximin share. While it is known that such an allocation need not exist [1] , [2] , a series of remarkable work [1] , [3] , [4] , [5] , [6] provided approximation algorithms for a 2 3 23 -MMS allocation in which each agent receives a bundle worth at least 2 3 23 times her maximin share. More recently, Ghodsi et al. [7] showed the existence of a 3 4 34 -MMS allocation and a PTAS to find a ( 3 4 − ϵ 34−ϵ )-MMS allocation for an ϵ &gt; 0 ϵ&amp;gt; 0 . Most of the previous works utilize intricate algorithms and require agents&#39; approximate MMS values, which are computationally expensive to obtain. In this paper, we develop a new approach that gives a simple algorithm for showing the existence of a 3 4 34 -MMS allocation. Furthermore, our approach is powerful enough to be easily extended in two directions: First, we get a strongly polynomial time algorithm to find a 3 4 34 -MMS allocation, where we do not need to approximate the MMS values at all. Second, we show that there always exists a ( 3 4 + 1 12 n ) (34+112n) -MMS allocation, improving the best previous factor. This improves the approximation guarantee, most notably for small n . We note that 3 4 34 was the best factor known for n &gt; 4 n&amp;gt; 4 .},
  archive      = {J_AIJ},
  author       = {Jugal Garg and Setareh Taki},
  doi          = {10.1016/j.artint.2021.103547},
  journal      = {Artificial Intelligence},
  pages        = {103547},
  shortjournal = {Artif. Intell.},
  title        = {An improved approximation algorithm for maximin shares},
  volume       = {300},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Kandinsky patterns. <em>AIJ</em>, <em>300</em>, 103546. (<a
href="https://doi.org/10.1016/j.artint.2021.103546">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Kandinsky Figures and Kandinsky Patterns are mathematically describable, simple, self-contained hence controllable synthetic test data sets for the development, validation and training of visual tasks and explainability in artificial intelligence (AI). Whilst Kandinsky Patterns have these computationally manageable properties, they are at the same time easily distinguishable by human observers. Consequently, controlled patterns can be described by both humans and computers. We define a Kandinsky Pattern as a set of Kandinsky Figures, where for each figure an “infallible authority” defines that the figure belongs to the Kandinsky Pattern. With this simple principle we build training and validation data sets for testing explainability, interpretability and context learning. In this paper we describe the basic idea and some underlying principles of Kandinsky Patterns. We provide a Github repository and invite the international AI research community to a challenge to experiment with our Kandinsky Patterns. The goal is to help expand and advance the field of AI, and in particular to contribute to the increasingly important field of explainable AI .},
  archive      = {J_AIJ},
  author       = {Heimo Müller and Andreas Holzinger},
  doi          = {10.1016/j.artint.2021.103546},
  journal      = {Artificial Intelligence},
  pages        = {103546},
  shortjournal = {Artif. Intell.},
  title        = {Kandinsky patterns},
  volume       = {300},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Solving hybrid boolean constraints in continuous space via
multilinear fourier expansions. <em>AIJ</em>, <em>299</em>, 103559. (<a
href="https://doi.org/10.1016/j.artint.2021.103559">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Boolean SATisfiability problem (SAT) is of central importance in computer science. Although SAT is known to be NP-complete, progress on the engineering side—especially that of Conflict-Driven Clause Learning (CDCL) and Local Search SAT solvers—has been remarkable. Yet, while SAT solvers, aimed at solving industrial-scale benchmarks in Conjunctive Normal Form ( CNF ), have become quite mature, SAT solvers that are effective on other types of constraints (e.g., cardinality constraints and XOR s) are less well-studied; a general approach to handling non- CNF constraints is still lacking. To address the issue above, we design FourierSAT , 1 an incomplete SAT solver based on Fourier Analysis (also known as Walsh-Fourier Transform) of Boolean functions , a technique to represent Boolean functions by multilinear polynomials. By such a reduction to continuous optimization , we propose an algebraic framework for solving systems consisting of different types of constraints. The idea is to leverage gradient information to guide the search process in the direction of local improvements. We show this reduction enjoys interesting theoretical properties. Empirical results demonstrate that FourierSAT can be a useful complement to other solvers on certain classes of benchmarks.},
  archive      = {J_AIJ},
  author       = {Anastasios Kyrillidis and Anshumali Shrivastava and Moshe Y. Vardi and Zhiwei Zhang},
  doi          = {10.1016/j.artint.2021.103559},
  journal      = {Artificial Intelligence},
  pages        = {103559},
  shortjournal = {Artif. Intell.},
  title        = {Solving hybrid boolean constraints in continuous space via multilinear fourier expansions},
  volume       = {299},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A budget-limited mechanism for category-aware crowdsourcing
of multiple-choice tasks. <em>AIJ</em>, <em>299</em>, 103538. (<a
href="https://doi.org/10.1016/j.artint.2021.103538">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Crowdsourcing harnesses human effort to solve computer-hard problems such as photo tagging, entity resolution and sentiment analysis . Such tasks often have different levels of difficulty and workers have varying levels of skill at completing them. With a limited budget, it is important to wisely allocate the spend among the tasks and workers such that the overall outcome is as good as possible. Most existing work addresses this budget allocation problem by assuming that workers have a single level of ability for all tasks and each task involves a choice between just two alternatives. However, this neglects the fact that many crowdsourcing applications ask workers to choose between multiple alternatives and that different tasks can belong to a variety of diverse categories. Moreover, workers may have varying abilities across these categories. For example, a science enthusiast is likely to do better than a cinephile when answering a question such as “selecting the melting point of Copper from 1) 327 degrees Celcius, 2) 1085 degrees Celcius and 3) 1495 degrees Celcius”. And a cinephile is likely to perform better in tasks related to movies such as “how many episodes of Fooly Cooly were ever made? 1) 6 2) 7 and 3) 8”. To incorporate such category-aware crowdsourcing of multiple-choice tasks, we model the interaction between the crowdsource campaign initiator and the workers as a procurement auction and propose a computationally efficient mechanism, INCARE, to achieve high-quality outcomes given a limited budget. We prove that INCARE is budget feasible, incentive compatible and individually rational. We also prove that INCARE can achieve a bounded approximation ratio for the optimal budget allocation mechanism with full knowledge of workers&#39; true costs. Finally, our numerical simulations, on both real and synthetic data, show that, compared to the state of the art, INCARE: (i) can improve the accuracy by up to 98\%, given a limited budget; and (ii) is significantly more robust to inaccuracies in prior information about each worker&#39;s ability and each task&#39;s difficulty.},
  archive      = {J_AIJ},
  author       = {Yuan Luo and Nicholas R. Jennings},
  doi          = {10.1016/j.artint.2021.103538},
  journal      = {Artificial Intelligence},
  pages        = {103538},
  shortjournal = {Artif. Intell.},
  title        = {A budget-limited mechanism for category-aware crowdsourcing of multiple-choice tasks},
  volume       = {299},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Popularity-similarity random SAT formulas. <em>AIJ</em>,
<em>299</em>, 103537. (<a
href="https://doi.org/10.1016/j.artint.2021.103537">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the last decades, we have witnessed a remarkable success of algorithms solving the Boolean Satisfiability problem (SAT) on instances encoding application or real-world problems arising from a very diverse number of domains, such as hardware and software verification , planning or cryptography. These algorithms are the so known Conflict-Driven Clause Learning (CDCL) SAT solvers. Interestingly enough, the reasons for the success of these solvers on this diverse range of problems are not completely understood yet. A common issue when facing this open challenge is the heterogeneity of this set of benchmarks. Another problem is the limited number of existing instances. In this context, random models of SAT formulas capturing features shared by the majority of these application benchmarks become crucial, for both theoretical and practical purposes. On the one hand, it is undoubtedly necessary to have random models where theoretical properties, like hardness, can be studied. Therefore, realistic random SAT models may contribute to explain the success of these solvers on these industrial problems. On the other hand, the limited number of benchmarks and their hardness in practice makes the evaluation of new solving techniques a costly task. Therefore, these realistic random SAT generators can provide an unlimited number of pseudo-industrial random SAT instances with some desired properties. In this work, we present a random SAT instances generator based on the notion of locality . This notion is complementary to the popularity of variables, which is present in the scale-free structure, observable in actual application problems and achievable by previous generators. Our random SAT model combines both locality and popularity, and we show that they are two decisive dimensions of attractiveness among the variables of a formula, and how CDCL SAT solvers take advantage of them. Locality is closely related to the community structure, another important feature of application SAT benchmarks, which is indirectly achieved by this model. To the best of our knowledge, this is the first random SAT model that generates both scale-free structure and community structure at once.},
  archive      = {J_AIJ},
  author       = {Jesús Giráldez-Cru and Jordi Levy},
  doi          = {10.1016/j.artint.2021.103537},
  journal      = {Artificial Intelligence},
  pages        = {103537},
  shortjournal = {Artif. Intell.},
  title        = {Popularity-similarity random SAT formulas},
  volume       = {299},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). First-order rewritability of ontology-mediated queries in
linear temporal logic. <em>AIJ</em>, <em>299</em>, 103536. (<a
href="https://doi.org/10.1016/j.artint.2021.103536">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We investigate ontology-based data access to temporal data. We consider temporal ontologies given in linear temporal logic LTL interpreted over discrete time ( Z , (Z, &amp;lt; ) . Queries are given in LTL or MFO ( MFO(&amp;lt; ) , monadic first-order logic with a built-in linear order. Our concern is first-order rewritability of ontology-mediated queries (OMQs) consisting of a temporal ontology and a query. By taking account of the temporal operators used in the ontology and distinguishing between ontologies given in full LTL and its core, Krom and Horn fragments, we identify a hierarchy of OMQs with atomic queries by proving rewritability into either FO ( FO(&amp;lt; ) , first-order logic with the built-in linear order, or FO ( FO(&amp;lt; , ≡) , which extends FO ( FO(&amp;lt; ) with the standard arithmetic predicates x ≡ 0 ( mod n ) x≡0(modn) , for any fixed n &gt; 1 n&amp;gt; 1 , or FO ( RPR ) FO(RPR) , which extends FO ( FO(&amp;lt; ) with relational primitive recursion. In terms of circuit complexity, FO ( FO(&amp;lt; , ≡) - and FO ( RPR ) FO(RPR) -rewritability guarantee OMQ answering in uniform and, respectively, . We obtain similar hierarchies for more expressive types of queries: positive LTL -formulas, monotone MFO ( MFO(&amp;lt; ) - and arbitrary MFO ( MFO(&amp;lt; ) -formulas. Our results are directly applicable if the temporal data to be accessed is one-dimensional; moreover, they lay foundations for investigating ontology-based access using combinations of temporal and description logics over two-dimensional temporal data.},
  archive      = {J_AIJ},
  author       = {Alessandro Artale and Roman Kontchakov and Alisa Kovtunova and Vladislav Ryzhikov and Frank Wolter and Michael Zakharyaschev},
  doi          = {10.1016/j.artint.2021.103536},
  journal      = {Artificial Intelligence},
  pages        = {103536},
  shortjournal = {Artif. Intell.},
  title        = {First-order rewritability of ontology-mediated queries in linear temporal logic},
  volume       = {299},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Reward is enough. <em>AIJ</em>, <em>299</em>, 103535. (<a
href="https://doi.org/10.1016/j.artint.2021.103535">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article we hypothesise that intelligence, and its associated abilities, can be understood as subserving the maximisation of reward. Accordingly, reward is enough to drive behaviour that exhibits abilities studied in natural and artificial intelligence, including knowledge, learning, perception, social intelligence, language, generalisation and imitation. This is in contrast to the view that specialised problem formulations are needed for each ability, based on other signals or objectives. Furthermore, we suggest that agents that learn through trial and error experience to maximise reward could learn behaviour that exhibits most if not all of these abilities, and therefore that powerful reinforcement learning agents could constitute a solution to artificial general intelligence.},
  archive      = {J_AIJ},
  author       = {David Silver and Satinder Singh and Doina Precup and Richard S. Sutton},
  doi          = {10.1016/j.artint.2021.103535},
  journal      = {Artificial Intelligence},
  pages        = {103535},
  shortjournal = {Artif. Intell.},
  title        = {Reward is enough},
  volume       = {299},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Levels of explainable artificial intelligence for
human-aligned conversational explanations. <em>AIJ</em>, <em>299</em>,
103525. (<a href="https://doi.org/10.1016/j.artint.2021.103525">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Over the last few years there has been rapid research growth into eXplainable Artificial Intelligence (XAI) and the closely aligned Interpretable Machine Learning (IML). Drivers for this growth include recent legislative changes and increased investments by industry and governments, along with increased concern from the general public. People are affected by autonomous decisions every day and the public need to understand the decision-making process to accept the outcomes. However, the vast majority of the applications of XAI/IML are focused on providing low-level ‘narrow’ explanations of how an individual decision was reached based on a particular datum. While important, these explanations rarely provide insights into an agent&#39;s: beliefs and motivations; hypotheses of other (human, animal or AI) agents&#39; intentions; interpretation of external cultural expectations; or, processes used to generate its own explanation. Yet all of these factors, we propose, are essential to providing the explanatory depth that people require to accept and trust the AI&#39;s decision-making. This paper aims to define levels of explanation and describe how they can be integrated to create a human-aligned conversational explanation system. In so doing, this paper will survey current approaches and discuss the integration of different technologies to achieve these levels with Broad eXplainable Artificial Intelligence (Broad-XAI) , and thereby move towards high-level ‘strong’ explanations.},
  archive      = {J_AIJ},
  author       = {Richard Dazeley and Peter Vamplew and Cameron Foale and Charlotte Young and Sunil Aryal and Francisco Cruz},
  doi          = {10.1016/j.artint.2021.103525},
  journal      = {Artificial Intelligence},
  pages        = {103525},
  shortjournal = {Artif. Intell.},
  title        = {Levels of explainable artificial intelligence for human-aligned conversational explanations},
  volume       = {299},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Deciding koopman’s qualitative probability. <em>AIJ</em>,
<em>299</em>, 103524. (<a
href="https://doi.org/10.1016/j.artint.2021.103524">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In their recent paper in this journal, Delgrande, Renne and Sack study qualitative probability and discuss its role in Artificial Intelligence . Building on related work by de Finetti, Scott, Segerberg and others, the authors provide general axioms for qualitative probability. In this paper we investigate Koopman&#39;s conditional qualitative probability from the computational viewpoint. An important part of his work, published in the Annals of Mathematics in 1940-1941, deals with finite conjunctions K K of statements of the form “the probability of a given h does not exceed the probability of b given k ”, with a , b , h , k a, b, h, k elements of a boolean algebra . Upon coding these elements by boolean formulas , we provide a decision procedure to check the consistency of any such K K . As an immediate consequence, also inferences in Koopman&#39;s probability theory are shown to be computable. These problems of qualitative probability theory significantly generalize Boole&#39;s (typically quantitative ) problem of estimating the possible probabilities of a new event given the probabilities of other events. Boole&#39;s classical problem today is known as the optimization version of the probabilistic satisfiability problem PSAT. In 1986 Nilsson published an influential paper on this subject in this journal. The scope of our results is much larger than that of PSAT, because Koopman&#39;s conjunctions K K also formalize the key notion of independence. Some familiarity with boolean logic and finite boolean algebras is the only prerequisite for this paper.},
  archive      = {J_AIJ},
  author       = {Daniele Mundici},
  doi          = {10.1016/j.artint.2021.103524},
  journal      = {Artificial Intelligence},
  pages        = {103524},
  shortjournal = {Artif. Intell.},
  title        = {Deciding koopman&#39;s qualitative probability},
  volume       = {299},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Deliberative acting, planning and learning with hierarchical
operational models. <em>AIJ</em>, <em>299</em>, 103523. (<a
href="https://doi.org/10.1016/j.artint.2021.103523">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In AI research, synthesizing a plan of action has typically used descriptive models of the actions that abstractly specify what might happen as a result of an action, and are tailored for efficiently computing state transitions. However, executing the planned actions has needed operational models, in which rich computational control structures and closed-loop online decision-making are used to specify how to perform an action in a nondeterministic execution context, react to events and adapt to an unfolding situation. Deliberative actors , which integrate acting and planning, have typically needed to use both of these models together—which causes problems when attempting to develop the different models, verify their consistency, and smoothly interleave acting and planning. As an alternative, we define and implement an integrated acting and planning system in which both planning and acting use the same operational models . These rely on hierarchical task-oriented refinement methods offering rich control structures. The acting component, called Reactive Acting Engine ( RAE ), is inspired by the well-known PRS system. At each decision step, RAE can get advice from a planner for a near-optimal choice with respect to an utility function. The anytime planner uses a UCT-like Monte Carlo Tree Search procedure, called UPOM , whose rollouts are simulations of the actor&#39;s operational models . We also present learning strategies for use with RAE and UPOM that acquire, from online acting experiences and/or simulated planning results, a mapping from decision contexts to method instances as well as a heuristic function to guide UPOM . We demonstrate the asymptotic convergence of UPOM towards optimal methods in static domains, and show experimentally that UPOM and the learning strategies significantly improve the acting efficiency and robustness.},
  archive      = {J_AIJ},
  author       = {Sunandita Patra and James Mason and Malik Ghallab and Dana Nau and Paolo Traverso},
  doi          = {10.1016/j.artint.2021.103523},
  journal      = {Artificial Intelligence},
  pages        = {103523},
  shortjournal = {Artif. Intell.},
  title        = {Deliberative acting, planning and learning with hierarchical operational models},
  volume       = {299},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Commonsense visual sensemaking for autonomous driving – on
generalised neurosymbolic online abduction integrating vision and
semantics. <em>AIJ</em>, <em>299</em>, 103522. (<a
href="https://doi.org/10.1016/j.artint.2021.103522">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We demonstrate the need and potential of systematically integrated vision and semantics solutions for visual sensemaking in the backdrop of autonomous driving . A general neurosymbolic method for online visual sensemaking using answer set programming (ASP) is systematically formalised and fully implemented. The method integrates state of the art in visual computing, and is developed as a modular framework that is generally usable within hybrid architectures for realtime perception and control. We evaluate and demonstrate with community established benchmarks KITTIMOD, MOT-2017, and MOT-2020. As use-case, we focus on the significance of human-centred visual sensemaking —e.g., involving semantic representation and explainability, question-answering, commonsense interpolation— in safety-critical autonomous driving situations. The developed neurosymbolic framework is domain-independent, with the case of autonomous driving designed to serve as an exemplar for online visual sensemaking in diverse cognitive interaction settings in the backdrop of select human-centred AI technology design considerations.},
  archive      = {J_AIJ},
  author       = {Jakob Suchan and Mehul Bhatt and Srikrishna Varadarajan},
  doi          = {10.1016/j.artint.2021.103522},
  journal      = {Artificial Intelligence},
  pages        = {103522},
  shortjournal = {Artif. Intell.},
  title        = {Commonsense visual sensemaking for autonomous driving – on generalised neurosymbolic online abduction integrating vision and semantics},
  volume       = {299},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Making sense of raw input. <em>AIJ</em>, <em>299</em>,
103521. (<a href="https://doi.org/10.1016/j.artint.2021.103521">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {How should a machine intelligence perform unsupervised structure discovery over streams of sensory input? One approach to this problem is to cast it as an apperception task [1] . Here, the task is to construct an explicit interpretable theory that both explains the sensory sequence and also satisfies a set of unity conditions, designed to ensure that the constituents of the theory are connected in a relational structure . However, the original formulation of the apperception task had one fundamental limitation: it assumed the raw sensory input had already been parsed using a set of discrete categories, so that all the system had to do was receive this already-digested symbolic input, and make sense of it. But what if we don&#39;t have access to pre-parsed input? What if our sensory sequence is raw unprocessed information? The central contribution of this paper is a neuro-symbolic framework for distilling interpretable theories out of streams of raw, unprocessed sensory experience. First, we extend the definition of the apperception task to include ambiguous (but still symbolic) input: sequences of sets of disjunctions. Next, we use a neural network to map raw sensory input to disjunctive input. Our binary neural network is encoded as a logic program, so the weights of the network and the rules of the theory can be solved jointly as a single SAT problem. This way, we are able to jointly learn how to perceive (mapping raw sensory information to concepts) and apperceive (combining concepts into declarative rules).},
  archive      = {J_AIJ},
  author       = {Richard Evans and Matko Bošnjak and Lars Buesing and Kevin Ellis and David Pfau and Pushmeet Kohli and Marek Sergot},
  doi          = {10.1016/j.artint.2021.103521},
  journal      = {Artificial Intelligence},
  pages        = {103521},
  shortjournal = {Artif. Intell.},
  title        = {Making sense of raw input},
  volume       = {299},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Paracoherent answer set computation. <em>AIJ</em>,
<em>299</em>, 103519. (<a
href="https://doi.org/10.1016/j.artint.2021.103519">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Answer Set Programming (ASP) is a well-established paradigm for declarative programming and nonmonotonic reasoning . ASP allows for flexible modeling using rules. ASP rules induce a set of intended models called answer sets. Incoherence , the non-existence of answer sets, is therefore a feature of ASP, indicating that the rules admit no intended models. However, this feature can also be problematic in certain circumstances: errors that cause incoherence are notoriously difficult to debug, and query answering will not provide any meaningful answers for incoherent programs. Paracoherent semantics have been suggested as a remedy. They extend the classical notion of answer sets to draw meaningful conclusions also from incoherent programs. However, paracoherent semantics have essentially been inapplicable in practice, due to the lack of efficient algorithms and implementations. In this paper, this lack is addressed, and several different algorithms to compute semi-stable and semi-equilibrium models are proposed and implemented within an answer set solving framework. A key role in the framework is played by syntactic program transformations that allow for characterizing paracoherent semantics in terms of the answer sets of transformed programs. Apart from existing transformations from the literature, a novel transformation is also proposed, which provides an alternative characterization of paracoherent semantics in terms of (extended) externally supported models. Notably, the new transformation is more compact than the existing ones, and brings performance benefits. An extensive empirical performance comparison among the algorithms on benchmarks from ASP competitions and a real-world use case is given as well. It shows not only that the methods developed in this paper lead to practically effective systems, but also show a clear advantage of the methods that rely on (extended) externally supported models.},
  archive      = {J_AIJ},
  author       = {Giovanni Amendola and Carmine Dodaro and Wolfgang Faber and Francesco Ricca},
  doi          = {10.1016/j.artint.2021.103519},
  journal      = {Artificial Intelligence},
  pages        = {103519},
  shortjournal = {Artif. Intell.},
  title        = {Paracoherent answer set computation},
  volume       = {299},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Approximation and hardness of shift-bribery. <em>AIJ</em>,
<em>298</em>, 103520. (<a
href="https://doi.org/10.1016/j.artint.2021.103520">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the Shift-Bribery problem we are given an election, a preferred candidate, and the costs of shifting this preferred candidate up the voters&#39; preference orders. The goal is to find such a set of shifts that ensures that the preferred candidate wins the election. We give the first polynomial-time approximation scheme for the Shift-Bribery problem for the case of positional scoring rules, and for the Copeland rule we show strong inapproximability results.},
  archive      = {J_AIJ},
  author       = {Piotr Faliszewski and Pasin Manurangsi and Krzysztof Sornat},
  doi          = {10.1016/j.artint.2021.103520},
  journal      = {Artificial Intelligence},
  pages        = {103520},
  shortjournal = {Artif. Intell.},
  title        = {Approximation and hardness of shift-bribery},
  volume       = {298},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Pay-as-you-go consequence-based reasoning for the
description logic SROIQ. <em>AIJ</em>, <em>298</em>, 103518. (<a
href="https://doi.org/10.1016/j.artint.2021.103518">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Consequence-based (CB) reasoners combine ideas from resolution and (hyper)tableau calculi for solving key reasoning problems in Description Logics (DLs), such as ontology classification. Existing CB reasoners , however, are only capable of handling DLs without nominals (such as ALCHIQ ALCHIQ ), or DLs without disjunction (such as Horn- ALCHOIQ ALCHOIQ ). In this paper, we present a consequence-based calculus for concept subsumption and classification in the DL ALCHOI Q + ALCHOIQ+ , which extends ALC ALC with role hierarchies, inverse roles, number restrictions, and nominals; to the best of our knowledge, ours is the first CB calculus for an NExpTime -complete DL. By using standard transformations, our calculus extends to SROIQ SROIQ , which covers all of OWL 2 DL except for datatypes. A key feature of our calculus is its pay-as-you-go behaviour: our calculus is worst-case optimal for all the well-known proper fragments of ALCHOI Q + ALCHOIQ+ . Furthermore, our calculus can be applied to DL reasoning problems other than subsumption and ontology classification, such as instance retrieval and realisation. We have implemented our calculus as an extension of Sequoia, a CB reasoner which previously supported ontology classification in SRIQ SRIQ . We have performed an empirical evaluation of our implementation, which shows that Sequoia offers competitive performance. Although there still remains plenty of room for further optimisation, the calculus presented in this paper and its implementation provide an important addition to the repertoire of reasoning techniques and practical systems for expressive DLs.},
  archive      = {J_AIJ},
  author       = {David Tena Cucala and Bernardo Cuenca Grau and Ian Horrocks},
  doi          = {10.1016/j.artint.2021.103518},
  journal      = {Artificial Intelligence},
  pages        = {103518},
  shortjournal = {Artif. Intell.},
  title        = {Pay-as-you-go consequence-based reasoning for the description logic SROIQ},
  volume       = {298},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Control complexity in borda elections: Solving all open
cases of offline control and some cases of online control. <em>AIJ</em>,
<em>298</em>, 103508. (<a
href="https://doi.org/10.1016/j.artint.2021.103508">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Borda Count is one of the earliest and most important voting rules and has been central to many applications in artificial intelligence . We study the problem of control in Borda elections where an election chair seeks to either make a designated candidate win (constructive case), or prevent her from winning (destructive case), via actions such as adding, deleting, or partitioning either candidates or voters. These scenarios have been studied for many voting rules and the related control problems have been classified in terms of their computational complexity . However, for one of the most prominent natural voting rules, the Borda Count, complexity results have been known for only half of these cases until recently. We settle the complexity for all missing cases, focusing on the unique-winner model. We also exhibit two of the very rare cases where the complexity of control problems differs depending on the winner model chosen: For destructive control by partition and by run-off partition of candidates when ties promote, Borda is resistant in the unique-winner model (i.e., these two control problems are NP-hard), yet is vulnerable in the non unique-winner model (i.e., one can decide in polynomial time whether control is possible). Finally, we turn to the model of online control in sequential elections that was recently proposed by Hemaspaandra et al. [62] , [61] . We show that sequential Borda elections are vulnerable to constructive and destructive online control by adding or deleting candidates, whereas we obtain coNP-hardness results for all types of online voter control in sequential Borda elections.},
  archive      = {J_AIJ},
  author       = {Marc Neveling and Jörg Rothe},
  doi          = {10.1016/j.artint.2021.103508},
  journal      = {Artificial Intelligence},
  pages        = {103508},
  shortjournal = {Artif. Intell.},
  title        = {Control complexity in borda elections: Solving all open cases of offline control and some cases of online control},
  volume       = {298},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). “That’s (not) the output i expected!” On the role of end
user expectations in creating explanations of AI systems. <em>AIJ</em>,
<em>298</em>, 103507. (<a
href="https://doi.org/10.1016/j.artint.2021.103507">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Research in the social sciences has shown that expectations are an important factor in explanations as used between humans: rather than explaining the cause of an event per se, the explainer will often address another event that did not occur but that the explainee might have expected . For AI-powered systems, this finding suggests that explanation-generating systems may need to identify such end user expectations. In general, this is a challenging task, not the least because users often keep them implicit; there is thus a need to investigate the importance of such an ability. In this paper, we report an empirical study with 181 participants who were shown outputs from a text classifier system along with an explanation of why the system chose a particular class for each text. Explanations were both factual , explaining why the system produced a certain output or counterfactual , explaining why the system produced one output instead of another. Our main hypothesis was explanations should align with end user expectations; that is, a factual explanation should be given when the system&#39;s output is in line with end user expectations, and a counterfactual explanation when it is not. We find that factual explanations are indeed appropriate when expectations and output match. When they do not, neither factual nor counterfactual explanations appear appropriate, although we do find indications that our counterfactual explanations contained at least some necessary elements. Overall, this suggests that it is important for systems that create explanations of AI systems to infer what outputs the end user expected so that factual explanations can be generated at the appropriate moments. At the same time, this information is, by itself, not sufficient to also create appropriate explanations when the output and user expectations do not match. This is somewhat surprising given investigations of explanations in the social sciences, and will need more scrutiny in future studies.},
  archive      = {J_AIJ},
  author       = {Maria Riveiro and Serge Thill},
  doi          = {10.1016/j.artint.2021.103507},
  journal      = {Artificial Intelligence},
  pages        = {103507},
  shortjournal = {Artif. Intell.},
  title        = {“That&#39;s (not) the output i expected!” on the role of end user expectations in creating explanations of AI systems},
  volume       = {298},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Neural probabilistic logic programming in DeepProbLog.
<em>AIJ</em>, <em>298</em>, 103504. (<a
href="https://doi.org/10.1016/j.artint.2021.103504">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce DeepProbLog, a neural probabilistic logic programming language that incorporates deep learning by means of neural predicates. We show how existing inference and learning techniques of the underlying probabilistic logic programming language ProbLog can be adapted for the new language. We theoretically and experimentally demonstrate that DeepProbLog supports (i) both symbolic and subsymbolic representations and inference, (ii) program induction, (iii) probabilistic (logic) programming, and (iv) (deep) learning from examples. To the best of our knowledge, this work is the first to propose a framework where general-purpose neural networks and expressive probabilistic-logical modeling and reasoning are integrated in a way that exploits the full expressiveness and strengths of both worlds and can be trained end-to-end based on examples.},
  archive      = {J_AIJ},
  author       = {Robin Manhaeve and Sebastijan Dumančić and Angelika Kimmig and Thomas Demeester and Luc De Raedt},
  doi          = {10.1016/j.artint.2021.103504},
  journal      = {Artificial Intelligence},
  pages        = {103504},
  shortjournal = {Artif. Intell.},
  title        = {Neural probabilistic logic programming in DeepProbLog},
  volume       = {298},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Toward personalized XAI: A case study in intelligent
tutoring systems. <em>AIJ</em>, <em>298</em>, 103503. (<a
href="https://doi.org/10.1016/j.artint.2021.103503">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Our research is a step toward ascertaining the need for personalization in XAI , and we do so in the context of investigating the value of explanations of AI-driven hints and feedback in Intelligent Tutoring Systems (ITS). We added an explanation functionality to the Adaptive CSP (ACSP) applet, an interactive simulation that helps students learn an algorithm for constraint satisfaction problems by providing AI-driven hints adapted to their predicted level of learning. We present the design of the explanation functionality and the results of a controlled study to evaluate its impact on students&#39; learning and perception of the ACPS hints. The study includes an analysis of how these outcomes are modulated by several user characteristics such as personality traits and cognitive abilities, to asses if explanations should be personalized to these characteristics. Our results indicate that providing explanations increase students&#39; trust in the ACPS hints, perceived usefulness of the hints, and intention to use them again. In addition, we show that students&#39; access of the ACSP explanation and learning gains are modulated by three user characteristics, Need for Cognition, Contentiousness and Reading Proficiency, providing insights on how to personalize the ACSP explanations to these traits, as well as initial evidence on the potential value of personalized Explainable AI (XAI) for ITS.},
  archive      = {J_AIJ},
  author       = {Cristina Conati and Oswald Barral and Vanessa Putnam and Lea Rieger},
  doi          = {10.1016/j.artint.2021.103503},
  journal      = {Artificial Intelligence},
  pages        = {103503},
  shortjournal = {Artif. Intell.},
  title        = {Toward personalized XAI: A case study in intelligent tutoring systems},
  volume       = {298},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Explaining individual predictions when features are
dependent: More accurate approximations to shapley values. <em>AIJ</em>,
<em>298</em>, 103502. (<a
href="https://doi.org/10.1016/j.artint.2021.103502">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Explaining complex or seemingly simple machine learning models is an important practical problem. We want to explain individual predictions from such models by learning simple, interpretable explanations. Shapley value is a game theoretic concept that can be used for this purpose. The Shapley value framework has a series of desirable theoretical properties, and can in principle handle any predictive model . Kernel SHAP is a computationally efficient approximation to Shapley values in higher dimensions. Like several other existing methods, this approach assumes that the features are independent. Since Shapley values currently suffer from inclusion of unrealistic data instances when features are correlated, the explanations may be very misleading. This is the case even if a simple linear model is used for predictions. In this paper, we extend the Kernel SHAP method to handle dependent features. We provide several examples of linear and non-linear models with various degrees of feature dependence, where our method gives more accurate approximations to the true Shapley values.},
  archive      = {J_AIJ},
  author       = {Kjersti Aas and Martin Jullum and Anders Løland},
  doi          = {10.1016/j.artint.2021.103502},
  journal      = {Artificial Intelligence},
  pages        = {103502},
  shortjournal = {Artif. Intell.},
  title        = {Explaining individual predictions when features are dependent: More accurate approximations to shapley values},
  volume       = {298},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A lightweight epistemic logic and its application to
planning. <em>AIJ</em>, <em>298</em>, 103437. (<a
href="https://doi.org/10.1016/j.artint.2020.103437">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study multiagent epistemic planning with a simple epistemic logic whose language is a restriction of that of standard epistemic logic. Its formulas are boolean combinations of observability atoms: sequences of ‘knowing whether’ operators followed by propositional variables . This compares favourably with other restricted languages where formulas are boolean combinations of epistemic literals: sequences of ‘knowing that’ epistemic operators and negations followed by propositional variables ; or in other terms: epistemic formulas without conjunctions or disjunctions. The reason is that our language enables a richer theory of mind: we can express statements such as “I don&#39;t know whether p , but I know that you know whether p ” which are important in communication and more generally in interaction and which cannot be expressed with epistemic literals. Going beyond previous work, we also introduce a ‘common knowledge whether’ operator. We show that satisfiability is nevertheless NP -complete. We then define simple epistemic planning tasks as generalisations of classical planning tasks: action descriptions have sets of observability atoms as add- and delete-lists, initial states are sets of observability atoms, and goals are boolean combinations of observability atoms. We show that simple epistemic planning tasks can be polynomially translated into classical planning tasks. It follows that checking solvability of simple epistemic planning tasks is PSpace -complete. We present some application examples such as the gossip problem and some experimental results and clarify the relationship with Dynamic Epistemic Logic-based planning.},
  archive      = {J_AIJ},
  author       = {Martin C. Cooper and Andreas Herzig and Faustine Maffre and Frédéric Maris and Elise Perrotin and Pierre Régnier},
  doi          = {10.1016/j.artint.2020.103437},
  journal      = {Artificial Intelligence},
  pages        = {103437},
  shortjournal = {Artif. Intell.},
  title        = {A lightweight epistemic logic and its application to planning},
  volume       = {298},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). PC-SyncBB: A privacy preserving collusion secure DCOP
algorithm. <em>AIJ</em>, <em>297</em>, 103501. (<a
href="https://doi.org/10.1016/j.artint.2021.103501">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, several studies proposed privacy-preserving algorithms for solving Distributed Constraint Optimization Problems (DCOPs). Those studies were based on existing DCOP solving algorithms, which they strengthened by implementing cryptographic weaponry that enabled performing the very same computation while protecting sensitive private data. All of those studies assumed that agents do not collude. In this study we propose the first privacy-preserving DCOP algorithm that is immune to coalitions. Our basic algorithm is secure against any coalition under the assumption of an honest majority (namely, the number of colluding agents is &amp;lt; n/2 , where n is the overall number of agents). We then proceed to describe two variants of that basic algorithm: a more efficient variant that is secure against coalitions of size ≤ c , for some constant c c&amp;lt; (n−1)/2 ; and another variant that is immune to agent coalitions of any size, but relies on an external committee of mediators with an honest majority. Our algorithm – PC-SyncBB – is based on the classical Branch and Bound DCOP algorithm. It offers constraint, topology and decision privacy. We evaluate its performance on different benchmarks, problem sizes, and constraint densities. We show that achieving security against coalitions is feasible. Our experiments indicate that PC-SyncBB can run in reasonable time on problems involving up to 19 agents. As all existing privacy-preserving DCOP algorithms base their security on assuming solitary conduct of the agents, we view this study as an essential first step towards lifting this potentially harmful assumption in all those algorithms.},
  archive      = {J_AIJ},
  author       = {Tamir Tassa and Tal Grinshpoun and Avishay Yanai},
  doi          = {10.1016/j.artint.2021.103501},
  journal      = {Artificial Intelligence},
  pages        = {103501},
  shortjournal = {Artif. Intell.},
  title        = {PC-SyncBB: A privacy preserving collusion secure DCOP algorithm},
  volume       = {297},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A survey of inverse reinforcement learning: Challenges,
methods and progress. <em>AIJ</em>, <em>297</em>, 103500. (<a
href="https://doi.org/10.1016/j.artint.2021.103500">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inverse reinforcement learning ( IRL ) is the problem of inferring the reward function of an agent, given its policy or observed behavior. Analogous to RL , IRL is perceived both as a problem and as a class of methods. By categorically surveying the extant literature in IRL , this article serves as a comprehensive reference for researchers and practitioners of machine learning as well as those new to it to understand the challenges of IRL and select the approaches best suited for the problem on hand. The survey formally introduces the IRL problem along with its central challenges such as the difficulty in performing accurate inference and its generalizability , its sensitivity to prior knowledge, and the disproportionate growth in solution complexity with problem size. The article surveys a vast collection of foundational methods grouped together by the commonality of their objectives, and elaborates how these methods mitigate the challenges. We further discuss extensions to the traditional IRL methods for handling imperfect perception, an incomplete model, learning multiple reward functions and nonlinear reward functions. The article concludes the survey with a discussion of some broad advances in the research area and currently open research questions.},
  archive      = {J_AIJ},
  author       = {Saurabh Arora and Prashant Doshi},
  doi          = {10.1016/j.artint.2021.103500},
  journal      = {Artificial Intelligence},
  pages        = {103500},
  shortjournal = {Artif. Intell.},
  title        = {A survey of inverse reinforcement learning: Challenges, methods and progress},
  volume       = {297},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Algorithms and conditional lower bounds for planning
problems. <em>AIJ</em>, <em>297</em>, 103499. (<a
href="https://doi.org/10.1016/j.artint.2021.103499">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider planning problems for graphs, Markov Decision Processes (MDPs), and games on graphs in an explicit state space. While graphs represent the most basic planning model, MDPs represent interaction with nature and games on graphs represent interaction with an adversarial environment. We consider two planning problems with k different target sets: (a) the coverage problem asks whether there is a plan for each individual target set; and (b) the sequential target reachability problem asks whether the targets can be reached in a given sequence. For the coverage problem, we present a linear-time algorithm for graphs, and quadratic conditional lower bound for MDPs and games on graphs. For the sequential target problem, we present a linear-time algorithm for graphs, a sub-quadratic algorithm for MDPs, and a quadratic conditional lower bound for games on graphs. Our results with conditional lower bounds, based on the boolean matrix multiplication (BMM) conjecture and strong exponential time hypothesis (SETH), establish (i) model-separation results showing that for the coverage problem MDPs and games on graphs are harder than graphs, and for the sequential reachability problem games on graphs are harder than MDPs and graphs; and (ii) problem-separation results showing that for MDPs the coverage problem is harder than the sequential target problem.},
  archive      = {J_AIJ},
  author       = {Krishnendu Chatterjee and Wolfgang Dvořák and Monika Henzinger and Alexander Svozil},
  doi          = {10.1016/j.artint.2021.103499},
  journal      = {Artificial Intelligence},
  pages        = {103499},
  shortjournal = {Artif. Intell.},
  title        = {Algorithms and conditional lower bounds for planning problems},
  volume       = {297},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Dissecting scientific explanation in AI (sXAI): A case for
medicine and healthcare. <em>AIJ</em>, <em>297</em>, 103498. (<a
href="https://doi.org/10.1016/j.artint.2021.103498">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Explanatory AI (XAI) is on the rise, gaining enormous traction with the computational community, policymakers, and philosophers alike. This article contributes to this debate by first distinguishing scientific XAI (sXAI) from other forms of XAI . It further advances the structure for bona fide sXAI, while remaining neutral regarding preferences for theories of explanations. Three core components are under study, namely, i) the structure for bona fide sXAI, consisting in elucidating the explanans , the explanandum , and the explanatory relation for sXAI: ii) the pragmatics of explanation, which includes a discussion of the role of multi-agents receiving an explanation and the context within which the explanation is given; and iii) a discussion on Meaningful Human Explanation , an umbrella concept for different metrics required for measuring the explanatory power of explanations and the involvement of human agents in sXAI. The kind of AI systems of interest in this article are those utilized in medicine and the healthcare system. The article also critically addresses current philosophical and computational approaches to XAI. Amongst the main objections, it argues that there has been a long-standing interpretation of classifications as explanation, when these should be kept separate.},
  archive      = {J_AIJ},
  author       = {Juan M. Durán},
  doi          = {10.1016/j.artint.2021.103498},
  journal      = {Artificial Intelligence},
  pages        = {103498},
  shortjournal = {Artif. Intell.},
  title        = {Dissecting scientific explanation in AI (sXAI): A case for medicine and healthcare},
  volume       = {297},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Expecting the unexpected: Goal recognition for rational and
irrational agents. <em>AIJ</em>, <em>297</em>, 103490. (<a
href="https://doi.org/10.1016/j.artint.2021.103490">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Contemporary cost-based goal-recognition assumes rationality: that observed behaviour is more or less optimal. Probabilistic goal recognition systems, however, explicitly depend on some degree of sub-optimality to generate probability distributions. We show that, even when an observed agent is only slightly irrational (sub-optimal), state-of-the-art systems produce counter-intuitive results (though these may only become noticeable when the agent is highly irrational). We provide a definition of rationality appropriate to situations where the ground truth is unknown, define a rationality measure (RM) that quantifies an agent&#39;s expected degree of sub-optimality, and define an innovative self-modulating probability distribution formula for goal recognition. Our formula recognises sub-optimality and adjusts its level of confidence accordingly, thereby handling irrationality—and rationality—in an intuitive, principled manner. Building on that formula, moreover, we strengthen a previously published result, showing that “single-observation” recognition in the path-planning domain achieves identical results to more computationally expensive techniques, where previously we claimed only to achieve equivalent rankings though values differed.},
  archive      = {J_AIJ},
  author       = {Peta Masters and Sebastian Sardina},
  doi          = {10.1016/j.artint.2021.103490},
  journal      = {Artificial Intelligence},
  pages        = {103490},
  shortjournal = {Artif. Intell.},
  title        = {Expecting the unexpected: Goal recognition for rational and irrational agents},
  volume       = {297},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Properties and interrelationships of skeptical, weakly
skeptical, and credulous inference induced by classes of minimal models.
<em>AIJ</em>, <em>297</em>, 103489. (<a
href="https://doi.org/10.1016/j.artint.2021.103489">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There are multiple ways of defining nonmonotonic inference relations based on a conditional knowledge base. While the axiomatic system P is an important standard for such plausible nonmonotonic reasoning , inference relations obtained from system Z or from c-representations have been designed which go beyond system P by selecting preferred models for inference. For any class of models M , we propose the notion of weakly skeptical inference, first introduced in an ECAI conference paper this article revises and extends, that lies between skeptical and credulous inference with respect to M . Weakly skeptical c-inference properly extends skeptical c-inference, but avoids disadvantages of a too liberal credulous c-inference. We extend the concepts of skeptical, weakly skeptical, and credulous c-inference modes by taking models obtained from different minimality criteria into account. We illustrate the usefulness of the obtained inference relations and show that they fulfill various desirable properties put forward for nonmonotonic reasoning . Furthermore, we elaborate in detail the interrelationships among the inference relations when taking the different inference modes and various classes of minimal models into account.},
  archive      = {J_AIJ},
  author       = {Christoph Beierle and Christian Eichhorn and Gabriele Kern-Isberner and Steven Kutsch},
  doi          = {10.1016/j.artint.2021.103489},
  journal      = {Artificial Intelligence},
  pages        = {103489},
  shortjournal = {Artif. Intell.},
  title        = {Properties and interrelationships of skeptical, weakly skeptical, and credulous inference induced by classes of minimal models},
  volume       = {297},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A unifying look at sequence submodularity. <em>AIJ</em>,
<em>297</em>, 103486. (<a
href="https://doi.org/10.1016/j.artint.2021.103486">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Several real-world problems in engineering and applied science require the selection of sequences that maximize a given reward function. Optimizing over sequences as opposed to sets requires exploring an exponentially larger search space and can become prohibitive in most cases of practical interest. However, if the objective function is submodular (intuitively, it exhibits a diminishing return property), the optimization problem becomes more manageable. Recently, there has been increasing interest in sequence submodularity in connection with applications such as recommender systems and online ad allocation. However, mostly ad hoc models and solutions have emerged within these applicative contexts. In consequence, the field appears fragmented and lacks coherence. In this paper, we offer a unified view of sequence submodularity and provide a generalized greedy algorithm that enjoys strong theoretical guarantees. We show how our approach naturally captures several application domains, and our algorithm encompasses existing methods, improving over them.},
  archive      = {J_AIJ},
  author       = {Sara Bernardini and Fabio Fagnani and Chiara Piacentini},
  doi          = {10.1016/j.artint.2021.103486},
  journal      = {Artificial Intelligence},
  pages        = {103486},
  shortjournal = {Artif. Intell.},
  title        = {A unifying look at sequence submodularity},
  volume       = {297},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Argumentative explanations for interactive recommendations.
<em>AIJ</em>, <em>296</em>, 103506. (<a
href="https://doi.org/10.1016/j.artint.2021.103506">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A significant challenge for recommender systems (RSs), and in fact for AI systems in general, is the systematic definition of explanations for outputs in such a way that both the explanations and the systems themselves are able to adapt to their human users&#39; needs. In this paper we propose an RS hosting a vast repertoire of explanations, which are customisable to users in their content and format, and thus able to adapt to users&#39; explanatory requirements, while being reasonably effective (proven empirically). Our RS is built on a graphical chassis, allowing the extraction of argumentation scaffolding, from which diverse and varied argumentative explanations for recommendations can be obtained. These recommendations are interactive because they can be questioned by users and they support adaptive feedback mechanisms designed to allow the RS to self-improve (proven theoretically). Finally, we undertake user studies in which we vary the characteristics of the argumentative explanations, showing users&#39; general preferences for more information, but also that their tastes are diverse, thus highlighting the need for our adaptable RS.},
  archive      = {J_AIJ},
  author       = {Antonio Rago and Oana Cocarascu and Christos Bechlivanidis and David Lagnado and Francesca Toni},
  doi          = {10.1016/j.artint.2021.103506},
  journal      = {Artificial Intelligence},
  pages        = {103506},
  shortjournal = {Artif. Intell.},
  title        = {Argumentative explanations for interactive recommendations},
  volume       = {296},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Acyclic orders, partition schemes and CSPs: Unified hardness
proofs and improved algorithms. <em>AIJ</em>, <em>296</em>, 103505. (<a
href="https://doi.org/10.1016/j.artint.2021.103505">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many computational problems arising in, for instance, artificial intelligence can be realized as infinite-domain constraint satisfaction problems (CSPs) based on partition schemes : a set of pairwise disjoint binary relations (containing the equality relation) whose union spans the underlying domain and which is closed under converse. We first consider partition schemes that contain an acyclic order and where the constraint language contains all unions of the basic relations; such CSPs are frequently occurring in e.g. temporal and spatial reasoning . We identify properties of such orders which, when combined, are sufficient to establish NP-hardness of the CSP and strong lower bounds under the exponential-time hypothesis, even for degree-bounded problems. This result explains, in a uniform way, many existing hardness results from the literature, and shows that it is impossible to obtain subexponential time algorithms unless the exponential-time hypothesis fails. However, some of these problems (including several important temporal problems), despite likely not being solvable in subexponential time, admit non-trivial improved exponential-time algorithm, and we present a novel improved algorithm for RCC-8 and related formalisms.},
  archive      = {J_AIJ},
  author       = {Peter Jonsson and Victor Lagerkvist and George Osipov},
  doi          = {10.1016/j.artint.2021.103505},
  journal      = {Artificial Intelligence},
  pages        = {103505},
  shortjournal = {Artif. Intell.},
  title        = {Acyclic orders, partition schemes and CSPs: Unified hardness proofs and improved algorithms},
  volume       = {296},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Peeking behind the ordinal curtain: Improving distortion via
cardinal queries. <em>AIJ</em>, <em>296</em>, 103488. (<a
href="https://doi.org/10.1016/j.artint.2021.103488">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aggregating the preferences of individuals into a collective decision is the core subject of study of social choice theory . In 2006, Procaccia and Rosenschein considered a utilitarian social choice setting, where the agents have explicit numerical values for the alternatives, yet they only report their linear orderings over them. To compare different aggregation mechanisms, Procaccia and Rosenschein introduced the notion of distortion , which quantifies the inefficiency of using only ordinal information when trying to maximize the social welfare, i.e., the sum of the underlying values of the agents for the chosen outcome. Since then, this research area has flourished and bounds on the distortion have been obtained for a wide variety of fundamental scenarios. However, the vast majority of the existing literature is focused on the case where nothing is known beyond the ordinal preferences of the agents over the alternatives. In this paper, we take a more expressive approach, and consider mechanisms that are allowed to further ask a few cardinal queries in order to gain partial access to the underlying values that the agents have for the alternatives. With this extra power, we design new deterministic mechanisms that achieve significantly improved distortion bounds and, in many cases, outperform the best-known randomized ordinal mechanisms. We paint an almost complete picture of the number of queries required by deterministic mechanisms to achieve specific distortion bounds.},
  archive      = {J_AIJ},
  author       = {Georgios Amanatidis and Georgios Birmpas and Aris Filos-Ratsikas and Alexandros A. Voudouris},
  doi          = {10.1016/j.artint.2021.103488},
  journal      = {Artificial Intelligence},
  pages        = {103488},
  shortjournal = {Artif. Intell.},
  title        = {Peeking behind the ordinal curtain: Improving distortion via cardinal queries},
  volume       = {296},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Planning-based knowing how: A unified approach.
<em>AIJ</em>, <em>296</em>, 103487. (<a
href="https://doi.org/10.1016/j.artint.2021.103487">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Various logical notions of know-how have been recently proposed and studied in the literature based on different types of epistemic planning in different frameworks. This paper proposes a unified logical framework to incorporate the existing and some new notions of know-how. We define the semantics of the know-how operator using a unified notion of epistemic planning with parameters of different types of plans specified by a programming language . Surprisingly, via a highly unified completeness proof , we show that all the ten intuitive notions of plans discussed in this paper lead to exactly the same know-how logic, which is proven to be decidable. We also show that over finite models, the know-how logic based on knowledge-based plans requires an extension with an axiom capturing the compositionality of the plans. In the context of epistemic planning, our axiomatization results reveal the core principles behind the very idea of epistemic planning, independent of the particular notion of plans. Moreover, since epistemic planning can be expressed by the know-how modality in our object language, we can greatly generalize the planning problems that can be solved formally by model checking various formulas in our language.},
  archive      = {J_AIJ},
  author       = {Yanjun Li and Yanjing Wang},
  doi          = {10.1016/j.artint.2021.103487},
  journal      = {Artificial Intelligence},
  pages        = {103487},
  shortjournal = {Artif. Intell.},
  title        = {Planning-based knowing how: A unified approach},
  volume       = {296},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Ballooning multi-armed bandits. <em>AIJ</em>, <em>296</em>,
103485. (<a href="https://doi.org/10.1016/j.artint.2021.103485">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we introduce ballooning multi-armed bandits (BL-MAB), a novel extension of the classical stochastic MAB model. In the BL-MAB model, the set of available arms grows (or balloons) over time. In contrast to the classical MAB setting where the regret is computed with respect to the best arm overall, the regret in a BL-MAB setting is computed with respect to the best available arm at each time. We first observe that the existing stochastic MAB algorithms result in linear regret for the BL-MAB model. We prove that, if the best arm is equally likely to arrive at any time instant, a sub-linear regret cannot be achieved. Next, we show that if the best arm is more likely to arrive in the early rounds, one can achieve sub-linear regret. Our proposed algorithm determines (1) the fraction of the time horizon for which the newly arriving arms should be explored and (2) the sequence of arm pulls in the exploitation phase from among the explored arms. Making reasonable assumptions on the arrival distribution of the best arm in terms of the thinness of the distribution&#39;s tail, we prove that the proposed algorithm achieves sub-linear instance-independent regret. We further quantify explicit dependence of regret on the arrival distribution parameters. We reinforce our theoretical findings with extensive simulation results. We conclude by showing that our algorithm would achieve sub-linear regret even if (a) the distributional parameters are not exactly known, but are obtained using a reasonable learning mechanism or (b) the best arm is not more likely to arrive early, but a large fraction of arms is likely to arrive relatively early.},
  archive      = {J_AIJ},
  author       = {Ganesh Ghalme and Swapnil Dhamal and Shweta Jain and Sujit Gujar and Y. Narahari},
  doi          = {10.1016/j.artint.2021.103485},
  journal      = {Artificial Intelligence},
  pages        = {103485},
  shortjournal = {Artif. Intell.},
  title        = {Ballooning multi-armed bandits},
  volume       = {296},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Enhanced aspect-based sentiment analysis models with
progressive self-supervised attention learning. <em>AIJ</em>,
<em>296</em>, 103477. (<a
href="https://doi.org/10.1016/j.artint.2021.103477">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In aspect-based sentiment analysis (ABSA), many neural models are equipped with an attention mechanism to quantify the contribution of each context word to sentiment prediction . However, such a mechanism suffers from one drawback: only a few frequent words with sentiment polarities are tended to be taken into consideration for final sentiment decision while abundant infrequent sentiment words are ignored by models. To deal with this issue, we propose a progressive self-supervised attention learning approach for attentional ABSA models. In this approach, we iteratively perform sentiment prediction on all training instances, and continually learn useful attention supervision information in the meantime. During training, at each iteration, context words with the highest impact on sentiment prediction, identified based on their attention weights or gradients, are extracted as words with active/misleading influence on the correct/incorrect prediction for each instance. Words extracted in this way are masked for subsequent iterations . To exploit these extracted words for refining ABSA models, we augment the conventional training objective with a regularization term that encourages ABSA models to not only take full advantage of the extracted active context words but also decrease the weights of those misleading words. We integrate the proposed approach into three state-of-the-art neural ABSA models. Experiment results and in-depth analyses show that our approach yields better attention results and significantly enhances the performance of all three models. We release the source code and trained models at https://github.com/DeepLearnXMU/PSSAttention .},
  archive      = {J_AIJ},
  author       = {Jinsong Su and Jialong Tang and Hui Jiang and Ziyao Lu and Yubin Ge and Linfeng Song and Deyi Xiong and Le Sun and Jiebo Luo},
  doi          = {10.1016/j.artint.2021.103477},
  journal      = {Artificial Intelligence},
  pages        = {103477},
  shortjournal = {Artif. Intell.},
  title        = {Enhanced aspect-based sentiment analysis models with progressive self-supervised attention learning},
  volume       = {296},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Predicting winner and estimating margin of victory in
elections using sampling. <em>AIJ</em>, <em>296</em>, 103476. (<a
href="https://doi.org/10.1016/j.artint.2021.103476">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predicting the winner of an election and estimating the margin of victory of that election are favorite problems both for news media pundits and computational social choice theorists. Since it is often infeasible to elicit the preferences of all the voters in a typical prediction scenario, a common algorithm used for predicting the winner and estimating the margin of victory is to run the election on a small sample of randomly chosen votes and predict accordingly. We analyze the performance of this algorithm for many commonly used voting rules. More formally, for predicting the winner of an election, we introduce the ( ε , δ ) (ε, δ) - Winner Determination problem, where given an election E E on n voters and m candidates in which the margin of victory is at least εn votes, the goal is to determine the winner with probability at least 1 − δ 1−δ where ε and δ are parameters with 0 0&amp;lt; ε, δ&amp;lt; 1 . The margin of victory of an election is the smallest number of votes that need to be modified in order to change the election winner. We show interesting lower and upper bounds on the number of samples needed to solve the ( ε , δ ) (ε, δ) - Winner Determination problem for many common voting rules, including all scoring rules, approval, maximin, Copeland, Bucklin, plurality with runoff, and single transferable vote. Moreover, the lower and upper bounds match for many common voting rules up to constant factors. For estimating the margin of victory of an election, we introduce the ( c , ε , δ ) (c, ε, δ) –Margin of Victory problem, where given an election E E on n voters, the goal is to estimate the margin of victory M ( E ) M(E) of E E within an additive error of c M ( E ) + ε n cM(E)+εn with probability of error at most δ where ε , δ ε, δ , and c are the parameters with 0 0&amp;lt; ε, δ&amp;lt; 1 and c &gt; 0 c&amp;gt; 0 . We exhibit interesting bounds on the sample complexity of the ( c , ε , δ ) (c, ε, δ) –Margin of Victory problem for many commonly used voting rules including all scoring rules, approval, Bucklin, maximin, and Copeland α . We observe that even for the voting rules for which computing the margin of victory is NP NP -hard, there may exist efficient sampling based algorithms for estimating the margin of victory, as observed in the cases of maximin and Copeland α voting rules.},
  archive      = {J_AIJ},
  author       = {Arnab Bhattacharyya and Palash Dey},
  doi          = {10.1016/j.artint.2021.103476},
  journal      = {Artificial Intelligence},
  pages        = {103476},
  shortjournal = {Artif. Intell.},
  title        = {Predicting winner and estimating margin of victory in elections using sampling},
  volume       = {296},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Differential privacy of hierarchical census data: An
optimization approach. <em>AIJ</em>, <em>296</em>, 103475. (<a
href="https://doi.org/10.1016/j.artint.2021.103475">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is motivated by applications of a Census Bureau interested in releasing aggregate socio-economic data about a large population without revealing sensitive information about any individual. The released information can be the number of individuals living alone, the number of cars they own, or their salary brackets. Recent events have identified some of the privacy challenges faced by these organizations [1] . To address them, this paper presents a novel differential-privacy mechanism for releasing hierarchical counts of individuals. The counts are reported at multiple granularities (e.g., the national, state, and county levels) and must be consistent across all levels. The core of the mechanism is an optimization model that redistributes the noise introduced to achieve differential privacy in order to meet the consistency constraints between the hierarchical levels. The key technical contribution of the paper shows that this optimization problem can be solved in polynomial time by exploiting the structure of its cost functions . Experimental results on very large, real datasets show that the proposed mechanism provides improvements of up to two orders of magnitude in terms of computational efficiency and accuracy with respect to other state-of-the-art techniques.},
  archive      = {J_AIJ},
  author       = {Ferdinando Fioretto and Pascal Van Hentenryck and Keyu Zhu},
  doi          = {10.1016/j.artint.2021.103475},
  journal      = {Artificial Intelligence},
  pages        = {103475},
  shortjournal = {Artif. Intell.},
  title        = {Differential privacy of hierarchical census data: An optimization approach},
  volume       = {296},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). What do we want from explainable artificial intelligence
(XAI)? – a stakeholder perspective on XAI and a conceptual model guiding
interdisciplinary XAI research. <em>AIJ</em>, <em>296</em>, 103473. (<a
href="https://doi.org/10.1016/j.artint.2021.103473">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Previous research in Explainable Artificial Intelligence (XAI) suggests that a main aim of explainability approaches is to satisfy specific interests, goals, expectations, needs, and demands regarding artificial systems (we call these “ stakeholders&#39; desiderata ”) in a variety of contexts. However, the literature on XAI is vast, spreads out across multiple largely disconnected disciplines, and it often remains unclear how explainability approaches are supposed to achieve the goal of satisfying stakeholders&#39; desiderata. This paper discusses the main classes of stakeholders calling for explainability of artificial systems and reviews their desiderata. We provide a model that explicitly spells out the main concepts and relations necessary to consider and investigate when evaluating, adjusting, choosing, and developing explainability approaches that aim to satisfy stakeholders&#39; desiderata. This model can serve researchers from the variety of different disciplines involved in XAI as a common ground. It emphasizes where there is interdisciplinary potential in the evaluation and the development of explainability approaches.},
  archive      = {J_AIJ},
  author       = {Markus Langer and Daniel Oster and Timo Speith and Holger Hermanns and Lena Kästner and Eva Schmidt and Andreas Sesing and Kevin Baum},
  doi          = {10.1016/j.artint.2021.103473},
  journal      = {Artificial Intelligence},
  pages        = {103473},
  shortjournal = {Artif. Intell.},
  title        = {What do we want from explainable artificial intelligence (XAI)? – a stakeholder perspective on XAI and a conceptual model guiding interdisciplinary XAI research},
  volume       = {296},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Using ontologies to enhance human understandability of
global post-hoc explanations of black-box models. <em>AIJ</em>,
<em>296</em>, 103471. (<a
href="https://doi.org/10.1016/j.artint.2021.103471">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The interest in explainable artificial intelligence has grown strongly in recent years because of the need to convey safety and trust in the ‘how’ and ‘why’ of automated decision-making to users. While a plethora of approaches has been developed, only a few focus on how to use domain knowledge and how this influences the understanding of explanations by users. In this paper, we show that by using ontologies we can improve the human understandability of global post-hoc explanations, presented in the form of decision trees. In particular, we introduce Trepan Reloaded, which builds on Trepan , an algorithm that extracts surrogate decision trees from black-box models. Trepan Reloaded includes ontologies, that model domain knowledge, in the process of extracting explanations to improve their understandability. We tested the understandability of the extracted explanations by humans in a user study with four different tasks. We evaluate the results in terms of response times and correctness, subjective ease of understanding and confidence, and similarity of free text responses. The results show that decision trees generated with Trepan Reloaded, taking into account domain knowledge, are significantly more understandable throughout than those generated by standard Trepan . The enhanced understandability of post-hoc explanations is achieved with little compromise on the accuracy with which the surrogate decision trees replicate the behaviour of the original neural network models.},
  archive      = {J_AIJ},
  author       = {Roberto Confalonieri and Tillman Weyde and Tarek R. Besold and Fermín Moscoso del Prado Martín},
  doi          = {10.1016/j.artint.2021.103471},
  journal      = {Artificial Intelligence},
  pages        = {103471},
  shortjournal = {Artif. Intell.},
  title        = {Using ontologies to enhance human understandability of global post-hoc explanations of black-box models},
  volume       = {296},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Open-world probabilistic databases: Semantics, algorithms,
complexity. <em>AIJ</em>, <em>295</em>, 103474. (<a
href="https://doi.org/10.1016/j.artint.2021.103474">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large-scale probabilistic knowledge bases are becoming increasingly important in academia and industry. They are continuously extended with new data, powered by modern information extraction tools that associate probabilities with knowledge base facts. The state of the art to store and process such data is founded on probabilistic databases. Many systems based on probabilistic databases, however, still have certain semantic deficiencies, which limit their potential applications. We revisit the semantics of probabilistic databases, and argue that the closed-world assumption of probabilistic databases, i.e., the assumption that facts not appearing in the database have the probability zero , conflicts with the everyday use of large-scale probabilistic knowledge bases. To address this discrepancy, we propose open-world probabilistic databases , as a new probabilistic data model. In this new data model, the probabilities of unknown facts, also called open facts , can be assigned any probability value from a default probability interval. Our analysis entails that our model aligns better with many real-world tasks such as query answering , relational learning , knowledge base completion , and rule mining . We make various technical contributions. We show that the data complexity dichotomy , between polynomial time and , for evaluating unions of conjunctive queries on probabilistic databases can be lifted to our open-world model. This result is supported by an algorithm that computes the probabilities of the so-called safe queries efficiently. Based on this algorithm, we prove that evaluating safe queries is in linear time for probabilistic databases, under reasonable assumptions. This remains true in open-world probabilistic databases for a more restricted class of safe queries. We extend our data complexity analysis beyond unions of conjunctive queries , and obtain a host of complexity results for both classical and open-world probabilistic databases. We conclude our analysis with an in-depth investigation of the combined complexity in the respective models.},
  archive      = {J_AIJ},
  author       = {İsmail İlkan Ceylan and Adnan Darwiche and Guy Van den Broeck},
  doi          = {10.1016/j.artint.2021.103474},
  journal      = {Artificial Intelligence},
  pages        = {103474},
  shortjournal = {Artif. Intell.},
  title        = {Open-world probabilistic databases: Semantics, algorithms, complexity},
  volume       = {295},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Acceptance in incomplete argumentation frameworks.
<em>AIJ</em>, <em>295</em>, 103470. (<a
href="https://doi.org/10.1016/j.artint.2021.103470">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract argumentation frameworks (AFs), originally proposed by Dung, constitute a central formal model for the study of computational aspects of argumentation in AI . Credulous and skeptical acceptance of arguments in a given AF are well-studied problems both in terms of theoretical analysis—especially computational complexity—and the development of practical decision procedures for the problems. However, AFs make the assumption that all attacks between arguments are certain (i.e., present attacks are known to exist, and missing attacks are known to not exist), which can in various settings be a restrictive assumption. A generalization of AFs to incomplete AFs was recently proposed as a formalism that allows the representation of both uncertain attacks and uncertain arguments in AFs. In this article, we explore the impact of allowing for modeling such uncertainties in AFs on the computational complexity of natural generalizations of acceptance problems to incomplete AFs under various central AF semantics. Complementing the complexity-theoretic analysis, we also develop the first practical decision procedures for all of the NP-hard variants of acceptance in incomplete AFs. In terms of complexity analysis, we establish a full complexity landscape, showing that depending on the variant of acceptance and property/semantics, the complexity of acceptance in incomplete AFs ranges from polynomial-time decidable to completeness for Σ 3 p Σ3p . In terms of algorithms, we show through an extensive empirical evaluation that an implementation of the proposed decision procedures, based on boolean satisfiability (SAT) solving, is effective in deciding variants of acceptance under uncertainties. We also establish conditions for what type of atomic changes are guaranteed to be redundant from the perspective of preserving extensions of completions of incomplete AFs, and show that the results allow for considerably improving the empirical efficiency of the proposed SAT-based counterexample-guided abstraction refinement algorithms for acceptance in incomplete AFs for problem variants with complexity beyond NP.},
  archive      = {J_AIJ},
  author       = {Dorothea Baumeister and Matti Järvisalo and Daniel Neugebauer and Andreas Niskanen and Jörg Rothe},
  doi          = {10.1016/j.artint.2021.103470},
  journal      = {Artificial Intelligence},
  pages        = {103470},
  shortjournal = {Artif. Intell.},
  title        = {Acceptance in incomplete argumentation frameworks},
  volume       = {295},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). New width parameters for SAT and #SAT. <em>AIJ</em>,
<em>295</em>, 103460. (<a
href="https://doi.org/10.1016/j.artint.2021.103460">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the parameterized complexity of the propositional satisfiability (SAT) and the more general model counting (#SAT) problems and obtain novel fixed-parameter algorithms that exploit the structural properties of input formulas. In the first part of the paper, we parameterize by the treewidth of the following two graphs associated with CNF formulas: the consensus graph and the conflict graph. Both graphs have as vertices the clauses of the formula; in the consensus graph two clauses are adjacent if they do not contain a complementary pair of literals, while in the conflict graph two clauses are adjacent if they do contain a complementary pair of literals. We show that #SAT is fixed-parameter tractable when parameterized by the treewidth of the former graph, but SAT is W[1]-hard when parameterized by the treewidth of the latter graph. In the second part of the paper, we turn our attention to a novel structural parameter we call h-modularity which is loosely inspired by the well-established notion of community structure. The new parameter is defined in terms of a partition of clauses of the given CNF formula into strongly interconnected communities which are sparsely interconnected with each other. Each community forms a hitting formula, whereas the interconnections between communities form a graph of small treewidth. Our algorithms first identify the community structure and then use them for an efficient solution of SAT and #SAT, respectively.},
  archive      = {J_AIJ},
  author       = {Robert Ganian and Stefan Szeider},
  doi          = {10.1016/j.artint.2021.103460},
  journal      = {Artificial Intelligence},
  pages        = {103460},
  shortjournal = {Artif. Intell.},
  title        = {New width parameters for SAT and #SAT},
  volume       = {295},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A review of possible effects of cognitive biases on
interpretation of rule-based machine learning models. <em>AIJ</em>,
<em>295</em>, 103458. (<a
href="https://doi.org/10.1016/j.artint.2021.103458">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While the interpretability of machine learning models is often equated with their mere syntactic comprehensibility , we think that interpretability goes beyond that, and that human interpretability should also be investigated from the point of view of cognitive science. The goal of this paper is to discuss to what extent cognitive biases may affect human understanding of interpretable machine learning models, in particular of logical rules discovered from data. Twenty cognitive biases are covered, as are possible debiasing techniques that can be adopted by designers of machine learning algorithms and software. Our review transfers results obtained in cognitive psychology to the domain of machine learning, aiming to bridge the current gap between these two areas. It needs to be followed by empirical studies specifically focused on the machine learning domain.},
  archive      = {J_AIJ},
  author       = {Tomáš Kliegr and Štěpán Bahník and Johannes Fürnkranz},
  doi          = {10.1016/j.artint.2021.103458},
  journal      = {Artificial Intelligence},
  pages        = {103458},
  shortjournal = {Artif. Intell.},
  title        = {A review of possible effects of cognitive biases on interpretation of rule-based machine learning models},
  volume       = {295},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Counterfactual state explanations for reinforcement learning
agents via generative deep learning. <em>AIJ</em>, <em>295</em>, 103455.
(<a href="https://doi.org/10.1016/j.artint.2021.103455">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Counterfactual explanations, which deal with “why not?” scenarios, can provide insightful explanations to an AI agent&#39;s behavior [Miller [38] ]. In this work, we focus on generating counterfactual explanations for deep reinforcement learning (RL) agents which operate in visual input environments like Atari. We introduce counterfactual state explanations , a novel example-based approach to counterfactual explanations based on generative deep learning. Specifically, a counterfactual state illustrates what minimal change is needed to an Atari game image such that the agent chooses a different action. We also evaluate the effectiveness of counterfactual states on human participants who are not machine learning experts. Our first user study investigates if humans can discern if the counterfactual state explanations are produced by the actual game or produced by a generative deep learning approach. Our second user study investigates if counterfactual state explanations can help non-expert participants identify a flawed agent; we compare against a baseline approach based on a nearest neighbor explanation which uses images from the actual game. Our results indicate that counterfactual state explanations have sufficient fidelity to the actual game images to enable non-experts to more effectively identify a flawed RL agent compared to the nearest neighbor baseline and to having no explanation at all.},
  archive      = {J_AIJ},
  author       = {Matthew L. Olson and Roli Khanna and Lawrence Neal and Fuxin Li and Weng-Keen Wong},
  doi          = {10.1016/j.artint.2021.103455},
  journal      = {Artificial Intelligence},
  pages        = {103455},
  shortjournal = {Artif. Intell.},
  title        = {Counterfactual state explanations for reinforcement learning agents via generative deep learning},
  volume       = {295},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Learning modulo theories for constructive preference
elicitation. <em>AIJ</em>, <em>295</em>, 103454. (<a
href="https://doi.org/10.1016/j.artint.2021.103454">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces CLEO, a novel preference elicitation algorithm capable of recommending complex configurable objects characterized by both discrete and continuous attributes and constraints defined over them. While existing preference elicitation techniques focus on searching for the best instance in a database of candidates, CLEO takes a constructive approach to recommendation through interactive optimization in a space of feasible configurations. The algorithm assumes minimal initial information, i.e., a set of catalog attributes, and defines decisional features as logic formulae combining Boolean and algebraic constraints over the attributes. The (unknown) utility of the decision maker is modeled as a weighted combination of features. CLEO iteratively alternates a preference elicitation step, where pairs of candidate configurations are selected based on the current utility model, and a refinement step where the utility is refined by incorporating the feedback received. The elicitation step leverages a Max-SMT solver to return optimal configurations according to the current utility model. The refinement step is implemented as learning to rank, and a sparsifying norm is used to favor the selection of few informative features in the combinatorial space of candidate decisional features. A major feature of CLEO is that it can recommend optimal configurations in hybrid domains (i.e., including both Boolean and numeric attributes), thanks to the use of Max-SMT technology, while retaining uncertainty in the decision-maker&#39;s utility and noisy feedback. In so doing, it adapts the recently introduced learning modulo theory framework to the preference elicitation setting. The combinatorial formulation of the utility function coupled with the feature selection capabilities of 1-norm regularization allow to effectively deal with the uncertainty in the DM utility while retaining high expressiveness. Experimental results on complex recommendation tasks show the ability of CLEO to quickly identify optimal configurations, as well as its capacity to recover from suboptimal initial choices. Our empirical evaluation highlights how CLEO outperforms a state-of-the-art Bayesian preference elicitation algorithm when applied to a purely discrete task},
  archive      = {J_AIJ},
  author       = {Paolo Campigotto and Stefano Teso and Roberto Battiti and Andrea Passerini},
  doi          = {10.1016/j.artint.2021.103454},
  journal      = {Artificial Intelligence},
  pages        = {103454},
  shortjournal = {Artif. Intell.},
  title        = {Learning modulo theories for constructive preference elicitation},
  volume       = {295},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Stable fractional matchings. <em>AIJ</em>, <em>295</em>,
103416. (<a href="https://doi.org/10.1016/j.artint.2020.103416">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study a generalization of the classical stable matching problem that allows for cardinal preferences (as opposed to ordinal) and fractional matchings (as opposed to integral). In this cardinal setting, stable fractional matchings can have much larger social welfare than stable integral ones. Our goal is to understand the computational complexity of finding an optimal (i.e., welfare-maximizing) stable fractional matching. We consider both exact and approximate stability notions, and provide simple approximation algorithms with weak welfare guarantees. Our main result is that, somewhat surprisingly, achieving better approximations is computationally hard. To the best of our knowledge, these are the first computational complexity results for stable fractional matchings in the cardinal model. En route to these results, we provide a number of structural observations that could be of independent interest.},
  archive      = {J_AIJ},
  author       = {Ioannis Caragiannis and Aris Filos-Ratsikas and Panagiotis Kanellopoulos and Rohit Vaish},
  doi          = {10.1016/j.artint.2020.103416},
  journal      = {Artificial Intelligence},
  pages        = {103416},
  shortjournal = {Artif. Intell.},
  title        = {Stable fractional matchings},
  volume       = {295},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Explaining black-box classifiers using post-hoc
explanations-by-example: The effect of explanations and error-rates in
XAI user studies. <em>AIJ</em>, <em>294</em>, 103459. (<a
href="https://doi.org/10.1016/j.artint.2021.103459">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we describe a post-hoc explanation-by-example approach to eXplainable AI (XAI), where a black-box, deep learning system is explained by reference to a more transparent, proxy model (in this situation a case-based reasoner), based on a feature-weighting analysis of the former that is used to find explanatory cases from the latter (as one instance of the so-called Twin Systems approach). A novel method (COLE-HP) for extracting the feature-weights from black-box models is demonstrated for a convolutional neural network (CNN) applied to the MNIST dataset; in which extracted feature-weights are used to find explanatory, nearest-neighbours for test instances. Three user studies are reported examining people&#39;s judgements of right and wrong classifications made by this XAI twin-system, in the presence/absence of explanations-by-example and different error-rates (from 3-60\%). The judgements gathered include item-level evaluations of both correctness and reasonableness, and system-level evaluations of trust, satisfaction, correctness, and reasonableness. Several proposals are made about the user&#39;s mental model in these tasks and how it is impacted by explanations at an item- and system-level. The wider lessons from this work for XAI and its user studies are reviewed.},
  archive      = {J_AIJ},
  author       = {Eoin M. Kenny and Courtney Ford and Molly Quinn and Mark T. Keane},
  doi          = {10.1016/j.artint.2021.103459},
  journal      = {Artificial Intelligence},
  pages        = {103459},
  shortjournal = {Artif. Intell.},
  title        = {Explaining black-box classifiers using post-hoc explanations-by-example: The effect of explanations and error-rates in XAI user studies},
  volume       = {294},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). GLocalX - from local to global explanations of black box AI
models. <em>AIJ</em>, <em>294</em>, 103457. (<a
href="https://doi.org/10.1016/j.artint.2021.103457">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial Intelligence (AI) has come to prominence as one of the major components of our society, with applications in most aspects of our lives. In this field, complex and highly nonlinear machine learning models such as ensemble models, deep neural networks , and Support Vector Machines have consistently shown remarkable accuracy in solving complex tasks. Although accurate, AI models often are “black boxes” which we are not able to understand. Relying on these models has a multifaceted impact and raises significant concerns about their transparency. Applications in sensitive and critical domains are a strong motivational factor in trying to understand the behavior of black boxes. We propose to address this issue by providing an interpretable layer on top of black box models by aggregating “local” explanations. We present GLocalX , a “local-first” model agnostic explanation method. Starting from local explanations expressed in form of local decision rules, GLocalX iteratively generalizes them into global explanations by hierarchically aggregating them. Our goal is to learn accurate yet simple interpretable models to emulate the given black box, and, if possible, replace it entirely. We validate GLocalX in a set of experiments in standard and constrained settings with limited or no access to either data or local explanations. Experiments show that GLocalX is able to accurately emulate several models with simple and small models, reaching state-of-the-art performance against natively global solutions. Our findings show how it is often possible to achieve a high level of both accuracy and comprehensibility of classification models , even in complex domains with high-dimensional data, without necessarily trading one property for the other. This is a key requirement for a trustworthy AI, necessary for adoption in high-stakes decision making applications.},
  archive      = {J_AIJ},
  author       = {Mattia Setzu and Riccardo Guidotti and Anna Monreale and Franco Turini and Dino Pedreschi and Fosca Giannotti},
  doi          = {10.1016/j.artint.2021.103457},
  journal      = {Artificial Intelligence},
  pages        = {103457},
  shortjournal = {Artif. Intell.},
  title        = {GLocalX - from local to global explanations of black box AI models},
  volume       = {294},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Show or suppress? Managing input uncertainty in machine
learning model explanations. <em>AIJ</em>, <em>294</em>, 103456. (<a
href="https://doi.org/10.1016/j.artint.2021.103456">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature attribution is widely used in interpretable machine learning to explain how influential each measured input feature value is for an output inference. However, measurements can be uncertain, and it is unclear how the awareness of input uncertainty can affect the trust in explanations. We propose and study two approaches to help users to manage their perception of uncertainty in a model explanation: 1) transparently show uncertainty in feature attributions to allow users to reflect on, and 2) suppress attribution to features with uncertain measurements and shift attribution to other features by regularizing with an uncertainty penalty. Through simulation experiments, qualitative interviews, and quantitative user evaluations, we identified the benefits of moderately suppressing attribution uncertainty, and concerns regarding showing attribution uncertainty. This work adds to the understanding of handling and communicating uncertainty for model interpretability .},
  archive      = {J_AIJ},
  author       = {Danding Wang and Wencan Zhang and Brian Y. Lim},
  doi          = {10.1016/j.artint.2021.103456},
  journal      = {Artificial Intelligence},
  pages        = {103456},
  shortjournal = {Artif. Intell.},
  title        = {Show or suppress? managing input uncertainty in machine learning model explanations},
  volume       = {294},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Epistemic GDL: A logic for representing and reasoning about
imperfect information games. <em>AIJ</em>, <em>294</em>, 103453. (<a
href="https://doi.org/10.1016/j.artint.2021.103453">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a logical framework for representing and reasoning about imperfect information games. We first extend Game Description Language (GDL) with the standard epistemic operators and provide it with a semantics based on the epistemic state transition model. We then demonstrate how to use the language to represent the rules of an imperfect information game and formalize common game properties as well as epistemic properties. We also show how to use the framework to reason about players&#39; own and each others&#39; knowledge during game playing. Furthermore, we prove that the model-checking problem of the framework is in Δ 2 P Δ2P , even though its lower bound is Θ 2 P Θ2P . These results indicate that the framework makes a good balance between expressive power and computational efficiency. Finally we provide a sound and complete axiomatic system for this logic. With action, temporal and epistemic operators, the completeness proof requires a novel combination of techniques used for completeness of dynamic logic and epistemic temporal logics. The proof theory provides a feasible tool to analyze properties of a family of games.},
  archive      = {J_AIJ},
  author       = {Guifei Jiang and Dongmo Zhang and Laurent Perrussel and Heng Zhang},
  doi          = {10.1016/j.artint.2021.103453},
  journal      = {Artificial Intelligence},
  pages        = {103453},
  shortjournal = {Artif. Intell.},
  title        = {Epistemic GDL: A logic for representing and reasoning about imperfect information games},
  volume       = {294},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A semantics for hybrid probabilistic logic programs with
function symbols. <em>AIJ</em>, <em>294</em>, 103452. (<a
href="https://doi.org/10.1016/j.artint.2021.103452">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Probabilistic Logic Programming (PLP) is a powerful paradigm for the representation of uncertain relations among objects. Recently, programs with continuous variables, also called hybrid programs, have been proposed and assigned a semantics. Hybrid programs are capable of representing real-world measurements but unfortunately the semantics proposal was imprecise so the definition did not assign a probability to all queries. In this paper, we remedy this and formally define a new semantics for hybrid programs. We prove that the semantics assigns a probability to all queries for a large class of programs.},
  archive      = {J_AIJ},
  author       = {Damiano Azzolini and Fabrizio Riguzzi and Evelina Lamma},
  doi          = {10.1016/j.artint.2021.103452},
  journal      = {Artificial Intelligence},
  pages        = {103452},
  shortjournal = {Artif. Intell.},
  title        = {A semantics for hybrid probabilistic logic programs with function symbols},
  volume       = {294},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An integrated approach to solving influence diagrams and
finite-horizon partially observable decision processes. <em>AIJ</em>,
<em>294</em>, 103431. (<a
href="https://doi.org/10.1016/j.artint.2020.103431">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We show how to integrate a variable elimination approach to solving influence diagrams with a value iteration approach to solving finite-horizon partially observable Markov decision processes (POMDPs). The integration of these approaches creates a variable elimination algorithm for influence diagrams that has much more relaxed constraints on elimination order, which allows improved scalability in many cases. The new algorithm can also be viewed as a generalization of the value iteration algorithm for POMDPs that solves non-Markovian as well as Markovian problems, in addition to leveraging a factored representation for improved efficiency. The development of a single algorithm that integrates and generalizes both of these classic algorithms, one for influence diagrams and the other for POMDPs, unifies these two approaches to solving Bayesian decision problems in a way that combines their complementary advantages.},
  archive      = {J_AIJ},
  author       = {Eric A. Hansen},
  doi          = {10.1016/j.artint.2020.103431},
  journal      = {Artificial Intelligence},
  pages        = {103431},
  shortjournal = {Artif. Intell.},
  title        = {An integrated approach to solving influence diagrams and finite-horizon partially observable decision processes},
  volume       = {294},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). On the noise estimation statistics. <em>AIJ</em>,
<em>293</em>, 103451. (<a
href="https://doi.org/10.1016/j.artint.2021.103451">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning with noisy labels has attracted much attention during the past few decades. A fundamental problem is how to estimate noise proportions from corrupted data. Previous studies on this issue resort to the estimations of class distributions, conditional distributions , or the kernel embedding of distributions. In this paper, we present another simple and effective approach for noise estimation. The basic idea is to utilize the first- and second-order statistics of observed data, and the positive semi-definiteness of covariance matrices . Then, an upper bound on noise estimation is provided without additional assumptions over data distribution. Based on this idea and using the locality property of random noise, we develop the Noise Estimation Statistics with Clusters ( NESC ) method, which firstly clusters the corrupted data by k -means algorithm, and then makes noise estimation from clusters based on the first- and second-order statistics. We present the existence, uniqueness and convergence analysis of our noise estimation, and empirical studies verify the effectiveness of the NESC method.},
  archive      = {J_AIJ},
  author       = {Wei Gao and Teng Zhang and Bin-Bin Yang and Zhi-Hua Zhou},
  doi          = {10.1016/j.artint.2021.103451},
  journal      = {Artificial Intelligence},
  pages        = {103451},
  shortjournal = {Artif. Intell.},
  title        = {On the noise estimation statistics},
  volume       = {293},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Credibility dynamics: A belief-revision-based trust model
with pairwise comparisons. <em>AIJ</em>, <em>293</em>, 103450. (<a
href="https://doi.org/10.1016/j.artint.2021.103450">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Trust models have become invaluable in dynamic scenarios, such as Internet applications, since they provide means for estimating trustworthiness of potential interaction counterparts. Currently, the majority of trust models require ratings to be expressed absolutely, that is as values from some predefined scale. However, literature shows that expressing ratings absolutely can be challenging for users and susceptible to their bias. But these issues can be tackled if instead of asking users to rate with absolute values, we ask them to express preferences between pairs of alternatives. Thus, in this paper we propose a trust model where pairwise comparisons are used as ratings and where trust is expressed as a strict partial order induced over agents. To maintain a sound ordering, the model uses a belief revision technique that prevents contradictions that may arise when adding new information. The technique uses mechanisms that reason quantitatively about the reliability of information allowing the model to time-discount ratings as well as withstand deceit. We evaluate the model in a series of experiments and compare the results against established trust models. The results show that the model quickly adapts to changes, gracefully handles deceitful, noisy and biased information, and generally achieves good accuracy.},
  archive      = {J_AIJ},
  author       = {David Jelenc and Luciano H. Tamargo and Sebastian Gottifredi and Alejandro J. García},
  doi          = {10.1016/j.artint.2021.103450},
  journal      = {Artificial Intelligence},
  pages        = {103450},
  shortjournal = {Artif. Intell.},
  title        = {Credibility dynamics: A belief-revision-based trust model with pairwise comparisons},
  volume       = {293},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Computational complexity of flat and generic
assumption-based argumentation, with and without probabilities.
<em>AIJ</em>, <em>293</em>, 103449. (<a
href="https://doi.org/10.1016/j.artint.2020.103449">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reasoning with probabilistic information has recently attracted considerable attention in argumentation, and formalisms of Probabilistic Abstract Argumentation (PAA), Probabilistic Bipolar Argumentation (PBA) and Probabilistic Structured Argumentation (PSA) have been proposed. These foundational advances have been complemented with investigations on the complexity of some approaches to PAA and PBA, but not to PSA. We study the complexity of an existing form of PSA, namely Probabilistic Assumption-Based Argumentation (PABA), a powerful, implemented formalism which subsumes several forms of PAA and other forms of PSA. Specifically, we establish membership (general upper bounds) and completeness (instantiated lower bounds) of reasoning in PABA for the class FP # P FP#P (of functions with a # P #P -oracle for counting the solutions of an NP NP problem) with respect to newly introduced probabilistic verification, credulous and sceptical acceptance function problems under several ABA semantics. As a by-product necessary to establish PABA complexity results, we provide a comprehensive picture of the ABA complexity landscape (for both flat and generic, possibly non-flat ABA) for the classical decision problems of verification, existence, credulous and sceptical acceptance under those ABA semantics.},
  archive      = {J_AIJ},
  author       = {Kristijonas Čyras and Quentin Heinrich and Francesca Toni},
  doi          = {10.1016/j.artint.2020.103449},
  journal      = {Artificial Intelligence},
  pages        = {103449},
  shortjournal = {Artif. Intell.},
  title        = {Computational complexity of flat and generic assumption-based argumentation, with and without probabilities},
  volume       = {293},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multiple object tracking: A literature review. <em>AIJ</em>,
<em>293</em>, 103448. (<a
href="https://doi.org/10.1016/j.artint.2020.103448">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multiple Object Tracking (MOT) has gained increasing attention due to its academic and commercial potential. Although different approaches have been proposed to tackle this problem, it still remains challenging due to factors like abrupt appearance changes and severe object occlusions. In this work, we contribute the first comprehensive and most recent review on this problem. We inspect the recent advances in various aspects and propose some interesting directions for future research. To the best of our knowledge, there has not been any extensive review on this topic in the community. We endeavor to provide a thorough review on the development of this problem in recent decades. The main contributions of this review are fourfold: 1) Key aspects in an MOT system, including formulation, categorization, key principles, evaluation of MOT are discussed; 2) Instead of enumerating individual works, we discuss existing approaches according to various aspects, in each of which methods are divided into different groups and each group is discussed in detail for the principles, advances and drawbacks; 3) We examine experiments of existing publications and summarize results on popular datasets to provide quantitative and comprehensive comparisons. By analyzing the results from different perspectives, we have verified some basic agreements in the field; and 4) We provide a discussion about issues of MOT research , as well as some interesting directions which will become potential research effort in the future.},
  archive      = {J_AIJ},
  author       = {Wenhan Luo and Junliang Xing and Anton Milan and Xiaoqin Zhang and Wei Liu and Tae-Kyun Kim},
  doi          = {10.1016/j.artint.2020.103448},
  journal      = {Artificial Intelligence},
  pages        = {103448},
  shortjournal = {Artif. Intell.},
  title        = {Multiple object tracking: A literature review},
  volume       = {293},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Making sense of sensory input. <em>AIJ</em>, <em>293</em>,
103438. (<a href="https://doi.org/10.1016/j.artint.2020.103438">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper attempts to answer a central question in unsupervised learning : what does it mean to “make sense” of a sensory sequence? In our formalization, making sense involves constructing a symbolic causal theory that both explains the sensory sequence and also satisfies a set of unity conditions. The unity conditions insist that the constituents of the causal theory – objects, properties, and laws – must be integrated into a coherent whole. On our account, making sense of sensory input is a type of program synthesis , but it is unsupervised program synthesis. Our second contribution is a computer implementation, the Apperception Engine , that was designed to satisfy the above requirements. Our system is able to produce interpretable human-readable causal theories from very small amounts of data, because of the strong inductive bias provided by the unity conditions. A causal theory produced by our system is able to predict future sensor readings, as well as retrodict earlier readings, and impute (fill in the blanks of) missing sensory readings, in any combination. In fact, it is able to do all three tasks simultaneously. We tested the engine in a diverse variety of domains, including cellular automata , rhythms and simple nursery tunes, multi-modal binding problems, occlusion tasks, and sequence induction intelligence tests. In each domain, we test our engine&#39;s ability to predict future sensor values, retrodict earlier sensor values, and impute missing sensory data. The Apperception Engine performs well in all these domains, significantly out-performing neural net baselines. We note in particular that in the sequence induction intelligence tests, our system achieved human-level performance. This is notable because our system is not a bespoke system designed specifically to solve intelligence tests, but a general-purpose system that was designed to make sense of any sensory sequence.},
  archive      = {J_AIJ},
  author       = {Richard Evans and José Hernández-Orallo and Johannes Welbl and Pushmeet Kohli and Marek Sergot},
  doi          = {10.1016/j.artint.2020.103438},
  journal      = {Artificial Intelligence},
  pages        = {103438},
  shortjournal = {Artif. Intell.},
  title        = {Making sense of sensory input},
  volume       = {293},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Fair division of mixed divisible and indivisible goods.
<em>AIJ</em>, <em>293</em>, 103436. (<a
href="https://doi.org/10.1016/j.artint.2020.103436">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the problem of fair division when the set of resources contains both divisible and indivisible goods. Classic fairness notions such as envy-freeness (EF) and envy-freeness up to one good (EF1) cannot be directly applied to this mixed goods setting. In this work, we propose a new fairness notion, envy-freeness for mixed goods (EFM) , which is a direct generalization of both EF and EF1 to the mixed goods setting. We prove that an EFM allocation always exists for any number of agents with additive valuations. We also propose efficient algorithms to compute an EFM allocation for two agents with general additive valuations and for n agents with piecewise linear valuations over the divisible goods. Finally, we relax the envy-freeness requirement, instead asking for ϵ-envy-freeness for mixed goods (ϵ-EFM) , and present an efficient algorithm that finds an ϵ -EFM allocation.},
  archive      = {J_AIJ},
  author       = {Xiaohui Bei and Zihao Li and Jinyan Liu and Shengxin Liu and Xinhang Lu},
  doi          = {10.1016/j.artint.2020.103436},
  journal      = {Artificial Intelligence},
  pages        = {103436},
  shortjournal = {Artif. Intell.},
  title        = {Fair division of mixed divisible and indivisible goods},
  volume       = {293},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Embedding deep networks into visual explanations.
<em>AIJ</em>, <em>292</em>, 103435. (<a
href="https://doi.org/10.1016/j.artint.2020.103435">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a novel Explanation Neural Network (XNN) to explain the predictions made by a deep network. The XNN works by learning a nonlinear embedding of a high-dimensional activation vector of a deep network layer into a low-dimensional explanation space while retaining faithfulness i.e., the original deep learning predictions can be constructed from the few concepts extracted by our explanation network. We then visualize such concepts for human to learn about the high-level concepts that the deep network is using to make decisions. We propose an algorithm called Sparse Reconstruction Autoencoder (SRAE) for learning the embedding to the explanation space. SRAE aims to reconstruct part of the original feature space while retaining faithfulness. A pull-away term is applied to SRAE to make the bases of the explanation space more orthogonal to each other. A visualization system is then introduced for human understanding of the features in the explanation space. The proposed method is applied to explain CNN models in image classification tasks . We conducted a human study, which shows that the proposed approach outperforms single saliency map baselines, and improves human performance on a difficult classification task. Besides, several novel metrics are introduced to evaluate the performance of explanations quantitatively without human involvement.},
  archive      = {J_AIJ},
  author       = {Zhongang Qi and Saeed Khorram and Li Fuxin},
  doi          = {10.1016/j.artint.2020.103435},
  journal      = {Artificial Intelligence},
  pages        = {103435},
  shortjournal = {Artif. Intell.},
  title        = {Embedding deep networks into visual explanations},
  volume       = {292},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Spatial relation learning for explainable image
classification and annotation in critical applications. <em>AIJ</em>,
<em>292</em>, 103434. (<a
href="https://doi.org/10.1016/j.artint.2020.103434">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the recent successes of black-box models in Artificial Intelligence (AI) and the growing interactions between humans and AIs, explainability issues have risen. In this article, in the context of high-stake applications, we propose an approach for explainable classification and annotation of images. It is based on a transparent model, whose reasoning is accessible and human understandable, and on interpretable fuzzy relations that enable to express the vagueness of natural language. The knowledge about relations is set beforehand by an expert and thus training instances do not need to be annotated. The most relevant relations are extracted using a fuzzy frequent itemset mining algorithm in order to build rules, for classification, and constraints, for annotation. We also present two heuristics that make the process of evaluating relations faster. Since the strengths of our approach are the transparency of the model and the interpretability of the relations, an explanation in natural language can be generated. Supported by experimental results, we show that, given a segmentation of the input, our approach is able to successfully perform the target task and generate explanations that were judged as consistent and convincing by a set of participants.},
  archive      = {J_AIJ},
  author       = {Régis Pierrard and Jean-Philippe Poli and Céline Hudelot},
  doi          = {10.1016/j.artint.2020.103434},
  journal      = {Artificial Intelligence},
  pages        = {103434},
  shortjournal = {Artif. Intell.},
  title        = {Spatial relation learning for explainable image classification and annotation in critical applications},
  volume       = {292},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Game description language and dynamic epistemic logic
compared. <em>AIJ</em>, <em>292</em>, 103433. (<a
href="https://doi.org/10.1016/j.artint.2020.103433">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Several different frameworks have been proposed to model and reason about knowledge in dynamic multi-agent settings, among them the logic-programming-based game description language GDL-III and dynamic epistemic logic (DEL). GDL-III and DEL have complementary strengths and weaknesses in terms of ease of modeling and simplicity of semantics. In this paper, we formally study the expressiveness of GDL-III vs. DEL. We clarify the commonalities and differences between those languages, demonstrate how to bridge the differences where possible, and identify large fragments of GDL-III and DEL that are equivalent in the sense that they can be used to encode games or planning tasks that admit the same legal action sequences. We prove the latter by providing translations between those fragments of GDL-III and DEL.},
  archive      = {J_AIJ},
  author       = {Thorsten Engesser and Robert Mattmüller and Bernhard Nebel and Michael Thielscher},
  doi          = {10.1016/j.artint.2020.103433},
  journal      = {Artificial Intelligence},
  pages        = {103433},
  shortjournal = {Artif. Intell.},
  title        = {Game description language and dynamic epistemic logic compared},
  volume       = {292},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Metamodeling and metaquerying in OWL 2 QL. <em>AIJ</em>,
<em>292</em>, 103432. (<a
href="https://doi.org/10.1016/j.artint.2020.103432">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {OWL 2 QL is a standard profile of the OWL 2 ontology language , specifically tailored to Ontology-Based Data Management. Inspired by recent work on higher-order Description Logics , in this paper we present a new semantics for OWL 2 QL ontologies, called Metamodeling Semantics (MS), and show that, in contrast to the official Direct Semantics (DS) for OWL 2 , it allows exploiting the metamodeling capabilities natively offered by the OWL 2 punning. We then extend unions of conjunctive queries with both metavariables, and the possibility of using TBox atoms, with the purpose of expressing meaningful metalevel queries. We first show that under MS both satisfiability checking and answering queries including only ABox atoms, have the same complexity as under DS. Second, we investigate the problem of answering general metaqueries, and single out a new source of complexity coming from the combined presence of a specific type of incompleteness in the ontology, and of TBox axioms among the query atoms. Then we focus on a specific class of ontologies, called TBox-complete, where there is no incompleteness in the TBox axioms, and show that general metaquery answering in this case has again the same complexity as under DS. Finally, we move to general ontologies and show that answering general metaqueries is coNP-complete with respect to ontology complexity, Π 2 p Π2p -complete with respect to combined complexity, and remains AC 0 AC0 with respect to ABox complexity.},
  archive      = {J_AIJ},
  author       = {Maurizio Lenzerini and Lorenzo Lepore and Antonella Poggi},
  doi          = {10.1016/j.artint.2020.103432},
  journal      = {Artificial Intelligence},
  pages        = {103432},
  shortjournal = {Artif. Intell.},
  title        = {Metamodeling and metaquerying in OWL 2 QL},
  volume       = {292},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Time-delayed collective flow diffusion models for inferring
latent people flow from aggregated data at limited locations.
<em>AIJ</em>, <em>292</em>, 103430. (<a
href="https://doi.org/10.1016/j.artint.2020.103430">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid adoption of wireless sensor devices has made it easier to record location information of people in a variety of spaces (e.g., exhibition halls). Location information is often aggregated due to privacy and/or cost concerns. The aggregated data we use as input consist of the numbers of incoming and outgoing people at each location and at each time step. Since the aggregated data lack tracking information of individuals, determining the flow of people between locations is not straightforward. In this article, we address the problem of inferring latent people flows, that is, transition populations between locations, from just aggregated population data gathered from observed locations. Existing models assume that everyone is always in one of the observed locations at every time step; this, however, is an unrealistic assumption, because we do not always have a large enough number of sensor devices to cover the large-scale spaces targeted. To overcome this drawback, we propose a probabilistic model with flow conservation constraints that incorporate travel duration distributions between observed locations. To handle noisy settings, we adopt noisy observation models for the numbers of incoming and outgoing people, where the noise is regarded as a factor that may disturb flow conservation, e.g., people may appear in or disappear from the predefined space of interest. We develop an approximate expectation-maximization (EM) algorithm that simultaneously estimates transition populations and model parameters. Our experiments demonstrate the effectiveness of the proposed model on real-world datasets of pedestrian data in exhibition halls, bike trip data and taxi trip data in New York City.},
  archive      = {J_AIJ},
  author       = {Yusuke Tanaka and Tomoharu Iwata and Takeshi Kurashima and Hiroyuki Toda and Naonori Ueda and Toshiyuki Tanaka},
  doi          = {10.1016/j.artint.2020.103430},
  journal      = {Artificial Intelligence},
  pages        = {103430},
  shortjournal = {Artif. Intell.},
  title        = {Time-delayed collective flow diffusion models for inferring latent people flow from aggregated data at limited locations},
  volume       = {292},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Weakly-supervised sensor-based activity segmentation and
recognition via learning from distributions. <em>AIJ</em>, <em>292</em>,
103429. (<a href="https://doi.org/10.1016/j.artint.2020.103429">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sensor-based activity recognition aims to recognize users&#39; activities from multi-dimensional streams of sensor readings received from ubiquitous sensors. It has been shown that data segmentation and feature extraction are two crucial steps in developing machine learning-based models for sensor-based activity recognition. However, most previous studies were only focused on the latter step by assuming that data segmentation is done in advance. In practice, on the one hand, doing data segmentation on sensory streams is very challenging. On the other hand, if data segmentation is considered as a pre-process, the errors in data segmentation may be propagated to latter steps. Therefore, in this paper, we propose a unified weakly-supervised framework based on kernel embedding of distributions to jointly segment sensor streams, extract powerful features from each segment, and train a final classifier for activity recognition. We further offer an accelerated version for large-scale data by utilizing the technique of random Fourier features . We conduct experiments on four benchmark datasets to verify the effectiveness and scalability of our proposed framework.},
  archive      = {J_AIJ},
  author       = {Hangwei Qian and Sinno Jialin Pan and Chunyan Miao},
  doi          = {10.1016/j.artint.2020.103429},
  journal      = {Artificial Intelligence},
  pages        = {103429},
  shortjournal = {Artif. Intell.},
  title        = {Weakly-supervised sensor-based activity segmentation and recognition via learning from distributions},
  volume       = {292},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Dependency-based syntax-aware word representations.
<em>AIJ</em>, <em>292</em>, 103427. (<a
href="https://doi.org/10.1016/j.artint.2020.103427">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dependency syntax has been demonstrated highly useful for a number of natural language processing (NLP) tasks. Typical approaches of utilizing dependency syntax include Tree-RNN and Tree-Linearization, both of which exploit explicit 1-best tree outputs from a well-trained parser as inputs. However, these approaches may suffer from error propagation due to the inevitable errors contained in the 1-best tree outputs. In this work, we propose a novel approach to integrate dependency syntax without using the discrete tree outputs. The key idea is to use the intermediate hidden representations of a well-trained encoder-decoder dependency parser , which are referred to as Dep endency-based S yntax- A ware W ord R epresentations ( Dep-SAWR s). Then, we simply concatenate such Dep-SAWRs with the conventional context-insensitive word embeddings to compose input word representations, without requiring to modify the model architecture of the downstream tasks. We evaluate the proposed method on four kinds of typical NLP tasks, including sentence classification, sentence matching, sequence labeling and machine translation. Experimental results show that the proposed approach is highly promising. On the one hand, it can utilize dependency syntax effectively, bringing consistently better performance on the four tasks compared with baselines without using syntax. On the other hand, the proposed method can outperform the Tree-RNN and Tree-Linearization approaches in most settings, and meanwhile are highly efficient in syntax integration. In addition, the proposed method would be easily extendable to encoding other structural attributes of language.},
  archive      = {J_AIJ},
  author       = {Meishan Zhang and Zhenghua Li and Guohong Fu and Min Zhang},
  doi          = {10.1016/j.artint.2020.103427},
  journal      = {Artificial Intelligence},
  pages        = {103427},
  shortjournal = {Artif. Intell.},
  title        = {Dependency-based syntax-aware word representations},
  volume       = {292},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Using POMDPs for learning cost sensitive decision trees.
<em>AIJ</em>, <em>292</em>, 103400. (<a
href="https://doi.org/10.1016/j.artint.2020.103400">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In classification, an algorithm learns to classify a given instance based on a set of observed attribute values. In many real world cases testing the value of an attribute incurs a cost. Furthermore, there can also be a cost associated with the misclassification of an instance. Cost sensitive classification attempts to minimize the expected cost of classification, by deciding after each observed attribute value, which attribute to measure next. In this paper we suggest Partially Observable Markov Decision Processes (POMDPs) as a modeling tool for cost sensitive classification. POMDPs are typically solved through a policy over belief states. We show how a relatively small set of potentially important belief states can be identified, and define an MDP over these belief states. To identify these potentially important belief states, we construct standard decision trees over all attribute subsets , and the leaves of these trees become the state space of our tree-based MDP. At each phase we decide on the next attribute to measure, balancing the cost of the measurement and the classification accuracy . We compare our approach to a set of previous approaches, showing our approach to work better for a range of misclassification costs.},
  archive      = {J_AIJ},
  author       = {Shlomi Maliah and Guy Shani},
  doi          = {10.1016/j.artint.2020.103400},
  journal      = {Artificial Intelligence},
  pages        = {103400},
  shortjournal = {Artif. Intell.},
  title        = {Using POMDPs for learning cost sensitive decision trees},
  volume       = {292},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Evaluating local explanation methods on ground truth.
<em>AIJ</em>, <em>291</em>, 103428. (<a
href="https://doi.org/10.1016/j.artint.2020.103428">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Evaluating local explanation methods is a difficult task due to the lack of a shared and universally accepted definition of explanation. In the literature, one of the most common ways to assess the performance of an explanation method is to measure the fidelity of the explanation with respect to the classification of a black box model adopted by an Artificial Intelligent system for making a decision. However, this kind of evaluation only measures the degree of adherence of the local explainer in reproducing the behavior of the black box classifier with respect to the final decision. Therefore, the explanation provided by the local explainer could be different in the content even though it leads to the same decision of the AI system. In this paper, we propose an approach that allows to measure to which extent the explanations returned by local explanation methods are correct with respect to a synthetic ground truth explanation. Indeed, the proposed methodology enables the generation of synthetic transparent classifiers for which the reason for the decision taken, i.e., a synthetic ground truth explanation, is available by design. Experimental results show how the proposed approach allows to easily evaluate local explanations on the ground truth and to characterize the quality of local explanation methods.},
  archive      = {J_AIJ},
  author       = {Riccardo Guidotti},
  doi          = {10.1016/j.artint.2020.103428},
  journal      = {Artificial Intelligence},
  pages        = {103428},
  shortjournal = {Artif. Intell.},
  title        = {Evaluating local explanation methods on ground truth},
  volume       = {291},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). X*: Anytime multi-agent path finding for sparse domains
using window-based iterative repairs. <em>AIJ</em>, <em>291</em>,
103417. (<a href="https://doi.org/10.1016/j.artint.2020.103417">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Real-world multi-agent systems such as warehouse robots operate under significant time constraints – in such settings, rather than spending significant amounts of time solving for optimal paths, it is instead preferable to find valid, collision-free paths quickly, even if suboptimal, and given additional time, to iteratively refine such paths to improve their cost. In such domains, we observe that agent-agent collisions are sparse – they involve small local subsets of agents, and are geographically contained within a small region of the overall space. Leveraging this insight, we can first plan paths for each agent individually, and in the cases of collisions between agents, perform small local repairs limited to local subspace windows . As time permits, these windows can be successively grown and the repairs within them refined, thereby improving the path quality, and eventually converging to the global joint optimal solution. Using these insights, we present two algorithmic contributions: 1) the Windowed Anytime Multiagent Planning Framework (WAMPF) for a class of anytime planners that quickly generate valid paths with suboptimality estimates and generate optimal paths given sufficient time, and 2) X*, an efficient WAMPF-based planner. X* is able to efficiently find successive valid solutions by employing re-use techniques during the repair growth step of WAMPF. Experimentally, we demonstrate that in sparse domains: 1) X* outperforms state-of-the-art anytime or optimal MAPF solvers in time to valid path, 2) X* is competitive with state-of-the-art anytime or optimal MAPF solvers in time to optimal path, 3) X* quickly converges to very tight suboptimality bounds, and 4) X* is competitive with state-of-the-art suboptimal MAPF solvers in time to valid path for small numbers of agents while providing much higher quality paths.},
  archive      = {J_AIJ},
  author       = {Kyle Vedder and Joydeep Biswas},
  doi          = {10.1016/j.artint.2020.103417},
  journal      = {Artificial Intelligence},
  pages        = {103417},
  shortjournal = {Artif. Intell.},
  title        = {X*: Anytime multi-agent path finding for sparse domains using window-based iterative repairs},
  volume       = {291},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Mis- and disinformation in a bounded confidence model.
<em>AIJ</em>, <em>291</em>, 103415. (<a
href="https://doi.org/10.1016/j.artint.2020.103415">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The bounded confidence model has been widely used to formally study groups of agents who are sharing opinions with those in their epistemic neighborhood. We revisit the model with an eye toward studying mis- and disinformation campaigns, which have been much in the news of late. To that end, we introduce typed agents into the model, specifically agents who can be irresponsible in different ways, most notably, by being deceitful, but also by being reluctant to try and obtain information from the world directly. We further add a mechanism of confidence dynamics to the model, which—among other things—allows agents to adapt the closeness threshold for counting others as being their epistemic neighbors. This will be used to study the effectiveness of possible defense mechanisms against mis- and disinformation efforts.},
  archive      = {J_AIJ},
  author       = {Igor Douven and Rainer Hegselmann},
  doi          = {10.1016/j.artint.2020.103415},
  journal      = {Artificial Intelligence},
  pages        = {103415},
  shortjournal = {Artif. Intell.},
  title        = {Mis- and disinformation in a bounded confidence model},
  volume       = {291},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Selecting goals in oversubscription planning using relaxed
plans. <em>AIJ</em>, <em>291</em>, 103414. (<a
href="https://doi.org/10.1016/j.artint.2020.103414">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Planning deals with the task of finding an ordered set of actions that achieves some goals from an initial state. In many real-world applications it is unfeasible to find a plan achieving all goals due to limitations in the available resources. A common case consists of having a bound on a given cost measure that is less than the optimal cost needed to achieve all goals. Oversubscription planning (OSP) is the field of Automated Planning dealing with such kinds of problems. Usually, OSP generates plans that achieve only a subset of the goals set. In this paper we present a new technique to a priori select goals in no-hard-goals satisficing OSP by searching in the space of subsets of goals. A key property of the proposed approach is that it is planner-independent once the goals have been selected; it creates a new non-OSP problem that can be solved using off-the-shelf planners. Extensive experimental results show that the proposed approach outperforms state-of-the-art OSP techniques in several domains of the International Planning Competition.},
  archive      = {J_AIJ},
  author       = {Angel García-Olaya and Tomás de la Rosa and Daniel Borrajo},
  doi          = {10.1016/j.artint.2020.103414},
  journal      = {Artificial Intelligence},
  pages        = {103414},
  shortjournal = {Artif. Intell.},
  title        = {Selecting goals in oversubscription planning using relaxed plans},
  volume       = {291},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Dynamically improved bounds bidirectional search.
<em>AIJ</em>, <em>291</em>, 103405. (<a
href="https://doi.org/10.1016/j.artint.2020.103405">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a bidirectional search algorithm that dynamically improves the bounds during its execution. It has the property that it always terminates on or before the forward search meets the backward search. Computational experiments on the pancake problem, the sliding tile puzzle, and the topspin problem demonstrate that it is capable of solving problems using significantly fewer node expansions than A ⁎ or state-of-the-art bidirectional algorithms such as MM ϵ and GBFHS .},
  archive      = {J_AIJ},
  author       = {E.C. Sewell and S.H. Jacobson},
  doi          = {10.1016/j.artint.2020.103405},
  journal      = {Artificial Intelligence},
  pages        = {103405},
  shortjournal = {Artif. Intell.},
  title        = {Dynamically improved bounds bidirectional search},
  volume       = {291},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Evaluating XAI: A comparison of rule-based and example-based
explanations. <em>AIJ</em>, <em>291</em>, 103404. (<a
href="https://doi.org/10.1016/j.artint.2020.103404">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Current developments in Artificial Intelligence (AI) led to a resurgence of Explainable AI (XAI). New methods are being researched to obtain information from AI systems in order to generate explanations for their output. However, there is an overall lack of valid and reliable evaluations of the effects on users&#39; experience of, and behavior in response to explanations. New XAI methods are often based on an intuitive notion what an effective explanation should be. Rule- and example-based contrastive explanations are two exemplary explanation styles. In this study we evaluate the effects of these two explanation styles on system understanding, persuasive power and task performance in the context of decision support in diabetes self-management. Furthermore, we provide three sets of recommendations based on our experience designing this evaluation to help improve future evaluations. Our results show that rule-based explanations have a small positive effect on system understanding, whereas both rule- and example-based explanations seem to persuade users in following the advice even when incorrect. Neither explanation improves task performance compared to no explanation. This can be explained by the fact that both explanation styles only provide details relevant for a single decision, not the underlying rational or causality. These results show the importance of user evaluations in assessing the current assumptions and intuitions on effective explanations.},
  archive      = {J_AIJ},
  author       = {Jasper van der Waa and Elisabeth Nieuwburg and Anita Cremers and Mark Neerincx},
  doi          = {10.1016/j.artint.2020.103404},
  journal      = {Artificial Intelligence},
  pages        = {103404},
  shortjournal = {Artif. Intell.},
  title        = {Evaluating XAI: A comparison of rule-based and example-based explanations},
  volume       = {291},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Robustness among multiwinner voting rules. <em>AIJ</em>,
<em>290</em>, 103403. (<a
href="https://doi.org/10.1016/j.artint.2020.103403">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We investigate how robust the results of committee elections are with respect to small changes in the input preference orders, depending on the voting rules used. We find that for typical rules the effect of making a single swap of adjacent candidates in a single preference order is either that (1) at most one committee member might be replaced, or (2) it is possible that the whole committee will be replaced. We also show that the problem of computing the smallest number of swaps that lead to changing the election outcome is typically NP-hard, but there are natural FPT algorithms. Finally, for a number of rules we assess experimentally the average number of random swaps necessary to change the election result.},
  archive      = {J_AIJ},
  author       = {Robert Bredereck and Piotr Faliszewski and Andrzej Kaczmarczyk and Rolf Niedermeier and Piotr Skowron and Nimrod Talmon},
  doi          = {10.1016/j.artint.2020.103403},
  journal      = {Artificial Intelligence},
  pages        = {103403},
  shortjournal = {Artif. Intell.},
  title        = {Robustness among multiwinner voting rules},
  volume       = {290},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Pruning external minimality checking for answer set programs
using semantic dependencies. <em>AIJ</em>, <em>290</em>, 103402. (<a
href="https://doi.org/10.1016/j.artint.2020.103402">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Answer set programming (ASP) has become an increasingly popular approach for declarative problem solving. In order to address the needs of applications, ASP has been extended in different approaches with means for interfacing the outside world, of which hex programs are one of the most powerful such extension that provides API-style interfaces to access arbitrary external sources of information and computation, respectively. Adhering to the principle of founded derivation, computing answer sets of hex programs requires an external (e-) minimality check for answer set candidates in order to prevent cyclic justifications via external sources. Due to the generic nature of external sources, the check can be a bottleneck in practice. To mitigate this, various optimizations have been developed previously, including the use of syntactic information about atom dependencies in order to detect cases when an e-minimality check can be avoided. However, the approach largely over-approximates the real dependencies due to the black-box nature of external sources. We thus consider in this work the use of semantic information for achieving better approximations . To this end, we introduce input-output (io-) dependencies for external sources, which intuitively link the occurrence of values in the result of a call to an external source to the occurrence of values in the input provided to this call. It appears that disposing of information about io-dependencies significantly increases the potential for pruning e-minimality checks, and an empirical evaluation exhibits a clear benefit of this approach. Moreover, we study semantic and computational properties of io-dependencies and provide algorithms for constructing and optimizing sets of io-dependencies. Our work aims at laying some foundations for the use of semantic dependency information in external source access from ASP. The results are not limited to hex programs, but may analogously be deployed to other approaches that integrate external sources into ASP, such as clingo or wasp with external propagators. Furthermore, the results may be applied in other parts of the hex program evaluation pipeline as well.},
  archive      = {J_AIJ},
  author       = {Thomas Eiter and Tobias Kaminski},
  doi          = {10.1016/j.artint.2020.103402},
  journal      = {Artificial Intelligence},
  pages        = {103402},
  shortjournal = {Artif. Intell.},
  title        = {Pruning external minimality checking for answer set programs using semantic dependencies},
  volume       = {290},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Protecting elections by recounting ballots. <em>AIJ</em>,
<em>290</em>, 103401. (<a
href="https://doi.org/10.1016/j.artint.2020.103401">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Complexity of voting manipulation is a prominent topic in computational social choice. In this work, we consider a two-stage voting manipulation scenario. First, a malicious party (an attacker) attempts to manipulate the election outcome in favor of a preferred candidate by changing the vote counts in some of the voting districts. Afterwards, another party (a defender), which cares about the voters&#39; wishes, demands a recount in a subset of the manipulated districts, restoring their vote counts to their original values. We investigate the resulting Stackelberg game for the case where votes are aggregated using two variants of the Plurality rule, and obtain an almost complete picture of the complexity landscape, both from the attacker&#39;s and from the defender&#39;s perspective.},
  archive      = {J_AIJ},
  author       = {Edith Elkind and Jiarui Gan and Svetlana Obraztsova and Zinovi Rabinovich and Alexandros A. Voudouris},
  doi          = {10.1016/j.artint.2020.103401},
  journal      = {Artificial Intelligence},
  pages        = {103401},
  shortjournal = {Artif. Intell.},
  title        = {Protecting elections by recounting ballots},
  volume       = {290},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A reconstruction of multipreference closure. <em>AIJ</em>,
<em>290</em>, 103398. (<a
href="https://doi.org/10.1016/j.artint.2020.103398">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paper describes a preferential approach for dealing with exceptions in KLM preferential logics, based on the rational closure. It is well known that rational closure does not allow an independent handling of inheritance of different defeasible properties of concepts. In this work, we consider an alternative closure construction, called Multi Preference closure (MP-closure), which has been first considered for reasoning with exceptions in DLs. We reconstruct the notion of MP-closure in the propositional case and show that it is a natural (weaker) variant of Lehmann&#39;s lexicographic closure, which appears to be too bold in some cases. The MP-closure defines a preferential consequence relation that, although weaker than lexicographic closure, is stronger than Relevant Closure.},
  archive      = {J_AIJ},
  author       = {Laura Giordano and Valentina Gliozzi},
  doi          = {10.1016/j.artint.2020.103398},
  journal      = {Artificial Intelligence},
  pages        = {103398},
  shortjournal = {Artif. Intell.},
  title        = {A reconstruction of multipreference closure},
  volume       = {290},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). On fair price discrimination in multi-unit markets.
<em>AIJ</em>, <em>290</em>, 103388. (<a
href="https://doi.org/10.1016/j.artint.2020.103388">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Discriminatory pricing policies, even if often perceived as unfair, are widespread. In fact, pricing differences for the same item among different national markets are common, or forms of discrimination based on the time of purchase, like in tickets&#39; sales. In this work, we propose a framework for capturing “fair” price discrimination policies that can be tolerated by customers, and study its application to multi-unit markets, in which many copies of the same item are on sale. Our model is able to incorporate the fundamental discrimination settings proposed in the literature, by expressing individual buyers constraints for assigning prices by means of a social relationship graph, modeling the information that each buyer can acquire about the prices assigned to the other buyers. After pointing out the positive effects of fair price discrimination, we investigate the computational complexity of maximizing the social welfare and the revenue in these markets, providing polynomial time , hardness and approximation results under various assumptions on the buyers&#39; valuations and on the social graph topology .},
  archive      = {J_AIJ},
  author       = {Michele Flammini and Manuel Mauro and Matteo Tonelli},
  doi          = {10.1016/j.artint.2020.103388},
  journal      = {Artificial Intelligence},
  pages        = {103388},
  shortjournal = {Artif. Intell.},
  title        = {On fair price discrimination in multi-unit markets},
  volume       = {290},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Swarm intelligence for self-organized clustering.
<em>AIJ</em>, <em>290</em>, 103237. (<a
href="https://doi.org/10.1016/j.artint.2020.103237">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Algorithms implementing populations of agents which interact with one another and sense their environment may exhibit emergent behavior such as self-organization and swarm intelligence . Here a swarm system, called Databionic swarm (DBS), is introduced which is able to adapt itself to structures of high-dimensional data characterized by distance and/or density-based structures in the data space. By exploiting the interrelations of swarm intelligence , self-organization and emergence, DBS serves as an alternative approach to the optimization of a global objective function in the task of clustering. The swarm omits the usage of a global objective function and is parameter-free because it searches for the Nash equilibrium during its annealing process . To our knowledge, DBS is the first swarm combining these approaches. Its clustering can outperform common clustering methods such as K-means, PAM, single linkage, spectral clustering , model-based clustering, and Ward, if no prior knowledge about the data is available. A central problem in clustering is the correct estimation of the number of clusters. This is addressed by a DBS visualization called topographic map which allows assessing the number of clusters. It is known that all clustering algorithms construct clusters, irrespective of the data set contains clusters or not. In contrast to most other clustering algorithms , the topographic map identifies, that clustering of the data is meaningless if the data contains no (natural) clusters. The performance of DBS is demonstrated on a set of benchmark data, which are constructed to pose difficult clustering problems and in two real-world applications.},
  archive      = {J_AIJ},
  author       = {Michael C. Thrun and Alfred Ultsch},
  doi          = {10.1016/j.artint.2020.103237},
  journal      = {Artificial Intelligence},
  pages        = {103237},
  shortjournal = {Artif. Intell.},
  title        = {Swarm intelligence for self-organized clustering},
  volume       = {290},
  year         = {2021},
}
</textarea>
</details></li>
</ul>

</body>
</html>
