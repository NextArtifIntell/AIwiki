<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>ARTMED_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="artmed---139">ARTMED - 139</h2>
<ul>
<li><details>
<summary>
(2021). Automated tibiofemoral joint segmentation based on deeply
supervised 2D-3D ensemble u-net: Data from the osteoarthritis
initiative. <em>ARTMED</em>, <em>122</em>, 102213. (<a
href="https://doi.org/10.1016/j.artmed.2021.102213">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Improving longevity is one of the greatest achievements in humanity. Because of this, the population is growing older, and the ubiquity of knee osteoarthritis (OA) is on the rise. Nonetheless, the understanding and ability to investigate potential precursors of knee OA have been impeded by time-consuming and laborious manual delineation processes which are prone to poor reproducibility. A method for automatic segmentation of the tibiofemoral joint using magnetic resonance imaging (MRI) is presented in this work. The proposed method utilizes a deeply supervised 2D-3D ensemble U-Net, which consists of foreground class oversampling, deep supervision loss branches, and Gaussian weighted softmax score aggregation. It was designed, optimized, and tested on 507 3D double echo steady-state (DESS) MR volumes using a two-fold cross-validation approach. A state-of-the-art segmentation accuracy measured as Dice similarity coefficient (DSC) for the femur bone (98.6 ± 0.27%), tibia bone (98.8 ± 0.31%), femoral cartilage (90.3 ± 2.89%), and tibial cartilage (86.7 ± 4.07%) is achieved. Notably, the proposed method yields sub-voxel accuracy for an average symmetric surface distance (ASD) less than 0.36 mm. The model performance is not affected by the severity of radiographic osteoarthritis (rOA) grades or the presence of pathophysiological changes. The proposed method offers an accurate segmentation with high time efficiency (~62 s) per 3D volume, which is well suited for efficient processing and analysis of the large prospective cohorts of the Osteoarthritis Initiative (OAI).},
  archive      = {J_ARTMED},
  author       = {Muhamad Hafiz Abd Latif and Ibrahima Faye},
  doi          = {10.1016/j.artmed.2021.102213},
  journal      = {Artificial Intelligence in Medicine},
  month        = {12},
  pages        = {102213},
  shortjournal = {Artif. Intell. Med.},
  title        = {Automated tibiofemoral joint segmentation based on deeply supervised 2D-3D ensemble U-net: Data from the osteoarthritis initiative},
  volume       = {122},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). TEDAR: Temporal dynamic signal detection of adverse
reactions. <em>ARTMED</em>, <em>122</em>, 102212. (<a
href="https://doi.org/10.1016/j.artmed.2021.102212">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Computational approaches to detect the signals of adverse drug reactions are powerful tools to monitor the unattended effects that users experience and report, also preventing death and serious injury . They apply statistical indices to affirm the validity of adverse reactions reported by users. The methodologies that scan fixed duration intervals in the lifetime of drugs are among the most used. Here we present a method, called TEDAR, in which ranges of varying length are taken into account. TEDAR has the advantage to detect a greater number of true signals without significantly increasing the number of false positives, which are a major concern for this type of tools. Furthermore, early detection of signals is a key feature of methods to prevent the safety of the population. The results show that TEDAR detects adverse reactions many months earlier than methodologies based on a fixed interval length.},
  archive      = {J_ARTMED},
  author       = {Antonino Aparo and Pietro Sala and Vincenzo Bonnici and Rosalba Giugno},
  doi          = {10.1016/j.artmed.2021.102212},
  journal      = {Artificial Intelligence in Medicine},
  month        = {12},
  pages        = {102212},
  shortjournal = {Artif. Intell. Med.},
  title        = {TEDAR: Temporal dynamic signal detection of adverse reactions},
  volume       = {122},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Interpreting clinical latent representations using
autoencoders and probabilistic models. <em>ARTMED</em>, <em>122</em>,
102211. (<a href="https://doi.org/10.1016/j.artmed.2021.102211">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electronic health records (EHRs) are a valuable data source that, in conjunction with deep learning (DL) methods, have provided important outcomes in different domains, contributing to supporting decision-making. Owing to the remarkable advancements achieved by DL-based models, autoencoders (AE) are becoming extensively used in health care . Nevertheless, AE-based models are based on nonlinear transformations, resulting in black-box models leading to a lack of interpretability, which is vital in the clinical setting. To obtain insights from AE latent representations, we propose a methodology by combining probabilistic models based on Gaussian mixture models and hierarchical clustering supported by Kullback-Leibler divergence. To validate the methodology from a clinical viewpoint, we used real-world data extracted from EHRs of the University Hospital of Fuenlabrada (Spain). Records were associated with healthy and chronic hypertensive and diabetic patients. Experimental outcomes showed that our approach can find groups of patients with similar health conditions by identifying patterns associated with diagnosis and drug codes. This work opens up promising opportunities for interpreting representations obtained by the AE-based model, bringing some light to the decision-making process made by clinical experts in daily practice.},
  archive      = {J_ARTMED},
  author       = {David Chushig-Muzo and Cristina Soguero-Ruiz and Pablo de Miguel-Bohoyo and Inmaculada Mora-Jiménez},
  doi          = {10.1016/j.artmed.2021.102211},
  journal      = {Artificial Intelligence in Medicine},
  month        = {12},
  pages        = {102211},
  shortjournal = {Artif. Intell. Med.},
  title        = {Interpreting clinical latent representations using autoencoders and probabilistic models},
  volume       = {122},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Seizure detection from multi-channel EEG using entropy-based
dynamic graph embedding. <em>ARTMED</em>, <em>122</em>, 102201. (<a
href="https://doi.org/10.1016/j.artmed.2021.102201">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An epileptic seizure is a chronic disease with sudden abnormal discharge of brain neurons, which leads to transient brain dysfunction . To detect epileptic seizures, we propose a novel idea based on a dynamic graph embedding model. The dynamic graph is built by identifying the correlation among the multi-channel EEG signals. Graph entropy measurement is exploited to calculate the similarity among the graph at each time interval and construct the graph embedding space. Since the abnormal electrical brain activity causes the epileptic seizure , the graph entropy during the seizure time interval is different from other time intervals. Therefore, we propose an entropy-based dynamic graph embedding model to cluster the graphs, and the graphs with epileptic seizures are discriminated. We applied the proposed approach to the Children Hospital Boston-Massachusetts Institute of Technology Scalp EEG database. The results have shown that the proposed approach outperformed the baselines by 1.4% with respect to accuracy.},
  archive      = {J_ARTMED},
  author       = {Gen Li and Jason J. Jung},
  doi          = {10.1016/j.artmed.2021.102201},
  journal      = {Artificial Intelligence in Medicine},
  month        = {12},
  pages        = {102201},
  shortjournal = {Artif. Intell. Med.},
  title        = {Seizure detection from multi-channel EEG using entropy-based dynamic graph embedding},
  volume       = {122},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Cardio-ML: Detection of malicious clinical programmings
aimed at cardiac implantable electronic devices based on machine
learning and a missing values resemblance framework. <em>ARTMED</em>,
<em>122</em>, 102200. (<a
href="https://doi.org/10.1016/j.artmed.2021.102200">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Patients with life-threatening arrhythmias are often treated with cardiac implantable electronic devices (CIEDs), such as pacemakers and implantable cardioverter defibrillators (ICDs). Recent advancements in CIEDs have enabled advanced functionality and connectivity that make such devices (particularly ICDs) vulnerable to cyber-attacks. One of the most dangerous attacks on CIED ecosystems is a data manipulation attack from a compromised programmer device that sends malicious clinical programmings to the CIED. Such attacks can affect the CIED functioning and impact patient&#39;s survival and quality of life. In this paper, we propose Cardio-ML – an automated system for the detection of malicious clinical programmings that is based on machine learning algorithms and a novel missing values resemblance framework. Our system is designed to detect new variants of existing attacks and, more importantly, new unknown (zero-day) attacks, aimed at ICDs. We collected 1651 legitimate clinical programmings from 514 patients, over a four-year period, from programmer devices at two medical centers. Our collection also includes 28 core malicious functionalities created by cardiac electrophysiology experts that were later used to create different variants of malicious programmings. Cardio-ML was evaluated extensively in three comprehensive experiments and showed high detection capabilities in most attack scenarios. We achieved perfect classification results for detecting newly created variants of existing core malicious functionalities, with an AUC of 100%; for completely new unknown (zero-day) malicious clinical programmings, an AUC of 80% was obtained, which is 14% better than the state-of-the-art method. We were able to further improve our detection results by identifying the best combination of legitimate and zero-day malicious programmings in the dataset, achieving an AUC of 87%. CIED clinical programmings have many parameters without values for a large number of samples (programmings). To cope with the extreme amount of missing values in our dataset, we developed a novel missing values-based resemblance framework and evaluated it using three dataset-creation approaches: a standard expert-driven approach, our novel data-driven approach, and a combined approach incorporating both approaches. The results showed that our novel framework handles missing values in the data better than the expert-driven approach which yields an empty dataset. In particular, the combined approach showed a 40% improvement in data utilization compared to the data-driven approach.},
  archive      = {J_ARTMED},
  author       = {Tamar Levy-Loboda and Moshe Rav-Acha and Amos Katz and Nir Nissim},
  doi          = {10.1016/j.artmed.2021.102200},
  journal      = {Artificial Intelligence in Medicine},
  month        = {12},
  pages        = {102200},
  shortjournal = {Artif. Intell. Med.},
  title        = {Cardio-ML: Detection of malicious clinical programmings aimed at cardiac implantable electronic devices based on machine learning and a missing values resemblance framework},
  volume       = {122},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Consensus clustering for case series identification and
adverse event profiles in pharmacovigilance. <em>ARTMED</em>,
<em>122</em>, 102199. (<a
href="https://doi.org/10.1016/j.artmed.2021.102199">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To describe and evaluate vigiGroup - a consensus clustering algorithm which can identify groups of individual case reports referring to similar suspected adverse drug reactions and describe associated adverse event profiles, accounting for co-reported adverse event terms. Consensus clustering is achieved by grouping pairs of reports that are repeatedly placed together in the same clusters across a set of mixture model-based cluster analyses. The latter use empirical Bayes statistical shrinkage for improved performance. As baseline comparison, we considered a regular mixture model-based cluster analysis. Three randomly selected drugs in VigiBase, the World Health Organization&#39;s global database of Individual Case Safety Reports were analyzed: sumatriptan , ambroxol and tacrolimus . Clustering stability was assessed using the adjusted Rand index, ranging between −1 and +1, and clinical coherence was assessed through an intruder detection analysis. For the three drugs considered, vigiGroup achieved stable and coherent results with adjusted Rand indices between +0.80 and +0.92, and intruder detection rates between 86% and 94%. Consensus clustering improved both stability and clinical coherence compared to mixture model-based clustering alone. Statistical shrinkage improved the stability of clusters compared to the baseline mixture model, as well as the cross-validated log-likelihood. The proposed algorithm can achieve adequate stability and clinical coherence in clustering individual case reports, thereby enabling better identification of case series and associated adverse event profiles in pharmacovigilance . The use of empirical Bayes shrinkage and consensus clustering each led to meaningful improvements in performance.},
  archive      = {J_ARTMED},
  author       = {G. Niklas Norén and Eva-Lisa Meldau and Rebecca E. Chandler},
  doi          = {10.1016/j.artmed.2021.102199},
  journal      = {Artificial Intelligence in Medicine},
  month        = {12},
  pages        = {102199},
  shortjournal = {Artif. Intell. Med.},
  title        = {Consensus clustering for case series identification and adverse event profiles in pharmacovigilance},
  volume       = {122},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Machine learning in deep brain stimulation: A systematic
review. <em>ARTMED</em>, <em>122</em>, 102198. (<a
href="https://doi.org/10.1016/j.artmed.2021.102198">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep Brain Stimulation (DBS) is an increasingly common therapy for a large range of neurological disorders , such as abnormal movement disorders . The effectiveness of DBS in terms of controlling patient symptomatology has made this procedure increasingly used over the past few decades. Concurrently, the popularity of Machine Learning (ML), a subfield of artificial intelligence , has skyrocketed and its influence has more recently extended to medical domains such as neurosurgery . Despite its growing research interest, there has yet to be a literature review specifically on the use of ML in DBS. We have followed a fully systematic methodology to obtain a corpus of 73 papers. In each paper, we identified the clinical application, the type/amount of data used, the method employed, and the validation strategy, further decomposed into 12 different sub-categories. The papers overall illustrated some existing trends in how ML is used in the context of DBS, including the breath of the problem domain and evolving techniques, as well as common frameworks and limitations. This systematic review analyzes at a broad level how ML have been recently used to address clinical problems on DBS, giving insight into how these new computational methods are helping to push the state-of-the-art of functional neurosurgery . DBS clinical workflow is complex, involves many specialists, and raises several clinical issues which have partly been addressed with artificial intelligence. However, several areas remain and those that have been recently addressed with ML are by no means considered “solved” by the community nor are they closed to new and evolving methods.},
  archive      = {J_ARTMED},
  author       = {Maxime Peralta and Pierre Jannin and John S.H. Baxter},
  doi          = {10.1016/j.artmed.2021.102198},
  journal      = {Artificial Intelligence in Medicine},
  month        = {12},
  pages        = {102198},
  shortjournal = {Artif. Intell. Med.},
  title        = {Machine learning in deep brain stimulation: A systematic review},
  volume       = {122},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An attention-based weakly supervised framework for spitzoid
melanocytic lesion diagnosis in whole slide images. <em>ARTMED</em>,
<em>121</em>, 102197. (<a
href="https://doi.org/10.1016/j.artmed.2021.102197">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Melanoma is an aggressive neoplasm responsible for the majority of deaths from skin cancer. Specifically, spitzoid melanocytic tumors are one of the most challenging melanocytic lesions due to their ambiguous morphological features. The gold standard for its diagnosis and prognosis is the analysis of skin biopsies . In this process, dermatopathologists visualize skin histology slides under a microscope, in a highly time-consuming and subjective task. In the last years, computer-aided diagnosis (CAD) systems have emerged as a promising tool that could support pathologists in daily clinical practice. Nevertheless, no automatic CAD systems have yet been proposed for the analysis of spitzoid lesions. Regarding common melanoma, no system allows both the selection of the tumor region and the prediction of the benign or malignant form in the diagnosis. Motivated by this, we propose a novel end-to-end weakly supervised deep learning model , based on inductive transfer learning with an improved convolutional neural network (CNN) to refine the embedding features of the latent space. The framework is composed of a source model in charge of finding the tumor patch-level patterns, and a target model focuses on the specific diagnosis of a biopsy. The latter retrains the backbone of the source model through a multiple instance learning workflow to obtain the biopsy-level scoring. To evaluate the performance of the proposed methods, we performed extensive experiments on a private skin database with spitzoid lesions. Test results achieved an accuracy of 0.9231 and 0.80 for the source and the target models, respectively. In addition, the heat map findings are directly in line with the clinicians&#39; medical decision and even highlight, in some cases, patterns of interest that were overlooked by the pathologist.},
  archive      = {J_ARTMED},
  author       = {Rocío del Amor and Laëtitia Launet and Adrián Colomer and Anaïs Moscardó and Andrés Mosquera-Zamudio and Carlos Monteagudo and Valery Naranjo},
  doi          = {10.1016/j.artmed.2021.102197},
  journal      = {Artificial Intelligence in Medicine},
  month        = {11},
  pages        = {102197},
  shortjournal = {Artif. Intell. Med.},
  title        = {An attention-based weakly supervised framework for spitzoid melanocytic lesion diagnosis in whole slide images},
  volume       = {121},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Fine-tuning deep learning model parameters for improved
super-resolution of dynamic MRI with prior-knowledge. <em>ARTMED</em>,
<em>121</em>, 102196. (<a
href="https://doi.org/10.1016/j.artmed.2021.102196">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic imaging is a beneficial tool for interventions to assess physiological changes. Nonetheless during dynamic MRI , while achieving a high temporal resolution, the spatial resolution is compromised. To overcome this spatio-temporal trade-off, this research presents a super-resolution (SR) MRI reconstruction with prior knowledge based fine-tuning to maximise spatial information while reducing the required scan-time for dynamic MRIs. A U-Net based network with perceptual loss is trained on a benchmark dataset and fine-tuned using one subject-specific static high resolution MRI as prior knowledge to obtain high resolution dynamic images during the inference stage. 3D dynamic data for three subjects were acquired with different parameters to test the generalisation capabilities of the network. The method was tested for different levels of in-plane undersampling for dynamic MRI. The reconstructed dynamic SR results after fine-tuning showed higher similarity with the high resolution ground-truth, while quantitatively achieving statistically significant improvement. The average SSIM of the lowest resolution experimented during this research (6.25% of the k-space) before and after fine-tuning were 0.939 ± 0.008 and 0.957 ± 0.006 respectively. This could theoretically result in an acceleration factor of 16, which can potentially be acquired in less than half a second. The proposed approach shows that the super-resolution MRI reconstruction with prior-information can alleviate the spatio-temporal trade-off in dynamic MRI, even for high acceleration factors.},
  archive      = {J_ARTMED},
  author       = {Chompunuch Sarasaen and Soumick Chatterjee and Mario Breitkopf and Georg Rose and Andreas Nürnberger and Oliver Speck},
  doi          = {10.1016/j.artmed.2021.102196},
  journal      = {Artificial Intelligence in Medicine},
  month        = {11},
  pages        = {102196},
  shortjournal = {Artif. Intell. Med.},
  title        = {Fine-tuning deep learning model parameters for improved super-resolution of dynamic MRI with prior-knowledge},
  volume       = {121},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). PSA-net: Deep learning–based physician style–aware
segmentation network for postoperative prostate cancer clinical target
volumes. <em>ARTMED</em>, <em>121</em>, 102195. (<a
href="https://doi.org/10.1016/j.artmed.2021.102195">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic segmentation of medical images with deep learning (DL) algorithms has proven highly successful in recent times. With most of these automation networks, inter-observer variation is an acknowledged problem that leads to suboptimal results. This problem is even more significant in segmenting postoperative clinical target volumes (CTV) because they lack a macroscopic visible tumor in the image. This study, using postoperative prostate CTV segmentation as the test case, tries to determine 1) whether physician styles are consistent and learnable, 2) whether physician style affects treatment outcome and toxicity, and 3) how to explicitly deal with different physician styles in DL-assisted CTV segmentation to facilitate its clinical acceptance. A dataset of 373 postoperative prostate cancer patients from UT Southwestern Medical Center was used for this study. We used another 83 patients from Mayo Clinic to validate the developed model and its adaptability. To determine whether physician styles are consistent and learnable, we trained a 3D convolutional neural network classifier to identify which physician had contoured a CTV from just the contour and the corresponding CT scan. Next, we evaluated whether adapting automatic segmentation to specific physician styles would be clinically feasible based on a lack of difference between outcomes. Here, biochemical progression–free survival (BCFS) and grade 3+ genitourinary and gastrointestinal toxicity were estimated with the Kaplan-Meier method and compared between physician styles with the log rank test and subsequently with a multivariate Cox regression . When we found no statistically significant differences in outcome or toxicity between contouring styles, we proposed a concept called physician style–aware (PSA) segmentation by developing an encoder-multidecoder network with perceptual loss to model different physician styles of CTV segmentation. The classification network captured the different physician styles with 87% accuracy. Subsequent outcome analysis showed no differences in BCFS and grade 3+ toxicity among physicians. With the proposed physician style–aware network (PSA-Net), Dice similarity coefficient (DSC) accuracy for all physicians was 3.4% higher on average than with a general model that does not differentiate physician styles. We show that these stylistic contouring variations also exist between institutions that follow the same segmentation guidelines, and we show the proposed method&#39;s effectiveness in adapting to new institutional styles. We observed an accuracy improvement of 5% in terms of DSC when adapting to the style of a separate institution. The performance of the classification network established that physician styles are learnable, and the lack of difference between outcomes among physicians shows that the network can feasibly adapt to different styles in the clinic. Therefore, we developed a novel PSA-Net model that can produce contours specific to the treating physician, thus improving segmentation accuracy and avoiding the need to train multiple models to achieve different style segmentations. We successfully validated this model on data from a separate institution, thus supporting the model&#39;s generalizability to diverse datasets.},
  archive      = {J_ARTMED},
  author       = {Anjali Balagopal and Howard Morgan and Michael Dohopolski and Ramsey Timmerman and Jie Shan and Daniel F. Heitjan and Wei Liu and Dan Nguyen and Raquibul Hannan and Aurelie Garant and Neil Desai and Steve Jiang},
  doi          = {10.1016/j.artmed.2021.102195},
  journal      = {Artificial Intelligence in Medicine},
  month        = {11},
  pages        = {102195},
  shortjournal = {Artif. Intell. Med.},
  title        = {PSA-net: Deep learning–based physician style–aware segmentation network for postoperative prostate cancer clinical target volumes},
  volume       = {121},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multiple instance convolutional neural network with
modality-based attention and contextual multi-instance learning pooling
layer for effective differentiation between borderline and malignant
epithelial ovarian tumors. <em>ARTMED</em>, <em>121</em>, 102194. (<a
href="https://doi.org/10.1016/j.artmed.2021.102194">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Malignant epithelial ovarian tumors (MEOTs) are the most lethal gynecologic malignancies , accounting for 90% of ovarian cancer cases. By contrast, borderline epithelial ovarian tumors (BEOTs) have low malignant potential and are generally associated with a good prognosis. Accurate preoperative differentiation between BEOTs and MEOTs is crucial for determining the appropriate surgical strategies and improving the postoperative quality of life . Multimodal magnetic resonance imaging (MRI) is an essential diagnostic tool. Although state-of-the-art artificial intelligence technologies such as convolutional neural networks can be used for automated diagnoses, their application have been limited owing to their high demand for graphics processing unit memory and hardware resources when dealing with large 3D volumetric data. In this study, we used multimodal MRI with a multiple instance learning (MIL) method to differentiate between BEOT and MEOT. We proposed the use of MAC-Net, a multiple instance convolutional neural network (MICNN) with modality-based attention (MA) and contextual MIL pooling layer (C-MPL). The MA module can learn from the decision-making patterns of clinicians to automatically perceive the importance of different MRI modalities and achieve multimodal MRI feature fusion based on their importance. The C-MPL module uses strong prior knowledge of tumor distribution as an important reference and assesses contextual information between adjacent images, thus achieving a more accurate prediction. The performance of MAC-Net is superior, with an area under the receiver operating characteristic curve of 0.878, surpassing that of several known MICNN approaches. Therefore, it can be used to assist clinical differentiation between BEOTs and MEOTs.},
  archive      = {J_ARTMED},
  author       = {Junming Jian and Wei Xia and Rui Zhang and Xingyu Zhao and Jiayi Zhang and Xiaodong Wu and Yong&#39;ai Li and Jinwei Qiang and Xin Gao},
  doi          = {10.1016/j.artmed.2021.102194},
  journal      = {Artificial Intelligence in Medicine},
  month        = {11},
  pages        = {102194},
  shortjournal = {Artif. Intell. Med.},
  title        = {Multiple instance convolutional neural network with modality-based attention and contextual multi-instance learning pooling layer for effective differentiation between borderline and malignant epithelial ovarian tumors},
  volume       = {121},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A reinforcement learning approach for finding optimal policy
of adaptive radiation therapy considering uncertain tumor biological
response. <em>ARTMED</em>, <em>121</em>, 102193. (<a
href="https://doi.org/10.1016/j.artmed.2021.102193">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent studies have shown that a tumor&#39;s biological response to radiation varies over time and has a dynamic nature. Dynamic biological features of tumor cells underscore the importance of using fractionation and adapting the treatment plan to tumor volume changes in radiation therapy treatment. Adaptive radiation therapy (ART) is an iterative process to adjust the dose of radiation in response to potential changes during the treatment. One of the key challenges in ART is how to determine the optimal timing of adaptations corresponding to tumor response to radiation. This paper aims to develop an automated treatment planning framework incorporating the biological uncertainties to find the optimal adaptation points to achieve a more effective treatment plan. First, a dynamic tumor-response model is proposed to predict weekly tumor volume regression during the period of radiation therapy treatment based on biological factors. Second, a Reinforcement Learning (RL) framework is developed to find the optimal adaptation points for ART considering the uncertainty in biological factors with the goal of achieving maximum final tumor control while minimizing or maintaining the toxicity level of the organs at risk (OARs) per the decision-maker&#39;s preference. Third, a beamlet intensity optimization model is solved using the predicted tumor volume at each adaptation point. The performance of the proposed RT treatment planning framework is tested using a clinical non-small cell lung cancer (NSCLC) case. The results are compared with the conventional fractionation schedule (i.e., equal dose fractionation) as a reference plan. The results show that the proposed approach performed well in achieving a robust optimal ART treatment plan under high uncertainty in the biological parameters. The ART plan outperformed the reference plan by increasing the mean biological effective dose ( BED ) value of the tumor by 2.01%, while maintaining the OAR BED within +0.5% and reducing the variability, in terms of the interquartile range (IQR) of tumor BED , by 25%.},
  archive      = {J_ARTMED},
  author       = {Saba Ebrahimi and Gino J. Lim},
  doi          = {10.1016/j.artmed.2021.102193},
  journal      = {Artificial Intelligence in Medicine},
  month        = {11},
  pages        = {102193},
  shortjournal = {Artif. Intell. Med.},
  title        = {A reinforcement learning approach for finding optimal policy of adaptive radiation therapy considering uncertain tumor biological response},
  volume       = {121},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). DeepMI: Deep multi-lead ECG fusion for identifying
myocardial infarction and its occurrence-time. <em>ARTMED</em>,
<em>121</em>, 102192. (<a
href="https://doi.org/10.1016/j.artmed.2021.102192">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Myocardial Infarction (MI) has the highest mortality of all cardiovascular diseases (CVDs). Detection of MI and information regarding its occurrence-time in particular, would enable timely interventions that may improve patient outcomes, thereby reducing the global rise in CVD deaths. Electrocardiogram (ECG) recordings are currently used to screen MI patients. However, manual inspection of ECGs is time-consuming and prone to subjective bias. Machine learning methods have been adopted for automated ECG diagnosis, but most approaches require extraction of ECG beats or consider leads independently of one another. We propose an end-to-end deep learning approach, DeepMI, to classify MI from Normal cases as well as identifying the time-occurrence of MI (defined as Acute, Recent and Old), using a collection of fusion strategies on 12 ECG leads at data-, feature-, and decision-level. In order to minimise computational overhead, we employ transfer learning using existing computer vision networks. Moreover, we use recurrent neural networks to encode the longitudinal information inherent in ECGs. We validated DeepMI on a dataset collected from 17,381 patients, in which over 323,000 samples were extracted per ECG lead. We were able to classify Normal cases as well as Acute, Recent and Old onset cases of MI, with AUROCs of 96.7%, 82.9%, 68.6% and 73.8%, respectively. We have demonstrated a multi-lead fusion approach to detect the presence and occurrence-time of MI. Our end-to-end framework provides flexibility for different levels of multi-lead ECG fusion and performs feature extraction via transfer learning .},
  archive      = {J_ARTMED},
  author       = {Girmaw Abebe Tadesse and Hamza Javed and Komminist Weldemariam and Yong Liu and Jin Liu and Jiyan Chen and Tingting Zhu},
  doi          = {10.1016/j.artmed.2021.102192},
  journal      = {Artificial Intelligence in Medicine},
  month        = {11},
  pages        = {102192},
  shortjournal = {Artif. Intell. Med.},
  title        = {DeepMI: Deep multi-lead ECG fusion for identifying myocardial infarction and its occurrence-time},
  volume       = {121},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). BCHisto-net: Breast histopathological image classification
by global and local feature aggregation. <em>ARTMED</em>, <em>121</em>,
102191. (<a href="https://doi.org/10.1016/j.artmed.2021.102191">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Breast cancer among women is the second most common cancer worldwide. Non-invasive techniques such as mammograms and ultrasound imaging are used to detect the tumor. However, breast histopathological image analysis is inevitable for the detection of malignancy of the tumor. Manual analysis of breast histopathological images is subjective, tedious, laborious and is prone to human errors. Recent developments in computational power and memory have made automation a popular choice for the analysis of these images. One of the key challenges of breast histopathological image classification at 100× magnification is to extract the features of the potential regions of interest to decide on the malignancy of the tumor. The current state-of-the-art CNN based methods for breast histopathological image classification extract features from the entire image (global features) and thus may overlook the features of the potential regions of interest. This can lead to inaccurate diagnosis of breast histopathological images. This research gap has motivated us to propose BCHisto-Net to classify breast histopathological images at 100× magnification. The proposed BCHisto-Net extracts both global and local features required for the accurate classification of breast histopathological images. The global features extract abstract image features while local features focus on potential regions of interest. Furthermore, a feature aggregation branch is proposed to combine these features for the classification of 100× images. The proposed method is quantitatively evaluated on red a private dataset and publicly available BreakHis dataset. An extensive evaluation of the proposed model showed the effectiveness of the local and global features for the classification of these images. The proposed method achieved an accuracy of 95% and 89% on KMC and BreakHis datasets respectively, outperforming state-of-the-art classifiers.},
  archive      = {J_ARTMED},
  author       = {Rashmi R and Keerthana Prasad and Chethana Babu K. Udupa},
  doi          = {10.1016/j.artmed.2021.102191},
  journal      = {Artificial Intelligence in Medicine},
  month        = {11},
  pages        = {102191},
  shortjournal = {Artif. Intell. Med.},
  title        = {BCHisto-net: Breast histopathological image classification by global and local feature aggregation},
  volume       = {121},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A healthy debate: Exploring the views of medical doctors on
the ethics of artificial intelligence. <em>ARTMED</em>, <em>121</em>,
102190. (<a href="https://doi.org/10.1016/j.artmed.2021.102190">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial Intelligence (AI) is moving towards the health space. It is generally acknowledged that, while there is great promise in the implementation of AI technologies in healthcare, it also raises important ethical issues. In this study we surveyed medical doctors based in The Netherlands, Portugal, and the U.S. from a diverse mix of medical specializations about the ethics surrounding Health AI. Four main perspectives have emerged from the data representing different views about this matter. The first perspective ( AI is a helpful tool: Let physicians do what they were trained for ) highlights the efficiency associated with automation, which will allow doctors to have the time to focus on expanding their medical knowledge and skills. The second perspective ( Rules &amp; Regulations are crucial: Private companies only think about money ) shows strong distrust in private tech companies and emphasizes the need for regulatory oversight. The third perspective ( Ethics is enough: Private companies can be trusted ) puts more trust in private tech companies and maintains that ethics is sufficient to ground these corporations. And finally the fourth perspective ( Explainable AI tools: Learning is necessary and inevitable ) emphasizes the importance of explainability of AI tools in order to ensure that doctors are engaged in the technological progress. Each perspective provides valuable and often contrasting insights about ethical issues that should be operationalized and accounted for in the design and development of AI Health.},
  archive      = {J_ARTMED},
  author       = {Andreia Martinho and Maarten Kroesen and Caspar Chorus},
  doi          = {10.1016/j.artmed.2021.102190},
  journal      = {Artificial Intelligence in Medicine},
  month        = {11},
  pages        = {102190},
  shortjournal = {Artif. Intell. Med.},
  title        = {A healthy debate: Exploring the views of medical doctors on the ethics of artificial intelligence},
  volume       = {121},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Fusing 2D and 3D convolutional neural networks for the
segmentation of aorta and coronary arteries from CT images.
<em>ARTMED</em>, <em>121</em>, 102189. (<a
href="https://doi.org/10.1016/j.artmed.2021.102189">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automated segmentation of three-dimensional medical images is of great importance for the detection and quantification of certain diseases such as stenosis in the coronary arteries . Many 2D and 3D deep learning models, especially deep convolutional neural networks (CNNs), have achieved state-of-the-art segmentation performance on 3D medical images. Yet, there is a trade-off between the field of view and the utilization of inter-slice information when using pure 2D or 3D CNNs for 3D segmentation, which compromises the segmentation accuracy . In this paper, we propose a two-stage strategy that retains the advantages of both 2D and 3D CNNs and apply the method for the segmentation of the human aorta and coronary arteries, with stenosis, from computed tomography (CT) images. In the first stage, a 2D CNN , which can extract large-field-of-view information, is used to segment the aorta and coronary arteries simultaneously in a slice-by-slice fashion. Then, in the second stage, a 3D CNN is applied to extract the inter-slice information to refine the segmentation of the coronary arteries in certain subregions not resolved well in the first stage. We show that the 3D network of the second stage can improve the continuity between slices and reduce the missed detection rate of the 2D CNN. Compared with directly using a 3D CNN, the two-stage approach can alleviate the class imbalance problem caused by the large non-coronary artery (aorta and background) and the small coronary artery and reduce the training time because the vast majority of negative voxels are excluded in the first stage. To validate the efficacy of our method, extensive experiments are carried out to compare with other approaches based on pure 2D or 3D CNNs and those based on hybrid 2D-3D CNNs.},
  archive      = {J_ARTMED},
  author       = {Linyan Gu and Xiao-Chuan Cai},
  doi          = {10.1016/j.artmed.2021.102189},
  journal      = {Artificial Intelligence in Medicine},
  month        = {11},
  pages        = {102189},
  shortjournal = {Artif. Intell. Med.},
  title        = {Fusing 2D and 3D convolutional neural networks for the segmentation of aorta and coronary arteries from CT images},
  volume       = {121},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Convolutional squeeze-and-excitation network for ECG
arrhythmia detection. <em>ARTMED</em>, <em>121</em>, 102181. (<a
href="https://doi.org/10.1016/j.artmed.2021.102181">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic detection of arrhythmia through an electrocardiogram (ECG) is of great significance for the prevention and treatment of cardiovascular diseases. In Convolutional neural network , the ECG signal is converted into multiple feature channels with equal weights through the convolution operation. Multiple feature channels can provide richer and more comprehensive information, but also contain redundant information, which will affect the diagnosis of arrhythmia , so feature channels that contain arrhythmia information should be paid attention to and given larger weight. In this paper, we introduced the Squeeze-and-Excitation (SE) block for the first time for the automatic detection of multiple types of arrhythmias with ECG. Our algorithm combines the residual convolutional module and the SE block to extract features from the original ECG signal. The SE block adaptively enhances the discriminative features and suppresses noise by explicitly modeling the interdependence between the channels, which can adaptively integrate information from different feature channels of ECG. The one-dimensional convolution operation over the time dimension is used to extract temporal information and the shortcut connection of the Se-Residual convolutional module in the proposed model makes the network easier to optimize. Thanks to the powerful feature extraction capabilities of the network, which can effectively extract discriminative arrhythmia features in multiple feature channels, so that no extra data preprocessing including denoising in other methods are need for our framework. It thus improves the working efficiency and keeps the collected biological information without loss. Experiments conducted with the 12-lead ECG dataset of the China Physiological Signal Challenge (CPSC) 2018 and the dataset of PhysioNet/Computing in Cardiology (CinC) Challenge 2017. The experiment results show that our model gains great performance and has great potential in clinical.},
  archive      = {J_ARTMED},
  author       = {Rongjun Ge and Tengfei Shen and Ying Zhou and Chengyu Liu and Libo Zhang and Benqiang Yang and Ying Yan and Jean-Louis Coatrieux and Yang Chen},
  doi          = {10.1016/j.artmed.2021.102181},
  journal      = {Artificial Intelligence in Medicine},
  month        = {11},
  pages        = {102181},
  shortjournal = {Artif. Intell. Med.},
  title        = {Convolutional squeeze-and-excitation network for ECG arrhythmia detection},
  volume       = {121},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A novel deep learning model DDU-net using edge features to
enhance brain tumor segmentation on MR images. <em>ARTMED</em>,
<em>121</em>, 102180. (<a
href="https://doi.org/10.1016/j.artmed.2021.102180">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Glioma is a relatively common brain tumor disease with high mortality rate. Humans have been seeking a more effective therapy. In the course of treatment, the specific location of the tumor needs to be determined first in any case. Therefore, how to segment tumors from brain tissue accurately and quickly is a persistent problem. In this paper, a new dual-stream decoding CNN architecture combined with U-net for automatic segmentation of brain tumor on MR images namely DDU-net is proposed. Two edge-based optimization strategies are used to enhance the performance of brain tumor segmentation. First, we design a separate branch to process edge stream information. Here, high level edge features are reduced in dimension of channel and integrated into the conventional semantic stream in the way of residual. Second, a regularization loss function is used to encourage the predicted segmentation mask to align with ground truth around the edge mainly by penalizing pixels where the predicted segmentation masks and labels do not match around the edge. In training, we employ a novel edge extraction algorithm for providing edge labels with higher quality. Moreover, we add a self-adaptive balancing class weight coefficient into the cross entropy loss function for solving the serious class imbalance problem in the backpropagation of edge extraction. Our experiments show that this leads to a very efficient architecture which can produce clearer prediction at the edge of the tumor. Our method achieves ideal performance on BraTS2017 and BraTS2018 in terms of Dice coefficient.},
  archive      = {J_ARTMED},
  author       = {Min Jiang and Fuhao Zhai and Jun Kong},
  doi          = {10.1016/j.artmed.2021.102180},
  journal      = {Artificial Intelligence in Medicine},
  month        = {11},
  pages        = {102180},
  shortjournal = {Artif. Intell. Med.},
  title        = {A novel deep learning model DDU-net using edge features to enhance brain tumor segmentation on MR images},
  volume       = {121},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Real-time frequency-independent single-lead and single-beat
myocardial infarction detection. <em>ARTMED</em>, <em>121</em>, 102179.
(<a href="https://doi.org/10.1016/j.artmed.2021.102179">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study proposes a novel real-time frequency-independent myocardial infarction detector for Lead II electrocardiograms . The underlying Deep-LSTM network is trained using the PTB-XL database, the largest to date publicly available electrocardiography dataset, and is tested over the same and the older PTB database. By testing the model over distinct datasets, collected under different conditions and from different patients, a more realistic measure of the performance can be gauged from the deployed system. The detector is trained over 3589 myocardial infarction (MI) patients and 7115 healthy controls (HC) while it is evaluated on 1076 MIs and 1840 HCs. The proposed algorithm, achieved an accuracy of 77.12%, recall/sensitivity of 75.85%, and a specificity of 83.02% over the entire PTB database; 85.07%, 81.54%, 87.31% over the PTB-XL validation set (fold 9), and 84.17%, 78.37%, 87.55% over the PTB-XL test set (fold 10). The model also achieves stable performance metrics over the frequency range of 202 Hz to 2.8 kHz. The processing time is dependent on the sampling frequency, ranging from 130 ms at 202 Hz to 1.8 s at 2.8 kHz. Such outcome is within the time required for real-time processing (less than 300 ms for fast heartbeats), between 202 Hz and 500 Hz making the algorithm practically real-time. Therefore, the proposed MI detector could be readily deployed onto existing wearable and/or portable devices and test instruments; potentially having significant societal and clinical impact in the lives of patients at risk for myocardial infarction.},
  archive      = {J_ARTMED},
  author       = {Harold Martin and Ulyana Morar and Walter Izquierdo and Mercedes Cabrerizo and Anastasio Cabrera and Malek Adjouadi},
  doi          = {10.1016/j.artmed.2021.102179},
  journal      = {Artificial Intelligence in Medicine},
  month        = {11},
  pages        = {102179},
  shortjournal = {Artif. Intell. Med.},
  title        = {Real-time frequency-independent single-lead and single-beat myocardial infarction detection},
  volume       = {121},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Automatic image and text-based description for colorectal
polyps using BASIC classification. <em>ARTMED</em>, <em>121</em>,
102178. (<a href="https://doi.org/10.1016/j.artmed.2021.102178">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Colorectal polyps (CRP) are precursor lesions of colorectal cancer (CRC). Correct identification of CRPs during in-vivo colonoscopy is supported by the endoscopist&#39;s expertise and medical classification models. A recent developed classification model is the Blue light imaging Adenoma Serrated International Classification (BASIC) which describes the differences between non-neoplastic and neoplastic lesions acquired with blue light imaging (BLI). Computer-aided detection (CADe) and diagnosis (CADx) systems are efficient at visually assisting with medical decisions but fall short at translating decisions into relevant clinical information. The communication between machine and medical expert is of crucial importance to improve diagnosis of CRP during in-vivo procedures. In this work, the combination of a polyp image classification model and a language model is proposed to develop a CADx system that automatically generates text comparable to the human language employed by endoscopists. The developed system generates equivalent sentences as the human-reference and describes CRP images acquired with white light (WL), blue light imaging (BLI) and linked color imaging (LCI). An image feature encoder and a BERT module are employed to build the AI model and an external test set is used to evaluate the results and compute the linguistic metrics. The experimental results show the construction of complete sentences with an established metric scores of BLEU-1 = 0.67, ROUGE-L = 0.83 and METEOR = 0.50. The developed CADx system for automatic CRP image captioning facilitates future advances towards automatic reporting and may help reduce time-consuming histology assessment.},
  archive      = {J_ARTMED},
  author       = {Roger Fonollà and Quirine E.W. van der Zander and Ramon M. Schreuder and Sharmila Subramaniam and Pradeep Bhandari and Ad A.M. Masclee and Erik J. Schoon and Fons van der Sommen and Peter H.N. de With},
  doi          = {10.1016/j.artmed.2021.102178},
  journal      = {Artificial Intelligence in Medicine},
  month        = {11},
  pages        = {102178},
  shortjournal = {Artif. Intell. Med.},
  title        = {Automatic image and text-based description for colorectal polyps using BASIC classification},
  volume       = {121},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A keyphrase-based approach for interpretable ICD-10 code
classification of spanish medical reports. <em>ARTMED</em>,
<em>121</em>, 102177. (<a
href="https://doi.org/10.1016/j.artmed.2021.102177">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The 10th version of International Classification of Diseases (ICD-10) codification system has been widely adopted by the health systems of many countries, including Spain. However, manual code assignment of Electronic Health Records (EHR) is a complex and time-consuming task that requires a great amount of specialised human resources. Therefore, several machine learning approaches are being proposed to assist in the assignment task. In this work we present an alternative system for automatically recommending ICD-10 codes to be assigned to EHRs. Our proposal is based on characterising ICD-10 codes by a set of keyphrases that represent them. These keyphrases do not only include those that have literally appeared in some EHR with the considered ICD-10 codes assigned, but also others that have been obtained by a statistical process able to capture expressions that have led the annotators to assign the code. The result is an information model that allows to efficiently recommend codes to a new EHR based on their textual content. We explore an approach that proves to be competitive with other state-of-the-art approaches and can be combined with them to optimise results. In addition to its effectiveness, the recommendations of this method are easily interpretable since the phrases in an EHR leading to recommend an ICD-10 code are known. Moreover, the keyphrases associated with each ICD-10 code can be a valuable additional source of information for other approaches, such as machine learning techniques .},
  archive      = {J_ARTMED},
  author       = {Andres Duque and Hermenegildo Fabregat and Lourdes Araujo and Juan Martinez-Romo},
  doi          = {10.1016/j.artmed.2021.102177},
  journal      = {Artificial Intelligence in Medicine},
  month        = {11},
  pages        = {102177},
  shortjournal = {Artif. Intell. Med.},
  title        = {A keyphrase-based approach for interpretable ICD-10 code classification of spanish medical reports},
  volume       = {121},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Classification of diabetic retinopathy using unlabeled data
and knowledge distillation. <em>ARTMED</em>, <em>121</em>, 102176. (<a
href="https://doi.org/10.1016/j.artmed.2021.102176">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Over the last decade, advances in Machine Learning and Artificial Intelligence have highlighted their potential as a diagnostic tool in the healthcare domain. Despite the widespread availability of medical images, their usefulness is severely hampered by a lack of access to labeled data. For example, while Convolutional Neural Networks (CNNs) have emerged as an essential analytical tool in image processing , their impact is curtailed by training limitations due to insufficient labeled data availability. Transfer Learning enables models developed for one task to be reused for a second task. Knowledge distillation enables transferring knowledge from a pre-trained model to another. However, it suffers from limitations, and the two models&#39; constraints need to be architecturally similar. Knowledge distillation addresses some of the shortcomings of transfer learning by generalizing a complex model to a lighter model. However, some parts of the knowledge may not be distilled by knowledge distillation sufficiently. In this paper, a novel knowledge distillation approach using transfer learning is proposed. The proposed approach transfers the complete knowledge of a model to a new smaller one. Unlabeled data are used in an unsupervised manner to transfer the new smaller model&#39;s maximum amount of knowledge. The proposed method can be beneficial in medical image analysis, where labeled data are typically scarce. The proposed approach is evaluated in classifying images for diagnosing Diabetic Retinopathy on two publicly available datasets, including Messidor and EyePACS. Simulation results demonstrate that the approach effectively transfers knowledge from a complex model to a lighter one. Furthermore, experimental results illustrate that different small models&#39; performance is improved significantly using unlabeled data and knowledge distillation.},
  archive      = {J_ARTMED},
  author       = {Sajjad Abbasi and Mohsen Hajabdollahi and Pejman Khadivi and Nader Karimi and Roshanak Roshandel and Shahram Shirani and Shadrokh Samavi},
  doi          = {10.1016/j.artmed.2021.102176},
  journal      = {Artificial Intelligence in Medicine},
  month        = {11},
  pages        = {102176},
  shortjournal = {Artif. Intell. Med.},
  title        = {Classification of diabetic retinopathy using unlabeled data and knowledge distillation},
  volume       = {121},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Substituting clinical features using synthetic medical
phrases: Medical text data augmentation techniques. <em>ARTMED</em>,
<em>120</em>, 102167. (<a
href="https://doi.org/10.1016/j.artmed.2021.102167">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Biomedical natural language processing (NLP) has an important role in extracting consequential information in medical discharge notes. Detecting meaningful features from unstructured notes is a challenging task in medical document classification . The domain specific phrases and different synonyms within the medical documents make it hard to analyze them. Analyzing clinical notes becomes more challenging for short documents like abstract texts. All of these can result in poor classification performance, especially when there is a shortage of the clinical data in real life. Two new approaches (an ontology-guided approach and a combined ontology-based with dictionary-based approach) are suggested for augmenting medical data to enrich training data . Three different deep learning approaches are used to evaluate the classification performance of the proposed methods. The obtained results show that the proposed methods improved the classification accuracy in clinical notes classification.},
  archive      = {J_ARTMED},
  author       = {Mahdi Abdollahi and Xiaoying Gao and Yi Mei and Shameek Ghosh and Jinyan Li and Michael Narag},
  doi          = {10.1016/j.artmed.2021.102167},
  journal      = {Artificial Intelligence in Medicine},
  month        = {10},
  pages        = {102167},
  shortjournal = {Artif. Intell. Med.},
  title        = {Substituting clinical features using synthetic medical phrases: Medical text data augmentation techniques},
  volume       = {120},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Artificial intelligence applied to support medical decisions
for the automatic analysis of echocardiogram images: A systematic
review. <em>ARTMED</em>, <em>120</em>, 102165. (<a
href="https://doi.org/10.1016/j.artmed.2021.102165">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The echocardiogram is a test that is widely used in Heart Disease Diagnoses. However, its analysis is largely dependent on the physician&#39;s experience. In this regard, artificial intelligence has become an essential technology to assist physicians. This study is a Systematic Literature Review (SLR) of primary state-of-the-art studies that used Artificial Intelligence (AI) techniques to automate echocardiogram analyses. Searches on the leading scientific article indexing platforms using a search string returned approximately 1400 articles. After applying the inclusion and exclusion criteria, 118 articles were selected to compose the detailed SLR. This SLR presents a thorough investigation of AI applied to support medical decisions for the main types of echocardiogram (Transthoracic, Transesophageal, Doppler, Stress, and Fetal). The article&#39;s data extraction indicated that the primary research interest of the studies comprised four groups: 1) Improvement of image quality ; 2) identification of the cardiac window vision plane; 3) quantification and analysis of cardiac functions, and; 4) detection and classification of cardiac diseases. The articles were categorized and grouped to show the main contributions of the literature to each type of ECHO. The results indicate that the Deep Learning (DL) methods presented the best results for the detection and segmentation of the heart walls, right and left atrium and ventricles, and classification of heart diseases using images/videos obtained by echocardiography. The models that used Convolutional Neural Network (CNN) and its variations showed the best results for all groups. The evidence produced by the results presented in the tabulation of the studies indicates that the DL contributed significantly to advances in echocardiogram automated analysis processes. Although several solutions were presented regarding the automated analysis of ECHO, this area of research still has great potential for further studies to improve the accuracy of results already known in the literature.},
  archive      = {J_ARTMED},
  author       = {Vilson Soares de Siqueira and Moisés Marcos Borges and Rogério Gomes Furtado and Colandy Nunes Dourado and Ronaldo Martins da Costa},
  doi          = {10.1016/j.artmed.2021.102165},
  journal      = {Artificial Intelligence in Medicine},
  month        = {10},
  pages        = {102165},
  shortjournal = {Artif. Intell. Med.},
  title        = {Artificial intelligence applied to support medical decisions for the automatic analysis of echocardiogram images: A systematic review},
  volume       = {120},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Artificial intelligence in gynecologic cancers: Current
status and future challenges – a systematic review. <em>ARTMED</em>,
<em>120</em>, 102164. (<a
href="https://doi.org/10.1016/j.artmed.2021.102164">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Over the past years, the application of artificial intelligence (AI) in medicine has increased rapidly, especially in diagnostics, and in the near future, the role of AI in medicine will become progressively more important. In this study, we elucidated the state of AI research on gynecologic cancers . A search was conducted in three databases—PubMed, Web of Science, and Scopus—for research papers dated between January 2010 and December 2020. As keywords, we used “artificial intelligence,” “deep learning,” “machine learning,” and “neural network,” combined with “cervical cancer,” “endometrial cancer,” “uterine cancer,” and “ovarian cancer.” We excluded genomic and molecular research, as well as automated pap-smear diagnoses and digital colposcopy . Of 1632 articles, 71 were eligible, including 34 on cervical cancer, 13 on endometrial cancer, three on uterine sarcoma , and 21 on ovarian cancer. A total of 35 studies (49%) used imaging data and 36 studies (51%) used value-based data as the input data. Magnetic resonance imaging (MRI), computed tomography (CT), ultrasound, cytology , and hysteroscopy data were used as imaging data, and the patients&#39; backgrounds, blood examinations, tumor markers, and indices in pathological examination were used as value-based data. The targets of prediction were definitive diagnosis and prognostic outcome, including overall survival and lymph node metastasis . The size of the dataset was relatively small because 64 studies (90%) included less than 1000 cases, and the median size was 214 cases. The models were evaluated by accuracy scores, area under the receiver operating curve (AUC), and sensitivity/specificity. Owing to the heterogeneity, a quantitative synthesis was not appropriate in this review. In gynecologic oncology , more studies have been conducted on cervical cancer than on ovarian and endometrial cancers. Prognoses were mainly used in the study of cervical cancer, whereas diagnoses were primarily used for studying ovarian cancer. The proficiency of the study design for endometrial cancer and uterine sarcoma was unclear because of the small number of studies conducted. The small size of the dataset and the lack of a dataset for external validation were indicated as the challenges of the studies.},
  archive      = {J_ARTMED},
  author       = {Munetoshi Akazawa and Kazunori Hashimoto},
  doi          = {10.1016/j.artmed.2021.102164},
  journal      = {Artificial Intelligence in Medicine},
  month        = {10},
  pages        = {102164},
  shortjournal = {Artif. Intell. Med.},
  title        = {Artificial intelligence in gynecologic cancers: Current status and future challenges – a systematic review},
  volume       = {120},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Low back pain expert systems: Clinical resolution through
probabilistic considerations and poset. <em>ARTMED</em>, <em>120</em>,
102163. (<a href="https://doi.org/10.1016/j.artmed.2021.102163">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Proper diagnosis of Low Back Pain (LBP) is quite challenging in especially the developing countries like India. Though some developed countries prepared guidelines for evaluation of LBP with tests to detect psychological overlay, implementation of the recommendations becomes quite difficult in regular clinical practice, and different specialties of medicine offer different modes of management. Aiming at offering an expert-level diagnosis for the patients having LBP, this paper uses Artificial Intelligence (AI) to derive a clinically justified and highly sensitive LBP resolution technique. The paper considers exhaustive knowledge for different LBP disorders (classified based on different pain generators), which have been represented using lattice structures to ensure completeness, non-redundancy, and optimality in the design of knowledge base . Further the representational enhancement of the knowledge has been done through construction of a hierarchical network, called RuleNet , using the concept of partially-ordered set (poset) with respect to the subset equality (⊆) relation. With implicit incorporation of probability within the knowledge, the RuleNet is used to derive reliable resolution logic along with effective resolution of uncertainties during clinical decision making. The proposed methodology has been validated with clinical records of seventy seven LBP patients accessed from the database of ESI Hospital Sealdah, India over a period of one year from 2018 to 2019. Achieving 83% sensitivity of the proposed technique, the pain experts at the hospital find the design clinically satisfactory. The inferred outcomes have also been found to be homogeneous with the actual or original diagnosis. The proposed approach achieves the clinical and computational efficiency by limiting the shortcomings of the existing methodologies for AI-based LBP diagnosis. While computational efficiency (with respect to both time and space complexity) is ensured by inferring clinical decisions through optimal processing of the knowledge items using poset, the clinical acceptability has been ascertained reaching to the most-likely diagnostic outcomes through probabilistic resolution of clinical uncertainties. The derived resolution technique, when embedded in LBP medical expert systems, would provide a fast, reliable, and affordable healthcare solution for this ailment to a wider range of general population suffering from LBP. The proposed scheme would significantly reduce the controversies and confusion in LBP treatment, and cut down the cost of unnecessary or inappropriate treatment and referral.},
  archive      = {J_ARTMED},
  author       = {Debarpita Santra and Subrata Goswami and Jyotsna Kumar Mandal and Swapan Kumar Basu},
  doi          = {10.1016/j.artmed.2021.102163},
  journal      = {Artificial Intelligence in Medicine},
  month        = {10},
  pages        = {102163},
  shortjournal = {Artif. Intell. Med.},
  title        = {Low back pain expert systems: Clinical resolution through probabilistic considerations and poset},
  volume       = {120},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Replication-based regularization approaches to diagnose
reinke’s edema by using voice recordings. <em>ARTMED</em>, <em>120</em>,
102162. (<a href="https://doi.org/10.1016/j.artmed.2021.102162">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reinke&#39;s edema is one of the most prevalent laryngeal pathologies. Its detection can be addressed by using computer-aided diagnosis systems based on features extracted from speech recordings. When extracting acoustic features from different voice recordings of a particular subject at a concrete moment, imperfections in technology and the very biological variability result in values that are close, but they are not identical. This suggests that the within-subject variability must be properly addressed in the statistical methodology. Regularization-based regression approaches can be used to reduce the classification errors by favoring the best predictors and penalizing the worst ones. Three replication-based regularization approaches for variable selection and classification have been specifically designed and implemented to take into account the underlying within-subject variability. In order to illustrate the applicability of these approaches, an experiment has been specifically conducted to discriminate Reinke&#39;s edema patients (30 subjects) from healthy people (30 subjects) in a hospital environment. The features have been extracted from four phonations of the sustained vowel /a/ recorded for each subject, leading to a database that has fed the proposed machine learning approaches. The proposed replication-based approaches have been proved to be reliable in terms of selected features and predictive ability , leading to a stable accuracy rate of 0.89 under a cross-validation framework. Also, a comparison with traditional independence-based regularization methods reports a great variability of the latter in terms of selected features and accuracy metrics. Therefore, the proposed approaches contribute to fill a gap in the scientific literature on statistical approaches considering within-subject variability and can be used to build a robust expert system .},
  archive      = {J_ARTMED},
  author       = {Lizbeth Naranjo and Carlos J. Pérez and Yolanda Campos-Roca and Mario Madruga},
  doi          = {10.1016/j.artmed.2021.102162},
  journal      = {Artificial Intelligence in Medicine},
  month        = {10},
  pages        = {102162},
  shortjournal = {Artif. Intell. Med.},
  title        = {Replication-based regularization approaches to diagnose reinke&#39;s edema by using voice recordings},
  volume       = {120},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Finding reduced raman spectroscopy fingerprint of skin
samples for melanoma diagnosis through machine learning.
<em>ARTMED</em>, <em>120</em>, 102161. (<a
href="https://doi.org/10.1016/j.artmed.2021.102161">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Early-stage detection of cutaneous melanoma can vastly increase the chances of cure. Excision biopsy followed by histological examination is considered the gold standard for diagnosing the disease, but requires long high-cost processing time, and may be biased, as it involves qualitative assessment by a professional. In this paper, we present a new machine learning approach using raw data for skin Raman spectra as input. The approach is highly efficient for classifying benign versus malignant skin lesions (AUC 0.98, 95% CI 0.97–0.99). Furthermore, we present a high-performance model (AUC 0.97, 95% CI 0.95–0.98) using a miniaturized spectral range (896–1039 cm −1 ), thus demonstrating that only a single fragment of the biological fingerprint Raman region is needed for producing an accurate diagnosis. These findings could favor the future development of a cheaper and dedicated Raman spectrometer for fast and accurate cancer diagnosis.},
  archive      = {J_ARTMED},
  author       = {Daniella Castro Araújo and Adriano Alonso Veloso and Renato Santos de Oliveira Filho and Marie-Noelle Giraud and Leandro José Raniero and Lydia Masako Ferreira and Renata Andrade Bitar},
  doi          = {10.1016/j.artmed.2021.102161},
  journal      = {Artificial Intelligence in Medicine},
  month        = {10},
  pages        = {102161},
  shortjournal = {Artif. Intell. Med.},
  title        = {Finding reduced raman spectroscopy fingerprint of skin samples for melanoma diagnosis through machine learning},
  volume       = {120},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Understanding patient reviews with minimum supervision.
<em>ARTMED</em>, <em>120</em>, 102160. (<a
href="https://doi.org/10.1016/j.artmed.2021.102160">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Understanding patient opinions expressed towards healthcare services in online platforms could allow healthcare professionals to respond to address patients&#39; concerns in a timely manner. Extracting patient opinion towards various aspects of health services is closely related to aspect-based sentiment analysis (ABSA) in which we need to identify both opinion targets and target-specific opinion expressions. The lack of aspect-level annotations however makes it difficult to build such an ABSA system. This paper proposes a joint learning framework for simultaneous unsupervised aspect extraction at the sentence level and supervised sentiment classification at the document level. It achieves 98.2% sentiment classification accuracy when tested on the reviews about healthcare services collected from Yelp, outperforming several strong baselines. Moreover, our model can extract coherent aspects and can automatically infer the distribution of aspects under different polarities without requiring aspect-level annotations for model learning.},
  archive      = {J_ARTMED},
  author       = {Lin Gui and Yulan He},
  doi          = {10.1016/j.artmed.2021.102160},
  journal      = {Artificial Intelligence in Medicine},
  month        = {10},
  pages        = {102160},
  shortjournal = {Artif. Intell. Med.},
  title        = {Understanding patient reviews with minimum supervision},
  volume       = {120},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Optimizing the setting of medical interactive rehabilitation
assistant platform to improve the performance of the patients: A case
study. <em>ARTMED</em>, <em>120</em>, 102151. (<a
href="https://doi.org/10.1016/j.artmed.2021.102151">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tele-rehabilitation is an alternative to the conventional rehabilitation service that helps patients in remote areas to access a service that is practical in terms of logistics and cost, in a controlled environment. It includes the usage of mobile phones or other wireless devices that are applied to rehabilitation exercises. Such applications or software include exercises in the form of virtual games, treatment monitoring based on the rehabilitation progress and data analysis. However, nowadays, physiotherapists use a default profiling setting for patients carrying out rehabilitation, due to lack of information. Medical Interactive Rehabilitation Assistant (MIRA) is a computer-based (virtual reality) rehabilitation platform. The profile setting includes: a level of difficulty, percentage of tolerance and maximum range. To the best of our knowledge, there is a lack of optimization in the parameter values setting of MIRA exergames that could enhance patients&#39; performance. Generally, non-optimal profile setting leads to reduced effectiveness. Therefore, this study aims to develop a method that optimizes the profile setting of each patient according to the estimated (desired) optimal results. The proposed method is developed using unsupervised and supervised machine learning techniques . We use Self-Organizing Map (SOM) to cluster patient records into several distinct clusters. K-fold cross validation is applied to construct the prediction models. Classification And Regression Tree (CART) is utilized to predict the patient&#39;s optimal input setting for playing the MIRA games. The combination of these techniques seems to improve the efficiency of the standard (default) way in predicting the optimal settings for exergames. To evaluate the proposed method, we conduct an experiment with data collected from a rehabilitation center . We use three metrics to quantify the quality of the results: R-squared (R 2 ), Mean Absolute Error (MAE) and Root Mean Square Error (RMSE). The results of experimental analysis demonstrate that the proposed method is effective in predicting the adequate parameter setting in MIRA platform. The method has potential to be implemented as an intelligent system for MIRA prediction in healthcare. Moreover, the method could be extended to similar platforms for which data is available to train our method on.},
  archive      = {J_ARTMED},
  author       = {Niayesh Gharaei and Waidah Ismail and Crina Grosan and Rimuljo Hendradi},
  doi          = {10.1016/j.artmed.2021.102151},
  journal      = {Artificial Intelligence in Medicine},
  month        = {10},
  pages        = {102151},
  shortjournal = {Artif. Intell. Med.},
  title        = {Optimizing the setting of medical interactive rehabilitation assistant platform to improve the performance of the patients: A case study},
  volume       = {120},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Dengue models based on machine learning techniques: A
systematic literature review. <em>ARTMED</em>, <em>119</em>, 102157. (<a
href="https://doi.org/10.1016/j.artmed.2021.102157">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dengue modeling is a research topic that has increased in recent years. Early prediction and decision-making are key factors to control dengue. This Systematic Literature Review (SLR) analyzes three modeling approaches of dengue: diagnostic, epidemic, intervention. These approaches require models of prediction, prescription and optimization. This SLR establishes the state-of-the-art in dengue modeling, using machine learning, in the last years. Several databases were selected to search the articles. The selection was made based on Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) methodology. Sixty-four articles were obtained and analyzed to describe their strengths and limitations. Finally, challenges and opportunities for research on machine-learning for dengue modeling were identified. Logistic regression was the most used modeling approach for the diagnosis of dengue (59.1%). The analysis of the epidemic approach showed that linear regression (17.4%) is the most used technique within the spatial analysis. Finally, the most used intervention modeling is General Linear Model with 70%. We conclude that cause-effect models may improve diagnosis and understanding of dengue. Models that manage uncertainty can also be helpful, because of low data-quality in healthcare. Finally, decentralization of data, using federated learning, may decrease computational costs and allow model building without compromising data security .},
  archive      = {J_ARTMED},
  author       = {William Hoyos and Jose Aguilar and Mauricio Toro},
  doi          = {10.1016/j.artmed.2021.102157},
  journal      = {Artificial Intelligence in Medicine},
  month        = {9},
  pages        = {102157},
  shortjournal = {Artif. Intell. Med.},
  title        = {Dengue models based on machine learning techniques: A systematic literature review},
  volume       = {119},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Hybrid COVID-19 segmentation and recognition framework
(HMB-HCF) using deep learning and genetic algorithms. <em>ARTMED</em>,
<em>119</em>, 102156. (<a
href="https://doi.org/10.1016/j.artmed.2021.102156">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {COVID-19 (Coronavirus) went through a rapid escalation until it became a pandemic disease. The normal and manual medical infection discovery may take few days and therefore computer science engineers can share in the development of the automatic diagnosis for fast detection of that disease. The study suggests a hybrid COVID-19 framework (named HMB-HCF) based on deep learning (DL), genetic algorithm (GA), weighted sum (WS), and majority voting principles in nine phases. Its segmentation phase suggests a lung segmentation algorithm using X-Ray images (named HMB-LSAXI) for extracting lungs. Its classification phase is built from a hybrid convolutional neural network (CNN) architecture using an abstractly-designed CNN (named HMB1-COVID19) and transfer learning (TL) pre-trained models (VGG16, VGG19, ResNet50, ResNet101, Xception, DenseNet121, DenseNet169, MobileNet, and MobileNetV2). The hybrid CNN architecture is used for learning, classification, and parameters optimization while GA is used to optimize the hyperparameters. This hybrid working mechanism is combined in an overall algorithm named HMB-DLGA. The study experiments implemented the WS approach to evaluate the models&#39; performance using the loss, accuracy, F1-score, precision, recall, and area under curve (AUC) metrics with different pre-defined ratios. A collected, combined, and unified X-Ray dataset from 8 different public datasets was used alongside the regularization , dropout, and data augmentation techniques to limit the overall overfitting. The applied experiments reported state-of-the-art metrics. VGG16 reported 100% WS metric (i.e., 0.0097, 99.78%, 0.9984, 99.89%, 99.78%, and 0.9996 for the loss, accuracy, F1, precision, recall, and AUC respectively) concerning the highest WS. It also reported a 99.92% WS metric (i.e., 0.0099, 99.84%, 0.9984, 99.84%, 99.84%, and 0.9996 for the loss, accuracy, F1, precision, recall, and AUC respectively) concerning the last reported WS result. HMB-HCF was validated on 13 different public datasets to verify its generalization. The best-achieved metrics were compared with 13 related studies. These extensive experiments&#39; target was the applicability verification and generalization.},
  archive      = {J_ARTMED},
  author       = {Hossam Magdy Balaha and Magdy Hassan Balaha and Hesham Arafat Ali},
  doi          = {10.1016/j.artmed.2021.102156},
  journal      = {Artificial Intelligence in Medicine},
  month        = {9},
  pages        = {102156},
  shortjournal = {Artif. Intell. Med.},
  title        = {Hybrid COVID-19 segmentation and recognition framework (HMB-HCF) using deep learning and genetic algorithms},
  volume       = {119},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Tumor saliency estimation for breast ultrasound images via
breast anatomy modeling. <em>ARTMED</em>, <em>119</em>, 102155. (<a
href="https://doi.org/10.1016/j.artmed.2021.102155">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tumor saliency estimation aims to localize tumors by modeling the visual stimuli in medical images. However, it is a challenging task for breast ultrasound (BUS) image due to the complicated anatomic structure of the breast and poor image quality; and existing saliency estimation approaches only model the generic visual stimuli, e.g., local and global contrast, location, and feature correlation, and achieve poor performance for tumor saliency estimation. In this paper, we propose a novel optimization model to estimate tumor saliency by utilizing breast anatomy. First, we model breast anatomy and decompose breast ultrasound image into layers using Neutro-Connectedness; then utilize the layers to generate the foreground and background maps; and finally propose a novel objective function to estimate the tumor saliency by integrating the foreground map, background map, adaptive center bias, and region-based correlation cues. The extensive experiments demonstrate that the proposed approach obtains more accurate foreground and background maps with breast anatomy; especially, for the images having large or small tumors. Meanwhile, the new objective function can handle the images without tumors. The newly proposed method achieves state-of-the-art performance comparing to eight tumor saliency estimation approaches using two BUS datasets.},
  archive      = {J_ARTMED},
  author       = {Fei Xu and Yingtao Zhang and H.D. Cheng and Boyu Zhang and Jianrui Ding and Chunping Ning and Ying Wang},
  doi          = {10.1016/j.artmed.2021.102155},
  journal      = {Artificial Intelligence in Medicine},
  month        = {9},
  pages        = {102155},
  shortjournal = {Artif. Intell. Med.},
  title        = {Tumor saliency estimation for breast ultrasound images via breast anatomy modeling},
  volume       = {119},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). EMONAS-net: Efficient multiobjective neural architecture
search using surrogate-assisted evolutionary algorithm for 3D medical
image segmentation. <em>ARTMED</em>, <em>119</em>, 102154. (<a
href="https://doi.org/10.1016/j.artmed.2021.102154">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning plays a critical role in medical image segmentation . Nevertheless, manually designing a neural network for a specific segmentation problem is a very difficult and time-consuming task due to the massive hyperparameter search space , long training time and large volumetric data . Therefore, most designed networks are highly complex, task specific and over-parametrized. Recently, multiobjective neural architecture search (NAS) methods have been proposed to automate the design of accurate and efficient segmentation architectures. However, they only search for either the micro- or macro-structure of the architecture, do not use the information produced during the optimization process to increase the efficiency of the search, or do not consider the volumetric nature of medical images. In this work, we present EMONAS-Net, an E fficient M ulti O bjective NAS framework for 3D medical image segmentation that optimizes both the segmentation accuracy and size of the network. EMONAS-Net has two key components, a novel search space that considers the configuration of the micro- and macro-structure of the architecture and a S urrogate- a ssisted M ultiobjective E volutionary based A lgorithm (SaMEA algorithm) that efficiently searches for the best hyperparameter values. The SaMEA algorithm uses the information collected during the initial generations of the evolutionary process to identify the most promising subproblems and select the best performing hyperparameter values during mutation to improve the convergence speed. Furthermore, a Random Forest surrogate model is incorporated to accelerate the fitness evaluation of the candidate architectures. EMONAS-Net is tested on the tasks of prostate segmentation from the MICCAI PROMISE12 challenge, hippocampus segmentation from the Medical Segmentation Decathlon challenge, and cardiac segmentation from the MICCAI ACDC challenge. In all the benchmarks, the proposed framework finds architectures that perform better or comparable with competing state-of-the-art NAS methods while being considerably smaller and reducing the architecture search time by more than 50%.},
  archive      = {J_ARTMED},
  author       = {Maria Baldeon Calisto and Susana K. Lai-Yuen},
  doi          = {10.1016/j.artmed.2021.102154},
  journal      = {Artificial Intelligence in Medicine},
  month        = {9},
  pages        = {102154},
  shortjournal = {Artif. Intell. Med.},
  title        = {EMONAS-net: Efficient multiobjective neural architecture search using surrogate-assisted evolutionary algorithm for 3D medical image segmentation},
  volume       = {119},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). TP-DDI: Transformer-based pipeline for the extraction of
drug-drug interactions. <em>ARTMED</em>, <em>119</em>, 102153. (<a
href="https://doi.org/10.1016/j.artmed.2021.102153">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Drug-Drug Interaction (DDI) extraction is the task of identifying drug entities and the potential interactions between drug pairs from biomedical literature. Computer-aided extraction of DDIs is vital for drug discovery , as this process remains extremely expensive and time consuming. Therefore, Machine Learning-based approaches can reduce the laborious task during the drug development cycle. Numerous traditional and Neural Network-based approaches for Drug Named Entity Recognition (DNER) and the classification of DDIs have been proposed over the years. However, despite the development of many effective methods, achieving good prediction accuracy is an area where significant improvement can be made. In this article, we present a novel end-to-end approach that tackles the overall DDI extraction task as a pipelined method via the Transformer model architecture and biomedical domain pre-trained weights. In our approach, the tasks of DNER and DDI classification are executed successively to extract the drug entities and to classify their relationship respectively. The proposed approach, TP-DDI, integrates prior knowledge by using pre-trained weights from BioBERT and improves in both the Drug Named Entity Recognition and the overall DDI extraction task over the current state-of-the-art approaches on the DDI Extraction 2013 corpus.},
  archive      = {J_ARTMED},
  author       = {Dimitrios Zaikis and Ioannis Vlahavas},
  doi          = {10.1016/j.artmed.2021.102153},
  journal      = {Artificial Intelligence in Medicine},
  month        = {9},
  pages        = {102153},
  shortjournal = {Artif. Intell. Med.},
  title        = {TP-DDI: Transformer-based pipeline for the extraction of drug-drug interactions},
  volume       = {119},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Optimization assisted kalman filter for cancer chemotherapy
dosage estimation. <em>ARTMED</em>, <em>119</em>, 102152. (<a
href="https://doi.org/10.1016/j.artmed.2021.102152">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cancer is regarded to be the earth&#39;s most deadly disease, with one of the highest mortality rates among people. “Surgery, radiotherapy , chemotherapy, hormone therapy , and immunotherapy” were all options for treat cancer. Chemotherapy is a medication that is most often deployed for treating cancer, as cancer cells develop and proliferate faster than other cells in the body. Even though chemotherapy is an effective method to treatment various kinds of cancers, the treatment includes risk as it causes side effects due to improper drug usage. The application of a controller-based strategy for determining the optimal rate of drug injection during treatment has risen dramatically in recent years. Thereby, this work develops a robust controller for controlling the dosage of drugs that is carried out under parameter estimation. In addition, a Modified Regularized Error Function-based Extended Kalman filter (MREF-EKF) is introduced for estimating the tumor cells and it can be exploited for diverse conditions. Moreover, the overfitting issue that occurs during drug dosage estimation is also solved using this approach. Further, to improve the performance of the developed approach, the initial state of EKF is fine-tuned via Mean fitness-based Particle Swarm Update (MF-PSU), which is the enhanced version of Particle Swarm Optimization (PSO). At last, the supremacy of the presented approach is proved with respect to convergence analysis and error analysis. For instance, our method outperforms existing GWO + e k + m , AGWO + e k + m , and PSO + e k + m approaches in convergence analysis at noise level 0.41 by 0.009%, 0.002%, and 4.9% respectively. In error analysis, the error values for tumor cells have reached a minimum error value of zero for all noise levels (0.41, 0.43, and 0.55). The findings of this study can help for a better understanding of our presented robust controller&#39;s effectiveness in controlling the dosage of drugs.},
  archive      = {J_ARTMED},
  author       = {Utkarsha L. Mohite and Hirenkumar G. Patel},
  doi          = {10.1016/j.artmed.2021.102152},
  journal      = {Artificial Intelligence in Medicine},
  month        = {9},
  pages        = {102152},
  shortjournal = {Artif. Intell. Med.},
  title        = {Optimization assisted kalman filter for cancer chemotherapy dosage estimation},
  volume       = {119},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-pathology detection and lesion localization in WCE
videos by using the instance segmentation approach. <em>ARTMED</em>,
<em>119</em>, 102141. (<a
href="https://doi.org/10.1016/j.artmed.2021.102141">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The majority of current systems for automatic diagnosis considers the detection of a unique and previously known pathology. Considering specifically the diagnosis of lesions in the small bowel using endoscopic capsule images, very few consider the possible existence of more than one pathology and when they do, they are mainly detection based systems therefore unable to localize the suspected lesions. Such systems do not fully satisfy the medical community, that in fact needs a system that detects any pathology and eventually more than one, when they coexist. In addition, besides the diagnostic capability of these systems, localizing the lesions in the image has been of great interest to the medical community, mainly for training medical personnel purposes. So, nowadays, the inclusion of the lesion location in automatic diagnostic systems is practically mandatory. Multi-pathology detection can be seen as a multi-object detection task and as each frame can contain different instances of the same lesion, instance segmentation seems to be appropriate for the purpose. Consequently, we argue that a multi-pathology system benefits from using the instance segmentation approach, since classification and segmentation modules are both required complementing each other in lesion detection and localization. According to our best knowledge such a system does not yet exist for the detection of WCE pathologies. This paper proposes a multi-pathology system that can be applied to WCE images, which uses the Mask Improved RCNN (MI-RCNN), a new mask subnet scheme which has shown to significantly improve mask predictions of the high performing state-of-the-art Mask-RCNN and PANet systems. A novel training strategy based on the second momentum is also proposed for the first time for training Mask-RCNN and PANet based systems. These approaches were tested using the public database KID, and the included pathologies were bleeding, angioectasias, polyps and inflammatory lesions. Experimental results show significant improvements for the proposed versions, reaching increases of almost 7% over the PANet model when the new proposed training approach was employed.},
  archive      = {J_ARTMED},
  author       = {Pedro M. Vieira and Nuno R. Freitas and Veríssimo B. Lima and Dalila Costa and Carla Rolanda and Carlos S. Lima},
  doi          = {10.1016/j.artmed.2021.102141},
  journal      = {Artificial Intelligence in Medicine},
  month        = {9},
  pages        = {102141},
  shortjournal = {Artif. Intell. Med.},
  title        = {Multi-pathology detection and lesion localization in WCE videos by using the instance segmentation approach},
  volume       = {119},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Neural network-based left ventricle geometry prediction from
CMR images with application in biomechanics. <em>ARTMED</em>,
<em>119</em>, 102140. (<a
href="https://doi.org/10.1016/j.artmed.2021.102140">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Combining biomechanical modelling of left ventricular (LV) function and dysfunction with cardiac magnetic resonance (CMR) imaging has the potential to improve the prognosis of patient-specific cardiovascular disease risks. Biomechanical studies of LV function in three dimensions usually rely on a computerized representation of the LV geometry based on finite element discretization , which is essential for numerically simulating in vivo cardiac dynamics. Detailed knowledge of the LV geometry is also relevant for various other clinical applications, such as assessing the LV cavity volume and wall thickness. Accurately and automatically reconstructing personalized LV geometries from conventional CMR images with minimal manual intervention is still a challenging task, which is a pre-requisite for any subsequent automated biomechanical analysis . We propose a deep learning-based automatic pipeline for predicting the three-dimensional LV geometry directly from routinely-available CMR cine images, without the need to manually annotate the ventricular wall. Our framework takes advantage of a low-dimensional representation of the high-dimensional LV geometry based on principal component analysis . We analyze how the inference of myocardial passive stiffness is affected by using our automatically generated LV geometries instead of manually generated ones. These insights will inform the development of statistical emulators of LV dynamics to avoid computationally expensive biomechanical simulations. Our proposed framework enables accurate LV geometry reconstruction, outperforming previous approaches by delivering a reconstruction error 50% lower than reported in the literature. We further demonstrate that for a nonlinear cardiac mechanics model, using our reconstructed LV geometries instead of manually extracted ones only moderately affects the inference of passive myocardial stiffness described by an anisotropic hyperelastic constitutive law. The developed methodological framework has the potential to make an important step towards personalized medicine by eliminating the need for time consuming and costly manual operations. In addition, our method automatically maps the CMR scan into a low-dimensional representation of the LV geometry, which constitutes an important stepping stone towards the development of an LV geometry-heterogeneous emulator.},
  archive      = {J_ARTMED},
  author       = {Lukasz Romaszko and Agnieszka Borowska and Alan Lazarus and David Dalton and Colin Berry and Xiaoyu Luo and Dirk Husmeier and Hao Gao},
  doi          = {10.1016/j.artmed.2021.102140},
  journal      = {Artificial Intelligence in Medicine},
  month        = {9},
  pages        = {102140},
  shortjournal = {Artif. Intell. Med.},
  title        = {Neural network-based left ventricle geometry prediction from CMR images with application in biomechanics},
  volume       = {119},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Deep learning methods for screening patients’ s-ICD
implantation eligibility. <em>ARTMED</em>, <em>119</em>, 102139. (<a
href="https://doi.org/10.1016/j.artmed.2021.102139">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Subcutaneous Implantable Cardioverter-Defibrillators (S-ICDs) are used for prevention of sudden cardiac death triggered by ventricular arrhythmias . T Wave Over Sensing (TWOS) is an inherent risk with S-ICDs which can lead to inappropriate shocks . A major predictor of TWOS is a high T:R ratio (the ratio between the amplitudes of the T and R waves). Currently, patients&#39; Electrocardiograms (ECGs) are screened over 10 s to measure the T:R ratio to determine the patients&#39; eligibility for S-ICD implantation. Due to temporal variations in the T:R ratio, 10 s is not a long enough window to reliably determine the normal values of a patient&#39;s T:R ratio. In this paper, we develop a convolutional neural network (CNN) based model utilising phase space reconstruction matrices to predict T:R ratios from 10-second ECG segments without explicitly locating the R or T waves, thus avoiding the issue of TWOS. This tool can be used to automatically screen patients over a much longer period and provide an in-depth description of the behavior of the T:R ratio over that period. The tool can also enable much more reliable and descriptive screenings to better assess patients&#39; eligibility for S-ICD implantation.},
  archive      = {J_ARTMED},
  author       = {Anthony J. Dunn and Mohamed H. ElRefai and Paul R. Roberts and Stefano Coniglio and Benedict M. Wiles and Alain B. Zemkoho},
  doi          = {10.1016/j.artmed.2021.102139},
  journal      = {Artificial Intelligence in Medicine},
  month        = {9},
  pages        = {102139},
  shortjournal = {Artif. Intell. Med.},
  title        = {Deep learning methods for screening patients&#39; S-ICD implantation eligibility},
  volume       = {119},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Aspect-based sentiment analysis with graph convolution over
syntactic dependencies. <em>ARTMED</em>, <em>119</em>, 102138. (<a
href="https://doi.org/10.1016/j.artmed.2021.102138">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aspect-based sentiment analysis is a natural language processing task whose aim is to automatically classify the sentiment associated with a specific aspect of a written text. In this study, we propose a novel model for aspect-based sentiment analysis, which exploits the dependency parse tree of a sentence using graph convolution to classify the sentiment of a given aspect. To evaluate this model in the domain of health and well-being, where this task is biased toward negative sentiment, we used a corpus of drug reviews. Specific aspects were grounded in the Unified Medical Language System, a large repository of inter-related biomedical concepts and the corresponding terminology. Our experiments demonstrated that graph convolution approach outperforms standard deep learning architectures on the task of aspect-based sentiment analysis. Moreover, graph convolution over dependency parse trees (F-score of 0.8179) outperforms the same approach over a flat sequence representation of sentences (F-score of 0.7332). These results bring the performance of sentiment analysis in health and well-being in line with the state of the art in other domains.},
  archive      = {J_ARTMED},
  author       = {Anastazia Žunić and Padraig Corcoran and Irena Spasić},
  doi          = {10.1016/j.artmed.2021.102138},
  journal      = {Artificial Intelligence in Medicine},
  month        = {9},
  pages        = {102138},
  shortjournal = {Artif. Intell. Med.},
  title        = {Aspect-based sentiment analysis with graph convolution over syntactic dependencies},
  volume       = {119},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Deep reinforcement learning for fractionated radiotherapy in
non-small cell lung carcinoma. <em>ARTMED</em>, <em>119</em>, 102137.
(<a href="https://doi.org/10.1016/j.artmed.2021.102137">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lung cancer is by far the leading cause of cancer death among both men and women. Radiation therapy is one of the main approaches to lung cancer treatment, and its planning is crucial for the therapy outcome. However, the current practice that uniformly delivers the dose does not take into account the patient-specific tumour features that may affect treatment success. Since radiation therapy is by its very nature a sequential procedure, Deep Reinforcement Learning (DRL) is a well-suited methodology to overcome this limitation. In this respect, in this work we present a DRL controller optimizing the daily dose fraction delivered to the patient on the basis of CT scans collected over time during the therapy, offering a personalized treatment not only for volume adaptation, as currently intended, but also for daily fractionation. Furthermore, this contribution introduces a virtual radiotherapy environment based on a set of ordinary differential equations modelling the tissue radiosensitivity by combining both the effect of the radiotherapy treatment and cell growth. Their parameters are estimated from CT scans routinely collected using the Particle Swarm Optimization algorithm. This permits the DRL to learn the optimal behaviour through an iterative trial and error process with the environment. We performed several experiments considering three rewards functions modelling treatment strategies with different tissue aggressiveness and two exploration strategies for the exploration-exploitation dilemma. The results show that our DRL approach can adapt to radiation therapy treatment, optimizing its behaviour according to the different reward functions and outperforming the current clinical practice.},
  archive      = {J_ARTMED},
  author       = {Matteo Tortora and Ermanno Cordelli and Rosa Sicilia and Marianna Miele and Paolo Matteucci and Giulio Iannello and Sara Ramella and Paolo Soda},
  doi          = {10.1016/j.artmed.2021.102137},
  journal      = {Artificial Intelligence in Medicine},
  month        = {9},
  pages        = {102137},
  shortjournal = {Artif. Intell. Med.},
  title        = {Deep reinforcement learning for fractionated radiotherapy in non-small cell lung carcinoma},
  volume       = {119},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Resolution-based distillation for efficient histology image
classification. <em>ARTMED</em>, <em>119</em>, 102136. (<a
href="https://doi.org/10.1016/j.artmed.2021.102136">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Developing deep learning models to analyze histology images has been computationally challenging, as the massive size of the images causes excessive strain on all parts of the computing pipeline. This paper proposes a novel deep learning-based methodology for improving the computational efficiency of histology image classification . The proposed approach is robust when used with images that have reduced input resolution, and it can be trained effectively with limited labeled data. Moreover, our approach operates at either the tissue- or slide-level, removing the need for laborious patch-level labeling. Our method uses knowledge distillation to transfer knowledge from a teacher model pre-trained at high resolution to a student model trained on the same images at a considerably lower resolution. Also, to address the lack of large-scale labeled histology image datasets, we perform the knowledge distillation in a self-supervised fashion. We evaluate our approach on three distinct histology image datasets associated with celiac disease , lung adenocarcinoma , and renal cell carcinoma . Our results on these datasets demonstrate that a combination of knowledge distillation and self-supervision allows the student model to approach and, in some cases, surpass the teacher model&#39;s classification accuracy while being much more computationally efficient. Additionally, we observe an increase in student classification performance as the size of the unlabeled dataset increases, indicating that there is potential for this method to scale further with additional unlabeled data. Our model outperforms the high-resolution teacher model for celiac disease in accuracy, F1-score, precision, and recall while requiring 4 times fewer computations. For lung adenocarcinoma , our results at 1.25× magnification are within 1.5% of the results for the teacher model at 10× magnification, with a reduction in computational cost by a factor of 64. Our model on renal cell carcinoma at 1.25× magnification performs within 1% of the teacher model at 5× magnification while requiring 16 times fewer computations. Furthermore, our celiac disease outcomes benefit from additional performance scaling with the use of more unlabeled data. In the case of 0.625× magnification, using unlabeled data improves accuracy by 4% over the tissue-level baseline. Therefore, our approach can improve the feasibility of deep learning solutions for digital pathology on standard computational hardware and infrastructures.},
  archive      = {J_ARTMED},
  author       = {Joseph DiPalma and Arief A. Suriawinata and Laura J. Tafe and Lorenzo Torresani and Saeed Hassanpour},
  doi          = {10.1016/j.artmed.2021.102136},
  journal      = {Artificial Intelligence in Medicine},
  month        = {9},
  pages        = {102136},
  shortjournal = {Artif. Intell. Med.},
  title        = {Resolution-based distillation for efficient histology image classification},
  volume       = {119},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Practical fine-grained learning based anomaly classification
for ECG image. <em>ARTMED</em>, <em>119</em>, 102130. (<a
href="https://doi.org/10.1016/j.artmed.2021.102130">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a widely used vital sign within cardiology, Electrocardiography (ECG) provides the basis for assessing heart function and diagnosing cardiovascular diseases. Automated anomaly detection for ECG plays an important role in improving patient diagnosis efficiency and reducing healthcare costs. Practically, due to the limits of electronics support or the medical system setting, image is a more common format for large-scale ECG storage in most clinical institutions. To guarantee an automated ECG detection model&#39;s scalability and practicality in clinical applications, taking good advantage of ECG images is crucial. However, existing time digital-based discriminative models fail to learn from images effectively for two reasons. First of all, the signals recorded on images have much lower resolution and higher noise, which makes it impractical to extract precise ECG signals following existing techniques. Meanwhile, the differences between abnormal signals are usually subtle, and they may be overwhelmed by the noises in the images as well. Towards this end, we design a novel neural framework that can be directly applied to massive ECG images determining various types of cardiology abnormalities. It classifies fine-grained ECG images based on weakly supervised strategy, in which case only image-level labeling is required. By eliminating the need for part annotations, the proposed method can result in significant savings in annotation time and cost. The effectiveness of the method is demonstrated by experimental results on two real ECG datasets.},
  archive      = {J_ARTMED},
  author       = {Qing Cao and Nan Du and Li Yu and Ming Zuo and Jingsheng Lin and Nathan Liu and Erheng Zhong and Zizhu Liu and Qiaoran Chen and Ying Shen and Kang Chen},
  doi          = {10.1016/j.artmed.2021.102130},
  journal      = {Artificial Intelligence in Medicine},
  month        = {9},
  pages        = {102130},
  shortjournal = {Artif. Intell. Med.},
  title        = {Practical fine-grained learning based anomaly classification for ECG image},
  volume       = {119},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A novel convolutional neural network for reconstructing
surface electrocardiograms from intracardiac electrograms and vice
versa. <em>ARTMED</em>, <em>118</em>, 102135. (<a
href="https://doi.org/10.1016/j.artmed.2021.102135">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a novel convolutional neural network framework for mapping a multivariate input to a multivariate output. In particular, we implement our algorithm within the scope of 12-lead surface electrocardiogram (ECG) reconstruction from intracardiac electrograms (EGM) and vice versa. The goal of performing this task is to allow for improved point-of-care monitoring of patients with an implanted device to treat cardiac pathologies. We will achieve this goal with 12-lead ECG reconstruction and by providing a new diagnostic tool for classifying five different ECG types. The algorithm is evaluated on a dataset retroactively collected from 14 patients. Correlation coefficients calculated between the reconstructed and the actual ECG show that the proposed convolutional neural network model represents an efficient, accurate, and superior way to synthesize a 12-lead ECG when compared to previous methods. We can also achieve the same reconstruction accuracy with only one EGM lead as input. We also tested the model in a non-patient specific way and saw a reasonable correlation coefficient. The model was also executed in the reverse direction to produce EGM signals from a 12-lead ECG and found that the correlation was comparable to the forward direction. Lastly, we analyzed the features learned in the model and determined that the model learns an overcomplete basis of our 12-lead ECG space. We then use this basis of features to create a new diagnostic tool for classifying different ECG arrhythmia&#39;s on the MIT-BIH arrhythmia database with an average accuracy of 0.98.},
  archive      = {J_ARTMED},
  author       = {Anton Banta and Romain Cosentino and Mathews M. John and Allison Post and Skylar Buchan and Mehdi Razavi and Behnaam Aazhang},
  doi          = {10.1016/j.artmed.2021.102135},
  journal      = {Artificial Intelligence in Medicine},
  month        = {8},
  pages        = {102135},
  shortjournal = {Artif. Intell. Med.},
  title        = {A novel convolutional neural network for reconstructing surface electrocardiograms from intracardiac electrograms and vice versa},
  volume       = {118},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Network differentiation: A computational method of
pathogenesis diagnosis in traditional chinese medicine based on systems
science. <em>ARTMED</em>, <em>118</em>, 102134. (<a
href="https://doi.org/10.1016/j.artmed.2021.102134">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Resembling the role of disease diagnosis in Western medicine, pathogenesis (also called Bing Ji ) diagnosis is one of the utmost important tasks in traditional Chinese medicine (TCM). In TCM theory, pathogenesis is a complex system composed of a group of interrelated factors, which is highly consistent with the character of systems science (SS). In this paper, we introduce a heuristic definition called pathogenesis network (PN) to represent pathogenesis in the form of the directed graph. Accordingly, a computational method of pathogenesis diagnosis, called network differentiation (ND), is proposed by integrating the holism principle in SS. ND consists of three stages. The first stage is to generate all possible diagnoses by Cartesian Product operated on specified prior knowledge corresponding to the input symptoms. The second stage is to screen the validated diagnoses by holism principle. The third stage is to pick out the clinical diagnosis by physician-computer interaction. Some theorems are stated and proved for the further optimization of ND in this paper. We conducted simulation experiments on 100 clinical cases. The experimental results show that our proposed method has an excellent capability to fit the holistic thinking in the process of physician inference.},
  archive      = {J_ARTMED},
  author       = {Qiang Xu and Qiang Guo and Chun-Xia Wang and Song Zhang and Chuan-Biao Wen and Tao Sun and Wei Peng and Jun Chen and Wei-Hong Li},
  doi          = {10.1016/j.artmed.2021.102134},
  journal      = {Artificial Intelligence in Medicine},
  month        = {8},
  pages        = {102134},
  shortjournal = {Artif. Intell. Med.},
  title        = {Network differentiation: A computational method of pathogenesis diagnosis in traditional chinese medicine based on systems science},
  volume       = {118},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). AIOSA: An approach to the automatic identification of
obstructive sleep apnea events based on deep learning. <em>ARTMED</em>,
<em>118</em>, 102133. (<a
href="https://doi.org/10.1016/j.artmed.2021.102133">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Obstructive Sleep Apnea Syndrome (OSAS) is the most common sleep-related breathing disorder. It is caused by an increased upper airway resistance during sleep, which determines episodes of partial or complete interruption of airflow. The detection and treatment of OSAS is particularly important in patients who suffered a stroke, because the presence of severe OSAS is associated with higher mortality, worse neurological deficits, worse functional outcome after rehabilitation, and a higher likelihood of uncontrolled hypertension. The gold standard test for diagnosing OSAS is polysomnography (PSG). Unfortunately, performing a PSG in an electrically hostile environment, like a stroke unit, on neurologically impaired patients is a difficult task; moreover, the number of strokes per day vastly outnumbers the availability of polysomnographs and dedicated healthcare professionals. Hence, a simple and automated recognition system to identify OSAS cases among acute stroke patients, relying on routinely recorded vital signs, is highly desirable. The vast majority of the work done so far focuses on data recorded in ideal conditions and highly selected patients, and thus it is hardly exploitable in real-life circumstances, where it would be of actual use. In this paper, we propose a novel convolutional deep learning architecture able to effectively reduce the temporal resolution of raw waveform data, like physiological signals, extracting key features that can be used for further processing. We exploit models based on such an architecture to detect OSAS events in stroke unit recordings obtained from the monitoring of unselected patients. Unlike existing approaches, annotations are performed at one-second granularity, allowing physicians to better interpret the model outcome. Results are considered to be satisfactory by the domain experts. Moreover, through tests run on a widely-used public OSAS dataset, we show that the proposed approach outperforms current state-of-the-art solutions.},
  archive      = {J_ARTMED},
  author       = {Andrea Bernardini and Andrea Brunello and Gian Luigi Gigli and Angelo Montanari and Nicola Saccomanno},
  doi          = {10.1016/j.artmed.2021.102133},
  journal      = {Artificial Intelligence in Medicine},
  month        = {8},
  pages        = {102133},
  shortjournal = {Artif. Intell. Med.},
  title        = {AIOSA: An approach to the automatic identification of obstructive sleep apnea events based on deep learning},
  volume       = {118},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Circumpapillary OCT-focused hybrid learning for glaucoma
grading using tailored prototypical neural networks. <em>ARTMED</em>,
<em>118</em>, 102132. (<a
href="https://doi.org/10.1016/j.artmed.2021.102132">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Glaucoma is one of the leading causes of blindness worldwide and Optical Coherence Tomography (OCT) is the quintessential imaging technique for its detection. Unlike most of the state-of-the-art studies focused on glaucoma detection, in this paper, we propose, for the first time, a novel framework for glaucoma grading using raw circumpapillary B-scans. In particular, we set out a new OCT-based hybrid network which combines hand-driven and deep learning algorithms . An OCT-specific descriptor is proposed to extract hand-crafted features related to the retinal nerve fibre layer (RNFL). In parallel, an innovative CNN is developed using skip-connections to include tailored residual and attention modules to refine the automatic features of the latent space. The proposed architecture is used as a backbone to conduct a novel few-shot learning based on static and dynamic prototypical networks. The k -shot paradigm is redefined giving rise to a supervised end-to-end system which provides substantial improvements discriminating between healthy, early and advanced glaucoma samples. The training and evaluation processes of the dynamic prototypical network are addressed from two fused databases acquired via Heidelberg Spectralis system. Validation and testing results reach a categorical accuracy of 0.9459 and 0.8788 for glaucoma grading, respectively. Besides, the high performance reported by the proposed model for glaucoma detection deserves a special mention. The findings from the class activation maps are directly in line with the clinicians&#39; opinion since the heatmaps pointed out the RNFL as the most relevant structure for glaucoma diagnosis.},
  archive      = {J_ARTMED},
  author       = {Gabriel García and Rocío del Amor and Adrián Colomer and Rafael Verdú-Monedero and Juan Morales-Sánchez and Valery Naranjo},
  doi          = {10.1016/j.artmed.2021.102132},
  journal      = {Artificial Intelligence in Medicine},
  month        = {8},
  pages        = {102132},
  shortjournal = {Artif. Intell. Med.},
  title        = {Circumpapillary OCT-focused hybrid learning for glaucoma grading using tailored prototypical neural networks},
  volume       = {118},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A framework to extract biomedical knowledge from
gluten-related tweets: The case of dietary concerns in digital era.
<em>ARTMED</em>, <em>118</em>, 102131. (<a
href="https://doi.org/10.1016/j.artmed.2021.102131">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Big data importance and potential are becoming more and more relevant nowadays, enhanced by the explosive growth of information volume that is being generated on the Internet in the last years. In this sense, many experts agree that social media networks are one of the internet areas with higher growth in recent years and one of the fields that are expected to have a more significant increment in the coming years. Similarly, social media sites are quickly becoming one of the most popular platforms to discuss health issues and exchange social support with others. In this context, this work presents a new methodology to process, classify, visualise and analyse the big data knowledge produced by the sociome on social media platforms. This work proposes a methodology that combines natural language processing techniques, ontology-based named entity recognition methods, machine learning algorithms and graph mining techniques to: ( i ) reduce the irrelevant messages by identifying and focusing the analysis only on individuals and patient experiences from the public discussion; ( ii ) reduce the lexical noise produced by the different ways in how users express themselves through the use of domain ontologies; ( iii ) infer the demographic data of the individuals through the combined analysis of textual, geographical and visual profile information; ( iv ) perform a community detection and evaluate the health topic study combining the semantic processing of the public discourse with knowledge graph representation techniques; and ( v ) gain information about the shared resources combining the social media statistics with the semantical analysis of the web contents. The practical relevance of the proposed methodology has been proven in the study of 1.1 million unique messages from &gt;400,000 distinct users related to one of the most popular dietary fads that evolve into a multibillion-dollar industry, i.e., gluten-free food. Besides, this work analysed one of the least research fields studied on Twitter concerning public health (i.e., the allergies or immunology diseases as celiac disease), discovering a wide range of health-related conclusions.},
  archive      = {J_ARTMED},
  author       = {Martín Pérez-Pérez and Gilberto Igrejas and Florentino Fdez-Riverola and Anália Lourenço},
  doi          = {10.1016/j.artmed.2021.102131},
  journal      = {Artificial Intelligence in Medicine},
  month        = {8},
  pages        = {102131},
  shortjournal = {Artif. Intell. Med.},
  title        = {A framework to extract biomedical knowledge from gluten-related tweets: The case of dietary concerns in digital era},
  volume       = {118},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Tracking leukocytes in intravital time lapse images using 3D
cell association learning network. <em>ARTMED</em>, <em>118</em>,
102129. (<a href="https://doi.org/10.1016/j.artmed.2021.102129">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Leukocytes are key cellular elements of the innate immune system in all vertebrates, which play a crucial role in defending organisms against invading pathogens . Tracking these highly migratory and amorphous cells in in vivo models such as zebrafish embryos is a challenging task in cellular immunology . As temporal and special analysis of these imaging datasets by a human operator is quite laborious, developing an automated cell tracking method is highly in demand. Despite the remarkable advances in cell detection, this field still lacks powerful algorithms to accurately associate the detected cell across time frames. The cell association challenge is mostly related to the amorphous nature of cells, and their complicated motion profile through their migratory paths. To tackle the cell association challenge, we proposed a novel deep-learning-based object linkage method. For this aim, we trained the 3D cell association learning network (3D-CALN) with enough manually labelled paired 3D images of single fluorescent zebrafish&#39;s neutrophils from two consecutive frames. Our experiment results prove that deep learning is significantly applicable in cell linkage and particularly for tracking highly mobile and amorphous leukocytes. A comparison of our tracking accuracy with other available tracking algorithms shows that our approach performs well in relation to addressing cell tracking problems .},
  archive      = {J_ARTMED},
  author       = {Marzieh R. Moghadam and Yi-Ping Phoebe Chen},
  doi          = {10.1016/j.artmed.2021.102129},
  journal      = {Artificial Intelligence in Medicine},
  month        = {8},
  pages        = {102129},
  shortjournal = {Artif. Intell. Med.},
  title        = {Tracking leukocytes in intravital time lapse images using 3D cell association learning network},
  volume       = {118},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-feature representation for burn depth classification
via burn images. <em>ARTMED</em>, <em>118</em>, 102128. (<a
href="https://doi.org/10.1016/j.artmed.2021.102128">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Burns are a common and severe problem in public health . Early and timely classification of burn depth is effective for patients to receive targeted treatment , which can save their lives. However, identifying burn depth from burn images requires physicians to have a lot of medical experience. The speed and precision to diagnose the depth of the burn image are not guaranteed due to its high workload and cost for clinicians. Thus, implementing some smart burn depth classification methods is desired at present. In this paper, we propose a computerized method to automatically evaluate the burn depth by using multiple features extracted from burn images. Specifically, color features , texture features and latent features are extracted from burn images, which are then concatenated together and fed to several classifiers, such as random forest to generate the burn level. A standard burn image dataset is evaluated by our proposed method, obtaining an Accuracy of 85.86% and 76.87% by classifying the burn images into two classes and three classes, respectively, outperforming conventional methods in the burn depth identification. The results indicate our approach is effective and has the potential to aid medical experts in identifying different burn depths.},
  archive      = {J_ARTMED},
  author       = {Bob Zhang and Jianhang Zhou},
  doi          = {10.1016/j.artmed.2021.102128},
  journal      = {Artificial Intelligence in Medicine},
  month        = {8},
  pages        = {102128},
  shortjournal = {Artif. Intell. Med.},
  title        = {Multi-feature representation for burn depth classification via burn images},
  volume       = {118},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Decision support for comorbid conditions via execution-time
integration of clinical guidelines using transaction-based semantics and
temporal planning. <em>ARTMED</em>, <em>118</em>, 102127. (<a
href="https://doi.org/10.1016/j.artmed.2021.102127">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In case of comorbidity, i.e., multiple medical conditions , Clinical Decision Support Systems (CDSS) should issue recommendations based on all relevant disease-related Clinical Practice Guidelines (CPG). However, treatments from multiple comorbid CPG often interact adversely (e.g., drug-drug interactions) or introduce operational inefficiencies (e.g., redundant scans). A common solution is the a-priori integration of computerized CPG, which involves integration decisions such as discarding, replacing or delaying clinical tasks (e.g., treatments) to avoid adverse interactions or inefficiencies. We argue this insufficiently deals with execution-time events: as the patient&#39;s health profile evolves, acute conditions occur, and real-time delays take place, new CPG integration decisions will often be needed, and prior ones may need to be reverted or undone. Any realistic CPG integration effort needs to further consider temporal aspects of clinical tasks—these are not only restricted by temporal constraints from CPGs (e.g., sequential relations, task durations) but also by CPG integration efforts (e.g., avoid treatment overlap). This poses a complex execution-time challenge and makes it difficult to determine an up-to-date, optimal comorbid care plan. We present a solution for dynamic integration of CPG in response to evolving health profiles and execution-time events. CPG integration policies are formulated by clinical experts for coping with comorbidity at execution-time, with clearly defined integration semantics that build on Description and Transaction Logics. A dynamic planning approach reconciles temporal constraints of CPG tasks at execution-time based on their importance, and continuously updates an optimal task schedule.},
  archive      = {J_ARTMED},
  author       = {William Van Woensel and Syed Sibte Raza Abidi and Samina Raza Abidi},
  doi          = {10.1016/j.artmed.2021.102127},
  journal      = {Artificial Intelligence in Medicine},
  month        = {8},
  pages        = {102127},
  shortjournal = {Artif. Intell. Med.},
  title        = {Decision support for comorbid conditions via execution-time integration of clinical guidelines using transaction-based semantics and temporal planning},
  volume       = {118},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Data-based algorithms and models using diabetics real data
for blood glucose and hypoglycaemia prediction – a systematic literature
review. <em>ARTMED</em>, <em>118</em>, 102120. (<a
href="https://doi.org/10.1016/j.artmed.2021.102120">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hypoglycaemia prediction play an important role in diabetes management being able to reduce the number of dangerous situations. Thus, it is relevant to present a systematic review on the currently available prediction algorithms and models for hypoglycaemia (or hypoglycemia in US English) prediction. This study aims to systematically review the literature on data-based algorithms and models using diabetics real data for hypoglycaemia prediction. Five electronic databases were screened for studies published from January 2014 to June 2020: ScienceDirect, IEEE Xplore, ACM Digital Library, SCOPUS, and PubMed . Sixty-three eligible studies were retrieved that met the inclusion criteria. The review identifies the current trend in this topic: most of the studies perform short-term predictions (82.5%). Also, the review pinpoints the inputs and shows that information fusion is relevant for hypoglycaemia prediction. Regarding data-based models (80.9%) and hybrid models (19.1%) different predictive techniques are used: Artificial neural network (22.2%), ensemble learning (27.0%), supervised learning (20.6%), statistic/probabilistic (7.9%), autoregressive (7.9%), evolutionary (6.4%), deep learning (4.8%) and adaptative filter (3.2%). Artificial Neural networks and hybrid models show better results. The data-based models for blood glucose and hypoglycaemia prediction should be able to provide a good balance between the applicability and performance, integrating complementary data from different sources or from different models. This review identifies trends and possible opportunities for research in this topic.},
  archive      = {J_ARTMED},
  author       = {Virginie Felizardo and Nuno M. Garcia and Nuno Pombo and Imen Megdiche},
  doi          = {10.1016/j.artmed.2021.102120},
  journal      = {Artificial Intelligence in Medicine},
  month        = {8},
  pages        = {102120},
  shortjournal = {Artif. Intell. Med.},
  title        = {Data-based algorithms and models using diabetics real data for blood glucose and hypoglycaemia prediction – a systematic literature review},
  volume       = {118},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Health issue identification in social media based on
multi-task hierarchical neural networks with topic attention.
<em>ARTMED</em>, <em>118</em>, 102119. (<a
href="https://doi.org/10.1016/j.artmed.2021.102119">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Health issue identification in social media is to predict whether the writers have a disease based on their posts. Numerous posts and comments are shared on social media by users. Certain posts may reflect writers&#39; health condition, which can be employed for health issue identification. Usually, the health issue identification problem is formulated as a classification task . In this paper, we propose novel multi-task hierarchical neural networks with topic attention for identifying health issue based on posts collected from the social media platforms . Specifically, the model incorporates the hierarchical relationship among the document, sentences, and words via bidirectional gated recurrent units (BiGRUs). The global topic information shared across posts is incorporated with the hidden states of BiGRUs to obtain the topic-enhanced attention weights for words. In addition, tasks of predicting whether the writers suffer from a disease (health issue identification) and predicting the specific domain of the posts (domain category classification) are learned jointly in multi-task mechanism. The proposed method is evaluated on two datasets: dementia issue dataset and depression issue dataset. The proposed approach achieves 98.03% and 88.28% F-1 score on two datasets, outperforming the state-of-the-art approach by 0.73% and 0.4% respectively. Further experimental analysis shows the effectiveness of incorporating both the multi-task learning framework and topic attention mechanism .},
  archive      = {J_ARTMED},
  author       = {Deyu Zhou and Jiale Yuan and Jiasheng Si},
  doi          = {10.1016/j.artmed.2021.102119},
  journal      = {Artificial Intelligence in Medicine},
  month        = {8},
  pages        = {102119},
  shortjournal = {Artif. Intell. Med.},
  title        = {Health issue identification in social media based on multi-task hierarchical neural networks with topic attention},
  volume       = {118},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The physiological deep learner: First application of
multitask deep learning to predict hypotension in critically ill
patients. <em>ARTMED</em>, <em>118</em>, 102118. (<a
href="https://doi.org/10.1016/j.artmed.2021.102118">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Critical care clinicians are trained to analyze simultaneously multiple physiological parameters to predict critical conditions such as hemodynamic instability. We developed the Multi-task Learning Physiological Deep Learner (MTL-PDL), a deep learning algorithm that predicts simultaneously the mean arterial pressure (MAP) and the heart rate (HR). In an external validation dataset, our model exhibited very good calibration: R 2 of 0.747 (95% confidence interval, 0.692 to 0.794) and 0.850 (0.815 to 0.879) for respectively, MAP and HR prediction 60-minutes ahead of time. For acute hypotensive episodes defined as a MAP below 65 mmHg for 5 min, our MTL-PDL reached a predictive value of 90% for patients at very high risk (predicted MAP ≤ 60 mmHg) and 2‰ for patients at low risk (predicted MAP &gt;70 mmHg). Based on its excellent prediction performance, the Physiological Deep Learner has the potential to help the clinician proactively adjust the treatment in order to avoid hypotensive episodes and end-organ hypoperfusion.},
  archive      = {J_ARTMED},
  author       = {Ményssa Cherifa and Yannet Interian and Alice Blet and Matthieu Resche-Rigon and Romain Pirracchio},
  doi          = {10.1016/j.artmed.2021.102118},
  journal      = {Artificial Intelligence in Medicine},
  month        = {8},
  pages        = {102118},
  shortjournal = {Artif. Intell. Med.},
  title        = {The physiological deep learner: First application of multitask deep learning to predict hypotension in critically ill patients},
  volume       = {118},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A progressive deep wavelet cascade classification model for
epilepsy detection. <em>ARTMED</em>, <em>118</em>, 102117. (<a
href="https://doi.org/10.1016/j.artmed.2021.102117">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic epileptic seizure detection according to EEG recordings is helpful for neurologists to identify an epilepsy occurrence in the initial anti-epileptic treatment. To quickly and accurately detect epilepsy, we proposed a progressive deep wavelet cascade classification model (PDWC) based on the discrete wavelet transform (DWT) and Random Forest (RF). Different from current deep networks, the PDWC mimics the progressive object identification process of human beings with recognition cycles. In every cycle, enhanced wavelet energy features at a specific scale were extracted by DWT and input into a set of cascade RF classifiers to realize one recognition. The recognition accuracy of PDWC is gradually improved by the fusion of classification results produced by multiple recognition cycles. Moreover, the cascade structure of PDWC can be automatically determined by the classification accuracy increment between layers. To verify the performance of the PDWC, we respectively applied five traditional schemes and four deep learning schemes to four public datasets. The results show that the PDWC is not only superior than five traditional schemes, including KNN, Bayes, DT, SVM , and RF, but also better than deep learning methods, i.e. convolutional neural network (CNN), Long Short-Term Memory (LSTM), multi-Grained Cascade Forest (gcForest) and wavelet cascade model (WCM). The mean accuracy of PDWC for all subjects of all datasets reaches to 0.9914. With a flexible structure and less parameters, the PDWC is more suitable for the epilepsy detection of diverse EEG signals.},
  archive      = {J_ARTMED},
  author       = {Hong He and Xinyue Liu and Yong Hao},
  doi          = {10.1016/j.artmed.2021.102117},
  journal      = {Artificial Intelligence in Medicine},
  month        = {8},
  pages        = {102117},
  shortjournal = {Artif. Intell. Med.},
  title        = {A progressive deep wavelet cascade classification model for epilepsy detection},
  volume       = {118},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Simultaneous segmentation and classification of the retinal
arteries and veins from color fundus images. <em>ARTMED</em>,
<em>118</em>, 102116. (<a
href="https://doi.org/10.1016/j.artmed.2021.102116">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The study of the retinal vasculature represents a fundamental stage in the screening and diagnosis of many high-incidence diseases, both systemic and ophthalmic . A complete retinal vascular analysis requires the segmentation of the vascular tree along with the classification of the blood vessels into arteries and veins. Early automatic methods approach these complementary segmentation and classification tasks in two sequential stages. However, currently, these two tasks are approached as a joint semantic segmentation, because the classification results highly depend on the effectiveness of the vessel segmentation. In that regard, we propose a novel approach for the simultaneous segmentation and classification of the retinal arteries and veins from eye fundus images. We propose a novel method that, unlike previous approaches, and thanks to the proposal of a novel loss, decomposes the joint task into three segmentation problems targeting arteries, veins and the whole vascular tree. This configuration allows to handle vessel crossings intuitively and directly provides accurate segmentation masks of the different target vascular trees. The provided ablation study on the public Retinal Images vessel Tree Extraction (RITE) dataset demonstrates that the proposed method provides a satisfactory performance, particularly in the segmentation of the different structures. Furthermore, the comparison with the state of the art shows that our method achieves highly competitive results in the artery/vein classification, while significantly improving the vascular segmentation. The proposed multi-segmentation method allows to detect more vessels and better segment the different structures, while achieving a competitive classification performance. Also, in these terms, our approach outperforms the approaches of various reference works. Moreover, in contrast with previous approaches, the proposed method allows to directly detect the vessel crossings, as well as preserving the continuity of both arteries and veins at these complex locations.},
  archive      = {J_ARTMED},
  author       = {José Morano and Álvaro S. Hervella and Jorge Novo and José Rouco},
  doi          = {10.1016/j.artmed.2021.102116},
  journal      = {Artificial Intelligence in Medicine},
  month        = {8},
  pages        = {102116},
  shortjournal = {Artif. Intell. Med.},
  title        = {Simultaneous segmentation and classification of the retinal arteries and veins from color fundus images},
  volume       = {118},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). MvKFN-MDA: Multi-view kernel fusion network for
miRNA-disease association prediction. <em>ARTMED</em>, <em>118</em>,
102115. (<a href="https://doi.org/10.1016/j.artmed.2021.102115">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predicting the associations between microRNAs (miRNAs) and diseases is of great significance for identifying miRNAs related to human diseases. Since it is time-consuming and costly to identify the association between miRNA and disease through biological experiments, computational methods are currently used as an effective supplement to identify the potential association between disease and miRNA. This paper presents a Multi-view Kernel Fusion Network (MvKFN) based prediction method (MvKFN-MDA) to address the problem of miRNA-disease associations prediction. A novel multiple kernel fusion framework Multi-view Kernel Fusion Network (MvKFN) is first proposed to effectively fuse different views similarity kernels constructed from different data sources in a highly nonlinear way. Using MvKFNs, both different base similarity kernels for miRNA, such as sequence, functional, semantic, Gaussian profile kernels and different base similarity kernels for diseases, such as semantic, Gaussian profile kernel are nonlinearly fused into two integrated similarity kernels, one for miRNA, another for disease. Then, miRNA and disease feature representations are extracted from the miRNA and disease integrated similarity kernels respectively. These features are then fed into a neural matrix completion framework which finally outputs the association prediction scores. The parameters of MvKFN-MDA are learned based on the known miRNA-disease association matrix in a supervised end-to-end way. We compare the proposed method with other state-of-the-art methods. The AUCs of our proposed method were superior to the existing methods in both 5-FCV and LOOCV on two open experimental datasets. Furthermore, 49, 48, and 47 of the top 50 predicted miRNAs for three high-risk human diseases, namely, colon cancer , lymphoma, and kidney cancer , are verified respectively using experimental literature. Finally, 100% accuracy from the top 50 predicted miRNAs is achieved when breast cancer is used as a case study to evaluate the ability of MvKFN-MDA for predicting a new disease without any known related miRNAs.},
  archive      = {J_ARTMED},
  author       = {Jin Li and Tao Liu and Jingru Wang and Qing Li and Chenxi Ning and Yun Yang},
  doi          = {10.1016/j.artmed.2021.102115},
  journal      = {Artificial Intelligence in Medicine},
  month        = {8},
  pages        = {102115},
  shortjournal = {Artif. Intell. Med.},
  title        = {MvKFN-MDA: Multi-view kernel fusion network for miRNA-disease association prediction},
  volume       = {118},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An explainable AI system for automated COVID-19 assessment
and lesion categorization from CT-scans. <em>ARTMED</em>, <em>118</em>,
102114. (<a href="https://doi.org/10.1016/j.artmed.2021.102114">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {COVID-19 infection caused by SARS-CoV-2 pathogen has been a catastrophic pandemic outbreak all over the world, with exponential increasing of confirmed cases and, unfortunately, deaths. In this work we propose an AI-powered pipeline, based on the deep-learning paradigm, for automated COVID-19 detection and lesion categorization from CT scans. We first propose a new segmentation module aimed at automatically identifying lung parenchyma and lobes. Next, we combine the segmentation network with classification networks for COVID-19 identification and lesion categorization. We compare the model&#39;s classification results with those obtained by three expert radiologists on a dataset of 166 CT scans . Results showed a sensitivity of 90.3% and a specificity of 93.5% for COVID-19 detection, at least on par with those yielded by the expert radiologists, and an average lesion categorization accuracy of about 84%. Moreover, a significant role is played by prior lung and lobe segmentation, that allowed us to enhance classification performance by over 6 percent points. The interpretation of the trained AI models reveals that the most significant areas for supporting the decision on COVID-19 identification are consistent with the lesions clinically associated to the virus, i.e., crazy paving, consolidation and ground glass. This means that the artificial models are able to discriminate a positive patient from a negative one (both controls and patients with interstitial pneumonia tested negative to COVID) by evaluating the presence of those lesions into CT scans. Finally, the AI models are integrated into a user-friendly GUI to support AI explainability for radiologists, which is publicly available at http://perceivelab.com/covid-ai . The whole AI system is unique since, to the best of our knowledge, it is the first AI-based software, publicly available, that attempts to explain to radiologists what information is used by AI methods for making decisions and that proactively involves them in the decision loop to further improve the COVID-19 understanding.},
  archive      = {J_ARTMED},
  author       = {Matteo Pennisi and Isaak Kavasidis and Concetto Spampinato and Vincenzo Schinina and Simone Palazzo and Federica Proietto Salanitri and Giovanni Bellitto and Francesco Rundo and Marco Aldinucci and Massimo Cristofaro and Paolo Campioni and Elisa Pianura and Federica Di Stefano and Ada Petrone and Fabrizio Albarello and Giuseppe Ippolito and Salvatore Cuzzocrea and Sabrina Conoci},
  doi          = {10.1016/j.artmed.2021.102114},
  journal      = {Artificial Intelligence in Medicine},
  month        = {8},
  pages        = {102114},
  shortjournal = {Artif. Intell. Med.},
  title        = {An explainable AI system for automated COVID-19 assessment and lesion categorization from CT-scans},
  volume       = {118},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Fully-channel regional attention network for
disease-location recognition with tongue images. <em>ARTMED</em>,
<em>118</em>, 102110. (<a
href="https://doi.org/10.1016/j.artmed.2021.102110">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Using the deep learning model to realize tongue image-based disease location recognition and focus on solving two problems: 1. The ability of the general convolution network to model detailed regional tongue features is weak; 2. Ignoring the group relationship between convolution channels, which caused the high redundancy of the model. To enhance the convolutional neural networks. In this paper, a stochastic region pooling method is proposed to gain detailed regional features. Also, an inner-imaging channel relationship modeling method is proposed to model multi-region relations on all channels. Moreover, we combine it with the spatial attention mechanism. The tongue image dataset with the clinical disease-location label is established. Abundant experiments are carried out on it. The experimental results show that the proposed method can effectively model the regional details of tongue image and improve the performance of disease location recognition. In this paper, we construct the tongue image dataset with disease-location labels to mine the relationship between tongue images and disease locations. A novel fully-channel regional attention network is proposed to model the local detail tongue features and improve the modeling efficiency. The applications of deep learning in tongue image disease-location recognition and the proposed innovative models have guiding significance for other assistant diagnostic tasks. The proposed model provides an example of efficient modeling of detailed tongue features, which is of great guiding significance for other auxiliary diagnosis applications.},
  archive      = {J_ARTMED},
  author       = {Yang Hu and Guihua Wen and Mingnan Luo and Pei Yang and Dan Dai and Zhiwen Yu and Changjun Wang and Wendy Hall},
  doi          = {10.1016/j.artmed.2021.102110},
  journal      = {Artificial Intelligence in Medicine},
  month        = {8},
  pages        = {102110},
  shortjournal = {Artif. Intell. Med.},
  title        = {Fully-channel regional attention network for disease-location recognition with tongue images},
  volume       = {118},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Enhancing evidence-based medicine with natural language
argumentative analysis of clinical trials. <em>ARTMED</em>,
<em>118</em>, 102098. (<a
href="https://doi.org/10.1016/j.artmed.2021.102098">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the latest years, the healthcare domain has seen an increasing interest in the definition of intelligent systems to support clinicians in their everyday tasks and activities. Among others, also the field of Evidence-Based Medicine is impacted by this twist, with the aim to combine the reasoning frameworks proposed thus far in the field with mining algorithms to extract structured information from clinical trials, clinical guidelines, and Electronic Health Records. In this paper, we go beyond the state of the art by proposing a new end-to-end pipeline to address argumentative outcome analysis on clinical trials. More precisely, our pipeline is composed of (i) an Argument Mining module to extract and classify argumentative components (i.e., evidence and claims of the trial) and their relations (i.e., support, attack), and (ii) an outcome analysis module to identify and classify the effects (i.e., improved, increased, decreased, no difference, no occurrence) of an intervention on the outcome of the trial, based on PICO elements. We annotated a dataset composed of more than 500 abstracts of Randomized Controlled Trials (RCT) from the MEDLINE database, leading to a labeled dataset with 4198 argument components, 2601 argument relations, and 3351 outcomes on five different diseases (i.e., neoplasm , glaucoma , hepatitis , diabetes , hypertension ). We experiment with deep bidirectional transformers in combination with different neural architectures (i.e., LSTM, GRU and CRF) and obtain a macro F1-score of.87 for component detection and.68 for relation prediction, outperforming current state-of-the-art end-to-end Argument Mining systems, and a macro F1-score of.80 for outcome classification.},
  archive      = {J_ARTMED},
  author       = {Tobias Mayer and Santiago Marro and Elena Cabrio and Serena Villata},
  doi          = {10.1016/j.artmed.2021.102098},
  journal      = {Artificial Intelligence in Medicine},
  month        = {8},
  pages        = {102098},
  shortjournal = {Artif. Intell. Med.},
  title        = {Enhancing evidence-based medicine with natural language argumentative analysis of clinical trials},
  volume       = {118},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Med7: A transferable clinical natural language processing
model for electronic health records. <em>ARTMED</em>, <em>118</em>,
102086. (<a href="https://doi.org/10.1016/j.artmed.2021.102086">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electronic health record systems are ubiquitous and the majority of patients’ data are now being collected electronically in the form of free text. Deep learning has significantly advanced the field of natural language processing and the self-supervised representation learning and the transfer learning have become the methods of choice in particular when the high quality annotated data are limited. Identification of medical concepts and information extraction is a challenging task, yet important ingredient for parsing unstructured data into structured and tabulated format for downstream analytical tasks. In this work we introduced a named-entity recognition (NER) model for clinical natural language processing. The model is trained to recognise seven categories: drug names, route of administration, frequency, dosage, strength, form, duration. The model was first pre-trained on the task of predicting the next word, using a collection of 2 million free-text patients’ records from MIMIC-III corpora followed by fine-tuning on the named-entity recognition task. The model achieved a micro-averaged F 1 score of 0.957 across all seven categories. Additionally, we evaluated the transferability of the developed model using the data from the Intensive Care Unit in the US to secondary care mental health records (CRIS) in the UK. A direct application of the trained NER model to CRIS data resulted in reduced performance of F 1 = 0.762, however after fine-tuning on a small sample from CRIS, the model achieved a reasonable performance of F 1 = 0.944. This demonstrated that despite a close similarity between the data sets and the NER tasks, it is essential to fine-tune the target domain data in order to achieve more accurate results. The resulting model and the pre-trained embeddings are available at https://github.com/kormilitzin/med7 .},
  archive      = {J_ARTMED},
  author       = {Andrey Kormilitzin and Nemanja Vaci and Qiang Liu and Alejo Nevado-Holgado},
  doi          = {10.1016/j.artmed.2021.102086},
  journal      = {Artificial Intelligence in Medicine},
  month        = {8},
  pages        = {102086},
  shortjournal = {Artif. Intell. Med.},
  title        = {Med7: A transferable clinical natural language processing model for electronic health records},
  volume       = {118},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A new approach for interpretability and reliability in
clinical risk prediction: Acute coronary syndrome scenario.
<em>ARTMED</em>, <em>117</em>, 102113. (<a
href="https://doi.org/10.1016/j.artmed.2021.102113">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The risk prediction of the occurrence of a clinical event is often based on conventional statistical procedures, through the implementation of risk score models. Recently, approaches based on more complex machine learning (ML) methods have been developed. Despite the latter usually have a better predictive performance, they obtain little approval from the physicians, as they lack interpretability and, therefore, clinical confidence. One clinical issue where both types of models have received great attention is the mortality risk prediction after acute coronary syndromes (ACS). We intend to create a new risk assessment methodology that combines the best characteristics of both risk score and ML models. More specifically, we aim to develop a method that, besides having a good performance, offers a personalized model and outcome for each patient, presents high interpretability, and incorporates an estimation of the prediction reliability which is not usually available. By combining these features in the same approach we expect that it can boost the confidence of physicians to use such a tool in their daily activity. In order to achieve the mentioned goals, a three-step methodology was developed: several rules were created by dichotomizing risk factors; such rules were trained with a machine learning classifier to predict the acceptance degree of each rule (the probability that the rule is correct) for each patient; that information was combined and used to compute the risk of mortality and the reliability of such prediction. The methodology was applied to a dataset of 1111 patients admitted with any type of ACS (myocardial infarction and unstable angina) in two Portuguese hospitals, to assess the 30-days all-cause mortality risk, being validated through a Monte-Carlo cross-validation technique. The performance was compared with state-of-the-art approaches: logistic regression (LR), artificial neural network (ANN), and clinical risk score model (namely the Global Registry of Acute Coronary Events – GRACE). For the scenario being analyzed, the performance of the proposed approach and the comparison models was assessed through discrimination and calibration. The ability to rank the patients was evaluated through the area under the ROC curve (AUC), and the ability to stratify the patients into low or high-risk groups was determined using the geometric mean (GM) of specificity and sensitivity, the negative predictive value (NPV) and the positive predictive value (PPV). The validation calibration curves were also inspected. The proposed approach (AUC = 81%, GM = 74%, PPV = 17%, NPV = 99%) achieved testing results identical to the standard LR model (AUC = 83%, GM = 73%, PPV = 16%, NPV=99%), but offers superior interpretability and personalization; it also significantly outperforms the GRACE risk model (AUC = 79%, GM = 47%, PPV = 13%, NPV = 98%) and the standard ANN model (AUC = 78%, GM = 70%, PPV = 13%, NPV = 98%). The calibration curve also suggests a very good generalization ability of the obtained model as it approaches the ideal curve (slope = 0.96). Finally, the reliability estimation of individual predictions presented a great correlation with the misclassifications rate. We developed and described a new tool that showed great potential to guide the clinical staff in the risk assessment and decision-making process, and to obtain their wide acceptance due to its interpretability and reliability estimation properties. The methodology presented a good performance when applied to ACS events, but those properties may have a beneficial application in other clinical scenarios as well.},
  archive      = {J_ARTMED},
  author       = {Francisco Valente and Jorge Henriques and Simão Paredes and Teresa Rocha and Paulo de Carvalho and João Morais},
  doi          = {10.1016/j.artmed.2021.102113},
  journal      = {Artificial Intelligence in Medicine},
  month        = {7},
  pages        = {102113},
  shortjournal = {Artif. Intell. Med.},
  title        = {A new approach for interpretability and reliability in clinical risk prediction: Acute coronary syndrome scenario},
  volume       = {117},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Improving clinical outcome predictions using convolution
over medical entities with multimodal learning. <em>ARTMED</em>,
<em>117</em>, 102112. (<a
href="https://doi.org/10.1016/j.artmed.2021.102112">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Early prediction of mortality and length of stay (LOS) of a patient is vital for saving a patient&#39;s life and management of hospital resources. Availability of Electronic Health Records (EHR) makes a huge impact on the healthcare domain and there are several works on predicting clinical problems. However, many studies did not benefit from the clinical notes because of the sparse, and high dimensional nature. In this work, we extract medical entities from clinical notes and use them as additional features besides time-series features to improve proposed model predictions. The proposed convolution based multimodal architecture, which not only learns effectively combining medical entities and time-series Intensive Care Unit (ICU) signals of patients but also allows to compare the effect of different embedding techniques such as Word2vec and FastText on medical entities. Results show that the proposed deep multimodal method outperforms all other baseline models including multimodal architectures and improves the mortality prediction performance for Area Under the Receiver Operating Characteristics (AUROC) and Area Under Precision-Recall Curve (AUPRC) by around 3%. For LOS predictions, there is an improvement of around 2.5% over the time-series baseline. The code for the proposed method is available at https://github.com/tanlab/ConvolutionMedicalNer .},
  archive      = {J_ARTMED},
  author       = {Batuhan Bardak and Mehmet Tan},
  doi          = {10.1016/j.artmed.2021.102112},
  journal      = {Artificial Intelligence in Medicine},
  month        = {7},
  pages        = {102112},
  shortjournal = {Artif. Intell. Med.},
  title        = {Improving clinical outcome predictions using convolution over medical entities with multimodal learning},
  volume       = {117},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A review of AI and data science support for cancer
management. <em>ARTMED</em>, <em>117</em>, 102111. (<a
href="https://doi.org/10.1016/j.artmed.2021.102111">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Thanks to improvement of care, cancer has become a chronic condition. But due to the toxicity of treatment, the importance of supporting the quality of life (QoL) of cancer patients increases. Monitoring and managing QoL relies on data collected by the patient in his/her home environment, its integration, and its analysis, which supports personalization of cancer management recommendations. We review the state-of-the-art of computerized systems that employ AI and Data Science methods to monitor the health status and provide support to cancer patients managed at home. Our main objective is to analyze the literature to identify open research challenges that a novel decision support system for cancer patients and clinicians will need to address, point to potential solutions, and provide a list of established best-practices to adopt. We designed a review study, in compliance with the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) guidelines, analyzing studies retrieved from PubMed related to monitoring cancer patients in their home environments via sensors and self-reporting: what data is collected, what are the techniques used to collect data, semantically integrate it, infer the patient’s state from it and deliver coaching/behavior change interventions. Starting from an initial corpus of 819 unique articles, a total of 180 papers were considered in the full-text analysis and 109 were finally included in the review. Our findings are organized and presented in four main sub-topics consisting of data collection, data integration, predictive modeling and patient coaching. Development of modern decision support systems for cancer needs to utilize best practices like the use of validated electronic questionnaires for quality-of-life assessment, adoption of appropriate information modeling standards supplemented by terminologies/ontologies, adherence to FAIR data principles, external validation, stratification of patients in subgroups for better predictive modeling, and adoption of formal behavior change theories. Open research challenges include supporting emotional and social dimensions of well-being, including PROs in predictive modeling, and providing better customization of behavioral interventions for the specific population of cancer patients.},
  archive      = {J_ARTMED},
  author       = {E. Parimbelli and S. Wilk and R. Cornet and P. Sniatala and K. Sniatala and S.L.C. Glaser and I. Fraterman and A.H Boekhout and M. Ottaviano and M. Peleg},
  doi          = {10.1016/j.artmed.2021.102111},
  journal      = {Artificial Intelligence in Medicine},
  month        = {7},
  pages        = {102111},
  shortjournal = {Artif. Intell. Med.},
  title        = {A review of AI and data science support for cancer management},
  volume       = {117},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Abdominal multi-organ segmentation with cascaded
convolutional and adversarial deep networks. <em>ARTMED</em>,
<em>117</em>, 102109. (<a
href="https://doi.org/10.1016/j.artmed.2021.102109">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abdominal anatomy segmentation is crucial for numerous applications from computer-assisted diagnosis to image-guided surgery. In this context, we address fully-automated multi-organ segmentation from abdominal CT and MR images using deep learning . The proposed model extends standard conditional generative adversarial networks. Additionally to the discriminator which enforces the model to create realistic organ delineations, it embeds cascaded partially pre-trained convolutional encoder-decoders as generator. Encoder fine-tuning from a large amount of non-medical images alleviates data scarcity limitations. The network is trained end-to-end to benefit from simultaneous multi-level segmentation refinements using auto-context. Employed for healthy liver, kidneys and spleen segmentation, our pipeline provides promising results by outperforming state-of-the-art encoder-decoder schemes. Followed for the Combined Healthy Abdominal Organ Segmentation (CHAOS) challenge organized in conjunction with the IEEE International Symposium on Biomedical Imaging 2019, it gave us the first rank for three competition categories: liver CT, liver MR and multi-organ MR segmentation. Combining cascaded convolutional and adversarial networks strengthens the ability of deep learning pipelines to automatically delineate multiple abdominal organs, with good generalization capability. The comprehensive evaluation provided suggests that better guidance could be achieved to help clinicians in abdominal image interpretation and clinical decision making.},
  archive      = {J_ARTMED},
  author       = {Pierre-Henri Conze and Ali Emre Kavur and Emilie Cornec-Le Gall and Naciye Sinem Gezer and Yannick Le Meur and M. Alper Selver and François Rousseau},
  doi          = {10.1016/j.artmed.2021.102109},
  journal      = {Artificial Intelligence in Medicine},
  month        = {7},
  pages        = {102109},
  shortjournal = {Artif. Intell. Med.},
  title        = {Abdominal multi-organ segmentation with cascaded convolutional and adversarial deep networks},
  volume       = {117},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A comprehensive scoping review of bayesian networks in
healthcare: Past, present and future. <em>ARTMED</em>, <em>117</em>,
102108. (<a href="https://doi.org/10.1016/j.artmed.2021.102108">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {No comprehensive review of Bayesian networks (BNs) in healthcare has been published in the past , making it difficult to organize the research contributions i n the present and identify challenges and neglected areas that need to be addressed in the future . This unique and novel scoping review of BNs in healthcare provides an analytical framework for comprehensively characterizing the domain and its current state. A literature search of health and health informatics literature databases using relevant keywords found 3810 articles that were reduced to 123. This was after screening out those presenting Bayesian statistics, meta-analysis or neural networks, as opposed to BNs and those describing the predictive performance of multiple machine learning algorithms, of which BNs were simply one type. Using the novel analytical framework, we show that: (1) BNs in healthcare are not used to their full potential; (2) a generic BN development process is lacking; (3) limitations exist in the way BNs in healthcare are presented in the literature, which impacts understanding, consensus towards systematic methodologies, practice and adoption; and (4) a gap exists between having an accurate BN and a useful BN that impacts clinical practice. This review highlights several neglected issues, such as restricted aims of BNs, ad hoc BN development methods, and the lack of BN adoption in practice and reveals to researchers and clinicians the need to address these problems. To map the way forward, the paper proposes future research directions and makes recommendations regarding BN development methods and adoption in practice.},
  archive      = {J_ARTMED},
  author       = {Evangelia Kyrimi and Scott McLachlan and Kudakwashe Dube and Mariana R. Neves and Ali Fahmi and Norman Fenton},
  doi          = {10.1016/j.artmed.2021.102108},
  journal      = {Artificial Intelligence in Medicine},
  month        = {7},
  pages        = {102108},
  shortjournal = {Artif. Intell. Med.},
  title        = {A comprehensive scoping review of bayesian networks in healthcare: Past, present and future},
  volume       = {117},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A predictive framework in healthcare: Case study on cardiac
arrest prediction. <em>ARTMED</em>, <em>117</em>, 102099. (<a
href="https://doi.org/10.1016/j.artmed.2021.102099">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data-driven healthcare uses predictive analytics to enhance decision-making and personalized healthcare. Developing prognostic models is one of the applications of predictive analytics in medical environments. Various studies have used machine learning techniques for this purpose. However, there is no specific standard for choosing prediction models for different medical purposes. In this paper, the ISAF framework was proposed for choosing appropriate prediction models with regard to the properties of the classification methods. As one of the case study applications, a prognostic model for predicting cardiac arrests in sepsis patients was developed step by step through the ISAF framework. Finally, a new modified stacking model produced the best results. We predict 85 % of heart arrest cases one hour before the incidence (sensitivity&gt; = 0.85) and 73 % of arrest cases 25 h before the occurrence (sensitivity&gt; = 0.73). The results indicated that the proposed prognostic model has significantly improved the prediction results compared to the two standard systems of APACHE II and MEWS. Furthermore, compared to previous research, the proposed model has extended the prediction interval and improved the performance criteria.},
  archive      = {J_ARTMED},
  author       = {Samaneh Layeghian Javan and Mohammad Mehdi Sepehri},
  doi          = {10.1016/j.artmed.2021.102099},
  journal      = {Artificial Intelligence in Medicine},
  month        = {7},
  pages        = {102099},
  shortjournal = {Artif. Intell. Med.},
  title        = {A predictive framework in healthcare: Case study on cardiac arrest prediction},
  volume       = {117},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Simultaneous imputation and classification using multigraph
geometric matrix completion (MGMC): Application to neurodegenerative
disease classification. <em>ARTMED</em>, <em>117</em>, 102097. (<a
href="https://doi.org/10.1016/j.artmed.2021.102097">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large-scale population-based studies in medicine are a key resource towards better diagnosis, monitoring, and treatment of diseases. They also serve as enablers of clinical decision support systems, in particular computer-aided diagnosis (CADx) using machine learning (ML). Numerous ML approaches for CADx have been proposed in literature. However, these approaches assume feature-complete data, which is often not the case in clinical data. To account for missing data, incomplete data samples are either removed or imputed, which could lead to data bias and may negatively affect classification performance. As a solution, we propose an end-to-end learning of imputation and disease prediction of incomplete medical datasets via Multi-graph Geometric Matrix Completion (MGMC). MGMC uses multiple recurrent graph convolutional networks, where each graph represents an independent population model based on a key clinical meta-feature like age, sex, or cognitive function. Graph signal aggregation from local patient neighborhoods, combined with multi-graph signal fusion via self-attention, has a regularizing effect on both matrix reconstruction and classification performance. Our proposed approach is able to impute class relevant features as well as perform accurate and robust classification on two publicly available medical datasets. We empirically show the superiority of our proposed approach in terms of classification and imputation performance when compared with state-of-the-art approaches. MGMC enables disease prediction in multimodal and incomplete medical datasets. These findings could serve as baseline for future CADx approaches which utilize incomplete datasets.},
  archive      = {J_ARTMED},
  author       = {Gerome Vivar and Anees Kazi and Hendrik Burwinkel and Andreas Zwergal and Nassir Navab and Seyed-Ahmad Ahmadi and for the Parkinson’s Progression Markers and Alzheimer’s Disease Neuroimaging Initiatives},
  doi          = {10.1016/j.artmed.2021.102097},
  journal      = {Artificial Intelligence in Medicine},
  month        = {7},
  pages        = {102097},
  shortjournal = {Artif. Intell. Med.},
  title        = {Simultaneous imputation and classification using multigraph geometric matrix completion (MGMC): Application to neurodegenerative disease classification},
  volume       = {117},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Evaluation of clustering and topic modeling methods over
health-related tweets and emails. <em>ARTMED</em>, <em>117</em>, 102096.
(<a href="https://doi.org/10.1016/j.artmed.2021.102096">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Internet provides different tools for communicating with patients, such as social media (e.g., Twitter) and email platforms. These platforms provided new data sources to shed lights on patient experiences with health care and improve our understanding of patient-provider communication. Several existing topic modeling and document clustering methods have been adapted to analyze these new free-text data automatically. However, both tweets and emails are often composed of short texts; and existing topic modeling and clustering approaches have suboptimal performance on these short texts. Moreover, research over health-related short texts using these methods has become difficult to reproduce and benchmark, partially due to the absence of a detailed comparison of state-of-the-art topic modeling and clustering methods on these short texts. We trained eight state-of- the-art topic modeling and clustering algorithms on short texts from two health-related datasets (tweets and emails): Latent Semantic Indexing (LSI), Latent Dirichlet Allocation (LDA), LDA with Gibbs Sampling (GibbsLDA), Online LDA, Biterm Model (BTM), Online Twitter LDA, and Gibbs Sampling for Dirichlet Multinomial Mixture (GSDMM), as well as the k -means clustering algorithm with two different feature representations: TF-IDF and Doc2Vec. We used cluster validity indices to evaluate the performance of topic modeling and clustering: two internal indices (i.e. assessing the goodness of a clustering structure without external information) and five external indices (i.e. comparing the results of a cluster analysis to an externally known provided class labels). In overall, for number of clusters ( k ) from 2 to 50, Online Twitter LDA and GSDMM achieved the best performance in terms of internal indices, while LSI and k -means with TF-IDF had the highest external indices. Also, of all tweets ( N = 286, 971; HPV represents 94.6% of tweets and lynch syndrome represents 5.4%), for k = 2, most of the methods could respect this initial clustering distribution. However, we found model performance varies with the source of data and hyper-parameters such as the number of topics and the number of iterations used to train the models. We also conducted an error analysis using the Hamming loss metric, for which the poorest value was obtained by GSDMM on both datasets. Researchers hoping to group or classify health related short-text data can expect to select the most suitable topic modeling and clustering methods for their specific research questions. Therefore, we presented a comparison of the most common used topic modeling and clustering algorithms over two health-related, short-text datasets using both internal and external clustering validation indices. Internal indices suggested Online Twitter LDA and GSDMM as the best, while external indices suggested LSI and k -means with TF-IDF as the best. In summary, our work suggested researchers can improve their analysis of model performance by using a variety of metrics, since there is not a single best metric.},
  archive      = {J_ARTMED},
  author       = {Juan Antonio Lossio-Ventura and Sergio Gonzales and Juandiego Morzan and Hugo Alatrista-Salas and Tina Hernandez-Boussard and Jiang Bian},
  doi          = {10.1016/j.artmed.2021.102096},
  journal      = {Artificial Intelligence in Medicine},
  month        = {7},
  pages        = {102096},
  shortjournal = {Artif. Intell. Med.},
  title        = {Evaluation of clustering and topic modeling methods over health-related tweets and emails},
  volume       = {117},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Deep ensemble multitask classification of emergency medical
call incidents combining multimodal data improves emergency medical
dispatch. <em>ARTMED</em>, <em>117</em>, 102088. (<a
href="https://doi.org/10.1016/j.artmed.2021.102088">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The objective of this work was to develop a predictive model to aid non-clinical dispatchers to classify emergency medical call incidents by their life-threatening level (yes/no), admissible response delay (undelayable, minutes, hours, days) and emergency system jurisdiction (emergency system/primary care) in real time. We used a total of 1 244 624 independent incidents from the Valencian emergency medical dispatch service in Spain, compiled in retrospective from 2009 to 2012, including clinical features, demographics, circumstantial factors and free text dispatcher observations. Based on them, we designed and developed DeepEMC 2 , a deep ensemble multitask model integrating four subnetworks: three specialized to context, clinical and text data, respectively, and another to ensemble the former. The four subnetworks are composed in turn by multi-layer perceptron modules, bidirectional long short-term memory units and a bidirectional encoding representations from transformers module. DeepEMC 2 showed a macro F1-score of 0.759 in life-threatening classification, 0.576 in admissible response delay and 0.757 in emergency system jurisdiction. These results show a substantial performance increase of 12.5 %, 17.5 % and 5.1 %, respectively, with respect to the current in-house triage protocol of the Valencian emergency medical dispatch service. Besides, DeepEMC 2 significantly outperformed a set of baseline machine learning models, including naive bayes, logistic regression, random forest and gradient boosting (α = 0.05). Hence, DeepEMC 2 is able to: 1) capture information present in emergency medical calls not considered by the existing triage protocol, and 2) model complex data dependencies not feasible by the tested baseline models. Likewise, our results suggest that most of this unconsidered information is present in the free text dispatcher observations. To our knowledge, this study describes the first deep learning model undertaking emergency medical call incidents classification. Its adoption in medical dispatch centers would potentially improve emergency dispatch processes, resulting in a positive impact in patient wellbeing and health services sustainability.},
  archive      = {J_ARTMED},
  author       = {Pablo Ferri and Carlos Sáez and Antonio Félix-De Castro and Javier Juan-Albarracín and Vicent Blanes-Selva and Purificación Sánchez-Cuesta and Juan M. García-Gómez},
  doi          = {10.1016/j.artmed.2021.102088},
  journal      = {Artificial Intelligence in Medicine},
  month        = {7},
  pages        = {102088},
  shortjournal = {Artif. Intell. Med.},
  title        = {Deep ensemble multitask classification of emergency medical call incidents combining multimodal data improves emergency medical dispatch},
  volume       = {117},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Prediction of weaning from mechanical ventilation using
convolutional neural networks. <em>ARTMED</em>, <em>117</em>, 102087.
(<a href="https://doi.org/10.1016/j.artmed.2021.102087">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Weaning from mechanical ventilation covers the process of liberating the patient from mechanical support and removing the associated endotracheal tube. The management of weaning from mechanical ventilation comprises a significant proportion of the care of critically ill intubated patients in Intensive Care Units (ICUs). Both prolonged dependence on mechanical ventilation and premature extubation expose patients to an increased risk of complications and increased health care costs. This work aims to develop a decision support model using routinely-recorded patient information to predict extubation readiness. In order to do so, we have deployed Convolutional Neural Networks (CNN) to predict the most appropriate treatment action in the next hour for a given patient state, using historical ICU data extracted from MIMIC-III. The model achieved 86% accuracy and 0.94 area under the receiver operating characteristic curve (AUC-ROC). We also performed feature importance analysis for the CNN model and interpreted these features using the DeepLIFT method. The results of the feature importance assessment show that the CNN model makes predictions using clinically meaningful and appropriate features. Finally, we implemented counterfactual explanations for the CNN model. This can help clinicians understand what feature changes for a particular patient would lead to a desirable outcome, i.e. readiness to extubate.},
  archive      = {J_ARTMED},
  author       = {Yan Jia and Chaitanya Kaul and Tom Lawton and Roderick Murray-Smith and Ibrahim Habli},
  doi          = {10.1016/j.artmed.2021.102087},
  journal      = {Artificial Intelligence in Medicine},
  month        = {7},
  pages        = {102087},
  shortjournal = {Artif. Intell. Med.},
  title        = {Prediction of weaning from mechanical ventilation using convolutional neural networks},
  volume       = {117},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Application of substitution box of present cipher for
automated detection of snoring sounds. <em>ARTMED</em>, <em>117</em>,
102085. (<a href="https://doi.org/10.1016/j.artmed.2021.102085">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Snoring is one of the sleep disorders, and snoring sounds have been used to diagnose many sleep-related diseases. However, the snoring sound classification is done manually which is time-consuming and prone to human errors. An automated snoring sound classification model is proposed to overcome these problems. This work proposes an automated snoring sound classification method using three new methods. These methods are maximum absolute pooling (MAP), the nonlinear present pattern, and two-layered neighborhood component analysis, and iterative neighborhood component analysis (NCAINCA) selector. Using these methods, a new snoring sound classification (SSC) model is presented. The MAP decomposition model is applied to snoring sounds to extract both low and high-level features. The presented model aims to attain high performance for SSC problem. The developed present pattern (Present-Pat) uses substitution box (SBox) and statistical feature generator. By deploying these feature generators, both textural and statistical features are generated. NCAINCA chooses the most informative/valuable features, and these selected features are fed to k-nearest neighbor (kNN) classifier with leave-one-out cross-validation (LOOCV). The Present-Pat based SSC system is developed using Munich-Passau Snore Sound Corpus (MPSSC) dataset comprising of four categories. Our model reached an accuracy and unweighted average recall (UAR) of 97.10 % and 97.60 %, respectively, using LOOCV. Moreover, a nocturnal sound dataset is used to show the universal success of the presented model. Our model attained an accuracy of 98.14 % using the used nocturnal sound dataset. Our developed classification model is ready to be tested with more data and can be used by sleep specialists to diagnose the sleep disorders based on snoring sounds.},
  archive      = {J_ARTMED},
  author       = {Sengul Dogan and Erhan Akbal and Turker Tuncer and U. Rajendra Acharya},
  doi          = {10.1016/j.artmed.2021.102085},
  journal      = {Artificial Intelligence in Medicine},
  month        = {7},
  pages        = {102085},
  shortjournal = {Artif. Intell. Med.},
  title        = {Application of substitution box of present cipher for automated detection of snoring sounds},
  volume       = {117},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Interpreting deep learning models for epileptic seizure
detection on EEG signals. <em>ARTMED</em>, <em>117</em>, 102084. (<a
href="https://doi.org/10.1016/j.artmed.2021.102084">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While Deep Learning (DL) is often considered the state-of-the art for Artificial Intel-ligence-based medical decision support, it remains sparsely implemented in clinical practice and poorly trusted by clinicians due to insufficient interpretability of neural network models. We have approached this issue in the context of online detection of epileptic seizures by developing a DL model from EEG signals, and associating certain properties of the model behavior with the expert medical knowledge. This has conditioned the preparation of the input signals, the network architecture, and the post-processing of the output in line with the domain knowledge. Specifically, we focused the discussion on three main aspects: (1) how to aggregate the classification results on signal segments provided by the DL model into a larger time scale, at the seizure-level; (2) what are the relevant frequency patterns learned in the first convolutional layer of different models, and their relation with the delta, theta, alpha, beta and gamma frequency bands on which the visual interpretation of EEG is based; and (3) the identification of the signal waveforms with larger contribution towards the ictal class, according to the activation differences highlighted using the DeepLIFT method. Results show that the kernel size in the first layer determines the interpretability of the extracted features and the sensitivity of the trained models, even though the final performance is very similar after post-processing. Also, we found that amplitude is the main feature leading to an ictal prediction, suggesting that a larger patient population would be required to learn more complex frequency patterns. Still, our methodology was successfully able to generalize patient inter-variability for the majority of the studied population with a classification F1-score of 0.873 and detecting 90% of the seizures.},
  archive      = {J_ARTMED},
  author       = {Valentin Gabeff and Tomas Teijeiro and Marina Zapater and Leila Cammoun and Sylvain Rheims and Philippe Ryvlin and David Atienza},
  doi          = {10.1016/j.artmed.2021.102084},
  journal      = {Artificial Intelligence in Medicine},
  month        = {7},
  pages        = {102084},
  shortjournal = {Artif. Intell. Med.},
  title        = {Interpreting deep learning models for epileptic seizure detection on EEG signals},
  volume       = {117},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-domain clinical natural language processing with
MedCAT: The medical concept annotation toolkit. <em>ARTMED</em>,
<em>117</em>, 102083. (<a
href="https://doi.org/10.1016/j.artmed.2021.102083">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electronic health records (EHR) contain large volumes of unstructured text, requiring the application of information extraction (IE) technologies to enable clinical analysis. We present the open source Medical Concept Annotation Toolkit (MedCAT) that provides: (a) a novel self-supervised machine learning algorithm for extracting concepts using any concept vocabulary including UMLS/SNOMED-CT; (b) a feature-rich annotation interface for customizing and training IE models; and (c) integrations to the broader CogStack ecosystem for vendor-agnostic health system deployment. We show improved performance in extracting UMLS concepts from open datasets (F1:0.448–0.738 vs 0.429–0.650). Further real-world validation demonstrates SNOMED-CT extraction at 3 large London hospitals with self-supervised training over ∼ ∼ 8.8B words from ∼ ∼ 17M clinical records and further fine-tuning with ∼ ∼ 6K clinician annotated examples. We show strong transferability (F1 &gt; 0.94) between hospitals, datasets and concept types indicating cross-domain EHR-agnostic utility for accelerated clinical and research use cases.},
  archive      = {J_ARTMED},
  author       = {Zeljko Kraljevic and Thomas Searle and Anthony Shek and Lukasz Roguski and Kawsar Noor and Daniel Bean and Aurelie Mascio and Leilei Zhu and Amos A. Folarin and Angus Roberts and Rebecca Bendayan and Mark P. Richardson and Robert Stewart and Anoop D. Shah and Wai Keong Wong and Zina Ibrahim and James T. Teo and Richard J.B. Dobson},
  doi          = {10.1016/j.artmed.2021.102083},
  journal      = {Artificial Intelligence in Medicine},
  month        = {7},
  pages        = {102083},
  shortjournal = {Artif. Intell. Med.},
  title        = {Multi-domain clinical natural language processing with MedCAT: The medical concept annotation toolkit},
  volume       = {117},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). NIA-network: Towards improving lung CT infection detection
for COVID-19 diagnosis. <em>ARTMED</em>, <em>117</em>, 102082. (<a
href="https://doi.org/10.1016/j.artmed.2021.102082">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {During pandemics (e.g., COVID-19) physicians have to focus on diagnosing and treating patients, which often results in that only a limited amount of labeled CT images is available. Although recent semi-supervised learning algorithms may alleviate the problem of annotation scarcity, limited real-world CT images still cause those algorithms producing inaccurate detection results, especially in real-world COVID-19 cases. Existing models often cannot detect the small infected regions in COVID-19 CT images, such a challenge implicitly causes that many patients with minor symptoms are misdiagnosed and develop more severe symptoms, causing a higher mortality. In this paper, we propose a new method to address this challenge. Not only can we detect severe cases, but also detect minor symptoms using real-world COVID-19 CT images in which the source domain only includes limited labeled CT images but the target domain has a lot of unlabeled CT images. Specifically, we adopt Network-in-Network and Instance Normalization to build a new module (we term it NI module) and extract discriminative representations from CT images from both source and target domains. A domain classifier is utilized to implement infected region adaptation from source domain to target domain in an Adversarial Learning manner, and learns domain-invariant region proposal network (RPN) in the Faster R-CNN model. We call our model NIA-Network ( Network-in-Network , Instance Normalization and Adversarial Learning ), and conduct extensive experiments on two COVID-19 datasets to validate our approach. The experimental results show that our model can effectively detect infected regions with different sizes and achieve the highest diagnostic accuracy compared with existing SOTA methods.},
  archive      = {J_ARTMED},
  author       = {Wei Li and Jinlin Chen and Ping Chen and Lequan Yu and Xiaohui Cui and Yiwei Li and Fang Cheng and Wen Ouyang},
  doi          = {10.1016/j.artmed.2021.102082},
  journal      = {Artificial Intelligence in Medicine},
  month        = {7},
  pages        = {102082},
  shortjournal = {Artif. Intell. Med.},
  title        = {NIA-network: Towards improving lung CT infection detection for COVID-19 diagnosis},
  volume       = {117},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Artificial intelligence in neurodegenerative diseases: A
review of available tools with a focus on machine learning techniques.
<em>ARTMED</em>, <em>117</em>, 102081. (<a
href="https://doi.org/10.1016/j.artmed.2021.102081">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neurodegenerative diseases have shown an increasing incidence in the older population in recent years. A significant amount of research has been conducted to characterize these diseases. Computational methods, and particularly machine learning techniques, are now very useful tools in helping and improving the diagnosis as well as the disease monitoring process. In this paper, we provide an in-depth review on existing computational approaches used in the whole neurodegenerative spectrum, namely for Alzheimer&#39;s, Parkinson&#39;s, and Huntington&#39;s Diseases, Amyotrophic Lateral Sclerosis, and Multiple System Atrophy. We propose a taxonomy of the specific clinical features, and of the existing computational methods. We provide a detailed analysis of the various modalities and decision systems employed for each disease. We identify and present the sleep disorders which are present in various diseases and which represent an important asset for onset detection. We overview the existing data set resources and evaluation metrics. Finally, we identify current remaining open challenges and discuss future perspectives.},
  archive      = {J_ARTMED},
  author       = {Alexandra-Maria Tăuţan and Bogdan Ionescu and Emiliano Santarnecchi},
  doi          = {10.1016/j.artmed.2021.102081},
  journal      = {Artificial Intelligence in Medicine},
  month        = {7},
  pages        = {102081},
  shortjournal = {Artif. Intell. Med.},
  title        = {Artificial intelligence in neurodegenerative diseases: A review of available tools with a focus on machine learning techniques},
  volume       = {117},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Cost-effectiveness analysis with unordered decisions.
<em>ARTMED</em>, <em>117</em>, 102064. (<a
href="https://doi.org/10.1016/j.artmed.2021.102064">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cost-effectiveness analysis (CEA) is used increasingly in medicine to determine whether the health benefit of an intervention is worth the economic cost. Decision trees, the standard decision modeling technique for non-temporal domains, can only perform CEAs for very small problems. Influence diagrams can model much larger problems, but only when the decisions are totally ordered. To develop a CEA method for problems with unordered or partially ordered decisions, such as finding the optimal sequence of tests for diagnosing a disease. We explain how to model those problems using decision analysis networks (DANs), a new type of probabilistic graphical model, somewhat similar to Bayesian networks and influence diagrams. We present an algorithm for evaluating DANs with two criteria, cost and effectiveness, and perform some experiments to study its computational efficiency. We illustrate the representation framework and the algorithm using a hypothetical example involving two therapies and several tests and then present a DAN for a real-world problem, the mediastinal staging of non-small cell lung cancer. The evaluation of a DAN with two criteria, cost and effectiveness, returns a set of intervals for the willingness to pay, separated by incremental cost-effectiveness ratios (ICERs). The cost, the effectiveness, and the optimal intervention are specific for each interval, i.e., they depend on the willingness to pay. Problems involving several unordered decisions can be modeled with DANs and evaluated in a reasonable amount of time. OpenMarkov, an open-source software tool developed by our research group, can be used to build the models and evaluate them using a graphical user interface.},
  archive      = {J_ARTMED},
  author       = {Francisco Javier Díez and Manuel Luque and Manuel Arias and Jorge Pérez-Martín},
  doi          = {10.1016/j.artmed.2021.102064},
  journal      = {Artificial Intelligence in Medicine},
  month        = {7},
  pages        = {102064},
  shortjournal = {Artif. Intell. Med.},
  title        = {Cost-effectiveness analysis with unordered decisions},
  volume       = {117},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Explaining heterogeneity of individual treatment causal
effects by subgroup discovery: An observational case study in
antibiotics treatment of acute rhino-sinusitis. <em>ARTMED</em>,
<em>116</em>, 102080. (<a
href="https://doi.org/10.1016/j.artmed.2021.102080">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Individuals may respond differently to the same treatment, and there is a need to understand such heterogeneity of causal individual treatment effects. We propose and evaluate a modelling approach to better understand this heterogeneity from observational studies by identifying patient subgroups with a markedly deviating response to treatment. We illustrate this approach in a primary care case-study of antibiotic (AB) prescription on recovery from acute rhino-sinusitis (ARS). Our approach consists of four stages and is applied to a large dataset in primary care dataset of 24,392 patients suspected of suffering from ARS. We first identify pre-treatment variables that either confound the relationship between treatment and outcome or are risk factors of the outcome. Second, based on the pre-treatment variables we create Synthetic Random Forest (SRF) models to compute the potential outcomes and subsequently the causal individual treatment effect (ITE) estimates. Third, we perform subgroup discovery using the ITE estimates as outcomes to identify positive and negative responders. Fourth, we evaluate the predictive performance of the identified subgroups for predicting the outcome in two ways: the likelihood ratio test, and whether the subgroups are selected via the Akaike Information Criterion (AIC) using backward stepwise variable selection. We validate the whole modelling strategy by means of 10-fold-cross-validation. Based on 20 pre-treatment variables, four subgroups (three for positive responders and one for negative responders) were identified. The log likelihood ratio tests showed that the subgroups were significant. Variable selection using the AIC kept two of the four subgroups, one for positive responders and one for negative responders. As for the validation of the whole modelling strategy, all reported measures (the number of pre-treatment variables associated with the outcome, number of subgroups, number of subgroups surviving variable selection and coverage) showed little variation. With the proposed approach, we identified subgroups of positive and negative responders to treatment that markedly deviate from the mean response. The subgroups showed additive predictive value of the outcome. The modelling approach strategy was shown to be robust on this dataset. Our approach was thus able to discover understandable subgroups from observational data that have predictive value and which may be considered by the clinical users to get insight into who responds positively or negatively to a proposed treatment.},
  archive      = {J_ARTMED},
  author       = {W. Qi and A. Abu-Hanna and T.E.M. van Esch and D. de Beurs and Y. Liu and L.E. Flinterman and M.C. Schut},
  doi          = {10.1016/j.artmed.2021.102080},
  journal      = {Artificial Intelligence in Medicine},
  month        = {6},
  pages        = {102080},
  shortjournal = {Artif. Intell. Med.},
  title        = {Explaining heterogeneity of individual treatment causal effects by subgroup discovery: An observational case study in antibiotics treatment of acute rhino-sinusitis},
  volume       = {116},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Bayesian networks in healthcare: What is preventing their
adoption? <em>ARTMED</em>, <em>116</em>, 102079. (<a
href="https://doi.org/10.1016/j.artmed.2021.102079">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There has been much research effort expended toward the use of Bayesian networks (BNs) in medical decision-making. However, because of the gap between developing an accurate BN and demonstrating its clinical usefulness, this has not resulted in any widespread BN adoption in clinical practice. This paper investigates this problem with the aim of finding an explanation and ways to address the problem through a comprehensive literature review of articles describing BNs in healthcare. Based on the literature collection that has been systematically narrowed down from 3810 to 116 most relevant articles, this paper analyses the benefits, barriers and facilitating factors (BBF) for implementing BN-based systems in healthcare using the ITPOSMO-BBF framework. A key finding is that works in the literature rarely consider barriers and even when these were identified they were not connected to facilitating factors. The main finding is that the barriers can be grouped into: (1) data inadequacies; (2) clinicians’ resistance to new technologies; (3) lack of clinical credibility; (4) failure to demonstrate clinical impact; (5) absence of an acceptable predictive performance; and (6) absence of evidence for model’s generalisability. The facilitating factors can be grouped into: (1) data collection improvements; (2) software and technological improvements; (3) having interpretable and easy to use BN-based systems; (4) clinical involvement in the development or review of the model; (5) investigation of model’s clinical impact; (6) internal validation of the model’s performance; and (7) external validation of the model. These groupings form a strong basis for a generic framework that could be used for formulating strategies for ensuring BN-based clinical decision-support system adoption in frontline care settings. The output of this review is expected to enhance the dialogue among researchers by providing a deeper understanding for the neglected issue of BN adoption in practice and promoting efforts for implementing BN-based systems.},
  archive      = {J_ARTMED},
  author       = {Evangelia Kyrimi and Kudakwashe Dube and Norman Fenton and Ali Fahmi and Mariana Raniere Neves and William Marsh and Scott McLachlan},
  doi          = {10.1016/j.artmed.2021.102079},
  journal      = {Artificial Intelligence in Medicine},
  month        = {6},
  pages        = {102079},
  shortjournal = {Artif. Intell. Med.},
  title        = {Bayesian networks in healthcare: What is preventing their adoption?},
  volume       = {116},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Transfer learning in medical image segmentation: New
insights from analysis of the dynamics of model parameters and learned
representations. <em>ARTMED</em>, <em>116</em>, 102078. (<a
href="https://doi.org/10.1016/j.artmed.2021.102078">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a critical assessment of the role of transfer learning in training fully convolutional networks (FCNs) for medical image segmentation. We first show that although transfer learning reduces the training time on the target task, improvements in segmentation accuracy are highly task/data-dependent. Large improvements are observed only when the segmentation task is more challenging and the target training data is smaller. We shed light on these observations by investigating the impact of transfer learning on the evolution of model parameters and learned representations. We observe that convolutional filters change little during training and still look random at convergence. We further show that quite accurate FCNs can be built by freezing the encoder section of the network at random values and only training the decoder section. At least for medical image segmentation, this finding challenges the common belief that the encoder section needs to learn data/task-specific representations. We examine the evolution of FCN representations to gain a deeper insight into the effects of transfer learning on the training dynamics. Our analysis shows that although FCNs trained via transfer learning learn different representations than FCNs trained with random initialization, the variability among FCNs trained via transfer learning can be as high as that among FCNs trained with random initialization. Moreover, feature reuse is not restricted to the early encoder layers; rather, it can be more significant in deeper layers. These findings offer new insights and suggest alternative ways of training FCNs for medical image segmentation.},
  archive      = {J_ARTMED},
  author       = {Davood Karimi and Simon K. Warfield and Ali Gholipour},
  doi          = {10.1016/j.artmed.2021.102078},
  journal      = {Artificial Intelligence in Medicine},
  month        = {6},
  pages        = {102078},
  shortjournal = {Artif. Intell. Med.},
  title        = {Transfer learning in medical image segmentation: New insights from analysis of the dynamics of model parameters and learned representations},
  volume       = {116},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Fenchel duality of cox partial likelihood with an
application in survival kernel learning. <em>ARTMED</em>, <em>116</em>,
102077. (<a href="https://doi.org/10.1016/j.artmed.2021.102077">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Cox proportional hazard model is one of the most widely used methods in modeling time-to-event data in the health sciences. Due to the simplicity of the Cox partial likelihood function, many machine learning algorithms use it for survival data. However, due to the nature of censored data, the optimization problem becomes intractable when more complicated regularization is employed, which is necessary when dealing with high dimensional omic data. In this paper, we show that a convex conjugate function of the Cox loss function based on Fenchel duality exists, and provide an alternative framework to optimization based on the primal form. Furthermore, the dual form suggests an efficient algorithm for solving the kernel learning problem with censored survival outcomes. We illustrate performance and properties of the derived duality form of Cox partial likelihood loss in multiple kernel learning problems with simulated and the Skin Cutaneous Melanoma TCGA datasets.},
  archive      = {J_ARTMED},
  author       = {Christopher M. Wilson and Kaiqiao Li and Qiang Sun and Pei Fen Kuan and Xuefeng Wang},
  doi          = {10.1016/j.artmed.2021.102077},
  journal      = {Artificial Intelligence in Medicine},
  month        = {6},
  pages        = {102077},
  shortjournal = {Artif. Intell. Med.},
  title        = {Fenchel duality of cox partial likelihood with an application in survival kernel learning},
  volume       = {116},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Evaluating diagnostic content of AI-generated radiology
reports of chest x-rays. <em>ARTMED</em>, <em>116</em>, 102075. (<a
href="https://doi.org/10.1016/j.artmed.2021.102075">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Radiology reports are of core importance for the communication between the radiologist and clinician. A computer-aided radiology report system can assist radiologists in this task and reduce variation between reports thus facilitating communication with the medical doctor or clinician. Producing a well structured, clear, and clinically well-focused radiology report is essential for high-quality patient diagnosis and care. Despite recent advances in deep learning for image caption generation, this task remains highly challenging in a medical setting. Research has mainly focused on the design of tailored machine learning methods for this task, while little attention has been devoted to the development of evaluation metrics to assess the quality of AI-generated documents. Conventional quality metrics for natural language processing methods like the popular BLEU score, provide little information about the quality of the diagnostic content of AI-generated radiology reports. In particular, because radiology reports often use standardized sentences, BLEU scores of generated reports can be high while they lack diagnostically important information. We investigate this problem and propose a new measure that quantifies the diagnostic content of AI-generated radiology reports. In addition, we exploit the standardization of reports by generating a sequence of sentences. That is, instead of using a dictionary of words, as current image captioning methods do, we use a dictionary of sentences. The assumption underlying this choice is that radiologists use a well-focused vocabulary of ‘standard’ sentences, which should suffice for composing most reports. As a by-product, a significant training speed-up is achieved compared to models trained on a dictionary of words. Overall, results of our investigation indicate that standard validation metrics for AI-generated documents are weakly correlated with the diagnostic content of the reports. Therefore, these measures should be not used as only validation metrics, and measures evaluating diagnostic content should be preferred in such a medical context.},
  archive      = {J_ARTMED},
  author       = {Zaheer Babar and Twan van Laarhoven and Fabio Massimo Zanzotto and Elena Marchiori},
  doi          = {10.1016/j.artmed.2021.102075},
  journal      = {Artificial Intelligence in Medicine},
  month        = {6},
  pages        = {102075},
  shortjournal = {Artif. Intell. Med.},
  title        = {Evaluating diagnostic content of AI-generated radiology reports of chest X-rays},
  volume       = {116},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Uncertainty-aware temporal self-learning (UATS):
Semi-supervised learning for segmentation of prostate zones and beyond.
<em>ARTMED</em>, <em>116</em>, 102073. (<a
href="https://doi.org/10.1016/j.artmed.2021.102073">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Various convolutional neural network (CNN) based concepts have been introduced for the prostate&#39;s automatic segmentation and its coarse subdivision into transition zone (TZ) and peripheral zone (PZ). However, when targeting a fine-grained segmentation of TZ, PZ, distal prostatic urethra (DPU) and the anterior fibromuscular stroma (AFS), the task becomes more challenging and has not yet been solved at the level of human performance. One reason might be the insufficient amount of labeled data for supervised training. Therefore, we propose to apply a semi-supervised learning (SSL) technique named uncertainty-aware temporal self-learning (UATS) to overcome the expensive and time-consuming manual ground truth labeling. We combine the SSL techniques temporal ensembling and uncertainty-guided self-learning to benefit from unlabeled images, which are often readily available. Our method significantly outperforms the supervised baseline and obtained a Dice coefficient (DC) of up to 78.9%, 87.3%, 75.3%, 50.6% for TZ, PZ, DPU and AFS, respectively. The obtained results are in the range of human inter-rater performance for all structures. Moreover, we investigate the method&#39;s robustness against noise and demonstrate the generalization capability for varying ratios of labeled data and on other challenging tasks, namely the hippocampus and skin lesion segmentation. UATS achieved superiority segmentation quality compared to the supervised baseline, particularly for minimal amounts of labeled data.},
  archive      = {J_ARTMED},
  author       = {Anneke Meyer and Suhita Ghosh and Daniel Schindele and Martin Schostak and Sebastian Stober and Christian Hansen and Marko Rak},
  doi          = {10.1016/j.artmed.2021.102073},
  journal      = {Artificial Intelligence in Medicine},
  month        = {6},
  pages        = {102073},
  shortjournal = {Artif. Intell. Med.},
  title        = {Uncertainty-aware temporal self-learning (UATS): Semi-supervised learning for segmentation of prostate zones and beyond},
  volume       = {116},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Coronary artery segmentation from intravascular optical
coherence tomography using deep capsules. <em>ARTMED</em>, <em>116</em>,
102072. (<a href="https://doi.org/10.1016/j.artmed.2021.102072">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The segmentation and analysis of coronary arteries from intravascular optical coherence tomography (IVOCT) is an important aspect of diagnosing and managing coronary artery disease. Current image processing methods are hindered by the time needed to generate expert-labelled datasets and the potential for bias during the analysis. Therefore, automated, robust, unbiased and timely geometry extraction from IVOCT, using image processing, would be beneficial to clinicians. With clinical application in mind, we aim to develop a model with a small memory footprint that is fast at inference time without sacrificing segmentation quality. Using a large IVOCT dataset of 12,011 expert-labelled images from 22 patients, we construct a new deep learning method based on capsules which automatically produces lumen segmentations. Our dataset contains images with both blood and light artefacts (22.8 %), as well as metallic (23.1 %) and bioresorbable stents (2.5 %). We split the dataset into a training (70 %), validation (20 %) and test (10 %) set and rigorously investigate design variations with respect to upsampling regimes and input selection. We show that our developments lead to a model, DeepCap, that is on par with state-of-the-art machine learning methods in terms of segmentation quality and robustness, while using as little as 12 % of the parameters. This enables DeepCap to have per image inference times up to 70 % faster on GPU and up to 95 % faster on CPU compared to other state-of-the-art models. DeepCap is a robust automated segmentation tool that can aid clinicians to extract unbiased geometrical data from IVOCT.},
  archive      = {J_ARTMED},
  author       = {Arjun Balaji and Lachlan J. Kelsey and Kamran Majeed and Carl J. Schultz and Barry J. Doyle},
  doi          = {10.1016/j.artmed.2021.102072},
  journal      = {Artificial Intelligence in Medicine},
  month        = {6},
  pages        = {102072},
  shortjournal = {Artif. Intell. Med.},
  title        = {Coronary artery segmentation from intravascular optical coherence tomography using deep capsules},
  volume       = {116},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A hybrid deep learning approach for gland segmentation in
prostate histopathological images. <em>ARTMED</em>, <em>115</em>,
102076. (<a href="https://doi.org/10.1016/j.artmed.2021.102076">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In digital pathology, the morphology and architecture of prostate glands have been routinely adopted by pathologists to evaluate the presence of cancer tissue. The manual annotations are operator-dependent, error-prone and time-consuming. The automated segmentation of prostate glands can be very challenging too due to large appearance variation and serious degeneration of these histological structures. A new image segmentation method, called RINGS (Rapid IdentificatioN of Glandural Structures), is presented to segment prostate glands in histopathological images. We designed a novel glands segmentation strategy using a multi-channel algorithm that exploits and fuses both traditional and deep learning techniques. Specifically, the proposed approach employs a hybrid segmentation strategy based on stroma detection to accurately detect and delineate the prostate glands contours. Automated results are compared with manual annotations and seven state-of-the-art techniques designed for glands segmentation. Being based on stroma segmentation, no performance degradation is observed when segmenting healthy or pathological structures. Our method is able to delineate the prostate gland of the unknown histopathological image with a dice score of 90.16 % and outperforms all the compared state-of-the-art methods. To the best of our knowledge, the RINGS algorithm is the first fully automated method capable of maintaining a high sensitivity even in the presence of severe glandular degeneration. The proposed method will help to detect the prostate glands accurately and assist the pathologists to make accurate diagnosis and treatment. The developed model can be used to support prostate cancer diagnosis in polyclinics and community care centres.},
  archive      = {J_ARTMED},
  author       = {Massimo Salvi and Martino Bosco and Luca Molinaro and Alessandro Gambella and Mauro Papotti and U. Rajendra Acharya and Filippo Molinari},
  doi          = {10.1016/j.artmed.2021.102076},
  journal      = {Artificial Intelligence in Medicine},
  month        = {5},
  pages        = {102076},
  shortjournal = {Artif. Intell. Med.},
  title        = {A hybrid deep learning approach for gland segmentation in prostate histopathological images},
  volume       = {115},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A data science approach to drug safety: Semantic and visual
mining of adverse drug events from clinical trials of pain treatments.
<em>ARTMED</em>, <em>115</em>, 102074. (<a
href="https://doi.org/10.1016/j.artmed.2021.102074">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Clinical trials are the basis of Evidence-Based Medicine. Trial results are reviewed by experts and consensus panels for producing meta-analyses and clinical practice guidelines. However, reviewing these results is a long and tedious task, hence the meta-analyses and guidelines are not updated each time a new trial is published. Moreover, the independence of experts may be difficult to appraise. On the contrary, in many other domains, including medical risk analysis, the advent of data science, big data and visual analytics allowed moving from expert -based to fact -based knowledge. Since 12 years, many trial results are publicly available online in trial registries. Nevertheless, data science methods have not yet been applied widely to trial data. In this paper, we present a platform for analyzing the safety events reported during clinical trials and published in trial registries. This platform is based on an ontological model including 582 trials on pain treatments, and uses semantic web technologies for querying this dataset at various levels of granularity. It also relies on a 26-dimensional flower glyph for the visualization of the Adverse Drug Events (ADE) rates in 13 categories and 2 levels of seriousness. We illustrate the interest of this platform through several use cases and we were able to find back conclusions that were initially found during meta-analyses. The platform was presented to four experts in drug safety, and is publicly available online, with the ontology of pain treatment ADE.},
  archive      = {J_ARTMED},
  author       = {Jean-Baptiste Lamy},
  doi          = {10.1016/j.artmed.2021.102074},
  journal      = {Artificial Intelligence in Medicine},
  month        = {5},
  pages        = {102074},
  shortjournal = {Artif. Intell. Med.},
  title        = {A data science approach to drug safety: Semantic and visual mining of adverse drug events from clinical trials of pain treatments},
  volume       = {115},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). EAR-UNet: A deep learning-based approach for segmentation of
tympanic membranes from otoscopic images. <em>ARTMED</em>, <em>115</em>,
102065. (<a href="https://doi.org/10.1016/j.artmed.2021.102065">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a method for automatic segmentation of tympanic membranes (TMs) from video-otoscopic images based on deep fully convolutional neural network. Built upon the UNet architecture, the proposed EAR scheme is based on three main paradigms: EfficientNet for the encoder, Attention gate for the skip connection path, and Residual blocks for the decoder. The paper also introduces a new loss function term for the neural networks to perform segmentation tasks. Particularly, we propose to integrate EfficientNet-B4 into the encoder part of the UNet. In addition, the decoder part of the proposed network is constructed based on residual blocks from ResNet architecture. By this way, the proposed approach could take advantages of the EfficientNet and ResNet architectures such as preserving efficient reception field size for the model and avoiding overfitting problem. In addition, in the skip connection path, we employ the attention gate that can handle the varieties in shapes and sizes of interested objects, which are common issues in TM regions. Moreover, for network training, we proposed a new loss function term based on the shape distance between predicted and ground truth masks, and exploited the stochastic weight averaging to avoid being trapped in local minima. We evaluate the proposed approach on a TM dataset which includes 1012 otoscopic images from patients diagnosed with and without otitis media. Experimental results show that the proposed approach achieves high segmentation performance with the average Dice similarity coefficient of 0.929, without any pre- or post-processing steps, that outperforms other state-of-the-art methods.},
  archive      = {J_ARTMED},
  author       = {Van-Truong Pham and Thi-Thao Tran and Pa-Chun Wang and Po-Yu Chen and Men-Tzung Lo},
  doi          = {10.1016/j.artmed.2021.102065},
  journal      = {Artificial Intelligence in Medicine},
  month        = {5},
  pages        = {102065},
  shortjournal = {Artif. Intell. Med.},
  title        = {EAR-UNet: A deep learning-based approach for segmentation of tympanic membranes from otoscopic images},
  volume       = {115},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Automated emotion classification in the early stages of
cortical processing: An MEG study. <em>ARTMED</em>, <em>115</em>,
102063. (<a href="https://doi.org/10.1016/j.artmed.2021.102063">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Here we aimed to automatically classify human emotion earlier than is typically attempted. There is increasing evidence that the human brain differentiates emotional categories within 100–300 ms after stimulus onset. Therefore, here we evaluate the possibility of automatically classifying human emotions within the first 300 ms after the stimulus and identify the time-interval of the highest classification performance. To address this issue, MEG signals of 17 healthy volunteers were recorded in response to three different picture stimuli (pleasant, unpleasant, and neutral pictures). Six Linear Discriminant Analysis (LDA) classifiers were used based on two binary comparisons (pleasant versus neutral and unpleasant versus neutral) and three different time-intervals (100–150 ms, 150–200 ms, and 200–300 ms post-stimulus). The selection of the feature subsets was performed by Genetic Algorithm and LDA. We demonstrated significant classification performances in both comparisons. The best classification performance was achieved with a median AUC of 0.83 (95 %- CI [0.71; 0.87]) classifying brain responses evoked by unpleasant and neutral stimuli within 100–150 ms, which is at least 850 ms earlier than attempted by other studies. Our results indicate that using the proposed algorithm, brain emotional responses can be significantly classified at very early stages of cortical processing (within 300 ms). Moreover, our results suggest that emotional processing in the human brain occurs within the first 100–150 ms.},
  archive      = {J_ARTMED},
  author       = {Mina Kheirkhah and Stefan Brodoehl and Lutz Leistritz and Theresa Götz and Philipp Baumbach and Ralph Huonker and Otto W. Witte and Carsten M. Klingner},
  doi          = {10.1016/j.artmed.2021.102063},
  journal      = {Artificial Intelligence in Medicine},
  month        = {5},
  pages        = {102063},
  shortjournal = {Artif. Intell. Med.},
  title        = {Automated emotion classification in the early stages of cortical processing: An MEG study},
  volume       = {115},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A reinforcement learning based algorithm for personalization
of digital, just-in-time, adaptive interventions. <em>ARTMED</em>,
<em>115</em>, 102062. (<a
href="https://doi.org/10.1016/j.artmed.2021.102062">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Suboptimal health related behaviors and habits; and resulting chronic diseases are responsible for majority of deaths globally. Studies show that providing personalized support to patients yield improved results by preventing and/or timely treatment of these problems. Digital, just-in-time and adaptive interventions are mobile phone-based notifications that are being utilized to support people wherever and whenever necessary in coping with their health problems. In this research, we propose a reinforcement learning-based mechanism to personalize interventions in terms of timing, frequency and preferred type(s) . We simultaneously employ two reinforcement learning models, namely intervention-selection and opportune-moment-identification ; capturing and exploiting changes in people&#39;s long-term and momentary contexts respectively. While the intervention-selection model adapts the intervention delivery with respect to type and frequency, the opportune-moment-identification model tries to find the most opportune moments to deliver interventions throughout a day. We propose two accelerator techniques over the standard reinforcement learning algorithms to boost learning performance. First, we propose a customized version of eligibility traces for rewarding past actions throughout an agent&#39;s trajectory. Second, we utilize the transfer learning method to reuse knowledge across multiple learning environments. We validate the proposed approach in a simulated experiment where we simulate four personas differing in their daily activities, preferences on specific intervention types and attitudes towards the targeted behavior. Our experiments show that the proposed approach yields better results compared to the standard reinforcement learning algorithms and successfully capture the simulated variations associated with the personas.},
  archive      = {J_ARTMED},
  author       = {Suat Gönül and Tuncay Namlı and Ahmet Coşar and İsmail Hakkı Toroslu},
  doi          = {10.1016/j.artmed.2021.102062},
  journal      = {Artificial Intelligence in Medicine},
  month        = {5},
  pages        = {102062},
  shortjournal = {Artif. Intell. Med.},
  title        = {A reinforcement learning based algorithm for personalization of digital, just-in-time, adaptive interventions},
  volume       = {115},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A machine learning perspective on the emotional content of
parkinsonian speech. <em>ARTMED</em>, <em>115</em>, 102061. (<a
href="https://doi.org/10.1016/j.artmed.2021.102061">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Patients with Parkinson&#39;s disease (PD) have distinctive voice patterns, often perceived as expressing sad emotion. While this characteristic of Parkinsonian speech has been supported through the perspective of listeners, where both PD and healthy control (HC) subjects repeat the same speaking tasks, it has never been explored through a machine learning modelling approach. Our work provides an objective evaluation of this characteristic of the PD speech, by building a transfer learning system to assess how the PD pathology affects the sadness perception. To do so we introduce a Mixture-of-Experts (MoE) architecture for speech emotion recognition designed to be transferable across datasets. Firstly, by relying on publicly available emotional speech corpora, we train the MoE model and then we use it to quantify perceived sadness in never seen before PD and matched HC speech recordings. To build our models (experts), we extracted spectral features of the voicing parts of speech and we trained a gradient boosting decision trees model in each corpus to predict happiness vs. sadness. MoE predictions are created by weighting each expert&#39;s prediction according to the distance between the new sample and the expert-specific training samples. The MoE approach systematically infers more negative emotional characteristics in PD speech than in HC. Crucially, these judgments are related to the disease severity and the severity of speech impairment in the PD patients: the more impairment, the more likely the speech is to be judged as sad. Our findings pave the way towards a better understanding of the characteristics of PD speech and show how publicly available datasets can be used to train models that provide interesting insights on clinical data.},
  archive      = {J_ARTMED},
  author       = {Konstantinos Sechidis and Riccardo Fusaroli and Juan Rafael Orozco-Arroyave and Detlef Wolf and Yan-Ping Zhang},
  doi          = {10.1016/j.artmed.2021.102061},
  journal      = {Artificial Intelligence in Medicine},
  month        = {5},
  pages        = {102061},
  shortjournal = {Artif. Intell. Med.},
  title        = {A machine learning perspective on the emotional content of parkinsonian speech},
  volume       = {115},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Machine learning in oral squamous cell carcinoma: Current
status, clinical concerns and prospects for future—a systematic review.
<em>ARTMED</em>, <em>115</em>, 102060. (<a
href="https://doi.org/10.1016/j.artmed.2021.102060">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Oral cancer can show heterogenous patterns of behavior. For proper and effective management of oral cancer, early diagnosis and accurate prediction of prognosis are important. To achieve this, artificial intelligence (AI) or its subfield, machine learning, has been touted for its potential to revolutionize cancer management through improved diagnostic precision and prediction of outcomes. Yet, to date, it has made only few contributions to actual medical practice or patient care. This study provides a systematic review of diagnostic and prognostic application of machine learning in oral squamous cell carcinoma (OSCC) and also highlights some of the limitations and concerns of clinicians towards the implementation of machine learning-based models for daily clinical practice. We searched OvidMedline, PubMed, Scopus, Web of Science, and Institute of Electrical and Electronics Engineers (IEEE) databases from inception until February 2020 for articles that used machine learning for diagnostic or prognostic purposes of OSCC. Only original studies that examined the application of machine learning models for prognostic and/or diagnostic purposes were considered. Independent extraction of articles was done by two researchers (A.R. &amp; O.Y) using predefine study selection criteria. We used the Preferred Reporting Items for Systematic Review and Meta-Analysis (PRISMA) in the searching and screening processes. We also used Prediction model Risk of Bias Assessment Tool (PROBAST) for assessing the risk of bias (ROB) and quality of included studies. A total of 41 studies were published to have used machine learning to aid in the diagnosis/or prognosis of OSCC. The majority of these studies used the support vector machine (SVM) and artificial neural network (ANN) algorithms as machine learning techniques. Their specificity ranged from 0.57 to 1.00, sensitivity from 0.70 to 1.00, and accuracy from 63.4 % to 100.0 % in these studies. The main limitations and concerns can be grouped as either the challenges inherent to the science of machine learning or relating to the clinical implementations. Machine learning models have been reported to show promising performances for diagnostic and prognostic analyses in studies of oral cancer. These models should be developed to further enhance explainability, interpretability, and externally validated for generalizability in order to be safely integrated into daily clinical practices. Also, regulatory frameworks for the adoption of these models in clinical practices are necessary.},
  archive      = {J_ARTMED},
  author       = {Rasheed Omobolaji Alabi and Omar Youssef and Matti Pirinen and Mohammed Elmusrati and Antti A. Mäkitie and Ilmo Leivo and Alhadi Almangush},
  doi          = {10.1016/j.artmed.2021.102060},
  journal      = {Artificial Intelligence in Medicine},
  month        = {5},
  pages        = {102060},
  shortjournal = {Artif. Intell. Med.},
  title        = {Machine learning in oral squamous cell carcinoma: Current status, clinical concerns and prospects for future—A systematic review},
  volume       = {115},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). CEFEs: A CNN explainable framework for ECG signals.
<em>ARTMED</em>, <em>115</em>, 102059. (<a
href="https://doi.org/10.1016/j.artmed.2021.102059">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the healthcare domain, trust, confidence, and functional understanding are critical for decision support systems, therefore, presenting challenges in the prevalent use of black-box deep learning (DL) models. With recent advances in deep learning methods for classification tasks, there is an increased use of deep learning in healthcare decision support systems, such as detection and classification of abnormal Electrocardiogram (ECG) signals. Domain experts seek to understand the functional mechanism of black-box models with an emphasis on understanding how these models arrive at specific classification of patient medical data. In this paper, we focus on ECG data as the healthcare data signal to be analyzed. Since ECG is a one-dimensional time-series data, we target 1D-CNN (Convolutional Neural Networks) as the candidate DL model. Majority of existing interpretation and explanations research has been on 2D-CNN models in non-medical domain leaving a gap in terms of explanation of CNN models used on medical time-series data. Hence, we propose a modular framework, CNN Explanations Framework for ECG Signals (CEFEs), for interpretable explanations. Each module of CEFEs provides users with the functional understanding of the underlying CNN models in terms of data descriptive statistics, feature visualization, feature detection, and feature mapping. The modules evaluate a model’s capacity while inherently accounting for correlation between learned features and raw signals which translates to correlation between model’s capacity to classify and it’s learned features. Explainable models such as CEFEs could be evaluated in different ways: training one deep learning architecture on different volumes/amounts of the same dataset, training different architectures on the same data set or a combination of different CNN architectures and datasets. In this paper, we choose to evaluate CEFEs extensively by training on different volumes of datasets with the same CNN architecture. The CEFEs’ interpretations, in terms of quantifiable metrics, feature visualization, provide explanation as to the quality of the deep learning model where traditional performance metrics (such as precision, recall, accuracy, etc.) do not suffice.},
  archive      = {J_ARTMED},
  author       = {Barbara Mukami Maweu and Sagnik Dakshit and Rittika Shamsuddin and Balakrishnan Prabhakaran},
  doi          = {10.1016/j.artmed.2021.102059},
  journal      = {Artificial Intelligence in Medicine},
  month        = {5},
  pages        = {102059},
  shortjournal = {Artif. Intell. Med.},
  title        = {CEFEs: A CNN explainable framework for ECG signals},
  volume       = {115},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Preface: AIME 2019. <em>ARTMED</em>, <em>115</em>, 102058.
(<a href="https://doi.org/10.1016/j.artmed.2021.102058">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_ARTMED},
  author       = {David Riaño and Szymon Wilk and Annette ten Teije},
  doi          = {10.1016/j.artmed.2021.102058},
  journal      = {Artificial Intelligence in Medicine},
  month        = {5},
  pages        = {102058},
  shortjournal = {Artif. Intell. Med.},
  title        = {Preface: AIME 2019},
  volume       = {115},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A novel approach for computerized quantitative image
analysis of proximal femur bone shape deformities based on the hip joint
symmetry. <em>ARTMED</em>, <em>115</em>, 102057. (<a
href="https://doi.org/10.1016/j.artmed.2021.102057">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a result of most of the bone disorders seen in hip joints, shape deformities occur in the structural form of the hip joint components. Image-based quantitative analysis and assessment of these deformities in bone shapes are very important for the evaluation, treatment, and prognosis of the various hip joint bone disorders. In this article, a novel approach for the image-based computerized quantitative analysis of proximal femur shape deformities is presented. In the proposed approach, shape deformities of the pathological proximal femurs were quantified over the contralateral healthy proximal femur shape structure of the same patient in 2D by taking the hip joint symmetry property of human anatomy into consideration. It is based on the idea that if the right and left proximal femurs in bilateral hip joints are highly symmetrical and also if one of the proximal femurs is healthy and the contralateral one is pathological, the non-overlapping bone shape regions can represent the deformities in pathological proximal femurs when both proximal femurs are registered to overlap each other. In the methodological process of the proposed study, a set of image preprocessing operations was primarily performed on the raw magnetic resonance imaging (MRI) data. Then, the segmented proximal femurs in bilateral hip joint images were automatically aligned with the Iterative Closest Point (ICP) rigid registration method. Following the registration, a set of image postprocessing operations was performed on the images of proximal femurs aligned. In the quantification phase, the bone shape deformities in pathological proximal femurs were quantified simply in terms of the mismatching area in 2D by measuring a shape variation index representing the total bone shape deformity ratio. To evaluate the proposed quantitative shape analysis approach, bilateral hip joints in a total of 13 coronal MRI sections of 13 patients with Legg-Calve-Perthes disease (LCPD) were used. Experimental studies have shown that the proposed approach has quite promising results in the quantitative representation of the pathological proximal femur shape deformities. Furthermore, consistent results have been observed for the Waldenström classification stages of the disease. The shape deformity ratios in pathological proximal femurs were quantified as 9.44% ( ± ± 1.40), 18.38% ( ± ± 6.30), 24.73% ( ± ± 12.42), and 27.66% ( ± ± 10.41), respectively for the Initial, Fragmentation, Reossification, and Remodelling stages of LCPD with the quantification error rates of 0.29% ( ± ± 0.16), 0.58% ( ± ± 0.71), 1.12% ( ± ± 0.82), and 0.80% ( ± ± 0.98). Additionally, a mean error rate of 0.65% ( ± ± 0.68) was observed for the quantified shape deformity ratios of all samples.},
  archive      = {J_ARTMED},
  author       = {Abbas Memiş and Songül Varlı and Fuat Bilgili},
  doi          = {10.1016/j.artmed.2021.102057},
  journal      = {Artificial Intelligence in Medicine},
  month        = {5},
  pages        = {102057},
  shortjournal = {Artif. Intell. Med.},
  title        = {A novel approach for computerized quantitative image analysis of proximal femur bone shape deformities based on the hip joint symmetry},
  volume       = {115},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Probabilistic domain-knowledge modeling of disorder
pathogenesis for dynamics forecasting of acute onset. <em>ARTMED</em>,
<em>115</em>, 102056. (<a
href="https://doi.org/10.1016/j.artmed.2021.102056">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Disease pathogenesis, a type of domain knowledge about biological mechanisms leading to diseases, has not been adequately encoded in machine-learning-based medical diagnostic models because of the inter-patient variabilities and complex dependencies of the underlying pathogenetic mechanisms. We propose 1) a novel pathogenesis probabilistic graphical model (PPGM) to quantify the dynamics underpinning patient-specific data and pathogenetic domain knowledge, 2) a Bayesian-based inference paradigm to answer the medical queries and forecast acute onsets. The PPGM model consists of two components: a Bayesian network of patient attributes and a temporal model of pathogenetic mechanisms. The model structure was reconstructed from expert knowledge elicitation, and its parameters were estimated using Variational Expectation-Maximization algorithms. We benchmarked our model with two well-established hidden Markov models (HMMs) – Input-output HMM (IO-HMM) and Switching Auto-Regressive HMM (SAR-HMM) – to evaluate the computational costs, forecasting performance, and execution time. Two case studies on Obstructive Sleep Apnea (OSA) and Paroxysmal Atrial Fibrillation (PAF) were used to validate the model. While the performance of the parameter learning step was equivalent to those of IO-HMM and SAR-HMM models, our model forecasting ability was outperforming those two models. The merits of the PPGM model are its representation capability to capture the dynamics of pathogenesis and perform medical inferences and its interpretability for physicians. The model has been used to perform medical queries and forecast the acute onset of OSA and PAF. Additional applications of the model include prognostic healthcare and preventive personalized treatments.},
  archive      = {J_ARTMED},
  author       = {Phat K. Huynh and Arveity Setty and Hao Phan and Trung Q. Le},
  doi          = {10.1016/j.artmed.2021.102056},
  journal      = {Artificial Intelligence in Medicine},
  month        = {5},
  pages        = {102056},
  shortjournal = {Artif. Intell. Med.},
  title        = {Probabilistic domain-knowledge modeling of disorder pathogenesis for dynamics forecasting of acute onset},
  volume       = {115},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Ethical evaluation of artificial intelligence applications
in radiotherapy using the four topics approach. <em>ARTMED</em>,
<em>115</em>, 102055. (<a
href="https://doi.org/10.1016/j.artmed.2021.102055">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial Intelligence is the capability of a machine to imitate intelligent human behavior. An important impact can be expected from Artificial Intelligence throughout the workflow of radiotherapy (such as automated organ segmentation, treatment planning, prediction of outcome and quality assurance). However, ethical concerns regarding the binding agreement between the patient and the physician have followed the introduction of artificial intelligence. Through the recording of personal and social moral values in addition to the usual demographics and the implementation of these as distinctive inputs to matching algorithms, ethical concerns such as consistency, applicability and relevance can be solved. In the meantime, physicians’ awareness of the ethical dimension in their decision-making should be challenged, so that they prioritize treating their patients and not diseases, remain vigilant to preserve patient safety, avoid unintended harm and establish institutional policies on these issues.},
  archive      = {J_ARTMED},
  author       = {Eda Yirmibesoglu Erkal and Aslıhan Akpınar and Haldun Şükrü Erkal},
  doi          = {10.1016/j.artmed.2021.102055},
  journal      = {Artificial Intelligence in Medicine},
  month        = {5},
  pages        = {102055},
  shortjournal = {Artif. Intell. Med.},
  title        = {Ethical evaluation of artificial intelligence applications in radiotherapy using the four topics approach},
  volume       = {115},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Survival in the intensive care unit: A prognosis model based
on bayesian classifiers. <em>ARTMED</em>, <em>115</em>, 102054. (<a
href="https://doi.org/10.1016/j.artmed.2021.102054">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We develop a predictive prognosis model to support medical experts in their clinical decision-making process in Intensive Care Units (ICUs) (a) to enhance early mortality prediction, (b) to make more efficient medical decisions about patients at higher risk, and (c) to evaluate the effectiveness of new treatments or detect changes in clinical practice. It is a machine learning hierarchical model based on Bayesian classifiers built from some recorded features of a real-world ICU cohort, to bring about the assessment of the risk of mortality, also predicting destination at ICU discharge if the patient survives, or the cause of death otherwise, constructed as an ensemble of five base Bayesian classifiers by using the average ensemble criterion with weights, and we name it the Ensemble Weighted Average (EWA). We compare EWA against other state-of-the-art machine learning predictive models. Our results show that EWA outperforms its competitors, presenting in addition the advantage over the ensemble using the majority vote criterion of allowing to associate a confidence level to the provided predictions. We also prove the convenience of locally recalibrate from data the standard model used to predict the mortality risk based on the APACHE II score, although as a predictive model it is weaker than the other.},
  archive      = {J_ARTMED},
  author       = {Rosario Delgado and J. David Núñez-González and J. Carlos Yébenes and Ángel Lavado},
  doi          = {10.1016/j.artmed.2021.102054},
  journal      = {Artificial Intelligence in Medicine},
  month        = {5},
  pages        = {102054},
  shortjournal = {Artif. Intell. Med.},
  title        = {Survival in the intensive care unit: A prognosis model based on bayesian classifiers},
  volume       = {115},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). NewsMeSH: A new classifier designed to annotate health news
with MeSH headings. <em>ARTMED</em>, <em>114</em>, 102053. (<a
href="https://doi.org/10.1016/j.artmed.2021.102053">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the age of big data, the amount of scientific information available online dwarfs the ability of current tools to support researchers in locating and securing access to the necessary materials. Well-structured open data and the smart systems that make the appropriate use of it are invaluable and can help health researchers and professionals to find the appropriate information by, e.g., configuring the monitoring of information or refining a specific query on a disease. We present an automated text classifier approach based on the MEDLINE/MeSH thesaurus, trained on the manual annotation of more than 26 million expert-annotated scientific abstracts. The classifier was developed tailor-fit to the public health and health research domain experts, in the light of their specific challenges and needs. We have applied the proposed methodology on three specific health domains: the Coronavirus, Mental Health and Diabetes, considering the pertinence of the first, and the known relations with the other two health topics. A classifier is trained on the MEDLINE dataset that can automatically annotate text, such as scientific articles, news articles or medical reports with relevant concepts from the MeSH thesaurus. The proposed text classifier shows promising results in the evaluation of health-related news. The application of the developed classifier enables the exploration of news and extraction of health-related insights, based on the MeSH thesaurus, through a similar workflow as in the usage of PubMed, with which most health researchers are familiar.},
  archive      = {J_ARTMED},
  author       = {Joao Pita Costa and Luis Rei and Luka Stopar and Flavio Fuart and Marko Grobelnik and Dunja Mladenić and Inna Novalija and Anthony Staines and Jarmo Pääkkönen and Jenni Konttila and Joseba Bidaurrazaga and Oihana Belar and Christine Henderson and Gorka Epelde and Mónica Arrúe Gabaráin and Paul Carlin and Jonathan Wallace},
  doi          = {10.1016/j.artmed.2021.102053},
  journal      = {Artificial Intelligence in Medicine},
  month        = {4},
  pages        = {102053},
  shortjournal = {Artif. Intell. Med.},
  title        = {NewsMeSH: A new classifier designed to annotate health news with MeSH headings},
  volume       = {114},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A novel method for clinical risk prediction with low-quality
data. <em>ARTMED</em>, <em>114</em>, 102052. (<a
href="https://doi.org/10.1016/j.artmed.2021.102052">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In real-world data, predictive models for clinical risks (such as adverse drug reactions, hospital readmission, and chronic disease onset) are constantly struggling with low-quality issues, namely redundant and highly correlated features, extreme category imbalances, and most importantly, a large number of missing values. In most existing work, each patient is represented as a value vector with the fixed-length from some feature space, and missing values are forced to be imputed, which introduces much noise for prediction if the data set is highly incomplete. Besides, other challenges are either remaining unresolved or only partially solved when modeling, but without a systematic approach. In this paper, we propose a novel framework to address these low-quality problems, that we first treat patients as bags with the various number of feature-value pairs, called instances, and map them to an embedding space through our proposed feature embedding method to learn from it directly. In this way, predictive models can avoid the negative impact of missing data naturally. A novel multi-instance neural network is then connected, using two computational modules to deal with the problems of correlated and redundant features: multi-head attention and attention-based multi-instance pooling. They are capable of capturing the instance correlations and locating valuable information in each instance or bag. The feature embedding and multi-instance neural network are parameterized and optimized jointly in an end-to-end manner. Moreover, the training process is under both main and auxiliary supervision with focal loss functions to avoid the caveat of a highly imbalanced label set. This proposed framework is named AMI-Net3. We evaluate it on three suitable data sets from real-world settings with different clinical risk prediction tasks: adverse drug reaction of risperidone, schizophrenia relapse, and invasive fungi infection, respectively. The comprehensive experimental results demonstrate the effectiveness and superiority of our proposed method over competitive baselines.},
  archive      = {J_ARTMED},
  author       = {Zeyuan Wang and Josiah Poon and Shuze Wang and Shiding Sun and Simon Poon},
  doi          = {10.1016/j.artmed.2021.102052},
  journal      = {Artificial Intelligence in Medicine},
  month        = {4},
  pages        = {102052},
  shortjournal = {Artif. Intell. Med.},
  title        = {A novel method for clinical risk prediction with low-quality data},
  volume       = {114},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Data imputation and compression for parkinson’s disease
clinical questionnaires. <em>ARTMED</em>, <em>114</em>, 102051. (<a
href="https://doi.org/10.1016/j.artmed.2021.102051">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Medical questionnaires are a valuable source of information but are often difficult to analyse due to both their size and the high possibility of them having missing values. This is a problematic issue in biomedical data science as it may complicate how individual questionnaire data is represented for statistical or machine learning analysis. In this paper, we propose a deeply-learnt residual autoencoder to simultaneously perform non-linear data imputation and dimensionality reduction. We present an extensive analysis of the dynamics of the performance of this autoencoder regarding the compression rate and the proportion of missing values. This method is evaluated on motor and non-motor clinical questionnaires of the Parkinson&#39;s Progression Markers Initiative (PPMI) database and consistently outperforms linear coupled imputation and reduction approaches.},
  archive      = {J_ARTMED},
  author       = {Maxime Peralta and Pierre Jannin and Claire Haegelen and John S.H. Baxter},
  doi          = {10.1016/j.artmed.2021.102051},
  journal      = {Artificial Intelligence in Medicine},
  month        = {4},
  pages        = {102051},
  shortjournal = {Artif. Intell. Med.},
  title        = {Data imputation and compression for parkinson&#39;s disease clinical questionnaires},
  volume       = {114},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Video-based eye tracking performance for computer-assisted
diagnostic support of diabetic neuropathy. <em>ARTMED</em>,
<em>114</em>, 102050. (<a
href="https://doi.org/10.1016/j.artmed.2021.102050">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Diabetes is currently one of the major public health threats. The essential components for effective treatment of diabetes include early diagnosis and regular monitoring. However, health-care providers are often short of human resources to closely monitor populations at risk. In this work, a video-based eye-tracking method is proposed as a low-cost alternative for detection of diabetic neuropathy . The method is based on the tracking of the eye-trajectories recorded on videos while the subject follows a target on a screen, forcing saccadic movements. Upon extraction of the eye trajectories, representation of the obtained time-series is made with the help of heteroscedastic ARX (H-ARX) models, which capture the dynamics and latency on the subject&#39;s response, while features based on the H-ARX model&#39;s predictive ability are subsequently used for classification. The methodology is evaluated on a population constituted by 11 control and 20 insulin-treated diabetic individuals suffering from diverse diabetic complications including neuropathy and retinopathy. Results show significant differences on latency and eye movement precision between the populations of control subjects and diabetics, while simultaneously demonstrating that both groups can be classified with an accuracy of 95%. Although this study is limited by the small sample size, the results align with other findings in the literature and encourage further research.},
  archive      = {J_ARTMED},
  author       = {Luis David Avendaño-Valencia and Knud B. Yderstræde and Esmaeil S. Nadimi and Victoria Blanes-Vidal},
  doi          = {10.1016/j.artmed.2021.102050},
  journal      = {Artificial Intelligence in Medicine},
  month        = {4},
  pages        = {102050},
  shortjournal = {Artif. Intell. Med.},
  title        = {Video-based eye tracking performance for computer-assisted diagnostic support of diabetic neuropathy},
  volume       = {114},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). R-HEFS: Rough set based heterogeneous ensemble feature
selection method for medical data classification. <em>ARTMED</em>,
<em>114</em>, 102049. (<a
href="https://doi.org/10.1016/j.artmed.2021.102049">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selection is one of the trustworthy processes of dimensionality reduction technique to select a subset of relevant and non-redundant features from large datasets. Ensemble feature selection (EFS) approach is a recent technique aiming at accumulating diversity in the subset of selected features. It improves the performance of learning algorithms and obtains more stable and robust results. In this paper, a novel rough set theory (RST) based heterogeneous EFS method (R-HEFS) is proposed for selecting the less redundant and highly relevant features during the aggregation of diverse feature subsets by applying the feature-class, feature-feature rough dependency and feature-significance measures. In R-HEFS five state-of-the-art RST based filter methods are used as a base feature selectors. Experiments are carried out on 10 benchmark medical datasets collected from the UCI repository. For the imputation of the missing values and discretization of the continuous features, k k nearest neighbor ( k k NN) imputation method and RST based discretization techniques are applied. The effectiveness of the proposed R-HEFS method is evaluated and analyzed by using four benchmark classifiers viz., Naïve Bayes (NB), random forest (RF), support vector machine (SVM), and AdaBoost. The proposed R-HEFS method turns out to be effective by removing the non-relevant and redundant features during the process of aggregation of base feature selectors and it assists to increase the classification accuracy. Out of 10 different medical datasets, on 7 datasets, R-HEFS has achieved better average classification accuracy. So, the overall results strongly suggest that the proposed R-HEFS method can reduce the dimension of large medical datasets and may help the physicians or medical experts to diagnose (classify) different diseases with lesser computational complexities.},
  archive      = {J_ARTMED},
  author       = {Rubul Kumar Bania and Anindya Halder},
  doi          = {10.1016/j.artmed.2021.102049},
  journal      = {Artificial Intelligence in Medicine},
  month        = {4},
  pages        = {102049},
  shortjournal = {Artif. Intell. Med.},
  title        = {R-HEFS: Rough set based heterogeneous ensemble feature selection method for medical data classification},
  volume       = {114},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A deep learning approach for mitosis detection: Application
in tumor proliferation prediction from whole slide images.
<em>ARTMED</em>, <em>114</em>, 102048. (<a
href="https://doi.org/10.1016/j.artmed.2021.102048">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The tumor proliferation, which is correlated with tumor grade, is a crucial biomarker indicative of breast cancer patients&#39; prognosis. The most commonly used method in predicting tumor proliferation speed is the counting of mitotic figures in Hematoxylin and Eosin (H&amp;E) histological slides. Manual mitosis counting is known to suffer from reproducibility problems. This paper presents a fully automated system for tumor proliferation prediction from whole slide images via mitosis counting. First, by considering the epithelial tissue as mitosis activity regions, we build a deep-learning-based region of interest detection method to select the high mitosis activity regions from whole slide images. Second, we learned a set of deep neural networks to detect mitosis detection from selected areas. The proposed mitosis detection system is designed to effectively overcome the mitosis detection challenges by two novel deep preprocessing and two-step hard negative mining approaches. Third, we trained a Support Vector Machine (SVM) classifier to predict the final tumor proliferation score. The proposed method was evaluated on the dataset of the Tumor Proliferation Assessment Challenge (TUPAC16) and achieved a 73.81 % F-measure and 0.612 weighted kappa score, respectively, outperforming all previous approaches significantly. Experimental results demonstrate that the proposed system considerably improves the tumor proliferation prediction accuracy and provides a reliable automated tool to support health care make-decisions.},
  archive      = {J_ARTMED},
  author       = {Ramin Nateghi and Habibollah Danyali and Mohammad Sadegh Helfroush},
  doi          = {10.1016/j.artmed.2021.102048},
  journal      = {Artificial Intelligence in Medicine},
  month        = {4},
  pages        = {102048},
  shortjournal = {Artif. Intell. Med.},
  title        = {A deep learning approach for mitosis detection: Application in tumor proliferation prediction from whole slide images},
  volume       = {114},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Advanced EEG-based learning approaches to predict
schizophrenia: Promises and pitfalls. <em>ARTMED</em>, <em>114</em>,
102039. (<a href="https://doi.org/10.1016/j.artmed.2021.102039">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The complexity and heterogeneity of schizophrenia symptoms challenge an objective diagnosis, which is typically based on behavioral and clinical manifestations. Moreover, the boundaries of schizophrenia are not precisely demarcated from other nosologic categories, such as bipolar disorder. The early detection of schizophrenia can lead to a more effective treatment, improving patients’ quality of life. Over the last decades, hundreds of studies aimed at specifying the neurobiological mechanisms that underpin clinical manifestations of schizophrenia, using techniques such as electroencephalography (EEG). Changes in event-related potentials of the EEG have been associated with sensory and cognitive deficits and proposed as biomarkers of schizophrenia. Besides contributing to a more effective diagnosis, biomarkers can be crucial to schizophrenia onset prediction and prognosis. However, any proposed biomarker requires substantial clinical research to prove its validity and cost-effectiveness. Fueled by developments in computational neuroscience, automatic classification of schizophrenia at different stages (prodromal, first episode, chronic) has been attempted, using brain imaging pattern recognition methods to capture differences in functional brain activity. Advanced learning techniques have been studied for this purpose, with promising results. This review provides an overview of recent machine learning-based methods for schizophrenia classification using EEG data, discussing their potentialities and limitations. This review is intended to serve as a starting point for future developments of effective EEG-based models that might predict the onset of schizophrenia, identify subjects at high-risk of psychosis conversion or differentiate schizophrenia from other disorders, promoting more effective early interventions.},
  archive      = {J_ARTMED},
  author       = {Carla Barros and Carlos A. Silva and Ana P. Pinheiro},
  doi          = {10.1016/j.artmed.2021.102039},
  journal      = {Artificial Intelligence in Medicine},
  month        = {4},
  pages        = {102039},
  shortjournal = {Artif. Intell. Med.},
  title        = {Advanced EEG-based learning approaches to predict schizophrenia: Promises and pitfalls},
  volume       = {114},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). STQS: Interpretable multi-modal spatial-temporal-seQuential
model for automatic sleep scoring. <em>ARTMED</em>, <em>114</em>,
102038. (<a href="https://doi.org/10.1016/j.artmed.2021.102038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sleep scoring is an important step for the detection of sleep disorders and usually performed by visual analysis. Since manual sleep scoring is time consuming, machine-learning based approaches have been proposed. Though efficient, these algorithms are black-box in nature and difficult to interpret by clinicians. In this paper, we propose a deep learning architecture for multi-modal sleep scoring, investigate the model&#39;s decision making process, and compare the model&#39;s reasoning with the annotation guidelines in the AASM manual. Our architecture, called STQS, uses convolutional neural networks (CNN) to automatically extract spatio-temporal features from 3 modalities (EEG, EOG and EMG), a bidirectional long short-term memory (Bi-LSTM) to extract sequential information, and residual connections to combine spatio-temporal and sequential features. We evaluated our model on two large datasets, obtaining an accuracy of 85% and 77% and a macro F1 score of 79% and 73% on SHHS and an in-house dataset, respectively. We further quantify the contribution of various architectural components and conclude that adding LSTM layers improves performance over a spatio-temporal CNN, while adding residual connections does not. Our interpretability results show that the output of the model is well aligned with AASM guidelines, and therefore, the model&#39;s decisions correspond to domain knowledge. We also compare multi-modal models and single-channel models and suggest that future research should focus on improving multi-modal models.},
  archive      = {J_ARTMED},
  author       = {Shreyasi Pathak and Changqing Lu and Sunil Belur Nagaraj and Michel van Putten and Christin Seifert},
  doi          = {10.1016/j.artmed.2021.102038},
  journal      = {Artificial Intelligence in Medicine},
  month        = {4},
  pages        = {102038},
  shortjournal = {Artif. Intell. Med.},
  title        = {STQS: Interpretable multi-modal spatial-temporal-seQuential model for automatic sleep scoring},
  volume       = {114},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Publishing artificial intelligence research papers: A tale
of three journals. <em>ARTMED</em>, <em>113</em>, 102037. (<a
href="https://doi.org/10.1016/j.artmed.2021.102037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_ARTMED},
  author       = {Edward H. Shortliffe and Mor Peleg and Carlo Combi and Anthony C. Chang and Justyna Vinci},
  doi          = {10.1016/j.artmed.2021.102037},
  journal      = {Artificial Intelligence in Medicine},
  month        = {3},
  pages        = {102037},
  shortjournal = {Artif. Intell. Med.},
  title        = {Publishing artificial intelligence research papers: A tale of three journals},
  volume       = {113},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). DeepAISE – an interpretable and recurrent neural survival
model for early prediction of sepsis. <em>ARTMED</em>, <em>113</em>,
102036. (<a href="https://doi.org/10.1016/j.artmed.2021.102036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sepsis, a dysregulated immune system response to infection, is among the leading causes of morbidity, mortality, and cost overruns in the Intensive Care Unit (ICU). Early prediction of sepsis can improve situational awareness among clinicians and facilitate timely, protective interventions. While the application of predictive analytics in ICU patients has shown early promising results, much of the work has been encumbered by high false-alarm rates and lack of trust by the end-users due to the ‘black box’ nature of these models. Here, we present DeepAISE (Deep Artificial Intelligence Sepsis Expert), a recurrent neural survival model for the early prediction of sepsis. DeepAISE automatically learns predictive features related to higher-order interactions and temporal patterns among clinical risk factors that maximize the data likelihood of observed time to septic events. A comparative study of four baseline models on data from hospitalized patients at three different healthcare systems indicates that DeepAISE produces the most accurate predictions (AUCs between 0.87 and 0.90) at the lowest false alarm rates (FARs between 0.20 and 0.25) while simultaneously producing interpretable representations of the clinical time series and risk factors.},
  archive      = {J_ARTMED},
  author       = {Supreeth P. Shashikumar and Christopher S. Josef and Ashish Sharma and Shamim Nemati},
  doi          = {10.1016/j.artmed.2021.102036},
  journal      = {Artificial Intelligence in Medicine},
  month        = {3},
  pages        = {102036},
  shortjournal = {Artif. Intell. Med.},
  title        = {DeepAISE – an interpretable and recurrent neural survival model for early prediction of sepsis},
  volume       = {113},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A multi-scale convolutional neural network with context for
joint segmentation of optic disc and cup. <em>ARTMED</em>, <em>113</em>,
102035. (<a href="https://doi.org/10.1016/j.artmed.2021.102035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Glaucoma is the leading cause of irreversible blindness. For glaucoma screening, the cup to disc ratio (CDR) is a significant indicator, whose calculation relies on the segmentation of optic disc(OD) and optic cup(OC) in color fundus images. This study proposes a residual multi-scale convolutional neural network with a context semantic extraction module to jointly segment the OD and OC. The proposed method uses a W-shaped backbone network, including image pyramid multi-scale input with the side output layer as an early classifier to generate local prediction output. The proposed method includes a context extraction module that extracts contextual semantic information from multiple level receptive field sizes and adaptively recalibrates channel-wise feature responses. It can effectively extract global information and reduce the semantic gaps in the fusion of deep and shallow semantic information. We validated the proposed method on four datasets, including DRISHTI-GS1, REFUGE, RIM-ONE r3, and a private dataset. The overlap errors are 0.0540, 0.0684, 0.0492, 0.0511 in OC segmentation and 0.2332, 0.1777, 0.2372, 0.2547 in OD segmentation, respectively. Experimental results indicate that the proposed method can estimate the CDR for a large-scale glaucoma screening.},
  archive      = {J_ARTMED},
  author       = {Xin Yuan and Lingxiao Zhou and Shuyang Yu and Miao Li and Xiang Wang and Xiujuan Zheng},
  doi          = {10.1016/j.artmed.2021.102035},
  journal      = {Artificial Intelligence in Medicine},
  month        = {3},
  pages        = {102035},
  shortjournal = {Artif. Intell. Med.},
  title        = {A multi-scale convolutional neural network with context for joint segmentation of optic disc and cup},
  volume       = {113},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). AIRBP: Accurate identification of RNA-binding proteins using
machine learning techniques. <em>ARTMED</em>, <em>113</em>, 102034. (<a
href="https://doi.org/10.1016/j.artmed.2021.102034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Identification of RNA-binding proteins (RBPs) that bind to ribonucleic acid molecules is an important problem in Computational Biology and Bioinformatics. It becomes indispensable to identify RBPs as they play crucial roles in post-transcriptional control of RNAs and RNA metabolism as well as have diverse roles in various biological processes such as splicing, mRNA stabilization, mRNA localization, and translation, RNA synthesis, folding-unfolding, modification, processing, and degradation. The existing experimental techniques for identifying RBPs are time-consuming and expensive. Therefore, identifying RBPs directly from the sequence using computational methods can be useful to annotate RBPs and assist the experimental design efficiently. In this work, we present a method called AIRBP, which is designed using an advanced machine learning technique, called stacking, to effectively predict RBPs by utilizing features extracted from evolutionary information, physiochemical properties, and disordered properties. Moreover, our method, AIRBP, use the majority vote from RBPPred, DeepRBPPred, and the stacking model for the prediction for RBPs. The results show that AIRBP attains Accuracy (ACC), Balanced Accuracy (BACC), F1-score, and Mathews Correlation Coefficient (MCC) of 95.84 %, 94.71 %, 0.928, and 0.899, respectively, based on the training dataset, using 10-fold cross-validation (CV). Further evaluation of AIRBP on independent test set reveals that it achieves ACC, BACC, F1-score, and MCC of 94.36 %, 94.28 %, 0.897, and 0.860, for Human test set; 91.25 %, 93.00 %, 0.896, and 0.835 for S. cerevisiae test set; and 90.60 %, 90.41 %, 0.934, and 0.775 for A. thaliana test set, respectively. These results indicate that the AIRBP outperforms the existing Deep- and TriPepSVM methods. Therefore, the proposed better-performing AIRBP can be useful for accurate identification and annotation of RBPs directly from the sequence and help gain valuable insight to treat critical diseases. Availability : Code-data is available here: http://cs.uno.edu/∼tamjid/Software/AIRBP/code_data.zip},
  archive      = {J_ARTMED},
  author       = {Avdesh Mishra and Reecha Khanal and Wasi Ul Kabir and Tamjidul Hoque},
  doi          = {10.1016/j.artmed.2021.102034},
  journal      = {Artificial Intelligence in Medicine},
  month        = {3},
  pages        = {102034},
  shortjournal = {Artif. Intell. Med.},
  title        = {AIRBP: Accurate identification of RNA-binding proteins using machine learning techniques},
  volume       = {113},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Improving sentiment analysis on clinical narratives by
exploiting UMLS semantic types. <em>ARTMED</em>, <em>113</em>, 102033.
(<a href="https://doi.org/10.1016/j.artmed.2021.102033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sentiments associated with assessments and observations recorded in a clinical narrative can often indicate a patient&#39;s health status. To perform sentiment analysis on clinical narratives, domain-specific knowledge concerning meanings of medical terms is required. In this study, semantic types in the Unified Medical Language System (UMLS) are exploited to improve lexicon-based sentiment classification methods. For sentiment classification using SentiWordNet, the overall accuracy is improved from 0.582 to 0.710 by using logistic regression to determine appropriate polarity scores for UMLS ‘Disorders’ semantic types. For sentiment classification using a trained lexicon, when disorder terms in a training set are replaced with their semantic types, classification accuracies are improved on some data segments containing specific semantic types. To select an appropriate classification method for a given data segment, classifier combination is proposed. Using classifier combination, classification accuracies are improved on most data segments, with the overall accuracy of 0.882 being obtained.},
  archive      = {J_ARTMED},
  author       = {Nuttapong Sanglerdsinlapachai and Anon Plangprasopchok and Tu Bao Ho and Ekawit Nantajeewarawat},
  doi          = {10.1016/j.artmed.2021.102033},
  journal      = {Artificial Intelligence in Medicine},
  month        = {3},
  pages        = {102033},
  shortjournal = {Artif. Intell. Med.},
  title        = {Improving sentiment analysis on clinical narratives by exploiting UMLS semantic types},
  volume       = {113},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multimodal tensor-based method for integrative and
continuous patient monitoring during postoperative cardiac care.
<em>ARTMED</em>, <em>113</em>, 102032. (<a
href="https://doi.org/10.1016/j.artmed.2021.102032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Patients recovering from cardiovascular surgeries may develop life-threatening complications such as hemodynamic decompensation, making the monitoring of patients for such complications an essential component of postoperative care. However, this need has given rise to an inexorable increase in the number and modalities of data points collected, making it challenging to effectively analyze in real time. While many algorithms exist to assist in monitoring these patients, they often lack accuracy and specificity, leading to alarm fatigue among healthcare practitioners. In this study we propose a multimodal approach that incorporates salient physiological signals and EHR data to predict the onset of hemodynamic decompensation. A retrospective dataset of patients recovering from cardiac surgery was created and used to train predictive models. Advanced signal processing techniques were employed to extract complex features from physiological waveforms, while a novel tensor-based dimensionality reduction method was used to reduce the size of the feature space. These methods were evaluated for predicting the onset of decompensation at varying time intervals, ranging from a half-hour to 12 h prior to a decompensation event. The best performing models achieved AUCs of 0.87 and 0.80 for the half-hour and 12-h intervals respectively. These analyses evince that a multimodal approach can be used to develop clinical decision support systems that predict adverse events several hours in advance.},
  archive      = {J_ARTMED},
  author       = {Larry Hernandez and Renaid Kim and Neriman Tokcan and Harm Derksen and Ben E. Biesterveld and Alfred Croteau and Aaron M. Williams and Michael Mathis and Kayvan Najarian and Jonathan Gryak},
  doi          = {10.1016/j.artmed.2021.102032},
  journal      = {Artificial Intelligence in Medicine},
  month        = {3},
  pages        = {102032},
  shortjournal = {Artif. Intell. Med.},
  title        = {Multimodal tensor-based method for integrative and continuous patient monitoring during postoperative cardiac care},
  volume       = {113},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Improving prediction for medical institution with limited
patient data: Leveraging hospital-specific data based on multicenter
collaborative research network. <em>ARTMED</em>, <em>113</em>, 102024.
(<a href="https://doi.org/10.1016/j.artmed.2021.102024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Clinical decision support assisted by prediction models usually faces the challenges of limited clinical data and a lack of labels when the model is developed with data from a single medical institution. Accordingly, research on multicenter clinical collaborative networks, which can provide external medical data, has received increasing attention. With the increasing availability of machine learning techniques such as transfer learning , leveraging large-scale patient data from multiple hospitals to build data-driven predictive models with clinical application potential provides an alternative solution to address the problem of limited patient data. A multicenter hybrid semi-supervised transfer learning model (MHSTL) is proposed in this study on the basis of unified common data model to ensure multicenter data standardized representation. Then the hospital-specific features, along with the co-occurrence features across domains, are aligned through a representation learning architecture that is built based on deep neural networks and the newly proposed neural decision forest model. In this process, limited patient data from the target hospital, both labeled and unlabeled, are incorporated during the feature adaptation process, thereby contributing to better model performance. Without patient-level data sharing, the proposed model learning strategy which overcomes feature misalignment and distribution divergence, enables the multi-source transfer learning process in the case of insufficient and unlabeled patient data at target hospital. The effectiveness of the proposed transfer learning model was evaluated on a collaborative research network of colorectal cancer patients in the US and China. The results demonstrate that the proposed model can achieve much better performance for predicting target risk with limited resources on patient data than baseline models      . Better discrimination and calibration ability are also observed when sufficient labeled data are not available in the target hospital for prognosis prediction tasks      . Further exploratory experiments show that the proposed approach exhibits good model generalizability regardless of the data heterogeneity. With the help of the SHapley Additive exPlanations for model interpretation, the effectiveness of incorporating hospital-specific features in the transfer learning model is shown. In this study, the proposed method can develop prediction models from multiple source hospitals and exhibit good performance by leveraging cross-domain hospital-specific feature information, therefore enhancing the model prediction when applied to single medical institution with limited patient data.},
  archive      = {J_ARTMED},
  author       = {Jin Li and Yu Tian and Runze Li and Tianshu Zhou and Jun Li and Kefeng Ding and Jingsong Li},
  doi          = {10.1016/j.artmed.2021.102024},
  journal      = {Artificial Intelligence in Medicine},
  month        = {3},
  pages        = {102024},
  shortjournal = {Artif. Intell. Med.},
  title        = {Improving prediction for medical institution with limited patient data: Leveraging hospital-specific data based on multicenter collaborative research network},
  volume       = {113},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Liver segmentation in abdominal CT images via auto-context
neural network and self-supervised contour attention. <em>ARTMED</em>,
<em>113</em>, 102023. (<a
href="https://doi.org/10.1016/j.artmed.2021.102023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Objective: Accurate image segmentation of the liver is a challenging problem owing to its large shape variability and unclear boundaries. Although the applications of fully convolutional neural networks (CNNs) have shown groundbreaking results, limited studies have focused on the performance of generalization. In this study, we introduce a CNN for liver segmentation on abdominal computed tomography (CT) images that focus on the performance of generalization and accuracy. Methods: To improve the generalization performance, we initially propose an auto-context algorithm in a single CNN . The proposed auto-context neural network exploits an effective high-level residual estimation to obtain the shape prior. Identical dual paths are effectively trained to represent mutual complementary features for an accurate posterior analysis of a liver. Further, we extend our network by employing a self-supervised contour scheme. We trained sparse contour features by penalizing the ground-truth contour to focus more contour attentions on the failures. Results: We used 180 abdominal CT images for training and validation. Two-fold cross-validation is presented for a comparison with the state-of-the-art neural networks. The experimental results show that the proposed network results in better accuracy when compared to the state-of-the-art networks by reducing 10.31% of the Hausdorff distance. Novel multiple N N -fold cross-validations are conducted to show the best performance of generalization of the proposed network. Conclusion and significance: The proposed method minimized the error between training and test images more than any other modern neural networks. Moreover, the contour scheme was successfully employed in the network by introducing a self-supervising metric.},
  archive      = {J_ARTMED},
  author       = {Minyoung Chung and Jingyu Lee and Sanguk Park and Chae Eun Lee and Jeongjin Lee and Yeong-Gil Shin},
  doi          = {10.1016/j.artmed.2021.102023},
  journal      = {Artificial Intelligence in Medicine},
  month        = {3},
  pages        = {102023},
  shortjournal = {Artif. Intell. Med.},
  title        = {Liver segmentation in abdominal CT images via auto-context neural network and self-supervised contour attention},
  volume       = {113},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Artificial intelligence for the diagnosis of lymph node
metastases in patients with abdominopelvic malignancy: A systematic
review and meta-analysis. <em>ARTMED</em>, <em>113</em>, 102022. (<a
href="https://doi.org/10.1016/j.artmed.2021.102022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate clinical diagnosis of lymph node metastases is of paramount importance in the treatment of patients with abdominopelvic malignancy. This review assesses the diagnostic performance of deep learning algorithms and radiomics models for lymph node metastases in abdominopelvic malignancies. Embase (PubMed, MEDLINE), Science Direct and IEEE Xplore databases were searched to identify eligible studies published between January 2009 and March 2019. Studies that reported on the accuracy of deep learning algorithms or radiomics models for abdominopelvic malignancy by CT or MRI were selected. Study characteristics and diagnostic measures were extracted. Estimates were pooled using random-effects meta-analysis. Evaluation of risk of bias was performed using the QUADAS-2 tool. In total, 498 potentially eligible studies were identified, of which 21 were included and 17 offered enough information for a quantitative analysis. Studies were heterogeneous and substantial risk of bias was found in 18 studies. Almost all studies employed radiomics models (n = 20). The single published deep-learning model out-performed radiomics models with a higher AUROC (0.912 vs 0.895), but both radiomics and deep-learning models outperformed the radiologist’s interpretation in isolation (0.774). Pooled results for radiomics nomograms amongst tumour subtypes demonstrated the highest AUC 0.895 (95 %CI, 0.810−0.980) for urological malignancy, and the lowest AUC 0.798 (95 %CI, 0.744−0.852) for colorectal malignancy. Radiomics models improve the diagnostic accuracy of lymph node staging for abdominopelvic malignancies in comparison with radiologist’s assessment. Deep learning models may further improve on this, but data remain limited.},
  archive      = {J_ARTMED},
  author       = {Sergei Bedrikovetski and Nagendra N. Dudi-Venkata and Gabriel Maicas and Hidde M. Kroon and Warren Seow and Gustavo Carneiro and James W. Moore and Tarik Sammour},
  doi          = {10.1016/j.artmed.2021.102022},
  journal      = {Artificial Intelligence in Medicine},
  month        = {3},
  pages        = {102022},
  shortjournal = {Artif. Intell. Med.},
  title        = {Artificial intelligence for the diagnosis of lymph node metastases in patients with abdominopelvic malignancy: A systematic review and meta-analysis},
  volume       = {113},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multiscale CNN with compound fusions for false positive
reduction in lung nodule detection. <em>ARTMED</em>, <em>113</em>,
102017. (<a href="https://doi.org/10.1016/j.artmed.2021.102017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pulmonary lung nodules are often benign at the early stage but they could easily become malignant and metastasize to other locations in later stages. Morphological characteristics of these nodule instances vary largely in terms of their size, shape, and texture. There are also other co-existing lung anatomical structures such as lung walls and blood vessels surrounding these nodules resulting in complex contextual information. As a result, their early diagnosis to enable decisive intervention using Computer-Aided Diagnosis (CAD) systems face serious challenges, especially at low false positive rates. In this paper, we propose a new Convolutional Neural Network (CNN) architecture called Multiscale CNN with Compound Fusions (MCNN-CF) for this purpose which uses multiscale 3D patches as inputs and performs a fusion of intermediate features at two different depths of the network in two diverse fashions. The network is trained by a new iterative training procedure adapted to circumvent the class imbalance problem and obtained a Competitive Performance Metric (CPM) score of 0.948 when tested on the LUNA16 dataset. Experimental results illustrate the robustness of the proposed system which has increased the confidence of the prediction probabilities in the detection of the most variety of nodules.},
  archive      = {J_ARTMED},
  author       = {Mittapalli Pardha Saradhi and Thanikaiselvan V},
  doi          = {10.1016/j.artmed.2021.102017},
  journal      = {Artificial Intelligence in Medicine},
  month        = {3},
  pages        = {102017},
  shortjournal = {Artif. Intell. Med.},
  title        = {Multiscale CNN with compound fusions for false positive reduction in lung nodule detection},
  volume       = {113},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Modeling multivariate clinical event time-series with
recurrent temporal mechanisms. <em>ARTMED</em>, <em>112</em>, 102021.
(<a href="https://doi.org/10.1016/j.artmed.2021.102021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we propose a novel autoregressive event time-series model that can predict future occurrences of multivariate clinical events. Our model represents multivariate event time-series using different temporal mechanisms aimed to fit different temporal characteristics of the time-series. In particular, information about distant past is modeled through the hidden state space defined by an LSTM-based model, information on recently observed clinical events is modeled through discriminative projections, and information about periodic (repeated) events is modeled using a special recurrent mechanism based on probability distributions of inter-event gaps compiled from past data. We evaluate our proposed model on electronic health record (EHRs) data derived from MIMIC-III dataset. We show that our new model equipped with the above temporal mechanisms leads to improved prediction performance compared to multiple baselines.},
  archive      = {J_ARTMED},
  author       = {Jeong Min Lee and Milos Hauskrecht},
  doi          = {10.1016/j.artmed.2021.102021},
  journal      = {Artificial Intelligence in Medicine},
  month        = {2},
  pages        = {102021},
  shortjournal = {Artif. Intell. Med.},
  title        = {Modeling multivariate clinical event time-series with recurrent temporal mechanisms},
  volume       = {112},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A survey of deep learning models in medical therapeutic
areas. <em>ARTMED</em>, <em>112</em>, 102020. (<a
href="https://doi.org/10.1016/j.artmed.2021.102020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial intelligence is a broad field that comprises a wide range of techniques, where deep learning is presently the one with the most impact. Moreover, the medical field is an area where data both complex and massive and the importance of the decisions made by doctors make it one of the fields in which deep learning techniques can have the greatest impact. A systematic review following the Cochrane recommendations with a multidisciplinary team comprised of physicians, research methodologists and computer scientists has been conducted. This survey aims to identify the main therapeutic areas and the deep learning models used for diagnosis and treatment tasks. The most relevant databases included were MedLine, Embase, Cochrane Central, Astrophysics Data System, Europe PubMed Central, Web of Science and Science Direct. An inclusion and exclusion criteria were defined and applied in the first and second peer review screening. A set of quality criteria was developed to select the papers obtained after the second screening. Finally, 126 studies from the initial 3493 papers were selected and 64 were described. Results show that the number of publications on deep learning in medicine is increasing every year. Also, convolutional neural networks are the most widely used models and the most developed area is oncology where they are used mainly for image analysis.},
  archive      = {J_ARTMED},
  author       = {Alberto Nogales and Álvaro J. García-Tejedor and Diana Monge and Juan Serrano Vara and Cristina Antón},
  doi          = {10.1016/j.artmed.2021.102020},
  journal      = {Artificial Intelligence in Medicine},
  month        = {2},
  pages        = {102020},
  shortjournal = {Artif. Intell. Med.},
  title        = {A survey of deep learning models in medical therapeutic areas},
  volume       = {112},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A method based on cardiopulmonary coupling analysis for
sleep quality assessment with FPGA implementation. <em>ARTMED</em>,
<em>112</em>, 102019. (<a
href="https://doi.org/10.1016/j.artmed.2021.102019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The relevance of sleep quality examination for clinical diagnosis is increasing with the discovery of new relationships with several diseases and the overall wellness. This assessment is commonly performed by conducting interviews with the subjects, evaluating the self-report and psychological variables. However, this approach has a major constraint since the subject is a poor self-observer of sleep behaviors. To address this issue, a method based on the examination of a physiological signal was developed. Specifically, the single-lead electrocardiogram signal was examined to estimate the cardiopulmonary coupling between the electrocardiogram derived respiration signal and the normal-to-normal sinus interbeat interval series. A one dimensional array was created from the coupling signal and was fed to a convolutional neural network to estimate the sleep quality. The age-related cyclic alternating pattern rate percentages in healthy subjects was considered as the classification reference. An accuracy of 91 % was attained by the developed model, with an area under the receiver operating characteristic curve of 97 %. The performance is in the upper range of the reported performance by the works presented in the state of the art, advocating the relevance of the proposed method. The model was implemented in a small field programmable gate array board. Hence, a home monitoring device was created, composed of a processing unit, a sensing module and a display unit. The device is resilient, easy to self-assemble and operate, and can conceivably be employed for clinical analysis.},
  archive      = {J_ARTMED},
  author       = {Fábio Mendonça and Sheikh Shanawaz Mostafa and Fernando Morgado-Dias and Antonio G. Ravelo-García},
  doi          = {10.1016/j.artmed.2021.102019},
  journal      = {Artificial Intelligence in Medicine},
  month        = {2},
  pages        = {102019},
  shortjournal = {Artif. Intell. Med.},
  title        = {A method based on cardiopulmonary coupling analysis for sleep quality assessment with FPGA implementation},
  volume       = {112},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A novel computational method for assigning weights of
importance to symptoms of COVID-19 patients. <em>ARTMED</em>,
<em>112</em>, 102018. (<a
href="https://doi.org/10.1016/j.artmed.2021.102018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The novel coronavirus disease 2019 (COVID-19) is considered a pandemic by the World Health Organization (WHO). As of April 3, 2020, there were 1,009,625 reported confirmed cases, and 51,737 reported deaths. Doctors have been faced with a myriad of patients who present with many different symptoms. This raises two important questions. What are the common symptoms, and what are their relative importance? A non-structured and incomplete COVID-19 dataset of 14,251 confirmed cases was preprocessed. This produced a complete and organized COVID-19 dataset of 738 confirmed cases. Six different feature selection algorithms were then applied to this new dataset. Five of these algorithms have been proposed earlier in the literature. The sixth is a novel algorithm being proposed by the authors, called Variance Based Feature Weighting (VBFW), which not only ranks the symptoms (based on their importance) but also assigns a quantitative importance measure to each symptom. For our COVID-19 dataset, the five different feature selection algorithms provided different rankings for the most important top-five symptoms. They even selected different symptoms for inclusion within the top five. This is because each of the five algorithms ranks the symptoms based on different data characteristics. Each of these algorithms has advantages and disadvantages. However, when all these five rankings were aggregated (using two different aggregating methods) they produced two identical rankings of the five most important COVID-19 symptoms. Starting from the most important to least important, they were: Fever/Cough, Fatigue, Sore Throat, and Shortness of Breath. (Fever and cough were ranked equally in both aggregations.) Meanwhile, the sixth novel Variance Based Feature Weighting algorithm, chose the same top five symptoms, but ranked fever much higher than cough, based on its quantitative importance measures for each of those symptoms ( Fever - 75 % , Cough - 39.8 % , Fatigue - 16.5 % , Sore Throat - 10.8 % , and Shortness of Breath - 6.6 %). Moreover, the proposed VBFW method achieved an accuracy of 92.1 % when used to build a one-class SVM model, and an NDCG@5 of 100 %. Based on the dataset, and the feature selection algorithms employed here, symptoms of Fever, Cough, Fatigue, Sore Throat and Shortness of Breath are important symptoms of COVID-19. The VBFW algorithm also indicates that Fever and Cough symptoms were especially indicative of COVID-19, for the confirmed cases that are documented in our database.},
  archive      = {J_ARTMED},
  author       = {Mohammad A. Alzubaidi and Mwaffaq Otoom and Nesreen Otoum and Yousef Etoom and Rudaina Banihani},
  doi          = {10.1016/j.artmed.2021.102018},
  journal      = {Artificial Intelligence in Medicine},
  month        = {2},
  pages        = {102018},
  shortjournal = {Artif. Intell. Med.},
  title        = {A novel computational method for assigning weights of importance to symptoms of COVID-19 patients},
  volume       = {112},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Medical analytics for healthcare intelligence – recent
advances and future directions. <em>ARTMED</em>, <em>112</em>, 102009.
(<a href="https://doi.org/10.1016/j.artmed.2021.102009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_ARTMED},
  author       = {Tianhua Chen and Elpida Keravnou-Papailiou and Grigoris Antoniou},
  doi          = {10.1016/j.artmed.2021.102009},
  journal      = {Artificial Intelligence in Medicine},
  month        = {2},
  pages        = {102009},
  shortjournal = {Artif. Intell. Med.},
  title        = {Medical analytics for healthcare intelligence – recent advances and future directions},
  volume       = {112},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). BertMCN: Mapping colloquial phrases to standard medical
concepts using BERT and highway network. <em>ARTMED</em>, <em>112</em>,
102008. (<a href="https://doi.org/10.1016/j.artmed.2021.102008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the last few years, people started to share lots of information related to health in the form of tweets, reviews and blog posts. All these user generated clinical texts can be mined to generate useful insights. However, automatic analysis of clinical text requires identification of standard medical concepts. Most of the existing deep learning based medical concept normalization systems are based on CNN or RNN. Performance of these models is limited as they have to be trained from scratch (except embeddings). In this work, we propose a medical concept normalization system based on BERT and highway layer. BERT, a pre-trained context sensitive deep language representation model advanced state-of-the-art performance in many NLP tasks and gating mechanism in highway layer helps the model to choose only important information. Experimental results show that our model outperformed all existing methods on two standard datasets. Further, we conduct a series of experiments to study the impact of different learning rates and batch sizes, noise and freezing encoder layers on our model.},
  archive      = {J_ARTMED},
  author       = {Katikapalli Subramanyam Kalyan and Sivanesan Sangeetha},
  doi          = {10.1016/j.artmed.2021.102008},
  journal      = {Artificial Intelligence in Medicine},
  month        = {2},
  pages        = {102008},
  shortjournal = {Artif. Intell. Med.},
  title        = {BertMCN: Mapping colloquial phrases to standard medical concepts using BERT and highway network},
  volume       = {112},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Objective and automated assessment of surgical technical
skills with IoT systems: A systematic literature review.
<em>ARTMED</em>, <em>112</em>, 102007. (<a
href="https://doi.org/10.1016/j.artmed.2020.102007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The assessment of surgical technical skills to be acquired by novice surgeons has been traditionally done by an expert surgeon and is therefore of a subjective nature. Nevertheless, the recent advances on IoT (Internet of Things), the possibility of incorporating sensors into objects and environments in order to collect large amounts of data, and the progress on machine learning are facilitating a more objective and automated assessment of surgical technical skills. This paper presents a systematic literature review of papers published after 2013 discussing the objective and automated assessment of surgical technical skills. 101 out of an initial list of 537 papers were analyzed to identify: 1) the sensors used; 2) the data collected by these sensors and the relationship between these data, surgical technical skills and surgeons’ levels of expertise; 3) the statistical methods and algorithms used to process these data; and 4) the feedback provided based on the outputs of these statistical methods and algorithms. Particularly, 1) mechanical and electromagnetic sensors are widely used for tool tracking, while inertial measurement units are widely used for body tracking; 2) path length, number of sub-movements, smoothness, fixation, saccade and total time are the main indicators obtained from raw data and serve to assess surgical technical skills such as economy, efficiency, hand tremor, or mind control, and distinguish between two or three levels of expertise (novice/intermediate/advanced surgeons); 3) SVM (Support Vector Machines) and Neural Networks are the preferred statistical methods and algorithms for processing the data collected, while new opportunities are opened up to combine various algorithms and use deep learning; and 4) feedback is provided by matching performance indicators and a lexicon of words and visualizations, although there is considerable room for research in the context of feedback and visualizations, taking, for example, ideas from learning analytics.},
  archive      = {J_ARTMED},
  author       = {Pablo Castillo-Segura and Carmen Fernández-Panadero and Carlos Alario-Hoyos and Pedro J. Muñoz-Merino and Carlos Delgado Kloos},
  doi          = {10.1016/j.artmed.2020.102007},
  journal      = {Artificial Intelligence in Medicine},
  month        = {2},
  pages        = {102007},
  shortjournal = {Artif. Intell. Med.},
  title        = {Objective and automated assessment of surgical technical skills with IoT systems: A systematic literature review},
  volume       = {112},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A deep-learning-based unsupervised model on esophageal
manometry using variational autoencoder. <em>ARTMED</em>, <em>112</em>,
102006. (<a href="https://doi.org/10.1016/j.artmed.2020.102006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High-resolution manometry (HRM) is the primary method for diagnosing esophageal motility disorders and its interpretation and classification are based on variables (features) from data of each swallow. Modeling and learning the semantics directly from raw swallow data could not only help automate the feature extraction, but also alleviate the bias from pre-defined features. With more than 32-thousand raw swallow data, a generative model using the approach of variational auto-encoder (VAE) was developed, which, to our knowledge, is the first deep-learning-based unsupervised model on raw esophageal manometry data. The VAE model was reformulated to include different types of loss motivated by domain knowledge and tuned with different hyper-parameters. Training of the VAE model was found sensitive on the learning rate and hence the evidence lower bound objective (ELBO) was further scaled by the data dimension. Case studies showed that the dimensionality of latent space have a big impact on the learned semantics. In particular, cases with 4-dimensional latent variables were found to encode various physiologically meaningful contraction patterns, including strength, propagation pattern as well as sphincter relaxation. Cases with so-called hybrid L2 loss seemed to better capture the coherence of contraction/relaxation transition. Discriminating capability was further evaluated using simple linear discriminative analysis (LDA) on predicting swallow type and swallow pressurization, which yields clustering patterns consistent with clinical impression. The current work on modeling and understanding swallow-level data will guide the development of study-level models for automatic diagnosis as the next stage.},
  archive      = {J_ARTMED},
  author       = {Wenjun Kou and Dustin A. Carlson and Alexandra J. Baumann and Erica Donnan and Yuan Luo and John E. Pandolfino and Mozziyar Etemadi},
  doi          = {10.1016/j.artmed.2020.102006},
  journal      = {Artificial Intelligence in Medicine},
  month        = {2},
  pages        = {102006},
  shortjournal = {Artif. Intell. Med.},
  title        = {A deep-learning-based unsupervised model on esophageal manometry using variational autoencoder},
  volume       = {112},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A new framework for classification of multi-category hand
grasps using EMG signals. <em>ARTMED</em>, <em>112</em>, 102005. (<a
href="https://doi.org/10.1016/j.artmed.2020.102005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electromyogram (EMG) signals have had a great impact on many applications, including prosthetic or rehabilitation devices, human-machine interactions, clinical and biomedical areas. In recent years, EMG signals have been used as a popular tool to generate device control commands for rehabilitation equipment, such as robotic prostheses. This intention of this study was to design an EMG signal-based expert model for hand-grasp classification that could enhance prosthetic hand movements for people with disabilities. The study, thus, aimed to introduce an innovative framework for recognising hand movements using EMG signals. The proposed framework consists of logarithmic spectrogram-based graph signal (LSGS), AdaBoost k-means (AB-k-means) and an ensemble of feature selection (FS) techniques. First, the LSGS model is applied to analyse and extract the desirable features from EMG signals. Then, to assist in selecting the most influential features, an ensemble FS is added to the design. Finally, in the classification phase, a novel classification model, named AB-k-means, is developed to classify the selected EMG features into different hand grasps. The proposed hybrid model, LSGS-based scheme is evaluated with a publicly available EMG hand movement dataset from the UCI repository. Using the same dataset, the LSGS-AB-k-means design model is also benchmarked with several classifications including the state-of-the-art algorithms. The results demonstrate that the proposed model achieves a high classification rate and demonstrates superior results compared to several previous research works. This study, therefore, establishes that the proposed model can accurately classify EMG hand grasps and can be implemented as a control unit with low cost and a high classification rate.},
  archive      = {J_ARTMED},
  author       = {Firas Sabar Miften and Mohammed Diykh and Shahab Abdulla and Siuly Siuly and Jonathan H. Green and Ravinesh C. Deo},
  doi          = {10.1016/j.artmed.2020.102005},
  journal      = {Artificial Intelligence in Medicine},
  month        = {2},
  pages        = {102005},
  shortjournal = {Artif. Intell. Med.},
  title        = {A new framework for classification of multi-category hand grasps using EMG signals},
  volume       = {112},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Transatlantic transferability of a new reinforcement
learning model for optimizing haemodynamic treatment for critically ill
patients with sepsis. <em>ARTMED</em>, <em>112</em>, 102003. (<a
href="https://doi.org/10.1016/j.artmed.2020.102003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, reinforcement learning (RL) has gained traction in the healthcare domain. In particular, RL methods have been explored for haemodynamic optimization of septic patients in the Intensive Care Unit. Most hospitals however, lack the data and expertise for model development, necessitating transfer of models developed using external datasets. This approach assumes model generalizability across different patient populations, the validity of which has not previously been tested. In addition, there is limited knowledge on safety and reliability. These challenges need to be addressed to further facilitate implementation of RL models in clinical practice. We developed and validated a new reinforcement learning model for hemodynamic optimization in sepsis on the MIMIC intensive care database from the USA using a dueling double deep Q network. We then transferred this model to the European AmsterdamUMCdb intensive care database. T-Distributed Stochastic Neighbor Embedding and Sequential Organ Failure Assessment scores were used to explore the differences between the patient populations. We apply off-policy policy evaluation methods to quantify model performance. In addition, we introduce and apply a novel deep policy inspection to analyse how the optimal policy relates to the different phases of sepsis and sepsis treatment to provide interpretable insight in order to assess model safety and reliability. The off-policy evaluation revealed that the optimal policy outperformed the physician policy on both datasets despite marked differences between the two patient populations and physician&#39;s policies. Our novel deep policy inspection method showed insightful results and unveiled that the model could initiate therapy adequately and adjust therapy intensity to illness severity and disease progression which indicated safe and reliable model behaviour. Compared to current physician behavior, the developed policy prefers a more liberal use of vasopressors with a more restrained use of fluid therapy in line with previous work. We created a reinforcement learning model for optimal bedside hemodynamic management and demonstrated model transferability between populations from the USA and Europe for the first time. We proposed new methods for deep policy inspection integrating expert domain knowledge. This is expected to facilitate progression to bedside clinical decision support for the treatment of critically ill patients.},
  archive      = {J_ARTMED},
  author       = {Luca Roggeveen and Ali el Hassouni and Jonas Ahrendt and Tingjie Guo and Lucas Fleuren and Patrick Thoral and Armand RJ Girbes and Mark Hoogendoorn and Paul WG Elbers},
  doi          = {10.1016/j.artmed.2020.102003},
  journal      = {Artificial Intelligence in Medicine},
  month        = {2},
  pages        = {102003},
  shortjournal = {Artif. Intell. Med.},
  title        = {Transatlantic transferability of a new reinforcement learning model for optimizing haemodynamic treatment for critically ill patients with sepsis},
  volume       = {112},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). MitPlan: A planning approach to mitigating concurrently
applied clinical practice guidelines. <em>ARTMED</em>, <em>112</em>,
102002. (<a href="https://doi.org/10.1016/j.artmed.2020.102002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the population ages, patients’ complexity and the scope of their care is increasing. Over 60% of the population is 65 years of age or older and suffers from multi-morbidity, which is associated with two times as many patient-physician encounters. Yet clinical practice guidelines (CPGs) are developed to treat a single disease. To reconcile these two competing issues, previously we developed a framework for mitigation, i.e., identifying and addressing adverse interactions in multi-morbid patients managed according to multiple CPGs. That framework relies on first-order logic (FOL) to represent CPGs and secondary medical knowledge and FOL theorem proving to establish valid patient management plans. In the work presented here, we leverage our earlier research and simplify the mitigation process by representing it as a planning problem using the Planning Domain Definition Language (PDDL). This new framework, called MitPlan, identifies and addresses adverse interactions using durative planning actions that embody clinical actions (including medication administration and patient testing), supports a physician-defined length of planning horizons, and optimizes plans based on patient preferences and action costs. It supports a variety of criteria when developing management plans, including the total cost of prescribed treatment and the cost of the revisions to be introduced. The solution to MitPlan&#39;s planning problem is a sequence of timed actions that are easy to interpret when creating a management plan. We demonstrate MitPlan&#39;s capabilities using illustrative and clinical case studies.},
  archive      = {J_ARTMED},
  author       = {Martin Michalowski and Szymon Wilk and Wojtek Michalowski and Marc Carrier},
  doi          = {10.1016/j.artmed.2020.102002},
  journal      = {Artificial Intelligence in Medicine},
  month        = {2},
  pages        = {102002},
  shortjournal = {Artif. Intell. Med.},
  title        = {MitPlan: A planning approach to mitigating concurrently applied clinical practice guidelines},
  volume       = {112},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Estimating sparse functional connectivity networks via
hyperparameter-free learning model. <em>ARTMED</em>, <em>111</em>,
102004. (<a href="https://doi.org/10.1016/j.artmed.2020.102004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Functional connectivity networks (FCNs) provide a potential way for understanding the brain organizational patterns and diagnosing neurological diseases . Currently, researchers have proposed many methods for FCN construction, among which the most classic example is Pearson&#39;s correlation (PC). Despite its simplicity and popularity, PC always results in dense FCNs, and thus a thresholding strategy is usually needed in practice to sparsify the estimated FCNs prior to the network analysis, which undoubtedly causes the problem of threshold parameter selection. As an alternative to PC, sparse representation (SR) can directly generate sparse FCNs due to the l 1 regularizer in the estimation model. However, similar to the thresholding scheme used in PC, it is also challenging to determine suitable values for the regularization parameter in SR. To circumvent the difficulty of parameter selection involved in these traditional methods, we propose a hyperparameter-free method for FCN construction based on the global representation among fMRI time courses. Interestingly, the proposed method can automatically generate sparse FCNs, without any thresholding or regularization parameters. To verify the effectiveness of the proposed method, we conduct experiments to identify subjects with mild cognitive impairment (MCI) and Autism spectrum disorder (ASD) from normal controls (NCs) based on the estimated FCNs. Experimental results on two benchmark databases demonstrate that the achieved classification performance of our proposed scheme is comparable to four conventional methods.},
  archive      = {J_ARTMED},
  author       = {Lei Sun and Yanfang Xue and Yining Zhang and Lishan Qiao and Limei Zhang and Mingxia Liu},
  doi          = {10.1016/j.artmed.2020.102004},
  journal      = {Artificial Intelligence in Medicine},
  month        = {1},
  pages        = {102004},
  shortjournal = {Artif. Intell. Med.},
  title        = {Estimating sparse functional connectivity networks via hyperparameter-free learning model},
  volume       = {111},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). DRNet: Segmentation and localization of optic disc and fovea
from diabetic retinopathy image. <em>ARTMED</em>, <em>111</em>, 102001.
(<a href="https://doi.org/10.1016/j.artmed.2020.102001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In modern ophthalmology, automated Computer-aided Screening Tools (CSTs) are crucial non-intrusive diagnosis methods, where an accurate segmentation of Optic Disc (OD) and localization of OD and Fovea centers are substantial integral parts. However, designing such an automated tool remains challenging due to small dataset sizes, inconsistency in spatial, texture, and shape information of the OD and Fovea, and the presence of different artifacts. This article proposes an end-to-end encoder-decoder network, named DRNet, for the segmentation and localization of OD and Fovea centers. In our DRNet, we propose a skip connection, named residual skip connection, for compensating the spatial information lost due to pooling in the encoder. Unlike the earlier skip connection in the UNet, the proposed skip connection does not directly concatenate low-level feature maps from the encoder&#39;s beginning layers with the corresponding same scale decoder. We validate DRNet using different publicly available datasets, such as IDRiD, RIMONE, DRISHTI-GS, and DRIVE for OD segmentation; IDRiD and HRF for OD center localization; and IDRiD for Fovea center localization. The proposed DRNet, for OD segmentation, achieves mean Intersection over Union (mIoU) of 0.845, 0.901, 0.933, and 0.920 for IDRiD, RIMONE, DRISHTI-GS, and DRIVE, respectively. Our OD segmentation result, in terms of mIoU, outperforms the state-of-the-art results for IDRiD and DRIVE datasets, whereas it outperforms state-of-the-art results concerning mean sensitivity for RIMONE and DRISHTI-GS datasets. The DRNet localizes the OD center with mean Euclidean Distance (mED) of 20.23 and 13.34 pixels, respectively, for IDRiD and HRF datasets; it outperforms the state-of-the-art by 4.62 pixels for IDRiD dataset. The DRNet also successfully localizes the Fovea center with mED of 41.87 pixels for the IDRiD dataset, outperforming the state-of-the-art by 1.59 pixels for the same dataset. As the proposed DRNet exhibits excellent performance even with limited training data and without intermediate intervention, it can be employed to design a better-CST system to screen retinal images. Our source codes, trained models, and ground-truth heatmaps for OD and Fovea center localization will be made publicly available upon publication at GitHub. 1},
  archive      = {J_ARTMED},
  author       = {Md. Kamrul Hasan and Md. Ashraful Alam and Md. Toufick E Elahi and Shidhartho Roy and Robert Martí},
  doi          = {10.1016/j.artmed.2020.102001},
  journal      = {Artificial Intelligence in Medicine},
  month        = {1},
  pages        = {102001},
  shortjournal = {Artif. Intell. Med.},
  title        = {DRNet: Segmentation and localization of optic disc and fovea from diabetic retinopathy image},
  volume       = {111},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). EPTs-TL: A two-level approach for efficient event prediction
in healthcare. <em>ARTMED</em>, <em>111</em>, 101999. (<a
href="https://doi.org/10.1016/j.artmed.2020.101999">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, the event prediction on time series (EPTs) was discussed as one of the important and interesting research trends that its usage is growing for taking proper decisions in the various sciences. In the real-world, time series event-based analysis can pose as one of the challenging prediction problems in healthcare, which have a direct impact and a key role in supporting health management. In this paper, an efficient approach of two-level (TL) is proposed to the EPTs problem in healthcare, which named EPTs-TL. At the first level, unseen time series data is predicted by using an enhanced hybrid model based on soft computing technology. Then, a new feature extraction-based method is proposed for fuzzy detection of future events in two-level. The EPTs -TL approach employed concepts of three components: weighting, fuzzy logic, and metaheuristics in two-level of the proposed approach. The empirical results demonstrate the excellent performance of the EPTs -TL approach in comparison to conventional prediction models in healthcare and medicine. Also, the proposed approach can be introduced as a strong tool to handle the complex and uncertain behaviors of time series, analyze unusual variations of those, forewarn the possible critical situations in the society, and fuzzy predict event in healthcare.},
  archive      = {J_ARTMED},
  author       = {Soheila Mehrmolaei},
  doi          = {10.1016/j.artmed.2020.101999},
  journal      = {Artificial Intelligence in Medicine},
  month        = {1},
  pages        = {101999},
  shortjournal = {Artif. Intell. Med.},
  title        = {EPTs-TL: A two-level approach for efficient event prediction in healthcare},
  volume       = {111},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Interactive medical image segmentation via a point-based
interaction. <em>ARTMED</em>, <em>111</em>, 101998. (<a
href="https://doi.org/10.1016/j.artmed.2020.101998">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to low tissue contrast, irregular shape, and large location variance, segmenting the objects from different medical imaging modalities ( e.g. , CT, MR) is considered as an important yet challenging task. In this paper, a novel method is presented for interactive medical image segmentation with the following merits. (1) Its design is fundamentally different from previous pure patch-based and image-based segmentation methods. It is observed that during delineation, the physician repeatedly check the intensity from area inside-object to outside-object to determine the boundary, which indicates that comparison in an inside-out manner is extremely important . Thus, the method innovatively models the segmentation task as learning the representation of bi-directional sequential patches, starting from (or ending in) the given central point of the object. This can be realized by the proposed ConvRNN network embedded with a gated memory propagation unit. (2) Unlike previous interactive methods (requiring bounding box or seed points), the proposed method only asks the physician to merely click on the rough central point of the object before segmentation, which could simultaneously enhance the performance and reduce the segmentation time. (3) The method is utilized in a multi-level framework for better performance. It has been systematically evaluated in three different segmentation tasks, including CT kidney tumor, MR prostate, and PROMISE12 challenge, showing promising results compared with state-of-the-art methods.},
  archive      = {J_ARTMED},
  author       = {Jian Zhang and Yinghuan Shi and Jinquan Sun and Lei Wang and Luping Zhou and Yang Gao and Dinggang Shen},
  doi          = {10.1016/j.artmed.2020.101998},
  journal      = {Artificial Intelligence in Medicine},
  month        = {1},
  pages        = {101998},
  shortjournal = {Artif. Intell. Med.},
  title        = {Interactive medical image segmentation via a point-based interaction},
  volume       = {111},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multichannel mixture models for time-series analysis and
classification of engagement with multiple health services: An
application to psychology and physiotherapy utilization patterns after
traffic accidents. <em>ARTMED</em>, <em>111</em>, 101997. (<a
href="https://doi.org/10.1016/j.artmed.2020.101997">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Motor vehicle accidents (MVA) represent a significant burden on health systems globally. Tens of thousands of people are injured in Australia every year and may experience significant disability. Associated economic costs are substantial. There is little literature on the health service utilization patterns of MVA patients. To fill this gap, this study has been designed to investigate temporal patterns of psychology and physiotherapy service utilization following transport-related injuries. De-identified compensation data was provided by the Australian Transport Accident Commission. Utilization of physiotherapy and psychology services was analysed. The datasets contained 788 psychology and 3115 physiotherapy claimants and 22,522 and 118,453 episodes of service utilization, respectively. 582 claimants used both services, and their data were preprocessed to generate multidimensional time series. Time series clustering was applied using a mixture of hidden Markov models to identify the main distinct patterns of service utilization. Combinations of hidden states and clusters were evaluated and optimized using the Bayesian information criterion and interpretability. Cluster membership was further investigated using static covariates and multinomial logistic regression, and classified using high-performing classifiers (extreme gradient boosting machine, random forest and support vector machine) with 5-fold cross-validation. Four clusters of claimants were obtained from the clustering of the time series of service utilization. Service volumes and costs increased progressively from clusters 1 to 4. Membership of cluster 1 was positively associated with nerve damage and negatively associated with severe ABI and spinal injuries. Cluster 3 was positively associated with severe ABI, brain/head injury and psychiatric injury. Cluster 4 was positively associated with internal injuries. The classifiers were capable of classifying cluster membership with moderate to strong performance (AUC: 0.62–0.96). The available time series of post-accident psychology and physiotherapy service utilization were coalesced into four clusters that were clearly distinct in terms of patterns of utilization. In addition, pre-treatment covariates allowed prediction of a claimant&#39;s post-accident service utilization with reasonable accuracy. Such results can be useful for a range of decision-making processes, including the design of interventions aimed at improving claimant care and recovery.},
  archive      = {J_ARTMED},
  author       = {Nazanin Esmaili and Quinlan D. Buchlak and Massimo Piccardi and Bernie Kruger and Federico Girosi},
  doi          = {10.1016/j.artmed.2020.101997},
  journal      = {Artificial Intelligence in Medicine},
  month        = {1},
  pages        = {101997},
  shortjournal = {Artif. Intell. Med.},
  title        = {Multichannel mixture models for time-series analysis and classification of engagement with multiple health services: An application to psychology and physiotherapy utilization patterns after traffic accidents},
  volume       = {111},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Individual tooth detection and identification from dental
panoramic x-ray images via point-wise localization and distance
regularization. <em>ARTMED</em>, <em>111</em>, 101996. (<a
href="https://doi.org/10.1016/j.artmed.2020.101996">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dental panoramic X-ray imaging is a popular diagnostic method owing to its very small dose of radiation. For an automated computer-aided diagnosis system in dental clinics, automatic detection and identification of individual teeth from panoramic X-ray images are critical prerequisites. In this study, we propose a point-wise tooth localization neural network by introducing a spatial distance regularization loss. The proposed network initially performs center point regression for all the anatomical teeth (i.e., 32 points), which automatically identifies each tooth. A novel distance regularization penalty is employed on the 32 points by considering L 2 L2 regularization loss of Laplacian on spatial distances. Subsequently, teeth boxes are individually localized using a multitask neural network on a patch basis. A multitask offset training is employed on the final output to improve the localization accuracy. Our method successfully localizes not only the existing teeth but also missing teeth; consequently, highly accurate detection and identification are achieved. The experimental results demonstrate that the proposed algorithm outperforms state-of-the-art approaches by increasing the average precision of teeth detection by 15.71 % compared to the best performing method. The accuracy of identification achieved a precision of 0.997 and recall value of 0.972. Moreover, the proposed network does not require any additional identification algorithm owing to the preceding regression of the fixed 32 points regardless of the existence of the teeth.},
  archive      = {J_ARTMED},
  author       = {Minyoung Chung and Jusang Lee and Sanguk Park and Minkyung Lee and Chae Eun Lee and Jeongjin Lee and Yeong-Gil Shin},
  doi          = {10.1016/j.artmed.2020.101996},
  journal      = {Artificial Intelligence in Medicine},
  month        = {1},
  pages        = {101996},
  shortjournal = {Artif. Intell. Med.},
  title        = {Individual tooth detection and identification from dental panoramic X-ray images via point-wise localization and distance regularization},
  volume       = {111},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Training data enhancements for improving colonic polyp
detection using deep convolutional neural networks. <em>ARTMED</em>,
<em>111</em>, 101988. (<a
href="https://doi.org/10.1016/j.artmed.2020.101988">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Over the last years, the most relevant results in the context of polyp detection were achieved through deep learning techniques. However, the most common obstacles in this field are the small datasets with a reduced number of samples and the lack of data variability. This paper describes a method to reduce this limitation and improve polyp detection results using publicly available colonoscopic datasets. To address this issue, we increased the number and variety of images from the original dataset. Our method consists on adding polyps to the dataset images. The developed algorithm performs a rigorous selection of the best region within the image to receive the polyp. This procedure preserves the realistic features of the images while creating more diverse samples for training purposes. Our method allows copying existing polyps to new non-polypoid target regions. We also develop a strategy to generate new and more varied polyps through generative adversarial neural networks. Hence, the developed approach enriches the training data, creating automatically new samples with their appropriate labels. We applied the proposed data enhancement over a colonic polyp dataset. Thus, we can assess the effectiveness of our approach through a Faster R-CNN detection model. Performance results show improvements over the polyp detections while reducing the false-negative rate. The experimental results also show better recall metrics in comparison with both the original training set and other studies in the literature. We demonstrate that our proposed method has the potential to increase the data variability and number of samples in a reduced polyp dataset, improving the polyp detection rate and recall values. These results open new possibilities for advancing the study and implementation of new methods to improve computer-assisted medical image analysis.},
  archive      = {J_ARTMED},
  author       = {Victor de Almeida Thomaz and Cesar A. Sierra-Franco and Alberto B. Raposo},
  doi          = {10.1016/j.artmed.2020.101988},
  journal      = {Artificial Intelligence in Medicine},
  month        = {1},
  pages        = {101988},
  shortjournal = {Artif. Intell. Med.},
  title        = {Training data enhancements for improving colonic polyp detection using deep convolutional neural networks},
  volume       = {111},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Overly optimistic prediction results on imbalanced data: A
case study of flaws and benefits when applying over-sampling.
<em>ARTMED</em>, <em>111</em>, 101987. (<a
href="https://doi.org/10.1016/j.artmed.2020.101987">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Information extracted from electrohysterography recordings could potentially prove to be an interesting additional source of information to estimate the risk on preterm birth. Recently, a large number of studies have reported near-perfect results to distinguish between recordings of patients that will deliver term or preterm using a public resource, called the Term/Preterm Electrohysterogram database. However, we argue that these results are overly optimistic due to a methodological flaw being made. In this work, we focus on one specific type of methodological flaw: applying over-sampling before partitioning the data into mutually exclusive training and testing sets. We show how this causes the results to be biased using two artificial datasets and reproduce results of studies in which this flaw was identified. Moreover, we evaluate the actual impact of over-sampling on predictive performance, when applied prior to data partitioning, using the same methodologies of related studies, to provide a realistic view of these methodologies’ generalization capabilities. We make our research reproducible by providing all the code under an open license.},
  archive      = {J_ARTMED},
  author       = {Gilles Vandewiele and Isabelle Dehaene and György Kovács and Lucas Sterckx and Olivier Janssens and Femke Ongenae and Femke De Backere and Filip De Turck and Kristien Roelens and Johan Decruyenaere and Sofie Van Hoecke and Thomas Demeester},
  doi          = {10.1016/j.artmed.2020.101987},
  journal      = {Artificial Intelligence in Medicine},
  month        = {1},
  pages        = {101987},
  shortjournal = {Artif. Intell. Med.},
  title        = {Overly optimistic prediction results on imbalanced data: A case study of flaws and benefits when applying over-sampling},
  volume       = {111},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A decision tree-initialised neuro-fuzzy approach for
clinical decision support. <em>ARTMED</em>, <em>111</em>, 101986. (<a
href="https://doi.org/10.1016/j.artmed.2020.101986">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Apart from the need for superior accuracy, healthcare applications of intelligent systems also demand the deployment of interpretable machine learning models which allow clinicians to interrogate and validate extracted medical knowledge. Fuzzy rule-based models are generally considered interpretable that are able to reflect the associations between medical conditions and associated symptoms, through the use of linguistic if-then statements. Systems built on top of fuzzy sets are of particular appealing to medical applications since they enable the tolerance of vague and imprecise concepts that are often embedded in medical entities such as symptom description and test results. They facilitate an approximate reasoning framework which mimics human reasoning and supports the linguistic delivery of medical expertise often expressed in statements such as ‘weight low’ or ‘glucose level high’ while describing symptoms. This paper proposes an approach by performing data-driven learning of accurate and interpretable fuzzy rule bases for clinical decision support. The approach starts with the generation of a crisp rule base through a decision tree learning mechanism, capable of capturing simple rule structures. The crisp rule base is then transformed into a fuzzy rule base, which forms the input to the framework of adaptive network-based fuzzy inference system (ANFIS), thereby further optimising the parameters of both rule antecedents and consequents. Experimental studies on popular medical data benchmarks demonstrate that the proposed work is able to learn compact rule bases involving simple rule antecedents, with statistically better or comparable performance to those achieved by state-of-the-art fuzzy classifiers.},
  archive      = {J_ARTMED},
  author       = {Tianhua Chen and Changjing Shang and Pan Su and Elpida Keravnou-Papailiou and Yitian Zhao and Grigoris Antoniou and Qiang Shen},
  doi          = {10.1016/j.artmed.2020.101986},
  journal      = {Artificial Intelligence in Medicine},
  month        = {1},
  pages        = {101986},
  shortjournal = {Artif. Intell. Med.},
  title        = {A decision tree-initialised neuro-fuzzy approach for clinical decision support},
  volume       = {111},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). EKNN: Ensemble classifier incorporating connectivity and
density into kNN with application to cancer diagnosis. <em>ARTMED</em>,
<em>111</em>, 101985. (<a
href="https://doi.org/10.1016/j.artmed.2020.101985">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the microarray-based approach for automated cancer diagnosis, the application of the traditional k -nearest neighbors k NN algorithm suffers from several difficulties such as the large number of genes (high dimensionality of the feature space) with many irrelevant genes (noise) relative to the small number of available samples and the imbalance in the size of the samples of the target classes. This research provides an ensemble classifier based on decision models derived from k NN that is applicable to problems characterized by imbalanced small size datasets. The proposed classification method is an ensemble of the traditional k NN algorithm and four novel classification models derived from it. The proposed models exploit the increase in density and connectivity using K 1 -nearest neighbors table (KNN-table) created during the training phase. In the density model, an unseen sample u is classified as belonging to a class t if it achieves the highest increase in density when this sample is added to it i.e. the unseen sample can replace more neighbors in the KNN-table for samples of class t than other classes. In the other three connectivity models, the mean and standard deviation of the distribution of the average, minimum as well the maximum distance to the K neighbors of the members of each class are computed in the training phase. The class t to which u achieves the highest possibility of belongness to its distribution is chosen, i.e. the addition of u to the samples of this class produces the least change to the distribution of the corresponding decision model for class t. Combining the predicted results of the four individual models along with traditional k NN makes the decision space more discriminative. With the help of the KNN-table which can be updated online in the training phase, an improved performance has been achieved compared to the traditional k NN algorithm with slight increase in classification time. The proposed ensemble method achieves significant increase in accuracy compared to the accuracy achieved using any of its base classifiers on Kentridge, GDS3257, Notterman, Leukemia and CNS datasets. The method is also compared to several existing ensemble methods and state of the art techniques using different dimensionality reduction techniques on several standard datasets. The results prove clear superiority of EKNN over several individual and ensemble classifiers regardless of the choice of the gene selection strategy.},
  archive      = {J_ARTMED},
  author       = {Mohamed A. Mahfouz and Amin Shoukry and Mohamed A. Ismail},
  doi          = {10.1016/j.artmed.2020.101985},
  journal      = {Artificial Intelligence in Medicine},
  month        = {1},
  pages        = {101985},
  shortjournal = {Artif. Intell. Med.},
  title        = {EKNN: Ensemble classifier incorporating connectivity and density into kNN with application to cancer diagnosis},
  volume       = {111},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Cartesian genetic programming for diagnosis of parkinson
disease through handwriting analysis: Performance vs. Interpretability
issues. <em>ARTMED</em>, <em>111</em>, 101984. (<a
href="https://doi.org/10.1016/j.artmed.2020.101984">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the last decades, early disease identification through non-invasive and automatic methodologies has gathered increasing interest from the scientific community. Among others, Parkinson&#39;s disease (PD) has received special attention in that it is a severe and progressive neuro-degenerative disease. As a consequence, early diagnosis would provide more effective and prompt care strategies, that cloud successfully influence patients’ life expectancy. However, the most performing systems implement the so called black-box approach, which do not provide explicit rules to reach a decision. This lack of interpretability, has hampered the acceptance of those systems by clinicians and their deployment on the field. In this context, we perform a thorough comparison of different machine learning (ML) techniques, whose classification results are characterized by different levels of interpretability. Such techniques were applied for automatically identify PD patients through the analysis of handwriting and drawing samples. Results analysis shows that white-box approaches, such as Cartesian Genetic Programming and Decision Tree, allow to reach a twofold goal: support the diagnosis of PD and obtain explicit classification models, on which only a subset of features (related to specific tasks) were identified and exploited for classification. Obtained classification models provide important insights for the design of non-invasive, inexpensive and easy to administer diagnostic protocols. Comparison of different ML approaches (in terms of both accuracy and interpretability) has been performed on the features extracted from the handwriting and drawing samples included in the publicly available PaHaW and NewHandPD datasets. The experimental findings show that the Cartesian Genetic Programming outperforms the white-box methods in accuracy and the black-box ones in interpretability.},
  archive      = {J_ARTMED},
  author       = {A. Parziale and R. Senatore and A. Della Cioppa and A. Marcelli},
  doi          = {10.1016/j.artmed.2020.101984},
  journal      = {Artificial Intelligence in Medicine},
  month        = {1},
  pages        = {101984},
  shortjournal = {Artif. Intell. Med.},
  title        = {Cartesian genetic programming for diagnosis of parkinson disease through handwriting analysis: Performance vs. interpretability issues},
  volume       = {111},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Detection-based prioritisation: Framework of
multi-laboratory characteristics for asymptomatic COVID-19 carriers
based on integrated entropy–TOPSIS methods. <em>ARTMED</em>,
<em>111</em>, 101983. (<a
href="https://doi.org/10.1016/j.artmed.2020.101983">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Corona virus (COVID) has rapidly gained a foothold and caused a global pandemic. Particularists try their best to tackle this global crisis. New challenges outlined from various medical perspectives may require a novel design solution. Asymptomatic COVID-19 carriers show different health conditions and no symptoms; hence, a differentiation process is required to avert the risk of chronic virus carriers. Laboratory criteria and patient dataset are compulsory in constructing a new framework. Prioritisation is a popular topic and a complex issue for patients with COVID-19, especially for asymptomatic carriers due to multi-laboratory criteria, criterion importance and trade-off amongst these criteria. This study presents new integrated decision-making framework that handles the prioritisation of patients with COVID-19 and can detect the health conditions of asymptomatic carriers. The methodology includes four phases. Firstly, eight important laboratory criteria are chosen using two feature selection approaches. Real and simulation datasets from various medical perspectives are integrated to produce a new dataset involving 56 patients with different health conditions and can be used to check asymptomatic cases that can be detected within the prioritisation configuration. The first phase aims to develop a new decision matrix depending on the intersection between ‘multi-laboratory criteria’ and ‘COVID-19 patient list’. In the second phase, entropy is utilised to set the objective weight, and TOPSIS is adapted to prioritise patients in the third phase. Finally, objective validation is performed. The patients are prioritised based on the selected criteria in descending order of health situation starting from the worst to the best. The proposed framework can discriminate among mild, serious and critical conditions and put patients in a queue while considering asymptomatic carriers. Validation findings revealed that the patients are classified into four equal groups and showed significant differences in their scores, indicating the validity of ranking. This study implies and discusses the numerous benefits of the suggested framework in detecting/recognising the health condition of patients prior to discharge, supporting the hospitalisation characteristics, managing patient care and optimising clinical prediction rule.},
  archive      = {J_ARTMED},
  author       = {A.S. Albahri and Rula A. Hamid and O.S. Albahri and A.A. Zaidan},
  doi          = {10.1016/j.artmed.2020.101983},
  journal      = {Artificial Intelligence in Medicine},
  month        = {1},
  pages        = {101983},
  shortjournal = {Artif. Intell. Med.},
  title        = {Detection-based prioritisation: Framework of multi-laboratory characteristics for asymptomatic COVID-19 carriers based on integrated Entropy–TOPSIS methods},
  volume       = {111},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Using interpretability approaches to update “black-box”
clinical prediction models: An external validation study in nephrology.
<em>ARTMED</em>, <em>111</em>, 101982. (<a
href="https://doi.org/10.1016/j.artmed.2020.101982">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite advances in machine learning-based clinical prediction models, only few of such models are actually deployed in clinical contexts. Among other reasons, this is due to a lack of validation studies. In this paper, we present and discuss the validation results of a machine learning model for the prediction of acute kidney injury in cardiac surgery patients initially developed on the MIMIC-III dataset when applied to an external cohort of an American research hospital. To help account for the performance differences observed, we utilized interpretability methods based on feature importance, which allowed experts to scrutinize model behavior both at the global and local level, making it possible to gain further insights into why it did not behave as expected on the validation cohort. The knowledge gleaned upon derivation can be potentially useful to assist model update during validation for more generalizable and simpler models. We argue that interpretability methods should be considered by practitioners as a further tool to help explain performance differences and inform model update in validation studies.},
  archive      = {J_ARTMED},
  author       = {Harry Freitas da Cruz and Boris Pfahringer and Tom Martensen and Frederic Schneider and Alexander Meyer and Erwin Böttinger and Matthieu-P. Schapranow},
  doi          = {10.1016/j.artmed.2020.101982},
  journal      = {Artificial Intelligence in Medicine},
  month        = {1},
  pages        = {101982},
  shortjournal = {Artif. Intell. Med.},
  title        = {Using interpretability approaches to update “black-box” clinical prediction models: An external validation study in nephrology},
  volume       = {111},
  year         = {2021},
}
</textarea>
</details></li>
</ul>

</body>
</html>
