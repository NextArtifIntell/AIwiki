<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>COMCOM_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="comcom---318">COMCOM - 318</h2>
<ul>
<li><details>
<summary>
(2021). Constriction factor particle swarm optimization based load
balancing and cell association for 5G heterogeneous networks.
<em>COMCOM</em>, <em>180</em>, 328–337. (<a
href="https://doi.org/10.1016/j.comcom.2021.10.021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapidly growing traffic demand, the cellular industry is moving toward heterogeneity to fulfill the heavy traffic requirement. The existing heterogeneous networks are comprised of the Long-Term Evolution (LTE), LTE-Advanced (LTE-A), and other compatible access technologies. It has been identified that due to the shortage of capacity, cell performance can deteriorate. To deal with users’ requirements, the 5G heterogeneous network architectures comprising LTE-advanced access technology with the combination of comparatively low configured small base stations , and macro eNodeBs (MeNB) have been extended as a solution. Therefore, operators have introduced the 5G with the existing LTE Advanced Heterogeneous Network (5GLHN) where small cells such as Home eNodeBs (HeNBs) are deployed overlapping with the conventional macro eNodeB (MeNB). However, in highly dense and closely compacted 5GLHNs, the cell capacity can still be lower than what is on-demand, thus affecting the system throughput. This article proposes a framework to maximize the throughput in 5GLHNs through a Constriction Factor Particle Swarm Optimization (CFPSO) technique of cell association and load-balancing algorithm to enhance the throughput of the 5GLHN. The proposed approach is designed to offload the traffic of MeNB Users (MUEs) to the small cells (HeNBs). The convergence, cumulative distribution function of the UEs rate, average throughput, and allocation time are analyzed to evaluate the performance of the proposed CFPSO approach. Simulation results reveal that the throughput of the proposed approach is improved by up to 44.08\% of the existing index-based approach and by 94.20\% of the existing Matching with Minimum Quota (MMQ) approach.},
  archive      = {J_COMCOM},
  author       = {Mohammad Kamrul Hasan and Teong Chee Chuah and Ayman A. El-Saleh and Muhammad Shafiq and Shoaib Ahmed Shaikh and Shayla Islam and Moez Krichen},
  doi          = {10.1016/j.comcom.2021.10.021},
  journal      = {Computer Communications},
  pages        = {328-337},
  shortjournal = {Comput. Commun.},
  title        = {Constriction factor particle swarm optimization based load balancing and cell association for 5G heterogeneous networks},
  volume       = {180},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). DPLBAnt: Improved load balancing technique based on
detection and rerouting of elephant flows in software-defined networks.
<em>COMCOM</em>, <em>180</em>, 315–327. (<a
href="https://doi.org/10.1016/j.comcom.2021.10.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traffic management in software-defined networks (SDNs) is critical for efficient bandwidth utilization and resource provisioning . Recent works on SDN load balancing (LB) have focused on identifying and rerouting elephant flows (EFs) for effective bandwidth usage. These techniques have some limitations, such as using source-to-destination hop count as the primary rerouting metric and not differentiating the types of flow that result in frequent resource conflicts when handling EF with long-lived bandwidth. Besides, current EF detection techniques use predefined bandwidth-use thresholds that cannot adapt to the ever-changing traffic condition. Also, detecting EF on switches results in high controller-switch bandwidth and high EF detection time. This study presents an ant colony optimization-based technique for rerouting EFs while considering load-balancing in the SDN links. This technique, called DPLBAnt, is formulated as a shortest-path problem in SDN that can alleviate the high controller-switch load. The proposed technique first detects EF by using a pair of classifiers on both SDN controller and switches. Most EF candidates are sifted on the switches, resulting in accurate and efficient detection of EF. Then, DPLBAnt obtains the global state of the SDN from which the most optimal paths for congested links are retrieved, and EF are redirected accordingly. The performance of the proposed DPLBAnt has been extensively simulated. Results indicate its superior performance over Equal-Cost Multi-Path (ECMP) and FlowSeer techniques in terms of average end-to-end delay (54\% and 7.9\% better), average network throughput ( 3 . 5 × 3.5× and 1 . 5 × 1.5× better), and average packet loss (18\% and 10\% better) respectively. The overall performance indicates that the proposed LB technique based on detection and rerouting of EFs can improve SDN’s overall performance.},
  archive      = {J_COMCOM},
  author       = {Mosab Hamdan and Suleman Khan and Ahmed Abdelaziz and Shahidatul Sadiah and Nasir Shaikh-Husin and Sattam Al Otaibi and Carsten Maple and M.N. Marsono},
  doi          = {10.1016/j.comcom.2021.10.013},
  journal      = {Computer Communications},
  pages        = {315-327},
  shortjournal = {Comput. Commun.},
  title        = {DPLBAnt: Improved load balancing technique based on detection and rerouting of elephant flows in software-defined networks},
  volume       = {180},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A markov chain-based data dissemination protocol for
vehicular ad hoc networks. <em>COMCOM</em>, <em>180</em>, 303–314. (<a
href="https://doi.org/10.1016/j.comcom.2021.10.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Enhancing road safety and offering infotainment services are of utmost importance to today’s Intelligent Transport System (ITS). Technically speaking, an ITS is based on self-organizing wireless networks, known as vehicular ad hoc networks (VANETs). In the latter, mobile vehicles can track, compile and share reports on-road travel, driving conditions, and threats, for example, road accidents , in real-time. The spread of such data in VANET would actually improve road safety and driving comfort. In this regard, designing efficient data dissemination protocols in VANET has become a pivotal issue, attracting the interest of academic researchers, networking experts, and automotive companies. This paper introduces a new adaptive geocast data dissemination protocol called Markov Chain-based data Dissemination Protocol (MCDP). MCDP relies on the forward-if-relevant principle to dynamically determine the Zone Of Relevance (ZOR) of the event. We consider the event worth enough for a vehicle whenever there is a high probability that it will meet the event location shortly. Indeed, we introduce a mathematical model to manage vehicle mobility in the road network . Besides, we design a new method for accurately assessing the event relevance to the receiving vehicle. Simulation results underscore MCDP outperforms the pioneering baseline protocols in terms of effectiveness and efficiency.},
  archive      = {J_COMCOM},
  author       = {Taoufik Yeferny and Sadok Ben Yahia},
  doi          = {10.1016/j.comcom.2021.10.001},
  journal      = {Computer Communications},
  pages        = {303-314},
  shortjournal = {Comput. Commun.},
  title        = {A markov chain-based data dissemination protocol for vehicular ad hoc networks},
  volume       = {180},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Test case prioritization based on artificial fish school
algorithm. <em>COMCOM</em>, <em>180</em>, 295–302. (<a
href="https://doi.org/10.1016/j.comcom.2021.09.014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Software testing is considered as an essential and critical part of the software development process. To improve the efficiency of software testing, the test case prioritization (TCP) technique is usually used to preprocess the test case set, which is formulated as a single-objective or multiple-objective optimization problem and solved by swarm intelligence algorithms. In this paper, we adopted one of the state-of-art swarm intelligence algorithms — Artificial Fish School Algorithm to solve the TCP problem. Specifically, the coding method of artificial fish school was designed in combination with the test case set; the Average Percentage of Test-point Coverage and Effective Execution Time were selected to optimize the design of clustering behavior, foraging behavior and tail-chasing behavior of artificial fish school; the optimal solution was found by population iteration. Empirical evaluation was conducted to analyze the performance of the proposed method. Comparison experiments were also carried out, and the experimental results showed that in terms of both single-objective and multiple-objective, the Artificial Fish School Algorithm could better solve the TCP problems and improve the efficiency of software testing.},
  archive      = {J_COMCOM},
  author       = {Ying Xing and Xingde Wang and Qianpeng Shen},
  doi          = {10.1016/j.comcom.2021.09.014},
  journal      = {Computer Communications},
  pages        = {295-302},
  shortjournal = {Comput. Commun.},
  title        = {Test case prioritization based on artificial fish school algorithm},
  volume       = {180},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Smart stochastic routing for 6G-enabled massive internet of
things. <em>COMCOM</em>, <em>180</em>, 284–294. (<a
href="https://doi.org/10.1016/j.comcom.2021.09.015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Faster and energy-efficient data transmission is desired for massive Internet of Things (IoT) applications in sixth-generation networks. In such high speed networks , providing reliable data delivery with low delay, while maintaining energy-efficiency, is a challenging task. In this paper, a deep learning-based stochastic routing approach, called smart stochastic routing (SSR), is presented to address this challenge. SSR takes into account reliability, delays due to transmission, reception and processing of the neighbors’ information, and energy consumption and remaining energy of IoT devices. Through our proposed mathematical model, a dataset is generated to train a deep neural network , which predicts the best routing path from source to destination and achieves substantial accuracy over the mathematically generated dataset. Through simulations, we show the efficacy of SSR over conventional stochastic routing in terms of reduced energy consumption and expected delivery delay.},
  archive      = {J_COMCOM},
  author       = {Ghulam Abbas and Ziaul Haq Abbas and Zaiwar Ali and Muhammad Shahwar Asad and Uttam Ghosh and Muhammad Bilal},
  doi          = {10.1016/j.comcom.2021.09.015},
  journal      = {Computer Communications},
  pages        = {284-294},
  shortjournal = {Comput. Commun.},
  title        = {Smart stochastic routing for 6G-enabled massive internet of things},
  volume       = {180},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Deep q-learning enabled joint optimization of mobile edge
computing multi-level task offloading. <em>COMCOM</em>, <em>180</em>,
271–283. (<a
href="https://doi.org/10.1016/j.comcom.2021.09.028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In a mobile edge computing (MEC) network, mobile devices could selectively offload tasks to the edge server(s) to save time and energy. However, we should consider many dynamic factors in task offloading optimization, which increases the complexity of this problem. The traditional optimization approaches could require solving complex models to derive the optimal solution. This type of optimization problems are often NP-hard and will cause a considerable overhead on optimization. In contrast, a well-trained empirical model, such as an artificial neural network could be more efficient in decision making. In this research, considering the potential uneven spatial distribution of mobile devices in a MEC network with multiple wireless edge gateways, we allow an edge gateway to offload tasks to a nearby edge gateway further. We propose a deep Q-learning-based joint optimization approach for both device-level and edge-level task offloading . We also design a centralized mathematical programming solution for exploring the optimal trade-off performance. Simulation results show that the proposed approach achieves a satisfactory task delay performance and a better trade-off between the task delay and the energy consumption on tasks.},
  archive      = {J_COMCOM},
  author       = {Peizhi Yan and Salimur Choudhury},
  doi          = {10.1016/j.comcom.2021.09.028},
  journal      = {Computer Communications},
  pages        = {271-283},
  shortjournal = {Comput. Commun.},
  title        = {Deep Q-learning enabled joint optimization of mobile edge computing multi-level task offloading},
  volume       = {180},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Demystifying frame aggregation in 802.11 networks:
Understanding and approximating optimality. <em>COMCOM</em>,
<em>180</em>, 259–270. (<a
href="https://doi.org/10.1016/j.comcom.2021.09.019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {MAC-layer frame aggregation has significantly improved the efficiency of IEEE 802.11n and 802.11ac networks by placing multiple MAC-layer data units in a large PHY-layer frame. In this paper, we focus on finding the optimal length of an Aggregated MAC Protocol Data Unit (A-MPDU) in order to maximize throughput. In theory, larger A-MPDUs amortize overheads over more bits and therefore increase throughput. However in practice, throughput can be negatively impacted if too many frames are aggregated, due to higher error rates at the end of A-MPDUs. Determining the optimal number of subframes is challenging because error rates can be higher in the later part of the A-MPDU which change with factors such as mobility, speed and transmission rate. Additionally, there are dependencies between consecutive A-MPDUs due to software retransmissions . We develop a model of A-MPDU frame aggregation and use it to design a statistically optimal algorithm. Using our understanding of that algorithm we develop a standard compliant, Practical, Near-Optimal Frame Aggregation algorithm (PNOFA). Our trace-based evaluation shows that across a variety of devices and scenarios PNOFA outperforms existing state-of-the-art algorithms and obtains throughputs that are within 97\% of those obtained using the statistically optimal algorithm. Furthermore, we implement PNOFA as a user-space process on an 802.11ac Wave 2, Google Wifi access point. We find that when compared with the frame aggregation algorithm provided in the device’s Qualcomm IPQ 4019 chipset’s firmware, PNOFA increases average throughput by 17\% and 13\% for UDP and TCP traffic on the scenarios tested.},
  archive      = {J_COMCOM},
  author       = {Ali Abedi and Tim Brecht and Omid Abari},
  doi          = {10.1016/j.comcom.2021.09.019},
  journal      = {Computer Communications},
  pages        = {259-270},
  shortjournal = {Comput. Commun.},
  title        = {Demystifying frame aggregation in 802.11 networks: Understanding and approximating optimality},
  volume       = {180},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Robustness analysis of DNS paths and web access paths in
public administration websites. <em>COMCOM</em>, <em>180</em>, 243–258.
(<a href="https://doi.org/10.1016/j.comcom.2021.09.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Attacks at the naming or the routing infrastructure of the Internet have long become a reality and one single such attack has the potential of affecting access to Internet-facing services in many organizations. An important question to address is assessing the potential impact of attacks of this sort on the web infrastructure of an entire nation . In this work we examine the dependence of a large set of public administration websites on DNS entities and autonomous systems of four different countries: Italy, Germany , UK and US. We collected the dependencies of those websites from DNS zones, nameservers, networks, autonomous systems , and assessed the potential global impact of localized attacks on those entities. We also analyzed the prevalence of such defensive technologies as BGP Route Origin Authorization, DNSSEC and HTTPS Strict Transport Security. Our analysis highlights the structural interdependencies within the web infrastructures of public interest and illustrates the corresponding open problems, issues whose relevance can only grow.},
  archive      = {J_COMCOM},
  author       = {Alberto Bartoli},
  doi          = {10.1016/j.comcom.2021.09.017},
  journal      = {Computer Communications},
  pages        = {243-258},
  shortjournal = {Comput. Commun.},
  title        = {Robustness analysis of DNS paths and web access paths in public administration websites},
  volume       = {180},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Hybrid beamforming NOMA for mmWave half-duplex UAV
relay-assisted B5G/6G IoT networks. <em>COMCOM</em>, <em>180</em>,
232–242. (<a
href="https://doi.org/10.1016/j.comcom.2021.09.025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile wireless data collection in beyond 5G (B5G)/6G cellular internet of things (IoT) networks can be achieved by unmanned aerial vehicle (UAV) with high flexible mobility and low cost. In this paper, a half-duplex UAV relay is exploited to improve the achievable rate of downlink millimeter-wave (mmWave) massive multi-user multiple-input and multiple-output (MU-MIMO) networks. To improve the spectrum efficiency and mitigate the inter-beam interference, the hybrid beamforming (HB) designs of the base station (BS), the UAV and multiusers are taken into account simultaneously. To maximize the achievable rate from the BS to the multiusers, a two-stage design approach which tries to design the two stages jointly by avoiding the loss of information is proposed. Assuming multiusers are alignment in different beams, the strong effective channel-based non-orthogonal multiple access (NOMA) in the power domain is employed to assign power efficiently for each user, thereby increasing the number of users. Simulation results validate the proposed HB-NOMA approach can achieve good achievable rate performance in both uniform linear array and uniform planar array .},
  archive      = {J_COMCOM},
  author       = {Jianhe Du and Yang Zhang and Yuanzhi Chen and Xingwang Li and Yuan Cheng and M.V. Rajesh},
  doi          = {10.1016/j.comcom.2021.09.025},
  journal      = {Computer Communications},
  pages        = {232-242},
  shortjournal = {Comput. Commun.},
  title        = {Hybrid beamforming NOMA for mmWave half-duplex UAV relay-assisted B5G/6G IoT networks},
  volume       = {180},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Edge and fog computing for IoT: A survey on current research
activities &amp; future directions. <em>COMCOM</em>, <em>180</em>,
210–231. (<a
href="https://doi.org/10.1016/j.comcom.2021.09.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Internet of Things (IoT) allows communication between devices, things, and any digital assets that send and receive data over a network without requiring interaction with a human. The main characteristic of IoT is the enormous quantity of data created by end-user’s devices that needs to be processed in a short time in the cloud. The current cloud-computing concept is not efficient to analyze very large data in a very short time and satisfy the users’ requirements. Analyzing the enormous quantity of data by the cloud will take a lot of time, which affects the quality of service (QoS) and negatively influences the IoT applications and the overall network performance. To overcome such challenges, a new architecture called edge computing — that allows to decentralize the process of data from the cloud to the network edge has been proposed to solve the problems occurred by using the cloud computing approach. Furthermore, edge computing supports IoT applications that require a short response time and consequently enhances the consumption of energy, resource utilization, etc. Motivated by the extensive research efforts in the edge computing and IoT applications, in this paper, we present a comprehensive review of edge and fog computing research in the IoT. We investigate the role of cloud, fog, and edge computing in the IoT environment. Subsequently, we cover in detail, different IoT use cases with edge and fog computing, the task scheduling in edge computing, the merger of software-defined networks (SDN) and network function virtualization (NFV) with edge computing, security and privacy efforts. Furthermore, the Blockchain in edge computing. Finally, we identify open research challenges and highlight future research directions.},
  archive      = {J_COMCOM},
  author       = {Mohammed Laroui and Boubakr Nour and Hassine Moungla and Moussa A. Cherif and Hossam Afifi and Mohsen Guizani},
  doi          = {10.1016/j.comcom.2021.09.003},
  journal      = {Computer Communications},
  pages        = {210-231},
  shortjournal = {Comput. Commun.},
  title        = {Edge and fog computing for IoT: A survey on current research activities &amp; future directions},
  volume       = {180},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Towards high quality mobile crowdsensing: Incentive
mechanism design based on fine-grained ability reputation.
<em>COMCOM</em>, <em>180</em>, 197–209. (<a
href="https://doi.org/10.1016/j.comcom.2021.09.026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile crowdsensing has become an efficient paradigm for performing large-scale sensing tasks. Many quality-aware incentive mechanisms for mobile crowdsensing have been proposed. However, most of them measure the data quality by one single metric from a specific perspective. Moreover, they usually use the real-time quality, which cannot provide sufficient incentive for the workers with long-term high quality. In this paper, we refine the generalized data quality into the fine-grained ability requirement. We present a mobile crowdsensing system to achieve the fine-grained quality control, and formulate the problem of maximizing the social cost such that the fine-grained ability requirement of all sensing tasks can be satisfied. To stimulate the workers with long-term high quality, we design two ability reputation systems to assess workers’ fine-grained abilities online. The incentive mechanism based on the reverse auction and fine-grained ability reputation system is proposed. We design a greedy algorithm to select the winners and determine the payment based on the bids and fine-grained ability reputation of workers. Through both rigorous theoretical analysis and extensive simulations, we demonstrate that the proposed mechanisms achieve computational efficiency, individual rationality , truthfulness, whitewashing proof, and guaranteed approximation . Moreover, the designed mechanisms show prominent advantage in terms of social cost and average ability achievement ratio.},
  archive      = {J_COMCOM},
  author       = {Zhuangye Luo and Jia Xu and Pengcheng Zhao and Dejun Yang and Lijie Xu and Jian Luo},
  doi          = {10.1016/j.comcom.2021.09.026},
  journal      = {Computer Communications},
  pages        = {197-209},
  shortjournal = {Comput. Commun.},
  title        = {Towards high quality mobile crowdsensing: Incentive mechanism design based on fine-grained ability reputation},
  volume       = {180},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Hybrid precoding design based on alternating optimization in
mmWave massive MIMO systems aided by intelligent reflecting surface.
<em>COMCOM</em>, <em>180</em>, 188–196. (<a
href="https://doi.org/10.1016/j.comcom.2021.09.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intelligent reflecting surface (IRS) offers a promising and revolutionizing solution to enhance spectrum and energy efficiency by leveraging massive low-cost passive elements that are able to reflect the incident signal with adjustable amplitude and phase. Different from the prior works focusing on MISO scenario, this paper considers the IRS-aided single-user mmWave massive MIMO systems. We formulate and solve new problems to maximize the spectral efficiency of the systems by jointly optimizing the active beamforming at both the base station and user equipment, as well as the passive beamforming at the IRS. To tackle this problem, we first give the closed-form solutions of active beamforming and passive beamforming in MISO scenario. Then, we divide the optimization problem into three sub-problems, and perform alternate optimization solutions in MIMO scenario. In addition, we analyze the performance of the proposed algorithms in more practical scenarios where each element of IRS can only take discrete phase-shift values and base station has imperfect CSI. Simulation results show that IRS-aided MIMO systems effectively improves the spectral efficiency and also verifies the superior performance of our proposed algorithms.},
  archive      = {J_COMCOM},
  author       = {Mingyang Cui and Weiliang Han and Datong Xu and Pan Zhao and Weixia Zou},
  doi          = {10.1016/j.comcom.2021.09.004},
  journal      = {Computer Communications},
  pages        = {188-196},
  shortjournal = {Comput. Commun.},
  title        = {Hybrid precoding design based on alternating optimization in mmWave massive MIMO systems aided by intelligent reflecting surface},
  volume       = {180},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Towards a reliable smart city through formal verification
and network analysis. <em>COMCOM</em>, <em>180</em>, 171–187. (<a
href="https://doi.org/10.1016/j.comcom.2021.09.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the immense increase of population density, many challenges facing organizations and governments. Thus, it has become mandatory to turn up our cities to be intelligent by introducing IoT and smart grids to build smart buildings , smart communication technologies, smart healthcare systems, smart transportation, etc. Smart cities guarantee the healthy living of indoor inhabitants by sensing, processing and controlling all possible indoor–outdoor measures. In this paper, we develop a framework that systematically builds a reliable and secure Smart City Model ( SCM ) to be integrated then exploited by the building information model (BIM). SCM encloses both physical and digital models which highlight smart buildings in particular. First, the proposed solution identifies and models SCM components including their appropriate architectures that are responsible for communication, extension, information flow, and protection. To ensure SCM functional and security requirements, we develop a sound hybrid approach that relies on formal methods and network analysis . Uppaal model checker is used to verify the satisfiability of the smart city requirements whereas Cooja is deployed to simulate the connectivity and the communication coverage of the developed SCM . The obtained results, in Uppaal, showed that the different implemented scenarios are satisfying the functional correctness and security policies. Moreover, the simulation through Cooja showed that how different obstacles and positions of nodes affect the communication coverage and the energy consumption regarding the deployed nodes. Experimentally, the effectiveness of the developed framework has been shown through practical scenarios that are difficult to model and analyze.},
  archive      = {J_COMCOM},
  author       = {Walid Miloud Dahmane and Samir Ouchani and Hafida Bouarfa},
  doi          = {10.1016/j.comcom.2021.09.006},
  journal      = {Computer Communications},
  pages        = {171-187},
  shortjournal = {Comput. Commun.},
  title        = {Towards a reliable smart city through formal verification and network analysis},
  volume       = {180},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Two-level discriminative speech emotion recognition model
with wave field dynamics: A personalized speech emotion recognition
method. <em>COMCOM</em>, <em>180</em>, 161–170. (<a
href="https://doi.org/10.1016/j.comcom.2021.09.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Presently available speech emotion recognition (SER) methods generally rely on a single SER model. Getting a higher accuracy of SER involves feature extraction method and model design scheme in the speech. However, the generalization performance of models is typically poor because the emotional features of different speakers can vary substantially. The present work addresses this issue by applying a two-level discriminative model to the SER task. The first level places an individual speaker within a specific speaker group according to the speaker’s characteristics. The second level constructs a personalized SER model for each group of speakers using the wave field dynamics model and a dual-channel general SER model. Two-level discriminative model are fused for implementing an ensemble learning scheme to achieve effective SER classification. The proposed method is demonstrated to provide higher SER accuracy in experiments based on interactive emotional dynamic motion capture (IEMOCAP) corpus and a custom-built SER corpus. In IEMOCAP corpus, the proposed model improves the recognition accuracy by 7\%. In custom-built SER corpus, both masked and unmasked speakers is employed to demonstrate that the proposed method maintains higher SER accuracy.},
  archive      = {J_COMCOM},
  author       = {Ning Jia and Chunjun Zheng},
  doi          = {10.1016/j.comcom.2021.09.013},
  journal      = {Computer Communications},
  pages        = {161-170},
  shortjournal = {Comput. Commun.},
  title        = {Two-level discriminative speech emotion recognition model with wave field dynamics: A personalized speech emotion recognition method},
  volume       = {180},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A decentralized framework for device authentication and data
security in the next generation internet of medical things.
<em>COMCOM</em>, <em>180</em>, 146–160. (<a
href="https://doi.org/10.1016/j.comcom.2021.09.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Internet of Things (IoT) applications have gained a huge momentum and have spanned across all domains adding innovations to the prevailing solutions. The IoT networks generate enormous data comprising meteorological information, patient critical body parameters, finance, logistics, location of a tracking object, etc. Security for sensitive data,such as patient body critical parameters from an attached monitoring device, streaming over IoT networks is vital and is a need of the hour. Data integrity and user (or device) authentication are crucial for building a trust-worthy communication network among the peers in IoT networks. Most networks still employ specific software encryption algorithms that provide considerable data security. But quantum computing has proved the vulnerability of computationally vigorous cryptographic algorithms . A decentralized and scalable framework for device authentication and data security is proposed in this paper based on blockchain platform and Physical Unclonable Functions (PUFs). An authentication protocol is developed using PUF-based cryptographic primitives . The PUF-based keys are hard to replicate and almost impossible to predict because of the randomness in the physical design and complex mathematical modeling of the system. Lightweight Smart contracts are used to facilitate role-based access control. Data privacy is preserved by storing the sensitive data off-chain. As a proof of concept , an IoT-based healthcare system based on Ethereum permissioned blockchain is developed using the proposed framework. The​ designed PUF exhibits 48.46\% uniqueness and 2.38\% reliability. A comparative analysis with existing similar models shows that the proposed approach is feasible and provides a scalable solution for device authentication and data security in resource-limited medical IoT networks.},
  archive      = {J_COMCOM},
  author       = {Krishna Prasad Satamraju and B. Malarkodi},
  doi          = {10.1016/j.comcom.2021.09.012},
  journal      = {Computer Communications},
  pages        = {146-160},
  shortjournal = {Comput. Commun.},
  title        = {A decentralized framework for device authentication and data security in the next generation internet of medical things},
  volume       = {180},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Resource-aware provisioning strategies in translucent
elastic optical networks. <em>COMCOM</em>, <em>180</em>, 134–145. (<a
href="https://doi.org/10.1016/j.comcom.2021.09.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Elastic optical networks (EONs) enable a more efficient use of spectrum resources than traditional wavelength-division multiplexing (WDM) networks, mainly by means of a flexible frequency grid and the use of bandwidth variable transponders (BVTs). In WDM networks, regeneration is avoided because it always produces a cost increase and it is only recommended when the transmission length cannot be met. Instead, in EONs, a trade-off exists between regeneration and spectrum use. Indeed, blocking probability can be widely reduced by incorporating regeneration (BVTs in a back-to-back configuration) to shorten the transmission lengths, therefore increasing spectrum efficiency. Provisioning algorithms that take into account this trade-off consider regeneration either as a cost to be minimized (full regeneration capacity) or as a resource to be smartly used (bounded number of predeployed transponders). In recent years, algorithms that minimize the resource use of either spectrum or BVT have been proposed. These algorithms, however, penalize the overall network performance in terms of blocking probability and cost, since they do not take into account the available resources. In this work, we propose two novel resource-aware algorithms, that take into account all available resources in the provisioning process. We report simulation results showing that using these resource-aware algorithms: (i) when full regeneration capacity is assumed, the regeneration cost can be reduced by more than a 30\% compared to the opaque solution and by a 10\% compared to the best known algorithms; (ii) for the bounded case, resource-aware strategies can reduce blocking probability by thousands of times compared to the transparent solution and by hundreds of times compared to the best known algorithms. Our results show that resource awareness helps to decrease the blocking probability while increasing the actual network capacity, thanks to a more efficient assignment of both spectrum and BVT resources.},
  archive      = {J_COMCOM},
  author       = {Nehuen Gonzalez-Montoro and Jorge M. Finochietto and Andrea Bianco},
  doi          = {10.1016/j.comcom.2021.09.008},
  journal      = {Computer Communications},
  pages        = {134-145},
  shortjournal = {Comput. Commun.},
  title        = {Resource-aware provisioning strategies in translucent elastic optical networks},
  volume       = {180},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Improving performance and data transmission security in
VANETs. <em>COMCOM</em>, <em>180</em>, 126–133. (<a
href="https://doi.org/10.1016/j.comcom.2021.09.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article proposes a new approach to achieve fast and reliable transfer of data and uses machine learning techniques for data processing to improve the performance and data transmission security of the vehicular network . The proposed approach is the combination of 5G cellular network and alternative data transmission channels. The data collection experiment took place within different areas of the city of Berlin over a 3-month time period and involved the use of 5G technologies. The study carried out the analysis and classification of big data with the help of position-based routing protocols and the Support Vector Machine algorithms. The said techniques were employed to detect non-line-of-sight (NLoS) conditions in real time, which ensure the secure transmission of data without the loss or degradation of network performance. The novelty of the work is that it tackles various traffic scenarios (the extent of road congestion can affect the quality of big data transmission) and offers a way to improve big data transfer using the Support Vector Machine technology. The study results show that the proposed approach is effective enough with big data and can be employed to improve the performance of urban VANET networks and data transmission security. The study results can be useful in developing high-performance 5G-VANET applications to improve traffic safety in urban vehicular environments .},
  archive      = {J_COMCOM},
  author       = {SuYu Zhang and Margarita Lagutkina and Kevser Ovaz Akpinar and Mustafa Akpinar},
  doi          = {10.1016/j.comcom.2021.09.005},
  journal      = {Computer Communications},
  pages        = {126-133},
  shortjournal = {Comput. Commun.},
  title        = {Improving performance and data transmission security in VANETs},
  volume       = {180},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Confidentially judging the relationship between an integer
and an interval against malicious adversaries and its applications.
<em>COMCOM</em>, <em>180</em>, 115–125. (<a
href="https://doi.org/10.1016/j.comcom.2021.09.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the growing prominence of privacy protection issues in big data, artificial intelligence and blockchain , secure multi-party computation has become a research hotspot. Confidentially computing the set problem is an important branch of secure multi-party computation. The relationship between an integer and an interval is the most basic problem in the study of computing set problems. At present, there are many research solutions for secure multi-party computation against malicious adversaries . In this paper, we analyze some possible malicious attacks in the protocol of determining an integer and an interval relationship under the semi-honest model. By using the Goldwasser–Micali encryption scheme , Paillier encryption algorithm, zero-knowledge proof and cut-choose method, we design the secret judgment protocol of an integer and an interval relationship under the malicious model. Finally, an ideal-practical example proof method is used to prove that the protocol is secure under the malicious model. Compared with the existing schemes, it not only keeps good efficiency, but also can resist the attack of malicious opponents, and the protocol is more fair. The scheme has a wide application prospect.},
  archive      = {J_COMCOM},
  author       = {Xin Liu and Ruiling Zhang and Gang Xu and Xiu-Bo Chen and Neal N. Xiong},
  doi          = {10.1016/j.comcom.2021.09.011},
  journal      = {Computer Communications},
  pages        = {115-125},
  shortjournal = {Comput. Commun.},
  title        = {Confidentially judging the relationship between an integer and an interval against malicious adversaries and its applications},
  volume       = {180},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Mask-RCNN with spatial attention for pedestrian segmentation
in cyber–physical systems. <em>COMCOM</em>, <em>180</em>, 109–114. (<a
href="https://doi.org/10.1016/j.comcom.2021.09.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the application of industrial cyber–physical systems in various fields such as transportation systems, smart cities, and medical systems, pedestrian scenarios are becoming more and more complex, which brings difficulties to pedestrian segmentation. The difficulty of pedestrian segmentation lies in the scene’s complexity where the pedestrian is located, including the pedestrian’s shooting angle, light, and obstructions, which makes it difficult to distinguish accurately. This paper proposes an S-Mask-RCNN network that integrates spatial attention mechanisms for pedestrian segmentation. Mask-RCNN uses residual neural networks in the feature extraction network , and the effect of model feature extraction is not ideal. Based on transfer learning , a spatial attention mechanism is introduced to focus more spatially on areas that need attention. The force mechanism focuses more on the areas that need attention in space. Experiments show that the S-Mask-RCNN method proposed in this paper has better performance than traditional Mask-RCNN in pedestrian segmentation. Experiments show that the S-Mask-RCNN method proposed in this paper has better performance than traditional Mask-RCNN in pedestrian segmentation, also can provide more comprehensive and practical information for the construction of cyber–physical systems.},
  archive      = {J_COMCOM},
  author       = {Lin Yuan and Zhao Qiu},
  doi          = {10.1016/j.comcom.2021.09.002},
  journal      = {Computer Communications},
  pages        = {109-114},
  shortjournal = {Comput. Commun.},
  title        = {Mask-RCNN with spatial attention for pedestrian segmentation in cyber–physical systems},
  volume       = {180},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Towards real-time privacy-preserving video surveillance.
<em>COMCOM</em>, <em>180</em>, 97–108. (<a
href="https://doi.org/10.1016/j.comcom.2021.09.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video surveillance on a massive scale can be a vital tool for law enforcement agencies . To mitigate the serious privacy concerns of wide-scale video surveillance, researchers have designed secure and privacy-preserving protocols that obliviously match live feeds against a suspects’ database. However, existing approaches are very expensive in terms of computation and communication costs and, as a result, they do not scale well for ubiquitous deployment. To this end, we propose a general framework for privacy-preserving identification that operates by storing an encrypted version of the suspects’ database at the video cameras. We show that this approach (i) reduces the protocol to a single round of communication between the camera and the server and (ii) speeds up the computation times significantly through the use of input-independent precomputations . We apply our framework to two practical use-cases, namely, face and license plate number recognition. In addition to the identification result, our face recognition protocol discloses some trivial information to the database server ; however, this information is not sufficient for the server to infer any meaningful characteristics about the underlying individuals. On the other hand, the license plate recognition protocol is provably secure and can also handle minor character recognition errors that often occur in such systems. We implemented working prototypes of both surveillance systems and our experimental results are very promising. In the case of face recognition, and for a database of 100 suspects, the online computation time at the camera and the server is 155 ms and 34 ms, respectively, while the online communication cost is only 12 KB. Similarly, for a database of 3000 entries, license plate recognition requires only 232 ms and 75 ms at the camera and the server, respectively, while the online communication cost is 375 KB.},
  archive      = {J_COMCOM},
  author       = {Elmahdi Bentafat and M. Mazhar Rathore and Spiridon Bakiras},
  doi          = {10.1016/j.comcom.2021.09.009},
  journal      = {Computer Communications},
  pages        = {97-108},
  shortjournal = {Comput. Commun.},
  title        = {Towards real-time privacy-preserving video surveillance},
  volume       = {180},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Constellation diagram processing with convolutional neural
networks for channel phase response estimation. <em>COMCOM</em>,
<em>180</em>, 89–96. (<a
href="https://doi.org/10.1016/j.comcom.2021.09.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A novel constellation diagram processing is proposed to implement channel phase response estimation by using convolutional neural networks ( CNN ). The constellation diagram images of asymmetric 4-QAM signals are presented as graphical patterns designed for CNN rotation angle prediction. The convolutional neural network is configured as a six-layer neural network in which constellation diagrams are feeding the input layer and rotation angle prediction only takes one convolutional layer . For rotation angle prediction, the highest accuracy is achieved at epochs of 20 (85\%) for image with pixel size 28 × × 28. We experimentally verified this channel phase response estimation method in a 1.2 m BNC coaxial cable as a transmission line using 6 sub-bands located between 150 kHz and 276 kHz. For experimental validation, the proposed methodology allows recovering between 64\% and 97\% of the transmitted symbols obtained after constellation diagram processing, compared to 20\% recovering without phase precompensation.},
  archive      = {J_COMCOM},
  author       = {Claudia L. Cortés and Neil Guerrero González},
  doi          = {10.1016/j.comcom.2021.09.010},
  journal      = {Computer Communications},
  pages        = {89-96},
  shortjournal = {Comput. Commun.},
  title        = {Constellation diagram processing with convolutional neural networks for channel phase response estimation},
  volume       = {180},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A hybrid intrusion detection system based on sparse
autoencoder and deep neural network. <em>COMCOM</em>, <em>180</em>,
77–88. (<a href="https://doi.org/10.1016/j.comcom.2021.08.026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A large number of attacks are launched daily in the era of the internet and with a large number of users. Nowadays, effective detection of numerous attacks using the Intrusion Detection System (IDS) is an emerging research technique. Machine learning methodologies show effective results in intrusion detection system. We proposed a two-stage hybrid methodology for intrusion detection . In the first stage, the unsupervised Sparse autoencoder (SAE) with smoothed l1 regularization . We employ smoothed l1 regularization to enforce a sparsity of autoencoder . The smoothed l1 regularization is indeed able to learn sparse representations of features. In the second stage, the Deep Neural Network (DNN) was used to predict and classify attacks. The classifier classifies multi attack classification from the extracted features. Unsupervised SAE was optimized to train an efficient model. The experimental results demonstrate that proposed model better than the conventional models in terms of overall performance in detection rate and low false positive rate. The proposed model was assessed on the datasets KDDCup99, NSL-KDD and UNSW-NB15. The model attained the accuracy 99.98\% , and detection rate 99.99\% on UNSW-NB15 dataset.},
  archive      = {J_COMCOM},
  author       = {K. Narayana Rao and K. Venkata Rao and Prasad Reddy P.V.G.D.},
  doi          = {10.1016/j.comcom.2021.08.026},
  journal      = {Computer Communications},
  pages        = {77-88},
  shortjournal = {Comput. Commun.},
  title        = {A hybrid intrusion detection system based on sparse autoencoder and deep neural network},
  volume       = {180},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An adaptive method and a new dataset, UKM-IDS20, for the
network intrusion detection system. <em>COMCOM</em>, <em>180</em>,
57–76. (<a href="https://doi.org/10.1016/j.comcom.2021.09.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, the demand for computer networks has grown rapidly, thus allowing for higher risk of novel attack incidents. Traditional network intrusion detection systems (IDSs) usually have difficulties detecting these attacks because they need to adapt to more advanced or challenging technologies of novel attacks, yet updating them can be computationally expensive and complicated. Therefore, an adaptive IDS is crucial to keep computer networks protected. In addition, consistent update of IDS datasets is essential due to the advancement in network technology and attack strategies. Updating the IDS datasets would allow for the testing of the proposed IDSs on datasets that are relevant to the recent attacks. Moreover, the connection between processing raw network data and creating an adaptive IDS has not been sufficiently studied in this domain. Therefore, this study presents an adaptive IDS and a new real-world network dataset called the UKM-IDS20. The proposed IDS employs the homogeneous ensemble method to create a model that can be periodically updated to detect novel attacks. The update procedure includes training new classifiers and adding them to the base ensemble model. Since this procedure requires further data, a simple data acquisition methodology is used for processing raw network traffic data. This process involves three stages; packet capturing, packet integration, and feature extraction. The collected data from the tests of this study is then used to create the UKM-IDS20 dataset. The created dataset contains 46 features and covers four types of attacks, namely ARP poisoning, DoS , Scans, and Exploits. The complexity of the UKM-IDS20 is compared to the KDD99 and UNSW-NB15 datasets from two aspects. First, an analysis of the features and classes is demonstrated using the rough-set theory. Second, a dynamic artificial neural network is used to test and compare the three datasets mentioned above. The results show a higher complexity and relevancy of the features in the introduced dataset. The UKM-IDS20 dataset is publicly available and can be accessed by all researchers. This study is anticipated to provide enough information to help cybersecurity academics to generate effective IDSs and up-to-date datasets.},
  archive      = {J_COMCOM},
  author       = {Muataz Salam Al-Daweri and Salwani Abdullah and Khairul Akram Zainol Ariffin},
  doi          = {10.1016/j.comcom.2021.09.007},
  journal      = {Computer Communications},
  pages        = {57-76},
  shortjournal = {Comput. Commun.},
  title        = {An adaptive method and a new dataset, UKM-IDS20, for the network intrusion detection system},
  volume       = {180},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). EDGF: Empirical dataset generation framework for wireless
sensor networks. <em>COMCOM</em>, <em>180</em>, 48–56. (<a
href="https://doi.org/10.1016/j.comcom.2021.08.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In wireless sensor networks (WSNs), simulation practices, system models, algorithms, and protocols have been published worldwide based on the assumption of randomness. The applied statistics used for randomness in WSNs are broad, e.g., random deployment , activity tracking, packet generation, etc. Even though authors’ adequate formal and informal information and pledge validation of the proposal became challenging, the minuscule information alteration in implementation and validation can reflect the enormous effect on eventual results. In this proposal, we show how the results are affected by the generalized assumption made on randomness. In sensor node deployment, ambiguity arises due to node error-value ( ε ε ), and its upper bound in the relative position is estimated to understand the delicacy of diminutives changes. Besides, the effect of uniformity in the traffic and participation of scheduling position of nodes is also generalized. We propose an algorithm to generate the unified dataset for the general and some specific applications system models in WSNs. The results produced by our algorithm reflect the pseudo-randomness and can efficiently regenerate through seed value for validation.},
  archive      = {J_COMCOM},
  author       = {Dinesh Kumar Sah and Korhan Cengiz and Praveen Kumar Donta and Venkata N. Inukollu and Tarachand Amgoth},
  doi          = {10.1016/j.comcom.2021.08.017},
  journal      = {Computer Communications},
  pages        = {48-56},
  shortjournal = {Comput. Commun.},
  title        = {EDGF: Empirical dataset generation framework for wireless sensor networks},
  volume       = {180},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). BCHealth: A novel blockchain-based privacy-preserving
architecture for IoT healthcare applications. <em>COMCOM</em>,
<em>180</em>, 31–47. (<a
href="https://doi.org/10.1016/j.comcom.2021.08.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The advancements in networking technologies have introduced the Internet of Everything (IoE) and smart living concepts. The main idea behind making everything smarter is to improve individuals’ quality of life. An excellent example of such a technology is smart healthcare which provides efficient, sustainable, and real-time human services. However, data security and privacy are among the most important challenges of smart healthcare applications. Blockchain (BC) has been considered as a promising solution for the secure management of healthcare data due to its immutability and transparency features. However, there is a trade-off between transparency and user data privacy which is a prominent challenge in adopting BC for healthcare applications. Some researchers have considered user data privacy and proposed a few solutions; however, data owner’s access control desire has not been considered in the state-of-the-art models. In this paper, to overcome the trade-off challenge between transparency and access control, we propose an architecture (so-called BCHealth) that enables data owners to define their desired access policies over their privacy-sensitive healthcare data. BCHealth is composed of two separate chains for storing access policies and data transactions. We address the real-world development challenges of BC, i.e., scalability, delay, and overhead, by adopting a clustering approach . Our extensive experimental analysis proves the efficiency of BCHealth (in terms of computation and processing time) and its resilience against several security attacks.},
  archive      = {J_COMCOM},
  author       = {Koosha Mohammad Hossein and Mohammad Esmaeil Esmaeili and Tooska Dargahi and Ahmad Khonsari and Mauro Conti},
  doi          = {10.1016/j.comcom.2021.08.011},
  journal      = {Computer Communications},
  pages        = {31-47},
  shortjournal = {Comput. Commun.},
  title        = {BCHealth: A novel blockchain-based privacy-preserving architecture for IoT healthcare applications},
  volume       = {180},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Trade-off analysis between delay and throughput of RAN
slicing for smart grid. <em>COMCOM</em>, <em>180</em>, 21–30. (<a
href="https://doi.org/10.1016/j.comcom.2021.07.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Emerging power services with massive connections and real-time control have different requirements on delay, rate, reliability, etc. In order to meet the diversified requirements of power services, network slicing can provide guarantee for the wide application of 5G in power. The current research on network slicing adapting power services is still in its infancy. This paper proposes a trade-off analysis method for radio access network (RAN) slice delay and throughput based on dynamic intelligent resource allocation to meet the different QoS requirements of different services in smart grid scenarios. Firstly, clustering analysis is used to classify the communication requirements of smart grid services . A throughput demand model for enhanced mobile broadband (eMBB) slice users based on importance and a delay constraint model for ultra-reliable and low latency communication (uRLLC) slice users are constructed, and a throughput model for slice users based on cell capacity limitation is constructed. Then, the problem model of maximizing the throughput of the eMBB slice by reasonably allocating resource blocks and power under the premise of ensuring the delay of the uRLLC slice is established. The Lyapunov drift plus penalty function method is used to convert the above problem into a tractable form, and then the problem is solved by the active set method. Simulation results show that the different QoS requirements of smart grid services will significantly affect the actual queue length of the uRLLC slice as well as the throughput of the eMBB slice.},
  archive      = {J_COMCOM},
  author       = {Zhi Li and Jiye Wang and Yang Wang and Sachula Meng and Sai Wu and Huixia Ding and Zhihui Wang},
  doi          = {10.1016/j.comcom.2021.07.004},
  journal      = {Computer Communications},
  pages        = {21-30},
  shortjournal = {Comput. Commun.},
  title        = {Trade-off analysis between delay and throughput of RAN slicing for smart grid},
  volume       = {180},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Security on in-vehicle communication protocols: Issues,
challenges, and future research directions. <em>COMCOM</em>,
<em>180</em>, 1–20. (<a
href="https://doi.org/10.1016/j.comcom.2021.08.027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The automotive industry has represented an important sector of industrial development worldwide. With technology growth, vehicles have been equipped with various devices that allow them to perform different functions, increase autonomy level, and give drivers greater confidence and comfort. In this sense, data security is a fundamental feature since access to car functionalities needs to be protected from outsiders, only allowing access to authorized users. It means to guarantee data security through communication buses even when connecting from external devices. Therefore, it is necessary to design new security techniques that increase the confidentiality and improve authentication in new vehicles. Although at first, automotive communication protocols did not include security mechanisms, the risk of threats was always latent. Due to this, the search for new methods and architectures to improve security and autonomous functions in communication protocols has been in constant increase. New paradigms and ways to prevent, detect and mitigate attacks on automotive communication are necessary for the new challenges ahead. This article comparatively analyses the state of the art for in-vehicle communications protocols regarding a variety of algorithmic approaches based on architectural configurations and extensively compares their performance.},
  archive      = {J_COMCOM},
  author       = {Alfonso Martínez-Cruz and Kelsey A. Ramírez-Gutiérrez and Claudia Feregrino-Uribe and Alicia Morales-Reyes},
  doi          = {10.1016/j.comcom.2021.08.027},
  journal      = {Computer Communications},
  pages        = {1-20},
  shortjournal = {Comput. Commun.},
  title        = {Security on in-vehicle communication protocols: Issues, challenges, and future research directions},
  volume       = {180},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Classification of flower image based on attention mechanism
and multi-loss attention network. <em>COMCOM</em>, <em>179</em>,
307–317. (<a
href="https://doi.org/10.1016/j.comcom.2021.09.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The accurate classification of flower images is the prerequisite for flower plant management to artificial intelligence , how to use the machine to classify flowers automatically is the current hot issue to be solved. This paper first introduced the principle of attention mechanism and realization of spatial attention mechanism and channel attention mechanism , and then designed the embedding of the spatial attention module and channel attention model in Xception structure based on Xception. Final, the network was optimized by jointing Triplet Loss and Softmax Loss in the network loss layer, to obtain a feature embedding space with high intra-class compactness and inter-class separation. This paper was experimented on two flower image data sets (Oxford 17 flowers and Oxford 102 flowers), the results show that the MLSAN, MLCAN, MLCSAN model proposed in this paper were 0.39\%, 0.50\%, and 0.72\% higher on the Oxford 17 flowers data set​ and 0.52\%, 0.63\% and 0.85\% higher on the data set Oxford 102 flowers data set.},
  archive      = {J_COMCOM},
  author       = {Mei Zhang and Huihui Su and Jinghua Wen},
  doi          = {10.1016/j.comcom.2021.09.001},
  journal      = {Computer Communications},
  pages        = {307-317},
  shortjournal = {Comput. Commun.},
  title        = {Classification of flower image based on attention mechanism and multi-loss attention network},
  volume       = {179},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An on demand load balancing multi-path routing protocol for
differentiated services in MWSN. <em>COMCOM</em>, <em>179</em>, 296–306.
(<a href="https://doi.org/10.1016/j.comcom.2021.08.020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As an important part of the Internet of Things , mobile wireless sensor network (MWSN) will generate traffic with different service quality requirements due to the multi-sensor integration of nodes and application diversity. Due to the topological changes, resource constraints and self-organizing characteristics of MWSN, the Per-Hop Behavior (PHB) approach in the traditional Diff-Serv model has many challenges in providing differential service. In this paper, a path reservation multipath routing (PRMR) protocol is proposed, which can provide a suitable path for each type of traffic with service requirements. PRMR protocol includes path discovery algorithm and packet scheduling algorithm . In addition, the path scheduling model and scheduling algorithm in PRMR solve the problem of load imbalance among reserved paths caused by different types of traffic. In scenarios with different number of nodes, three types of traffic, integrity sensitive data, delay sensitive data and normal data, are used to verify the performance of PRMR differential service and load balancing. Simulation experiments not only compare the quality of service provided by each reserved path in PRMR, but also compare the differential service performance between PRMR and several multipath routing algorithms. Simulation results show that PRMR routing algorithm can guarantee high packet delivery rate and low delay for integrity-sensitive data and delay-sensitive data, respectively. In addition, the simulation results of the average residual energy index show that the protocol can achieve network energy balance.},
  archive      = {J_COMCOM},
  author       = {Zheng Chen and Wenli Zhou and Shuo Wu and Li Cheng},
  doi          = {10.1016/j.comcom.2021.08.020},
  journal      = {Computer Communications},
  pages        = {296-306},
  shortjournal = {Comput. Commun.},
  title        = {An on demand load balancing multi-path routing protocol for differentiated services in MWSN},
  volume       = {179},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Using data mining techniques to explore security issues in
smart living environments in twitter. <em>COMCOM</em>, <em>179</em>,
285–295. (<a
href="https://doi.org/10.1016/j.comcom.2021.08.021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In present-day in consumers’ homes, there are millions of Internet-connected devices that are known to jointly represent the Internet of Things (IoT). The development of the IoT industry has led to the emergence of connected devices and home assistants that create smart living environments. However, the continuously generated data accumulated by these connected devices create security issues and raise user’s privacy concerns. The present study aims to explore the main security issues in smart living environments using data mining techniques . To this end, we applied a three-sentence data mining analysis of 938,258 tweets collected from Twitter under the user-generated data (UGD) framework. First, sentiment analysis was applied using Textblob which was tested with support vector classifier, multinomial naïve bayes, logistic regression , and random forest classifier ; as a result, the analyzed tweets were divided into those expressing positive, negative, and neutral sentiment. Next, a Latent Dirichlet Allocation (LDA) algorithm was applied to divide the sample into topics related to security issues in smart living environments. Finally, the insights were extracted by applying a textual analysis process in Python validated with the analysis of frequency and weighted percentage variables and calculating the statistical measure known as mutual information (MI) to analyze the identified n-grams (unigrams and bigrams). As a result of the research 10 topics were identified in which we found that the main security issues are malware , cybersecurity attacks, data storing vulnerabilities, the use of testing software in IoT, and possible leaks due to the lack of user experience . We discussed different circumstances and causes that may affect user security and privacy when using IoT devices and emphasized the importance of UGC in the processing of personal data of IoT device users.},
  archive      = {J_COMCOM},
  author       = {Jose Ramon Saura and Daniel Palacios-Marqués and Domingo Ribeiro-Soriano},
  doi          = {10.1016/j.comcom.2021.08.021},
  journal      = {Computer Communications},
  pages        = {285-295},
  shortjournal = {Comput. Commun.},
  title        = {Using data mining techniques to explore security issues in smart living environments in twitter},
  volume       = {179},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). On the efficient design of network resilient to
electro-magnetic pulse attack—elastic optical network case study.
<em>COMCOM</em>, <em>179</em>, 272–284. (<a
href="https://doi.org/10.1016/j.comcom.2021.08.025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rising popularity of the telecommunication networks and their growing support in our every-day life make them a potential target of various security threats and malicious attacks . The international security organizations warn against increasing likelihood of nuclear weapon or electro-magnetic pulse (EMP) attacks, which can be extremely harmful also for the networks. On that background, we study efficient design of a network resilient to the EMP attack wherein the required protection level is provided by the application of multipath routing and military grade bunkers (advanced electro-magnetic radiation resilient approaches protecting whole network node) implementation. Formally, we define and study the problem of bunkers location, routing and spectrum allocation (BLRSA) in an elastic optical network (EON). In the problem objective we address two criteria — network resilience (measured by the average lost flow per potential attack) and spectrum usage . For that problem we propose integer linear programming (ILP) model and two dedicated heuristics — 1S-RSA and 2S-RSA. Then, we perform extensive numerical experiments divided into three parts: ( i ) tuning of the proposed approaches, ( ii ) comparison with reference methods, ( iii ) realistic case study — efficient EMP-resilient network design. In the case study we analyze benefits and costs (especially in terms of the spectrum usage) of the proposed protection scheme. Moreover, we also analyze vulnerabilities of three realistic network topologies to the EMP attacks and identify their critical nodes. The investigation proves high efficiency of the proposed approaches and shows that they allow to save up to 90\% of the traffic lost in the case of no protection against these types of attacks.},
  archive      = {J_COMCOM},
  author       = {Róża Goścień},
  doi          = {10.1016/j.comcom.2021.08.025},
  journal      = {Computer Communications},
  pages        = {272-284},
  shortjournal = {Comput. Commun.},
  title        = {On the efficient design of network resilient to electro-magnetic pulse attack—elastic optical network case study},
  volume       = {179},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). CROWD-CDN: A cryptocurrency incentivized crowdsourced
peer-to-peer content delivery framework. <em>COMCOM</em>, <em>179</em>,
260–271. (<a
href="https://doi.org/10.1016/j.comcom.2021.08.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Content Distribution Network (CDN) is one of the most established technology for improving application and media service providers’ scalability, quality of service (QoS), and quality of experience (QoE). A hybrid content delivery network (CDN) with peer-to-peer (P2P) networking (CDN-P2P) is one strategy for further improving the scalability and QoS/QoE. However, CDN-P2P suffers from peer churning and free riding due to the inexistence of stimulating monetary incentives for the participating peers in the P2P overlay. Furthermore, to incentivize participating peers according to the peer contributions, it is not clear how much a peer contributes back to the overall content distribution capacity. To this end, this manuscript proposes a cryptocurrency incentivized crowdsourced P2P content delivery network (CROWD-CDN). CROWD-CDN monetizes the services of seeds supplying peers according to their contribution to the overall CDN content distribution capacity. CROWD-CDN employed blockchain-based cryptocurrencies and smart contracts for the monetization of peers. Additionally, CROWD-CDN utilizes the container-based virtualization of the peer nodes enabling CDN providers for transparent monitoring of peers’ contribution and securing the CDN contents at the peer in the isolated container. Lastly, we provide a proof of concept simulated testbed for the dimensioning of different variants of the proposed hybrid architecture and validating the provisioning of monetary incentives to peers.},
  archive      = {J_COMCOM},
  author       = {Abdullah Yousafzai and Priyan Malarvizhi Kumar and Choong Seon Hong},
  doi          = {10.1016/j.comcom.2021.08.007},
  journal      = {Computer Communications},
  pages        = {260-271},
  shortjournal = {Comput. Commun.},
  title        = {CROWD-CDN: A cryptocurrency incentivized crowdsourced peer-to-peer content delivery framework},
  volume       = {179},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Transceiver design for high altitude pseudo satellite aided
dual satellite systems. <em>COMCOM</em>, <em>179</em>, 251–259. (<a
href="https://doi.org/10.1016/j.comcom.2021.08.024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work focuses on a dual satellite system (DSS) where two multiple spot beam geosynchronous satellites transmit simultaneously on the same frequency across all spot beams. The intra-satellite co-channel interference is managed through precoding , while the inter-satellite co-channel interference is managed with successive interference cancellation (SIC) at the user terminals. The SIC eliminates the strongest co-channel interference from an adjacent satellite while treating the remaining interfering signals as noise. The power required at the transmitter to achieve the desired data rate is formulated as a semidefinite programming problem and relaxed rank constraints. The SIC-based receivers are shown to achieve a better data rate than traditional detectors that treat co-channel interference as noise while saving transmit power at the satellites. Though SIC-based DSS achieves better throughput than a single satellite system, the receiver complexity is high. A high-altitude pseudo satellite (HAPS) aided DSS is proposed to address this issue. In the case of HAPS-aided DSS, users within each spot beam are served by a HAPS, and the HAPSs use SIC to detect signals from satellites. The user terminals in HAPS-aided DSS can use simple detectors as HAPS eliminates co-channel interference through precoding . The full-duplex HAPS-aided DSS is shown to outperform SIC-based DSS.},
  archive      = {J_COMCOM},
  author       = {Rajendra Prasad Sirigina and Madhukumar AS and Mark Bowyer},
  doi          = {10.1016/j.comcom.2021.08.024},
  journal      = {Computer Communications},
  pages        = {251-259},
  shortjournal = {Comput. Commun.},
  title        = {Transceiver design for high altitude pseudo satellite aided dual satellite systems},
  volume       = {179},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). UAV path planning for backscatter communication with phase
cancellation. <em>COMCOM</em>, <em>179</em>, 242–250. (<a
href="https://doi.org/10.1016/j.comcom.2021.08.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Backscatter communication has emerged as a promising technology to realize internet of things (IoT), which can fascinate the data transmission without energy supply and constitute a maintenance-free wireless network. When combining it with unmanned aerial vehicle (UAV), it can gather sensed data in extreme scenarios such as surveying in unreachable areas. When modulated by amplitude shift keying (ASK), the received signal at an UAV is the superposition of backscatter signal of tags and the signal of the RF source. As the UAV moves, the phase difference between the two signals changes. A phase cancellation effect will happen when the UAV enters a blind communication zone, which will deteriorate the performance of communication. In this paper, a two-step moving strategy for the UAV is proposed to eliminate the phase cancellation effect and find the optimal communication spot, so as to improve the reliability and stability of date transmission. The sampling-based UAV path planning algorithm and a median filter is used to adjust the moving direction and filter out environmental noise. By simulation, we can see that it is feasible for the UAV to find global optimal spot and the probability of finding the optimal spot can reach 96\%.},
  archive      = {J_COMCOM},
  author       = {Chunyue Wu and Ruifeng Liang and Feng Xu and Feng Ke},
  doi          = {10.1016/j.comcom.2021.08.013},
  journal      = {Computer Communications},
  pages        = {242-250},
  shortjournal = {Comput. Commun.},
  title        = {UAV path planning for backscatter communication with phase cancellation},
  volume       = {179},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A data-driven intelligent planning model for UAVs routing
networks in mobile internet of things. <em>COMCOM</em>, <em>179</em>,
231–241. (<a
href="https://doi.org/10.1016/j.comcom.2021.08.014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Owing to constant progress of wireless communications , the Unmanned Aerial Vehicles (UAVs) routing networks (UAVs-RN) under mobile Internet of Things (MIoT) have been prevalent tools to deal with natural emergencies. But the achievement of effective responses and proper utility, still remains a challenging task. It is required to analyze multi-source data of UAVs-RN, so that optimal planning schemes under MIoT can be found. To bridge such gap, this work mainly takes three aspects of factors into consideration: rapid response, finite budget and uncertain signal fading. Accordingly, a data-driven intelligent planning model for UAVs-RN under MIoT, is put forward in this paper. Data about wildfire happened in local areas of Australia is selected to build experimental scenarios. And two kinds of UAVs, Surveillance and Situational Awareness drones and Radio Repeater drones, are considered in this study. Firstly, the source data is visualized and the internal trend is analyzed to verify true validity. Then, a multi-objective planning model is accordingly established to aggregate multi-source data. At last, a case study is deeply investigated on real-world data to assess the proposed approach and suggest feasible planning schemes.},
  archive      = {J_COMCOM},
  author       = {Dian Meng and Yang Xiao and Zhiwei Guo and Alireza Jolfaei and Lanxia Qin and Xinting Lu and Qiao Xiang},
  doi          = {10.1016/j.comcom.2021.08.014},
  journal      = {Computer Communications},
  pages        = {231-241},
  shortjournal = {Comput. Commun.},
  title        = {A data-driven intelligent planning model for UAVs routing networks in mobile internet of things},
  volume       = {179},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Unearthing malicious campaigns and actors from the
blockchain DNS ecosystem. <em>COMCOM</em>, <em>179</em>, 217–230. (<a
href="https://doi.org/10.1016/j.comcom.2021.08.023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Blockchain DNS has emerged as an alternative solution to traditional DNS to address many of its inherent drawbacks. In this regard, a blockchain DNS approach is decentralised, resilient, provides high availability, and prevents censorship. Unfortunately, despite these desirable features, the major blockchain DNS solutions to date, Namecoin and Emercoin have been repeatedly reported for malicious abuse, ranging from malware distribution to phishing. In this work, we perform a longitudinal analysis of both these chains trying to identify and quantify the penetration of malicious actors in their ecosystems. To this end, we apply a haircut blacklisting policy and the intelligence collected from various engines to perform a taint analysis on the metadata existing in these blockchains, aiming to identify malicious acts through the merge of identifying information. Our analysis provides an automated validation methodology that supports the various reports about the wide-scale abuse of these solutions showing that malicious actors have already obtained an alarming and extensive share of these platforms.},
  archive      = {J_COMCOM},
  author       = {Fran Casino and Nikolaos Lykousas and Vasilios Katos and Constantinos Patsakis},
  doi          = {10.1016/j.comcom.2021.08.023},
  journal      = {Computer Communications},
  pages        = {217-230},
  shortjournal = {Comput. Commun.},
  title        = {Unearthing malicious campaigns and actors from the blockchain DNS ecosystem},
  volume       = {179},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Mobile computing and communications-driven fog-assisted
disaster evacuation techniques for context-aware guidance support: A
survey. <em>COMCOM</em>, <em>179</em>, 195–216. (<a
href="https://doi.org/10.1016/j.comcom.2021.07.020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The importance of an optimal solution for disaster evacuation has recently raised attention from researchers across multiple disciplines. This is not only a serious, but also a challenging task due to the complexities of the evacuees’ behaviors, route planning, and demanding coordination services. Although existing studies have addressed these challenges to some extent, mass evacuation in natural disasters tends to be difficult to predict and manage due to the limitation of the underlying models to capture realistic situations. It is therefore desirable to have on-demand mechanisms of locally-driven computing and data exchange services in order to enable near real-time capture of the disaster area during the evacuation. For this purpose, this paper comprehensively surveys recent advances in information and communication technology-enabled disaster evacuations, with the focus on fog computation and communication services to support a massive evacuation process. A numerous variety of tools and techniques are encapsulated within a coordinated on-demand strategy of an evacuation platform, which is aimed to provide a situational awareness and response. Herein fog services appear to be one of the viable options for responsive mass evacuation because they enable low latency data processing and dissemination. They can additionally provide data analytics support for autonomous learning for both the short-term guidance supports and long-term usages. This work extends the existing data-oriented framework by outlining comprehensive functionalities and providing seamless integration. We review the principles, challenges, and future direction of the state-of-the-art strategies proposed to sit within each functionality. Taken together, this survey highlights the importance of adaptive coordination and reconfiguration within the fog services to facilitate responsive mass evacuations as well as open up new research challenges associated with analytics-embedding network and computation, which is critical for any disaster recovery activities.},
  archive      = {J_COMCOM},
  author       = {Ibnu Febry Kurniawan and A. Taufiq Asyhari and Fei He and Ye Liu},
  doi          = {10.1016/j.comcom.2021.07.020},
  journal      = {Computer Communications},
  pages        = {195-216},
  shortjournal = {Comput. Commun.},
  title        = {Mobile computing and communications-driven fog-assisted disaster evacuation techniques for context-aware guidance support: A survey},
  volume       = {179},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Construction of a smart management system for physical
health based on IoT and cloud computing with big data. <em>COMCOM</em>,
<em>179</em>, 183–194. (<a
href="https://doi.org/10.1016/j.comcom.2021.08.018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In response to the needs of physical health data management in the context of the Internet of Everything, this article first uses cloud computing , big data, mobile Internet and other technologies to build a physical health smart management system . When the system is deployed, edge nodes are introduced in each data collection area, and the system is composed of data collection, transmission, and query and analysis modules. Secondly, it uses convolutional neural network to learn features from body measurement data unsupervised. Then, based on the Gaussian mixture distribution, a three-level physical fitness assessment model was established. Finally, input the learned features into the evaluation model to get the result of physical fitness evaluation. The results show that the system not only has a better response to the family, but also can reduce operating costs and improve work efficiency. Moreover, the algorithm in this paper is not affected by individual physical fitness assessment methods and results, and provides new ideas and methods for physical fitness assessment.},
  archive      = {J_COMCOM},
  author       = {Ning Zhang and Chenfei Zhang and Dengpan Wu},
  doi          = {10.1016/j.comcom.2021.08.018},
  journal      = {Computer Communications},
  pages        = {183-194},
  shortjournal = {Comput. Commun.},
  title        = {Construction of a smart management system for physical health based on IoT and cloud computing with big data},
  volume       = {179},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A fast calibration algorithm for non-dispersive infrared
single channel carbon dioxide sensor based on deep learning.
<em>COMCOM</em>, <em>179</em>, 175–182. (<a
href="https://doi.org/10.1016/j.comcom.2021.08.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As people pay more attention to environmental monitoring, Carbon dioxide (CO 2 2 ) sensors are widely used. However, most of the infrared CO 2 2 single-channel sensors are accompanied by low calibration efficiency and low accuracy. In order to save costs while improving calibration efficiency and accuracy, we proposed a fast calibration algorithm for Non-Dispersive Infrared (NDIR) single-channel carbon dioxide sensor based on deep learning . Firstly, we establish N network models which consist of N sensors by collecting m data points from different temperatures and concentrations. Secondly, we collect six data points from a new sensor which are measured at three temperatures and two concentrations. Thirdly, we choose multiple approximate models from N network models based on the matching of the data points. At last, we regard these models as the estimation model of the new sensor to calibrate the sensor concentration. This method eliminates the individual differences of a single model to a certain extent and achieves the purpose of rapid calibration. After comparing three kinds of neural networks and conducting relevant experiments, we chose BP neural network as the model, and set the number of selected models to three. The results show that the floating up and down by industry-standard 5\% plus or minus 50 ppm calculation, the qualified rate of our method is up to 91.542\% between 0 °C to 45 °C, and the qualified rate even reaches 99.063\% between 20 °C to 35 °C. Compared with similar products, the qualified rate of our method in the calibration of carbon dioxide increases by 12.315\% and 22.732\% respectively.},
  archive      = {J_COMCOM},
  author       = {Keji Mao and Jinyu Xu and Runhui Jin and Yuxiang Wang and Kai Fang},
  doi          = {10.1016/j.comcom.2021.08.003},
  journal      = {Computer Communications},
  pages        = {175-182},
  shortjournal = {Comput. Commun.},
  title        = {A fast calibration algorithm for non-dispersive infrared single channel carbon dioxide sensor based on deep learning},
  volume       = {179},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Design of countermeasure to packet falsification in vehicle
platooning by explainable artificial intelligence. <em>COMCOM</em>,
<em>179</em>, 166–174. (<a
href="https://doi.org/10.1016/j.comcom.2021.06.026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In view of system reliability, extraction of knowledge from models of artificial intelligence may be more important than their forecasting ability. The elaboration of rules found by explainable artificial intelligence gives here insight into the problem of packet falsification in vehicle platooning. Detection and countermeasure are designed on the basis of feature and value ranking as well as rule confidence and they are validated under a large range of working conditions. The certification of safe operating conditions is found by achieving (statistically) zero false negatives , namely, the operating conditions predicted as ‘safe’ never lead to collision despite the cyber attack .},
  archive      = {J_COMCOM},
  author       = {M. Mongelli},
  doi          = {10.1016/j.comcom.2021.06.026},
  journal      = {Computer Communications},
  pages        = {166-174},
  shortjournal = {Comput. Commun.},
  title        = {Design of countermeasure to packet falsification in vehicle platooning by explainable artificial intelligence},
  volume       = {179},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Spectrum assignment for connected vehicles: Local licensing
versus coopetition. <em>COMCOM</em>, <em>179</em>, 157–165. (<a
href="https://doi.org/10.1016/j.comcom.2021.08.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The deployment of 5G urban networks is often described as a disruptive phenomenon since it enables new emerging Internet of Things (IoT) applications such as connected vehicles. Such applications demand new spectrum regulations to decrease network investment requirements by incentivizing operator cooperation. However, currently, no clear consensus exists on the appropriate regulatory regime for such an urban deployment. This work explores two main alternative regulatory scenarios for a connected vehicle use case. Both alternatives lower implementation costs while promoting competition. The first alternative is to maintain the current scheme of spectrum assignment while facilitating additional flexibility for infrastructure sharing (ex-post competition). The second alternative is to define local areas for monopoly 5G provisioning and define the conditions for competition ex-ante. Through agent-based simulations, this work shows that a local licensing of spectrum scenario may achieve better performance than alternative scenarios with traditional spectrum assignment. Additional sensitivity checks also help detail the practical trade-offs.},
  archive      = {J_COMCOM},
  author       = {A. Basaure and B. Finley and H. Hämmäinen},
  doi          = {10.1016/j.comcom.2021.08.009},
  journal      = {Computer Communications},
  pages        = {157-165},
  shortjournal = {Comput. Commun.},
  title        = {Spectrum assignment for connected vehicles: Local licensing versus coopetition},
  volume       = {179},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Fast speech adversarial example generation for keyword
spotting system with conditional GAN. <em>COMCOM</em>, <em>179</em>,
145–156. (<a
href="https://doi.org/10.1016/j.comcom.2021.08.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep network-based keyword spotting (KWS) has embraced great success in many speech assistant applications. However, such network-based KWS systems were demonstrated vulnerable to adversarial attacks . In this work, we propose to utilize a conditional generative adversarial network (CGAN) to efficiently craft targeted speech adversarial examples . Specifically, we first transform the attacking target label into a vector, which is treated as the condition input of CGAN. The generator in CGAN is tasked to generate perturbation that could make the adversarial example misclassified as the pre-specified target keyword, while simultaneously deceiving the discriminator to misclassify the adversarial example as genuine. The discriminator aims to differentiate the crafted adversarial examples from the legitimate samples. Secondly, the target network-based KWS classifier(s) are ensembled and integrated into the proposed CGAN framework to enforce the generator to construct model-independent perturbation. The classification error loss of the target KWS is back-propagated through gradients for guiding the weight update of the generator. Finally, with properly devised network architecture and training procedure, we obtain a well-trained generator that generates the adversarial perturbation for a given speech clip and target label. Experimental results show that the crafted adversarial examples could effectively attack the state-of-the-art KWS system with quite a high attack success rate, while attaining acceptable perception quality.},
  archive      = {J_COMCOM},
  author       = {Donghua Wang and Li Dong and Rangding Wang and Diqun Yan},
  doi          = {10.1016/j.comcom.2021.08.010},
  journal      = {Computer Communications},
  pages        = {145-156},
  shortjournal = {Comput. Commun.},
  title        = {Fast speech adversarial example generation for keyword spotting system with conditional GAN},
  volume       = {179},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). NASOR: A network slicing approach for multiple autonomous
systems. <em>COMCOM</em>, <em>179</em>, 131–144. (<a
href="https://doi.org/10.1016/j.comcom.2021.07.028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Realizing network slicing inside and between Autonomous Systems (ASs), that is, multi-domain, is challenging because there is no consensus or solutions that consider both policy and technological independence between domains. Many approaches found in the literature aimed to realize network slices that span across multiple ASs. However, they commonly rely on cross-connected technologies or domain-coupled such as Virtual Private Network (VPN) or Multi-Protocol Label Switching (MPLS). This work addresses the issue of multi-domain network slicing by leveraging technologies such as Software-defined Networking (SDN), Segment Routing (SR), and Network Functions Virtualization (NFV) in an innovative distributed framework, called Network And Slice ORchestrator (NASOR). Our work advances resource management and orchestration potentialities, providing a recursive network slice mechanism and adding dynamism in the network slice deployment between multiple domains through an open interface. As a result, NASOR functionally outperforms its peers. Experiments showcased the proposal’s applicability and scalability in multi-domain network slicing. Additionally, experiments suggest that an open interface enhances network slices’ customization degree and improves the network Quality of Service (QoS) in typical Internet applications, such as Voice over Internet Protocol (VoIP).},
  archive      = {J_COMCOM},
  author       = {Rodrigo Moreira and Pedro Frosi Rosa and Rui Luis Andrade Aguiar and Flávio de Oliveira Silva},
  doi          = {10.1016/j.comcom.2021.07.028},
  journal      = {Computer Communications},
  pages        = {131-144},
  shortjournal = {Comput. Commun.},
  title        = {NASOR: A network slicing approach for multiple autonomous systems},
  volume       = {179},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Unbalanced abnormal traffic detection based on improved
res-BIGRU and integrated dynamic ELM optimization. <em>COMCOM</em>,
<em>179</em>, 112–130. (<a
href="https://doi.org/10.1016/j.comcom.2021.08.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Problems such as a vanishing gradient and overfitting will occur when a recurrent neural network (RNN) is exploited to detect abnormal network traffic. In addition, some network traffic is unbalanced, which leads to low detection accuracy. Therefore, an unbalanced abnormal traffic detection method has been proposed. It is composed of the improved bidirectional residual gated recurrent unit (Res-BIGRU) and integrated dynamic extreme learning machine (IDELM). First, the candidate hidden state activation function of the GRU is changed into an unsaturated activation function . The residual connection is used to avoid the vanishing gradient. The purpose of alleviating network degradation is achieved, and the traffic features extracted are better. Second, an IDELM is proposed to solve the unbalanced classification. The minority samples are generated by the IDELM model. The set model in game theory is used to compute the combined weight, which improves the fitting effect. Third, two IDELMs are used to update the final classification results . Fourth, four network datasets and IoT datasets are used to verify the performance. The average accuracy on four network datasets is 91.11\% when samples are unbalanced. Furthermore, it can be concluded that the improved Res-BIGRU and IDELM strategy is effective. Better classification results can be achieved when network traffic is unbalanced. In particular, the performance is better in unbalanced NSL-KDD datasets. The index values obtained are the best compared with other methods. It is also suitable for intrusion detection of the Internet of Things, which has good performance. The further advantage lies in that the robustness is better when there are other sample interferences.},
  archive      = {J_COMCOM},
  author       = {Wengang Ma and Yadong Zhang and Jin Guo and Kehong Li},
  doi          = {10.1016/j.comcom.2021.08.005},
  journal      = {Computer Communications},
  pages        = {112-130},
  shortjournal = {Comput. Commun.},
  title        = {Unbalanced abnormal traffic detection based on improved res-BIGRU and integrated dynamic ELM optimization},
  volume       = {179},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A renewable energy-aware power allocation for cloud data
centers: A game theory approach. <em>COMCOM</em>, <em>179</em>, 102–111.
(<a href="https://doi.org/10.1016/j.comcom.2021.08.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid emerging of Internet of Things (IoT) devices and the proliferation of cloud-based applications, the cloud computing industry is becoming a vital element for ensuring our daily services. However, cloud computing uses large scale data centers equipped with energy-hungry servers and huge power facilities that massively consume power. This presents a real challenge which can negatively influence the power grid, while exposing the environment to global warming issues. Therefore, minimizing cloud data center power consumption is a challenging problem and has to be addressed. In this paper, we look at renewable energy in the context of a smart grid–cloud architecture and investigate the issue of grid power dispatching to cloud data centers . Since cloud data centers have a non-cooperative nature regarding power demand from the power stations, we model our power allocation problem as a non-cooperative game. Afterwards, we prove the existence and the uniqueness of Nash equilibrium . Moreover, we formulate the payoff function of our game as a non-linear optimization problem before resolving it using Lagrange multipliers and Karush–Kuhn–Tucker (KKT) conditions. Thus, we determine the assigned optimal quantity to each data center based on three main criteria : renewable energy usage, number of critical running applications and workload charge. Extensive simulations are performed by comparing our scheme with an existing work. Results show that our scheme outperforms the comparing approach with a percentage of 31.2\% in terms of power load rate and significantly reduces emissions of carbon dioxide.},
  archive      = {J_COMCOM},
  author       = {Mohammed Anis Benblidia and Bouziane Brik and Moez Esseghir and Leila Merghem-Boulahia},
  doi          = {10.1016/j.comcom.2021.08.001},
  journal      = {Computer Communications},
  pages        = {102-111},
  shortjournal = {Comput. Commun.},
  title        = {A renewable energy-aware power allocation for cloud data centers: A game theory approach},
  volume       = {179},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A hierarchical caching strategy in content delivery network.
<em>COMCOM</em>, <em>179</em>, 92–101. (<a
href="https://doi.org/10.1016/j.comcom.2021.07.029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper considers a hierarchical content delivery network in a randomly distributed interference environment, where the caching capability is distributed among two layers, the caching nodes and part of users. We propose a hierarchical caching strategy that is jointly optimized with the delivery performance, to achieve a fine balance between the cooperative gain and the caching diversity gain. In particular, to guarantee the effectiveness of caching strategy, the impact of communication interference at different layers on caching strategy is discussed during the file delivery phase. The optimization problem to maximize the offloading probability is formulated as a combinatorial optimization problem . By breaking the problem into two sub-multiple choice knapsack problems , the extreme case in the absence of user caching ability is first analyzed, and an optimization method based on the worst-case among users is proposed. Detailed analytical analysis and simulation experiments are carried out to evaluate the proposed caching strategy. The experimental results prove the superiority of the proposed cache strategy by comparing it with other caching strategies.},
  archive      = {J_COMCOM},
  author       = {Fang Shi and Lisheng Fan and Xiazhi Lai and Yuehong Chen and Weiwei Lin},
  doi          = {10.1016/j.comcom.2021.07.029},
  journal      = {Computer Communications},
  pages        = {92-101},
  shortjournal = {Comput. Commun.},
  title        = {A hierarchical caching strategy in content delivery network},
  volume       = {179},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Resources optimization for secure transmission in wireless
powered communication networks. <em>COMCOM</em>, <em>179</em>, 82–91.
(<a href="https://doi.org/10.1016/j.comcom.2021.07.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the secrecy communication on wireless powered communication network (WPCN) in an orthogonal frequency division multiplexing (OFDM) system, where an energy harvest (EH) user sends confidential information to the hybrid access point (HAP) in the presence of a potential eavesdropper. We introduce a wireless powered cooperative jammer to improve the secrecy performance of this system. For the user and the jammer , we both consider the linear energy harvesting model and the nonlinear energy harvesting model. More specifically, the half-duplex WPCN is considered first. We study secrecy rate maximization problem by jointly optimizing the time allocation and the transmit power allocation for the HAP, the jammer and the user over sub-carriers. The nested form algorithm is proposed to solve the original non-convex problem, where one-dimension search method is used at the outer layer and a convex approximation algorithm by leveraging DC-based optimization is adopted at the inner layer. Then, the full-duplex WPCN is considered. We formulated the secrecy rate maximization problem and optimized the transmit power by using the DC algorithm and convex optimization . Simulation results demonstrate that the proposed scheme dramatically enhances the secrecy rate compared to the benchmark schemes.},
  archive      = {J_COMCOM},
  author       = {Juan Sun and Shubin Zhang and Kaikai Chi},
  doi          = {10.1016/j.comcom.2021.07.017},
  journal      = {Computer Communications},
  pages        = {82-91},
  shortjournal = {Comput. Commun.},
  title        = {Resources optimization for secure transmission in wireless powered communication networks},
  volume       = {179},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Amelia—a new security protocol for protection against false
links. <em>COMCOM</em>, <em>179</em>, 73–81. (<a
href="https://doi.org/10.1016/j.comcom.2021.07.030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent months, the demand for services provided on the Internet (scientific conferences, training, webinars) has increased. As this activity grew, so did cybercrime . Social networks share invitations to various training and webinars. We also receive similar announcements via e-mail. It is not difficult to accidentally click on the attached link. The submitted URL may contain a script. The script may infect our device or steal our login details. We have developed a new security protocol — Amelia, to protect against responding to a false invitation to a web event. Our protocol makes it possible to check if the link sent is valid. Also, it enables the generation of unique user identifiers. Amelia protocol provides users’ verification and distribution of symmetric session keys. We conducted a study of our protocol. We checked its vulnerability to Intruder attacks. The obtained results are promising. We did not find an attack on this protocol.},
  archive      = {J_COMCOM},
  author       = {Sabina Szymoniak ( Researcher )},
  doi          = {10.1016/j.comcom.2021.07.030},
  journal      = {Computer Communications},
  pages        = {73-81},
  shortjournal = {Comput. Commun.},
  title        = {Amelia—A new security protocol for protection against false links},
  volume       = {179},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). IoTD: An approach to identify e-mails sent by IoT devices.
<em>COMCOM</em>, <em>179</em>, 62–72. (<a
href="https://doi.org/10.1016/j.comcom.2021.07.024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the number of low-cost Internet-of-Things (IoT) devices increases dramatically in recent years, they have become ideal targets for E-mail spammers. Some network cameras are shipped to the market with default passwords . Operating systems of many IoT devices are often outdated or not well-configured. Those practices make IoT devices easy to be compromised. Some of these compromised IoT devices may be used for E-mail spamming. Hence, how to handle undesired connections from client IoT devices becomes an important issue for mail server administrators. Even though the whitelist or blacklist are adopted by a mail server only allowing to receive E-mails relayed from few trusted SMTP servers, such list-based approach apparently cannot be applied for global SMTP clients when considering to the flexibility and cost of list maintenance. For most mail servers providing SMTP for desktop, laptop, or mobile clients rather than IoT devices, this paper proposes a server-side approach, called IoT detector (IoTD), to detect E-mails which are sent from IoT devices. Because the majority of IoT devices are not used by human users to send E-mail, administrators of mail servers may consider the E-mail sent by an IoT device as spam directly if IoT clients are not expected. Experimental results show that IoTD can accurately detect E-mails sent by IoT devices. The accuracy evaluation among five IoT devices and two non-IoT devices of this study shows that all tests for these five IoT devices are true positives , and all tests for these two non-IoT devices are true negatives as well.},
  archive      = {J_COMCOM},
  author       = {Fu-Hau Hsu and Jyun-Shao Wu and Chih-Wen Ou and Tzu-Chi Liu and Yung-Yu Zhuang},
  doi          = {10.1016/j.comcom.2021.07.024},
  journal      = {Computer Communications},
  pages        = {62-72},
  shortjournal = {Comput. Commun.},
  title        = {IoTD: An approach to identify E-mails sent by IoT devices},
  volume       = {179},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A novel visibility semantic feature-aided pedestrian
detection scheme for autonomous vehicles. <em>COMCOM</em>, <em>179</em>,
50–61. (<a href="https://doi.org/10.1016/j.comcom.2021.06.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intelligent transportation systems (ITS) have become a popular method for enhancing transportation safety and efficiency. As essential participants of ITS, autonomous vehicles need to detect pedestrians accurately. In this paper, we propose a one-stage anchor-free pedestrian detection model named Bi-Center Network (BCNet), which is aided by the semantic features of pedestrians’ visible parts. We perform an ablation study to discover how visibility features could benefit the detector’s performance, including introducing two hyper-parameters and adopting three different attention mechanisms , respectively. The experimental results indicate that the performance of pedestrian detection could be significantly improved, since the visibility semantic could prompt stronger responses on the heatmap. We compare our BCNet variants with state-of-the-art models on the CityPersons dataset and ETH dataset; results indicate that our detector is effective and achieves a promising performance.},
  archive      = {J_COMCOM},
  author       = {Mingzhi Sha and Azzedine Boukerche},
  doi          = {10.1016/j.comcom.2021.06.009},
  journal      = {Computer Communications},
  pages        = {50-61},
  shortjournal = {Comput. Commun.},
  title        = {A novel visibility semantic feature-aided pedestrian detection scheme for autonomous vehicles},
  volume       = {179},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Traveling salesman problem with drone under recharging
policy. <em>COMCOM</em>, <em>179</em>, 35–49. (<a
href="https://doi.org/10.1016/j.comcom.2021.07.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The traveling salesman problem is one of the most studied problems in combinatorial optimization . An emerging variant of this problem, which is referred to as the traveling salesman problem with drone, focuses on deploying a drone and a delivery truck for last-mile delivery. This problem coordinates the truck and drone deliveries in both time and location because the drone requires the truck to refresh its battery and load the next customer’s package on the drone. Previous studies assume that the drone battery is swapped with a new/fully recharged battery at the end of each drone flight. In contrast, this study investigates a flexible recharging policy. For this purpose, we develop a new mixed integer linear programming formulation into which remaining battery level consideration is incorporated. A computational study is provided to compare the recharging policy with the battery swapping policy in terms of delivery time. Due to the complexity of the problem, a heuristic approach is proposed to solve medium-sized instances.},
  archive      = {J_COMCOM},
  author       = {Emine Es Yurek and H. Cenk Ozmutlu},
  doi          = {10.1016/j.comcom.2021.07.013},
  journal      = {Computer Communications},
  pages        = {35-49},
  shortjournal = {Comput. Commun.},
  title        = {Traveling salesman problem with drone under recharging policy},
  volume       = {179},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A randomized algorithm for joint power and channel
allocation in 5G D2D communication. <em>COMCOM</em>, <em>179</em>,
22–34. (<a href="https://doi.org/10.1016/j.comcom.2021.07.018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We formulate the joint power and channel allocation problem (JPCAP) for device to device (D2D) communication as a cost minimization problem , where cost is defined as a linear combination of the number of channels used and total power requirement. We first show that JPCAP is a NP-hard problem and providing n 1 / ε n1/ε approximation for JPCAP ∀ ε &gt; 0 ∀ε&amp;gt;0 is also NP-hard. Then we propose a mixed integer linear programming (MILP) to solve this problem. As solving MILP is a NP-hard problem we propose a greedy channel and power allocation (GCPA) algorithm to assign channels and powers to the links. We design GCPA in such a fashion that there exists an order of the links for which it produces optimum solution. We show that an order is equivalent to many orders and hence design an incremental algorithm (IA) to efficiently search good orders. Finally using IA we develop a randomized joint channel and power allocation (RJCPA) algorithm. We show that if a certain condition holds we can find the optimum in expected polynomial time else a slowly growing exponential time with very high probability. We then theoretically calculate the expected cost and energy efficiency (EE) produced by RJCPA. Through simulation, we show that RJCPA outperforms two existing approaches with respect to both cost and EE significantly. Finally we validate our theoretical findings through simulation.},
  archive      = {J_COMCOM},
  author       = {Subhankar Ghosal and Sasthi C. Ghosh},
  doi          = {10.1016/j.comcom.2021.07.018},
  journal      = {Computer Communications},
  pages        = {22-34},
  shortjournal = {Comput. Commun.},
  title        = {A randomized algorithm for joint power and channel allocation in 5G D2D communication},
  volume       = {179},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Resource design in federated sensor networks using
RELOAD/CoAP overlay architectures. <em>COMCOM</em>, <em>179</em>, 11–21.
(<a href="https://doi.org/10.1016/j.comcom.2021.07.019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sensor networks can be federated for wide-area geographical coverage using RELOAD/CoAP architectures. In this case, proxy nodes of constrained environments form a P2P overlay to announce device resources or sensor data. Although this is a standard-based solution, consistency problems may arise because P2P resources (data objects stored at the overlay network) may end up including similar device resource entries. This is so because device resource entries, or sensor data, can be announced under different P2P resource umbrellas, meaning that any update to them will require changing multiple P2P resources. Here in this article, a multi-layer approach is proposed to solve this issue, allowing for a more efficient storage/retrieval of IoT data. Information at the overlay network is kept consistent, although additional P2P anonymous resources must be created. A mathematical model is proposed for the planning of such multi-layer organization of P2P resources, together with a heuristic algorithm . A required overlay service is also discussed.},
  archive      = {J_COMCOM},
  author       = {L. Rodrigues and J. Guerreiro and N. Correia},
  doi          = {10.1016/j.comcom.2021.07.019},
  journal      = {Computer Communications},
  pages        = {11-21},
  shortjournal = {Comput. Commun.},
  title        = {Resource design in federated sensor networks using RELOAD/CoAP overlay architectures},
  volume       = {179},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Genetically optimized massively parallel binary neural
networks for intrusion detection systems. <em>COMCOM</em>, <em>179</em>,
1–10. (<a href="https://doi.org/10.1016/j.comcom.2021.07.015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a new hard-wired combinational Binary Neural Network (BNN) architecture and its design methodology, where the networks are constructed and trained with the aim of tackling the problem of classifying IP packets efficiently for Intrusion Detection Systems (IDSs). Shallow, single-hidden-layer BNNs are trained on benchmark NSL-KDD and UNSW-NB15 datasets and achieve accuracy rates (77.77\% to 98.96\%) comparable to those of similar compact networks used for detecting intrusions . These networks are then implemented in Field-Programmable Gate Arrays (FPGAs) using this novel combinational ripple architecture, which is optimized using a genetic algorithm and uses neuron-to-neuron similarities to achieve state-of-the-art performance in terms of resource usage (8606 to 17990 lookup tables) and classification latency (16– 19 ns 19ns ).},
  archive      = {J_COMCOM},
  author       = {Tadej Murovič and Andrej Trost},
  doi          = {10.1016/j.comcom.2021.07.015},
  journal      = {Computer Communications},
  pages        = {1-10},
  shortjournal = {Comput. Commun.},
  title        = {Genetically optimized massively parallel binary neural networks for intrusion detection systems},
  volume       = {179},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A fog assisted intelligent framework based on cyber physical
system for safe evacuation in panic situations. <em>COMCOM</em>,
<em>178</em>, 297–306. (<a
href="https://doi.org/10.1016/j.comcom.2021.08.022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the current scenario of the COVID-19 pandemic and worldwide health emergency, one of the major challenges is to identify and predict the panic health of persons. The management of panic health and on-time evacuation prevents COVID-19 infection incidences in educational institutions and public places. Therefore, a system is required to predict the infection and suggests a safe evacuation path to people that control panic scenarios with mortality. In this paper, a fog-assisted cyber physical system is introduced to control panic attacks and COVID-19 infection risk in public places. The proposed model uses the concept of physical and cyber space. The physical space helps in real time data collection and transmission of the alert generation to the stakeholders. Cyberspace consists of two spaces, fog space, and cloud-space. The fog-space facilitates panic health and COVID-19 symptoms determination with alert generation for risk-affected areas. Cloud space monitors and predicts the person’s panic health and symptoms using the SARIMA model. Furthermore, it also identifies risk-prone regions in the affected place using Geographical Population Analysis. The performance evaluation acknowledges the efficiency related to panic health determination and prediction based on the SARIMA with risks mapping accuracy. The proposed system provides an efficient on time evacuation with priority from risk-affected places that protect people from attacks due to panic and infection caused by COVID-19.},
  archive      = {J_COMCOM},
  author       = {Sandeep Kumar Sood and Keshav Singh Rawat},
  doi          = {10.1016/j.comcom.2021.08.022},
  journal      = {Computer Communications},
  pages        = {297-306},
  shortjournal = {Comput. Commun.},
  title        = {A fog assisted intelligent framework based on cyber physical system for safe evacuation in panic situations},
  volume       = {178},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Deep neural network for text anomaly detection in SIoT.
<em>COMCOM</em>, <em>178</em>, 286–296. (<a
href="https://doi.org/10.1016/j.comcom.2021.08.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unsupervised textual anomaly detection , which discovers anomalies from unlabeled texts, is critical to improve the cybersecurity and interaction ability among the objects in the Social Internet of Things (SIoT). Recently, detecting anomalies by deep neural networks has become a popular trend. Specially, context vector data description (CVDD) method shows the promising performance. However, CVDD has two limitations: (1) it uses an one-class classification objective to constrain the sentence embeddings, which leads the learned embeddings to lose content information of text. (2) Scalar-based attention weights, which are used to extract sentence features, fail to focus on dimensional properties in a word. Learning the text contents and the dimensional properties is important for detection task in SIoT, which can help detector capture the difference between normal and anomaly texts. To overcome these limits, this paper proposes a textual anomaly detection network. First, an adversarial training strategy is designed to fight against the problem of missing content information. Second, a textual anomaly detection module with multiple dimensional transformation matrices is constructed to learn dimensional properties of words in diverse semantic subspaces. Experimental results on several textual datasets show that our proposed method outperforms CVDD and other strong baselines.},
  archive      = {J_COMCOM},
  author       = {Jie Mu and Xianchao Zhang and Yuangang Li and Jun Guo},
  doi          = {10.1016/j.comcom.2021.08.016},
  journal      = {Computer Communications},
  pages        = {286-296},
  shortjournal = {Comput. Commun.},
  title        = {Deep neural network for text anomaly detection in SIoT},
  volume       = {178},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Trajectory-aware spatio-temporal range query processing for
unmanned aerial vehicle networks. <em>COMCOM</em>, <em>178</em>,
271–285. (<a
href="https://doi.org/10.1016/j.comcom.2021.08.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unmanned aerial vehicle (UAV) network is widely used in environmental monitoring, target searching and rescuing, logistics, and other fields due to its characteristics of large-scale coverage, rapid deployment and strong resistance to destruction. When users are interested in sensory data in certain areas covered by UAV networks, they can send a spatio-temporal range query with time and geography constraints through the ground station. For example, obtaining the temperature information around fire points in the forest within an hour before the fire bursts out. Then, UAVs that carry the query results will return the data to the ground station through multi-hop routing. However, most of the existing spatio-temporal range query algorithms are designed for static networks. How to conduct spatio-temporal range queries in the UAV networks is still an open problem. In this paper, we propose a Trajectory-Aware Spatio-Temporal range query processing algorithm (TAST) for UAV networks. The ground station takes advantage of the pre-planned trajectory information of UAVs to build the topology change model of the UAV network, which can reflect the changes of UAVs’ communication links and neighbors. Furthermore, the static topology change graph (TCG) is proposed for optimizing the routing of query results in the spatio-temporal query processing. Next, we propose a Trajectory-Aware Spatio-Temporal range query processing algorithm based on packet Splitting (TASTS), which is used to split large query results into multiple small packets called unit packets, and each unit packet is transmitted back to the ground station independently and efficiently. Finally, we evaluated our algorithms through simulation experiments. The simulation results show that TAST and TASTS perform well in terms of query success rate, query efficiency and overhead ratio.},
  archive      = {J_COMCOM},
  author       = {Xin Li and Liang Liu and Lisong Wang and Jie Xi and Jianfei Peng and Jingwen Meng},
  doi          = {10.1016/j.comcom.2021.08.008},
  journal      = {Computer Communications},
  pages        = {271-285},
  shortjournal = {Comput. Commun.},
  title        = {Trajectory-aware spatio-temporal range query processing for unmanned aerial vehicle networks},
  volume       = {178},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Maximizing the minimum secrecy rate of two-way relay
networks. <em>COMCOM</em>, <em>178</em>, 259–270. (<a
href="https://doi.org/10.1016/j.comcom.2021.08.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper concerns maximizing the minimum achievable secrecy rate in a two-way multi-antenna relay network in which two single-antenna nodes aim at exchanging their confidential messages with the help of some multi-antenna relays incorporating the Amplify and Forward (AF) strategy, while a single-antenna passive eavesdropper attempts to overhear the exchanged information. The communication is carried out in two hops. During the first hop, two source nodes transmit their information, hence, the relays get a combination of transmitted signals. Then, throughout the second hop, each relay applies a beamforming matrix to its received signal vector and broadcasts the resulting signal vector to the transmitting ends. Also, the eavesdropper overhears the exchanged information of two hops. The main goal persuaded in the current work is to devise proper beamforming strategies at the relays to improve the minimum secrecy rate. The problem is cast as an optimization problem , where it is shown that the underlying problem is not convex in general. Hence, two suboptimal approaches, called null-space (NS) and interference-leakage alignment (ILA) are devised, where using the so-called semi-definite relaxation (SDR) and Charnes–Cooper transformation techniques, the underlying problems are formulated as semi-definite programming (SDP) problems which can be numerically solved.},
  archive      = {J_COMCOM},
  author       = {Faezeh Sharifi and Soroush Akhlaghi},
  doi          = {10.1016/j.comcom.2021.08.012},
  journal      = {Computer Communications},
  pages        = {259-270},
  shortjournal = {Comput. Commun.},
  title        = {Maximizing the minimum secrecy rate of two-way relay networks},
  volume       = {178},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Survey on atrial fibrillation detection from a single-lead
ECG wave for internet of medical things. <em>COMCOM</em>, <em>178</em>,
245–258. (<a
href="https://doi.org/10.1016/j.comcom.2021.08.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advances of Internet of Medical Things have allowed for continuous heart rhythm monitoring in a comfortable fashion. Single lead Electrocardiograph (ECG) is first collected by the wearable devices , and then some intelligent approaches are employed for automatic recognition of heart rhythms. Because the single lead ECG wave is different from traditional 12-leads Holter-based ECG signal in terms of high noise/artifact and the missing of other channels, specific algorithms for pattern recognition of the single lead ECG waves have been proposed in recent years. This paper systematically surveys state-of-the-art methods for screening atrial fibrillation from a single lead ECG wave. The database and performance metrics for this problem are demonstrated, the data preprocessing and feature extraction techniques are collected, and then the learning methods in terms of machine learning and deep learning are comparatively summarized. Specifically, the techniques for data preprocessing are reviewed and the most common and powerful features are listed, which are capable of providing a guideline for researchers aiming at developing AF detection algorithms . Finally, we discuss the potential contributors that are probably helpful for screening the atrial fibrillation from a single lead ECG wave.},
  archive      = {J_COMCOM},
  author       = {Yu Liu and Junxin Chen and Nan Bao and Brij B. Gupta and Zhihan Lv},
  doi          = {10.1016/j.comcom.2021.08.002},
  journal      = {Computer Communications},
  pages        = {245-258},
  shortjournal = {Comput. Commun.},
  title        = {Survey on atrial fibrillation detection from a single-lead ECG wave for internet of medical things},
  volume       = {178},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Optimization of network sensor node location based on edge
coverage control. <em>COMCOM</em>, <em>178</em>, 234–244. (<a
href="https://doi.org/10.1016/j.comcom.2021.07.027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasing maturity of wireless communication technology and computer software has dramatically reduced the cost of embedded devices with functions such as sensing targets, processing data, and communications and expanded the application scenarios and scale, which has promoted the rapid development of WSN. Moreover, the acquisition of location information of unknown nodes is one of the critical issues that can be studied in wireless sensor networks . Therefore, aiming to solve large-ranging errors caused by uncertain factors in the ranging stage, this paper proposes a sensor network positioning method based on edge coverage control. It can dynamically correct model parameters to improve the performance of the DV-Hop method, integrate RSSI technology and error correction into the corresponding stage of DV-Hop, and make full use of the advantages of RSSI technology in short-distance applications. With the help of the known location information in WSN, the ranging error is reduced while avoiding information redundancy . The performance of DV-Hop can be improved to finally solve the positioning problem when the node deployment is relatively sparse. Simulation verification data show that the improved method can effectively reduce the distance estimation error in the same situation and achieve higher positioning accuracy.},
  archive      = {J_COMCOM},
  author       = {Yanna Wang and Xinyue Zhou and Jian Sun and Xiaoye Li and Junping Zhang},
  doi          = {10.1016/j.comcom.2021.07.027},
  journal      = {Computer Communications},
  pages        = {234-244},
  shortjournal = {Comput. Commun.},
  title        = {Optimization of network sensor node location based on edge coverage control},
  volume       = {178},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Subjective logic-based trust model for fog computing.
<em>COMCOM</em>, <em>178</em>, 221–233. (<a
href="https://doi.org/10.1016/j.comcom.2021.05.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fog computing , a term coined by Cisco, is a new paradigm that extends the capabilities and services of cloud computing to the edge of the network. As a result, fog computing provides better location awareness and reduces the latency that occurs due to the distance between end devices and the cloud, which is a major issue for sensitive applications. Given that fog computing runs software on devices at the edge of the network rather than on the cloud side, it supports real-time smart applications, such as smart homes, smart grids, health data management, and smart vehicular technologies . This study focuses on security and privacy challenges in the fog computing paradigm and proposes a trust mechanism to address data breach, data loss, and denial of service (DoS) and establish a secure environment for fog applications. The novel model based on the subjective logic method calculates the trust value of nodes to determine if a node is a legitimate node or a rogue node. The proposed trust model is implemented on iFogSim simulator and analyzed with multiple fog nodes, which clearly demonstrates the efficacy of the proposed model in providing effective security.},
  archive      = {J_COMCOM},
  author       = {Jalal Al Muhtadi and Rawan A. Alamri and Farrukh Aslam Khan and Kashif Saleem},
  doi          = {10.1016/j.comcom.2021.05.016},
  journal      = {Computer Communications},
  pages        = {221-233},
  shortjournal = {Comput. Commun.},
  title        = {Subjective logic-based trust model for fog computing},
  volume       = {178},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Channel allocation optimization algorithm for hybrid
wireless mesh networks for information physical fusion system.
<em>COMCOM</em>, <em>178</em>, 212–220. (<a
href="https://doi.org/10.1016/j.comcom.2021.07.031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reasonable channel selection and allocation is the basis and premise of fair routing protocol design in information physical fusion system. In this paper, a channel allocation optimization algorithm for hybrid wireless mesh networks is proposed for the information physical fusion system. A new channel allocation model is designed, which uses greedy algorithm to select the channel with the least interference for the wireless network link. Based on the spatiotemporal multi interface and multi-channel allocation optimization algorithm , a joint channel allocation algorithm based on greedy algorithm is proposed in this paper. The communication between nodes is artificially divided into continuous sub time periods, but the communication between nodes cannot be guaranteed to exist in a certain period of time. The communication lines between nodes can be determined to avoid the shortcoming because the shortest path is used as the index to allocate the communication path.},
  archive      = {J_COMCOM},
  author       = {Shasha Zhao and Gan Yu},
  doi          = {10.1016/j.comcom.2021.07.031},
  journal      = {Computer Communications},
  pages        = {212-220},
  shortjournal = {Comput. Commun.},
  title        = {Channel allocation optimization algorithm for hybrid wireless mesh networks for information physical fusion system},
  volume       = {178},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Anomaly detection method of packet loss node location in
heterogeneous hash networks. <em>COMCOM</em>, <em>178</em>, 201–211. (<a
href="https://doi.org/10.1016/j.comcom.2021.07.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When the current method is used to detect the location anomaly of packet loss nodes in heterogeneous hash networks, the detection takes a long time, and the detection results obtained have large errors, which have the problems of low detection efficiency and low accuracy. This paper presents an anomaly detection method for packet loss node location in heterogeneous hash networks, The node distribution model and heterogeneous hash network topology are constructed, It provides relevant information for location anomaly detection of packet loss nodes, The high-pass graph filter is used to process the network signal to obtain high-frequency components, divide heterogeneous hash networks, obtain specific frequency components corresponding to sub-graph output signals, judge sub-graph signals through thresholds, establish suspected abnormal node sets, and compare suspected abnormal node sets and sub-graph node sets to realize abnormal detection of packet loss node location. The experimental results show that the method has good positioning effect, high detection efficiency, and better detection effectiveness and stability than the comparative test method.},
  archive      = {J_COMCOM},
  author       = {Jian Wang and Yulan Hu and Yining Wang and Qingshan Zhao},
  doi          = {10.1016/j.comcom.2021.07.003},
  journal      = {Computer Communications},
  pages        = {201-211},
  shortjournal = {Comput. Commun.},
  title        = {Anomaly detection method of packet loss node location in heterogeneous hash networks},
  volume       = {178},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Construction of super-resolution model of remote sensing
image based on deep convolutional neural network. <em>COMCOM</em>,
<em>178</em>, 191–200. (<a
href="https://doi.org/10.1016/j.comcom.2021.06.022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the continuous improvement of satellite remote sensing technology, using super-resolution image reconstruction technology to reconstruct remote sensing images has important application significance for social development. In the generator model proposed in this paper, the standard convolution layer in the residual network structure is replaced by empty convolution to improve the overall performance of the model while keeping the number of parameters unchanged and the receptive field of convolution at each stage unchanged. By analyzing the advantages of residual network , dense connection network, and cavity convolution in the field of image super resolution , an optimized super-resolution reconstruction model of GAN image with cavity convolution is constructed with dense connection block of cavity residue as a generator component. The cloud computing-based service model is introduced into the image reconstruction system, and the background management module is built through the cloud service system, which is responsible for model training, image transmission, image processing request and database reading. Through experimental analysis, it is proved that the whole automatic data processing from automatic matching data to processing data can be completed, and the performance is better than the traditional service mode, which can produce great economic benefits.},
  archive      = {J_COMCOM},
  author       = {Zikang Wei and Yunqing Liu},
  doi          = {10.1016/j.comcom.2021.06.022},
  journal      = {Computer Communications},
  pages        = {191-200},
  shortjournal = {Comput. Commun.},
  title        = {Construction of super-resolution model of remote sensing image based on deep convolutional neural network},
  volume       = {178},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Handoff control strategy of cyber physical systems under
dynamic data attack. <em>COMCOM</em>, <em>178</em>, 183–190. (<a
href="https://doi.org/10.1016/j.comcom.2021.07.026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the continuous development of Internet technology and Internet of things technology, digital and intelligent industrial system will continue to iterate. At the same time, as the core technology of the new generation of industrial system, cyber physical systems has also received more and more attention. At present, there are network security problems such as virus intrusion, denial of service and so on in the cyber physical systems , and the corresponding dynamic data attack will damage the cyber physical systems. Based on this, this paper will start with the information physical switching control theory under the dynamic data attack, and first establish the relevant mathematical model of the cyber physical systems for analysis, so as to realize the stability of the cyber physical system and the sensitivity of the handoff strategy so as to realize the stability of the cyber physical systems The sensitivity of switching strategy. In order to achieve the stability of the cyber physical systems under dynamic data attack, based on the control initiative related theorem, an innovative steady-state correction algorithm of the cyber physical systems is proposed, so that the system can achieve good control performance under dynamic data attack. The simulation results show that the proposed control strategy is effective.},
  archive      = {J_COMCOM},
  author       = {Hongzhi Cui},
  doi          = {10.1016/j.comcom.2021.07.026},
  journal      = {Computer Communications},
  pages        = {183-190},
  shortjournal = {Comput. Commun.},
  title        = {Handoff control strategy of cyber physical systems under dynamic data attack},
  volume       = {178},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). GraphNET: Graph neural networks for routing optimization in
software defined networks. <em>COMCOM</em>, <em>178</em>, 169–182. (<a
href="https://doi.org/10.1016/j.comcom.2021.07.025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a graph neural net-based routing algorithm is designed which leverages global information from controller of a software-defined network to predict optimal path with minimum average delay between source and destination nodes in software-defined networks. Graph nets are used because of their generalization capability which allows the routing algorithm to scale across varying topologies, traffic schemes and changing conditions. A deep reinforcement learning framework is developed to train the Graph Neural Networks using prioritized experience replay from the experiences learnt by the controllers. The algorithm is tested on various small and large topologies in terms of packets successfully routed and average packet delay time. Experiments are performed to check robustness of routing algorithms to changes in network structure and effects of varying hyperparameters. The proposed algorithm shows impressive results when compared to q-routing and shortest path routing algorithm in terms of above experiments and is robust to varying graphical structure of the network.},
  archive      = {J_COMCOM},
  author       = {Avinash Swaminathan and Mridul Chaba and Deepak Kumar Sharma and Uttam Ghosh},
  doi          = {10.1016/j.comcom.2021.07.025},
  journal      = {Computer Communications},
  pages        = {169-182},
  shortjournal = {Comput. Commun.},
  title        = {GraphNET: Graph neural networks for routing optimization in software defined networks},
  volume       = {178},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Maintainable stochastic communication network reliability
within tolerable packet error rate. <em>COMCOM</em>, <em>178</em>,
161–168. (<a
href="https://doi.org/10.1016/j.comcom.2021.07.023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The communication networks are complex and considered a stochastic flow network. This throws enormous challenges for the service provider to provide a desired Quality of Service (QoS) to the customer. Due to the stochastic behavior of the network, ensuring QoS requires serious efforts to make the entire system work within the given time constraint, cost, and failure rate. When the communication problem is time-bound, providing a quick and reasonable solution with a permissible error rate is of great importance. Therefore, in this paper, fast solutions to data communication problems are proposed to send the required d d units of user’s data from the desired source node to the destination node within some constraints such as permissible error rate ε ε , time constraint T T and maintenance budget constraints B B . System reliability and the performance of the proposed approaches are evaluated using minimal paths. All the minimal flow vectors evaluated from minimal paths that satisfy all the above-mentioned constraints are considered for network reliability evaluation. Further, the proposed approaches are observed as faster concerning computation time than the existing approaches.},
  archive      = {J_COMCOM},
  author       = {Suchi Kumari and Rajesh Kumar and Seifedine Kadry and Suyel Namasudra and David Taniar},
  doi          = {10.1016/j.comcom.2021.07.023},
  journal      = {Computer Communications},
  pages        = {161-168},
  shortjournal = {Comput. Commun.},
  title        = {Maintainable stochastic communication network reliability within tolerable packet error rate},
  volume       = {178},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Transformer text recognition with deep learning algorithm.
<em>COMCOM</em>, <em>178</em>, 153–160. (<a
href="https://doi.org/10.1016/j.comcom.2021.04.031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The transformer is a vital equipment in the power system , which is used in large quantities and replaced frequently in industrial projects. Therefore, it is essential to find an efficient automatic detection and recognition method for the text information of the transformer nameplate. At present, the text information of the transformer nameplate is collected manually, which is inefficient. On the other hand, the complex text features of transformer nameplates are a challenge to the existing text recognition algorithms . Therefore, we propose a two-stage network based on deep learning to recognize the nameplate text content automatically. At the same time, we establish a transformer nameplate dataset due to the particularity of the data characteristics of the transformer nameplate. The dataset is used to train our network to improve its sensitivity of the transformer nameplate information. The experimental results show that our model achieves a recognition accuracy of 71\% in the transformer nameplate dataset. The test performance of our network on the transformer nameplate dataset is comparable with the state-of-the-art text recognition algorithms.},
  archive      = {J_COMCOM},
  author       = {Ye Chen and Hongchun Shu and Wenjiao Xu and Zhengyu Yang and Zhihu Hong and Mingshuai Dong},
  doi          = {10.1016/j.comcom.2021.04.031},
  journal      = {Computer Communications},
  pages        = {153-160},
  shortjournal = {Comput. Commun.},
  title        = {Transformer text recognition with deep learning algorithm},
  volume       = {178},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Operation and maintenance(o&amp;m) for data center: An
intelligent anomaly detection approach. <em>COMCOM</em>, <em>178</em>,
141–152. (<a
href="https://doi.org/10.1016/j.comcom.2021.06.030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the popularity of cloud services and big data in the Internet enterprise, the operation and maintenance (O&amp;M) of data centers have become more critical. The key to O&amp;M is to find anomalies through indicator data. However, the traditional O&amp;M suffers from poor efficiency and low satisfaction, along with a low degree of intelligence. Therefore, introducing a machine learning based anomaly detection method in O&amp;M can effectively improve real-time detection accuracy and make O&amp;M more intelligent. Based on two typical O&amp;M problems prevalent in Internet enterprises at present, stability detection and unattended release of cluster machines, this paper proposes an intelligent anomaly detection approach, called Ensemble learning on Partition Interval (ELPI). The main steps include dividing the data set into the stable interval and the unsteady interval. Then we establish an online/offline algorithm module and perform corresponding integrated learning for different interval characteristics to detect abnormal data. At last, we set up a self-feedback mechanism to dynamically adjust the module threshold. The results show that our method is more accurate and stable than traditional methods. Additionally, our method has been effectively applied to the anomaly detection of big clusters and app release.},
  archive      = {J_COMCOM},
  author       = {Xisheng Xiao and Jin Sun and Jinxin Yang},
  doi          = {10.1016/j.comcom.2021.06.030},
  journal      = {Computer Communications},
  pages        = {141-152},
  shortjournal = {Comput. Commun.},
  title        = {Operation and maintenance(O&amp;M) for data center: An intelligent anomaly detection approach},
  volume       = {178},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Network intrusion detection based on IE-DBN model.
<em>COMCOM</em>, <em>178</em>, 131–140. (<a
href="https://doi.org/10.1016/j.comcom.2021.07.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing network intrusion detection models suffer such problems as low detection accuracy and high false alarm rates in face of massive data traffic. Deep-learning models provide a solution as they can reduce the dimensionality of massive data, extract data features , and identify intrusions. However, the network structure and the number of hidden layer neurons of deep-learning models are determined by empirical or trial-and-error methods, which will affect the generalization ability and learning efficiency of the model. In the present work, a deep belief network model based on information entropy (IE-DBN model) is proposed for network intrusion detection . The model uses information gain (IG) to reduce the dimensionality of high-dimensional data features and remove redundant features. The information entropy is used to determine the number of hidden neurons in the DBN network and the network depth. The synthetic minority oversampling technique (SMOTE) algorithm is used to address the problem of data imbalance. Tests on the KDD CUP 99 intrusion detection data set have shown that the proposed IE-DBN model improved the convergence speed of the model and reduced the likelihood of overfitting. Compared with the conventional back propagation (BP) neural network and DBN network model, the IE-DBN model obtained a higher detection accuracy and a lower false alarm rate. Verification tests on other intrusion detection data sets showed that the proposed IE-DBN model had good generalization capacity.},
  archive      = {J_COMCOM},
  author       = {Huaping Jia and Jun Liu and Min Zhang and Xiaohu He and Weixi Sun},
  doi          = {10.1016/j.comcom.2021.07.016},
  journal      = {Computer Communications},
  pages        = {131-140},
  shortjournal = {Comput. Commun.},
  title        = {Network intrusion detection based on IE-DBN model},
  volume       = {178},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). MASK-GD segmentation based robotic grasp detection.
<em>COMCOM</em>, <em>178</em>, 124–130. (<a
href="https://doi.org/10.1016/j.comcom.2021.07.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reliability-grasping detection of an object in a complex scene is a challenging task and is a critical problem that needs to be solved urgently in practical application. At present, the grasp position is obtained through the feature analysis of the whole input image. However, the clutter background information in the image impairs the accuracy of grasping detection. In this paper, a robotic grasp detection algorithm named MASK-GD (grasp detection based on mask region) is proposed, which provides a feasible solution to this problem. MASK is a segmented image that only contains the pixels of the target object. MASK-GD for grasp detection only uses the features of the MASK area rather than the features of the entire image in the scene. It has two stages: the first stage is to provide the MASK area of the target object, and the second stage is a grasp detector based on the features of the MASK area. Experimental results demonstrate that the performance of MASK-GD is comparable with state-of-the-art grasp detection algorithms on Cornell Grasp Dataset and Jacquard Dataset. In the meantime, MASK-GD performs much better in complex scenes.},
  archive      = {J_COMCOM},
  author       = {Mingshuai Dong and Shimin Wei and Xiuli Yu and Jianqin Yin},
  doi          = {10.1016/j.comcom.2021.07.012},
  journal      = {Computer Communications},
  pages        = {124-130},
  shortjournal = {Comput. Commun.},
  title        = {MASK-GD segmentation based robotic grasp detection},
  volume       = {178},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Dynamic server placement in edge computing toward internet
of vehicles. <em>COMCOM</em>, <em>178</em>, 114–123. (<a
href="https://doi.org/10.1016/j.comcom.2021.07.021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Facing serious challenges in bandwidth and delay, currently adopted cloud computing is no longer effective for providing real-time Internet of Vehicles (IoV) services in the intelligent transportation system (ITS). A newly introduced computing paradigm with a distributed feature, i.e., edge computing , can be a complement to the centralized cloud computing with computation offloaded to the distributed edge servers (ESs). Typically, edge servers are the host of IoV services in edge computing , which requires an appropriate quantification and placement before the implementation of computation offloading . To pursue a higher quality of service (QoS), the quantity and locations of the ESs need to be thoroughly discussed ahead. Otherwise, additional delay and network congestion will occur. Simultaneously, as the ITS is continuously developing, the existing placement of ESs ought to be adjusted to be in line with the dynamic change of IoV traffic. However, ES placement schemes are often devised by clustering methods with a fixed ES quantity and are unaware of the extensibility of the placement. To address the problems that mentioned, a d ynamic E S p lacement approach (DEP) is developed. Technically, DEP leverages the non-dominated sorting genetic algorithm III (NSGA-III) for placements with better performance and less reconstruction of existing placement. The population of NSGA-III is initialized with clustering algorithms for a higher accuracy and convergence speed, and the fitness of minimum reconstruction cost is calculated based on Kuhn–Munkres bipartite graph matching algorithm . A real-world traffic data with 436 deployed roadside units in the provincial capital city Nanjing, China, is leveraged for comparative experiments . The experimental results verify the effectiveness of DEP with a 17.64\% lower latency and 25.82\% lower workload standard deviation comparing to the clustering method.},
  archive      = {J_COMCOM},
  author       = {Bowen Shen and Xiaolong Xu and Lianyong Qi and Xuyun Zhang and Gautam Srivastava},
  doi          = {10.1016/j.comcom.2021.07.021},
  journal      = {Computer Communications},
  pages        = {114-123},
  shortjournal = {Comput. Commun.},
  title        = {Dynamic server placement in edge computing toward internet of vehicles},
  volume       = {178},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Reinforcement and deep reinforcement learning for wireless
internet of things: A survey. <em>COMCOM</em>, <em>178</em>, 98–113. (<a
href="https://doi.org/10.1016/j.comcom.2021.07.014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, many research studies and industrial investigations have allowed the integration of the Internet of Things (IoT) in current and future networking applications by deploying a diversity of wireless-enabled devices ranging from smartphones, wearables, to sensors, drones, and connected vehicles. The growing number of IoT devices, the increasing complexity of IoT systems, and the large volume of generated data have made the monitoring and management of these networks extremely difficult. Numerous research papers have applied Reinforcement Learning (RL) and Deep Reinforcement Learning (DRL) techniques to overcome these difficulties by building IoT systems with effective and dynamic decision-making mechanisms, dealing with incomplete information related to their environments. The paper first reviews pre-existing surveys covering the application of RL and DRL techniques in IoT communication technologies and networking. The paper then analyzes the research papers that apply these techniques in wireless IoT to resolve issues related to routing, scheduling, resource allocation, dynamic spectrum access , energy, mobility, and caching. Finally, a discussion of the proposed approaches and their limits is followed by the identification of open issues to establish grounds for future research directions proposal.},
  archive      = {J_COMCOM},
  author       = {Mohamed Said Frikha and Sonia Mettali Gammar and Abdelkader Lahmadi and Laurent Andrey},
  doi          = {10.1016/j.comcom.2021.07.014},
  journal      = {Computer Communications},
  pages        = {98-113},
  shortjournal = {Comput. Commun.},
  title        = {Reinforcement and deep reinforcement learning for wireless internet of things: A survey},
  volume       = {178},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The groundwater potential assessment system based on cloud
computing: A case study in islands region. <em>COMCOM</em>,
<em>178</em>, 83–97. (<a
href="https://doi.org/10.1016/j.comcom.2021.06.028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Today’s intelligent system based on cloud computing platform can realize “unattended”, real-time monitoring observation and forecast by remote sensing. In order to import the development and efficiency of groundwater potential assessment(GPA) by remote sensing, the cloud computing platform was tried to use in the computing GPA. In this study, the Pearl River Estuary islands region(China) was selected as the study area. The slope, aspect, water-density(WD), land surface temperature(LST), NDVI and NDWI were used as the GPA indexes, which have been used before. Considering the similar geological and geomorphological conditions of the islands area, the analytic hierarchy process (AHP) method and these indexes can be used to assess GPA in the remote sensing cloud computing platform efficiently and conveniently. The results of the assessment were in good agreement with the actual hydrogeological map. Besides, the other intelligent algorithms can also be applied in this platform. Finally, this study realized the rapid “unattended” and “real-time monitoring” groundwater potential assessment, and carried out a multi-level GPA. It will be of certain reference significance to the exploitation of groundwater in the island area, which has realized convenient and efficient processing and analysis of data anytime and anywhere. At the same time, attention must be paid to the security of data and the maintenance of the system.},
  archive      = {J_COMCOM},
  author       = {Daqing Wang and Haoli Xu and Yue Shi and Zhibin Ding and Zhengdong Deng and Zhixin Liu and Xingang Xu and Zhao Lu and Guangyuan Wang and Zijian Cheng and Xiaoning Zhao},
  doi          = {10.1016/j.comcom.2021.06.028},
  journal      = {Computer Communications},
  pages        = {83-97},
  shortjournal = {Comput. Commun.},
  title        = {The groundwater potential assessment system based on cloud computing: A case study in islands region},
  volume       = {178},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A deep heterogeneous optimization framework for bayesian
compressive sensing. <em>COMCOM</em>, <em>178</em>, 74–82. (<a
href="https://doi.org/10.1016/j.comcom.2021.07.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Bayesian compressive sensing (BCS) is an available approach for data compressions based on compressed sensing framework. Moreover, the priors of sparse signals play a key role in BCS. Various studies that exploit the priors only via models generating, which exist the low prior utilizations. Therefore, to fully use the priors for signals recovering, we propose a novel deep heterogeneous optimization framework which can completely express the priors in a data-model double driven manner. Our work can be briefly summarized by the following aspects. As the heterogeneous handles benefiting recovery solutions, we firstly exploit the available heterogeneous arrangements for traditional BCS recovery models. Secondly, inspired by the deep neural networks (DNNs), we do researches on adding a deep optimization scheme for the scale parameters of heterogeneous prior functions via supervised learning. In addition to developing the three complete algorithms with that merge the prior parameters learning and signal recoveries. Finally, Experimental results show that for both synthetic data and images data our proposed double driven framework achieves the superior performances compared with that of the other well-known compressed recovery algorithms no matter in noise-free or noisy measurement environments.},
  archive      = {J_COMCOM},
  author       = {Le Qin and Yuanlong Cao and Xun Shao and Yong Luo and Xinping Rao and Yugen Yi and Gang Lei},
  doi          = {10.1016/j.comcom.2021.07.011},
  journal      = {Computer Communications},
  pages        = {74-82},
  shortjournal = {Comput. Commun.},
  title        = {A deep heterogeneous optimization framework for bayesian compressive sensing},
  volume       = {178},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Path control of panoramic visual recognition for intelligent
robots based-edge computing. <em>COMCOM</em>, <em>178</em>, 64–73. (<a
href="https://doi.org/10.1016/j.comcom.2021.06.018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The application of service-oriented intelligent robots in hospitals solves the problems of manual service such as delivery of medicines and orders from the medical aids. However, there is a problem of robot path planning , which leads to poor service. Taking the self-control robot with visual recognition capability in medical institutions as the research background, this paper proposes an image edge detection algorithm based on three-dimensional features. First, reconstruct the three-dimensional image through visual recognition, and calculate the three-dimensional feature map of the scene in the hospital. Secondly, the edge computing algorithm is used to realize the route area diversion, and the best route area is planned in the 3D feature map to realize the delivery of medicines and other items in the complex environment of the hospital, so as to achieve the purpose of improving the technical level of medical auxiliary equipment . Finally, the image restoration technology can improve the image clarity of the robot vision system and the robot automation level, and it is also helpful for the promotion of robot automatic path planning and control technology. The experimental results show that, compared with the hidden Markov algorithm, the method in this paper is significantly better than the hidden Markov algorithm, which meets the needs of medical institutions for intelligent robots .},
  archive      = {J_COMCOM},
  author       = {Linkun Fan and Xuchuan Li and Congshuai Guo and Bingshuo Jia},
  doi          = {10.1016/j.comcom.2021.06.018},
  journal      = {Computer Communications},
  pages        = {64-73},
  shortjournal = {Comput. Commun.},
  title        = {Path control of panoramic visual recognition for intelligent robots based-edge computing},
  volume       = {178},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Blockchain management and machine learning adaptation for
IoT environment in 5G and beyond networks: A systematic review.
<em>COMCOM</em>, <em>178</em>, 37–63. (<a
href="https://doi.org/10.1016/j.comcom.2021.07.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Keeping in view of the constraints and challenges with respect to big data analytics along with security and privacy preservation for 5G and B5G applications, the integration of machine learning and blockchain , two of the most promising technologies of the modern era is inevitable. In comparison to the traditional centralized techniques for security and privacy preservation , blockchain uses decentralized consensus algorithms for verification and validation of different transactions which are supposed to become an integral part of blockchain network. Starting with the existing literature survey, we introduce the basic concepts of blockchain and machine learning in this article. Then, we presented a comprehensive taxonomy for integration of blockchain and machine learning in an IoT environment. We also explored federated learning , reinforcement learning , deep learning algorithms usage in blockchain based applications. Finally, we provide recommendations for future use cases of these emerging technologies in 5G and B5G technologies.},
  archive      = {J_COMCOM},
  author       = {Arzoo Miglani and Neeraj Kumar},
  doi          = {10.1016/j.comcom.2021.07.009},
  journal      = {Computer Communications},
  pages        = {37-63},
  shortjournal = {Comput. Commun.},
  title        = {Blockchain management and machine learning adaptation for IoT environment in 5G and beyond networks: A systematic review},
  volume       = {178},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A softwarized resource allocation framework for security and
location guaranteed services in B5G networks. <em>COMCOM</em>,
<em>178</em>, 26–36. (<a
href="https://doi.org/10.1016/j.comcom.2021.07.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Network softwarization (NetSoft) is recognized as the most promising technology of the fundamental network architecture in beyond 5G (B5G). By adopting NetSoft, physical resources of B5G can be fully virtualized, sliced and softwarized. Softwarized resources are easy to be operated and managed. One dominant technical issue in NetSoft for B5G is the softwarized resource allocation. Efficient softwarized resource allocation can bring more benefits to the service providers. However, prior researchers simply focus on maximizing the softwarized resource acceptance. Few research is conducted to guarantee the security and location demands of each softwarized service. Thus, we propose one softwarized resource allocation framework in this paper. The framework is labeled as NetSoft-Sec-Loc . The goal of NetSoft-Sec-Loc is to provide the guaranteed security and location services besides of fulfilling their softwarized resource demands. Details of NetSoft-Sec-Loc are presented. In order to highlight the merits of NetSoft-Sec-Loc framework, we do the comprehensive simulation work. We select the mostly closely framework and resource allocation strategies for comparison. Simulation results are plotted and discussed.},
  archive      = {J_COMCOM},
  author       = {Shengchen Wu and Haotong Cao and Haitao Zhao and Yue Hu and Longxiang Yang and Hao Yin and Hongbo Zhu},
  doi          = {10.1016/j.comcom.2021.07.007},
  journal      = {Computer Communications},
  pages        = {26-36},
  shortjournal = {Comput. Commun.},
  title        = {A softwarized resource allocation framework for security and location guaranteed services in B5G networks},
  volume       = {178},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Optimization algorithm of wireless surveillance data
transmission task based on edge computing. <em>COMCOM</em>,
<em>178</em>, 14–25. (<a
href="https://doi.org/10.1016/j.comcom.2021.07.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cloud computing and edge computing have potent capabilities and value, and the combination of edge computing and wireless transmission has become a research hotspot, making cloud computing and edge computing adapt to broader application scenarios and exert more powerful functions. Due to the relatively large data volume of terminal devices in the edge computing network, how to process the upstream data stream and efficiently and accurately realize the wireless data monitoring transmission is a problem that the edge server needs to solve. This paper analyzes the interaction and cooperation relationship between levels, proposes a scheduling model and storage strategy for uplink data flow, and uses data flow scheduling and data flow hierarchical storage algorithms to optimize the edge system of data flow scheduling and storage. Combined with the attributes of the edge computing network system, the measurement indicators of the scheduling and storage of the terminal uplink data flow in the edge computing network are modeled and analyzed. We analyze the processing time delay , cost, and optimization target for optimizing the data transmission task. The simulation experiments prove that the algorithm in this paper has advantages in solving data transmission and storage problems in the network. It can reduce costs and delays, increase throughput, ensure monitoring node access delays, and maintain edge servers and disaster monitoring data centers .},
  archive      = {J_COMCOM},
  author       = {Peng Liu and Shuran Lyu and Shuqi Ma and Wanqing Wang},
  doi          = {10.1016/j.comcom.2021.07.008},
  journal      = {Computer Communications},
  pages        = {14-25},
  shortjournal = {Comput. Commun.},
  title        = {Optimization algorithm of wireless surveillance data transmission task based on edge computing},
  volume       = {178},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Quality of perception prediction in 5G slices for e-health
services using user-perceived QoS. <em>COMCOM</em>, <em>178</em>, 1–13.
(<a href="https://doi.org/10.1016/j.comcom.2021.07.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to compete for a prominent market share, network operators and service providers should retain and increase the verticals’ subscription, catering to their needs in order to differentiate themselves from competitors. In this scenario, verticals’ satisfaction arises of paramount importance. As such, user experience is becoming a reliable indicator for service providers and telecommunication operators to convey overall end-to-end system functioning. To properly estimate end user satisfaction, operators and service providers require efficient means for quality monitoring and estimation at all layers, in conjunction with mechanisms able to maintain said quality at optimum levels. Given these factors, this paper proposes a mechanism for Quality of Perception (QoP) estimation in e-Health services, enabling the QoP-aware management of network slices fulfilling the requirements of supported services. To this end, the paper proposes a cognitive-based architecture which allows for the collection and monitoring of verticals’ data to estimate QoP and provides mechanisms to re-configure the underlying network slices according to the monitored quality levels. A machine learning (ML) model is introduced that aims to forecast any future degradation in the quality perceived by vertical users. In case of a predicted degradation, the proposed architecture reacts and triggers the necessary remedial actions, referred as actuations . In order to evaluate the developed ML model and to showcase the interaction between the different components of the proposed architecture, an experimental study is presented with real data extracted from a roaming ambulance. In addition, a Proof of Concept of the actuation mechanism is demonstrated through an experimental testbed emulating e-Health services.},
  archive      = {J_COMCOM},
  author       = {Yosra Ben Slimen and Joanna Balcerzak and Albert Pagès and Fernando Agraz and Salvatore Spadaro and Konstantinos Koutsopoulos and Mustafa Al-Bado and Thuy Truong and Pietro G. Giardina and Giacomo Bernini},
  doi          = {10.1016/j.comcom.2021.07.002},
  journal      = {Computer Communications},
  pages        = {1-13},
  shortjournal = {Comput. Commun.},
  title        = {Quality of perception prediction in 5G slices for e-health services using user-perceived QoS},
  volume       = {178},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Retraction notice to “an assessment of software defined
networking approach in surveillance using sparse optimization algorithm”
[comput. Commun. 151 (2020) 98–110]. <em>COMCOM</em>, <em>177</em>, 265.
(<a href="https://doi.org/10.1016/j.comcom.2021.08.019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_COMCOM},
  author       = {T.K.S. Rathish Babu and N.M. Balamurugan and S. Suresh and L. Sharmila},
  doi          = {10.1016/j.comcom.2021.08.019},
  journal      = {Computer Communications},
  pages        = {265},
  shortjournal = {Comput. Commun.},
  title        = {Retraction notice to “An assessment of software defined networking approach in surveillance using sparse optimization algorithm” [Comput. commun. 151 (2020) 98–110]},
  volume       = {177},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multiple intersection selection routing protocol based on
road section connectivity probability for urban VANETs. <em>COMCOM</em>,
<em>177</em>, 255–264. (<a
href="https://doi.org/10.1016/j.comcom.2021.08.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An efficient routing protocol is of great significance to improve vehicular ad hoc networks (VANETs) performance. However, due to complex road conditions, intermittent connectivity among vehicles and rapid changes of network topology , how to design an efficient routing protocol in an urban environment to transmit the data packet to the destination remains a challenging problem. In this paper, we propose a multiple intersection selection based on road section connectivity probability routing protocol for vehicle–vehicle (V2V) communication in urban VANETs, which considers the vehicle distribution influenced by traffic lights. First, we present a method to calculate the road section connectivity probability of a two-way lane with traffic lights consideration. Then, we establish an optimization model to select the optimal road path from the source node to the destination node based on the road section connectivity probability. Furthermore, we analyze the relay node selection on the road section after the optimal road path is determined, which discusses the number of neighbor vehicles in the communication range of the vehicle carrying packets and jointly considers the position, speed and direction of vehicles. Simulation results demonstrate that our proposed routing protocol increases the packet delivery rate and reduces the end-to-end delay.},
  archive      = {J_COMCOM},
  author       = {Shuang Zhou and Demin Li and Qinghua Tang and Yue Fu and Chang Guo and Xuemin Chen},
  doi          = {10.1016/j.comcom.2021.08.004},
  journal      = {Computer Communications},
  pages        = {255-264},
  shortjournal = {Comput. Commun.},
  title        = {Multiple intersection selection routing protocol based on road section connectivity probability for urban VANETs},
  volume       = {177},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Dynamic geo-based resource selection in LTE-V2V
communications using vehicle trajectory prediction. <em>COMCOM</em>,
<em>177</em>, 239–254. (<a
href="https://doi.org/10.1016/j.comcom.2021.08.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vehicle to Vehicle (V2V) communication has recently been considered in 4G and 5G cellular networks . One of the challenging issues in cellular V2V is allocating radio resources to the vehicles. Although previous work have addressed this issue, the fast varying nature of vehicular traffic and its regularities implies that the mobility of the vehicles should be more attended. To this goal, we propose an autonomous geo-based resource selection algorithm that uses deep learning to predict vehicle locations in the future and alleviate the computation and signalling overhead of the cellular infrastructure in contrast to previous geo-based resource allocation algorithms. We utilize the current and the future of vehicle densities in a formulated matching problem to find the optimum assignment of sub-resource pools to geographic areas. Simulation results of a highway with diverse density scenarios and different number of available resources show that the proposed method guarantees a considerable reduction in computation and signalling overhead while in low awareness ranges, it provides up to 10\% improvement in Packet Reception Ratio (PRR) and the error rate of vehicles compared to the previous Dynamic Geo-based Resource Selection Algorithm (DGRSA). The proposed method also provides up to 15\% improvement in PRR and error rate compared to the modified DGRSA, which we have changed to run with an overhead equal to the overhead of our proposed method. Furthermore, our results demonstrate up to 67\% and 76\% improvement in blocking rate compared to DGRSA and modified DGRSA, respectively.},
  archive      = {J_COMCOM},
  author       = {Amirreza Hajrasouliha and Behrouz Shahgholi Ghahfarokhi},
  doi          = {10.1016/j.comcom.2021.08.006},
  journal      = {Computer Communications},
  pages        = {239-254},
  shortjournal = {Comput. Commun.},
  title        = {Dynamic geo-based resource selection in LTE-V2V communications using vehicle trajectory prediction},
  volume       = {177},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A game-based power optimization for 5G femtocell networks.
<em>COMCOM</em>, <em>177</em>, 230–238. (<a
href="https://doi.org/10.1016/j.comcom.2021.07.022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spectrum sharing deployment of femtocells brings interferences which dramatically degrade network performance. Hence, interference control is a crucial challenge for femtocell networks. In this paper, we propose a power optimization approach for 5G femtocell networks consisting of macrocell and underlying femtocells to manage the interference. Firstly, we formulate the problem based on a non-cooperative game to analyze the competition among the users to access shared spectrum. We then design a pricing mechanism in the utility function to guarantee quality of service (QoS) requirements of macro users. The mechanism lets the macro users experience lower interference and achieve the minimum required data rate. As a result, QoS requirements of both macro and femto users are fulfilled in a non-cooperative manner. We also design a minimax decision rule to optimize the worst-case performance and find an optimal transmission power for each user. By adjusting the optimal power for each user, the maximum aggregate interference is minimized, and the network throughput is maximized. Finally, we develop an iterative learning-based algorithm to implement the proposed scheme and achieve the game equilibrium. Theoretical analysis and simulation results verifies the effectiveness of the proposed mechanism in terms of throughput maximization, QoS assurance and interference mitigation .},
  archive      = {J_COMCOM},
  author       = {Azadeh Pourkabirian and Mohammad Hossein Anisi and Fereshteh Kooshki},
  doi          = {10.1016/j.comcom.2021.07.022},
  journal      = {Computer Communications},
  pages        = {230-238},
  shortjournal = {Comput. Commun.},
  title        = {A game-based power optimization for 5G femtocell networks},
  volume       = {177},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A scalable rule engine system for trigger-action application
in large-scale IoT environment. <em>COMCOM</em>, <em>177</em>, 220–229.
(<a href="https://doi.org/10.1016/j.comcom.2021.06.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The development of IoT techniques and the automation enabled by trigger-action platforms have brought great convenience to human life. However, with time the proliferating IoT devices will eventually overwhelm such platforms. Specifically, the ever-increasing huge amount of linkage rules significantly challenge the response rate as well as the efficiency of conflict rule detection, which will lead to terrible user experience and disastrous security issues. In this work, we develop a rule engine system for large-scale trigger-action applications. The key insight is that the linkage rules can be executed independent from the central cloud platform, which only require edge-side gateways and an efficient addressing strategy. The platform-side maintains an global image consisting of mappings between rules and gateway addresses, while edge-side rule engine is designed based on an open source tool , i.e., Drools. The implemented RETE algorithm helps to carry out large-scale linkage rules. In addition, we design a lightweight yet effective conflict detection algorithm that categorizes those rules into several types to downgrade the computation complexity. Experiments prove that the system can reduce the resource consumption of the platform-side and remarkably enhance the response speed. Moreover, our system also achieve a high efficacy when detecting conflicts.},
  archive      = {J_COMCOM},
  author       = {Xi Luo and Ye Fu and Lihua Yin and Hao Xun and Yixin Li},
  doi          = {10.1016/j.comcom.2021.06.016},
  journal      = {Computer Communications},
  pages        = {220-229},
  shortjournal = {Comput. Commun.},
  title        = {A scalable rule engine system for trigger-action application in large-scale IoT environment},
  volume       = {177},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Reinforcement learning multi-agent system for faults
diagnosis of mircoservices in industrial settings. <em>COMCOM</em>,
<em>177</em>, 213–219. (<a
href="https://doi.org/10.1016/j.comcom.2021.07.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper develops a new framework called MASAD (Multi-Agents System for Anomaly Detection), a hybrid combination of reinforcement learning , and a multi-agents system to identify abnormal behaviors of microservices in industrial environment settings. A multi-agent system is implemented using reinforcement learning , where each agent learns from the given microservice. Intelligent communication among the different agents is then established to enhance the learning of each agent by considering the experience of the agents of the other microservices of the system. The above setting not only allows to identify local anomalies but global ones from the whole microservices architecture . To show the effectiveness of the framework as proposed, we have gone through a thorough experimental analysis on two microservice architectures (NETFLIX, and LAMP). Results showed that our proposed framework can understand the behavior of microservices, and accurately simulate different interactions in the microservices. Besides, our approach outperforms baseline methods in identifying both local and global outliers.},
  archive      = {J_COMCOM},
  author       = {Asma Belhadi and Youcef Djenouri and Gautam Srivastava and Jerry Chun-Wei Lin},
  doi          = {10.1016/j.comcom.2021.07.010},
  journal      = {Computer Communications},
  pages        = {213-219},
  shortjournal = {Comput. Commun.},
  title        = {Reinforcement learning multi-agent system for faults diagnosis of mircoservices in industrial settings},
  volume       = {177},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Performance analysis of opportunistic NOMA strategy in
uplink coordinated multi-points systems. <em>COMCOM</em>, <em>177</em>,
207–212. (<a
href="https://doi.org/10.1016/j.comcom.2021.07.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Non-orthogonal multiple access (NOMA) has attracted a great deal of interest due to its potential contribution to the 5th generation (5G) mobile networks. In conventional power-domain NOMA, one of the disadvantages is that the edge-users which are far from the receivers may suffer edge-interference issue, and they may not be served if the propagation channels are extremely poor. In this study, an amplify-and-forward (AF) user-relay based opportunistic NOMA (UR-ONOMA) strategy, which aims to adaptively improve the coverage of high-quality service to the far-end edge users with weak channel scenarios, is designed for the uplink cooperative networks. The transmission data rates of a two-layer UR-ONOMA strategy are theoretically analyzed, and the closed-form expressions of outage probability are derived and evaluated. The numerical results show that the proposed cooperative UR-ONOMA has superior performance in terms of outage probability and throughput than the NOMA without the aid of user-relays when the far-end users are with weak channels.},
  archive      = {J_COMCOM},
  author       = {Yue Tian and Baiyun Xiao and Xianling Wang and Yau Hee Kho and Chen Tian},
  doi          = {10.1016/j.comcom.2021.07.001},
  journal      = {Computer Communications},
  pages        = {207-212},
  shortjournal = {Comput. Commun.},
  title        = {Performance analysis of opportunistic NOMA strategy in uplink coordinated multi-points systems},
  volume       = {177},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Improved algorithm of cloud service node path based on
cross-border transaction platform under load balancing. <em>COMCOM</em>,
<em>177</em>, 195–206. (<a
href="https://doi.org/10.1016/j.comcom.2021.06.024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cross-border trading platforms study logistics from the perspective of the network, involving all links in the network and the supply chain. The network status is constantly changing, and the acquisition and analysis of the real-time status of each link on the transaction path can further improve the accuracy of the optimal path selection. Meanwhile, traditional networks can no longer adapt to the rapid development of today’s network technology and applications due to their rigid structure and simplified functions . As for traditional networks and their associated network equipment, problems such as inconvenient management and monitoring, poor interoperability, difficulty in expanding network functions, and high operating costs have severely hindered the efficiency of network functions and the pace of innovation. In order to solve many problems faced by traditional networks, in the paper, an SDN network path selection algorithm based on the dual impact factors of cloud service nodes is proposed. In the algorithm proposed in the paper, the final selected path is considered to be composed of multiple links. First, a cloud environment based on the Ryu controller is build, and a corresponding data collection strategy is constructed to complete the acquisition of the link available bandwidth and delay that affect the real-time status of the path. Then, the weighted results are calculated according to the proposed candidate path weight distribution formula to realize the sorting and screening of each transaction link, and provide support for the selection of the cross-border transaction system service path with load balance. The simulation results show that compared with the traditional DLB algorithm, the algorithm proposed in the paper has better load balancing performance, which further shows that the proposed algorithm has a better choice for the path.},
  archive      = {J_COMCOM},
  author       = {Xuefeng Hu},
  doi          = {10.1016/j.comcom.2021.06.024},
  journal      = {Computer Communications},
  pages        = {195-206},
  shortjournal = {Comput. Commun.},
  title        = {Improved algorithm of cloud service node path based on cross-border transaction platform under load balancing},
  volume       = {177},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Efficient deployment of UAVs for disaster management: A
multi-criterion optimization approach. <em>COMCOM</em>, <em>177</em>,
185–194. (<a
href="https://doi.org/10.1016/j.comcom.2021.07.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently different information and communication technologies are investigated to manage disasters. Acknowledging disaster resilience, many efforts are commenced to monitor, forecast, and assess the situation in time. Response time and situational awareness is the key to save lives in disaster situations. These issues motivate the utilization of unmanned aerial vehicles (UAVs) in emergency conditions where a lack of communication and support services are core objectives to control. This paper has addressed UAV-assisted wireless networks’ situational awareness deployment in disaster management as a mobile helping unit. In this regard, we have to efficiently place UAVs in emergency situations where infrastructure is devastated and diffused with features of minimum distance, cost, and number of UAVs. To this end, we optimize a multi-objective problem of UAV placement, users-UAV connectivity, distance, and cost. The formulated problem is a integer linear optimization problem (ILP). To solve it, we first propose a high complexity branch and bound (B&amp;B) algorithm to find an optimal solution. Then, we develop a low complexity heuristic to conquer the objectives efficiently. Finally, simulation results show that our proposed approach can maximize the number of users with a minimum number of UAVs efficiently.},
  archive      = {J_COMCOM},
  author       = {Rooha Masroor and Muhammad Naeem and Waleed Ejaz},
  doi          = {10.1016/j.comcom.2021.07.006},
  journal      = {Computer Communications},
  pages        = {185-194},
  shortjournal = {Comput. Commun.},
  title        = {Efficient deployment of UAVs for disaster management: A multi-criterion optimization approach},
  volume       = {177},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A deep learning based non-intrusive household load
identification for smart grid in china. <em>COMCOM</em>, <em>177</em>,
176–184. (<a
href="https://doi.org/10.1016/j.comcom.2021.06.023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Load identification have shown significant performance gains in Chinese smart grids. Most existing load identification algorithms are based on electrical characteristics of a steady or transient state, which are therefore limited by feature selection and analysing pattern. To address the above issues, this paper proposes the use of the deep neural network for load identification in a Non-Intrusive Load Monitoring (NILM) test-bed, which is set up by introducing diversified household appliances with different load characteristics, to collect the real-time power usage of appliances in a typical Chinese home. The collected load dataset are then sampled, preprocessed and input to the CNN–LSTM framework for training and features extraction. Next, according to several experiments, the structure of our CNN–LSTM network is determined with reasonable hyper-parameters initialised. Numerical results show that our model is superior to the k-NN, SVM , LSTM and CNN load identification methods, with the average recognition accuracy of 99\%, across different kinds of appliances enabled in the typical power grid in China.},
  archive      = {J_COMCOM},
  author       = {Chen Chen and Pinghang Gao and Jiange Jiang and Hao Wang and Pu Li and Shaohua Wan},
  doi          = {10.1016/j.comcom.2021.06.023},
  journal      = {Computer Communications},
  pages        = {176-184},
  shortjournal = {Comput. Commun.},
  title        = {A deep learning based non-intrusive household load identification for smart grid in china},
  volume       = {177},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The influence of computer network technology on national
income distribution under the background of social economy.
<em>COMCOM</em>, <em>177</em>, 166–175. (<a
href="https://doi.org/10.1016/j.comcom.2021.06.025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data mining algorithm is widely used in data management. In view of the current situation that the edge computing mode based on computer network technology is applied to data management, this paper studies the optimization and improvement of the classic Apriori algorithm and K-means algorithm respectively, improves the operation efficiency by optimizing the candidate set, enhances the clustering effect by determining the initial clustering center, and applies the improved algorithm to the national income management which contains 10 attributes. The algorithm performance test shows that the improved Apriori algorithm can generate frequent itemsets in a shorter time, which is about 2000 ms when the minimum support threshold is 30\%–90\%, while the original algorithm is about 4000 Ms. K-means algorithm is relatively sparse in the same type of distribution, while im-k-means algorithm is relatively aggregated. According to the confidence level and related attributes, the order of the influence on salary level from large to small is marital status, education level and time, working time and nature, and the corresponding confidence levels are about 0.95, 0.84 and 0.80 respectively. The improved Apriori algorithm and im-k-means algorithm can well show the relationship between education level and salary level. The research results make a great contribution to the application of computer network technology in data management, and also provide a scientific and reasonable method for the income classification of population.},
  archive      = {J_COMCOM},
  author       = {Xiaoyun Zhu and Shuping Luo},
  doi          = {10.1016/j.comcom.2021.06.025},
  journal      = {Computer Communications},
  pages        = {166-175},
  shortjournal = {Comput. Commun.},
  title        = {The influence of computer network technology on national income distribution under the background of social economy},
  volume       = {177},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Kalman prediction-based virtual network experimental
platform for smart living. <em>COMCOM</em>, <em>177</em>, 156–165. (<a
href="https://doi.org/10.1016/j.comcom.2021.07.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Today, the increasing investigation of smart living opens new attack surfaces to intruders. Therefore, developing an emulation platform to test new technologies for current large-scale smart living scenarios is an emerging issue. However, existing network emulation systems suffer from coarse-grained virtual link emulation, including bandwidth, delay, and packet loss rate (PLR). Furthermore, a lack of virtual link emulation accuracy results in an unpredictable emulation fidelity. In order to address this issue, this paper presents Kalman prediction-based experimental platform based on multiple virtualization technologies for smart living to test new technologies and security threats. We introduce the core deployment, link-emulation, and emulator modules in the framework and propose Delay-PLR Kalman Prediction ( DPKP ) algorithm, which employs Kalman prediction theory based on the packet delay and loss measurement scheme. In particular, the DPKP takes the inherent network traffic errors of the substrate network into consideration, thus improving emulation fidelity. Experiments on the emulation of a BeiDou based satellite network scenario verify the ability of our emulation system to flexibly construct a target virtual network and set the expected bandwidth for each virtual link within 5\% errors. In addition, the experimental results demonstrate that the proposed DPKP -based virtual link emulation scheme outperforms the traditional method by up to 21.54\% and 78.65\% in terms of delay and PLR, respectively.},
  archive      = {J_COMCOM},
  author       = {Desheng Wang and Weizhe Zhang and Xiaofeng Wang and Yang Xiang and Yu-Chu Tian},
  doi          = {10.1016/j.comcom.2021.07.005},
  journal      = {Computer Communications},
  pages        = {156-165},
  shortjournal = {Comput. Commun.},
  title        = {Kalman prediction-based virtual network experimental platform for smart living},
  volume       = {177},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A survey on 360-degree video: Coding, quality of experience
and streaming. <em>COMCOM</em>, <em>177</em>, 133–155. (<a
href="https://doi.org/10.1016/j.comcom.2021.06.029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The commercialization of Virtual Reality (VR) headsets has made immersive and 360-degree video streaming the subject of intense interest in the industry and research communities. While the basic principles of video streaming are the same, immersive video presents a set of specific challenges that need to be addressed. In this survey, we present the latest developments in the relevant literature on four of the most important ones: (i) omnidirectional video coding and compression, (ii) subjective and objective Quality of Experience (QoE) and the factors that can affect it, (iii) saliency measurement and viewport prediction, and (iv) the adaptive streaming of immersive 360-degree videos. The final objective of the survey is to provide an overview of the research on all the elements of an immersive video streaming system, giving the reader an understanding of their interplay and performance.},
  archive      = {J_COMCOM},
  author       = {Federico Chiariotti},
  doi          = {10.1016/j.comcom.2021.06.029},
  journal      = {Computer Communications},
  pages        = {133-155},
  shortjournal = {Comput. Commun.},
  title        = {A survey on 360-degree video: Coding, quality of experience and streaming},
  volume       = {177},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Optimization of fitness data monitoring system based on
internet of things and cloud computing. <em>COMCOM</em>, <em>177</em>,
125–132. (<a
href="https://doi.org/10.1016/j.comcom.2021.06.027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the service dimension, the construction of fitness science data supervision service mode is discussed. Based on the stakeholder theory, through the statistical analysis of the stakeholders of fitness science data supervision, three core stakeholders of the government, users and data service personnel are identified. Based on these three dimensions, we find out the core concepts of government policy model, user demand model and service model. At the same time, each dimension is deeply analyzed. Through the relationship analysis between these three dimensions, the user-oriented collaborative supervision service model of fitness scientific data is expected to guide the specific service practice of fitness scientific data supervision through the establishment of this model. In addition, an unsupervised learning method in machine learning , the isolation forest algorithm, is introduced to detect abnormal data; at the same time, using real fitness data sets, through comparative experiments with local anomaly factor algorithms, it is verified that the isolation forest algorithm has a good effect of anomaly detection ; this article also uses redis cache to optimize the performance of the fitness data monitoring system, which solves the access pressure of the main database in a multi-user high-concurrency environment; Finally, the usability and stability of the system are verified by functional tests and stress tests.},
  archive      = {J_COMCOM},
  author       = {Xiuhai Shang and Xusheng Che},
  doi          = {10.1016/j.comcom.2021.06.027},
  journal      = {Computer Communications},
  pages        = {125-132},
  shortjournal = {Comput. Commun.},
  title        = {Optimization of fitness data monitoring system based on internet of things and cloud computing},
  volume       = {177},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Capacity analysis of public blockchain. <em>COMCOM</em>,
<em>177</em>, 112–124. (<a
href="https://doi.org/10.1016/j.comcom.2021.06.019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As distributed ledgers, blockchains run consensus protocols which trade capacity for consistency, especially in non-ideal networks with incomplete connectivity and erroneous links. Existing studies on the tradeoff between capacity and consistency are only qualitative or rely on specific assumptions. This paper presents discrete-time Markov chain models to quantify the capacity of Proof-of-Work based public blockchains in non-ideal networks. The comprehensive model is collapsed to be ergodic under the eventual consistency of blockchains, achieving tractability and efficient evaluations of blockchain capacity. A closed-form expression for the capacity is derived in the case of two miners. Another important aspect is that we extend the ergodic model to analyze the capacity under strong consistency , evaluating the robustness of blockchains against double-spending attacks. Validated by simulations, the proposed model is accurate and reveals the effect of link quality and the distribution of mining rates on blockchain capacity and the ratio of stale blocks.},
  archive      = {J_COMCOM},
  author       = {Xu Wang and Wei Ni and Xuan Zha and Guangsheng Yu and Ren Ping Liu and Nektarios Georgalas and Andrew Reeves},
  doi          = {10.1016/j.comcom.2021.06.019},
  journal      = {Computer Communications},
  pages        = {112-124},
  shortjournal = {Comput. Commun.},
  title        = {Capacity analysis of public blockchain},
  volume       = {177},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). AIoTES: Setting the principles for semantic interoperable
and modern IoT-enabled reference architecture for active and healthy
ageing ecosystems. <em>COMCOM</em>, <em>177</em>, 96–111. (<a
href="https://doi.org/10.1016/j.comcom.2021.06.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The average life expectancy of the world’s population is increasing and the healthcare systems sooner than later will be compromised by its reduced capacity and its highly economic cost; in addition, the age distribution of the population is leading towards the older spectrum. This trend will lead to immeasurable and unexpected economic problems and social changes. In order to face up this challenge and complex economic and social problem, it is necessary to rely on the appropriate digital tools and technological infrastructures for ensuring that the elderly are properly cared in their everyday living environments and they can live independently for longer. This article presents ACTIVAGE IoT Ecosystem Suite (AIoTES), a concrete reference architecture and its implementation process that addresses these issues and that was designed within the first European Large Scale Pilot, ACTIVAGE, a H2020 funded project by the European Commission with the objective of creating sustainable ecosystems for Active and Healthy Ageing (AHA) based on Internet of Things and big data technologies . AIoTES offers platform level semantic interoperability, with security and privacy, as well as Big Data and Ecosystem tools. AIoTES enables and promotes the creation, exchange and adoption of cross-platform services and applications for AHA. The number of existing AHA services and solutions are quite large, especially when state-of-the-art technology is introduced, however a concrete architecture such as AIoTES gains more importance and relevance by providing a vision for establishing a complete ecosystem, that looks for supporting a larger variety of AHA services, rather than claiming to be a unique solution for all the AHA domain problems. AIoTES has been successfully validated by testing all of its components, individually, integrated, and in real-world environments with 4345 direct users. Each validation is contextualized in 11 Deployment Sites (DS) with 13 Validation Scenarios covering the heterogeneity of the AHA-IoT needs. These results also show a clear path for improvement, as well as the importance for standardization efforts in the ever-evolving AHA-IoT domain.},
  archive      = {J_COMCOM},
  author       = {Clara I. Valero and Alejandro M. Medrano Gil and Regel Gonzalez-Usach and Matilde Julian and Giuseppe Fico and Maria Teresa Arredondo and Thanos G. Stavropoulos and Dimitrios Strantsalis and Antonis Voulgaridis and Felipe Roca and Antonio J. Jara and Martín Serrano and Achille Zappa and Yasar Khan and Sergio Guillen and Pilar Sala and Andreu Belsa and Konstantinos Votis and Carlos E. Palau},
  doi          = {10.1016/j.comcom.2021.06.010},
  journal      = {Computer Communications},
  pages        = {96-111},
  shortjournal = {Comput. Commun.},
  title        = {AIoTES: Setting the principles for semantic interoperable and modern IoT-enabled reference architecture for active and healthy ageing ecosystems},
  volume       = {177},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Spoofing-jamming attack based on cross-technology
communication for wireless networks. <em>COMCOM</em>, <em>177</em>,
86–95. (<a href="https://doi.org/10.1016/j.comcom.2021.06.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cross-Technology Communication(CTC) enables that WiFi devices can talk to ZigBee devices directly without any hardware changes or gateway equipment, and WiFi occupies a much wider bandwidth (20MHz) than ZigBee (2MHz), which sheds the light on spoofing-jamming attack based on CTC, where a WiFi device, as a sophisticated attacker spoofs or jams an area in which multiple-channels sensor network operating. In this work, we attempt to emulate two ZigBee frames under different frequencies within a single WiFi frame by controlling non-continuous bands of subcarriers . In other words, a WiFi device can independently communicate with the ZigBee devices operating in two channels. In a different perspective, the application based on CTC will be significantly impaired when CTC suffers from malicious attacks such as spoofing or jamming. In our work, we implement a parallel spoofing system, called SamBee, that can spoof the ZigBee devices operating in two different channels or jam the ZigBee devices operating in five distinct channels simultaneously only using a single WiFi frame, which causes maximum damage to the network in term of corrupted communication links with low cost. We implement our design based on a USRP-N210 and MICAz hybrid platform, the results show that parallel spoofing attacks and multiple-channels jamming attacks based on CTC is feasible, and our results also provide valuable insights about the associated defense mechanisms on achieving desirable performance.},
  archive      = {J_COMCOM},
  author       = {Demin Gao and Shuai Wang and Yunhuai Liu and Wenchao Jiang and Zhijun Li and Tian He},
  doi          = {10.1016/j.comcom.2021.06.017},
  journal      = {Computer Communications},
  pages        = {86-95},
  shortjournal = {Comput. Commun.},
  title        = {Spoofing-jamming attack based on cross-technology communication for wireless networks},
  volume       = {177},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Joint task offloading and resource allocation in
vehicle-assisted multi-access edge computing. <em>COMCOM</em>,
<em>177</em>, 77–85. (<a
href="https://doi.org/10.1016/j.comcom.2021.06.014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-access Edge Computing (MEC) has significant advantages in improving resource efficiency of Internet of Things (IoT) and 5G networks , however its limited resources cannot meet the demand of data communication and computation capability during off-peak time. Incentivizing intelligent vehicles with idle computation resources as vehicle edge nodes (VENs) to provide computation offloading for nearby user equipments (UEs) is an appealing idea. Thus, we propose a vehicle-assisted MEC (VMEC) paradigm, where tasks can be offloaded to MEC server and VENs. In this paper, we first establish a differentiated pricing model based on different states of resources and a dynamic incentive model according to the demands of UEs. Then, we formulate a Stackelberg game between UEs and MEC service provider (MEC SP) to obtain the optimal offloading strategy and pricing scheme. A gradient-based resource allocation iteration algorithm (GRAIA) is designed for the Nash equilibrium solution. Finally, considering the matching between UEs and vehicles, we present a reverse auction-based task scheduling algorithm (RATSA) to choose VENs. The simulation results demonstrate that the proposed scheme can achieve significant performance improvement and is superior to the existing schemes in improving system utility.},
  archive      = {J_COMCOM},
  author       = {Jianbin Xue and Qingchun Hu and Yaning An and Lu Wang},
  doi          = {10.1016/j.comcom.2021.06.014},
  journal      = {Computer Communications},
  pages        = {77-85},
  shortjournal = {Comput. Commun.},
  title        = {Joint task offloading and resource allocation in vehicle-assisted multi-access edge computing},
  volume       = {177},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An enhanced lightweight and secured authentication protocol
for vehicular ad-hoc network. <em>COMCOM</em>, <em>177</em>, 57–76. (<a
href="https://doi.org/10.1016/j.comcom.2021.06.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A substantial number of authentication protocols are designed to safeguard vehicular ad-hoc network (VANET) communication from potential attacks; however, they experienced an inability to provide a balance between lightweight and security. Existing security and privacy-preserving based authentication protocols in vehicular networks mostly rely on the trusted authority and signatures to validate the communication on road. Accomplishing the quick validation and correspondence is difficult in such methodologies and further, they endure execution obliges from coming about overhead. To overcome these issues, we have developed an enhanced lightweight and secure authentication protocol ( ELSAP ) for V2V Communication in VANETs. Moreover, the scheme withheld with self-authentication prior to communication that enhances the network feasibilities, which in return needs less message transfer during authentication as well as communication, indicates lightweight features. Furthermore, two or more vehicles can securely perform mutual authentication, proven by Burrow–Abadi–Needham (BAN) logic. Additionally, the competency of the proposed protocol against the current updated threats is shown via security analysis and comparisons tools such as Automated Validation of Internet Security Protocols and Applications (AVISPA). The result of the performance analysis shows that the communication cost and computational cost outperformed the earlier authentication schemes alongside the security features of the proposed protocol.},
  archive      = {J_COMCOM},
  author       = {Tarak Nandy and Mohd Yamani Idna Idris and Rafidah Md Noor and Ashok Kumar Das and Xiong Li and Norjihan Abdul Ghani and Sananda Bhattacharyya},
  doi          = {10.1016/j.comcom.2021.06.013},
  journal      = {Computer Communications},
  pages        = {57-76},
  shortjournal = {Comput. Commun.},
  title        = {An enhanced lightweight and secured authentication protocol for vehicular ad-hoc network},
  volume       = {177},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Performance analysis of short-packet communications with
incremental relaying. <em>COMCOM</em>, <em>177</em>, 51–56. (<a
href="https://doi.org/10.1016/j.comcom.2021.06.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the fifth generation (5G) cellular system , short-packet communication is a key enabler to support critical applications, i.e., ultra-reliable low-latency communications (URLLCs), where finite block-length codewords are adopted. However, the short-packet communication suffers from a higher decoding error rate and has a lower transmission rate than the Shannon channel capacity. To improve both the reception reliability and the transmission efficiency, the incremental relaying (IR) is considered to improve the performance of the short-packet communication. Especially, we investigate an IR scheme for short-packet communications to reduce the transmission delay. To evaluate the system performance, closed-form expressions for the decoding error probability, the throughput and the delay are derived by considering the feedback overhead of IR. Finally, we provide simulation results to verify the accuracy of the theoretical analysis, and also compare the proposed IR scheme with the direct transmission (DT) and conventional relaying transmission (RT) schemes. Simulation results verify the effectiveness of the proposed IR scheme for the short-packet communication.},
  archive      = {J_COMCOM},
  author       = {Manlin Fang and Dong Li and Han Zhang and Lisheng Fan and Imene Trigui},
  doi          = {10.1016/j.comcom.2021.06.007},
  journal      = {Computer Communications},
  pages        = {51-56},
  shortjournal = {Comput. Commun.},
  title        = {Performance analysis of short-packet communications with incremental relaying},
  volume       = {177},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Leveraging context-awareness for internet of things
ecosystem: Representation, organization, and management of context.
<em>COMCOM</em>, <em>177</em>, 33–50. (<a
href="https://doi.org/10.1016/j.comcom.2021.06.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Present-day devices are becoming increasingly smarter than their predecessors. From a simple passive light switch to an intelligent wristwatch, great strides have been made in networking smart devices, creating an autonomous ecosystem, the so-called Internet of Things . In an increasingly information-driven world, context-awareness supports the intended applications as well as their constituent devices, making them conscious of and adaptive to the specific scenario in real-time. Moreover, heterogeneous devices in the Internet of Things ecosystem peruse disparate data formats and semantics, giving rise to interoperability and information sharing challenges. Context modeling is a core feature that facilitates interoperability and information sharing between applications. Although generic context models exist, they do not consider pertinent dimensions of context to provide a generic vocabulary, and therefore, they cannot be extended to generalize situations commonly encountered in the Internet of Things environment. An extensible, generic modeling and representation of context is required to manage pertinent context dimensions in various ecosystems by being dynamically aware of the situation. This paper presents Context Model for Internet of Things, an extensible and generic ontology-based context modeling approach that provides relevant information at the right time. This work encompasses Context Ontology for Internet of Things, an ontology-based context organization approach, which provides an abstract and overarching vocabulary that fosters knowledge reusability and sharing. The proposed model has been implemented and evaluated with a use case to validate its adaptability, effectiveness, and viability. Our evaluation based on generality, effectiveness, and consistency shows that the proposed model can effectively represent, organize, and manage the context in different Internet of Things ecosystems.},
  archive      = {J_COMCOM},
  author       = {Preeja Pradeep and Shivsubramani Krishnamoorthy and Rahul Krishnan Pathinarupothi and Athanasios V. Vasilakos},
  doi          = {10.1016/j.comcom.2021.06.004},
  journal      = {Computer Communications},
  pages        = {33-50},
  shortjournal = {Comput. Commun.},
  title        = {Leveraging context-awareness for internet of things ecosystem: Representation, organization, and management of context},
  volume       = {177},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Memory performance optimization of DTN relay node based on
m/g/1. <em>COMCOM</em>, <em>177</em>, 24–32. (<a
href="https://doi.org/10.1016/j.comcom.2021.06.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Delay/Disruption Tolerant Networking offers a solution to communications in challenged networks despite the long propagation delay , and intermittent connectivity is commonly characteristic of deep-space communications. It combined with the actual application scenarios of M/G/1 queuing model and based on the data delivery mechanism of store-and-forward and retransmission under Bundle Protocol/Licklider Transmission Protocol in DTN. The data delivery time can be divided into two parts by the last round of LTP data segments transmission process, the custody queue length model of BP data unit (i.e. bundle) in relay nodes memory space is determined by calculating the retransmission time of LTP data segments spent in different delivery parts, which can directly measure the consumption and use of relay nodes memory resources. Without affecting the correct delivery of data and in order to obtain a more perfect memory resources allocation strategy, the optimized length of LTP data segment and the optimized number of bundles aggregated by per LTP block are proposed as the joint optimization scheme. The simulation results show that in deep-space channel environment where bundle arrival rate and bit error rate constantly change, the joint optimization scheme proposed in this paper can always maintain the shortest average queue length , which means, occupy less memory space. Compared with the queue without optimization, the queue length of the joint optimization scheme is reduced by 76.65\%, which demonstrates the superior performance of this scheme, and realizes the reasonable optimization and utilization of the memory resources of the relay nodes in DTN.},
  archive      = {J_COMCOM},
  author       = {Changpeng Ji and Xingmei Han and Wei Dai and Wenxin Ji and Zirui Wang},
  doi          = {10.1016/j.comcom.2021.06.008},
  journal      = {Computer Communications},
  pages        = {24-32},
  shortjournal = {Comput. Commun.},
  title        = {Memory performance optimization of DTN relay node based on M/G/1},
  volume       = {177},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Optimizing the performance of vehicular delay tolerant
networks using multi-objective PSO and artificial intelligence.
<em>COMCOM</em>, <em>177</em>, 10–23. (<a
href="https://doi.org/10.1016/j.comcom.2021.06.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vehicular delay tolerant network (VDTN) technology uses vehicles on the road as moving nodes to deliver data from source to destination using several intermediate nodes . Efficient data dissemination in VDTN is a difficult problem due to existing trade-offs between several metric variables such as delivery ratio, delay, and overhead ratio. Inclusion of important social network parameters (like community, social strength, trust, friendship, and selfishness) in computation of forwarding probability may help to improve the performance of a routing algorithm . However, different tuning of these parameters results in different outcomes for the metric variables. A proper balancing of these parameters may result in an optimized outcome solving the trade-off between the metric variables. Nonetheless, dependency of the variables on a number of social network parameters and their mutual trade-offs makes this a non-trivial optimization problem . In this paper, we propose a novel approach to optimize these trade-offs using multi-objective particle swarm optimization (MOPSO). The proposed approach provides a set of pareto-optimal solutions also known as non-dominating solutions. Further, based on the requirements of a target application scenario, a specific optimal solution out of the pareto-optimal solution set is delivered using artificial intelligence (AI) technique. The proposed methodology is simulated in a VDTN scenario using the opportunistic network environment (ONE) simulator and Matlab. Furthermore, based on the experimental results, an exhaustive analysis is provided about how the metric variables are affected by the involvement of the social-based parameters. The capabilities of the proposed approach are validated using a statistical comparative analysis of the results. In future, the outcome of the study may play a helpful role to decide the priorities of the network parameters while designing new data dissemination algorithms for VDTN.},
  archive      = {J_COMCOM},
  author       = {Vishakha Chourasia and Sudhakar Pandey and Sanjay Kumar},
  doi          = {10.1016/j.comcom.2021.06.006},
  journal      = {Computer Communications},
  pages        = {10-23},
  shortjournal = {Comput. Commun.},
  title        = {Optimizing the performance of vehicular delay tolerant networks using multi-objective PSO and artificial intelligence},
  volume       = {177},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A cost-effective trilateration-based radio localization
algorithm using machine learning and sequential least-square programming
optimization. <em>COMCOM</em>, <em>177</em>, 1–9. (<a
href="https://doi.org/10.1016/j.comcom.2021.06.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wireless communication systems play an essential role in everyday life situations and enable a wide range of location-based services to their users. The imminent adoption of 5G networks worldwide and the future establishment of next-generation wireless networks will allow various applications, such as autonomous vehicles, connected robotics, and most recently, crowd monitoring for fighting infectious diseases, such as COVID-19. In this context, radio localization techniques have become an essential tool to provide solid performance for mobile positioning systems, through increased accuracy or less computational time. With this in mind, we propose a trilateration-based approach using machine learning (ML) and sequential least-square programming (SLSQP) optimization to estimate the outdoor position of mobile terminals in cellular networks . The ML technique employed is the k k -nearest neighbors ( k k -NN). The optimization methods analyzed are Nelder–Mead (NM), genetic algorithms (GA), and SLSQP. Different environments (noise-free and noisy) and network scenarios (different numbers of base stations) are considered to evaluate the approaches. Numerical results indicate that the k k -NN/SLSQP technique has similar accuracy compared to the k k -NN/GA with eight generations. Both perform better than k k -NN/NM in all scenarios and environments. When comparing computational times, our proposal is considerably more time-efficient. Aside from that, SLSQP computational time is less affected by network scenarios with more base stations in comparison with GA. That feature is significant considering the ultra-dense base station deployment forecasted for the next-generation cellular networks .},
  archive      = {J_COMCOM},
  author       = {João Paulo P.G. Marques and Daniel C. Cunha and Lucas M.F. Harada and Lizandro N. Silva and Igor D. Silva},
  doi          = {10.1016/j.comcom.2021.06.005},
  journal      = {Computer Communications},
  pages        = {1-9},
  shortjournal = {Comput. Commun.},
  title        = {A cost-effective trilateration-based radio localization algorithm using machine learning and sequential least-square programming optimization},
  volume       = {177},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Accurate item recommendation algorithm of itemrank based on
tag and context information. <em>COMCOM</em>, <em>176</em>, 282–289. (<a
href="https://doi.org/10.1016/j.comcom.2021.06.020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The traditional itemrank recommendation algorithm only uses the two-dimensional relationship between user and item to achieve recommendation, without considering the important information (such as label information and context information) that plays an important role in the association between user and item, so the accuracy of recommendation needs to be improved. Therefore, in this paper, tag information and context information are integrated into the link relationship between user and item, and a user–context–item tag association graph is constructed. An itemrank recommendation algorithm is proposed by integrating tag and context information. Firstly, ap-ml-rbf-relm model is used to determine user labels, and then deep neural network is used to determine the relationship between tags. Finally, item and label are calculated The association weight between the signatures is used to implement the recommendation service for the target users. Experimental results on public datasets show that the proposed algorithm is better than the traditional recommendation algorithm in recommendation accuracy.},
  archive      = {J_COMCOM},
  author       = {Zhiliang Huang and Hong Ma and Shizhi Wang and Yuan Shen},
  doi          = {10.1016/j.comcom.2021.06.020},
  journal      = {Computer Communications},
  pages        = {282-289},
  shortjournal = {Comput. Commun.},
  title        = {Accurate item recommendation algorithm of itemrank based on tag and context information},
  volume       = {176},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). On-path caching based on content relevance in
information-centric networking. <em>COMCOM</em>, <em>176</em>, 272–281.
(<a href="https://doi.org/10.1016/j.comcom.2021.06.015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Internet of things (IoT) is a new network concept. Based on the Internet, the idea of connecting everything is proposed, which is likely to become the development direction of computer and communication in the future. Meanwhile, as a disruptive new communication network model, Information-Centric Network (ICN) has become a hot spot in the field of future network architecture research in recent years. ICN is information-centric, and uses the name of the information to implement data identification, retrieval, and routing and forwarding. The information centric network uses the cache as a built-in structure, and nodes store all the data that flows by default, so that subsequent requests can be responded to as soon as possible. In the actual network, the spread and trend of an information constantly change with time, and the popularity of the information is different in different time periods. However, the existing ICN native caching mechanism ignores the correlation between contents, and the existing relevant research makes insufficient use of content relevance. In this paper may exist a certain correlation between nodes have access to the content of the facts, we design a path cache method based on the correlation content, by discovering target content and the correlation between nodes store content, at the same time considering the node position in the path, make caching decisions, make the cache memory more efficient. The feasibility and effectiveness of the proposed method are verified by simulation experiments under different parameters.},
  archive      = {J_COMCOM},
  author       = {Dapeng Man and Qi Lu and Hanbo Wang and Jiafei Guo and Wu Yang and Jiguang Lv},
  doi          = {10.1016/j.comcom.2021.06.015},
  journal      = {Computer Communications},
  pages        = {272-281},
  shortjournal = {Comput. Commun.},
  title        = {On-path caching based on content relevance in information-centric networking},
  volume       = {176},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Hyperbolic k-means for traffic-aware clustering in cloud and
virtualized RANs. <em>COMCOM</em>, <em>176</em>, 258–271. (<a
href="https://doi.org/10.1016/j.comcom.2021.06.021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the internet and connected objects gain more and more in popularity, serving the ever-increasing data traffic becomes a challenge for the mobile operators. The traditional cellular radio access network (RAN), where each base station is co-located with its own processing unit and is responsible for a specific geographic area, has evolved first with the so-called Cloud RAN (C-RAN), and is currently undergoing further architectural evolution under the virtualized RAN (vRAN), Software-Defined RAN (SD-RAN), and Open RAN (O-RAN) architectures. In all these versions, the data processing units can be dynamically centralized into a pool and shared between several base stations, enlarging the geographical view for scheduling and resource allocation algorithms. For instance, resource utilization is improved by avoiding resource idling during off-peak hours. C-RAN and vRAN gains depend strongly on the clustering scheme of radio units (RRHs and RUs). In this paper, we propose a novel radio clustering algorithm that takes into account both the traffic demand and the position of stations, by using the hyperbolic distance in 3-dimensions. We introduce a modified K-means clustering algorithm , called Hyperbolic K-means, and show that this generates geographically compact RU clusters with traffic charge equally shared among them. Application of our algorithm on real-world mobile data traffic , collected from the cities of Nantes and Lille in France, shows an increase in resource utilization by 25\%, and a reduction in deployment cost by 15\%, compared to the standard RAN. Furthermore, the performance of our Hyperbolic K-means algorithm is compared extensively against alternative C-RAN clustering proposals from the literature and is shown to outperform them, in resource utilization as well as in cost reduction.},
  archive      = {J_COMCOM},
  author       = {Hanane Djeddal and Liticia Touzari and Anastasios Giovanidis and Chi-Dung Phung and Stefano Secci},
  doi          = {10.1016/j.comcom.2021.06.021},
  journal      = {Computer Communications},
  pages        = {258-271},
  shortjournal = {Comput. Commun.},
  title        = {Hyperbolic K-means for traffic-aware clustering in cloud and virtualized RANs},
  volume       = {176},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). ShuffleNet-inspired lightweight neural network design for
automatic modulation classification methods in ubiquitous IoT
cyber–physical systems. <em>COMCOM</em>, <em>176</em>, 249–257. (<a
href="https://doi.org/10.1016/j.comcom.2021.05.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic modulation classification (AMC) is one of the most important technologies of cognitive radios and ubiquitous internet of things (IoT) cyber–physical systems, and it can be adopted to recognize unknown signals. Recently, deep learning (DL) has been applied into AMC for the advanced classification performance. However, DL-based AMC methods generally have high computation complexity and large model sizes, which means that these methods can be rarely implemented into some IoT devices. In this paper, inspired by ShuffleNet, we design a lightweight convolutional neural network (CNN), which is named as ShuffleCNN, and a ShuffleCNN-based AMC (ShffuleAMC) method is proposed for the ubiquitous IoT cyber–physical systems with orthogonal frequency division multiplexing (OFDM). Besides, we also introduce fast Fourier transform (FFT) to pre-process the OFDM signals for the classification performance improvement, and apply ℓ 2 ℓ2 regularization to avoid overfitting. It is demonstrated by simulation results that our proposed ShuffleAMC method has little performance loss, when compared with the common CNN-based AMC methods. More importantly, our proposed ShuffleAMC method also has the strengths of low computation complexity and few model sizes.},
  archive      = {J_COMCOM},
  author       = {Jie Yin and Liang Guo and Wei Jiang and Sheng Hong and Jie Yang},
  doi          = {10.1016/j.comcom.2021.05.005},
  journal      = {Computer Communications},
  pages        = {249-257},
  shortjournal = {Comput. Commun.},
  title        = {ShuffleNet-inspired lightweight neural network design for automatic modulation classification methods in ubiquitous IoT cyber–physical systems},
  volume       = {176},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Efficient deep neural networks for classification of
COVID-19 based on CT images: Virtualization via software defined radio.
<em>COMCOM</em>, <em>176</em>, 234–248. (<a
href="https://doi.org/10.1016/j.comcom.2021.06.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The novel 2019 coronavirus disease (COVID-19) has infected over 141 million people worldwide since April 20, 2021. More than 200 countries around the world have been affected by the coronavirus pandemic. Screening for COVID-19, we use fast and inexpensive images from computed tomography (CT) scans. In this paper, ResNet-50, VGG-16, convolutional neural network (CNN), convolutional auto-encoder neural network (CAENN), and machine learning (ML) methods are proposed for classifying Chest CT Images of COVID-19. The dataset consists of 1252 CT scans that are positive and 1230 CT scans that are negative for COVID-19 virus. The proposed models have priority over the other models that there is no need of pre-trained networks and data augmentation for them. The classification accuracies of ResNet-50, VGG-16, CNN, and CAENN were obtained 92.24\%, 94.07\%, 93.84\%, and 93.04\% respectively. Among ML classifiers, the nearest neighbor (NN) had the highest performance with an accuracy of 94\%.},
  archive      = {J_COMCOM},
  author       = {Saman Fouladi and M.J. Ebadi and Ali A. Safaei and Mohd Yazid Bajuri and Ali Ahmadian},
  doi          = {10.1016/j.comcom.2021.06.011},
  journal      = {Computer Communications},
  pages        = {234-248},
  shortjournal = {Comput. Commun.},
  title        = {Efficient deep neural networks for classification of COVID-19 based on CT images: Virtualization via software defined radio},
  volume       = {176},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). DISTANT: DIStributed trusted authority-based key managemeNT
for beyond 5G wireless mobile small cells. <em>COMCOM</em>,
<em>176</em>, 218–233. (<a
href="https://doi.org/10.1016/j.comcom.2021.06.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The 5G mobile network is embracing new technologies to keep providing network subscribers with a high Quality of Service (QoS). However, this has become increasingly difficult in the urban landscape as more devices are being connected and each device is requesting increasing amounts of data. Network operators rely on the small cell technology to maintain coverage and service for its subscribers, but this technology is incapable of mitigating the increasing workload on the network infrastructure and preventing the associated network delays. The next logical step is to cover the urban landscape with mobile small cells, since these take advantage of the dynamic network topology and optimizes network services in a cost-effective fashion while taking advantage of the high device density. However, the introduction of mobile small cells raises various security challenges. Cryptographic solutions are capable of solving these as long as they are supported by an appropriate key management scheme . In this article, we propose DISTANT: a DIStributed Trusted Authority-based key managemeNT scheme. This key management scheme is specifically designed to provide security in a network which takes advantage of the mobile small cell technology. The scheme relies on threshold secret sharing to decentralize trust and utilizes the self-generated certificates paradigm. Through an extensive security analysis and communication overhead evaluation, we conclude that our design provides an improved level of security and has a low communication overhead compared to previous works.},
  archive      = {J_COMCOM},
  author       = {Marcus de Ree and Georgios Mantas and Jonathan Rodriguez and Ifiok E. Otung and Christos Verikoukis},
  doi          = {10.1016/j.comcom.2021.06.012},
  journal      = {Computer Communications},
  pages        = {218-233},
  shortjournal = {Comput. Commun.},
  title        = {DISTANT: DIStributed trusted authority-based key managemeNT for beyond 5G wireless mobile small cells},
  volume       = {176},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Secure and energy-efficient smart building architecture with
emerging technology IoT. <em>COMCOM</em>, <em>176</em>, 207–217. (<a
href="https://doi.org/10.1016/j.comcom.2021.06.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the advent of the Internet-of-Things (IoT), it is considered to be one of the latest innovations that offer interesting opportunities for different vertical industries. One of the most relevant IoT technology areas is smart construction. IoT operates in several sectors on a daily basis; implementation includes smart building , smart grids, smart cities, smart houses, physical defense, e-health, asset, and transportation management, but it is not restricted to this. Support from smart IoT buildings is an IoT-level, connected, and cost-effective system. Commercial space has major requirements in terms of comfort, accessibility, security, and energy management . Such requirements can be served organically by IoT-based systems. As the supply of energy has been exhausted and energy demand has risen, there has been a growing focus on energy usage and the maintenance of buildings. With the use of evolving IoT technology, we present a secure and energy-efficient smart building architecture. Every device is known by its unique address, and one of the key web transfer protocols is the Constrained Application Protocol (CoAP). It is an application layer protocol that does not use protected channels for data transfer. Automatic key management, confidentiality, authentication , and data integrity are all features of the Datagram Transport Layer Protection (DTLS). To achieve energy efficiency, we propose a smart construction architecture that, through IoT, manages the performance of all technological systems. The results of the simulation show that the energy consumption is lowered by about 30.86\% with the use of the CoAP in the smart building, which is less than the Message Queuing Telemetry Transport case (MQTT). This paper also aims to observe how to integrate the DTLS protocol with the Secure Hash Algorithm (SHA-256) using optimizations from the Certificate Authority (CA) to improve security.},
  archive      = {J_COMCOM},
  author       = {Arun Kumar and Sharad Sharma and Nitin Goyal and Aman Singh and Xiaochun Cheng and Parminder Singh},
  doi          = {10.1016/j.comcom.2021.06.003},
  journal      = {Computer Communications},
  pages        = {207-217},
  shortjournal = {Comput. Commun.},
  title        = {Secure and energy-efficient smart building architecture with emerging technology IoT},
  volume       = {176},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). On a multisensor knowledge fusion heuristic for the internet
of things. <em>COMCOM</em>, <em>176</em>, 190–206. (<a
href="https://doi.org/10.1016/j.comcom.2021.04.025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Internet of Things (IoT) is envisioned as the interconnection of the Internet with sensing and actuating devices. IoT systems are usually designed to collect massive amounts of data from multiple and possibly conflicting sources. Nevertheless, data must be refined before being stored in a repository, so as information can be correctly extracted for further uses. Knowledge fusion is an important technique to identify and eliminate erroneous data from compromised sources or any mistakes that might have occurred during the extraction process. We propose a new multisensor knowledge fusion heuristic (MKFH) for IoT supporting the knowledge extraction and transfer needed to further knowledge management , also discuss the role of reinforcement learning over integration on a multi-application wireless sensor/actuator network (WSAN). Results shows that the proposed multisensor knowledge fusion heuristic is compatible with the IoT paradigm and enhances integration.},
  archive      = {J_COMCOM},
  author       = {Gabriel Martins and Sergio Guedes de Souza and Igor Leão dos Santos and Luci Pirmez and Claudio M. de Farias},
  doi          = {10.1016/j.comcom.2021.04.025},
  journal      = {Computer Communications},
  pages        = {190-206},
  shortjournal = {Comput. Commun.},
  title        = {On a multisensor knowledge fusion heuristic for the internet of things},
  volume       = {176},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Trajectory tracking analysis of airborne data link antenna.
<em>COMCOM</em>, <em>176</em>, 182–189. (<a
href="https://doi.org/10.1016/j.comcom.2021.06.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of weapons and equipment and changes in combat concepts, airborne data links have become more and more widely used in war communications. Whether their system performance is stable and reliable has gradually become a key indicator for measuring the combat effectiveness of the Air Force. This article mainly introduces the airborne data link to provide graphical information for combatants, solves the problem that people’s information cannot be shared synchronously, expands the transmission scale of data information, and greatly improves the situational awareness of the battlefield. This paper mainly studies the link between the airborne data link between the computer and the aircraft, and makes a substantial analysis of the trajectory tracking, which is helpful for the combatants to be familiar with the trajectory direction and internal structure, and provide clear trajectory information for the fighters Interpretation, you can see at a glance the graphics, and the information obtained by the combatants is consistent. This paper mainly uses the standard Kalman filter algorithm to study the basic characteristics of the target ballistic group motion, and based on the HLA-simulated development of GBR radar integration and completed the system test to verify the accuracy of the simulation signal processing. The experimental results of this paper show that the information acquisition rate of combatants under the airborne data link has been increased by 40\%, and the consistency of simultaneous information acquisition has been improved by 90\%. This is the future development direction of the theater.},
  archive      = {J_COMCOM},
  author       = {Gang Yao and Zhiyuan Xu},
  doi          = {10.1016/j.comcom.2021.06.001},
  journal      = {Computer Communications},
  pages        = {182-189},
  shortjournal = {Comput. Commun.},
  title        = {Trajectory tracking analysis of airborne data link antenna},
  volume       = {176},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). BLER performance evaluation of an enhanced channel
autoencoder. <em>COMCOM</em>, <em>176</em>, 173–181. (<a
href="https://doi.org/10.1016/j.comcom.2021.05.026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The concept of using autoencoders (AEs) to represent wireless communication systems as an end-to-end reconstruction task that optimizes the transmitter and receiver components simultaneously in a single process has attracted the attention of wireless practitioners worldwide. This is attributable to the flexibility, and convenience of representing complex channel models. However, owing to the characteristics of deep neural networks (DNNs), as the AE learns the representation of the channel, overfitting limits its performance. In this paper, we propose RegAE, a regularized DNN architecture that overcomes the overfitting limitation in AEs and reduces their training complexity, which are characteristics of models with higher dimensions. We demonstrate that RegAE improves the block error rate (BLER) as compared with equivalent models from the literature. Thereby, it achieves a performance (1) better than that of a 4 ∕ 7 4∕7 rate Hamming code with a 16 phase-shift keying (16PSK) modulation under an additive white Gaussian noise (AWGN) channel, (2) comparable to that of a 4 ∕ 7 4∕7 rate maximum likelihood decoding (MLD) with a E b ∕ N 0 Eb∕N0 range from 1 dB to 5 dB, and (3) equivalent to that of an uncoded binary phase-shift keying (BPSK) modulation over a E b ∕ N 0 Eb∕N0 range from 0 dB to 10 dB.},
  archive      = {J_COMCOM},
  author       = {Judith Nkechinyere Njoku and Manuel Eugenio Morocho-Cayamcela and Wansu Lim},
  doi          = {10.1016/j.comcom.2021.05.026},
  journal      = {Computer Communications},
  pages        = {173-181},
  shortjournal = {Comput. Commun.},
  title        = {BLER performance evaluation of an enhanced channel autoencoder},
  volume       = {176},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A fast reconstruction of the parity-check matrices of LDPC
codes in a noisy environment. <em>COMCOM</em>, <em>176</em>, 163–172.
(<a href="https://doi.org/10.1016/j.comcom.2021.05.023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In non-cooperative communications, blind identification of the widely used LDPC codes is an emerging research hot spot . This is different from and more difficult than blind identification of channel coding in cooperative communications. Common disadvantages of the existing algorithms are poor fault tolerance , high number of iterations, and only being applicable to short codes. Our proposed algorithm is based on the idea presented by Sicot et al. (2009) for binary phase-shift keying (BPSK) signals over the additive white Gaussian noise (AWGN) channel. Firstly, to sort the codewords according to a proper threshold, we present a threshold function and derive its zero point, which is verified to be the optimal threshold through experiments. This threshold improves the fault tolerance of our algorithm. Secondly, an operation called bidirectional Gaussian column elimination (BGCE) is proposed to replace Gaussian column elimination (GCE). This operation speeds up the process of deriving parity-checks, and considerably reduces the number of iterations. Thirdly, we use an existing technique for finding low-weight codewords as proposed by Canteaut and Chabaud (1998) to make the linearly independent parity-checks sparse, thereby realizing reconstruction of the sparse parity-check matrix of the LDPC code. The results of comparative experiments demonstrate that our algorithm outperforms existing algorithms.},
  archive      = {J_COMCOM},
  author       = {Qian Liu and Hao Zhang and Gaofeng Shen and Fengtong Mei},
  doi          = {10.1016/j.comcom.2021.05.023},
  journal      = {Computer Communications},
  pages        = {163-172},
  shortjournal = {Comput. Commun.},
  title        = {A fast reconstruction of the parity-check matrices of LDPC codes in a noisy environment},
  volume       = {176},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Asymptotically optimal link bit error probability for
distributed detection in wireless sensor networks. <em>COMCOM</em>,
<em>176</em>, 155–162. (<a
href="https://doi.org/10.1016/j.comcom.2021.05.022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Distributed detection in wireless sensor networks is considered, where the decisions made by local sensors are transmitted towards a fusion center through parallel binary symmetric channels . Our contribution is to show that, when the number of local sensors approaches infinity and the channel capacity from the local sensor to the fusion center is larger than the entropy of any local decision, there exists one method in theory that the local decision can be sent to the fusion center without distortion. Correspondingly, the asymptotically optimal link bit error probability between each sensor and the FC is determined. The resulting distributed detection system can reach asymptotically the same detection performance as that with ideal communication. Although the proposed method is asymptotically optimal in nature, it is valid to the distributed detection system when the quantity of the sensors is above dozens. The simulation confirms its validity. Moreover, when compared with the ideal one, simulations confirmed that the proposed scheme achieves a significant saving of communication resource at the expense of a small reduction in the detection performance for the system with dozens of sensors.},
  archive      = {J_COMCOM},
  author       = {Xiangyang Liu and Xiangli Liu},
  doi          = {10.1016/j.comcom.2021.05.022},
  journal      = {Computer Communications},
  pages        = {155-162},
  shortjournal = {Comput. Commun.},
  title        = {Asymptotically optimal link bit error probability for distributed detection in wireless sensor networks},
  volume       = {176},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Internet of things attack detection using hybrid deep
learning model. <em>COMCOM</em>, <em>176</em>, 146–154. (<a
href="https://doi.org/10.1016/j.comcom.2021.05.024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Internet of Things (IoT) has become a very popular area of research due to its large-scale implementation and challenges. However, security is the key concern while witnessing the rapid growth in its size and applications. It is a tedious task to individually put security mechanisms in each IoT device and update it as per newer threats. Moreover, machine learning models can best utilize the colossal amount of data generated by IoT devices. Therefore, many Deep Learning (DL) based mechanisms have been proposed to detect attacks in IoT. However, the existing security mechanisms addressed limited attacks, and they used limited and outdated datasets for evaluations. This paper presents a novel security framework and an attack detection mechanism using a Deep Learning model to fill in the gap, which will efficiently detect malicious devices. The proposed mechanism uses a Convolution Neural Network (CNN) to extract the accurate feature representation of data and further classifies those by Long Short-Term Memory (LSTM) Model. The dataset used in the experimental evaluation is from twenty Raspberry Pi infected IoT devices. The accuracy of the empirical study for attack detection is 96 percent. In addition, it is observed that the proposed model outperformed various recently proposed DL-based attack detection mechanisms.},
  archive      = {J_COMCOM},
  author       = {Amiya Kumar Sahu and Suraj Sharma and M. Tanveer and Rohit Raja},
  doi          = {10.1016/j.comcom.2021.05.024},
  journal      = {Computer Communications},
  pages        = {146-154},
  shortjournal = {Comput. Commun.},
  title        = {Internet of things attack detection using hybrid deep learning model},
  volume       = {176},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Precise grabbing of overlapping objects system based on
end-to-end deep neural network. <em>COMCOM</em>, <em>176</em>, 138–145.
(<a href="https://doi.org/10.1016/j.comcom.2021.03.015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, robotic arm technology is in dire need of reform because of the remarkable advances in artificial intelligence and computer vision . The traditional robotic arm techniques, e.g., template matching algorithm and iterative closest point algorithm , suffer from the low precision issue, especially when the target objects overlap with each other, resulting in inaccurate estimation of overlapping objects. This paper proposes a precise grabbing of overlapping objects system based on an end-to-end deep neural network . The successful grabbing is realized in the case of overlapping objects. First, the datasets needed for network training were established, utilizing structured light to obtain the point cloud information of the arbitrarily placed target objects. Furthermore, we collect the corresponding postures as data labels via the teaching device of the robotic arm, and train the network models using the datasets and labels. Finally, we can predict the postures of the target objects in real time and transmit the results to a robotic arm to complete the grabbing work. The experiment results indicate that the proposed grabbing system can grab small irregular objects accurately, only using the point cloud information , estimating the posture of multiple target objects in the scene simultaneously, and estimating the posture of overlapping small objects in the scene.},
  archive      = {J_COMCOM},
  author       = {Hongyu Sun and Xining Cui and Zhan Song and Feifei Gu},
  doi          = {10.1016/j.comcom.2021.03.015},
  journal      = {Computer Communications},
  pages        = {138-145},
  shortjournal = {Comput. Commun.},
  title        = {Precise grabbing of overlapping objects system based on end-to-end deep neural network},
  volume       = {176},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). RPC: Representative possible world based consistent
clustering algorithm for uncertain data. <em>COMCOM</em>, <em>176</em>,
128–137. (<a
href="https://doi.org/10.1016/j.comcom.2021.06.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Clustering uncertain data is an essential task in data mining and machine learning . Possible world based algorithms seem promising for clustering uncertain data. However, there are two issues in existing possible world based algorithms: (1) They rely on all the possible worlds and treat them equally, but some marginal possible worlds may cause negative effects. (2) They do not well utilize the consistency among possible worlds, since they conduct clustering or construct the affinity matrix on each possible world independently. In this paper, we propose a representative possible world based consistent clustering (RPC) algorithm for uncertain data. First, by introducing representative loss and using Jensen–Shannon divergence as the distribution measure, we design a heuristic strategy for the selection of representative possible worlds, thus avoiding the negative effects caused by marginal possible worlds. Second, we integrate a consistency learning procedure into spectral clustering to deal with the representative possible worlds synergistically, thus utilizing the consistency to achieve better performance. Experimental results show that our proposed algorithm outperforms existing algorithms in effectiveness and performs competitively in efficiency.},
  archive      = {J_COMCOM},
  author       = {Han Liu and Xiaotong Zhang and Xianchao Zhang and Qimai Li and Xiao-Ming Wu},
  doi          = {10.1016/j.comcom.2021.06.002},
  journal      = {Computer Communications},
  pages        = {128-137},
  shortjournal = {Comput. Commun.},
  title        = {RPC: Representative possible world based consistent clustering algorithm for uncertain data},
  volume       = {176},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Distributed time synchronization algorithm based on
sequential belief propagation in wireless sensor networks.
<em>COMCOM</em>, <em>176</em>, 119–127. (<a
href="https://doi.org/10.1016/j.comcom.2021.05.018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the context of the non-Gaussian delay model, the fully distributed time synchronization approach based on Gaussian belief propagation will lead to the decline of synchronization accuracy. This paper proposes a distributed time synchronization algorithm based on sequential belief propagation (SBP-DTS), which assumes that the network delay is unknown. SBP-DTS first establishes a factor graph (FG) model for the time synchronization problem of wireless sensor networks (WSNs), and then uses sequential belief propagation (BP) algorithms to estimate node clock parameters under an unknown random delay model. At the same time, in order to reduce the amount of data exchanged between nodes during the execution of sequential belief propagation algorithm, the weighted expectation–maximization (EM) algorithm is used to reduce the number of Gaussian mixture components in the message. At last, the performance of SBP-DTS is evaluated under asymmetric Gaussian and exponential delay models.},
  archive      = {J_COMCOM},
  author       = {Bing Hu and Zhixin Sun and Jian Liu},
  doi          = {10.1016/j.comcom.2021.05.018},
  journal      = {Computer Communications},
  pages        = {119-127},
  shortjournal = {Comput. Commun.},
  title        = {Distributed time synchronization algorithm based on sequential belief propagation in wireless sensor networks},
  volume       = {176},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Information security in the post quantum era for 5G and
beyond networks: Threats to existing cryptography, and post-quantum
cryptography. <em>COMCOM</em>, <em>176</em>, 99–118. (<a
href="https://doi.org/10.1016/j.comcom.2021.05.019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quantum computing is an emerging field that uses the concepts of quantum mechanics to outperform classical computers. Quantum computing finds plethora of applications in the 5G and Beyond networks. It can process data at an exponential rate, which can address numerous business and scientific challenges. In this paper, we provide a detailed review of the field, starting from the most important applications of quantum computers and then diving into the future of cryptography. The major applications of quantum computing include unstructured search, quantum simulation, and optimization. It can also provide improvements in terms of speed and accuracy for some existing technologies, such as machine learning . These technologies have numerous applications in 5G and beyond networks. However, due to such abilities of quantum computing, it can also pose a serious risk to many existing security systems, especially the asymmetric key cryptography schemes. The risk of quantum computing has also influenced the mobile broadband standards to move from a symmetric key cryptography techniques to PKI-based trust model. We also discuss in detail various alternate cryptosystems based on mathematical problems that are believed to be hard even for a quantum computer to solve. In parallel, we discuss the developments in the field of quantum key distribution that makes use of quantum phenomenon to develop a quantum-resistant crypto systems. Such quantum-resistant systems have a great potential in provisioning secure 5G and beyond networks.},
  archive      = {J_COMCOM},
  author       = {Vinay Chamola and Alireza Jolfaei and Vaibhav Chanana and Prakhar Parashari and Vikas Hassija},
  doi          = {10.1016/j.comcom.2021.05.019},
  journal      = {Computer Communications},
  pages        = {99-118},
  shortjournal = {Comput. Commun.},
  title        = {Information security in the post quantum era for 5G and beyond networks: Threats to existing cryptography, and post-quantum cryptography},
  volume       = {176},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An edge computing based data detection scheme for traffic
light at intersections. <em>COMCOM</em>, <em>176</em>, 91–98. (<a
href="https://doi.org/10.1016/j.comcom.2021.05.014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The reliability and validity of traffic data plays an important role in intelligent transportation systems . Most of the data detection schemes target the network level, and rarely discuss the impact of vehicle data detection at intersections on the intelligent control of traffic lights. Moreover, most data detection is processed in a centralized cloud center, which is not suitable for complex and changeable intersections. In this regard, we propose an edge computing based data detection scheme for traffic light intersections. In our scheme, traffic lights act as edge nodes to detect vehicles data. We first consider a single intersection scenario. We collect vehicle data through V2E communication through base station , and use the quotient filter to detect and verify the validity of the data. We further consider the multiple intersections scenario. We merge the vehicle data of the two adjacent intersections, and then detect the validity of the data by the quotient filter. In addition, the scheme uses mmh3 hash functions in the QF filter to reduce the computing resource occupation of edge nodes and the bit error rate. The experimental results show that the data detection solution is effective in detecting data quickly even there is a large number of vehicles and complex vehicle data. Our proposed scheme can also verify the reliability and effectiveness of vehicles with a smaller delay.},
  archive      = {J_COMCOM},
  author       = {Libing Wu and Rui Zhang and Ruiting Zhou and Dan Wu},
  doi          = {10.1016/j.comcom.2021.05.014},
  journal      = {Computer Communications},
  pages        = {91-98},
  shortjournal = {Comput. Commun.},
  title        = {An edge computing based data detection scheme for traffic light at intersections},
  volume       = {176},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Efficient personalized search over encrypted data for mobile
edge-assisted cloud storage. <em>COMCOM</em>, <em>176</em>, 81–90. (<a
href="https://doi.org/10.1016/j.comcom.2021.05.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cloud storage services allow a data owner to share her/his outsourced data with other users, and enable the users to search target data by keywords. To ensure the data confidentiality , data owner always encrypt data using traditional encryption schemes before outsourcing. Whereas, it makes efficiently searching impossible. Symmetric searchable encryption (SSE) is a cryptographic primitive that resolves this tension. However, most existing SSE schemes do not consider the individual characteristics of users during the search, such that they cannot support personalized search services over encrypted data . Meanwhile, security and efficiency issues in the cloud service model have also severely affected the user’s search experience, and the introduction of mobile edge servers can solve these problems to some extent. In this paper, we propose a personalized searchable encryption scheme (PSED) for mobile edge-assisted cloud storage. Our contribution consists of three aspects. First, we incorporate the user’s preference factors into the user’s query which enable users to get accurate personalized search results. Second, the computational overhead of the cloud server is reduced by calculating the relevance scores of the subqueries and subindexes on mobile edge servers. Third, by cutting the index and the query matrix, the encryption efficiency of the index and the query matrix is improved. Security analysis shows that PSED can guarantee the privacy of the data and the user. Experimental results demonstrate that the proposed schemes are highly efficient and accurate.},
  archive      = {J_COMCOM},
  author       = {Qiang Zhang and Guojun Wang and Wenjuan Tang and Karim Alinani and Qin Liu and Xin Li},
  doi          = {10.1016/j.comcom.2021.05.009},
  journal      = {Computer Communications},
  pages        = {81-90},
  shortjournal = {Comput. Commun.},
  title        = {Efficient personalized search over encrypted data for mobile edge-assisted cloud storage},
  volume       = {176},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). AFIF: Automatically finding important features in community
evolution prediction for dynamic social networks. <em>COMCOM</em>,
<em>176</em>, 66–80. (<a
href="https://doi.org/10.1016/j.comcom.2021.05.025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Applications of Intelligent systems have increased the impact of modeling and analyzing in dynamic social networks. For effective decision making, models must be able to forecast the outcome of each option and determine which option is the best for a particular situation. In this context, community evolution prediction is a challenging and time-consuming task, which is the extraction of structural features from large real-world networks. We present AFIF, Automatically Finding Important Features, an efficient solution to examine communities’ structural features and also to find a proper subset of promising features in order to predict the upcoming changes of social networks. AFIF combines two key concepts to find prominent features: (i) Prioritization of attributes based on their Spearman’s correlation with other features. This enables us to know the features that can represent the rest and to explore which features are unique compared to others. (ii) Training a boosting learner and prioritizing attributes based on their usage frequency in learning process to realize which features are more valuable. Eventually, important features are determined by random forest classifier . We have then conducted extensive experiments and confirmed that our selection of features delivers an outstanding performance in contrast with using the entire set of features.},
  archive      = {J_COMCOM},
  author       = {Kaveh Kadkhoda Mohammadmosaferi and Hassan Naderi},
  doi          = {10.1016/j.comcom.2021.05.025},
  journal      = {Computer Communications},
  pages        = {66-80},
  shortjournal = {Comput. Commun.},
  title        = {AFIF: Automatically finding important features in community evolution prediction for dynamic social networks},
  volume       = {176},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Data driven interference source localization based on train
real-time onboard interference monitoring. <em>COMCOM</em>,
<em>176</em>, 56–65. (<a
href="https://doi.org/10.1016/j.comcom.2021.05.021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Interference is an important factor affecting railway mobile communications, which leads to deterioration of communication quality. In serious cases, the link connection interruption will lead to degraded operation of train control system, then affect the operation efficiency of the railway system . In order to reduce the impact of interference on railway communications, the interference source should be localized and eliminated timely. However, the traditional interference localization methods require auxiliary equipment to be arranged along the track. In this paper, a data driven interference source localization method based on train real-time onboard interference monitoring is proposed, which can reduce the interference localization cost. Based on the collected Received Signal Strength (RSS) of interference signal, the particle filter principle is used to locate the target interference source combined with the data driven path-loss models. Besides, the modified whale optimization algorithm (MWOA) is introduced to further improve the positioning accuracy. The simulation and experiment results show that the proposed data driven interference source localization method outperforms the traditional localization method, and the positioning accuracy is improved from tens of meters degree to meters degree, which can meet the requirements of engineering practice to find the interference source.},
  archive      = {J_COMCOM},
  author       = {Ruirui Ning and Siyu Lin and Hongwei Wang and Weiyang Feng and Bin Sun and Jianwen Ding and Wenyi Jiang and Zhangdui Zhong},
  doi          = {10.1016/j.comcom.2021.05.021},
  journal      = {Computer Communications},
  pages        = {56-65},
  shortjournal = {Comput. Commun.},
  title        = {Data driven interference source localization based on train real-time onboard interference monitoring},
  volume       = {176},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). BSLA: Blockchain-assisted secure and lightweight
authentication for SGIN. <em>COMCOM</em>, <em>176</em>, 46–55. (<a
href="https://doi.org/10.1016/j.comcom.2021.05.015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Space–Ground Integrated Network (SGIN) can dramatically reduce the coverage restriction of terrestrial networks , and it therefore can meet the high service requirements to achieve low-latency and high-speed global interconnection at anytime and anywhere. Due to the vulnerable communication channels and the limited resources of spatial nodes such as satellite, SGIN is facing many potential threats. As the first gateway of the SGIN, access authentication is an essential step that guarantees the internal security of the network. However, there are some problems in traditional cryptosystem-based authentication mechanisms , such as certificate management problem and centralized key escrow problem. Consequently, designing a lightweight and secure identity authentication protocol can effectively solve the problems faced by SGIN. In this paper, we focus on the private key escrow problem caused by the Private Key Generator (PKG) in Identity-Based Cryptosystems (IBC) mechanism, and propose a Blockchain-assisted Secure and Lightweight Authentication (BSLA) scheme which introduces the blockchain to improve the robustness and reliability of authentication . In BSLA, user’s private key is determined by itself through combining the partial private keys from different PKGs, which prevents the risk of private key exposure caused by single PKG. Meanwhile, the blockchain also serves as the information source for synchronizing user revocation lists to the spatial nodes, which realizes the fast detection of user revocation . We further analyse the security of BSLA and the analytical results show that BSLA can meet various security requirements. In addition, according to the performance evaluation results, BSLA has good scalability in terms of key security strength. Therefore, users can choose different key security strength and make a trade-off between efficiency and security based on the specific requirements.},
  archive      = {J_COMCOM},
  author       = {Jianfeng Guan and Yinan Wu and Su Yao and Tianhong Zhang and Xiaokang Su and Chuanqing Li},
  doi          = {10.1016/j.comcom.2021.05.015},
  journal      = {Computer Communications},
  pages        = {46-55},
  shortjournal = {Comput. Commun.},
  title        = {BSLA: Blockchain-assisted secure and lightweight authentication for SGIN},
  volume       = {176},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Sparse bayesian learning based channel estimation in
FBMC/OQAM industrial IoT networks. <em>COMCOM</em>, <em>176</em>, 40–45.
(<a href="https://doi.org/10.1016/j.comcom.2021.05.020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The next generation of communication technology is accelerating the transformation of industrial internet of things (IIoT). Filter bank multicarrier with offset quadrature amplitude modulation (FBMC/OQAM), as a candidate wireless transmission technology for beyond fifth generation (5G), has been widely concerned by researchers. However, effective channel estimation (CE) in IIoT communication should be solved. In practice, wireless channels have block–sparse structures. For the conventional sparse channel model, the general sparse channel estimation methods do not take the potential block–sparse structure information into account. In this paper, we have investigated the sparse Bayesian learning (SBL) framework for sparse multipath CE in FBMC/OQAM communications. Block SBL (BSBL) algorithm is proposed to estimate the channel performance by exploiting the block–sparse structure of sparse multipath channel model. The BSBL method can improve the estimation performance by using the block correlation of the training matrix. Computer simulation results demonstrate the robustness of the BSBL CE approach in FBMC/OQAM systems, which can achieve lower mean square error (MSE) and bit error rate (BER) than traditional least squares (LS) method and classical compressive sensing methods. The state of art compressive sampling matching pursuit (CoSaMP) greedy algorithm with a prior knowledge of sparse degree can provide slightly better CE performance than BSBL algorithm, but the proposed method maintains robustness in practical channel scenario without the prior knowledge of sparse degree.},
  archive      = {J_COMCOM},
  author       = {Han Wang and Xingwang Li and Rutvij H. Jhaveri and Thippa Reddy Gadekallu and Mingfu Zhu and Tariq Ahamed Ahanger and Sunder Ali Khowaja},
  doi          = {10.1016/j.comcom.2021.05.020},
  journal      = {Computer Communications},
  pages        = {40-45},
  shortjournal = {Comput. Commun.},
  title        = {Sparse bayesian learning based channel estimation in FBMC/OQAM industrial IoT networks},
  volume       = {176},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A correlation-based approach to detecting wireless physical
covert channels. <em>COMCOM</em>, <em>176</em>, 31–39. (<a
href="https://doi.org/10.1016/j.comcom.2021.05.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of wireless communication technology, the openness of wireless communication makes it more likely to be threated by radio interception or even maliciously use. As a widely used way to exfiltrate information, the wireless covert channel brings a great threat to communication security. Compared with the wireless covert channel on the upper layer, the wireless covert channel based on the physical layer (WCC-P) has better concealment and greater capacity. However, due to the high variation in the wireless communication channel, detecting WCC-P is a challenging task. Existing detection schemes are ineffective at detecting most of WCC-P schemes. In this paper, we propose a new correlation-based scheme to detect WCC-P communication signal. The proposed detection scheme is based on the correlation coefficient of the constellation error vectors (CEV) for multiple antennas . The difference in the correlation coefficient of a detection process provides a critical clue for WCC-P signal detection. Exploiting this observation, we investigate the use of the correlation coefficient in detecting WCC-P communication signal. Simulations show that the proposed scheme can effectively detect WCC-P signal. When the signal-to-noise ratio (SNR) reaches 5 dB, the detection accuracy can reach more than 90\%.},
  archive      = {J_COMCOM},
  author       = {Shuhua Huang and Weiwei Liu and Guangjie Liu and Yuewei Dai and Huiwen Bai},
  doi          = {10.1016/j.comcom.2021.05.017},
  journal      = {Computer Communications},
  pages        = {31-39},
  shortjournal = {Comput. Commun.},
  title        = {A correlation-based approach to detecting wireless physical covert channels},
  volume       = {176},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A mutual information based federated learning framework for
edge computing networks. <em>COMCOM</em>, <em>176</em>, 23–30. (<a
href="https://doi.org/10.1016/j.comcom.2021.05.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the application of artificial intelligence in all field of life, people pay more attention to user privacy and data security. Under the condition of protecting user privacy, the federated learning model has become a popular research technology to solve the data islands problems. The edge computing network can be applied to smart city, Internet of vehicles and so on. Federated learning is a framework in which multiple hosts jointly learn a machine learning model. Each work device maintains the local model of its local training dataset, while the master device maintains the global model by aggregating the local models from the work devices. However, it cannot ensure that every local work device is an honest user because of a phenomenon that the hosts has been operated by attacker interferes in the process of local model training. In this paper, we assume that malicious nodes upload unreal learning parameters in the federated learning framework, which the global model will have high error rate. We propose a federated learning parameter aggregating algorithm based on mutual information. We introduced the relevance of model training learning rate to determine the consistency of the training direction of the local and central models at coarse granularity . We aggregated the parameters of the models at fine granularity based on the correlation of the gradients based on the mutual information. The mutual information method is used to calculate the similarity of the gradient trend between the local training model and overall model. We set the trust weight of each work device to reduce the negative impact of malicious nodes. The evaluation results show that the classification accuracy of the MIFL model is improved as compared with the average federated learning without malicious node. Especially, in the case of existing malicious nodes, the proposed algorithm can defend against malicious node attacks and sustain the robustness of Federated learning.},
  archive      = {J_COMCOM},
  author       = {Naiyue Chen and Yinglong Li and Xuejun Liu and Zhenjiang Zhang},
  doi          = {10.1016/j.comcom.2021.05.013},
  journal      = {Computer Communications},
  pages        = {23-30},
  shortjournal = {Comput. Commun.},
  title        = {A mutual information based federated learning framework for edge computing networks},
  volume       = {176},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Reinforcement learning-enabled intelligent device-to-device
(i-D2D) communication in narrowband internet of things (NB-IoT).
<em>COMCOM</em>, <em>176</em>, 13–22. (<a
href="https://doi.org/10.1016/j.comcom.2021.05.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The 5 5 th Generation (5G) and Beyond 5G (B5G) are expected to be the enabling technologies for Internet-of-Everything (IoE). The quality-of-service (QoS) for IoE in the context of uplink data delivery of the content is of prime importance. The 3 3 rd Generation Partnership Project (3GPP) standardizes the Narrowband Internet-of-Things (NB-IoT) in 5G, which is Low Power Wide Area (LPWA) technology to enhance the coverage and to optimize the power consumption for the IoT devices. Repetitions of control and data signals between NB-IoT User Equipment (UE) and the evolved NodeB/Base Station (eNB/BS), is one of the most prominent characteristics in NB-IoT. These repetitions ensure high reliability in the context of data delivery of time-sensitive applications, e.g., healthcare applications. However, these repetitions degrade the performance of the resource-constrained IoT network in terms of energy consumption. Device-to-Device (D2D) communication standardized in Long Term Evolution-Advanced (LTE-A) offers a key solution for NB-IoT UE to transmit in two hops route instead of direct uplink, which augments the efficiency of the system. In an effort to improve the data packet delivery , this study investigates D2D communication for NB-IoT delay-sensitive applications, such as healthcare-IoT services. This study formulates the selection of D2D communication relay as Multi-Armed Bandit (MAB) problem and incorporates Upper Confidence Bound (UCB) based Reinforcement Learning (RL) to solve MAB problem. The proposed Intelligent-D2D (I-D2D) communication methodology selects the optimum relay with a maximum Packet Delivery Ratio (PDR) with minimum End-to-End Delay (EED), which ultimately augments energy efficiency.},
  archive      = {J_COMCOM},
  author       = {Ali Nauman and Muhammad Ali Jamshed and Rashid Ali and Korhan Cengiz and Zulqarnain and Sung Won Kim},
  doi          = {10.1016/j.comcom.2021.05.007},
  journal      = {Computer Communications},
  pages        = {13-22},
  shortjournal = {Comput. Commun.},
  title        = {Reinforcement learning-enabled intelligent device-to-device (I-D2D) communication in narrowband internet of things (NB-IoT)},
  volume       = {176},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Time dependent network resource optimization in
cyber–physical systems using game theory. <em>COMCOM</em>, <em>176</em>,
1–12. (<a href="https://doi.org/10.1016/j.comcom.2021.04.034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The social and economic stability of a country is dependent on critical infrastructures (CIs) whose services range from financial to healthcare and power to transportation and communications. Most of these CIs are cyber–physical systems (CPSs), which integrate the network’s computational and communication capabilities to facilitate the monitoring and controlling of physical processes. Such systems are vulnerable to damage due to natural disasters, physical incidents, or cyber-attacks impacting the CPS organizations managing complex industrial control systems and data acquisition systems. When these CPSs are exposed to systemic cyber risks and cascaded network failures, network administrators need to recover from the compromise under limited resources. This is formulated as an attacker-defender game model to emulate the decision-making process in choosing an appropriate attack/defence mechanism in response to cybersecurity incidents using game theory. To further improve the assumptions made in the pure game-theoretic model, we relax the constraints on the rationality of the players, monetary payoff, and completeness of information by incorporating learning in games using reinforcement learning technique and compute the expected payoff using linguistic fuzzy variables.},
  archive      = {J_COMCOM},
  author       = {Monica Ravishankar and Thompson Stephan and Thinagaran Perumal},
  doi          = {10.1016/j.comcom.2021.04.034},
  journal      = {Computer Communications},
  pages        = {1-12},
  shortjournal = {Comput. Commun.},
  title        = {Time dependent network resource optimization in cyber–physical systems using game theory},
  volume       = {176},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A cloud-RAN based end-to-end computation offloading in
mobile edge computing. <em>COMCOM</em>, <em>175</em>, 193–204. (<a
href="https://doi.org/10.1016/j.comcom.2021.05.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cloud Radio Access Network (C-RAN) and Mobile Edge Computing (MEC) have recently emerged as promising leading technologies for next generation mobile networks. Due to its low access latency, MEC is not only a convenient candidate for deployment of C-RAN, but it can also be served by Mobile Users (MUs) to offload their computation-intensive applications. This convergence can facilitate the utilization of knowledge acquired through inter-BBU information sharing to improve the quality of offloading decision. In this paper, we propose an end-to-end communication and computation offloading architecture which takes the full advantage of C-RAN to solve the MEC offloading problem with regard to both partitioning as well as sending and return RRH assignment problems. Based on the proposed architecture, we model the end-to-end offloading problem as an ILP with the objective of minimizing the cost of offloading considering the intra and inter cluster handover costs besides other factors. Due to the complexity of the end-to-end offloading problem, we propose a combination of utility functions and modified min-cut algorithms to solve the aforementioned problems in a timely manner. Simulation results demonstrate that the proposed approach outperforms significantly other alternatives in terms of execution time, energy consumption and aggregated cost under scenarios with different amounts of normalized throughput , invocation data and workload.},
  archive      = {J_COMCOM},
  author       = {Rezvan Gholivand and Zeinab Movahedi},
  doi          = {10.1016/j.comcom.2021.05.003},
  journal      = {Computer Communications},
  pages        = {193-204},
  shortjournal = {Comput. Commun.},
  title        = {A cloud-RAN based end-to-end computation offloading in mobile edge computing},
  volume       = {175},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). BlockTour: A blockchain-based smart tourism platform.
<em>COMCOM</em>, <em>175</em>, 186–192. (<a
href="https://doi.org/10.1016/j.comcom.2021.05.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The traditional tourism industry is in urgent need of digital technologies for cost reduction and efficiency enhancement. Blockchain , as an emerging technology, is promising to reform the tourism industry because it provides a trustworthy platform to link the tourism company and tourists. However, the existing blockchain-based smart tourism solutions are either conceptual or limited in solving the fundamental tourism challenges. In this paper, we propose BlockTour, a blockchain-based smart tourism platform with dedicated solution to address the challenges and real-world prototype deployment. In particular, we design the overall system architecture of BlockTour to link the tourists and attractions in a trustworthy way. Moreover, an efficient consensus mechanism is designed with incentives for the tourists to explore more attractions. Finally, we implement BlockTour and conduct extensive experiments for performance evaluation. The experimental results indicate that BlockTour is a practical and high-performance smart tourism platform.},
  archive      = {J_COMCOM},
  author       = {Li Luo and Jing Zhou},
  doi          = {10.1016/j.comcom.2021.05.011},
  journal      = {Computer Communications},
  pages        = {186-192},
  shortjournal = {Comput. Commun.},
  title        = {BlockTour: A blockchain-based smart tourism platform},
  volume       = {175},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Survivability of mobile and wireless communication networks
by using service oriented software defined network based heterogeneous
inter-domain handoff system. <em>COMCOM</em>, <em>175</em>, 177–185. (<a
href="https://doi.org/10.1016/j.comcom.2021.05.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Internet of Things (IoT) is one of the heterogeneous network consists of vast number of connected devices. These networks need smart architecture to accommodate the expected increase of data generation. Software-Defined Networks (SDN) have gained popularity as a key enabler for automated provisioning and ease in IoT network resources management . For ubiquitous coverage, these network involve seamless handoff of the user devices ensuring the provision the services as per user demand. Although the basic inter-domain handoff rules exist in the next SDN domain are not sufficient to provide the primary domain services to the IoT networks. This issue leads to degradation of post-handover performance. In this paper, the SDN based Heterogeneous Inter-Domain Handoff system for IoT (SDN-HIIoT) is proposed that enables SDN-Controller to exchange flow rules by using the East/West application programming interface . The proposed system is using a process of hybrid flow rules execution on heterogeneous SDN domain for provision of Quality of Services (QoS) to mobile users the same as the primary domain. Experiment results are provided to demonstrate the proposed system can significantly improve the post-handoff performance and provides ubiquitous services.},
  archive      = {J_COMCOM},
  author       = {Sabih Khan and Saleem Iqbal and Kashif Naseer Qureshi and Kayhan Zrar Ghafoor and Pyoungwon Kim and Gwanggil Jeon},
  doi          = {10.1016/j.comcom.2021.05.010},
  journal      = {Computer Communications},
  pages        = {177-185},
  shortjournal = {Comput. Commun.},
  title        = {Survivability of mobile and wireless communication networks by using service oriented software defined network based heterogeneous inter-domain handoff system},
  volume       = {175},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Regression-based fragmentation metric and
fragmentation-aware algorithm in spectrally-spatially flexible optical
networks. <em>COMCOM</em>, <em>175</em>, 156–176. (<a
href="https://doi.org/10.1016/j.comcom.2021.05.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spectrally-spatially flexible optical networks (SS-FONs) are seen as a next frontier in optical backbone networks that allow supplying demanded high-capacity transmission. In SS-FONs, signals are co-propagating in spatial modes of suitably designed optical fibers , e.g., in the bundles of single-core single-mode fibers. Despite significant fiber capacity, SS-FONs operate on a flexible (elastic) grid which allows for assigning an adjustable amount of spectrum resources according to the requested bit-rate. The full potential of SS-FONs’ spectral and spatial flexibility can be exploited when nodes are equipped with switching devices enabling lane changes, i.e., the devices that support arbitrary switching between input and output spatial modes connected to the node. However, before the SS-FON will reach maturity and become ready for commercial applications, several crucial issues need to be solved. In this paper, we study the fragmentation problem for dynamic traffic in SS-FONs with lane changes. We propose a novel weighted fragmentation metric that accounts for vertical and horizontal fragmentation in the considered scenario. The machine learning regression model is created and solved to obtain the best weights combination that minimizes the network fragmentation. We run experiments on the representative network topology using our developed fragmentation-aware algorithm showing that the proposed metric and assigned fiber weights result in network fragmentation decrease. As a consequence, the proposed solution allows for bandwidth blocking probability reduction when compared to the reference methods. Finally, we discuss several optimization strategies that decrease the computational complexity of our algorithm.},
  archive      = {J_COMCOM},
  author       = {Piotr Lechowicz},
  doi          = {10.1016/j.comcom.2021.05.012},
  journal      = {Computer Communications},
  pages        = {156-176},
  shortjournal = {Comput. Commun.},
  title        = {Regression-based fragmentation metric and fragmentation-aware algorithm in spectrally-spatially flexible optical networks},
  volume       = {175},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). IRS-assisted low altitude passive aerial relaying.
<em>COMCOM</em>, <em>175</em>, 150–155. (<a
href="https://doi.org/10.1016/j.comcom.2021.05.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies an unmanned aerial vehicle (UAV) based intelligent reflecting surface (IRS) assisted low altitude passive aerial relaying system. This ensures that more users can be served with better wireless channels. The flexibility of the UAV-based relay carrying the IRS can passively provide better signal-to-noise ratio (SNR) to compensate the performance degradation at the edge of cells or in the period of heavy traffic. In particular, the UAV-based IRS can generate an equivalent line-of-sight (ELoS) channel to transform the conventional Rayleigh fading channel into a Rician fading channel, which will significantly improve the performance of urban mobile communications. Closed-form expression for the outage is derived, and numerical results are presented to demonstrate the performance of the proposed UAV-IRS passive relaying scheme.},
  archive      = {J_COMCOM},
  author       = {Minghe Mao and Ning Cao and Rui Li and Rui Shi},
  doi          = {10.1016/j.comcom.2021.05.001},
  journal      = {Computer Communications},
  pages        = {150-155},
  shortjournal = {Comput. Commun.},
  title        = {IRS-assisted low altitude passive aerial relaying},
  volume       = {175},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Cascaded fault detection system of error back-propagation
network based on node association degree. <em>COMCOM</em>, <em>175</em>,
142–149. (<a
href="https://doi.org/10.1016/j.comcom.2021.04.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In view of the problems of low fault identification rate and large global error of network fault system designed by the existing methods, an automatic fault detection system based on node association degree is proposed. Firstly, the hardware design of the system is completed by describing and analyzing the initialization module, detector training module , memory antibody module and fault automatic detection module. Secondly, the system software is designed by network anomaly diagnosis and configuration anomaly detection . Finally, the system can detect the cascade fault of the backward propagation network by the design of software and hardware. The experimental results show that the system designed in this paper has high fault identification rate and small global error of fault detection, and can accurately detect the network cascade faults.},
  archive      = {J_COMCOM},
  author       = {Feifei Yin and Bingzhe He},
  doi          = {10.1016/j.comcom.2021.04.011},
  journal      = {Computer Communications},
  pages        = {142-149},
  shortjournal = {Comput. Commun.},
  title        = {Cascaded fault detection system of error back-propagation network based on node association degree},
  volume       = {175},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Four-channel LIDAR relative navigation system for rocket
first stage recovery at sea. <em>COMCOM</em>, <em>175</em>, 123–141. (<a
href="https://doi.org/10.1016/j.comcom.2021.05.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In view of the shortcomings of “GPS + INS + two-way data link” navigation solution for rocket first stage recovery using vertical landing droneship, a four-channel light detection and ranging (LIDAR) relative navigation system (FCLRNS) is proposed in this paper. The system is based on the physical phenomenon that the laser reflectivity of the ship deck in the near-infrared band is four orders of magnitude higher than that of the sea surface. The FCLRNS laser detection model is established and its navigation solution which provides estimates of the trajectory inclination angle, the altitude, the speed of the rocket first stage relative to the sea/ship surface, and the roll angle of the first stage using four-channel LIDAR ranging information is formulated. Simulation results show that the FCLRNS can reliably identify the ship surface and the sea surface and accurately obtain the above navigation parameters. In order to verify the effectiveness of FCLRNS, a relative navigation experiment is conducted in which rotorcraft and reduced scale ship on the lake are used to simulate the rocket first stage recovery at sea. The experiment results are consistent with those of the simulation. The FCLRNS navigation scheme can be further combined with other systems, for example the optical system to provide full relative position and attitude information, and thus is a useful supplement to “GPS+INS+two-way data link” navigation solution for the rocket first stage recovery.},
  archive      = {J_COMCOM},
  author       = {Tao Zeng and Hua Wang and Wei Wei and Hao Cheng and CanLun Zheng and XiuYuan Feng and Wei Shan},
  doi          = {10.1016/j.comcom.2021.05.004},
  journal      = {Computer Communications},
  pages        = {123-141},
  shortjournal = {Comput. Commun.},
  title        = {Four-channel LIDAR relative navigation system for rocket first stage recovery at sea},
  volume       = {175},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An efficient time-sensitive data scheduling approach for
wireless sensor networks in smart cities. <em>COMCOM</em>, <em>175</em>,
112–122. (<a
href="https://doi.org/10.1016/j.comcom.2021.05.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Continuous increase in urban population causes enormous pressure on cities’ limited resources, including transport, energy, water, housing, public services, and others. Hence, the need to plan and develop smart cities based solutions for enhanced urban governance is becoming more evident. These solutions are motivated by innovations in Information and Communication Technology to support smart planning for the city and to facilitate enhanced services to its citizens. Important areas where smart city services can be offered include urban planning, transport planning, energy conservation, water management, waste management, environmental monitoring, public safety, healthcare, education, entertainment, and many other services. Hence, the enormous data collected from different networks and applications to facilitate the offering of smart city services requires efficient data scheduling, aggregation, and processing to ensure service quality (QoS). However, existing data scheduling approaches consider scheduling and processing data only in the cloud, while processing also in the data collecting devices is significantly essential. This paper first introduces the multi-layer network architecture comprising sensor/device networks and cloud. The paper then introduces a Multi-layer, Priority-based, Dynamic, and Time-sensitive data processing and Scheduling approach (MPDTS) in the proposed multi-layer networks. Simulation results show that the proposed MPDTS approach achieves lower latency and data processing time than existing traditional data scheduling approaches that work only in the cloud layer.},
  archive      = {J_COMCOM},
  author       = {Nidal Nasser and Nargis Khan and Lutful Karim and Mohamed ElAttar and Kassem Saleh},
  doi          = {10.1016/j.comcom.2021.05.006},
  journal      = {Computer Communications},
  pages        = {112-122},
  shortjournal = {Comput. Commun.},
  title        = {An efficient time-sensitive data scheduling approach for wireless sensor networks in smart cities},
  volume       = {175},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A big data based architecture for collaborative networks:
Supply chains mixed-network. <em>COMCOM</em>, <em>175</em>, 102–111. (<a
href="https://doi.org/10.1016/j.comcom.2021.05.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, the world knows a high-speed development and evolution of technologies, vulnerable economic environments, market changes, and personalised consumer trends. The issue and challenge related to enterprises networks design are more and more critical. These networks are often designed for short terms since their strategies must be competitive and better adapted to the environment, social and economical changes. As a solution, to design a flexible and robust network, it is necessary to deal with the trade-off between conflicting qualitative and quantitative criteria such as cost, quality, delivery time, and competition, etc. To this end, using Big Data (BD) as emerging technology will enhance the real performances of these kinds of networks. Moreover, even if the literature is rich with BD models and frameworks developed for a single supply chain network (SCN), there is a real need to scale and extend these BD models to networked supply chains (NSCs). To do so, this paper proposes a BD architecture to drive a mixed-network of SCs that collaborate in serial and parallel fashions. The collaboration is set up by sharing their resources, capabilities, competencies, and information to imitate a unique organisation. The objective is to increase internal value to their shareholders (where value is seen as wealth) and deliver better external value to the end-customer (where value represents customer satisfaction). Within a mixed-network of SCs, both values are formally calculated considering both serial and parallel networks configurations . Besides, some performance factors of the proposed BD architecture such as security, flexibility, robustness and resilience are discussed.},
  archive      = {J_COMCOM},
  author       = {Lahcen Tamym and Lyes Benyoucef and Ahmed Nait Sidi Moh and Moulay Driss El Ouadghiri},
  doi          = {10.1016/j.comcom.2021.05.008},
  journal      = {Computer Communications},
  pages        = {102-111},
  shortjournal = {Comput. Commun.},
  title        = {A big data based architecture for collaborative networks: Supply chains mixed-network},
  volume       = {175},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Game-based incentive mechanism for enabling edge video
caching over passive optical networks. <em>COMCOM</em>, <em>175</em>,
91–101. (<a href="https://doi.org/10.1016/j.comcom.2021.05.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the ever-increasing mobile video traffic, edge caching enabled passive optical networks (PONs), where storages are deployed on optical network units (ONUs), are becoming a desirable back-end for mobile backhaul (MBH). By caching videos on ONUs, video requests generated in MBH can be efficiently accommodated. Thus, many previous works focus on leveraging the caching capabilities of ONUs to maximize the video cache-hit ratio. However, it is largely ignored how to stimulate individual ONUs to contribute their storages for caching videos. In this paper, we propose a game-based incentive mechanism through which the content provider (CP) rewards ONUs for their storage-contributions. We firstly formulate a two-level Stackelberg game to capture the interaction between the CP and ONUs. At the first level, the CP determines rewarding policy to maximize its utility. At the second level, ONUs react with the amount of provided storages with the aim to cooperatively maximize the social utility or competitively maximize their respective utilities, and thereby two sub-games are further modeled to depict the cooperation and competition among ONUs. We then give the specific strategies of cooperative ONUs and competitive ONUs, respectively. We also show the existence of an equilibrium in the formulated Stackelberg game . The performance of the proposed incentive scheme is finally evaluated by simulations.},
  archive      = {J_COMCOM},
  author       = {Yan Li and Jianping Wang and Jinliang Liu},
  doi          = {10.1016/j.comcom.2021.05.002},
  journal      = {Computer Communications},
  pages        = {91-101},
  shortjournal = {Comput. Commun.},
  title        = {Game-based incentive mechanism for enabling edge video caching over passive optical networks},
  volume       = {175},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). 3P-SAKE: Privacy-preserving and physically secured
authenticated key establishment protocol for wireless industrial
networks. <em>COMCOM</em>, <em>175</em>, 82–90. (<a
href="https://doi.org/10.1016/j.comcom.2021.04.021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A new industrial revolution is emerging with the Internet of Things (IoT) growing use in enabling the machine to machine communication between the devices, sensors, actuators, and gateways. IoT lets the communication across devices and the network happen in real-time and helps make technologically smart homes, smart hospitals, and smart industrial applications. The authentication schemes in IoT have to be robust and lightweight to be useful for resource-constrained real-time applications where user privacy and physical security are the priority concerns. The IoT devices are prone to physical attacks due to their installation in hostile environments. The intruders want to physically capture the IoT nodes for cloning and accessing the stored confidential information, thus necessitating IoT nodes’ physical protection. This article proposes a less expensive and physically secured user authentication and secure key exchange protocol for industry 4.0 applications. Physically unclonable functions (PUF), hash, and XOR operations are used in the proposed method to attain robustness and efficiency. The scheme’s other benefits include low computational cost, retaining the device’s confidentiality, safety from major security threats, low communication, and storage overhead.},
  archive      = {J_COMCOM},
  author       = {Mehedi Masud and Mamoun Alazab and Karanjeet Choudhary and Gurjot Singh Gaba},
  doi          = {10.1016/j.comcom.2021.04.021},
  journal      = {Computer Communications},
  pages        = {82-90},
  shortjournal = {Comput. Commun.},
  title        = {3P-SAKE: Privacy-preserving and physically secured authenticated key establishment protocol for wireless industrial networks},
  volume       = {175},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Utility maximization data scheduling in drone-assisted
vehicular networks. <em>COMCOM</em>, <em>175</em>, 68–81. (<a
href="https://doi.org/10.1016/j.comcom.2021.04.033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In Vehicular Networks (VANETs), the rapid movement of vehicles leads to highly time-varying network topology and brings the problem of blind spots in signal coverage. To address these issues, drones are employed to assist data dissemination in VANETs attribute to the flexible development of drones. As random data transmission will result in decreased network performance and low efficiency in data retrieval service, it is urgent to develop efficient data scheduling schemes that meet the quality of service (QoS) of different applications in VANETs. In this context, to fulfill the request of real-time and reliable data transmission, we formulate a data scheduling problem that considers the factors such as priority of data transmission, link quality, link connection time and network fairness. Our goal is to reduce random data transmission, therefore maximizing network transmission utility. We utilize graph theory to describe network topology , in which vehicles and drones are represented as vertices and links between the nodes are represented as edges. The weight of edges indicates the utility obtained when data transmits between the corresponding nodes. We reduce the data scheduling problem to the maximum weighted matching problem and then propose a data scheduling scheme that can satisfy data requests of different vehicles to the maximum extent. The theoretical analysis derives the scheduling algorithm’s time complexity and the number of scheduling stages required to satisfy the data requests. Finally, simulation verifies the proposed scheme’s effectiveness in terms of service rate, service delay, fairness and throughput.},
  archive      = {J_COMCOM},
  author       = {Xiying Fan and Baolin Liu and Chuanhe Huang and Shaojie Wen and Bin Fu},
  doi          = {10.1016/j.comcom.2021.04.033},
  journal      = {Computer Communications},
  pages        = {68-81},
  shortjournal = {Comput. Commun.},
  title        = {Utility maximization data scheduling in drone-assisted vehicular networks},
  volume       = {175},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Performance evaluation of convolutional neural network for
web security. <em>COMCOM</em>, <em>175</em>, 58–67. (<a
href="https://doi.org/10.1016/j.comcom.2021.04.029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the daily use of web applications in several critical domains such as banking and online shopping, cybersecurity has become a challenge. Recently, deep learning techniques have achieved promising results and attracted cybersecurity researchers. In this paper, we explore and evaluate deep learning techniques used for the security of web applications. We analyze through experiments the different factors influencing the performance of the Convolutional Neural Network (CNN) technique for web attacks detection. The experiments done in this paper focus on CNN and have three goals. First, we evaluate the performance of different CNN models using two different methods of data input presentation and data input splitting. Second, we study the impact of the different CNN hyper-parameters on the attack detection rate. Third, we select the best deep learning toolbox that will be used in our future proposed detection technique. Through the experiments conducted in this paper, we reveal that an adequate tuning of hyper-parameters and the way of pre-processing data input have a significant impact on the attack detection rate.},
  archive      = {J_COMCOM},
  author       = {Ines Jemal and Mohamed Amine Haddar and Omar Cheikhrouhou and Adel Mahfoudhi},
  doi          = {10.1016/j.comcom.2021.04.029},
  journal      = {Computer Communications},
  pages        = {58-67},
  shortjournal = {Comput. Commun.},
  title        = {Performance evaluation of convolutional neural network for web security},
  volume       = {175},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A novel approach for phishing URLs detection using lexical
based machine learning in a real-time environment. <em>COMCOM</em>,
<em>175</em>, 47–57. (<a
href="https://doi.org/10.1016/j.comcom.2021.04.023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent times, we can see a massive increase in the number of devices that are being connected to the internet. These devices include but are not limited to smartphones, IoT , and cloud networks. In comparison to other possible cyber-attacks, these days, hackers are targeting these devices with phishing attacks since it exploits human vulnerabilities rather than system vulnerabilities. In a phishing attack, an online user is deceived by a seemingly trusted entity to give their personal data, i.e., login credentials or credit card details. When this private information is leaked to the hackers, this information becomes the source of other sophisticated attacks. In recent times many researchers have proposed the machine learning-based approach to solve phishing attacks ; however, they have used a large number of features to develop reliable phishing detection techniques. A large number of features requires large processing powers to detect phishing, which makes it very much unsuitable for resource constrained devices. To address this issue, we have developed a phishing detection approach that only needs nine lexical features for effectively detecting phishing attacks. We used ISCXURL-2016 dataset for our experimental purpose, where 11964 instances of legitimate and phishing URLs are used. We have tested our approach against different machine learning classifiers and have obtained the highest accuracy of 99.57\% with the Random forest algorithm.},
  archive      = {J_COMCOM},
  author       = {Brij B. Gupta and Krishna Yadav and Imran Razzak and Konstantinos Psannis and Arcangelo Castiglione and Xiaojun Chang},
  doi          = {10.1016/j.comcom.2021.04.023},
  journal      = {Computer Communications},
  pages        = {47-57},
  shortjournal = {Comput. Commun.},
  title        = {A novel approach for phishing URLs detection using lexical based machine learning in a real-time environment},
  volume       = {175},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Interval-valued intuitionistic fuzzy-analytic hierarchy
process for evaluating the impact of security attributes in fog based
internet of things paradigm. <em>COMCOM</em>, <em>175</em>, 35–46. (<a
href="https://doi.org/10.1016/j.comcom.2021.04.019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Internet of Things (IoT) may be defined as a network of smart devices that are involved in data collection and exchange. This technology has automated the day-to-day jobs and thus made our lives easier. But, real-time analysis of data is not always possible in a typical cloud-IoT architecture, especially for latency-sensitive applications. This led to the introduction of fog computing . On one side, fog layer has the capability of data processing and computation at the network edge and thus provides faster results. But, on the other hand, it also brings the attack surface closer to the devices. This makes the sensitive data on the layer vulnerable to attacks. Thus, considering Fog-IoT security is of prime importance. The security of a system or platform depends upon multiple factors. The order of selection of these factors plays a vital role in efficient assessment of security. This makes the problem of assessment of Fog-IoT security a Multi-Criteria Decision-Making (MCDM) problem. Therefore, the authors have deployed an Interval-Valued Intuitionistic Fuzzy Set (IVIFS) based Analytical Hierarchy Process (AHP) for the said environment. Using this integrated approach, the Fog-IoT security factors and their sub-factors are prioritized and ranked. The results obtained using above hybrid approach are validated by comparing them with Fuzzy-AHP (F-AHP) and Classical- AHP (C-AHP) results and are found to statistically correlated. The ideology and results of this research will help the security practitioners in accessing the security of Fog-IoT environment effectively. Moreover, the outcome of this analysis will help in paving a path for researchers by shifting their focus towards the most prioritized factor thereby assuring security in the environment.},
  archive      = {J_COMCOM},
  author       = {Richa Verma and Shalini Chandra},
  doi          = {10.1016/j.comcom.2021.04.019},
  journal      = {Computer Communications},
  pages        = {35-46},
  shortjournal = {Comput. Commun.},
  title        = {Interval-valued intuitionistic fuzzy-analytic hierarchy process for evaluating the impact of security attributes in fog based internet of things paradigm},
  volume       = {175},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A new intelligent and data-driven product quality control
system of industrial valve manufacturing process in CPS.
<em>COMCOM</em>, <em>175</em>, 25–34. (<a
href="https://doi.org/10.1016/j.comcom.2021.04.022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The development of intelligent and data-driven product quality control system are emerging as key engineering technologies for industrial manufacturing process . And many studies have been made to investigate the application of quality control of industrial valve manufacturing process in cyber–physical systems (CPS). The purpose of this article is to provide a quality control and management system by using the modern electronics technology, information technology and network technology. Firstly, we propose an intelligent and data-driven framework model of product quality based on the advanced technology of digital twin (DT) and simulation methods for CPS. Secondly, we emphasize the manufacturing enterprise should hold a data accumulation, and give some useful advises on how to carry out a successful quality analysis system of industrial valve manufacturing process in CPS. Then, as a case, the intelligent method of BP neural network is constructed according to lots of quality characteristics (QCs) of the mechanical and electrical product of industrial valve, and the BP network is trained by using many quality failures of manufacturing process. Finally, the results show that the new quality control system has good accuracy and practicability by the practical example.},
  archive      = {J_COMCOM},
  author       = {Jihong Pang and Nan Zhang and Quan Xiao and Faqun Qi and Xiaobo Xue},
  doi          = {10.1016/j.comcom.2021.04.022},
  journal      = {Computer Communications},
  pages        = {25-34},
  shortjournal = {Comput. Commun.},
  title        = {A new intelligent and data-driven product quality control system of industrial valve manufacturing process in CPS},
  volume       = {175},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Air quality assessment system based on self-driven drone and
LoRaWAN network. <em>COMCOM</em>, <em>175</em>, 13–24. (<a
href="https://doi.org/10.1016/j.comcom.2021.04.032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Poor air quality harms human health and the environment. In Europe, emissions of many air pollutants have decreased substantially over the past decades. A significant part of Europe’s population lives in areas, especially cities, where exceedances of air quality standards occur: ozone (O3), nitrogen dioxide (NO2) and particulate matter (PM) pollution pose serious health problems. Several countries have exceeded one or more of their 2010 emission limits for four important air pollutants. Reducing air pollution therefore remains important. This paper presents a low-cost air quality monitoring device that due to the communication technology (LoRaWAN) can be used on large geographical areas. The presented solution was tested and verified on real field service conditions. The obtained data is compared with existing public air quality stations official data.},
  archive      = {J_COMCOM},
  author       = {Attila Simo and Simona Dzitac and Ioan Dzitac and Mihaela Frigura-Iliasa and Flaviu Mihai Frigura-Iliasa},
  doi          = {10.1016/j.comcom.2021.04.032},
  journal      = {Computer Communications},
  pages        = {13-24},
  shortjournal = {Comput. Commun.},
  title        = {Air quality assessment system based on self-driven drone and LoRaWAN network},
  volume       = {175},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Deep reinforcement learning for computation offloading in
mobile edge computing environment. <em>COMCOM</em>, <em>175</em>, 1–12.
(<a href="https://doi.org/10.1016/j.comcom.2021.04.028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, in order to distribute computing, networking resources, services, near terminals, mobile fog is gradually becoming the mobile edge computing (MEC) paradigm. In a mobile fog environment, the quality of service affected by offloading speeds and the fog processing, however the traditional fog method to solve the problem of computation resources allocation is difficult because of the complex network states distribution environment (that is, F-AP states, AP states, mobile device states and code block states). In this paper, to improve the fog resource provisioning performance of mobile devices, the learning-based mobile fog scheme with deep deterministic policy gradient (DDPG) algorithm is proposed. An offloading block pulsating discrete event system is modeled as a Markov Decision Processes (MDPs), which can realize the offloading computing without knowing the transition probabilities among different network states. Furthermore, the DDPG algorithm is used to solve the issue of state spaces explosion and learn an optimal offloading policy on distributed mobile fog computing . The simulation results show that our proposed scheme achieves 20\%, 37\%, 46\% improvement on related performance compared with the policy gradient (PG), deterministic policy gradient (DPG) and actor–critic (AC) methods. Besides, compared with the traditional fog provisioning scheme, our scheme shows better cost performance of fog resource provisioning under different locations number and different task arrival rates.},
  archive      = {J_COMCOM},
  author       = {Miaojiang Chen and Tian Wang and Shaobo Zhang and Anfeng Liu},
  doi          = {10.1016/j.comcom.2021.04.028},
  journal      = {Computer Communications},
  pages        = {1-12},
  shortjournal = {Comput. Commun.},
  title        = {Deep reinforcement learning for computation offloading in mobile edge computing environment},
  volume       = {175},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A novel adaptive density-based spatial clustering of
application with noise based on bird swarm optimization algorithm.
<em>COMCOM</em>, <em>174</em>, 205–214. (<a
href="https://doi.org/10.1016/j.comcom.2021.03.021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The commonly used density-based spatial clustering method (DBSCAN) connects contiguous regions with sufficiently large densities when processing datasets to efficiently discover clusters of different shapes and densities and outliers. However, the algorithm has the problem that radius of neighborhood ( Eps ) argument requires to be selected manually. For datasets with higher dimensionality and larger data volume, the selection of Eps parameters can be difficult thus leading to poor clustering quality . To solve the above problem, we propose a novel adaptive density-based spatial clustering of application with noise based on bird swarm optimization algorithm (BSA-DBSCAN). We use the global search capability of the bird swarm method to select the best Eps parameter neighborhood values. We can avoid manual intervention and realize adaptive parameter optimization in the clustering process . To further explore the clustering performance of BSA-DBSCAN method, we test the synthetic datasets and the real-world datasets respectively and perform images analysis on the clustering evaluation index values. The simulation experiments show that the improved method in this paper can reasonably search the Eps parameter value and can obtain the higher accuracy of clustering.},
  archive      = {J_COMCOM},
  author       = {Limin Wang and Honghuan Wang and Xuming Han and Wei Zhou},
  doi          = {10.1016/j.comcom.2021.03.021},
  journal      = {Computer Communications},
  pages        = {205-214},
  shortjournal = {Comput. Commun.},
  title        = {A novel adaptive density-based spatial clustering of application with noise based on bird swarm optimization algorithm},
  volume       = {174},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Ontology knowledge base combined with bayesian networks for
integrated corridor risk warning. <em>COMCOM</em>, <em>174</em>,
190–204. (<a
href="https://doi.org/10.1016/j.comcom.2021.04.024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the accelerated urbanization process, the emergence of urban underground integrated pipeline corridors is the trend for cities, especially large and medium-sized cities. However, due to the complexity of the internal system of the integrated corridor, there are various risks in the process of its construction and operation and maintenance , and the risk factors are complex and diverse. In this paper, we introduce ontology technology and knowledge base construction into the risk management of integrated pipeline corridor, build an ontology-based knowledge base of integrated pipeline corridor risk, and construct a Bayesian network based on the established risk knowledge base for risk evaluation of identified risk factors. The combination of ontology knowledge base construction and Bayesian network method of integrated pipeline corridor risk makes the risk identification system completer and more effective, and the method can effectively evaluate the disaster risk level of integrated pipeline corridor operation and maintenance , which can meet the practical needs of integrated pipeline corridor operation and maintenance risk management and disaster prevention and mitigation work.},
  archive      = {J_COMCOM},
  author       = {Nan Hai and Daqing Gong and Shifeng Liu},
  doi          = {10.1016/j.comcom.2021.04.024},
  journal      = {Computer Communications},
  pages        = {190-204},
  shortjournal = {Comput. Commun.},
  title        = {Ontology knowledge base combined with bayesian networks for integrated corridor risk warning},
  volume       = {174},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Developing an asynchronous NoAck-based full-duplex MAC for
IEEE 802.11 networks in a systems approach. <em>COMCOM</em>,
<em>174</em>, 172–189. (<a
href="https://doi.org/10.1016/j.comcom.2021.04.018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many studies have introduced full-duplex (FD) medium access controls (MAC) in wireless networks that realize the physical FD capability of the latest devices. However, practical experiences with 802.11 wireless LANs (WLANs) have not yet been addressed. This study proposes a novel FD MAC that extends the IEEE 802.11 based on no acknowledgment (NoAck) data transmission. Because ACK is not needed after data transmission, the MAC can be purely asynchronous; there is neither overhead required for synchronizing transmission, such as request-to-send/clear-to-send (RTS/CTS) handshaking, nor wasted time even in asymmetric traffic. The proposed MAC also provides access point (AP) initiated uni-directional full-duplex (AP-initiated UFD) transmission, which has mostly not been supported in practice, by extending the carrier sense condition. An approximated collision avoidance method is also introduced, where a CTS frame without a preceding RTS is transmitted by AP using FD capability to protect the frame being received. A prototype of the proposed MAC is implemented in ns-3 network simulator , and extensive simulation experiments are conducted in various test setups to validate the correct MAC behaviors, performance improvement, and fairness. The results show that performance improvements, more than twice as high under favorable conditions, are possible while maintaining interoperability with legacy devices.},
  archive      = {J_COMCOM},
  author       = {Chang Yun Park},
  doi          = {10.1016/j.comcom.2021.04.018},
  journal      = {Computer Communications},
  pages        = {172-189},
  shortjournal = {Comput. Commun.},
  title        = {Developing an asynchronous NoAck-based full-duplex MAC for IEEE 802.11 networks in a systems approach},
  volume       = {174},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Adversarial attacks on a lexical sentiment analysis
classifier. <em>COMCOM</em>, <em>174</em>, 154–171. (<a
href="https://doi.org/10.1016/j.comcom.2021.04.026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Social media has become a relevant information source for several decision-making processes and for the definition of business strategies. As various sentiment analysis techniques are used to transform collected data into intelligence information, the sentiment classifiers used in these collection environments must be carefully studied and observed before being considered trustful and ready to be installed in decision support systems. An important research area concerns the robustness of sentiment classifiers in view of new adversarial attacks , in which small perturbations may be created by malicious users to deceive the sentiment classifiers, generating a perception different from the one that should be observed in the environment. Thus, it is important to identify and analyze the vulnerabilities of these classifiers under different strategies of adversarial attacks to propose countermeasures that can be used to mitigate such attacks. In this context, this work presents adversarial attacks related to a lexical natural language classifier. Being the target of the attacks, this classifier is used to calculate the sentiment of collected data as posted by users in various social media applications . The results indicate that the found vulnerabilities, if exploited by malicious users in applications that use the same lexical classifier, could invert or cancel the classifiers’ perception, thus generating perceptions that do not correspond to the reality for decision making. This work also proposes some countermeasures that might mitigate the implemented attacks.},
  archive      = {J_COMCOM},
  author       = {Gildásio Antonio de Oliveira Júnior and Rafael Timóteo de Sousa Jr. and Robson de Oliveira Albuquerque and Luis Javier García Villalba},
  doi          = {10.1016/j.comcom.2021.04.026},
  journal      = {Computer Communications},
  pages        = {154-171},
  shortjournal = {Comput. Commun.},
  title        = {Adversarial attacks on a lexical sentiment analysis classifier},
  volume       = {174},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). DEQLFER — a deep extreme q-learning firefly energy efficient
and high performance routing protocol for underwater communication.
<em>COMCOM</em>, <em>174</em>, 143–153. (<a
href="https://doi.org/10.1016/j.comcom.2021.04.030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With an advent of Underwater sensor networks, underwater communication has reached its new dimension of research. These networks are characterized by the elongated end to end delay , high energy utility and most importantly dynamic network topologies . By incorporating these characteristics, numerous automated routing algorithms has been proposed to achieve the energy efficient and low latency data transmission. But still, short-comings still exists due to the above mentioned characteristics and the most comprehensive routing algorithms are badly desired. In this article, a novel routing scheme based on Q-learning framework and Deep Extreme Learning Machines aided with Adaptive Firefly Routing algorithm to address the above mentioned research constraints including energy efficiency and network unsteadiness in underwater communication , that practices the hybrid combination of reward function and adaptive fireflies to determine the optimal routing mechanism. In this algorithm, traditional q-learning mechanism has been replaced by the powerful q-deep extreme learning mechanism which uses the adaptive reward function for the varying underwater environment and to boost the packet-delivery ratio (PDR) and throughputs. Also the paper uses the powerful firefly aided routing mechanism to achieve the energy efficient data transmission and to avoid the void dilemma problems. The extensive experimentations has been conducted on the proposed algorithm and compared with other state of art schemes such as Q deep q-Learning energy aware routing protocol (DQLER), DELR Protocols and VBF protocols in which the proposed algorithm has outperformed than the compared existing algorithms in terms of complexity, energy consumption , packet delivery ratio and end to end delay .},
  archive      = {J_COMCOM},
  author       = {D. Anitha and R.A. Karthika},
  doi          = {10.1016/j.comcom.2021.04.030},
  journal      = {Computer Communications},
  pages        = {143-153},
  shortjournal = {Comput. Commun.},
  title        = {DEQLFER — a deep extreme Q-learning firefly energy efficient and high performance routing protocol for underwater communication},
  volume       = {174},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A secure road condition monitoring scheme in cloud based
VANET. <em>COMCOM</em>, <em>174</em>, 131–142. (<a
href="https://doi.org/10.1016/j.comcom.2021.04.027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Connected vehicular cloud computing (CVCC) is a promising technology that integrates cloud computing and vehicular ad-hoc network (VANET) for road condition monitoring tasks. However, maintaining security and privacy is crucial for wide deployment of such framework. Existing researches fail to address critical security flaws in CVCC scenario. This paper performs cryptanalysis on the CVCC based road condition monitoring scheme recently proposed by Wang et al. (2019). The scheme fails to achieve anonymity, unlinkability and nonrepudiation . Moreover, honest but curious RSUs may collude with each other to learn sensitive information , such as vehicle user’s trajectory. Also, an attacker can induce forged emergency case into the system through replay attack. Furthermore, in the scheme, the cloud server cannot segregate a threshold number of current reports, from a threshold number of combination of old and current reports. Along with this cryptanalysis , this paper proposes a secure road condition monitoring scheme in cloud based VANET, addressing the critical issues identified in the existing works. The security of the proposed scheme has been thoroughly evaluated using an adversary model , BAN Logic and AVISPA tool. Moreover, the performance of the proposed scheme is analyzed and compared with the existing schemes in terms of security and computation overhead.},
  archive      = {J_COMCOM},
  author       = {Barnana Baruah and Subhasish Dhal},
  doi          = {10.1016/j.comcom.2021.04.027},
  journal      = {Computer Communications},
  pages        = {131-142},
  shortjournal = {Comput. Commun.},
  title        = {A secure road condition monitoring scheme in cloud based VANET},
  volume       = {174},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Social media privacy management strategies: A SEM analysis
of user privacy behaviors. <em>COMCOM</em>, <em>174</em>, 122–130. (<a
href="https://doi.org/10.1016/j.comcom.2021.04.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial intelligence (AI) is widely used in social network as AD Recommender Systems , Viral Marketing, and User Sentiment Detection. However, such things as Fake News and Privacy Leaking may violate privacy and security concerns. AI technology is also often used in social media as the main technology to prevent personal privacy from leaking. This study explored whether social media users will disclose information or further protect privacy when facing information privacy issues. It studied information security awareness and perceived privacy control while affecting privacy concerns and customer calibration related factors, and finds their privacy management and self-disclosure. This study used questionnaire survey method to understand user data and used Structural Equation Modeling (SEM) to analyze the relationship of various dimensions. The results showed that understanding information security awareness and customer alienation through AI technology has a positive impact on consumers’ privacy concerns. Through privacy management, consumers can indeed reduce their doubts about privacy leakage . Customer privacy concerns and customer calibration have positive and significant effects on privacy management and self-disclosure, respectively. This study showed that user trust in the platform will affect the degree of user information disclosure . The industry should focus more on the user’s privacy maintenance and establish a complete protection mechanism.},
  archive      = {J_COMCOM},
  author       = {Kuo-Cheng Chung and Chun-Hung Chen and Hsueh-Hsuan Tsai and Ya-Hsueh Chuang},
  doi          = {10.1016/j.comcom.2021.04.012},
  journal      = {Computer Communications},
  pages        = {122-130},
  shortjournal = {Comput. Commun.},
  title        = {Social media privacy management strategies: A SEM analysis of user privacy behaviors},
  volume       = {174},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Countering radiometric signature exploitation using
adversarial machine learning based protocol switching. <em>COMCOM</em>,
<em>174</em>, 109–121. (<a
href="https://doi.org/10.1016/j.comcom.2021.04.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A Radiometric signature refers to transceiver specific features that are caused by variations in the manufacturing process even for the same circuit design. While such a radiometric signature constitutes a fingerprint that can be exploited for device authentication , it is a threat to privacy. Particularly, in the realm of wireless networks, an adversary may exploit radio frequency (RF) fingerprinting to identify devices and conduct traffic analysis in order to uncover the topology and categorize the role of various nodes. In this paper, we show how an adversary could employ RF fingerprinting to distinguish among nodes and bypass the provisioned anonymity protection in the network. We analyze the accuracy of RF fingerprinting and highlight how the accuracy affects the success of adversary attacks. To counter such a threat, we propose a novel methodology that requires no hardware changes to the radio transceiver and the associated host device. Our methodology is based on coordinated switching among preset link-layer and physical-layer communication protocols. For the latter, we particularly exploit distributed beamforming . We employ adversarial machine learning to select the protocol configuration for each transmission so that the accuracy of the RF fingerprinting diminishes. We demonstrate the effectiveness of our scheme through simulation and prototype experiments.},
  archive      = {J_COMCOM},
  author       = {Wassila Lalouani and Mohamed Younis and Uthman Baroudi},
  doi          = {10.1016/j.comcom.2021.04.007},
  journal      = {Computer Communications},
  pages        = {109-121},
  shortjournal = {Comput. Commun.},
  title        = {Countering radiometric signature exploitation using adversarial machine learning based protocol switching},
  volume       = {174},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Marginal and average weight-enabled data aggregation
mechanism for the resource-constrained networks. <em>COMCOM</em>,
<em>174</em>, 101–108. (<a
href="https://doi.org/10.1016/j.comcom.2021.04.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In Wireless Sensor Networks (WSNs), data redundancy is a challenging issue that not only introduces network congestion but also consumes a considerable amount of sensor node resources. Data redundancy occurs due to the spatial and temporal correlation among the data gathered by the neighboring nodes. Data aggregation is a prominent technique that performs in-network filtering of the redundant data and accelerates the knowledge extraction by eliminating the correlated data . However, most of the data aggregation techniques have lower accuracy as they do not cater for erroneous data from faulty nodes and pose an open research challenge. To address this challenge, we have proposed a novel, lightweight, and energy-efficient function-based data aggregation approach for a cluster-based hierarchical WSN. Our proposed approach works at two levels, i.e., at the node level and at the cluster head level. At the node level, the data aggregation is performed using Exponential Moving Average (EMA) and a threshold-based mechanism is adopted to detect any outliers for improving the accuracy of aggregated data. At the cluster head level, we have employed a modified version of Euclidean distance function to provide highly-refined aggregated data to the base station . Our experimental results show that our approach reduces the communication cost, transmission cost, energy consumption at the nodes and cluster heads, and delivers highly-refined and fused data to the base station .},
  archive      = {J_COMCOM},
  author       = {Syed Roohullah Jan and Rahim Khan and Fazlullah Khan and Mian Ahmad Jan and Mohamamd Dahman Alshehri and Venki Balasubramaniam and Paramjit S. Sehdev},
  doi          = {10.1016/j.comcom.2021.04.004},
  journal      = {Computer Communications},
  pages        = {101-108},
  shortjournal = {Comput. Commun.},
  title        = {Marginal and average weight-enabled data aggregation mechanism for the resource-constrained networks},
  volume       = {174},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Internet connected vehicle platoon system modeling and
linear stability analysis. <em>COMCOM</em>, <em>174</em>, 92–100. (<a
href="https://doi.org/10.1016/j.comcom.2021.04.015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The fast development of communication technique builds an era of Internet of Everything. In the automobile world, Internet-Connected Vehicle (CV), also called IntelliDrive, will accelerate the autonomous driving era’s coming. And the traffic flow theory will undergo major changes as CV platoon becomes common way for our travel. As we know that the CV has different driving decision mechanisms from human-driven vehicles, such as an CV can receive more information and make much faster decision than a human-driven vehicle. Only if we fully understand the autonomous traffic flow’s characteristics, then we can improve the level of traffic engineering study and management in the future. On the thought of building autonomous traffic flow theory, we present CV platoon car-following model as the theoretical microscopic traffic flow model. The model is described by a mathematical differential-difference equation, which has a synthesized optimal velocity differential function and a full platoon with weighted relative velocity difference function. There are three main factors in the model, which are the optimal velocity difference impact factor p p and action related vehicle number l l , and weighted velocity difference sum coefficient λ λ . The model reflects the effects of front interactions between every two adjacent CV instead of the weighted average headway in the platoon. We deduce the model’s stability conditions with linear system stability theory and do some computer numerical simulations to verify our suppositions. Simulation results show that the more information broadcasting among CV, the more stable of the traffic flow system is. At last, we discuss our study’s contributions from the viewpoint of theoretical and practical value, and point out future research directions. In a word, the highlight of the paper is that we find the CV platoon system’s running mechanism by building an CV platoon car-following model under connected environment and give its linear stability condition, which is great value for advanced traffic management in autonomous driving era.},
  archive      = {J_COMCOM},
  author       = {Lidong Zhang and Mengmeng Zhang and Jian Wang and Xiaowei Li and Wenxing Zhu},
  doi          = {10.1016/j.comcom.2021.04.015},
  journal      = {Computer Communications},
  pages        = {92-100},
  shortjournal = {Comput. Commun.},
  title        = {Internet connected vehicle platoon system modeling and linear stability analysis},
  volume       = {174},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-criteria handover mobility management in 5G cellular
network. <em>COMCOM</em>, <em>174</em>, 81–91. (<a
href="https://doi.org/10.1016/j.comcom.2021.04.020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To fulfill the future demand and expansion of the coverage of the network, ultra-dense deployment of small cell (SC) is an optimal solution for future 5G networks , which will ensure the UEs (User Equipment) continuous connectivity. However, these small cells (SCs) lead to the issue of interference, additional unnecessary handover (HO), signaling overhead, and which in turn decreases the overall quality of service (QoS) of the users. In this paper, an intelligent mobility management system based on Enhanced Multi-Objective Optimization Method by Ratio Analysis (E-MOORA) and Q-learning approach is introduced for handover optimization. E-MOORA method is the combination of modified entropy weighting technique and Multi-Objective Optimization Method by Ratio Analysis (MOORA) which introduces vector normalization. The proposed E-MOORA method judicially exploits the performance parameters and thus reduces ranking abnormality when it selects a HO target cell. Q-learning approach is applied to select the optimal triggering points to minimize the effect of frequent unnecessary handovers for satisfying user QoS requirements. The performance analysis results depict significant performance improvement in terms of minimizing the unnecessary HO, radio link failure, and user throughput compared to other existing Multi-Criteria Decision Making (MCDM) methods.},
  archive      = {J_COMCOM},
  author       = {Md. Rajibul Palas and Md. Rakibul Islam and Palash Roy and Md. Abdur Razzaque and Ahmad Alsanad and Salman A. AlQahtani and Mohammad Mehedi Hassan},
  doi          = {10.1016/j.comcom.2021.04.020},
  journal      = {Computer Communications},
  pages        = {81-91},
  shortjournal = {Comput. Commun.},
  title        = {Multi-criteria handover mobility management in 5G cellular network},
  volume       = {174},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Quality evaluation of lightweight realistic 3D model based
on BIM forward design. <em>COMCOM</em>, <em>174</em>, 75–80. (<a
href="https://doi.org/10.1016/j.comcom.2021.04.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we assess the lightweight efficiency of the realistic 3D model data through comparative tests by introducing the realistic three-dimensional model into building information modeling (BIM) design. To meet the varied needs of engineering design in the construction field at different stages, a quality evaluation method for the lightweight realistic 3D model is proposed, with the texture quality and plane positioning accuracy of the model taken into account. The results show that the best lightweight coefficient of realistic 3D model data in film box (FBX) format is 40\%. Under a lightweight coefficient at 40\%, the amount of model data is reduced by 25\%, with only small holes incurred in the texture, and the atness error is ± 9 mm. After lightweight processing, the model meets the requirements of BIM designers for vision and plane positioning accuracy. By putting forward a data lightweight processing standard and a model evaluation method based on the idea of BIM design, we aimed to solve the challenges in applying realistic 3D models to BIM design due to the large amounts of data, thereby to lay a foundation for wider application of realistic 3D models to BIM design.},
  archive      = {J_COMCOM},
  author       = {Jiao Chen and Yongquan Luo and Hongfei Zhang and Weibing Du},
  doi          = {10.1016/j.comcom.2021.04.017},
  journal      = {Computer Communications},
  pages        = {75-80},
  shortjournal = {Comput. Commun.},
  title        = {Quality evaluation of lightweight realistic 3D model based on BIM forward design},
  volume       = {174},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An ensemble approach for optimization of penetration layout
in wide area networks. <em>COMCOM</em>, <em>174</em>, 61–74. (<a
href="https://doi.org/10.1016/j.comcom.2021.04.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The complexity of IoT based networks and an exponential increase in new vulnerabilities has increased the demand for security assessment strategies manifold. Attack graphs or Penetration layouts play a paramount role to harden and analyze such complex networks. As the size of the network grows, administrators may find it difficult to comprehend penetration layout. In this article, we present a methodology to bridge the gap between large networks and penetration layouts leading to a strategy that automatically generates, optimizes, and improves visualization of penetration layout in large networks. More specifically, we take the network model as input to the designed simulator which analyzes the network and generates the penetration layout. Additionally, we have designed an algorithm to optimize the size of the penetration layout at various levels. This will also improve the visualization of the graph. We designed a simulator that uses a real-time network blueprint to visualize and analyze the effect and performance of the proposed approach. The results show that there is a lossless reduction in the size of penetration layout by 99.95\% for the example real-time network.},
  archive      = {J_COMCOM},
  author       = {Urvashi Garg and Geeta Sikka and Lalit K. Awasthi},
  doi          = {10.1016/j.comcom.2021.04.009},
  journal      = {Computer Communications},
  pages        = {61-74},
  shortjournal = {Comput. Commun.},
  title        = {An ensemble approach for optimization of penetration layout in wide area networks},
  volume       = {174},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A multi-stage graph based algorithm for survivable service
function chain orchestration with backup resource sharing.
<em>COMCOM</em>, <em>174</em>, 42–60. (<a
href="https://doi.org/10.1016/j.comcom.2021.04.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Network softwarisation introduces flexibility in network management by enabling the deployment of network functions as software modules running on virtual machines. However, this creates new concerns for service availability and reliability due to multiple sources of failures at both software and hardware levels, potentially resulting in service degradations and penalties due to Service Level Agreement (SLA) violations. The survivability of critical services can best be guaranteed by pro-actively provisioning dedicated backup resources for these services, but at the cost of a high resource consumption. Aware of the divergent requirements of future services, a promising alternative is envisaged, allowing non-critical users to use the unused backup resources of high priority users. However, this approach poses a stringent challenge if a critical service disruption occurs, requiring the computation of a traffic rerouting solution for the non-critical requests when preempted from their borrowed resources. In this paper we first propose a generic multi-stage graph based algorithm as an alternative algorithm for Service Function Chain (SFC) deployments. Simulation results demonstrate that the proposed algorithm is optimized in terms of resource utilization, resulting in a 10\% improvement in terms of acceptance ratio compared to a given state of the art algorithm, and within a 4\% margin of the optimal solution. Based on the mentioned algorithm, we propose a new migration-aware algorithm for the mapping of non-critical services, enabling the non-critical services to borrow the unused backup resources from the critical services while minimizing the probability of preemption they could experience. The migration-aware algorithm results in more than an 8\% resource saving, in most scenarios, compared to a dedicated backup strategy, and more than a 70\% performance improvement in terms of the number of service preemptions, compared to a cost based algorithm. Additionally, whenever low priority users are preempted from their borrowed resources, we propose a new QoS-aware global-rerouting algorithm for remapping those users, reducing the impact of the service interruption thanks to avoiding the migration of surviving VNFs and virtual links when feasible. The proposed algorithm is shown to outperform a service restoration strategy based on local rerouting, in terms of successful service restoration and resource consumption.},
  archive      = {J_COMCOM},
  author       = {Godfrey Kibalya and Joan Serrat and Juan-Luis Gorricho and Jonathan Serugunda and Peiying Zhang},
  doi          = {10.1016/j.comcom.2021.04.008},
  journal      = {Computer Communications},
  pages        = {42-60},
  shortjournal = {Comput. Commun.},
  title        = {A multi-stage graph based algorithm for survivable service function chain orchestration with backup resource sharing},
  volume       = {174},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Detection of collaborative misbehaviour in distributed
cyber-attacks. <em>COMCOM</em>, <em>174</em>, 28–41. (<a
href="https://doi.org/10.1016/j.comcom.2021.04.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we consider the detection of suspiciously high correlation between malicious Internet users that are collaborating in order to cause a Distributed Denial of Service (DDoS) attack. The main goal is to obtain a method for judging correlated misbehaviour among the requests that are issued by different users, aiming to recognize early enough any abnormal behaviour and avoid the full consequences of the DDoS attack. The identification is based on the frequencies with which users issue (simultaneous) requests and is accomplished through the analysis of the data traffic using the requests for connection across the concerned network over a period of time. The paper models normal and malicious behaviour via hidden Markov models, and analyses the performance of the proposed detection method using both mathematical reasoning and simulations. Evaluations of the proposed method on real data sets and comparisons of its performance against existing related methodologies are also provided.},
  archive      = {J_COMCOM},
  author       = {Marios Thoma and Christoforos N. Hadjicostis},
  doi          = {10.1016/j.comcom.2021.04.013},
  journal      = {Computer Communications},
  pages        = {28-41},
  shortjournal = {Comput. Commun.},
  title        = {Detection of collaborative misbehaviour in distributed cyber-attacks},
  volume       = {174},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Quantifying the millimeter wave new radio base stations
density for network slicing with prescribed SLAs. <em>COMCOM</em>,
<em>174</em>, 13–27. (<a
href="https://doi.org/10.1016/j.comcom.2021.04.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Network slicing is expected to become an integral part of future 5G systems providing a simple mechanism for physical network operators to diversify their business models. New Radio (NR) technology operating in millimeter wave (mmWave) band is one of the critical bearers for this functionality, providing extraordinary capacity at the air interface. This paper provides a mathematical tool for assessing the upper and lower bounds of NR BS density needed to maintain the requested slice rate guarantees. The upper bound corresponds to the full traffic isolation between slices while the lower one — to the full mixing of traffic from the slices. To this aim, we unite the tools of stochastic geometry and queuing theory formulating a performance evaluation framework that allows assessing the rate violation metrics in a dynamic network slicing environment. The developed framework captures specifics of mmWave NR technology, including antenna directivity at the UE and NR BS sides, propagation and blockage losses, as well as the service process with location-dependent resource requirements. Our results show that for considered schemes, the operational regime of the system changes abruptly with respect to the density of NR BSs. The difference between full isolation and full mixing schemes becomes bigger in environments with high session arrival intensities that naturally require dense deployments. Thus, at the initial market penetration phase, full isolation can be used without compromising the network performance. However, at mature stages, more complex schemes are needed to reduce the capital expenditures of the operators.},
  archive      = {J_COMCOM},
  author       = {Yevgeni Koucheryavy and Ekaterina Lisovskaya and Dmitri Moltchanov and Roman Kovalchukov and Andrey Samuylov},
  doi          = {10.1016/j.comcom.2021.04.010},
  journal      = {Computer Communications},
  pages        = {13-27},
  shortjournal = {Comput. Commun.},
  title        = {Quantifying the millimeter wave new radio base stations density for network slicing with prescribed SLAs},
  volume       = {174},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). HBRSS: Providing high-secure data communication and
manipulation in insecure cloud environments. <em>COMCOM</em>,
<em>174</em>, 1–12. (<a
href="https://doi.org/10.1016/j.comcom.2021.03.018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cloud storage and cloud services provide a stronger computing power and distributed computing capability for IoT users with a minimal cost. However, the security issues of cloud always limit the development of cloud computing and storage. In the meanwhile, the channel instability and exposure of the public network make the security of data in transmission challenged (HTTPS protocol cannot guarantee the security of data after receiving by servers). Even if homomorphic encryption can protect IoTs’ sensitive data, attackers still can infer sensitive behaviors about users by listening to the frequency of cloud services usage. To solve the above problems, in this paper, we propose a novel data transmission structure named HBRSS for high-security data transmission and data processing in insecure cloud environments and channels. HBRSS harnesses proposed data splitting principle to divide the data into blocks, packages the block data and forms a block ring based on the concept of blockchain to ensure the non-tamperability and non-destructibility of data. In addition, we propose an improved partial homomorphic encryption algorithm, which adds fuzzy processing for the data service functions to improve function-privacy. We also build a virtual mistrusted cloud service scene by using Docker and Kubernetes to evaluate our method’s performance, which can also be utilized as a standard attack drill platform for all researchers to test their own security algorithms. Based on our best knowledge, this platform is the first open-source automatic cloud attack exploitation system that contains attacks against browsers, channels, and servers. The experimental results indicate that our new encryption algorithm brings larger key-space and lower power consumption compared with some encryption algorithms.},
  archive      = {J_COMCOM},
  author       = {Hui Xie and Zhengyuan Zhang and Qi Zhang and Shengjun Wei and Changzhen Hu},
  doi          = {10.1016/j.comcom.2021.03.018},
  journal      = {Computer Communications},
  pages        = {1-12},
  shortjournal = {Comput. Commun.},
  title        = {HBRSS: Providing high-secure data communication and manipulation in insecure cloud environments},
  volume       = {174},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-layer and multi-order fine-grained feature learning
for artwork attribute recognition. <em>COMCOM</em>, <em>173</em>,
214–219. (<a
href="https://doi.org/10.1016/j.comcom.2021.03.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the digital development of artwork, more and more artwork images are made available to the public. In iMet Collection Dataset which is part of the FGVC6 workshop at CVPR 2019, an artwork image is annotated by multiple labels. Because of the local and subtle differences between artwork images with different attribute labels, artwork attribute recognition can be considered as a fine-grained visual categorization (FGVC) task. In this paper, a multi-layer and multi-order network (MLMO-Net) is proposed to capture both first- and second-order information in the artwork images. First-order information can be used to characterize the global spatial information and second-order information can be used to characterize the local statistical information. Both of first- and second-order information from multiple layers are aggregated together in MLMO-Net. In our experiments, several convolutional neural network (CNN) architectures, such as Vgg16 and ResNet50, and recent FGVC methods, such as the bilinear CNN, hierarchical bilinear CNN, and Navigator–teacher–scrutinizer network (NTS-Net), are tested on the iMet Collection 2019 Dataset. Experimental results shown that MLMO-Net achieves improvements over baseline methods . Through the research of this paper, a direction to improve the performance of artwork attribute recognition could be provided.},
  archive      = {J_COMCOM},
  author       = {Yang Gao and Neng Chang and Kai Shang},
  doi          = {10.1016/j.comcom.2021.03.006},
  journal      = {Computer Communications},
  pages        = {214-219},
  shortjournal = {Comput. Commun.},
  title        = {Multi-layer and multi-order fine-grained feature learning for artwork attribute recognition},
  volume       = {173},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Attack sample generation algorithm based on data association
group by GAN in industrial control dataset. <em>COMCOM</em>,
<em>173</em>, 206–213. (<a
href="https://doi.org/10.1016/j.comcom.2021.04.014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The importance of industrial control networks security is growing, but the intrusion detection research of industrial control networks is seriously restricted by the existing attack samples of the business dataset, especially the quantity and quality. In order to solve the problem of the scarcity of attack industrial control datasets, this paper proposes an attack sample generation algorithm. Firstly, based on the weight and degree of membership distribution, calculate the value of membership distance between dimensions, and the data association is strong when the membership distance of dimensions is small. Then, divide dimensions which have small distance into a group, so as to realize the association grouping of the original data. The data association of dimensions in an association group is strong when the association group appears frequently. According to the frequency of the association group, all the association groups are divided into strong association group and weak association group. Attack all the dimensions of one strong association group in the original data by false data injection attack , realized attack sample generation algorithm in the original data. Finally, expand the attack sample into a large amount of attack sample industrial control dataset by the Generative Adversarial Network . In this paper, the attack samples are generated by the BATADAL dataset and the business dataset of an oil depot, and the data is expanded by 100 times through the algorithm. Compared with the attack samples provided by the BATADAL dataset, the coincidence degree and fitting degree of generated data is improved by 38.20\%–42.94\% and 98.22\%–98.36\%, respectively. The classification results of XGBoost and SVM are 100\% and 98.01\%, which is close to the classification result of attack samples provided by BATADAL dataset.},
  archive      = {J_COMCOM},
  author       = {Wen Zhou and Xiang-min Kong and Kai-li Li and Xiao-ming Li and Lin-lin Ren and Yong Yan and Yun Sha and Xue-ying Cao and Xue-jun Liu},
  doi          = {10.1016/j.comcom.2021.04.014},
  journal      = {Computer Communications},
  pages        = {206-213},
  shortjournal = {Comput. Commun.},
  title        = {Attack sample generation algorithm based on data association group by GAN in industrial control dataset},
  volume       = {173},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). PPaaS: Privacy preservation as a service. <em>COMCOM</em>,
<em>173</em>, 192–205. (<a
href="https://doi.org/10.1016/j.comcom.2021.04.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Personally identifiable information (PII) can find its way into cyberspace through various channels, and many potential sources can leak such information. Data sharing (e.g. cross-agency data sharing) for machine learning and analytics is one of the important components in data science. However, due to privacy concerns, data should be enforced with strong privacy guarantees before sharing. Different privacy-preserving approaches were developed for privacy preserving data sharing; however, identifying the best privacy-preservation approach for the privacy-preservation of a certain dataset is still a challenge. Different parameters can influence the efficacy of the process, such as the characteristics of the input dataset, the strength of the privacy-preservation approach, and the expected level of utility of the resulting dataset (on the corresponding data mining application such as classification). This paper presents a framework named P rivacy P reservation a s a S ervice (PPaaS) to reduce this complexity. The proposed method employs selective privacy preservation via data perturbation and looks at different dynamics that can influence the quality of the privacy preservation of a dataset. PPaaS includes pools of data perturbation methods, and for each application and the input dataset, PPaaS selects the most suitable data perturbation approach after rigorous evaluation. It enhances the usability of privacy-preserving methods within its pool; it is a generic platform that can be used to sanitize big data in a granular, application-specific manner by employing a suitable combination of diverse privacy-preserving algorithms to provide a proper balance between privacy and utility.},
  archive      = {J_COMCOM},
  author       = {M.A.P. Chamikara and P. Bertok and I. Khalil and D. Liu and S. Camtepe},
  doi          = {10.1016/j.comcom.2021.04.006},
  journal      = {Computer Communications},
  pages        = {192-205},
  shortjournal = {Comput. Commun.},
  title        = {PPaaS: Privacy preservation as a service},
  volume       = {173},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A cooperative resource allocation model for IoT applications
in mobile edge computing. <em>COMCOM</em>, <em>173</em>, 183–191. (<a
href="https://doi.org/10.1016/j.comcom.2021.04.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the advancement in the development of the Internet of Things (IoT) technology, as well as the industrial IoT, various applications and services are benefiting from this emerging technology such as smart healthcare systems, virtual realities applications , connected and autonomous vehicles, to name a few. However, IoT devices are known for being limited computation capacities which is crucial to the device’s availability time. Traditional approaches used to offload the applications to the cloud to ease the burden on the end user’s devices, however, greater latency and network traffic issues still persist. Mobile Edge Computing (MEC) technology has emerged to address these issues and enhance the survivability of cloud infrastructure. While a lot of attempts have been made to manage an efficient process of applications offload , many of which either focus on the allocation of computational or communication protocols without considering a cooperative solution. In addition, a single-user scenario was considered. Therefore, we study multi-user IoT applications offloading for a MEC system, which cooperatively considers to allocate both the resources of computation and communication. The proposed system focuses on minimizing the weighted overhead of local IoT devices, and minimize the offload measured by the delay and energy consumption. The mathematical formulation is a typical mixed integer nonlinear programming (MINP), and this is an NP-hard problem. We obtain the solution to the objective function by splitting the objective problem into three sub-problems. Extensive set of evaluations have been performed so as to get the evaluation of the proposed model. The collected results indicate that offloading decisions, energy consumption, latency, and the impact of the number of IoT devices have shown superior improvement over traditional models.},
  archive      = {J_COMCOM},
  author       = {Xianwei Li and Liang Zhao and Keping Yu and Moayad Aloqaily and Yaser Jararweh},
  doi          = {10.1016/j.comcom.2021.04.005},
  journal      = {Computer Communications},
  pages        = {183-191},
  shortjournal = {Comput. Commun.},
  title        = {A cooperative resource allocation model for IoT applications in mobile edge computing},
  volume       = {173},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Linking handover delay to load balancing in SDN-based
heterogeneous networks. <em>COMCOM</em>, <em>173</em>, 170–182. (<a
href="https://doi.org/10.1016/j.comcom.2021.04.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Software-Defined Networking (SDN) paradigm provides the ability to handle mobility more efficiently due to its programmability and fine granularity . However, in this emerging setting, the handover procedure still suffers delay due to exchanging and processing handover signaling messages. In this paper, we study the relevancy between an SDN controller’s load and handover delay. We show that an over-loading state can prolong handover delay, so as a countermeasure , reaching that state is mitigated by applying a load balancing mechanism. Our primary metric is the controller’s response time, as it directly affects the completion of any mobility-related procedure. We propose a load balancing management framework that deploys two concepts: network heterogeneity and context-aware vertical mobility . Our proposal is composed of three main aspects. First, we identify candidate users based on their context information. Second, we reduce the frequency of load dissemination between multiple controllers , and hence, reducing processing and communication overhead . Third, after the candidate users are determined, we optimize the decision problem on the selection among heterogeneous candidate networks. Through simulation, our framework has shown as much drop as a 28\% drop in response time compared to previous proposals.},
  archive      = {J_COMCOM},
  author       = {Modhawi Alotaibi and Amiya Nayak},
  doi          = {10.1016/j.comcom.2021.04.001},
  journal      = {Computer Communications},
  pages        = {170-182},
  shortjournal = {Comput. Commun.},
  title        = {Linking handover delay to load balancing in SDN-based heterogeneous networks},
  volume       = {173},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-feature fusion for fault diagnosis of rotating
machinery based on convolutional neural network. <em>COMCOM</em>,
<em>173</em>, 160–169. (<a
href="https://doi.org/10.1016/j.comcom.2021.04.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The fast and efficient fault diagnosis is the key to guarantee uninterrupted working of facilities, which is more frugal and trustworthy than scheduled upkeep. At present, data acquisition and fault diagnosis based on a variety of sensors have become an indispensable means for manufacturing enterprises. However, through the independent analysis of all kinds of sensor data, the traditional analysis method fails to make full use of the interrelationship between data sources. A new feature fusion approach that is based on Convolutional Neural Network (CNN) is put forward in this study for rotating machinery fault diagnosis. For multi-source data, some data sources are extracted with empirical features and others are extracted with hidden features. CNN is adopted to obtain the recessive features of complex signal waveform , such as acceleration, displacement, etc. The fusion of statistical features and recessive features is a new set of features and is input into Light Gradient Boosting Machine (LightGBM) model. The stator and rotor fault experiment is designed and implemented to verify the advantages of the proposed method. Compared with the traditional approaches, this method is 3\% more accurate or at least 4 times faster than the traditional method under the same conditions.},
  archive      = {J_COMCOM},
  author       = {Shaoqing Liu and Zhenshan Ji and Yong Wang and Zuchao Zhang and Zhanghou Xu and Chaohao Kan and Ke Jin},
  doi          = {10.1016/j.comcom.2021.04.016},
  journal      = {Computer Communications},
  pages        = {160-169},
  shortjournal = {Comput. Commun.},
  title        = {Multi-feature fusion for fault diagnosis of rotating machinery based on convolutional neural network},
  volume       = {173},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-source fusion for weak target images in the industrial
internet of things. <em>COMCOM</em>, <em>173</em>, 150–159. (<a
href="https://doi.org/10.1016/j.comcom.2021.04.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the influence of information fusion in Industrial Internet of Things (IIoT) environments, there are many problems, such as weak intelligent visual target positioning, disappearing features, large error in visual positioning processes, and so on. Therefore, this paper proposes a weak target positioning method based on multi-information fusion, namely the “confidence interval method”. The basic idea is to treat the brightness and gray value of the target feature image area as a population with a certain average and standard deviation in IIoT environments. Based on the average and the standard deviation, and using a reasonable confidence level, a critical threshold is obtained. Compared with the threshold obtained by the maximum variance method, the obtained threshold is more suitable for the segmentation of key image features in an environment in which interference is present. After interpolation and de-noising, it is applied to mobile weak target location of complex IIoT systems. Using the metallurgical industry for experimental analysis, results show that the proposed method has better performance and stronger feature resolution.},
  archive      = {J_COMCOM},
  author       = {Keming Mao and Gautam Srivastava and Reza M. Parizi and Mohammad S. Khan},
  doi          = {10.1016/j.comcom.2021.04.002},
  journal      = {Computer Communications},
  pages        = {150-159},
  shortjournal = {Comput. Commun.},
  title        = {Multi-source fusion for weak target images in the industrial internet of things},
  volume       = {173},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Resource allocation for downlink non-orthogonal multiple
access in joint transmission coordinated multi-point networks.
<em>COMCOM</em>, <em>173</em>, 134–149. (<a
href="https://doi.org/10.1016/j.comcom.2021.03.025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Joint transmission coordinated multi-point (JT-CoMP) and non-orthogonal multiple access (NOMA) are key enabling technologies of 5G ubiquitous broadband infrastructures. These technologies are jointly expected to exploit multi-cell and non-orthogonal resource transmissions; thus, conventional resource allocation schemes that only consider either one of them fail to efficiently exploit resources of 5G networks. In this paper, we bridge this gap by proposing a practical and comprehensive joint sub-carrier assignment and power allocation scheme for network sum-rate maximization in JT-CoMP-enabled NOMA networks. We formulate the problem as a mixed integer non-linear programming (MINLP) problem, which is NP-hard. The problem is decoupled into two sub-problems, where the sub-carrier assignment is modeled as a two-sided many-to-many matching game and the power allocation is formulated as a difference of convex (DC) programming problem. The matching algorithm is proved to converge to a two-sided exchange stable matching. Furthermore, the solution computed by the proposed scheme is verified against a baseline solution computed by a commercial optimization package, and has been shown to achieve 91.38\% of the baseline solution for JT-CoMP-NOMA networks. Simulation results illustrate that the proposed scheme enhances cell-edge users’ achievable rates by 0 . 1 − 27 . 7\% 0.1−27.7\% in JT-CoMP-NOMA over conventional NOMA.},
  archive      = {J_COMCOM},
  author       = {Mohamad Khattar Awad and Mohammed W. Baidas and Ahmad A. El-Amine},
  doi          = {10.1016/j.comcom.2021.03.025},
  journal      = {Computer Communications},
  pages        = {134-149},
  shortjournal = {Comput. Commun.},
  title        = {Resource allocation for downlink non-orthogonal multiple access in joint transmission coordinated multi-point networks},
  volume       = {173},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A survivable communication game based approach for a network
of cooperative UAVs. <em>COMCOM</em>, <em>173</em>, 120–133. (<a
href="https://doi.org/10.1016/j.comcom.2021.04.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unmanned Aerial Vehicle (UAV) based technologies are suitable for many civil and military application. In case of the occurrence of some natural disasters such as storms, the infrastructure of the communication system plays a vital role in offering rescue services. In such situations, energy and distance limitations can affect the operations of the UAVs and change the efficiency of the UAV network. To overcome intermittent connectivity and unstable links in this highly dynamic topology , a resilient UAV network is needed. In this paper, the communications infrastructure of a multi-UAV network is investigated in term of availability and survivability factors. We utilize the selected path in the multi-level multi-UAV network to avoid problems associated to interference, link failures, energy constrains, and routing. We present a distributed approach, namely: Survivable Communication Game based Approach (SCGA). SCGA works based on a cooperative communication between UAVs to guarantee a reliable data transmission using the best path. First, we build the utility of our approach based on the achievable rate, transmission delay, and energy consumption. Next, we formulate the interactions between UAVs based on a game framework approach. last, we conduct an extensive simulation using different communication scenarios to investigate the performance of the SCGA in terms of survivability , scalability, and reliability. In addition, the communication links and the connectivity between UAVs are tested using different performance metrics. Moreover, we compare SCGA against both of Nearest Neighbor (NN) and Nash Network Formation (NNF) schemes. The simulation results show that SCGA outperforms both of NN and NNF schemes in terms survivability, scalability, and reliability.},
  archive      = {J_COMCOM},
  author       = {Ibrahim A. Nemer and Tarek R. Sheltami and Ansar Ul-Haque Yasar},
  doi          = {10.1016/j.comcom.2021.04.003},
  journal      = {Computer Communications},
  pages        = {120-133},
  shortjournal = {Comput. Commun.},
  title        = {A survivable communication game based approach for a network of cooperative UAVs},
  volume       = {173},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Comprehensive study of schedulability tests and optimal
design for rate-monotonic scheduling. <em>COMCOM</em>, <em>173</em>,
107–119. (<a
href="https://doi.org/10.1016/j.comcom.2021.03.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Schedulability analysis of the rate-monotonic (RM) scheduling algorithm is an important research field in real-time systems. New dimensions in RM have been explored, ranging from faster schedulability tests to the optimal design of real-time systems. Recently, researchers have extended the schedulability problem to a more generalized case: the rate-monotonic optimal-design problem (RM-ODP), wherein the execution time is limited to an interval rather than a sole point. The RM-ODP processes task-execution-time adjustment such that (i) the system is RM schedulable and (ii) certain system performances (e.g., processor utilization) are optimized. In this paper, we review RM scheduling and summarize three aspects of the related research: (1) evaluate existing relevant feasibility tests by categorizing them based on inexact or exact conditions; (2) comprehensively review RM-ODP, summarize associated advantages and disadvantages, and provide some recommendations on schedulability tests to achieve the optimal system design under RM-scheduling policies; and (3) propose a hybrid search method based on linear programming with respect to both depth-first search and breadth-first search using the dynamic pruning strategy.},
  archive      = {J_COMCOM},
  author       = {Yang Li and Tianying Liu and Jianming Zhu and Xiuli Wang and Meijiao Duan and Youwei Wang},
  doi          = {10.1016/j.comcom.2021.03.013},
  journal      = {Computer Communications},
  pages        = {107-119},
  shortjournal = {Comput. Commun.},
  title        = {Comprehensive study of schedulability tests and optimal design for rate-monotonic scheduling},
  volume       = {173},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Osprey: A fast and accurate patch presence test framework
for binaries. <em>COMCOM</em>, <em>173</em>, 95–106. (<a
href="https://doi.org/10.1016/j.comcom.2021.03.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of Internet of Things (IoT), a new paradigm named Mobile Edge Computing (MEC) is proposed to push the cloud computing to the edge devices. However the rapid growth of Internet-of-Things (IoT) and its inadvertent incorporation of vulnerable third-party code have created a massive amount of vulnerable IoT devices. Even worse, the majority of vulnerable devices are left unpatched due to the lack of easy upgrade routine and automated patch management. Thus, it is crucial to test the patch presence in IoT devices rapidly and accurately, for both defenders and attackers. In this paper, we present Osprey, a fast and accurate patch presence test framework for automatically identifying security patches in a firmware. Osprey identifies fine-grain semantic binary changes introduced by the patch in the binary by analyzing data flow slices across the basic blocks. It parses and analyzes these binary changes to extract patch signatures, which incorporate representative operators and the origins of operands. Then, patch presence can be identified by matching patch signatures through lexical comparison. Compared with the state-of-the-art patch presence test approach, Osprey extracts precise patch semantic information from data flow without expensive symbolic execution. We implement and evaluate Osprey against 45 patches and 8 versions of OpenSSL project, and the results show that Osprey is able to perform patch presence test 9.6 times faster than the state-of-the-art approach with high precision that exceeds 90\%.},
  archive      = {J_COMCOM},
  author       = {Peiyuan Sun and Qiben Yan and Haoyi Zhou and Jianxin Li},
  doi          = {10.1016/j.comcom.2021.03.011},
  journal      = {Computer Communications},
  pages        = {95-106},
  shortjournal = {Comput. Commun.},
  title        = {Osprey: A fast and accurate patch presence test framework for binaries},
  volume       = {173},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A hybrid of neuro-fuzzy inference system and hidden markov
model for activity-based mobility modeling of cellphone users.
<em>COMCOM</em>, <em>173</em>, 79–94. (<a
href="https://doi.org/10.1016/j.comcom.2021.03.028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The aim of this paper is to develop an activity-based travel demand model by receiving cellular network data. Our contribution is to model the uncertainty of human behaviors and also the ambiguity in features affecting users’ activities. We used probabilities to model the first aspect and fuzzy theory to treat with the second; therefore, a hybrid model is proposed based on the Hidden Markov Model (HMM) and Fuzzy Inference System (FIS) such that FIS is used in the emission model of HMM. To show the efficiency of this model, we applied the model to the data collected by Irancell operator and validated the results with four different data sources; labeled data collected from volunteers, ground truth data labeled by an expert, activity-based number of trips generated from/attracted to different regions and reported traffic volume of highways. We have shown that the activity recognition accuracy of the model is 83\% and an average error of 5\% is obtained when comparing the statistics of the model generated activity plans and the corresponding statistics provided in reports. Generated activity plans are also converted to traffic volumes on transportation network links through MATSIM simulation software and the promising R 2 value of 0.83 is observed.},
  archive      = {J_COMCOM},
  author       = {Shiva Rahimipour and Mehdi Ghatee and S.M. Hashemi and Ahmad Nickabadi},
  doi          = {10.1016/j.comcom.2021.03.028},
  journal      = {Computer Communications},
  pages        = {79-94},
  shortjournal = {Comput. Commun.},
  title        = {A hybrid of neuro-fuzzy inference system and hidden markov model for activity-based mobility modeling of cellphone users},
  volume       = {173},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A blockchain-based collaborative training method for
multi-party data sharing. <em>COMCOM</em>, <em>173</em>, 70–78. (<a
href="https://doi.org/10.1016/j.comcom.2021.03.027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, the construction of Space–Ground Integrated Network has been accelerated, connecting different types of networks in remote regions. The various devices are connected together, so that data that was difficult to communicate before can be used to train particular models together, giving birth to new service models. Privacy issues, however, remain a substantial concern affecting data sharing among multiple parties. Cooperative training methods such as federated learning usually require a centralized aggregator to aggregate the dispersed sub-models. In general, various privacy-preserving methods assume the aggregator as an honest-but-curious (HBC) role and cannot guarantee that the program can be executed correctly. In this paper, we propose a blockchain-based collaborative training method that uses the decentralized accounting technology of the blockchain to solve the trust problem between different participants. Through the anti-repudiation nature of the blockchain , it is ensured that the aggregation of the model is executed correctly. We designed a function encryption-based privacy preserving method in which the aggregator can only obtain the results of the aggregation model, and cannot access the models uploaded to the blockchain from other participants. Subsequently, a prototype system based on blockchain is developed to analyze and evaluate the time consumption of our proposed cooperative training method and function encryption module. The result of our experiments shows the feasibility of our cooperative training model.},
  archive      = {J_COMCOM},
  author       = {Lihua Yin and Jiyuan Feng and Sixin Lin and Zhiqiang Cao and Zhe Sun},
  doi          = {10.1016/j.comcom.2021.03.027},
  journal      = {Computer Communications},
  pages        = {70-78},
  shortjournal = {Comput. Commun.},
  title        = {A blockchain-based collaborative training method for multi-party data sharing},
  volume       = {173},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Collision-free and low delay MAC protocol based on
multi-level quorum system in underwater wireless sensor networks.
<em>COMCOM</em>, <em>173</em>, 56–69. (<a
href="https://doi.org/10.1016/j.comcom.2021.03.020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Underwater wireless sensor network (UWSN) is a typical application of wireless network in underwater environment, which mainly uses acoustic communication at present. However, due to the characteristics of high bit error rate, very limited bandwidth and high transmission delay, the data transmission collision of underwater communication is very serious. In order to reduce transmission collision and improve network performance, we propose a collision-free time slot scheduling MAC protocol based on multi-level quorum system for high loaded UWSNs. The proposed protocol can allocate different time slots for nodes in the same collision area, while realize space reuse for nodes in different collision areas. Considering the unbalanced data transmission of each node, a multi-level quorum system algorithm is constructed for fairness, which can allocate time slots on demand according to the data transmission amount of each node. In order to ensure reliable transmission of data, a light weight retransmission mechanism is designed to reduce the impact of long delay on channel duty cycle. Simulation results prove that the proposed MAC protocol can effectively avoid transmission collision, reduce transmission delay, improve system energy efficiency, and have good adaptability for different network topologies .},
  archive      = {J_COMCOM},
  author       = {Ning Sun and Xingjie Wang and Guangjie Han and Yan Peng and Jinfang Jiang},
  doi          = {10.1016/j.comcom.2021.03.020},
  journal      = {Computer Communications},
  pages        = {56-69},
  shortjournal = {Comput. Commun.},
  title        = {Collision-free and low delay MAC protocol based on multi-level quorum system in underwater wireless sensor networks},
  volume       = {173},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Three-factor authentication protocol using physical
unclonable function for IoV. <em>COMCOM</em>, <em>173</em>, 45–55. (<a
href="https://doi.org/10.1016/j.comcom.2021.03.022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As an extension of Internet of Things (IoT) in transportation sector, the Internet of Vehicles (IoV) can greatly facilitate vehicle management and route planning. With ever-increasing penetration of IoV, the security and privacy of driving data should be guaranteed. Moreover, since vehicles are often left unattended with minimum human interventions, the onboard sensors are vulnerable to physical attacks. Therefore, the physically secure authentication and key exchange (AKE) protocol is urgently needed for IoV to implement access control and information protection. In this paper, physical unclonable function (PUF) is introduced in the AKE protocol to ensure that the system is secure even if the user devices or sensors are compromised. Specifically, PUF, as a hardware fingerprint generator, eliminates the storage of any secret information in user devices or vehicle sensors. By combining password, biometrics with PUF, the user device cannot be used by someone else to be successfully authenticated as the user. Finally, the elaborate security analysis demonstrates that the proposed protocol is free from the influence of known attacks and can achieve expected security properties, and the performance evaluation indicates the efficiency of our protocol.},
  archive      = {J_COMCOM},
  author       = {Qi Jiang and Xin Zhang and Ning Zhang and Youliang Tian and Xindi Ma and Jianfeng Ma},
  doi          = {10.1016/j.comcom.2021.03.022},
  journal      = {Computer Communications},
  pages        = {45-55},
  shortjournal = {Comput. Commun.},
  title        = {Three-factor authentication protocol using physical unclonable function for IoV},
  volume       = {173},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). TEAP: Traffic engineering and ALR policy based power-aware
solutions for green routing and planning problems in backbone networks.
<em>COMCOM</em>, <em>173</em>, 27–44. (<a
href="https://doi.org/10.1016/j.comcom.2021.02.025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Enormous and ever-increasing energy consumption in the Internet and the burgeoning global GreenHouse Gas (GHG) emission that come with it have been crucial issues for the past few years due to an exponential traffic growth and a rapid expansion of communication infrastructures worldwide. In this paper, we target Routing and Planning problems of Green Networking with bundled links referred to as RPGN by leveraging Traffic Engineering (TE) and Adaptive Link Rate (ALR) policy jointly to investigate the power-saving potentialities and effective applicability in the backbone networks . We formulate RPGN as a non-linear multi-commodity flow model and develop green heuristics-TE and ALR policy based Power-aware heuristics (TEAP) to solve it. We have investigated and compared different characterizations of the solutions to RPGN by evaluating network power saving ratio, rate level duration distribution, mean rate switching times and mean running time, under different real backbone network topology scenarios. Our results indicate the different power-saving potential of these solutions once applied in the backbone network.},
  archive      = {J_COMCOM},
  author       = {Jinhong Zhang and Xingwei Wang and Qiang He and Min Huang},
  doi          = {10.1016/j.comcom.2021.02.025},
  journal      = {Computer Communications},
  pages        = {27-44},
  shortjournal = {Comput. Commun.},
  title        = {TEAP: Traffic engineering and ALR policy based power-aware solutions for green routing and planning problems in backbone networks},
  volume       = {173},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Representation method of cooperative social network features
based on Node2Vec model. <em>COMCOM</em>, <em>173</em>, 21–26. (<a
href="https://doi.org/10.1016/j.comcom.2021.03.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the deepening of the research on complex networks in recent years, based on the operational research and management of data, this paper builds a cooperation network, the network characteristics of represented by Node2Vec union, the method and complex network of academic cooperation network nodes into a low dimensional vector , and then link prediction, community detection and network stability analysis, such as experiment, finally found the characteristics of the said method has good adaptability for complex network. Based on this, the network feature learning method based on Node2Vec can be applied to network security , science of science, medical treatment and other aspects to promote the rapid development of society.},
  archive      = {J_COMCOM},
  author       = {Xuemei You and Yinghong Ma and Zhiyuan Liu and Jiacheng Liu and Mingming Zhang},
  doi          = {10.1016/j.comcom.2021.03.012},
  journal      = {Computer Communications},
  pages        = {21-26},
  shortjournal = {Comput. Commun.},
  title        = {Representation method of cooperative social network features based on Node2Vec model},
  volume       = {173},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Sparse auto-encoder combined with kernel for network attack
detection. <em>COMCOM</em>, <em>173</em>, 14–20. (<a
href="https://doi.org/10.1016/j.comcom.2021.03.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, we propose sparse auto-encoder combined with kernel for network attack detection for better network security . High-dimensional data seriously affects the accuracy and efficiency of network attack detection, leading to dimension disaster and model over fitting. To address this problem, we optimize the sparse auto-encoder with combined kernel to reconstruct the data features of network attack. Besides, we used the iterative method of adaptive genetic algorithm to optimize the objective function of sparse auto-encoder with combined kernel. The feature matrix after dimension reduction is obtained by sparse auto-encoder with combined kernel, which solves the dimensional reduction problem of nonlinear features and sparse features of network attack. The proposed model improves the efficiency of network attack detection. The simulation using experimental data based on botnet attack detection data set of the Internet of things(IOT) show that, compared with the traditional feature extraction algorithm and other deep learning feature extraction methods, the recognition rate based on sparse auto-encoder method with combined kernel for network attack detection can reach 98.68\%, and the average dimension reduction time is 5.59 s, which depicts better recognition rate and computational efficiency.},
  archive      = {J_COMCOM},
  author       = {Xiaolu Han and Yun Liu and Zhenjiang Zhang and Xin Lü and Yang Li},
  doi          = {10.1016/j.comcom.2021.03.004},
  journal      = {Computer Communications},
  pages        = {14-20},
  shortjournal = {Comput. Commun.},
  title        = {Sparse auto-encoder combined with kernel for network attack detection},
  volume       = {173},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Hidden terminal-aware access point selection for IEEE
802.11ah networks. <em>COMCOM</em>, <em>173</em>, 1–13. (<a
href="https://doi.org/10.1016/j.comcom.2021.02.024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Connectivity provisioning in large-scale Internet-of-Things (IoT) networks raises several challenges, one of which is the high collision rate among the transmission attempts of IoT devices. Transmission collisions result in prolonged data delivery delay and increased energy consumption of IoT devices. Contention-based wireless communication technologies such as WiFi is particularly vulnerable to this issue. As a remedy, a new standard IEEE 802.11ah is designed and such methods as RAW (Restricted Access Window) grouping is incorporated in order to curb the high collision rate . Meanwhile, in IEEE 802.11ah the transmission range and the number of devices that can be accommodated are also drastically increased. As a result, the impact of the hidden terminal problem is significantly amplified, which causes transmission collisions. In this paper, we propose an approach to avoid the high collision rate at the phase of the AP(Access Point) selection for IEEE 802.11ah networks. The proposed scheme considers the traffic load balancing and the hidden terminal issue simultaneously, without incurring any burden to the IoT devices. No modification of the IEEE 802.11ah standard is needed. Via extensive NS-3 simulations, we have verified that the proposed AP selection scheme outperforms the existing schemes in terms of data delivery delay and energy consumption by reducing transmission collisions.},
  archive      = {J_COMCOM},
  author       = {Jung-Han Han and Seung-Jae Han},
  doi          = {10.1016/j.comcom.2021.02.024},
  journal      = {Computer Communications},
  pages        = {1-13},
  shortjournal = {Comput. Commun.},
  title        = {Hidden terminal-aware access point selection for IEEE 802.11ah networks},
  volume       = {173},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Security policies definition and enforcement utilizing
policy control function framework in 5G. <em>COMCOM</em>, <em>172</em>,
226–237. (<a
href="https://doi.org/10.1016/j.comcom.2021.03.024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This research analyses new approaches to security enforcement in fifth generation (5G) architecture from end to end perspective. With the aim of finding a suitable and effective unified schema across the different network domains, it shows that policy control framework may become the cornerstone for the definition and enforcement of security policies in new 5G networks. The 5G core network architecture reference model is defined as a Service Based Architecture (SBA). The Policy Control Function (PCF) is a Network Function (NF) that constitutes, within the SBA architecture, a unique framework for defining any type of policies in the network and delivering those to other control plane NFs. In previous generations the policy control approach has been restricted to Quality of Service (QoS) and charging aspects. In contrast, the 5G system is now based on a unified policy control scheme that allows to build consistent policies covering the entire network. By utilizing the unified 5G policy framework we have found an effective security enforcement schema flexible to create new security policies, and agile to react to the constantly changing environment, across the end to end architecture. Within this schema we have defined mechanisms to apply the QoS principles to security use cases. We have also set up the user plane security enforcement within the session management and established security policies. Finally we have made proposals to extend the network analytics to security analytics . Our overall vision is to consider security as a quality element of the network.},
  archive      = {J_COMCOM},
  author       = {German Peinado Gomez and Jordi Mongay Batalla and Yoan Miche and Silke Holtmanns and Constandinos X. Mavromoustakis and George Mastorakis and Noman Haider},
  doi          = {10.1016/j.comcom.2021.03.024},
  journal      = {Computer Communications},
  pages        = {226-237},
  shortjournal = {Comput. Commun.},
  title        = {Security policies definition and enforcement utilizing policy control function framework in 5G},
  volume       = {172},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A blockchain-based access control and intrusion detection
framework for satellite communication systems. <em>COMCOM</em>,
<em>172</em>, 216–225. (<a
href="https://doi.org/10.1016/j.comcom.2021.03.023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent works have shown great potentials for enhancing satellite communications (SATCOM) in terms of security and privacy from blockchains and smart contracts . However, smart contracts deployed on the blockchain also suffer from various attacks, e.g., illegal trigger and access, continuous intrusion, which causes critical threats toward blockchain-based SATCOM. In this paper, we first design a token-based access control mechanism for smart contracts with dynamic adjustment of the access control rules (ACRs), which guarantees that only authorized users can trigger and execute specific smart contracts. We then propose an intrusion detection mechanism for smart contracts to detect attacks against smart contracts in an effective and real-time way. Based on these mechanisms, we propose an access control and intrusion detection framework, dubbed ACID, to resist various attacks while remaining all characteristics and functionalities of the underlying blockchain-based SATCOM system. We conduct a comprehensive evaluation, which demonstrates that ACID is secure, feasible, and efficient.},
  archive      = {J_COMCOM},
  author       = {Sheng Cao and Sixuan Dang and Yuan Zhang and Wei Wang and Nan Cheng},
  doi          = {10.1016/j.comcom.2021.03.023},
  journal      = {Computer Communications},
  pages        = {216-225},
  shortjournal = {Comput. Commun.},
  title        = {A blockchain-based access control and intrusion detection framework for satellite communication systems},
  volume       = {172},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Generation of realistic cloud access times for mobile
application testing using transfer learning. <em>COMCOM</em>,
<em>172</em>, 196–215. (<a
href="https://doi.org/10.1016/j.comcom.2021.03.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The network Quality of Service (QoS) metrics such as the access time, the bandwidth, and the packet loss play an important role in determining the Quality of Experience (QoE) of mobile applications. Various factors like the Radio Resource Control (RRC) states, the Mobile Network Operator (MNO) specific retransmission configurations, handovers triggered by the user mobility, the network load, etc. can cause high variability in these QoS metrics on 4G/LTE, and WiFi networks, which can be detrimental to the application QoE. Therefore, exposing the mobile application to realistic network QoS metrics is critical for a tester attempting to predict its QoE. A viable approach is testing using synthetic traces. The main challenge in the generation of realistic synthetic traces is the diversity of environments and the lack of wide scope of real traces to calibrate the generators. In this paper, we describe a measurement-driven methodology based on transfer learning with Long Short Term Memory (LSTM) neural nets to solve this problem. The methodology requires a relatively short sample of the targeted environment to adapt the presented basic model to new environments, thus simplifying synthetic traces generation. We present this feature for realistic WiFi and LTE cloud access time models adapted for diverse target environments with a trace size of just 6000 samples measured over a few tens of minutes. We demonstrate that synthetic traces generated from these models are capable of accurately reproducing application QoE metric distributions including their outlier values.},
  archive      = {J_COMCOM},
  author       = {Manoj R. Rege and Vlado Handziski and Adam Wolisz},
  doi          = {10.1016/j.comcom.2021.03.010},
  journal      = {Computer Communications},
  pages        = {196-215},
  shortjournal = {Comput. Commun.},
  title        = {Generation of realistic cloud access times for mobile application testing using transfer learning},
  volume       = {172},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Time-predictable routing algorithm for time-sensitive
networking: Schedulable guarantee of time-triggered streams.
<em>COMCOM</em>, <em>172</em>, 183–195. (<a
href="https://doi.org/10.1016/j.comcom.2021.03.019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To make manufacturers more intelligent in the production of cyber-physical systems (CPS), the IEEE 802.1 working group proposes a Time-Sensitive Network (TSN) standard based on traditional Ethernet. TSN can help the industrial environment to realize intelligent real-time transmission requirements. At present, the research on TSN focuses mainly on how to optimize the scheduling table synthesis to reduce the end-to-end delay of the frame. Routing selection typically uses the common shortest path first (SPF) and weighted shortest path first (wtSPF) algorithms. The path chosen by these algorithms can only ensure a low end-to-end delay of newly added streams, but they cannot guarantee the success rate of scheduling newly added streams or determine whether the delay will have a serious impact on other streams. Therefore, this paper proposes a scheduling routing algorithm for the TSN environment, named Real-Time Routing Scheduler (RTRS), which is applicable to Time-Triggered (TT) streams with immediate constraints. Based on the calculation of the end-to-end maximum delay time , the RTRS is used as a basis for routing to ensure that all TT streams are transmitted within the deadline. The experimental results show that the RTRS algorithm can provide an excellent real-time performance of CPS, improve the scheduling success rate, optimize the maximum end-to-end delay, and ensure that newly added streams do not easily affect the transmission of other streams.},
  archive      = {J_COMCOM},
  author       = {Shih-Hung Chang and Huan Chen and Bo-Chao Cheng},
  doi          = {10.1016/j.comcom.2021.03.019},
  journal      = {Computer Communications},
  pages        = {183-195},
  shortjournal = {Comput. Commun.},
  title        = {Time-predictable routing algorithm for time-sensitive networking: Schedulable guarantee of time-triggered streams},
  volume       = {172},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Real-time optimizations in energy profiles and end-to-end
delay in WSN using two-hop information. <em>COMCOM</em>, <em>172</em>,
169–182. (<a
href="https://doi.org/10.1016/j.comcom.2021.02.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a routing protocol established upon the IEEE 802.15.4a that enhances the delay and energy efficiency in Wireless sensor networks (WSN) using two-hop information. Owing to the miniaturized form and non-rechargeable nature, nodes deployed in WSN suffer from resource constraints which affects its performance in terms of delay and energy consumption. Motivated by this, the proposed scheme exploits two-hop information to improve the performance of WSNs. First, a robust metric function known as the potential relay information (PRI) is formulated. Unlike other metric functions, the PRI leverages the residual energy , distance and delay and assesses the link quality of neighbor nodes to ascertain that the selected next-hop forwarder delivers data packets to the destination with the highest possible quality of service (QoS). Second, a preemptive neighborhood state index (NSI) algorithm which enable nodes view two-hops down its routing path to make good forwarding decisions that minimizes delay and balances load traffic across the system is devised. Last, a proactive feedback technique is integrated to simplify the update of two-hop information in order to address the excessive pursuing of energy consumption resulting from overhead packets. Simulation results validate the efficiency of the proposed scheme and demonstrates improvements in network lifetime, packet delivery ratio (PDR), end-to-end delay and energy consumption over the compared algorithms. Moreover, the results reflect QoS which supports real timeliness.},
  archive      = {J_COMCOM},
  author       = {Etobi Damian Tita and Williams-Paul Nwadiugwu and Jae Min Lee and Dong-Seong Kim},
  doi          = {10.1016/j.comcom.2021.02.007},
  journal      = {Computer Communications},
  pages        = {169-182},
  shortjournal = {Comput. Commun.},
  title        = {Real-time optimizations in energy profiles and end-to-end delay in WSN using two-hop information},
  volume       = {172},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Providing a CoAP-based technique to get wireless sensor data
via IoT gateway. <em>COMCOM</em>, <em>172</em>, 155–168. (<a
href="https://doi.org/10.1016/j.comcom.2021.03.026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The advancement of wireless sensor networks and the possibility of using Internet protocols in devices with limited resources (such as sensors) have changed the future of the Internet. How to interact and exchange information is one of the challenges in the Internet of Things (IoT). The 6LoWPAN (IP6 Low Power Wireless Personal Area Network) and CoAP (Constrained Application Protocol) standards have been developed for using web protocols in sensor-based LLN (Low-power and Lossy Network). The 6LoWPAN/CoAP protocol stack enables access to the sensor network via web protocols. This facilitates the development of applications on the sensor network and their access to the Internet. Each of the layers of the 6LoWPAN/CoAP protocol stack imposes an overhead on the transmitted messages, and the resulting data overhead intensifies the energy consumption in multi-hop networks. In this paper, a technique is provided to reduce the burden imposed on small and medium-size packets on 6LoWPAN/CoAP multi-hop networks by scheduling and aggregating CoAP packets on sensor nodes . It classifies the CoAP requests/responses over the network (by specifying the maximum allowed delay) and manages the timing and aggregation of received messages on the sensor nodes (based on the maximum allowed delay on each one). The results of the evaluation of the provided technique indicated reducing the power consumption and network traffic for applications such as monitoring in multi-hop networks based on the 6LoWPAN/CoAP protocol stack.},
  archive      = {J_COMCOM},
  author       = {Mohammad Reza Nikseresht and Mahdi Mollamotalebi},
  doi          = {10.1016/j.comcom.2021.03.026},
  journal      = {Computer Communications},
  pages        = {155-168},
  shortjournal = {Comput. Commun.},
  title        = {Providing a CoAP-based technique to get wireless sensor data via IoT gateway},
  volume       = {172},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Service differentiation in IEEE 802.11ah WLAN under
restricted access window based MAC protocol. <em>COMCOM</em>,
<em>172</em>, 142–154. (<a
href="https://doi.org/10.1016/j.comcom.2021.03.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The restricted access window (RAW) based channel access scheme proposed for IEEE 802.11ah wireless LAN (WLAN) divides the stations (STAs) in the network into groups and allocates RAW slots for each group of STAs. In this way, the STAs belonging to each group can attempt to access the medium during their designated RAW slot by invoking the enhanced distributed channel access (EDCA) protocol. This paper describes an analytical model to evaluate the saturation throughput of IEEE 802.11ah WLAN under the RAW based scheme, when STAs carry traffic of distinct access categories (ACs) and use the EDCA protocol for medium sharing. However, when groups are formed by randomly selecting the STAs, i.e., if random grouping (RG) scheme is employed, each group will contain STAs carrying traffic of distinct ACs. This will lead to starvation and degraded throughput performance for the low priority class STAs, since they have to contend with high priority class STAs within the same group during the RAW slot assigned. To resolve this issue, we propose an algorithm to realize priority class based grouping (PCG), in which the STAs belonging to the same ACs are grouped together. We also describe an analytical model to evaluate the saturation throughput of the network under the proposed PCG scheme. We establish that saturation throughput of the network and the relative service differentiation ratio of the lower priority class STAs can be significantly improved under the proposed PCG scheme compared to the conventional RG scheme.},
  archive      = {J_COMCOM},
  author       = {U. Sangeetha and A.V. Babu},
  doi          = {10.1016/j.comcom.2021.03.017},
  journal      = {Computer Communications},
  pages        = {142-154},
  shortjournal = {Comput. Commun.},
  title        = {Service differentiation in IEEE 802.11ah WLAN under restricted access window based MAC protocol},
  volume       = {172},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Network coding assisted reliable multi-source multicasting
over a multi-hop wireless mesh network. <em>COMCOM</em>, <em>172</em>,
130–141. (<a
href="https://doi.org/10.1016/j.comcom.2021.03.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a Network Coding (NC) Assisted Reliable Multi-Source Multicasting (NCRMM) technique for multi-hop wireless mesh networks . The NCRMM scheme decreases the average number of packet transmissions in a network, which in turn reduces resource expenditure and traffic congestion problems . Multicast Least Cost Anypath Routing (MLCAR) algorithm is considered in NCRMM to select the neighbouring nodes participating in efficient packet transmission from multiple source nodes to the corresponding destination sets. At each intermediate node , a Coding Window (CW) is defined which stores packets received at the node from the same and/or different sessions. In the proposed NCRMM algorithm, packets are judiciously combined using intra-session and inter-session NC to ensure efficient distribution of coded packets among the neighbouring nodes. This is done while ensuring that packets transmitted at each source node are reliably received at all nodes of the corresponding destination set. The results are obtained for NCRMM and compared with that of the respective MLCAR and NC-MLCAR approach through extensive simulations. It is observed that the cost of multicasting packets in the NCRMM scheme is significantly less than that of the existing MLCAR and NC-MLCAR schemes for both independent and correlated link scenarios. Results comparing the complexity of the proposed NCRMM scheme with other multicasting schemes are also presented.},
  archive      = {J_COMCOM},
  author       = {Prateek Rathore and Kalpana Dhaka and Sanjay K. Bose},
  doi          = {10.1016/j.comcom.2021.03.016},
  journal      = {Computer Communications},
  pages        = {130-141},
  shortjournal = {Comput. Commun.},
  title        = {Network coding assisted reliable multi-source multicasting over a multi-hop wireless mesh network},
  volume       = {172},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A security framework for ethereum smart contracts.
<em>COMCOM</em>, <em>172</em>, 119–129. (<a
href="https://doi.org/10.1016/j.comcom.2021.03.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The use of blockchain and smart contracts have not stopped growing in recent years. Like all software that begins to expand its use, it is also beginning to be targeted by hackers who will try to exploit vulnerabilities in both the underlying technology and the smart contract code itself. While many tools already exist for analyzing vulnerabilities in smart contracts, the heterogeneity and variety of approaches and differences in providing the analysis data makes the learning curve for the smart contract developer steep. In this article the authors present ESAF (Ethereum Security Analysis Framework), a framework for analysis of smart contracts that aims to unify and facilitate the task of analyzing smart contract vulnerabilities which can be used as a persistent security monitoring tool for a set of target contracts as well as a classic vulnerability analysis tool among other uses.},
  archive      = {J_COMCOM},
  author       = {Antonio López Vivar and Ana Lucila Sandoval Orozco and Luis Javier García Villalba},
  doi          = {10.1016/j.comcom.2021.03.008},
  journal      = {Computer Communications},
  pages        = {119-129},
  shortjournal = {Comput. Commun.},
  title        = {A security framework for ethereum smart contracts},
  volume       = {172},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Amalgamation of blockchain and IoT for smart cities
underlying 6G communication: A comprehensive review. <em>COMCOM</em>,
<em>172</em>, 102–118. (<a
href="https://doi.org/10.1016/j.comcom.2021.03.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, increasing urbanization has necessitated the social, environmental, and economic development of cities to enhance the Quality of Life (QoL) significantly and introduces the “Smart City” concept. It integrates Information and Communication Tools (ICT), Internet of Things (IoT), and other technologies to resolve urban challenges. The key goal is to make the most acceptable use of available resources and technologies to develop smart cities. An IoT-enabled application plays a crucial role here, but it has various security, privacy, latency, and reliability issues with a single-point-of-failure problem. The evolving technology blockchain can handle the aforementioned security and privacy issues and provide high-quality services due to several features like transparency, trust-free, decentralization, immutability, and others. The 6G communication network takes care of latency and reliability issues in the smart city with their unique characteristics such as latency (10–100 μ μ s) and reliability (99.99999\%). Motivated by these facts, in this paper, we present a comprehensive review for blockchain technology and IoT together functional to smart cities. First, state-of-art-the works and contextual information are introduced. Then, we proposed a blockchain-based decentralized architecture for IoT-integrated smart cities covering different application perspectives, such as smart grid, Intelligent Transportation System (ITS), and healthcare 5.0 underlying 6G communication networks. Next, we describe the challenges of the proposed architecture respective to each application, as mentioned above. Finally, we collated the open research issues and future direction to efficiently integrate blockchain into IoT-envisioned smart cities.},
  archive      = {J_COMCOM},
  author       = {Aparna Kumari and Rajesh Gupta and Sudeep Tanwar},
  doi          = {10.1016/j.comcom.2021.03.005},
  journal      = {Computer Communications},
  pages        = {102-118},
  shortjournal = {Comput. Commun.},
  title        = {Amalgamation of blockchain and IoT for smart cities underlying 6G communication: A comprehensive review},
  volume       = {172},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Exploring active attacks for three incorrect implementations
of the ISO/IEC 9798 in satellite networks. <em>COMCOM</em>,
<em>172</em>, 93–101. (<a
href="https://doi.org/10.1016/j.comcom.2021.02.023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A variety of satellite authentication protocols have been proposed to meet the requirements of the security and efficiency in satellite communication networks nowadays. Most of them are variants from entity authentication technical standards published by the International Organization for Standardization (ISO), the International Electrotechnical Commission(IEC), or Consultative Committee for Space Data Systems (CCSDS), etc. Unfortunately, the variants will be error-prone if technicians do not faithfully implement the standard procedure. In this article, we explore three potential incorrect implementations of the ISO/IEC 9798-2 and ISO/IEC 9798-3 technical standards for enhancing the performance in satellite communication networks . Specifically, we show the concrete attack steps and analyze the reasons for the success of the attack. We then design a simulation platform, and evaluate the performance for the correct implementation in the case of the ISO/IEC 9798-2.},
  archive      = {J_COMCOM},
  author       = {Zhengjia Zhu and Hao Yin and Zijian Zhang and Tielei Li and Jiamou Liu and Bakh Khoussainov and Chang Xu},
  doi          = {10.1016/j.comcom.2021.02.023},
  journal      = {Computer Communications},
  pages        = {93-101},
  shortjournal = {Comput. Commun.},
  title        = {Exploring active attacks for three incorrect implementations of the ISO/IEC 9798 in satellite networks},
  volume       = {172},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Data tampering attacks diagnosis in dynamic wireless sensor
networks. <em>COMCOM</em>, <em>172</em>, 84–92. (<a
href="https://doi.org/10.1016/j.comcom.2021.03.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Real-world wireless sensor networks (WSNs) usually have dynamic topologies and are vulnerable to data tampering attacks, which may possibly lead to serious consequences. This paper addresses the issue of defending against data tampering attacks to dynamic WSNs. First, a hybrid diagnosis algorithm is proposed, which consists of three phases: data comparison phase, distributed diagnosis phase , and global diagnosis phase . In the distributed diagnosis phase, a majority voting mechanism and a multi-round diagnosis mechanism are introduced. As the phase may lead to inconsistent diagnosis results among different sensor nodes , we introduce a global diagnosis phase to overcome the shortcoming. Next, we evaluate the performance of the diagnosis algorithm , accompanied with a few examples. Finally, to achieve near perfect performance, some experiments on how to choose the parameters of the algorithm are provided. This work provides guidance for dealing with data tampering attacks in dynamic WSNs.},
  archive      = {J_COMCOM},
  author       = {Da-Wen Huang and Wanping Liu and Jichao Bi},
  doi          = {10.1016/j.comcom.2021.03.007},
  journal      = {Computer Communications},
  pages        = {84-92},
  shortjournal = {Comput. Commun.},
  title        = {Data tampering attacks diagnosis in dynamic wireless sensor networks},
  volume       = {172},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Planning fog networks for time-critical IoT requests.
<em>COMCOM</em>, <em>172</em>, 75–83. (<a
href="https://doi.org/10.1016/j.comcom.2021.03.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The massive growth of the Internet of Things (IoT) applications and the challenges of Cloud computing have increased the importance of Fog networks for timely processing the requests from delay-sensitive applications. A Fog network provides local aggregation, analysis, and processing of IoT requests that may or may not be time-critical. One of the major issues of Fog is its capacity planning considering the traffic load of time-critical requests. The response time can be huge if a time-critical request is processed on Cloud. The response time of a time-critical request can be big on the Fog layer if it is not prioritized. Hence, there is a need to handle the time-critical traffic on a priority basis at the Fog layer. In this paper, a priority queuing model with preemption has been proposed considering the mixed types of requests at the Fog layer. The proposed approach determines the required number of Fog nodes in order to satisfy the desired Quality of Service (QoS) requirements of IoT requests. The proposed mechanism is evaluated through simulations using the iFogSim simulator. The work can be used in the capacity planning of Fog networks.},
  archive      = {J_COMCOM},
  author       = {Ume Kalsoom Saba and Saif ul Islam and Humaira Ijaz and Joel J.P.C. Rodrigues and Abdullah Gani and Kashif Munir},
  doi          = {10.1016/j.comcom.2021.03.002},
  journal      = {Computer Communications},
  pages        = {75-83},
  shortjournal = {Comput. Commun.},
  title        = {Planning fog networks for time-critical IoT requests},
  volume       = {172},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). EdgeSOM: Distributed hierarchical edge-driven IoT data
analytics framework. <em>COMCOM</em>, <em>172</em>, 64–74. (<a
href="https://doi.org/10.1016/j.comcom.2021.02.021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid growth in the number of interacting IoT devices producing a huge amount of data, existing traditional systems are unable to handle the resulting data flow in such a way as to meet timeliness and performance requirements of critical services. Cloud computing systems have enabled us to access enormous computing power and storage capacity. However, despite its potential advantages, cloud computing is not always an ideal solution for real-time analytics services, where centralisation of computing resources has led to an increase in the separation between local devices and cloud partners, resulting in an increase in network latency , performance degradation and migration of the data away from its sources. To address these issues, a new paradigm is emerging, known as mobile edge computing (MEC), that enables the operation of highly demanding applications at the edge of the cellular network while meeting real-time response and low latency requirements. In this paper, we introduce EdgeSOM, a distributed and hierarchical MEC-based data analytics framework. EdgeSOM uses the combination of an enhanced Self-organising Map (SOM) and the Hierarchical Agglomerative Clustering (HAC) algorithm for distributed data clustering . EdgeSOM is fully distributed, such that MEC servers do not require a synchronisation server to cluster the data initially. The experimental evaluation shows that the EdgeSOM significantly reduces the network traffic of the aggregated IoT raw data to the cloud by up to 99.66\% while achieving highly accurate analysis results.},
  archive      = {J_COMCOM},
  author       = {Kassem Bagher and Ibrahim Khalil and Abdulatif Alabdulatif and Mohammed Atiquzzaman},
  doi          = {10.1016/j.comcom.2021.02.021},
  journal      = {Computer Communications},
  pages        = {64-74},
  shortjournal = {Comput. Commun.},
  title        = {EdgeSOM: Distributed hierarchical edge-driven IoT data analytics framework},
  volume       = {172},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Target vehicle lane-change intention detection: An approach
based on online transfer learning. <em>COMCOM</em>, <em>172</em>, 54–63.
(<a href="https://doi.org/10.1016/j.comcom.2021.02.018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The lack of visual information from the driver of the target vehicle makes it difficult to detect the intention of the target vehicle early before the start of the lane-change maneuver. Moreover, in current studies, the prerequisite for the successful application of intention detection models is to obtain a sufficient number of lane-change maneuver samples covering various scenarios and characteristics. Thus, a universal detector may not be optimal for lane-change intention detection in different scenarios in the real world. In this paper, we propose an intent detection method based on online transfer learning (OTL). First, a passive–aggressive (PA) algorithm is adopted to construct a lane-change source classifier with a large number of lane-change maneuvers as training samples. These samples contain the motion parameters of the vehicle before changing lanes, and the relative motion relationship between the target vehicle and the surrounding vehicles. Then, an OTL strategy that automatically and dynamically updates the weights is designed to detect the intention of the target vehicle to change lanes. The construction of the source classifier is supported by Next Generation Simulation (NGSIM) natural driving data, and the verification of the intention predictions exploits data collected from real natural driving experiments. The performance analysis results demonstrate that the proposed method can successfully detect lane-change intention 3 s before the start of the lane-change maneuver, with an accuracy of 93.0\%.},
  archive      = {J_COMCOM},
  author       = {Hailun Zhang and Rui Fu},
  doi          = {10.1016/j.comcom.2021.02.018},
  journal      = {Computer Communications},
  pages        = {54-63},
  shortjournal = {Comput. Commun.},
  title        = {Target vehicle lane-change intention detection: An approach based on online transfer learning},
  volume       = {172},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Enhanced network sensitive access control scheme for
LTE–LAA/WiFi coexistence: Modeling and performance analysis.
<em>COMCOM</em>, <em>172</em>, 45–53. (<a
href="https://doi.org/10.1016/j.comcom.2021.03.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Implementation of 5G and beyond networks is looking to expand the operation of licensed systems into unlicensed frequency bands through technologies such as license assisted access (LAA) and New Radio Unlicensed (NR-U). LAA aggregates licensed and unlicensed bands for long term evolution (LTE) implementation to address the ever-increasing demand for cellular data traffic and shortage of licensed spectrum. Spectrum-efficient resource-sharing schemes are, however, critical for the harmonious coexistence of LTE–LAA with incumbent systems on the unlicensed band, especially WiFi, while opportunistically improving LTE throughput and enhancing spectrum utilization of the unlicensed band. In this paper, we present a listen before talk (LBT) based clear channel assessment (CCA) mechanism for LAA eNodeBs (eNBs) to improve the coexistence performance of LTE–LAA with WiFi. Particularly, we propose an adaptive exponential backoff scheme for LTE eNB that dynamically updates the contention window (CW) size and transmission opportunity (TXOP) parameters according to network load variations. A three-dimensional discrete Markov model is developed to describe the LBT procedure of LAA eNB, and a performance model is further derived to evaluate steady-state channel access, transmission, and failure probabilities. The proposed scheme’s performance is evaluated in terms of successful transmission probability, throughput, and delay according to the 3GPP and WiFi guidelines. The results are compared with the traditional schemes proposed in literature considering fixed and adaptive CW size for LAA eNB.},
  archive      = {J_COMCOM},
  author       = {Salman Saadat and Waleed Ejaz and Shahzad Hassan and Inam Bari and Tariq Hussain},
  doi          = {10.1016/j.comcom.2021.03.003},
  journal      = {Computer Communications},
  pages        = {45-53},
  shortjournal = {Comput. Commun.},
  title        = {Enhanced network sensitive access control scheme for LTE–LAA/WiFi coexistence: Modeling and performance analysis},
  volume       = {172},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-windowed vertex-frequency analysis for signals on
undirected graphs. <em>COMCOM</em>, <em>172</em>, 35–44. (<a
href="https://doi.org/10.1016/j.comcom.2021.02.019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The recent emerging graph signal processing technologies have been widely applied to analyze signals defined on irregular domains, e.g., data collected from social networks, sensor networks, or transportation systems. Vertex frequency analysis, especially the windowed graph Fourier transform , is one of the most important tools for graph signal analysis and representations. Nevertheless, with a selected window function, it is rather challenging to construct tight frames via the windowed graph Fourier transform . To facilitate the construction of tight frames, in this paper, we consider multi-windowed graph Fourier transforms to develop novel vertex frequency analysis methods. Firstly, under the multi-windowed setting, tight graph Fourier frames are elaborately constructed to fulfill technical demands in different application scenarios. The canonical dual frames of the multi-windowed graph Fourier frames are investigated to establish the reconstruction formulas of graph signals. Additionally, we propose shift multi-windowed graph Fourier frames by directly using the shift operators, e.g., the adjacency matrix . The related tight frames, dual frames and their constructions are also discussed. Experimental results show that the proposed two types of frames can efficiently extract vertex-frequency features of synthetic graph signals. Furthermore, anomaly data can also be detected by these frames.},
  archive      = {J_COMCOM},
  author       = {Xianwei Zheng and Cuiming Zou and Li Dong and Jiantao Zhou},
  doi          = {10.1016/j.comcom.2021.02.019},
  journal      = {Computer Communications},
  pages        = {35-44},
  shortjournal = {Comput. Commun.},
  title        = {Multi-windowed vertex-frequency analysis for signals on undirected graphs},
  volume       = {172},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). AdS: An adaptive spectrum sensing technique for
survivability under jamming attack in cognitive radio networks.
<em>COMCOM</em>, <em>172</em>, 25–34. (<a
href="https://doi.org/10.1016/j.comcom.2021.03.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IEEE 802.22 Cognitive Radio Network (CRN) allows sharing of geographically unused spectrum allocated to the television broadcast service, on a non-interfering basis. CRNs make use of Dynamic Spectrum Access (DSA) which is a two-stage mechanism comprising fast sensing , which is mandatory and fine sensing which is optional. However, the two-stage spectrum sensing mechanism suits malicious nodes in the CRN which intend to deny the use of vacant spectrum to the CRN by jamming its communication while at the same time, minimizing the amount of power expended on jamming. Such Minimal Denial of Service (MDoS) jamming attack can be launched by the malicious nodes by transmitting a very short jamming signal during the mandatory fast sensing stage which will in turn force the CRN to carry out the otherwise optional, fine sensing. MDoS jamming attack results in wastage of spectrum opportunities for the rest of the CRN to the extent which can jeopardize its survivability . In this paper we present AdS : an Intelligent Ad aptive spectrum S ensing technique which, not only minimizes the effects of MDoS jamming attack but can also reduce the effects of noise during the spectrum sensing stages of DSA. The adaptive nature of AdS improves spectrum utilization by CRNs by up to 90\% through adaptive tuning of the fine sensing threshold which is based on an estimate of PU’s activity and the severity of MDoS jamming attack.},
  archive      = {J_COMCOM},
  author       = {Muhammad Faisal Amjad and Hammad Afzal and Haider Abbas and Abdul B. Subhani},
  doi          = {10.1016/j.comcom.2021.03.001},
  journal      = {Computer Communications},
  pages        = {25-34},
  shortjournal = {Comput. Commun.},
  title        = {AdS: An adaptive spectrum sensing technique for survivability under jamming attack in cognitive radio networks},
  volume       = {172},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An intelligent work order classification model for
government service based on multi-label neural network. <em>COMCOM</em>,
<em>172</em>, 19–24. (<a
href="https://doi.org/10.1016/j.comcom.2021.02.020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The classification of work orders for livelihood service play an important role in the e-government system, which goal is to push these work orders to the corresponding processing department. Although many studies have realized the classification of work orders automatically, these work orders are either related to many subjects or related to many departments. Therefore, the problem of work order classification is not a single label classification problem, but a multi-label classification problem. In view of the continuous development of deep neural networks , the goal of this paper is to modify a MultilabelMarginLoss function and design a MultilabelCrossEntropyLoss function to realize the multi-classification system of work orders, which can push the work orders to the related departments(one or more departments) automatically according to their appeal contents (consisting of short texts). We perform deep neural network for text classification including TextCNN, TextRCNN, TextRNN, TextRNN_Att, FastText and DPCNN on the real government hotline data set and compare the performances of these models. The results reveal that TextCNN and TextRCNN have a more stable performance on different loss functions, especially on the MultilabelCrossEntropyLoss function.},
  archive      = {J_COMCOM},
  author       = {Weidong Huang and Chong Su and Yuan Wang},
  doi          = {10.1016/j.comcom.2021.02.020},
  journal      = {Computer Communications},
  pages        = {19-24},
  shortjournal = {Comput. Commun.},
  title        = {An intelligent work order classification model for government service based on multi-label neural network},
  volume       = {172},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An intelligent parking sharing system for green and smart
cities based IoT. <em>COMCOM</em>, <em>172</em>, 10–18. (<a
href="https://doi.org/10.1016/j.comcom.2021.02.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Today car drivers struggle to find a free parking space for their cars. It is considered a big challenge specially in large cities and in rush hours. Many studies considered this problem and how it influences our life. This increases emissions and energy consumption and wastes people’s times as they try to find a free space for their cars. People normally become exhausted all over the day to reach their destination which causes stress and make them lose their temper. This would have a bad impact on the quality of life and economy. Based on the above, today people expect technology to address this problem and hence find a suitable solution to end the suffering of motorists. On the other hand, IoT is a promising platform for providing unusual applications for helping people and provide them a better way to manage their day’s lives. This work proposes a solution for a green intelligent parking system based on IoT . This solution is supported by proposing the game theory mathematical model. Game theory is used to model a reservation system of the proposed car parking solution. This work tackles the main problems facing car drivers to find available car parking spaces. These problems include: the parking fees, how far the car park from the car drivers destinations and hence the amount of walking, and the parking duration. Moreover, the proposed solution encourages companies and householders to offer their own parking stalls and/or driveways for renting in the unused times. From one hand, this will help on providing more parking lots specially in the dense traffic areas. On the other hand, the owners will get a revenue of their unused assets. Therefore, this work proposes a solution to parking problems by providing affordable parking lots based on the choice of the car driver that is relatively close to the destination. As a result of that, there will not be wasting of time or energy, frustration and panic will be reduced, fewer traffic jams, and consequently a green environment and a better quality of life.},
  archive      = {J_COMCOM},
  author       = {Adel Mounir Said and Ahmed E. Kamal and Hossam Afifi},
  doi          = {10.1016/j.comcom.2021.02.017},
  journal      = {Computer Communications},
  pages        = {10-18},
  shortjournal = {Comput. Commun.},
  title        = {An intelligent parking sharing system for green and smart cities based IoT},
  volume       = {172},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). MECGuard: GRU enhanced attack detection in mobile edge
computing environment. <em>COMCOM</em>, <em>172</em>, 1–9. (<a
href="https://doi.org/10.1016/j.comcom.2021.02.022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the commercialization of 5G technology, various Mobile Edge Computing (MEC) services are being deployed widely. Generally, MEC services rely on MEC devices and servers deployed at the edge of the network. Whether it is a MEC device or an edge server, most of them lack computing resources, and it is difficult to implement powerful security capabilities. Moreover, there are a large number of MEC service providers, different standards, and different protocols, which extend the attack interface of MEC services. In response to this situation, this paper proposes MECGuard, an attack detection solution designed for the MEC environment based on deep learning technology. Based on its distributed architecture designed for the MEC environment, MECGuard implements a lightweight TCP-level protocol extractor based on Decision Tree , and an attack detection network based on Gated Recurrent Unit (GRU). Experiments prove that MECGuard could have a good performance of malicious traffic detection in the EMC environment.},
  archive      = {J_COMCOM},
  author       = {Xin Liu and Wenqiang Zhang and Xiaokang Zhou and Qingguo Zhou},
  doi          = {10.1016/j.comcom.2021.02.022},
  journal      = {Computer Communications},
  pages        = {1-9},
  shortjournal = {Comput. Commun.},
  title        = {MECGuard: GRU enhanced attack detection in mobile edge computing environment},
  volume       = {172},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A variable-scale dynamic clustering method. <em>COMCOM</em>,
<em>171</em>, 163–172. (<a
href="https://doi.org/10.1016/j.comcom.2021.03.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the high intensity and density of aerospace launch in China, aerospace project materials management faces various challenges, such as multiple aerospace projects concurrent, high supply timeliness and high quality level. Although several enterprises have successfully explored a versatile material management regulation for multiple aerospace projects, the low inventory turnover problem still exist due to the difficulty in versatile material recognition and inventory distribution. This paper studies the dynamic inventory management problem of aerospace project materials. Firstly, a numerical concept space model is established to describe the data characteristics of aerospace project materials. Then, we propose the variable-scale clustering algorithm based on the numerical concept space, which is utilized to automatically recognize versatile materials. Also, the obtained satisfy scale feature supports managers making inventory-related decision. Finally, a dynamic adjustment algorithm of inventory classification based on the variable-scale clustering is proposed, in order to dynamically maintain the inventory management plan of aerospace project materials. Experiments select the inventory data of aerospace project metal materials during Jan 1, 2015 to Mar 31, 2018 from the logistics center in China Academy of Launch Vehicle Technology. And experiment results illustrate that our proposed variable-scale clustering algorithm has high efficiency and practical application value in solving dynamic inventory management problem of aerospace project materials.},
  archive      = {J_COMCOM},
  author       = {Ai Wang and Xuedong Gao},
  doi          = {10.1016/j.comcom.2021.03.009},
  journal      = {Computer Communications},
  pages        = {163-172},
  shortjournal = {Comput. Commun.},
  title        = {A variable-scale dynamic clustering method},
  volume       = {171},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Machine vision-based network monitoring system for
solar-blind ultraviolet signal. <em>COMCOM</em>, <em>171</em>, 157–162.
(<a href="https://doi.org/10.1016/j.comcom.2021.03.014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The ultraviolet (UV) wavelength of 240 nm to 280 nm is called the solar-blind area. Therefore, if the UV signal in the solar-blind area can be detected, then it can only be the radiation from the measured object on the earth. To meet the requirements of UV signal detection, such as corona discharge and forest fire, this work designs a kind of UV dual spectrum imaging monitoring system. This system uses visible and UV dual light path structure for imaging, selects UV narrow-band filter to obtain UV light , and utilizes spectral conversion and image enhancement technology to image it. Web server and digital signal processing realize the function of remote network monitoring, and users can monitor and detect objects remotely through the client. An image fusion method based on nonsubsampling contourlet transform (NSCT) and visual saliency is proposed. Experimental results show that the fusion effect based on subjective visual effect and objective evaluation criteria is good. This method can also obtain high standard deviation, information entropy, edge preservation , and mutual information and preserve the details of the fusion image effectively. The results of system running and debugging show that the system design and image processing scheme proposed in this work are effective.},
  archive      = {J_COMCOM},
  author       = {Wei Li and Qinyong Lin and Keqiang Wang and Ken Cai},
  doi          = {10.1016/j.comcom.2021.03.014},
  journal      = {Computer Communications},
  pages        = {157-162},
  shortjournal = {Comput. Commun.},
  title        = {Machine vision-based network monitoring system for solar-blind ultraviolet signal},
  volume       = {171},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An improved OIF elman neural network based on CSO algorithm
and its applications. <em>COMCOM</em>, <em>171</em>, 148–156. (<a
href="https://doi.org/10.1016/j.comcom.2021.01.035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to prevent air pollution and improve the living environment for residents, it is particularly important to carry out air quality forecasting. Air quality is affected by many factors, and showed significant non-linear features. Output–input feedback Elman (OIF Elman) neural network can effectively solve non-linear problems. However, the disadvantages of OIF Elman neural network are easy to fall into local minimum, slow convergence and inflexibility. Chicken swarm optimization (CSO) algorithm has high operating efficiency and fast convergence speed. Therefore, this paper proposes an air pollution prediction model for OIF Elman neural network based on the CSO algorithm (CSO-OIF Elman neural network model). Evaluation indicators are absolute average error and accuracy rate. The efficacy of the proposed model is compared with other models such as traditional Elman neural network model , OIF Elman neural network model and Elman neural network model based on CSO algorithm (CSO-Elman neural network model). The experimental results show that CSO-OIF Elman neural network model has the best accuracy and the smallest absolute average error value, and has higher nonlinear fitting capabilities and generalization capabilities. The establishment of this model can provide useful reference value for atmospheric prediction research.},
  archive      = {J_COMCOM},
  author       = {Yufei Zhang and Jianping Zhao and Limin Wang and Honggang Wu and Ruihong Zhou and Jinglin Yu},
  doi          = {10.1016/j.comcom.2021.01.035},
  journal      = {Computer Communications},
  pages        = {148-156},
  shortjournal = {Comput. Commun.},
  title        = {An improved OIF elman neural network based on CSO algorithm and its applications},
  volume       = {171},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Expressway traffic safety early warning system based on
cloud architecture. <em>COMCOM</em>, <em>171</em>, 140–147. (<a
href="https://doi.org/10.1016/j.comcom.2021.01.033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of the society, highway traffic safety is gradually valued by the world. However, due to the complicated state of the highway roads, the faster road speeds and the different types of vehicles, the problem of highway safety warning is an extremely complex system engineering problem faced by the entire society. In view of the characteristics of the problem studied, this study firstly conducted a simple analysis of the design goals and overall architecture of the highway traffic safety early warning system ; on this basis, the various components of the system-road information collection, road information processing analysis and road the early warning information release and other functional modules have been elaborated and analyzed accordingly. The road information collection and cloud architecture are combined to solve the problem of excessive data generation. Finally, the important link of analysis and early warning-highway status classification Problem, the BP neural network algorithm is proposed. Through the BP neural network algorithm, the road nodes are classified, and then the safety warnings are generated according to the road status information. The safety warnings are divided into four levels: the first level is particularly dangerous and vehicle traffic is strictly prohibited; the second level is more dangerous and requires vehicles to bypass; the third level is a certain danger, the vehicle is required to pay attention to the prompt information, and you must go to the service area to rest for a long time Through the BP neural network algorithm, the efficiency of node classification is improved by 13\%.},
  archive      = {J_COMCOM},
  author       = {Yujia Tian and Dianliang Xiao and Lu Wang and Hong Chen},
  doi          = {10.1016/j.comcom.2021.01.033},
  journal      = {Computer Communications},
  pages        = {140-147},
  shortjournal = {Comput. Commun.},
  title        = {Expressway traffic safety early warning system based on cloud architecture},
  volume       = {171},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Cryptomining makes noise: Detecting cryptojacking via
machine learning. <em>COMCOM</em>, <em>171</em>, 126–139. (<a
href="https://doi.org/10.1016/j.comcom.2021.02.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cryptojacking occurs when an adversary illicitly runs crypto-mining software over the devices of unaware users. This novel cybersecurity attack, that is emerging in both the literature and in the wild, has proved to be very effective given the simplicity of running a crypto-client into a target device. Several countermeasures have recently been proposed, with different features and performance, but all characterized by a host-based architecture. The cited solutions, designed to protect the individual user, are not suitable for efficiently protecting a corporate network, especially against insiders. In this paper, we propose a network-based approach to detect and identify crypto-clients activities by solely relying on the network traffic, even when encrypted and mixed with non-malicious traces. First, we provide a detailed analysis of the real network traces generated by three major cryptocurrencies , Bitcoin , Monero , and Bytecoin, considering both the normal traffic and the one shaped by a VPN . Then, we propose Crypto-Aegis, a Machine Learning (ML) based framework built over the results of our investigation, aimed at detecting cryptocurrencies related activities, e.g., pool mining, solo mining, and active full nodes. Our solution achieves a striking 0.96 of F1-score and 0.99 of AUC for the ROC, while enjoying a few other properties, such as device and infrastructure independence. Given the extent and novelty of the addressed threat we believe that our approach, supported by its excellent results, pave the way for further research in this area.},
  archive      = {J_COMCOM},
  author       = {Maurantonio Caprolu and Simone Raponi and Gabriele Oligeri and Roberto Di Pietro},
  doi          = {10.1016/j.comcom.2021.02.016},
  journal      = {Computer Communications},
  pages        = {126-139},
  shortjournal = {Comput. Commun.},
  title        = {Cryptomining makes noise: Detecting cryptojacking via machine learning},
  volume       = {171},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Privacy preserving distributed machine learning with
federated learning. <em>COMCOM</em>, <em>171</em>, 112–125. (<a
href="https://doi.org/10.1016/j.comcom.2021.02.014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Edge computing and distributed machine learning have advanced to a level that can revolutionize a particular organization. Distributed devices such as the Internet of Things (IoT) often produce a large amount of data, eventually resulting in big data that can be vital in uncovering hidden patterns, and other insights in numerous fields such as healthcare, banking, and policing. Data related to areas such as healthcare and banking can contain potentially sensitive data that can become public if they are not appropriately sanitized. Federated learning (FedML) is a recently developed distributed machine learning (DML) approach that tries to preserve privacy by bringing the learning of an ML model to data owners’ devices. However, literature shows different attack methods such as membership inference that exploit the vulnerabilities of ML models as well as the coordinating servers to retrieve private data. Hence, FedML needs additional measures to guarantee data privacy. Furthermore, big data often requires more resources than available in a standard computer. This paper addresses these issues by proposing a distributed perturbation algorithm named as DISTPAB, for privacy preservation of horizontally partitioned data. DISTPAB alleviates computational bottlenecks by distributing the task of privacy preservation utilizing the asymmetry of resources of a distributed environment, which can have resource-constrained devices as well as high-performance computers. Experiments show that DISTPAB provides high accuracy, high efficiency, high scalability, and high attack resistance. Further experiments on privacy-preserving FedML show that DISTPAB is an excellent solution to stop privacy leaks in DML while preserving high data utility.},
  archive      = {J_COMCOM},
  author       = {M.A.P. Chamikara and P. Bertok and I. Khalil and D. Liu and S. Camtepe},
  doi          = {10.1016/j.comcom.2021.02.014},
  journal      = {Computer Communications},
  pages        = {112-125},
  shortjournal = {Comput. Commun.},
  title        = {Privacy preserving distributed machine learning with federated learning},
  volume       = {171},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Sieve: A flow scheduling framework in SDN based data center
networks. <em>COMCOM</em>, <em>171</em>, 99–111. (<a
href="https://doi.org/10.1016/j.comcom.2021.02.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Today’s data centers act as the primary infrastructure for emerging technologies. QoS imposes requirements for more attentive techniques that can deal with different characteristics of traffic classes and patterns. In this context, network flows can be classified into large and long-lived flows called elephant flows and mice flows, which are small and short-lived flows. According to the characteristics of the emerging technologies, e.g., IoT and Big Data, mice flows are dominant; Hence, it is crucial to improve Flow Completion Time (FCT) for such delay-sensitive flows. This paper presents Sieve, a new distributed Software Defined Networks (SDN) based framework. Sieve initially schedules a portion of the flows based on the available bandwidth despite their classes. We propose a distributed sampling technique which sends a portion of the packets to the controller. Furthermore, Sieve polls the edge switches periodically to get the network information rather than polls all switches in the network, and it reschedules elephant flows only. Mininet emulator and mathematical analysis have been employed to validate the proposed solution in 4-ary Fat-Tree DCN. Sieve provides less FCT up to around 58\% for mice flows and maintains throughput of elephant flows compared to Equal Cost MultiPath (ECMP) and Hedera.},
  archive      = {J_COMCOM},
  author       = {Maiass Zaher and Aymen Hasan Alawadi and Sándor Molnár},
  doi          = {10.1016/j.comcom.2021.02.013},
  journal      = {Computer Communications},
  pages        = {99-111},
  shortjournal = {Comput. Commun.},
  title        = {Sieve: A flow scheduling framework in SDN based data center networks},
  volume       = {171},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Fair auctioning and trading framework for cloud virtual
machines based on blockchain. <em>COMCOM</em>, <em>171</em>, 89–98. (<a
href="https://doi.org/10.1016/j.comcom.2021.02.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cloud auction provides a cost-effective approach to cloud resource allocation. Most existing cloud auction mechanisms simply assume that the auctioneer is trustable, and overlook the fairness of auctions. However, in fact, such a trustable auctioneer may not exist, and the fairness is non-trivial to guarantee. In this work, for the first time, we propose a decentralized auctioning and trading framework for cloud virtual machines based on blockchain . We realize both auction fairness and trade fairness among participants (e.g., cloud provider and cloud users), which guarantees each participant will not suffer any loss as long as it follows the protocol. Furthermore, we implement our system through the local analog network and Ethereum official test network, carry out experimental simulation, and demonstrate the feasibility of our system.},
  archive      = {J_COMCOM},
  author       = {Zhili Chen and Wei Ding and Yan Xu and Miaomiao Tian and Hong Zhong},
  doi          = {10.1016/j.comcom.2021.02.010},
  journal      = {Computer Communications},
  pages        = {89-98},
  shortjournal = {Comput. Commun.},
  title        = {Fair auctioning and trading framework for cloud virtual machines based on blockchain},
  volume       = {171},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A survey on TCP over mmWave. <em>COMCOM</em>, <em>171</em>,
80–88. (<a href="https://doi.org/10.1016/j.comcom.2021.01.032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Millimeter wave (mmWave) technology has rapidly evolved into one of the critical components of the 5th generation of mobile communication networks and beyond (5G/B5G), with its abundant spectrum resources and extremely high data transmission rate . However, highly variable mmWave channels pose unique challenges to transport layer protocols and end-to-end applications, such as link quality judgment, rate adaptation, bufferbloat, and beam misalignment. In recent years, various protocols have emerged for improving the adaptability between the Transmission Control Protocol (TCP) of the transport layer and the mmWave communication system of the physical layer . This paper provides a comprehensive survey of the performance, causes, and improvements of TCP over mmWave networks. We analyze the details of the problems of TCP transmission in mmWave networks and summarize the progress of research on TCP over mmWave by classifying various methods into four categories including new congestion control algorithms, retransmission proxies, multiple paths and machine learning-based protocols. We conclude by exposing and discussing further open research challenges.},
  archive      = {J_COMCOM},
  author       = {Yongmao Ren and Wanghong Yang and Xu Zhou and Huan Chen and Bing Liu},
  doi          = {10.1016/j.comcom.2021.01.032},
  journal      = {Computer Communications},
  pages        = {80-88},
  shortjournal = {Comput. Commun.},
  title        = {A survey on TCP over mmWave},
  volume       = {171},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A hybrid trust management framework for a multi-service
social IoT network. <em>COMCOM</em>, <em>171</em>, 61–79. (<a
href="https://doi.org/10.1016/j.comcom.2021.02.015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Social IoT (or SIoT) is an alternate architectural pattern for IoT , which involves IoT devices with social behavioural attributes. A SIoT-based service network makes use of social collaboration between IoT devices to enable low-latency collaborative services and applications. A key challenge in implementing a SIoT-based service network in a multi-vendor environment of heterogeneous devices is the issue of Trust . In this paper, we propose a hybrid trust management framework that makes use of Probabilistic Neighbourhood Overlap (P-NO) , a method for estimating tie-strengths between nodes. The neighbourhood overlap concept is borrowed from past research in sociology and extended in our paper for directed social networks. Our proposed trust management framework is hybrid because: (1) P-NO is applied on a social graph that is generated from two types of social networks — the IoT device owners’ online social network (like Facebook) and the IoT-devices’ social network (i.e. the SIoT network). Accordingly, the approach makes use of both human intelligence and device artificial intelligence for trust management. (2) The framework uses a mix of dynamic ( interaction-based ) and static ( graph-based ) approach for trust management. It helps in limiting resource overheads of a pure dynamic approach, while still benefiting from its higher accuracy compared to a pure-static approach. We provide both theoretical and simulation-based analysis of our trust management framework. Our study shows the effectiveness of the proposed framework in handling different attack scenarios while requiring limited storage and computational resources in IoT devices.},
  archive      = {J_COMCOM},
  author       = {Nishit Narang and Subrat Kar},
  doi          = {10.1016/j.comcom.2021.02.015},
  journal      = {Computer Communications},
  pages        = {61-79},
  shortjournal = {Comput. Commun.},
  title        = {A hybrid trust management framework for a multi-service social IoT network},
  volume       = {171},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Web service discovery based on maximum weighted bipartite
graphs. <em>COMCOM</em>, <em>171</em>, 54–60. (<a
href="https://doi.org/10.1016/j.comcom.2021.01.031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Web service discovery is the process that service requestor or user finds services to meet their requirements, its core technologies include Web service description language and the service matching algorithm . Duo to services with more ambiguity, using service-oriented computing in the process of finding service without strong restriction can cause some error services which have the same background but not satisfy the initial request returned. In order to eliminate the effect of this kind of situation in service-oriented computing, we present a novel approach for Web service retrieval based on the evaluation of similarity between Web service interfaces . The algorithm automatically distributes the keyword weights for the request service, in order to weaken the weight of some keywords in request service have the same background in services set, which is to help the request service find the more accurate results. The experiments show that our solution outperforms some searching methods.},
  archive      = {J_COMCOM},
  author       = {Kuo Chen and Cuiping Kuang},
  doi          = {10.1016/j.comcom.2021.01.031},
  journal      = {Computer Communications},
  pages        = {54-60},
  shortjournal = {Comput. Commun.},
  title        = {Web service discovery based on maximum weighted bipartite graphs},
  volume       = {171},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Don’t interrupt me when you reconfigure my service function
chains. <em>COMCOM</em>, <em>171</em>, 39–53. (<a
href="https://doi.org/10.1016/j.comcom.2021.02.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Software Defined Networking (SDN) and Network Function Virtualization (NFV) are complementary and core components of modernized networks. In this paper, we consider the problem of reconfiguring Service Function Chains (SFC) with the goal of bringing the network from a sub-optimal to an optimal operational state. We propose optimization models based on the make-before-break mechanism, in which a new path is set up before the old one is torn down. Our method takes into consideration the chaining requirements of the flows and scales well with the number of nodes in the network. We show that, with our approach, the network operational cost defined in terms of both bandwidth and installed network function costs can be reduced and a higher acceptance rate can be achieved, while not interrupting the flows.},
  archive      = {J_COMCOM},
  author       = {Adrien Gausseran and Andrea Tomassilli and Frederic Giroire and Joanna Moulierac},
  doi          = {10.1016/j.comcom.2021.02.008},
  journal      = {Computer Communications},
  pages        = {39-53},
  shortjournal = {Comput. Commun.},
  title        = {Don’t interrupt me when you reconfigure my service function chains},
  volume       = {171},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An efficient medium access control protocol for RF energy
harvesting based IoT devices. <em>COMCOM</em>, <em>171</em>, 28–38. (<a
href="https://doi.org/10.1016/j.comcom.2021.02.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Energy efficiency is one of the major challenges in IEEE 802.15.4 based Internet of Things (IoT). In the Medium Access Control (MAC) layer of the IEEE 802.15.4 standard, Guaranteed Time Slot (GTS) are allocated to the IoT devices for data transmission. However, GTS allocation does not consider residual energy of IoT devices resulting in reduced life cycle of these devices. In this paper, we propose an efficient MAC protocol for RF harvesting based IoT devices. The proposed protocol uses residual energy based duty cycle adaptation to prioritize transmission of high energy devices, allowing low energy devices to harvest energy in the mean time. Simulation results show that the life cycle and transmitted data of IoT devices is improved up to 94\% and 79\% respectively by using the proposed protocol, as compared to the IEEE 802.15.4 standard.},
  archive      = {J_COMCOM},
  author       = {Sangrez Khan and Ahmad Naseem Alvi and Muhammad Awais Javed and Yasser D. Al-Otaibi and Ali Kashif Bashir},
  doi          = {10.1016/j.comcom.2021.02.011},
  journal      = {Computer Communications},
  pages        = {28-38},
  shortjournal = {Comput. Commun.},
  title        = {An efficient medium access control protocol for RF energy harvesting based IoT devices},
  volume       = {171},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). FAMOBACH: A fast and survivable workflow scheduling approach
based MOHEFT using backtacking and checkpointing. <em>COMCOM</em>,
<em>171</em>, 16–27. (<a
href="https://doi.org/10.1016/j.comcom.2021.02.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Workflows and workflow scheduling are increasingly used in many applications with many tasks and dependency constraints between these tasks. On the other hand, cloud computing offers huge opportunities to process large-scale workflows and data-intensive applications. The processing performance of a workflow is highly depending on how the different tasks are scheduled on the cloud’s resources. Workflow scheduling is still a challenging issue that falls into NP-hard problems category, for which finding an exact solution is intractable. Much research effort has gone into solving this problem, including multi-objective heterogeneous earliest-finish-time (MOHEFT) method, which turns to be a reference for the workflow scheduling problem. While demonstrating very high efficiency at the provided results quality, MOHEFT suffers from its high time complexity when it comes to large-scale workflows. To address this shortcoming, we first investigate MOHEFT complexity. Then, we propose FA st workflow scheduling approach based MO HEFT using BA cktraking and CH eckpointing (FAMOBACH). The latter is an improved version that eliminates redundant calculations in MOHEFT using checkpointing and backtacking. FAMOBACH performance evaluation depicts it runs up to 9 times faster than the MOHEFT.},
  archive      = {J_COMCOM},
  author       = {Mohammed Redha Bouzidi and Mourad Daoudi and Benameur Ziani and Kamel Boukhalfa and Chaker Abdelaziz Kerrache and Nasreddine Lagraa},
  doi          = {10.1016/j.comcom.2021.02.005},
  journal      = {Computer Communications},
  pages        = {16-27},
  shortjournal = {Comput. Commun.},
  title        = {FAMOBACH: A fast and survivable workflow scheduling approach based MOHEFT using backtacking and checkpointing},
  volume       = {171},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). System reliability evaluation using budget constrained real
d-MC search. <em>COMCOM</em>, <em>171</em>, 10–15. (<a
href="https://doi.org/10.1016/j.comcom.2021.02.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the network flow problems, it is the most challenging task to maintain the system reliability and high quality of service (QoS). Most of these networks are stochastic and ensuring optimal data flow under some constraints especially, budget and time, is a very challenging task. If the user’s data can be transferred within the budget then the network is called budget constrained stochastic flow network (SFN). The system reliability can be checked through minimal paths and minimal cuts in the network. In this paper, it is aimed to evaluate the system reliability of the budget constrained SFN with the help of minimal cuts in the network. The problem is to find out all the minimal cuts, such that d d units of data can be communicated within a specified budget B B . All the minimal cuts that satisfy budget constraint are employed for system reliability evaluation. From the results, it can be said that the proposed approach is much faster than the earlier approaches without any compromise in the network reliability.},
  archive      = {J_COMCOM},
  author       = {Suchi Kumari and Suyel Namasudra},
  doi          = {10.1016/j.comcom.2021.02.004},
  journal      = {Computer Communications},
  pages        = {10-15},
  shortjournal = {Comput. Commun.},
  title        = {System reliability evaluation using budget constrained real d-MC search},
  volume       = {171},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Improved design of low energy clustering algorithm for
mobile sensor network. <em>COMCOM</em>, <em>171</em>, 1–9. (<a
href="https://doi.org/10.1016/j.comcom.2021.01.034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {LEACH class clustering algorithms have been widely used in the topology control of mobile sensor networks because of their simplicity, practicality and good energy efficiency. Aiming at the common problems of LEACH clustering algorithm, such as large energy consumption of nodes, short network life cycle, easy loss of data transmission, etc., according to the set mobile sensor network model, based on LEACH-Mobile algorithm, a low-energy clustering algorithm LEACH-MII is designed. LEACH-MII clustering algorithm assigns tasks according to the working conditions of sensor nodes , combines the activity, location and energy consumption of nodes to select and rotate cluster heads ; and uses dynamic time slot allocation mechanism to avoid time slot reallocation caused by frequent join-cluster and leave-cluster of sensor nodes , so as to ensure the stability and connectivity of the network structure, reduce the energy consumption of nodes, and extend the life cycle of the network. In order to verify the feasibility and effectiveness of LEACH-MII clustering algorithm, the simulation experiment of LEACH-MII clustering algorithm is carried out. The simulation results show that The data transmission efficiency, average node energy consumption and network life cycle of LEACH-MII network are 30\%, 20\% and 15\% better than LEACH-Mobile network, respectively. In addition, the performance of LEACH-MII network is better than that of LEACH-Mobile network, such as the load balance degree, the scalability of network monitoring range, and the speed effect of network life cycle.},
  archive      = {J_COMCOM},
  author       = {Song Liu and Runlan Zhang and Yongheng Shi},
  doi          = {10.1016/j.comcom.2021.01.034},
  journal      = {Computer Communications},
  pages        = {1-9},
  shortjournal = {Comput. Commun.},
  title        = {Improved design of low energy clustering algorithm for mobile sensor network},
  volume       = {171},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A hybrid DL-driven intelligent SDN-enabled malware detection
framework for internet of medical things (IoMT). <em>COMCOM</em>,
<em>170</em>, 209–216. (<a
href="https://doi.org/10.1016/j.comcom.2021.01.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rise of Internet of Things (IoT) has envisioned smart connectivity of billions of varied devices with high computational and processing capabilities resulting in the evolution of Internet of Medical Things (IoMT). This radical increase in the digital landscape of IoMT that processes considerably large amount of valuable data is primarily a potential attack target for varied cyber adversaries . One of the most prevalent, sophisticated and new evolving cyber threats for IoT ecosystems are multifaceted malicious malwares . The authors propose a highly scalable hybrid (deep learning) DL-driven SDN-enabled framework for efficient and timely detection of sophisticated IoMT malwares . Further, the proposed framework leverages the underlying IoMT resource constrained devices without exhaustion. We employed state-of-the-art publicly available dataset for a comprehensive evaluation of the proposed mechanism. Further, standard metrics have been employed to rigorously evaluate the performance of the proposed technique. For verification purpose, we compare our proposed mechanism with our constructed hybrid DL-driven architectures comprised of state-of-the-art DL-algorithms and current benchmarks. The proposed scheme outperforms in terms of high detection accuracy and speed efficiency. We also employed 10-fold cross validation to explicitly show unbiased results.},
  archive      = {J_COMCOM},
  author       = {Soneila Khan and Adnan Akhunzada},
  doi          = {10.1016/j.comcom.2021.01.013},
  journal      = {Computer Communications},
  pages        = {209-216},
  shortjournal = {Comput. Commun.},
  title        = {A hybrid DL-driven intelligent SDN-enabled malware detection framework for internet of medical things (IoMT)},
  volume       = {170},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Blockchain-based lamport merkle digital signature:
Authentication tool in IoT healthcare. <em>COMCOM</em>, <em>170</em>,
200–208. (<a
href="https://doi.org/10.1016/j.comcom.2021.02.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Internet of Things (IoT) includes medical devices, servers, and applications linked using computer networks to collect and share data. Recently there is a massive surge in IoT-enabled applications, especially in the medical field. Medical devices, like intravenous pumps, Magnetic Resonance Imaging (MRI) machines, infusion pumps, and ventilators, are connected with the hospital networks to enhance the quality and efficiency of delivering medical care. Integrated with the cloud server, IoT improves patients’ lifestyles and minimizes the time and cost by efficiently managing the medical resources. However, due to the presence of malicious users, sensitive patient data is often compromised. Motivated and driven by these factors, this work proposes a blockchain-assisted highly secure system for medical IoT devices using Lamport Merkle Digital Signature (LMDS). Initially, the Lamport Merkle Digital Signature Generation (LMDSG) model performs the task of authenticating IoT devices by constructing a tree in which the leaves symbolize sensitive patient medical data’s hash function . Further, a Centralized Healthcare Controller (CHC) performs the task of determining the root of the LMDSG by using Lamport Merkle Digital Signature Verification (LMDSV). In this verification process , when the hash of the public key ‘ p b k e y ′ pbkey′ is equal to leaf ‘ P g n Pgn ’, then it is the root of the tree, and the signature is valid. In this way, the proposed LMDS technique efficiently identifies malicious user behavior with minimum Computational Overhead (CO) and Computational Time (CT). The proposed LMDS technique’s performance is analyzed in terms of CO, CT, and authentication accuracy. The experimental analysis proves that the proposed LMDS technique ensures higher security and minimum CT and CO in medical IoT systems than other existing methods.},
  archive      = {J_COMCOM},
  author       = {Jafar A. Alzubi},
  doi          = {10.1016/j.comcom.2021.02.002},
  journal      = {Computer Communications},
  pages        = {200-208},
  shortjournal = {Comput. Commun.},
  title        = {Blockchain-based lamport merkle digital signature: Authentication tool in IoT healthcare},
  volume       = {170},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Public key encryption supporting equality test and flexible
authorization without bilinear pairings. <em>COMCOM</em>, <em>170</em>,
190–199. (<a
href="https://doi.org/10.1016/j.comcom.2021.02.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Public key encryption with equality test (PKEET) is an important cryptographic primitive for protecting users’ outsourced data in the cloud-based email systems. Due to the fact that it is required to deploy different authorization policies for the demand of dynamic privacy protection in the cloud-based email systems, Ma et al. recently presented a new related primitive, called public key encryption with equality test supporting flexible authorization (PKEET-FA). In their proposal, four types of authorization were considered to support different authorization policies . Their proposal is based on the bilinear pairings . However, as the basic operation of equality test, bilinear pairings are expensive operations compared with modular multiplications and modular inverses. Hence, it is desired to propose a new method for constructing efficient equality test with modular multiplications and modular inverses. In this paper, we present such a PKEET-FA scheme. Compared with Ma et al.’s, our proposal is (surprisingly) more efficient, especially in terms of equality test. Moreover, our proposal supports an additional type of authorization, called user-specific ciphertext-to-user (or user-specific user-to-ciphertext) level authorization . Hence, ours is more flexible than Ma et al.’s.},
  archive      = {J_COMCOM},
  author       = {Xi-Jun Lin and Lin Sun and Haipeng Qu and Xiaoshuai Zhang},
  doi          = {10.1016/j.comcom.2021.02.006},
  journal      = {Computer Communications},
  pages        = {190-199},
  shortjournal = {Comput. Commun.},
  title        = {Public key encryption supporting equality test and flexible authorization without bilinear pairings},
  volume       = {170},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Online available bandwidth estimation using multiclass
supervised learning techniques. <em>COMCOM</em>, <em>170</em>, 177–189.
(<a href="https://doi.org/10.1016/j.comcom.2021.02.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to answer how much bandwidth is available to an application from one end to another in a network, state-of-the-art estimation techniques, based on active probing, inject artificial traffic with a known structure into the network. At the receiving end, the available bandwidth is estimated by measuring the structural changes in the injected traffic, which are caused by the network path. However, bandwidth estimation becomes difficult when packet distributions are distorted by non-fluid bursty cross traffic and multiple links. This eventually leads to an estimation bias. One known approach to reduce the bias in bandwidth estimations is to probe a network with constant-rate packet trains and measure the average structural changes in them. However, one cannot increase the number of packet trains in a designated time period as much as needed because high probing intensity overloads the network and results in packet losses in probe and cross traffic, which distorts probe packet gaps and inflicts more bias. In this work, we propose a machine learning-based, particularly classification-based, method that provides reliable estimates utilizing fewer packet trains. Then, we implement supervised learning techniques. Furthermore, considering the correlated changes over time in traffic in a network, we apply filtering techniques on estimation results in order to track the changes in the available bandwidth. We set up an experimental testbed using the Emulab software and a dumbbell topology in order to create training and testing data for performance analysis. Our results reveal that our proposed method identifies the available bandwidth significantly well in single-link networks as well as networks with heavy cross traffic burstiness and multiple links. It is also able to estimate the available bandwidth in randomly generated networks where the network capacity and the cross traffic intensity vary substantially. We also compare our technique with the others that use direct probing and regression approaches, and show that ours has better performance in terms of standard deviation around the actual bandwidth values.},
  archive      = {J_COMCOM},
  author       = {Sukhpreet Kaur Khangura and Sami Akın},
  doi          = {10.1016/j.comcom.2021.02.009},
  journal      = {Computer Communications},
  pages        = {177-189},
  shortjournal = {Comput. Commun.},
  title        = {Online available bandwidth estimation using multiclass supervised learning techniques},
  volume       = {170},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Efficient forwarding strategy in HDRP protocol based
internet of things. <em>COMCOM</em>, <em>170</em>, 164–176. (<a
href="https://doi.org/10.1016/j.comcom.2021.02.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Internet of Things (IoT) includes a variety of heterogeneous wireless network technologies such as Delay Tolerant Networks (DTN) and all kinds of smart devices connected over a wireless network. The strong size and cost constraints of DTN nodes lead to corresponding constraints on resources such as energy, memory, communication speed and bandwidth, which in turn limits the contact between DTN nodes. DTN has emerged as a promising new network paradigm that aims to cope with the increasing number of heterogeneous networks and the need for efficient and robust data dissemination to be more stable. But one of the hindering bottlenecks the full applicability of such a DTN-based approach to the IoT, is that forwarding data in an environment could lose when the connection between nodes is intermittent. In this paper, we propose an effective bundle forwarding strategy for the IoT environment in which we control the number of bundle replications to balance energy consumption on the network. Simulation results demonstrate that the proposed solution performs better than other methods in terms of delivery delay and delivery rate (roughly 18\% improvement).},
  archive      = {J_COMCOM},
  author       = {Stephane Cedric Koumetio Tekouabou and El Arbi Abdellaoui Alaoui and Antoine Gallais},
  doi          = {10.1016/j.comcom.2021.02.003},
  journal      = {Computer Communications},
  pages        = {164-176},
  shortjournal = {Comput. Commun.},
  title        = {Efficient forwarding strategy in HDRP protocol based internet of things},
  volume       = {170},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Performance evaluation of attribute-based encryption on
constrained IoT devices. <em>COMCOM</em>, <em>170</em>, 151–163. (<a
href="https://doi.org/10.1016/j.comcom.2021.02.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Internet of Things (IoT) is enabling a new generation of innovative services based on the seamless integration of smart objects into information systems. This raises new security and privacy challenges that require novel cryptographic methods. Attribute-Based Encryption (ABE) is a type of public-key encryption that enforces a fine-grained access control on encrypted data based on flexible access policies. The feasibility of ABE adoption in fully-fledged computing systems, i.e., smartphones or embedded systems , has been demonstrated in recent works. In this paper, we consider IoT devices characterized by strong limitations in terms of computing, storage, and power. Specifically, we assess the performance of ABE in typical IoT constrained devices. We evaluate the performance of three representative ABE schemes configured considering the worst-case scenario on two popular IoT platforms, namely ESP32 and RE-Mote. Our results show that, if we assume to employ up to 10 attributes in ciphertexts and to leverage hardware cryptographic acceleration, then ABE can indeed be adopted on devices with very limited memory and computing power, while obtaining a satisfactory battery lifetime. In our experiments, as also performed in other works in the literature, we consider only the worst-case configuration, which, however, might not be completely representative of the real working conditions of sensors employing ABE. For this reason, we complete our evaluation by proposing a novel benchmark method that we used to complement the experiments by evaluating the average performance. We show that by always considering the worst case, the current literature significantly overestimates the processing time and the energy consumption.},
  archive      = {J_COMCOM},
  author       = {Pericle Perazzo and Francesca Righetti and Michele La Manna and Carlo Vallati},
  doi          = {10.1016/j.comcom.2021.02.012},
  journal      = {Computer Communications},
  pages        = {151-163},
  shortjournal = {Comput. Commun.},
  title        = {Performance evaluation of attribute-based encryption on constrained IoT devices},
  volume       = {170},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A delay-sensitive resource allocation algorithm for
container cluster in edge computing environment. <em>COMCOM</em>,
<em>170</em>, 144–150. (<a
href="https://doi.org/10.1016/j.comcom.2021.01.020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of lightweight container virtualization technology , it becomes possible to quickly and efficiently deploy software in edge computing environments. When allocating resources to containers in edge nodes, end-to-end latency is an important performance indicator for evaluating strategies. However, it is often difficult to develop a delay model of the container cluster to obtain the real-time end-to-end delay of the service request flow. The state information is always extremely complicated in edge computing environment. Different container service combinations reach edge computing nodes at different time periods. The arrival rate of each container service flow also changes over time. In this paper, we first develop a dynamic M/D/1 queuing model to analyze the end-to-end delay of the data packets of the container service flow and use the average packet delay as the optimization goal of the Edge container resource allocation problem . Then a delay-sensitive resource allocation algorithm based on A3C (Asynchronous Advantage Actor–Critic) is proposed to solve this problem. Finally, we utilize the ESN (Echo state network) to improve the traditional A3C algorithm. Simulation shows that the ESN-based critic A3C(EC-A3C) algorithm has better performance by at least 10.9\% than other algorithms in terms of latency and throughput and greatly improves the convergence speed of the network.},
  archive      = {J_COMCOM},
  author       = {Shaoyong Guo and Keqin Zhang and Bei Gong and Wenchen He and Xuesong Qiu},
  doi          = {10.1016/j.comcom.2021.01.020},
  journal      = {Computer Communications},
  pages        = {144-150},
  shortjournal = {Comput. Commun.},
  title        = {A delay-sensitive resource allocation algorithm for container cluster in edge computing environment},
  volume       = {170},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The anomaly detection mechanism using deep learning in a
limited amount of data for fog networking. <em>COMCOM</em>,
<em>170</em>, 130–143. (<a
href="https://doi.org/10.1016/j.comcom.2021.01.036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The treatment of brain ischemia is the use of tissue plasminogen activator. But after treatment there may be a risk of Brain hemorrhage. Under the pressure of rescue time, medical personnel and their families must make decisions. There is currently no benchmark that can provide what can happen after treatment. This is because there are too many uncertainties. This study proposes that an adaptive deep autoencoder model is used to learn the features of a particular data and analyze the results that the data belongs to. For data preprocessing , the study also proposes methods such as K-means and connecting and labeling non-background areas to de-noise the image and preserve the desired areas to the maximum extent. In addition, we use Variational AutoEncoder Wasserstein Generative Adversarial Network with Gradient Penalty (VAE WGAN-GP) to generate 3D medical images to solve the problem of too few training data. We study key techniques such as pre-processing of real data and image generation with limited real data, so that the model can be trained smoothly. From our experiments, we found that the autoencoder model analyzes real data that is bleeding and non-bleeding and achieves 76\% accuracy.},
  archive      = {J_COMCOM},
  author       = {Gwo-Jiun Horng and Min-Xiang Liu and Chien-Chin Hsu},
  doi          = {10.1016/j.comcom.2021.01.036},
  journal      = {Computer Communications},
  pages        = {130-143},
  shortjournal = {Comput. Commun.},
  title        = {The anomaly detection mechanism using deep learning in a limited amount of data for fog networking},
  volume       = {170},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A review on p4-programmable data planes: Architecture,
research efforts, and future directions. <em>COMCOM</em>, <em>170</em>,
109–129. (<a
href="https://doi.org/10.1016/j.comcom.2021.01.027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Software Defined Networking (SDN) is a promising technology that provides flexibility, programmability , and network automation by shifting the network intelligence to the logically centralized controller . In SDN architecture, the controller maintains the global view of network topology ; therefore the network management is efficient as compared to the traditional networks. Moreover, the cost of SDN devices is less due to the use of open source network operating system instead of proprietary and vendor-specific software. In spite of the flexibility offered by the SDN, OpenFlow enabled switches have a fixed behavior as specified in the datasheet of switch ASIC . They recognize fixed set of header fields according to the support of OpenFlow version. In addition, SDN is suffering from scalability and performance issues because SDN switches heavily dependent on the control plane to forward the packets which increases the data-control communication overhead . To resolve these issues, P4-Programmable data plane switches can be used. The analysis of review articles about SDN suggests insufficient focus on the data plane programmability . Therefore, this paper provides the comprehensive overview of domain-specific language (P4) for the programmability of the data plane. We have discussed the problems in the traditional SDN architecture and then, how these problems can be managed by the data plane programmability. Further, this study critically analyze the research articles based on the P4 programming language for network traffic monitoring, DDoS attack detection, load balancing, and packet aggregation and disaggregation. Finally, we have identified the research gaps and highlighted the open research challenges in the field of data plane programmability for the future directions.},
  archive      = {J_COMCOM},
  author       = {Sukhveer Kaur and Krishan Kumar and Naveen Aggarwal},
  doi          = {10.1016/j.comcom.2021.01.027},
  journal      = {Computer Communications},
  pages        = {109-129},
  shortjournal = {Comput. Commun.},
  title        = {A review on p4-programmable data planes: Architecture, research efforts, and future directions},
  volume       = {170},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Fly-path: Traffic-based multi-hop routing approach for
hybrid wireless data centers. <em>COMCOM</em>, <em>170</em>, 95–108. (<a
href="https://doi.org/10.1016/j.comcom.2020.12.029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High data transfer rates achieved by 802.11ad at 60 GHz ISM band enables use of wireless communication in data centers . In this paper, we investigate the possibility of offloading traffic from wired to wireless network in hybrid data centers . By understanding the capabilities of the wireless network, we can design the hybrid data center network accordingly, to achieve better construction and operating efficiency. First, we propose a system model in which each top-of-the-rack switch is equipped with two radios, so that three non-overlapping channels of 802.11ad that are available worldwide can be assigned in an interference-free manner to any configuration of wireless links . Then, we propose multi-hop routing algorithms that assign traffic to wireless infrastructure . These algorithms consist of two families. SP family of algorithms route traffic only over shortest-paths between source and destination pairs. LP algorithms relax this restriction and assign traffic to longer paths when necessary. In order to evaluate the performance of our routing algorithms , we also propose a random data center traffic generation method, based on an analysis of a real-world data center traffic pattern. We evaluate the performance of our allocation methods in terms of different metrics for various network sizes. Results show that our methods can offload significant amount of traffic from wired to wireless network, can achieve quite high throughput , and can utilize wireless links very well.},
  archive      = {J_COMCOM},
  author       = {Cem Mergenci and Ibrahim Korpeoglu},
  doi          = {10.1016/j.comcom.2020.12.029},
  journal      = {Computer Communications},
  pages        = {95-108},
  shortjournal = {Comput. Commun.},
  title        = {Fly-path: Traffic-based multi-hop routing approach for hybrid wireless data centers},
  volume       = {170},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Virtual care for cyber–physical systems (VH_CPS): NODE-RED,
community of practice and thick data analytics ecosystem.
<em>COMCOM</em>, <em>170</em>, 84–94. (<a
href="https://doi.org/10.1016/j.comcom.2021.01.029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Virtual care is changing from the mere Face-to-Face Services, which includes telephone visits in addition to audio and video visits to include several non Face-to-Face Services, including E-visits, community of practice consultations and remote Patient Monitoring (RPM). Virtual care has the capacity to transform how people interact and collaborate with each other using the cyber–physical systems’ services. However, the use of cyber–physical​ systems (CPS) in healthcare is still in its infancy and there exist many challenges to be solved. The future of virtual care based on CPS will be require the availability of an ecosystem that leverages range of technologies to enable care to shift away from the legacy clinical setting when appropriate. In order to provide such open loop type of connectivity and interfacing, this article presents a solution VH_CPS ecosystem that push beyond the telehealth visit to create an ecosystem that integrates the care team collaboration with other essential virtual services such as remote monitoring and diagnostics as well as chronic care management services. Moreover, this article incorporate at VH_CPS ecosystem a component that enables the care team to assist in driving more in depth analytics based on qualitative techniques borrowed from the paradigm of thick data analytics . The Siamese Neural Network used in this paper is an example where care team members like a radiologist can feed few labelled CT-Scans to let the decision making component of the VH_CPS to learn the diagnosis of COVID cases. Our VH_CPS ecosystem uses a scalable Node-RED framework with the care team as well as to the remote patient monitoring devices. Our ecosystem will enable more patients to access the care they need, keep more patients in a low-risk care setting, and contribute to better outcomes at lower costs.},
  archive      = {J_COMCOM},
  author       = {Jinan Fiaidhi and Sabah Mohammed},
  doi          = {10.1016/j.comcom.2021.01.029},
  journal      = {Computer Communications},
  pages        = {84-94},
  shortjournal = {Comput. Commun.},
  title        = {Virtual care for cyber–physical systems (VH_CPS): NODE-RED, community of practice and thick data analytics ecosystem},
  volume       = {170},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Spatial reuse in IEEE 802.11ax WLANs. <em>COMCOM</em>,
<em>170</em>, 65–83. (<a
href="https://doi.org/10.1016/j.comcom.2021.01.028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dealing with massively crowded scenarios is one of the most ambitious goals of next-generation wireless networks. With this goal in mind, the IEEE 802.11ax amendment includes, among other techniques, the Spatial Reuse (SR) operation. The SR operation encompasses a set of unprecedented techniques that are expected to significantly boost Wireless Local Area Networks (WLANs) performance in dense environments . In particular, the main objective of the SR operation is to maximize the utilization of the medium by increasing the number of parallel transmissions. Nevertheless, due to the novelty of the operation, its performance gains remain largely unknown. In this paper, we first provide a gentle tutorial of the SR operation included in the IEEE 802.11ax. Then, we analytically model SR and delve into the new kinds of MAC-level interactions among network devices. Finally, we provide a simulation-driven analysis to showcase the potential of SR in various deployments, comprising different network densities and traffic loads. Our results show that the SR operation can significantly improve the medium utilization, especially in scenarios under high interference conditions. Moreover, our results demonstrate the non-intrusive design characteristic of SR, which allows enhancing the number of simultaneous transmissions with a low impact on the environment. We conclude the paper by giving some thoughts on the main challenges and limitations of the IEEE 802.11ax SR operation, including research gaps and future directions.},
  archive      = {J_COMCOM},
  author       = {Francesc Wilhelmi and Sergio Barrachina-Muñoz and Cristina Cano and Ioannis Selinis and Boris Bellalta},
  doi          = {10.1016/j.comcom.2021.01.028},
  journal      = {Computer Communications},
  pages        = {65-83},
  shortjournal = {Comput. Commun.},
  title        = {Spatial reuse in IEEE 802.11ax WLANs},
  volume       = {170},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Towards an energy balancing solution for wireless sensor
network with mobile sink node. <em>COMCOM</em>, <em>170</em>, 50–64. (<a
href="https://doi.org/10.1016/j.comcom.2021.01.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The issue of energy holes, or hotspots , in wireless sensor networks is well referenced. As is the proposed mobilisation of the sink node in order to combat this. However, as the mobile sink node may communicate with some nodes more than others, issues remain, such as energy spikes. In this study we propose a lightweight MAC layer solution — Dynamic Mobility and Energy Aware Algorithm (DMEAAL). Building on existing solutions utilising a communication threshold between static nodes and a sink node using a predictable mobility pattern, DMEAAL takes knowledge of optimum energy consumption levels and implements a cross-layer approach, utilising current energy consumption and dynamically adjusting communication threshold size based on target energy consumption. This approach is shown to balance energy consumption across individual nodes without increasing overall energy consumption compared to previous solutions. This without detrimentally affecting frame delivery to the sink. As such, network lifetime is improved. In addition we propose Mobile Edge Computing (MEC) applications for this solution, removing certain functionality from static nodes and instead deploying this within the mobile sink at the network edge.},
  archive      = {J_COMCOM},
  author       = {Craig Thomson and Isam Wadhaj and Zhiyuan Tan and Ahmed Al-Dubai},
  doi          = {10.1016/j.comcom.2021.01.011},
  journal      = {Computer Communications},
  pages        = {50-64},
  shortjournal = {Comput. Commun.},
  title        = {Towards an energy balancing solution for wireless sensor network with mobile sink node},
  volume       = {170},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Spectral efficiency analysis and optimal power allocation
for uplink multi-user cell-free massive MIMO networks employing STBCs.
<em>COMCOM</em>, <em>170</em>, 42–49. (<a
href="https://doi.org/10.1016/j.comcom.2021.01.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Massive MIMO is a key technique in the fifth generation (5G) of wireless networks. This technique, by increasing base station (BS) antennas and exploiting spatial diversity , improves system performance in terms of common criteria such as spectral efficiency. Cell free massive MIMO is considered for 6G mobile communications to overcome the shortcomings associated with the cellular design. In this system, BS antennas are distributed across the system environment and provide uniform service to all users. Also, space time block codes (STBCs) can be used to improve the diversity gain and reliability of the system. In this paper, a cell free massive MIMO system is investigated in the uplink considering effects of channel estimation errors . Users are equipped with two antennas and employ STBC. Lower bound of spectral efficiency is derived for the zero forcing (ZF) and maximal ratio combining (MRC) decoders. Furthermore, spectral efficiency is compared for dual and single antenna users. Moreover, two power control problems are defined based on minimizing the total transmit power and maximizing the minimum rate of the users. Also, an algorithm is proposed for removing the inefficient BSs in the network. The proposed theoretical ideas are evaluated via numerical simulations.},
  archive      = {J_COMCOM},
  author       = {Akbar Mazhari Saray and Jafar Pourrostam},
  doi          = {10.1016/j.comcom.2021.01.009},
  journal      = {Computer Communications},
  pages        = {42-49},
  shortjournal = {Comput. Commun.},
  title        = {Spectral efficiency analysis and optimal power allocation for uplink multi-user cell-free massive MIMO networks employing STBCs},
  volume       = {170},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Deep learning for network traffic monitoring and analysis
(NTMA): A survey. <em>COMCOM</em>, <em>170</em>, 19–41. (<a
href="https://doi.org/10.1016/j.comcom.2021.01.021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modern communication systems and networks, e.g., Internet of Things (IoT) and cellular networks , generate a massive and heterogeneous amount of traffic data. In such networks, the traditional network management techniques for monitoring and data analytics face some challenges and issues, e.g., accuracy, and effective processing of big data in a real-time fashion. Moreover, the pattern of network traffic, especially in cellular networks, shows very complex behavior because of various factors, such as device mobility and network heterogeneity. Deep learning has been efficiently employed to facilitate analytics and knowledge discovery in big data systems to recognize hidden and complex patterns. Motivated by these successes, researchers in the field of networking apply deep learning models for Network Traffic Monitoring and Analysis (NTMA) applications, e.g., traffic classification and prediction. This paper provides a comprehensive review on applications of deep learning in NTMA. We first provide fundamental background relevant to our review. Then, we give an insight into the confluence of deep learning and NTMA, and review deep learning techniques proposed for NTMA applications. Finally, we discuss key challenges, open issues, and future research directions for using deep learning in NTMA applications.},
  archive      = {J_COMCOM},
  author       = {Mahmoud Abbasi and Amin Shahraki and Amir Taherkordi},
  doi          = {10.1016/j.comcom.2021.01.021},
  journal      = {Computer Communications},
  pages        = {19-41},
  shortjournal = {Comput. Commun.},
  title        = {Deep learning for network traffic monitoring and analysis (NTMA): A survey},
  volume       = {170},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A lightweight mutual authentication and key agreement
protocol for remote surgery application in tactile internet environment.
<em>COMCOM</em>, <em>170</em>, 1–18. (<a
href="https://doi.org/10.1016/j.comcom.2021.01.025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The emergence of the fifth generation (5G) networks has revolutionized the cyberspace due to its ultra-low latency, huge capacity, higher data rate, and more reliable connections. One of such technological innovations is Tactile Internet which means remotely transmitting a physical sense of touch. Tactile Internet supports a number of realtime interaction applications such as augmented reality , virtual reality, gaming, smart grid, and ehealthcare. In the context of ehealthcare, Tactile Internet allows a surgeon to remotely operate a patient by implementing some control actions via a robotic system and receiving a haptic feedback. Although, the ultimate goal of this auspicious technology is to safe human lives, the aim may be jeopardized if proper security measures are not implemented. Any unauthorized access to the robotic system may lead to wrong surgical procedures that can cause havoc or even result to death. To this end, we develop an ultraefficient mutual authentication and key agreement protocol for Tactile Internet-assisted remote surgery application. The protocol is designed using a few cryptographic hash function and exclusive-OR operations. The security of the proposed protocol is demonstrated formally using Real-Or-Random (ROR) model, formal security verification using Automated Verification of Internet Security Protocols and Applications (AVISPA) toolkit and the generally-acknowledged Burrows–Abadi–Nedham (BAN) Logic, and information security analysis to corroborate the results of the formal security analyses. The functionality comparison and numerical analysis show the superiority of the proposed protocol over the state-of-the-art schemes. The experimental simulation reveals that the protocol is very efficient and suitable for practical deployment.},
  archive      = {J_COMCOM},
  author       = {Ismaila Adeniyi Kamil and Sunday Oyinlola Ogundoyin},
  doi          = {10.1016/j.comcom.2021.01.025},
  journal      = {Computer Communications},
  pages        = {1-18},
  shortjournal = {Comput. Commun.},
  title        = {A lightweight mutual authentication and key agreement protocol for remote surgery application in tactile internet environment},
  volume       = {170},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The prediction model for residence based on reliability in
social network. <em>COMCOM</em>, <em>169</em>, 243–249. (<a
href="https://doi.org/10.1016/j.comcom.2021.01.030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Currently, the implementation judge often encounter such tough problems the person subject to enforcement usually change residence in secret to avoid execution. This problem has become a major obstacle for the courts in the process of law enforcement. Many research results indicated that the predictors based on the person’s social network for simulate his behavior will be accurate. Consequently, this paper proposes a PLRU (predict Location Based on the Reliability of Social-online Users) model improving the execution efficiency of the court to the dishonest person subject to enforcement. We estimates and filters the trust degree of the relevant in social network, and then this paper presents the DDA (Density based late Differential Allocation) model to estimate the weight of the text in social conversation about the dimension of residence. Finally, the prediction range of the residence is obtained while combining with the person profile though the historical residence of the person subject to enforcement. The experiments reveal that the accuracy of the model is greatly improved compared with other models while it is well recognized by the executive judges of the court.},
  archive      = {J_COMCOM},
  author       = {Bin Zhang and Yanglan Fu and Jing Li and Zhou Ye},
  doi          = {10.1016/j.comcom.2021.01.030},
  journal      = {Computer Communications},
  pages        = {243-249},
  shortjournal = {Comput. Commun.},
  title        = {The prediction model for residence based on reliability in social network},
  volume       = {169},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Increasing energy efficiency of massive-MIMO network via
base stations switching using reinforcement learning and radio
environment maps. <em>COMCOM</em>, <em>169</em>, 232–242. (<a
href="https://doi.org/10.1016/j.comcom.2021.01.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Energy Efficiency (EE) is of high importance while considering Massive Multiple-Input Multiple-Output (M-MIMO) networks where base stations (BSs) are equipped with an antenna array composed of up to hundreds of elements. M-MIMO transmission, although highly spectrally efficient, results in high energy consumption growing with the number of antennas. This paper investigates EE improvement through switching on/off underutilized BSs. It is proposed to use the location-aware approach, where data about an optimal active BSs set is stored in a Radio Environment Map (REM). For efficient acquisition, processing and utilization of the REM data, reinforcement learning (RL) algorithms are used. State-of-the-art exploration/exploitation methods including ϵ ϵ -greedy, Upper Confidence Bound (UCB), and Gradient Bandit are evaluated. Then analytical action filtering, and an REM-based Exploration Algorithm (REM-EA) are proposed to improve the RL convergence time. Algorithms are evaluated using an advanced, system-level simulator of an M-MIMO Heterogeneous Network (HetNet) utilizing an accurate 3D-ray-tracing radio channel model. The proposed RL-based BSs switching algorithm is proven to provide 70\% gains in EE over a state-of-the-art algorithm using an analytical heuristic. Moreover, the proposed action filtering and REM-EA can reduce RL convergence time in relation to the best-performing state-of-the-art exploration method by 60\% and 83\%, respectively.},
  archive      = {J_COMCOM},
  author       = {Marcin Hoffmann and Paweł Kryszkiewicz and Adrian Kliks},
  doi          = {10.1016/j.comcom.2021.01.012},
  journal      = {Computer Communications},
  pages        = {232-242},
  shortjournal = {Comput. Commun.},
  title        = {Increasing energy efficiency of massive-MIMO network via base stations switching using reinforcement learning and radio environment maps},
  volume       = {169},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An experimental study of the performance of IEEE 802.11ad in
smartphones. <em>COMCOM</em>, <em>169</em>, 220–231. (<a
href="https://doi.org/10.1016/j.comcom.2021.01.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present the first extensive measurement study of the performance of the 60 GHz 802.11ad technology on commercial smartphones. We focus on five major perspectives: (i) TCP throughput and communication range in static scenarios, (ii) spatial and temporal variations, (iii) coverage, (iv) performance under realistic smartphone user mobility patterns, and (v) impact of human blockage. We also compare for the first time 802.11ad against its two main competitors in the 5 GHz band: the state-of-the-art 802.11ac and the upcoming 802.11ax, which also promises multi-Gbps data rates. Finally, we present a preliminary evaluation of the 802.11ad power consumption on a smartphone under Gbps data rates. Overall, our results show that, in spite of earlier concerns, 802.11ad has higher potential to address the needs of emerging bandwidth-intensive applications in smartphones than its 5 GHz counterparts. At the same time, our study identifies several open challenges and key research directions towards fully realizing this potential for future smartphone users.},
  archive      = {J_COMCOM},
  author       = {Shivang Aggarwal and Moinak Ghoshal and Piyali Banerjee and Dimitrios Koutsonikolas},
  doi          = {10.1016/j.comcom.2021.01.006},
  journal      = {Computer Communications},
  pages        = {220-231},
  shortjournal = {Comput. Commun.},
  title        = {An experimental study of the performance of IEEE 802.11ad in smartphones},
  volume       = {169},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Fostering secure cross-layer collaborative communications by
means of covert channels in MEC environments. <em>COMCOM</em>,
<em>169</em>, 211–219. (<a
href="https://doi.org/10.1016/j.comcom.2021.01.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, due to unexpected conditions introduced by the COVID-19 outbreak, collaborative tools are widely adopted in almost all sectors of our daily lifestyle. Almost all tools rely mainly on the World Wide Web technologies that, in turn, are built upon the HTTP protocol. The HTTP protocol is considered as the “bricks” of all kind of communications among people/devices that exchange messages with different purposes and meanings. Unfortunately, it is widely used to track and monitor people when using the Internet. This paper exploits the HTTP protocol and try to reverse this negative aspect by designing and implementing a way to help users (and devices) to not disclose too much information when collaborating each other even in an unfriendly environment. A novel steganographic protocol is proposed by using the HTTP “control” messages. The proposed protocol can be easily adopted by devices communicating in a MEC (Mobile Edge Computing) environment where it is important to guarantee the integrity and the confidentiality of all communications, especially messages that give “instructions” to devices or in device-to-device communications. The proposed protocol allows to avoid using complex and computationally demanding cryptographic protocols that are very difficult to be used in devices with limited resources.},
  archive      = {J_COMCOM},
  author       = {Aniello Castiglione and Michele Nappi and Fabio Narducci and Chiara Pero},
  doi          = {10.1016/j.comcom.2021.01.007},
  journal      = {Computer Communications},
  pages        = {211-219},
  shortjournal = {Comput. Commun.},
  title        = {Fostering secure cross-layer collaborative communications by means of covert channels in MEC environments},
  volume       = {169},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Novel congestion avoidance scheme for internet of drones.
<em>COMCOM</em>, <em>169</em>, 202–210. (<a
href="https://doi.org/10.1016/j.comcom.2021.01.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Internet of Drones (IoDs) is getting growing interest of researchers due to its applicability in wide range of applications for transportation, weather monitoring, emergency monitoring for flood, earth quake, healthcare and road hazards. To update the data about emergency situation, a real-time data sharing is mandatory. However, regular message transmission by various drones may not only overwhelm a central server but it also causes congestion on the network. It is mandatory to reduce messaging cost and congestion. This paper presents a fog-assisted congestion avoidance approach for Smooth Message Dissemination (SMD). We present a message forwarding algorithm for congestion avoidance to select the appropriate next-hop node using layered model. This model is based on various layers having drones. In first phase, it looks for an appropriate drone in a layer near the fog server for message forwarding. In next step, the drone is identified in nearby layers to forward the emergency message to next-hop to further locate the group head as per priority. It is a drone that has less distance towards fog server and inform in its one-hop circle. It can stop forwarding message after delivering it to fog server. Finally, the fog server disseminates information timely towards upper layers for necessary actions for emergency situations. The performance of the proposed approach is validated through extensive simulations using NS 2.35. Results prove the dominance of SMD over counterparts in terms of messaging overhead, packet delivery ratio , throughput, energy consumption and average delay. Proposed SMD improves PDR by 85\% and message overhead cost by 91\% as compared to counterparts.},
  archive      = {J_COMCOM},
  author       = {Shumayla Yaqoob and Ata Ullah and Muhammad Awais and Iyad Katib and Aiiad Albeshri and Rashid Mehmood and Mohsin Raza and Saif ul Islam and Joel J.P.C. Rodrigues},
  doi          = {10.1016/j.comcom.2021.01.008},
  journal      = {Computer Communications},
  pages        = {202-210},
  shortjournal = {Comput. Commun.},
  title        = {Novel congestion avoidance scheme for internet of drones},
  volume       = {169},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A survey of breakthrough in blockchain technology:
Adoptions, applications, challenges and future research.
<em>COMCOM</em>, <em>169</em>, 179–201. (<a
href="https://doi.org/10.1016/j.comcom.2020.12.028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Blockchain technology gets more attention and adoptions in various countries and companies all over the world. Blockchain is currently bringing a revolution in many enterprises like finance, healthcare, supply chain, insurance, registry, and the internet of things . Many enterprises integrate blockchain with their systems for the benefits of the blockchain. Despite its strength, blockchain has some challenges in security, privacy, scalability, and other few. This paper surveys the breakthrough in blockchain technology, its applications, and challenges. As many blockchain papers focus on cryptocurrencies , IoT, and security, this paper focuses on the overall state of the art of blockchain technology, its recent developments, and adoptions, especially in areas besides cryptocurrencies . We give a comprehensive review of the cryptography behind the blockchain for a better understanding of the technology. We also review quantitative surveys and analysis on both the public and the enterprise blockchains. Finally, we review the future research opportunities and directions on the blockchain technology.},
  archive      = {J_COMCOM},
  author       = {Abdurrashid Ibrahim Sanka and Muhammad Irfan and Ian Huang and Ray C.C. Cheung},
  doi          = {10.1016/j.comcom.2020.12.028},
  journal      = {Computer Communications},
  pages        = {179-201},
  shortjournal = {Comput. Commun.},
  title        = {A survey of breakthrough in blockchain technology: Adoptions, applications, challenges and future research},
  volume       = {169},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A community detection based approach for service function
chain online placement in data center network. <em>COMCOM</em>,
<em>169</em>, 168–178. (<a
href="https://doi.org/10.1016/j.comcom.2021.01.014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the emerging paradigm of Network Function Virtualization (NFV), the Internet Service Provider (ISP) can outsource their service functions to the cloud data center (DC) to reduce Operating Expenditures (OPEX) and Capital Expenditures (CAPEX). In this paper, we study the virtual network function (VNF) online placement and migration problem in DC considering user’s Service Function Chain (SFC). In order to solve the practical problems, we take the data center topology, Basic Resource Consumption, multi-tenancy, flow characteristics, and VNF relationship into consideration. Firstly, we formulate this problem into a dynamic programming model with the aim to minimize the average operational cost in a long term. To reduce the complexity of the online decision, an online two-stage heuristic (OTSH) algorithm is designed to optimally place SFCs. The OTSH consists of a community detection based differentiated greedy algorithm for SFC mapping and an offline iterative migration algorithm for VNF migrating. At last, the joint online heuristic algorithm is proven to make intelligent predictions based on the historical traffic and provide good performance guarantees by simulation.},
  archive      = {J_COMCOM},
  author       = {Jiachen Zu and Guyu Hu and Jiajie Yan and Siqi Tang},
  doi          = {10.1016/j.comcom.2021.01.014},
  journal      = {Computer Communications},
  pages        = {168-178},
  shortjournal = {Comput. Commun.},
  title        = {A community detection based approach for service function chain online placement in data center network},
  volume       = {169},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). AMOUN: Asymmetric lightweight cryptographic scheme for
wireless group communication. <em>COMCOM</em>, <em>169</em>, 154–167.
(<a href="https://doi.org/10.1016/j.comcom.2021.01.019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-recipient cryptographic schemes provide secure communication, between one sender and multiple recipients, in a multi-party group. Providing secure multi-party communication is very challenging, especially in dynamic networks. Existing multi-recipient cryptographic schemes pose a variety of limitations. These include high computational overhead for both encryption and decryption, additional communication overhead and high setup cost due to change in membership, and collusion among recipients. In order to overcome these limitations, this paper introduces an efficient asymmetric multi-recipient cryptographic scheme, A M O U N . In the proposed scheme, to better utilize network resources, the sender transmits a ciphertext containing different messages to multiple recipients, where each recipient is only allowed to retrieve its own designated message. Security analysis demonstrates that the proposed scheme is indistinguishable under adaptive chosen plaintext attack . Quantitative analysis reveals that lightweight A M O U N shows lower average computational cost than both RSA and Multi-RSA, for both encryption and decryption, even when the key sizes are four times larger. For a given prime size, in case of encryption, A M O U N shows 98\% and 99\% lower average computational cost than RSA and Multi-RSA, respectively. For decryption, A M O U N shows a performance improvement of 99\% compared to RSA and Multi-RSA.},
  archive      = {J_COMCOM},
  author       = {Ahmad Mansour and Khalid M. Malik and Niko Kaso},
  doi          = {10.1016/j.comcom.2021.01.019},
  journal      = {Computer Communications},
  pages        = {154-167},
  shortjournal = {Comput. Commun.},
  title        = {AMOUN: Asymmetric lightweight cryptographic scheme for wireless group communication},
  volume       = {169},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). SDN/NFV architectures for edge-cloud oriented IoT: A
systematic review. <em>COMCOM</em>, <em>169</em>, 129–153. (<a
href="https://doi.org/10.1016/j.comcom.2021.01.018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Software-defined network (SDN) and network function virtualization (NFV) have entirely changed the way internetwork backhaul should be utilized and behaved for virtualized service provisioning. Several benefits have been observed in multiple domains of applications that has used SDN and NFV in integrated way. Thus, SDN/NFV paradigm has been investigated to seek whether network services could be efficiently delivered, managed, and disseminated to the end users. Internet of Things (IoT) is justifiably associated with the SDN/NFV augmentation to make this task enriched. However, factors related to edge-cloud communication and network services have not been effectively mitigated until now. In this paper, we present an in-depth, qualitative, and comprehensive systematic review to find the answers of following research questions, such as, (i) how does state-of-the-art SDN/NFV architecture look like, (ii) how to solve next generation cellular services via architecture involvement, (iii) what type of application/test-bed need to be studied, and (iv) security framework should be catered. We further, elaborate various key issues and challenges in the existing architecture mitigation for SDN/NFV integration to the IoT-based edge-cloud oriented network service provisioning. Future directions are also prescribed to support fellow researchers to improve existing virtualized service scenario. Lessons learned after performing comparative study with other survey articles dictates that our work presents timely contribution in terms of novel knowledge toward understanding of formulating SDN/NFV virtualization services under the aegis of IoT-centric edge-cloud scenario.},
  archive      = {J_COMCOM},
  author       = {Partha Pratim Ray and Neeraj Kumar},
  doi          = {10.1016/j.comcom.2021.01.018},
  journal      = {Computer Communications},
  pages        = {129-153},
  shortjournal = {Comput. Commun.},
  title        = {SDN/NFV architectures for edge-cloud oriented IoT: A systematic review},
  volume       = {169},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Secure device-to-device communications for 5G enabled
internet of things applications. <em>COMCOM</em>, <em>169</em>, 114–128.
(<a href="https://doi.org/10.1016/j.comcom.2021.01.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Smart cities are developed to optimize operations across the city such as waste and traffic management, water supply management, criminal tracking, and pollution monitoring, etc. Smart cities are formed by the interconnection of various Internet of Things (IoT) devices for collecting the data from objects and humans to perform necessary actions. But the challenge lies in the exchange of enormous information in real-time to drive smart city applications . Therefore, smart city applications make use of Device-to-Device (D2D) communications which provides higher bandwidth and lower latency in message exchanges. D2D communications do not need any infrastructure for communication and hence are cost and time effective. However, this advantage becomes a threat as no third party is involved to verify the authenticity of the devices before exchange of real information. Consequently, a reliable authentication mechanism is required to address the security issues in WiFi (wireless fidelity) Direct communication. In this paper, we propose a secure and lightweight mutual authentication and key agreement protocol for WiFi Direct. The principle of the protocol is based upon a commit/open pair and Diffie Hellman key exchange algorithm. It is observed from the simulations that the proposed protocol successfully authenticates the D2D devices in the WiFi Direct environment. Investigation through formal security analysis revealed the strong resistivity of the proposed protocol against the prominent attacks in the WiFi Direct environment. The comparative analysis demonstrates the reliability of the suggested protocol over the traditional one. The proposed protocol eliminates the occurrence of the denial of service (DoS) and man-in-the-middle (MITM) attacks in the discovery and key agreement phase, respectively. The proposed protocol can be easily integrated into the devices enabled with WiFi Direct and can offer a wide security package.},
  archive      = {J_COMCOM},
  author       = {Gurjot Singh Gaba and Gulshan Kumar and Tai-Hoon Kim and Himanshu Monga and Pardeep Kumar},
  doi          = {10.1016/j.comcom.2021.01.010},
  journal      = {Computer Communications},
  pages        = {114-128},
  shortjournal = {Comput. Commun.},
  title        = {Secure device-to-device communications for 5G enabled internet of things applications},
  volume       = {169},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Private blockchain-envisioned multi-authority CP-ABE-based
user access control scheme in IIoT. <em>COMCOM</em>, <em>169</em>,
99–113. (<a href="https://doi.org/10.1016/j.comcom.2021.01.023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advances in Low Power Wide Area Network (LPWAN) are expected to augment the already prodigious proliferation of Industrial Internet of Things (IIoT). However, this unrepresented growth is tinged by the uncertainty of possible challenges in security and privacy. In this work, we propose a novel blockchain-envisioned fine grained user access control scheme for data security and scalability in IIoT environment. The proposed scheme supports multiple attribute authorities and also a constant size key and ciphertext . The data gathered by the IoT smart devices are encrypted using the cipher-policy attribute based encryption (CP-ABE) and sent to their nearby gateway nodes. Later, the gateway nodes form the transactions from the encrypted data from the smart devices which are used to form partial blocks. The partial blocks are then forwarded to the cloud server(s) in the peer-to-peer (P2P) network to convert them into full blocks, which are verified, mined and added into the blockchain using the voting-based practical Byzantine fault tolerance (PBFT) consensus algorithm . The proposed scheme also allows a user to access the secure data stored in the blocks into the blockchain using the CP-ABE mechanism. The security analysis demonstrates the robustness of the proposed scheme against various attacks, and the comparative study with related relevant schemes also highlights the advantage of the proposed scheme over existing approaches. Finally, a blockchain implementation of the presented scheme summarizes the computational costs for a varied number of transactions per block, and also for a varied number of blocks mined in the blockchain.},
  archive      = {J_COMCOM},
  author       = {Soumya Banerjee and Basudeb Bera and Ashok Kumar Das and Samiran Chattopadhyay and Muhammad Khurram Khan and Joel J.P.C. Rodrigues},
  doi          = {10.1016/j.comcom.2021.01.023},
  journal      = {Computer Communications},
  pages        = {99-113},
  shortjournal = {Comput. Commun.},
  title        = {Private blockchain-envisioned multi-authority CP-ABE-based user access control scheme in IIoT},
  volume       = {169},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A GPU-assisted NFV framework for intrusion detection system.
<em>COMCOM</em>, <em>169</em>, 92–98. (<a
href="https://doi.org/10.1016/j.comcom.2021.01.024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The network function virtualization (NFV) paradigm advocates the replacement of specific-purpose hardware supporting packet processing by general-purpose ones, reducing costs and bringing more flexibility and agility to the network operation. However, this shift can degrade the network performance due to the non-optimal packet processing capabilities of the general-purpose hardware. Meanwhile, graphics processing units (GPUs) have been deployed in many data centers (DCs) due to their broad use in, e.g., machine learning (ML). These GPUs can be leveraged to accelerate the packet processing capability of virtual network functions (vNFs), but the delay introduced can be an issue for some applications. Our work proposes a framework for packet processing acceleration using GPUs to support vNF execution. We validate the proposed framework with a case study, analyzing the benefits of using GPU to support the execution of an intrusion detection system (IDS) as a vNF and evaluating the traffic intensities where using our framework brings the most benefits. Results show that the throughput of the system increases from 50 Mbps to 1 Gbps by employing our framework while reducing the central process unit (CPU) resource usage by almost 40\%. The results indicate that GPUs are a good candidate for accelerating packet processing in vNFs. 1},
  archive      = {J_COMCOM},
  author       = {Igor Araujo and Carlos Natalino and Diego Cardoso},
  doi          = {10.1016/j.comcom.2021.01.024},
  journal      = {Computer Communications},
  pages        = {92-98},
  shortjournal = {Comput. Commun.},
  title        = {A GPU-assisted NFV framework for intrusion detection system},
  volume       = {169},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Efficient high-performance FPGA-redis hybrid NoSQL caching
system for blockchain scalability. <em>COMCOM</em>, <em>169</em>, 81–91.
(<a href="https://doi.org/10.1016/j.comcom.2021.01.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The inspiring blockchain technology has got successes and many adoptions in areas besides cryptocurrencies as its benefits have been explored and successfully tested. Scalability is one of the biggest challenges of blockchain. Due to the huge increasing size of blockchain data, many devices (lightweight nodes) especially IoT depend on full blockchain servers, hence there is a need to reduce the workload on the servers for high performance. This paper presents a high performance and efficient hybrid (multilevel) and distributed NoSQL caching system of FPGA and Redis for improving the scalability (throughput) of blockchain applications. We investigate performance bottlenecks in blockchain and design an efficient Gigabit Ethernet FPGA NoSQL cache architecture that works in synergy with Redis database via Hiredis C client. Curl and Jansson are used to connect with the blockchain. We design a customized SHA-256 core for the efficient caching specific for blockchain. Our results revealed an improvement of 103 times when cache hit occurs on the FPGA without cache miss. When cache miss occurs on the FPGA, up to 4.09 times improvement is obtained with the proposed FPGA–Redis system compared to FPGA only system. Small FPGA area utilization and less power consumption were also achieved.},
  archive      = {J_COMCOM},
  author       = {Abdurrashid Ibrahim Sanka and Mehdi Hasan Chowdhury and Ray C.C. Cheung},
  doi          = {10.1016/j.comcom.2021.01.017},
  journal      = {Computer Communications},
  pages        = {81-91},
  shortjournal = {Comput. Commun.},
  title        = {Efficient high-performance FPGA-redis hybrid NoSQL caching system for blockchain scalability},
  volume       = {169},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Intelligent workload allocation in IoT–fog–cloud
architecture towards mobile edge computing. <em>COMCOM</em>,
<em>169</em>, 71–80. (<a
href="https://doi.org/10.1016/j.comcom.2021.01.022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Because of the tremendous growth in the number of smart vehicular devices and 5G mobile technologies, the Internet of Things (IoT) has experienced rapid expansion. This has led to a considerable increase in the volume of sensory data produced from, but not limited to, monitoring devices, traffic congestion in cities, safety, and pollution control. Cloud computing can deal with the corresponding workload by providing virtually unlimited computational resources. But, given the importance of the quality of service and security in delay-sensitive requests, other solutions like fog computing have also been introduced to speed up processing and management of sensory data in real scenarios like smart grid and IoT. Processing workloads at the network edge reduces the delay in mobile edge computing , but it highly increases the consuming power. Therefore, there is an urgent need for the improvement of the energy model of fog devices at the network edge. This paper is an attempt to modify this model using the green energy concept and reduce both delay and power consumption in multi-sensorial frameworks in secure IoT systems. In the proposed method, a Genetic Algorithm (GA) is used for handling a large number of requests and the corresponding quality and security limitations. Simulation results show that the proposed method can simultaneously reduce the delay and the power consumption of edge devices compared to a baseline strategy.},
  archive      = {J_COMCOM},
  author       = {M. Abbasi and E. Mohammadi-Pasand and M.R. Khosravi},
  doi          = {10.1016/j.comcom.2021.01.022},
  journal      = {Computer Communications},
  pages        = {71-80},
  shortjournal = {Comput. Commun.},
  title        = {Intelligent workload allocation in IoT–Fog–cloud architecture towards mobile edge computing},
  volume       = {169},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An enhanced superframe structure of IEEE 802.15.4 standard
for adaptive data requirement. <em>COMCOM</em>, <em>169</em>, 59–70. (<a
href="https://doi.org/10.1016/j.comcom.2020.12.023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the superframe structure of IEEE 802.15.4 standard is improved to meet the adaptive data traffic requirements of hierarchical Wireless Sensor Networks (WSNs). In the IEEE 802.15.4 standard, sensor nodes send their data implicitly by using the Guaranteed Time Slots (GTS) to their PAN coordinator. The standard does not meet the adaptive data requirements of GTS requesting nodes. If requesting GTSs in an active period are more or less than the available limit, then either the requested nodes will not be entertained or GTSs remain underutilized. Consequently, it may cause unnecessary delays or poor GTS utilization. In this work, an Enhanced Superframe offering Adaptive Duty cycle (ESAD) is proposed. ESAD adapts the active period in accordance with the requested data. In addition, the actual size of GTS has been halved to accommodate more GTS requesting nodes. The shortest job first algorithm is applied to scrutinize the requested GTS nodes. Simulation results verify that the proposed scheme increases the link utilization, improves the data transmission, reduces the delay, and allows more nodes to transfer their data in a specified superframe .},
  archive      = {J_COMCOM},
  author       = {Sangrez Khan and A. Naseem Alvi and M. Awais Javed and Safdar H. Bouk},
  doi          = {10.1016/j.comcom.2020.12.023},
  journal      = {Computer Communications},
  pages        = {59-70},
  shortjournal = {Comput. Commun.},
  title        = {An enhanced superframe structure of IEEE 802.15.4 standard for adaptive data requirement},
  volume       = {169},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Hybrid fog/cloud computing resource allocation: Joint
consideration of limited communication resources and user credibility.
<em>COMCOM</em>, <em>169</em>, 48–58. (<a
href="https://doi.org/10.1016/j.comcom.2021.01.026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study the communication and computation resource allocation problem with the assumption of enough computation resources but limited communication resources. This assumption is indeed practical in a hybrid fog/cloud computing system, when there exists a large amount of data to be executed. More specifically, a powerful cloud computing center can help fog nodes (FNs) release the heavy computation burden. Namely, with the assistance of cloud computing , the system usually has enough computation resources to execute such computation-intensive applications. However, since the system has a certain amount of subchannels , the communication resources of the system may be limited at times, especially when the number of subchannels is insufficient. Therefore, with the aim of handling tasks in an energy efficient way, we propose a communication resource-aware cooperated with computation resources (CRACCR) scheme which has two components. The one is called spectral multiplexing computation consideration, where the system multiplexes communication resources under the consideration of computation resource allocation. The other is called FN scale adjustment (FNSA), where the number of FNs in use is influenced by the communication resource allocation. Furthermore, to develop a user-aware CRACCR scheme, we also design a mechanism to sketch users’ credibility. Then a limited communication resource allocation problem with the consideration of user credibility is formulated as a mixed integer non-linear programming problem (MINLP). After transforming the problem by ℓ p ℓp -box constraints and scale conversion, the problem is tackled by the alternating direction multiplier method. Simulation results prove the improvement of energy efficiency achieved by the proposed scheme, and show the variation of FNs’ number while considering the communication resource allocation.},
  archive      = {J_COMCOM},
  author       = {Xincheng Chen and Yuchen Zhou and Long Yang and Lu Lv},
  doi          = {10.1016/j.comcom.2021.01.026},
  journal      = {Computer Communications},
  pages        = {48-58},
  shortjournal = {Comput. Commun.},
  title        = {Hybrid fog/cloud computing resource allocation: Joint consideration of limited communication resources and user credibility},
  volume       = {169},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Optimal scheduling for maximizing information freshness and
system performance in industrial cyber–physical systems.
<em>COMCOM</em>, <em>169</em>, 33–47. (<a
href="https://doi.org/10.1016/j.comcom.2021.01.015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {“Age of Information” is a newly introduced metric, getting vivid attention for measuring the freshness of information in real-time networks. This parameter has evolved to guarantee the timely reception of information from the latest status update received by a user from any real-time application. In this paper, we study a centralized, closed-loop, networked controlled industrial wireless sensor–actuator network for cyber–physical production systems. Here, we jointly address the problem of transmission scheduling of sensor updates and the restoration of an information flow-line after any real-time update, having hard-deadline, drops from it, resulting in a break in the loop. Unlike existing real-time scheduling policies that only ensure timely updates, this work aims to accomplish both the time-sensitivity and data freshness in new and regenerative real-time updates in terms of the ‘age’ of information. Here, the coexistence of both cyber and physical units and their individual requirements for providing the quality of service to the system, as a whole, seems to be one of the major challenges to handle. In this work, minimization of staleness of the time-critical updates to extract maximum utilization out of its information content and its effects on other network performances are thoroughly investigated. A greedy scheduling policy called “Deadline-aware Highest Latency First” has been used to solve this problem; its performance optimality is proved analytically. Finally, our claim is validated by comparing the results obtained by our algorithm with those of other popular scheduling policies through extensive simulations.},
  archive      = {J_COMCOM},
  author       = {Devarpita Sinha and Rajarshi Roy},
  doi          = {10.1016/j.comcom.2021.01.015},
  journal      = {Computer Communications},
  pages        = {33-47},
  shortjournal = {Comput. Commun.},
  title        = {Optimal scheduling for maximizing information freshness and system performance in industrial cyber–physical systems},
  volume       = {169},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). D2D communication channel allocation and resource
optimization in 5G network based on game theory. <em>COMCOM</em>,
<em>169</em>, 26–32. (<a
href="https://doi.org/10.1016/j.comcom.2021.01.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of intelligent hardware and the Internet of Things , the bandwidth and resource utilization efficiency of related networks need to be improved. At the same time, the corresponding communication spectrum is becoming more and more scarce. At present, cognitive D2D communication technology in 5G network can establish communication link directly through communication equipment, so that two established communication equipment can realize direct communication, so as to make full use of communication resources and finally meet the explosive growth of traffic demand. How to manage communication resources and select communication links is the main research direction of D2D communication technology in 5G technology. Based on the knowledge of game theory, this paper proposes a communication channel allocation scheme and resource optimization scheme based on spectrum clustering and non cooperative game to maximize the operation efficiency of D2D communication equipment. The actual efficiency can reach about 1.5 times of the original communication efficiency. Finally, the optimization method proposed in this paper is compared with the traditional communication method. The experimental results show that this method has higher advantages.},
  archive      = {J_COMCOM},
  author       = {Shasha Zhao and Yingying Feng and Gan Yu},
  doi          = {10.1016/j.comcom.2021.01.016},
  journal      = {Computer Communications},
  pages        = {26-32},
  shortjournal = {Comput. Commun.},
  title        = {D2D communication channel allocation and resource optimization in 5G network based on game theory},
  volume       = {169},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). HCR-WSN: Hybrid MIMO cognitive radio system for wireless
sensor network. <em>COMCOM</em>, <em>169</em>, 11–25. (<a
href="https://doi.org/10.1016/j.comcom.2020.12.025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi Input Multi Output (MIMO) based Cognitive Radio (CR) provisions an efficient utilization of the scarce electromagnetic spectrum. Traditional CR includes Interweave and Underlay techniques. We propose a Hybrid MIMO CR system for Wireless Sensor Network , HCR-WSN, that utilizes both underlay and interweave CR techniques and provides higher spectral efficiency . The wireless sensor network consisting of CR nodes achieves higher throughput using the proposed framework. HCR-WSN improves the spectral efficiency gain of an Uplink Hybrid Cognitive Radio MIMO system in wireless sensor network (WSN), by implementing Narrowband and Wideband (Multiple Carrier Direct Sequence Code Division Multiple Access , i.e., MC-DS-CDMA) technology adhering to the Interference Threshold limit. The WSN is consisting of nodes acting as primary users (PU) and CR secondary users (SU). The proposed Hybrid CR system ensures efficient spectral utilization under circumstances resulting in near zero throughput for SU. In the presence of PU, CR-SU transmits in either Narrowband or MC-DS-CDMA based on the proposed transmission selection algorithm . In the absence of PU, SU uses Interweave technique thereby allowing other competing SUs to transmit in Interference Alignment underlay mode in a multi-user scenario. The achievable throughput is enhanced using the proposed technique in a multi-user hybrid MIMO cognitive radio wireless sensor network.},
  archive      = {J_COMCOM},
  author       = {Chetna Singhal and Vinayak Patil},
  doi          = {10.1016/j.comcom.2020.12.025},
  journal      = {Computer Communications},
  pages        = {11-25},
  shortjournal = {Comput. Commun.},
  title        = {HCR-WSN: Hybrid MIMO cognitive radio system for wireless sensor network},
  volume       = {169},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Efficient multi-category packet classification using TCAM.
<em>COMCOM</em>, <em>169</em>, 1–10. (<a
href="https://doi.org/10.1016/j.comcom.2020.12.027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Packet classification is the base of various network functions such as firewall filtering , network intrusion detection and quality of services, etc. Ternary content addressable memory (TCAM) is widely employed in performing efficient packet classification. However, TCAM has some drawbacks, including limited capacity, high energy consumption, and incapability to store arbitrary ranges. Moreover, TCAM is only suitable for single-match packet classification natively, which is associated with one rule-set and reports one rule, for it only reports the first matching entry. However, except for single-match packet classification, another type of packet classification, multi-category packet classification, which is associated with multiple rule-sets and reports one matching rule for each rule-set, is also required in some scenarios, such as in the consolidation of multiple single-match network functions. The naive scheme performing multi-category packet classification with TCAM is to search a packet in multiple rule-sets one by one. Its performance decreases linearly as the number of rule-sets increases. To efficiently perform multi-category packet classification using TCAM, a novel scheme named REM is proposed in this paper. REM is based on the idea of reducing TCAM accesses per classification by merging rule-entry sets converted from rule-sets. The experiments show that compared with the naive scheme, REM can achieve 3x to 5x improvement on packet classification throughput, and reduce the energy consumption by 50\% to 75\%.},
  archive      = {J_COMCOM},
  author       = {Jincheng Zhong and Shuhui Chen},
  doi          = {10.1016/j.comcom.2020.12.027},
  journal      = {Computer Communications},
  pages        = {1-10},
  shortjournal = {Comput. Commun.},
  title        = {Efficient multi-category packet classification using TCAM},
  volume       = {169},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Editorial for special issue on analysis and performance of
wireless mobile systems. <em>COMCOM</em>, <em>168</em>, 178–179. (<a
href="https://doi.org/10.1016/j.comcom.2021.02.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_COMCOM},
  doi          = {10.1016/j.comcom.2021.02.001},
  journal      = {Computer Communications},
  pages        = {178-179},
  shortjournal = {Comput. Commun.},
  title        = {Editorial for special issue on analysis and performance of wireless mobile systems},
  volume       = {168},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). 5G heterogeneous network selection and resource allocation
optimization based on cuckoo search algorithm. <em>COMCOM</em>,
<em>168</em>, 170–177. (<a
href="https://doi.org/10.1016/j.comcom.2020.12.026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to solve the problem of spectrum resource shortage and high-speed access in 5G network , the multi-agent system is embedded into the standard cuckoo algorithm, and the multi-agent cuckoo algorithm is proposed. Firstly, the spectrum information of network channel sharing available to users is obtained, and the cuckoo search algorithm is used to optimize under the condition of satisfying the quality of service (QoS) guarantee of users, and the optimal allocation scheme is obtained by iterating for many times. The use steps are illustrated by examples. Compared with the traditional genetic algorithm , the calculation complexity can be reduced, and it can also be extended to more users and networks. In this algorithm, each cuckoo represents an agent, and all the agents constitute a von-Neumann structure. Through the neighborhood competition cooperation operator, mutation operator , self-learning operator and the evolution mechanism of cuckoo algorithm, they can continuously enhance the energy and improve the adaptability, and can quickly and accurately find the optimal solution of the problem.},
  archive      = {J_COMCOM},
  author       = {Ning Ai and Bin Wu and Boyu Li and Zhipeng Zhao},
  doi          = {10.1016/j.comcom.2020.12.026},
  journal      = {Computer Communications},
  pages        = {170-177},
  shortjournal = {Comput. Commun.},
  title        = {5G heterogeneous network selection and resource allocation optimization based on cuckoo search algorithm},
  volume       = {168},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Green computing in IoT: Time slotted simultaneous wireless
information and power transfer. <em>COMCOM</em>, <em>168</em>, 155–169.
(<a href="https://doi.org/10.1016/j.comcom.2020.12.024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Simultaneous Wireless Information and Power Transfer (SWIPT) is an emerging field to transmit information and power in IoT network through the same RF signal . Time switching (TS) protocol is more favorable in free space communication than Power Splitting (PS) protocol when the transmitted RF signal is already weak. This is because, transmitted signal loses its power due to attenuation in free space, and using PS design receiver circuit (complex), the received weak signal is further split into two fraction for energy harvesting (EH) and information decoding (ID) simultaneously, that causes inadequacy in SWIPT system. Whereas, using TS design receiver circuit (simple) insert extra delay in the network as EH and ID operations are done in two different time domain one by one. Literature on SWIPT lacks towards cooperation between more energy harvesting in case of free space communication (TS) and critical information transmission in case of delay constraint communication (PS). In this context, this paper presents a time-slotted SWIPT (T-SWIPT) focusing on maximization of energy efficiency in the relay based sensors-enabled IoT network. It enables simultaneous energy harvesting at receiver and neighboring sensors without adding extra delay in the network. The PS ratio , transmission power allotment and energy broadcast time are jointly formulated as non-convex energy efficiency maximization problem. A solution to the problem is presented using Lagrangian dual decomposition and fractional programming . The performance evaluation shows that T-SWIPT attains optimum energy efficiency by trading off transmission power allotment, power-splitting ratio and sink broadcast time slot.},
  archive      = {J_COMCOM},
  author       = {Ankita Jaiswal and Sushil Kumar and Omprakash Kaiwartya and Mukesh Prasad and Neeraj Kumar and Houbing Song},
  doi          = {10.1016/j.comcom.2020.12.024},
  journal      = {Computer Communications},
  pages        = {155-169},
  shortjournal = {Comput. Commun.},
  title        = {Green computing in IoT: Time slotted simultaneous wireless information and power transfer},
  volume       = {168},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Optimization of battery swapping infrastructure for
e-commerce drone delivery. <em>COMCOM</em>, <em>168</em>, 146–154. (<a
href="https://doi.org/10.1016/j.comcom.2020.12.015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Drone delivery is widely-researched to alter the current e-commerce delivery convention for providing short delivery lead times. Yet, flight range of drones, constrained by the available battery technology, sets a milestone toward realizing the sole-drone delivery. To tackle with the flight range limitation, locating automated battery swapping machines (ABSM) have been proposed and a few studies modeled the problem. Using the ABSMs, drones can be loaded with fully-charged batteries along the route to a demand location. In this study, we introduce a mixed-integer nonlinear program to model the problem. The objective of the program is to optimally select ABSM locations, determine the delivery-mode choices (drone-only, truck-only, and mixed delivery) of demand locations, find drone delivery routes, and approximate the baseline requirements for the number of drones and batteries needed. The program minimizes the overall delivery system costs including: ABSM, delivery, drone ownership, battery inventory, and service congestion. A cutting-plane method is developed to find exact solutions in finite iterations. Computational experiments showed that the method quickly yields the optimal solution to instances with less than 60 ABSM candidates and 20 demand locations. A case study shows that the optimal drone delivery infrastructure can save almost 20\% cost compared to the conventional truck-only delivery. Sensitivity analyses were conducted to reveal the impact of key parameters in the decision-making and found that a decrease in the ABSM and drone costs highly affect the system cost. Code to solve the case study is publicly available at https://gitlab.com/tcokyasar/optimization-of-battery-swapping .},
  archive      = {J_COMCOM},
  author       = {Taner Cokyasar},
  doi          = {10.1016/j.comcom.2020.12.015},
  journal      = {Computer Communications},
  pages        = {146-154},
  shortjournal = {Comput. Commun.},
  title        = {Optimization of battery swapping infrastructure for e-commerce drone delivery},
  volume       = {168},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Optimization scheme for intrusion detection scheme GBDT in
edge computing center. <em>COMCOM</em>, <em>168</em>, 136–145. (<a
href="https://doi.org/10.1016/j.comcom.2020.12.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Combination of edge computing technologies and machine learning help to put edge intelligence into practice. Industrial Internet of Things (IIoT) is one of its most typical applications. But this system can be easily attacked in the process of using edge computing center to process localized perception data. Intrusion detection technologies based on machine learning provide strong security for edge computing center, in which the most widely used is gradient boosting decision tree (i.e., GBDT). But still this model faces with problems such as imbalanced data , high dimensional data characteristics, and low efficiency of parameter optimization. To solve these problems, this paper proposes an optimization scheme for GBDT to improve its detection precision and training efficiency. First, to solve the problem of imbalanced data in data set, we propose a margin synthetic minority oversampling technique (i.e., MSMOTE), which can expand the non-noise data with less sample size, namely, small sample, to ensure equilibrium distribution of data. Second, to lower the data feature dimensionality, we propose a recursive feature elimination-hierarchy cross validation algorithm (i.e., RFE-HCV). The new algorithm eliminates redundant data features recursively according to feature weight, to strengthen the relationship between features and goals. It also designs hierarchy system to ensure equal proportionment of data category (attack category) in training set and testing set at cross validation stage. Next, in order to improve the efficiency of parameter optimization in model training process, we develop a flexible grid search algorithm (i.e., FGS) to improve retrieval efficiency of optimum parameters. Finally, the detailed experimental results show that our new scheme ensures data balance in dataset and eliminates redundant data features, and helps the efficiency of parameter optimization increase by three times. Moreover, the new scheme defends against intrusion more effectively.},
  archive      = {J_COMCOM},
  author       = {Ju-fu Cui and Hui Xia and Rui Zhang and Ben-xu Hu and Xiang-guo Cheng},
  doi          = {10.1016/j.comcom.2020.12.007},
  journal      = {Computer Communications},
  pages        = {136-145},
  shortjournal = {Comput. Commun.},
  title        = {Optimization scheme for intrusion detection scheme GBDT in edge computing center},
  volume       = {168},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Addressing disasters in smart cities through UAVs path
planning and 5G communications: A systematic review. <em>COMCOM</em>,
<em>168</em>, 114–135. (<a
href="https://doi.org/10.1016/j.comcom.2021.01.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {UAVs are increasingly incorporated in a wide range of domains such as disaster management and rescue missions. UAV path planning deals with finding the most optimal or shortest path for UAVs such that minimum energy and resources are utilized. This paper examines the path planning algorithms for UAVs through a literature survey conducted on 139 systematically retrieved articles published in the last decade that are narrowed down to 36 highly relevant articles. As retrieved from the shortlisted articles, the path planning algorithms include RRT, Artificial Potential, Voronoi, D-Star, A-Star, Dijkstra, MILP , Neural Network , Ant Colony Optimization , and Particle Swarm Optimization that are classified into four main types: Model-based, Conventional, Learning-based, and Cell-based. Most of the disaster-related articles are focused on the post-disaster phase only and use conventional and learning-based algorithms with applications to localize victims and optimize paths. Regarding the UAV communication network (UAVCN), the key challenges are communication issues, resource allocation, UAV deployment, defining UAV trajectory, and content security. UAV path planning’s key barriers are path optimization, path completeness, optimality , efficiency, and achieving robustness. Accordingly, a holistic IoT-powered UAV-based smart city management system has been recommended in the current study where all the smart city key components are integrated to address disasters like floods, earthquakes, and bush fire. The proposed holistic system can help prepare for disasters and mitigate them as soon as these arise and help enhance the smart city governance.},
  archive      = {J_COMCOM},
  author       = {Zakria Qadir and Fahim Ullah and Hafiz Suliman Munawar and Fadi Al-Turjman},
  doi          = {10.1016/j.comcom.2021.01.003},
  journal      = {Computer Communications},
  pages        = {114-135},
  shortjournal = {Comput. Commun.},
  title        = {Addressing disasters in smart cities through UAVs path planning and 5G communications: A systematic review},
  volume       = {168},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An efficient data transmission scheme through 5G D2D-enabled
relays in wireless sensor networks. <em>COMCOM</em>, <em>168</em>,
102–113. (<a
href="https://doi.org/10.1016/j.comcom.2021.01.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Energy-efficient data transmission is a key challenge in Wireless Sensor Networks (WSNs). Cluster heads (CHs) are often used to relay aggregated data from sensor nodes to a central base station (BS). However, the transmission range of such relay nodes is limited, necessitating multihop communication for forwarding data from edge relays to BS. Further, links may not be created due to the unavailability of suitable relays resulting in unreliable networks. The use of cellular device-to-device (D2D) communication eliminates the requirement of very short-range communication of WSNs and also helps in maintaining a good link throughput. In this paper, a cellular D2D-assisted relay communication scheme has been proposed for forwarding data where the issue of link disconnection is solved using dual connectivity of D2D and cellular communication among cluster heads. The proposed scheme, DSPA (D2D Relay Node (DRN) Selection and uplink Power Allocation), uses the Maximum Weight Bipartite Matching for selection of relays. Performance analysis shows that the higher sleeping probability of the sensor nodes improves the overall energy efficiency of the network and also increases the average hop gain.},
  archive      = {J_COMCOM},
  author       = {Pradip Kumar Barik and Chetna Singhal and Raja Datta},
  doi          = {10.1016/j.comcom.2021.01.004},
  journal      = {Computer Communications},
  pages        = {102-113},
  shortjournal = {Comput. Commun.},
  title        = {An efficient data transmission scheme through 5G D2D-enabled relays in wireless sensor networks},
  volume       = {168},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Green communication for OFDMA cellular networks with
multiple antennas. <em>COMCOM</em>, <em>168</em>, 93–101. (<a
href="https://doi.org/10.1016/j.comcom.2021.01.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The green communication which requires the maximum reduction of energy consumption has become a strong need for the new wireless system designs because of the massive increasing number of mobile subscriptions. Thus, in this paper, energy efficiency (EE) maximization problem is considered for multiple-input single-output orthogonal frequency division multiple access (MISO-OFDMA) cellular networks . The EE maximization problem is defined for a downlink communication model by considering the total transmit power and circuit power constraints. Quality of service (QoS) constraints which guarantee the minimum data rate requirement of the users are also accounted. The considered problem belongs to the category of mixed-integer non-linear programming problem (MINLP), and thus is NP-hard. To cope up with this complexity, a two-step resource allocation algorithm, which contains an heuristic subchannel allocation algorithm and the iterative power allocation algorithm with fast convergence based on the Dinkelbach method, is proposed. Numerical results are provided to demonstrate the effectiveness of the proposed algorithm and the convergence and energy efficiency performance of the proposed scheme is validated.},
  archive      = {J_COMCOM},
  author       = {İlhan Baştürk},
  doi          = {10.1016/j.comcom.2021.01.001},
  journal      = {Computer Communications},
  pages        = {93-101},
  shortjournal = {Comput. Commun.},
  title        = {Green communication for OFDMA cellular networks with multiple antennas},
  volume       = {168},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). SD-CPC: SDN controller placement camouflage based on
stochastic game for moving-target defense. <em>COMCOM</em>,
<em>168</em>, 75–92. (<a
href="https://doi.org/10.1016/j.comcom.2020.11.019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The modern paradigm of Software Defined Network (SDN) inspired the research community to develop more innovative and transformative solutions for large scale and complex crucial Cyber Physical Systems (CPS). However, the recent destructive attacks targeting such CPS applications, raised the need to initially secure and scale the core SDN network. These attacks may target the heart of SDN networks itself formed by the controllers. Therefore, recent research works discussed the Controller Placement Problem (CPP) to determine the required number of SDN controller(s) and their optimal locations in synonyms wide area networks. A few of the presented solutions discussed the network security aspect to solve this problem. In addition, none of them addressed the need to secure and dynamically change SDN controller location to confuse attackers. Therefore, in this paper, we introduce a new concept of Controller Placement Camouflage (CPC) to dynamically change the attack surface (SDN controller placements) for Moving-target Defense (MTD). The new paradigm of MTD imposes various asymmetric offensive and defensive modes against cyber-adversaries. We relied on the Zero-Sum game as a stochastic game between the system defender and the attacker to guide our MTD solution. In addition, our presented solution is adapted to consider the network vulnerabilities, evaluate the risk level of the system in real-time using Bayesian Attack Graph (BAG), to frequently shift the SDN controller(s) location. Furthermore, we used the Smart Grid as a case study for a mission critical CPS application. We conducted a scenario of UK Bulk Demand Points (BDP), 50MVA generation network capacity map to simulate a real mini-grid network topology . To the best of our knowledge, this research work may be considered the first introduction for SD-CPC for MTD.},
  archive      = {J_COMCOM},
  author       = {Mohamed Samir and Mohamed Azab and Effat Samir},
  doi          = {10.1016/j.comcom.2020.11.019},
  journal      = {Computer Communications},
  pages        = {75-92},
  shortjournal = {Comput. Commun.},
  title        = {SD-CPC: SDN controller placement camouflage based on stochastic game for moving-target defense},
  volume       = {168},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Clustering-based feature subset selection with analysis on
the redundancy–complementarity dimension. <em>COMCOM</em>, <em>168</em>,
65–74. (<a href="https://doi.org/10.1016/j.comcom.2021.01.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the era of big data, dimensionality reduction plays an extremely important role in many fields driven by machine learning and data mining techniques . The existing information-theoretic feature selection algorithms generally reduce the dimension by selecting the features with maximum class-relevance and minimum redundancy , while relatively overlook the complementary correlation among features and sometimes deal with it improperly. This paper proposes a novel feature subset selection algorithm called the Clustering-based Feature Selection with Redundancy–Complementarity Analysis (CFSRCA). The proposed algorithm can be mainly divided into two steps, namely, (a) selecting the candidate class-relevant features, and (b) selecting the representative features. In the latter step, the representative features are defined as the features with minimum redundancy and maximum complementarity, and a clustering method based on the minimum spanning tree (MST) is proposed to distinguish them effectively. To validate the effectiveness of CFSRCA, three comparative feature selection algorithms (ReliefF, CFS, and FOU) and four well-known classifiers (C4.5, SVM , kNN, and NBC) are used to conduct classification experiments on eight datasets. Experimental results verify the effectiveness of the proposed feature subset algorithm.},
  archive      = {J_COMCOM},
  author       = {Zhijun Chen and Qiushi Chen and Yishi Zhang and Lei Zhou and Junfeng Jiang and Chaozhong Wu and Zhen Huang},
  doi          = {10.1016/j.comcom.2021.01.005},
  journal      = {Computer Communications},
  pages        = {65-74},
  shortjournal = {Comput. Commun.},
  title        = {Clustering-based feature subset selection with analysis on the redundancy–complementarity dimension},
  volume       = {168},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A novel approach of hierarchical compressive sensing in
wireless sensor network using block tri-diagonal matrix clustering.
<em>COMCOM</em>, <em>168</em>, 54–64. (<a
href="https://doi.org/10.1016/j.comcom.2020.12.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wireless Sensor Network (WSN) delivers an important contribution in evolving fields for example ubiquitous computing and ambient intelligence . Monitoring environment is the vital applications of WSN’s. Likewise, inherent energy restriction becomes a bottleneck for applications in WSNs. However, the node such as the sensor and receiver ingests high power when proceeding the data transmission. Also, vast data are managed in network which similarly consumes more energy. A novel architecture is being proposed in this paper which integrates clustering and compressive sensing (CS) by employing Block Tri-Diagonal Matrices (BDM). BDMs are measurement matrices which combine compression, data prediction, and recovery to produce accuracy and provide efficient data processing while using clustered WSNs. Theoretical analysis formed the basis to design numerous algorithms for execution. Real world data were used for simulation and the proposed results revealed that the framework described here provides a cost effective solution for applications that used to monitor environment in clustered WSN. The proposed IHCS achieves 70\% energy efficiency and 93\% prediction rate.},
  archive      = {J_COMCOM},
  author       = {Prabha M. and Darly S.S. and B. Justus Rabi},
  doi          = {10.1016/j.comcom.2020.12.017},
  journal      = {Computer Communications},
  pages        = {54-64},
  shortjournal = {Comput. Commun.},
  title        = {A novel approach of hierarchical compressive sensing in wireless sensor network using block tri-diagonal matrix clustering},
  volume       = {168},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Singability-enhanced lyric generator with music style
transfer. <em>COMCOM</em>, <em>168</em>, 33–53. (<a
href="https://doi.org/10.1016/j.comcom.2021.01.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The lyrics generator should consider the context and the singability of the songs because every song expresses a story through the context of lyrics, and the lyrics should sound with the music well. Therefore, this study proposes a framework to generate the singable lyrics, and the context of lyrics should fit the given musical style. For the context, this study adopts the GPT-2 model which is powerful for text generation. The conditional GPT-2 model can be used to generate lyrics according to the given style. For suitable for singing, this study adjusts the structure and rhyme of lyrics through the use of a syntactic parser and a rhyme modification module. With automatic and human evaluations, the experimental results show that the proposed method can generate lyrics with high structural consistency, rhyme consistency, and originality according to the given music style.},
  archive      = {J_COMCOM},
  author       = {Jia-Wei Chang and Jason C. Hung and Kuan-Cheng Lin},
  doi          = {10.1016/j.comcom.2021.01.002},
  journal      = {Computer Communications},
  pages        = {33-53},
  shortjournal = {Comput. Commun.},
  title        = {Singability-enhanced lyric generator with music style transfer},
  volume       = {168},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). On deep reinforcement learning security for industrial
internet of things. <em>COMCOM</em>, <em>168</em>, 20–32. (<a
href="https://doi.org/10.1016/j.comcom.2020.12.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Industrial Internet of Things (IIoT), also known as Industry 4.0 , empowers manufacturing and production processes by leveraging automation and Internet of Things (IoT) technologies. In IIoT, the information communication technologies enabled by IoT could greatly improve the efficiency and timeliness of information exchanges between both vertical and horizontal system integrations . Likewise, machine learning algorithms, particularly Deep Reinforcement Learning (DRL), are viable for assisting in automated control of complex IIoT systems, with the support of distributed edge computing infrastructure. Despite noticeable performance improvements, the security threats brought by massive interconnections in IoT and the vulnerabilities of deep neural networks used in DRL must be thoroughly investigated and mitigated before widespread deployment. Thus, in this paper we first design a DRL-based controller that could be deployed at edge computing server to enable automated control in an IIoT context. We then investigate malicious behaviors of adversaries with two attacks: (i) function-based attacks that can be launched during training phase and (ii) performance-based attacks that can be launched after training phase, to study the security impacts of vulnerable DRL-based controllers. From the adversary’s perspective, maximum entropy Inverse Reinforcement Learning (IRL) is used to approximate a reward function through observation of system trajectories under the control of trained DRL-based controllers. The approximated reward function is then used to launch attacks by the adversary against the Deep Q Network (DQN)-based controller. Via simulation, we evaluate the impacts of our two investigated attacks, finding that attacks are increasingly successful with increasing accuracy of the control model. Furthermore, we discuss some tradeoffs between control performance and security performance of DRL-based IIoT controllers, and outline several future research directions to secure machine learning use in IIoT systems.},
  archive      = {J_COMCOM},
  author       = {Xing Liu and Wei Yu and Fan Liang and David Griffith and Nada Golmie},
  doi          = {10.1016/j.comcom.2020.12.013},
  journal      = {Computer Communications},
  pages        = {20-32},
  shortjournal = {Comput. Commun.},
  title        = {On deep reinforcement learning security for industrial internet of things},
  volume       = {168},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Radio access technology characterisation through object
detection. <em>COMCOM</em>, <em>168</em>, 12–19. (<a
href="https://doi.org/10.1016/j.comcom.2020.12.021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Radio Access Technology (RAT) classification and monitoring are essential for efficient coexistence of different communication systems in shared spectrum. Shared spectrum, including operation in license-exempt bands, is envisioned in the fifth generation of wireless technology (5G) standards (e.g., 3GPP Rel. 16). In this paper, we propose a Machine Learning (ML) approach to characterise the spectrum utilisation and facilitate the dynamic access to it. Recent advances in Convolutional Neural Networks (CNNs) enable us to perform waveform classification by processing spectrograms as images. In contrast to other ML methods that can only provide the class of the monitored RATs, the solution we propose can recognise not only different RATs in shared spectrum, but also identify critical parameters such as inter-frame duration, frame duration, centre frequency, and signal bandwidth by using object detection and a feature extraction module to extract features from spectrograms . We have implemented and evaluated our solution using a dataset of commercial transmissions, as well as in a Software-Defined Radio (SDR) testbed environment. The scenario evaluated was the coexistence of WiFi and LTE transmissions in shared spectrum. Our results show that our approach has an accuracy of 96\% in the classification of RATs from a dataset that captures transmissions of regular user communications. It also shows that the extracted features can be precise within a margin of 2\%, and can detect above 94\% of objects under a broad range of transmission power levels and interference conditions.},
  archive      = {J_COMCOM},
  author       = {Erika Fonseca and Joao F. Santos and Francisco Paisana and Luiz A. DaSilva},
  doi          = {10.1016/j.comcom.2020.12.021},
  journal      = {Computer Communications},
  pages        = {12-19},
  shortjournal = {Comput. Commun.},
  title        = {Radio access technology characterisation through object detection},
  volume       = {168},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Enhancing mobile cloud with social-aware device-to-device
offloading. <em>COMCOM</em>, <em>168</em>, 1–11. (<a
href="https://doi.org/10.1016/j.comcom.2020.12.020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile cloud computing has been widely used to support the computation-intensive applications in mobile devices . Since cloud computing relies on the facilities like network infrastructures and cloud servers, the cloud service can be easily hampered by the limitation of these facilities in many cases. Therefore, researchers proposed the concept of device-to-device offloading to offload workload to nearby devices, without going through other facilities. Most existing works on device-to-device offloading aim to minimize the execution time of tasks or minimize the energy consumption. These works assume devices can be connected for a long time, but they neglect the fact that the connections among mobile devices are usually intermittent and even opportunistic, which may render the failure of task offloading . In this paper, we propose a new approach, PeerCloud, that aims to improve the success ratio of task offloading . Specifically, since mobile devices are carried by human beings, we study the social relationship between the device carriers and discover the hidden regularity in their contact patterns, in order to predict the likelihood of node departure. Optimization problems are then formalized to maximize the success ratio of task offloading within tasks’ time constraints. Experimental results based on three real-world datasets demonstrate that PeerCloud outperforms existing approaches by significantly improving the success ratio.},
  archive      = {J_COMCOM},
  author       = {Xiaomei Zhang},
  doi          = {10.1016/j.comcom.2020.12.020},
  journal      = {Computer Communications},
  pages        = {1-11},
  shortjournal = {Comput. Commun.},
  title        = {Enhancing mobile cloud with social-aware device-to-device offloading},
  volume       = {168},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A method of two-stage clustering learning based on improved
DBSCAN and density peak algorithm. <em>COMCOM</em>, <em>167</em>, 75–84.
(<a href="https://doi.org/10.1016/j.comcom.2020.12.019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Density peak (DP) and density-based spatial clustering of applications with noise (DBSCAN) are the representative clustering algorithms on the basis of density in unsupervised learning . They are capable of clustering data of arbitrary shape as well as identifying noise samples in a potential data set. Notwithstanding, DP algorithm depends on the decision graph when selecting the centers, it is difficult for users without priori knowledge to automatically as well as accurately identify cluster centers. The clustering performance exhibited by DBSCAN algorithm presents a strong sensitivity to parameter setting regarding Eps and MinPts . For dealing with afore-mentioned issues, we propose a new two-stage clustering method based on improved DBSCAN and DP algorithm (TSCM), which first use an improved DBSCAN algorithm based on bat optimization to generate initial clusters. Specifically, the improved DBSCAN takes a well-known internal clustering validation index without labels called Silhouette as fitness function to control the process of parameters determination by bat optimization. The cluster centers in decision graph are automatically selected according to the initial clusters. The final clusters are obtained by DP with the determined cluster centers. As found in the experiments, relative to DP and DBSCAN, TSCM can effectively overcome the manual intervention of cluster center selection in DP and parameters setting in DBSCAN. The clustering performance is significantly improved.},
  archive      = {J_COMCOM},
  author       = {Mingyang Li and Xinhua Bi and Limin Wang and Xuming Han},
  doi          = {10.1016/j.comcom.2020.12.019},
  journal      = {Computer Communications},
  pages        = {75-84},
  shortjournal = {Comput. Commun.},
  title        = {A method of two-stage clustering learning based on improved DBSCAN and density peak algorithm},
  volume       = {167},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Systematic review on next-generation web-based software
architecture clustering models. <em>COMCOM</em>, <em>167</em>, 63–74.
(<a href="https://doi.org/10.1016/j.comcom.2020.12.022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Software architecture is the heart of web-based software systems determining its components and their connections. These days, fast release and quick delivery of next-generation software, which is the primary goal of the software industry, triggers an occurring error in the software development process. Therefore, recovery and metric measurement techniques are essential tools to assess the quality and soundness of web-based software architecture and return the system to the earlier or original stable state. Reusability techniques could be used to decrease the time, effort, and cost of software development as well. Clustering is a commonly used data mining technique employed to achieve these goals. Therefore, this paper as a first survey presents a literature review for web-based software architecture clustering models that are categorized into software architecture recovery, software architecture metric measurement, and software architecture reusability. Most of the papers studied in this literature were published in 2017 and 2018. IEEE publication has the highest published papers. We classified 67 selected research studies in 3 classes where 42\% of them were considered as software architecture recovery methods, 39\% of them were reported for software architecture metric measurement methods, and 19\% of them were considered for software architecture reusability methods.},
  archive      = {J_COMCOM},
  author       = {Tianfu Yang and Zhiyong Jiang and Yanhong Shang and Monire Norouzi},
  doi          = {10.1016/j.comcom.2020.12.022},
  journal      = {Computer Communications},
  pages        = {63-74},
  shortjournal = {Comput. Commun.},
  title        = {Systematic review on next-generation web-based software architecture clustering models},
  volume       = {167},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Boosting performance for software defined networks from
traffic engineering perspective. <em>COMCOM</em>, <em>167</em>, 55–62.
(<a href="https://doi.org/10.1016/j.comcom.2020.12.018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Paths selection algorithms and rate adaptation objective functions are usually studied separately. In contrast, this paper evaluates some traffic engineering (TE) systems for software defined networking obtained by combining path selection techniques with average delay and load balancing, the two most popular TE objective functions. Based on TE simulation results, the best TE system suitable for software defined networks is a system where the paths are calculated using an oblivious routing model and its adaptation rate calculated using an average delay objective function. Thus, we propose the RACKE+AD system combining path sets computed using Räcke’s oblivious routing and a traffic splitting objective function using average delay. This model outperforms current state-of-the-art models, maximizes throughput, achieves better network resource utilization, and minimizes delay. The proposed system outperformed SMORE and SWAN by 4.2\% and 9.6\% respectively, achieving 27\% better utilization and delivering 34\% more traffic with 50\% less latency compared with both systems on a GÉANT network.},
  archive      = {J_COMCOM},
  author       = {Mohammed I. Salman and Bin Wang},
  doi          = {10.1016/j.comcom.2020.12.018},
  journal      = {Computer Communications},
  pages        = {55-62},
  shortjournal = {Comput. Commun.},
  title        = {Boosting performance for software defined networks from traffic engineering perspective},
  volume       = {167},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An ultra light weight and secure RFID batch authentication
scheme for IoMT. <em>COMCOM</em>, <em>167</em>, 48–54. (<a
href="https://doi.org/10.1016/j.comcom.2020.12.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As an application of IoT technology in the healthcare industry , IoMT has higher security requirements than IoT while improving medical efficiency and reducing medical costs. How to ensure the safety of IoMT is a challenging task. In the implementation of IoMT, Radio-Frequency Identification (RFID) is a key technology for establishing an identity authentication system, which can efficiently identify medical equipment and patients. Designing a safe and efficient RFID authentication protocol will help protect user privacy, enhance the security of the IoMT system and improve the efficiency of medical staff to detect and manage patients. Most of the existing RFID authentication protocols can only authenticate one tag in each authentication session, which is called a per-tag protocol. In medical scenarios that need to efficiently authenticate a mass of tags at short notice, the use of traditional per-tag protocols is inefficient and may delay the treatment of patients. To solve the problem that the per-tag protocols are not applicable in some medical scenarios, we designed a low-cost batch authentication protocol which can accurately identify each illegal tag and reduce the overhead of authentication data transmission. We use the solution of homogeneous linear equations as a key to encrypt the authentication data of the tag to further reduce the cost of the tag. The protocol proposed in this paper is capable of batch certification of tags, with strong security and low tag cost. After security analysis and performance analysis, our scheme can be well applied to IoMT.},
  archive      = {J_COMCOM},
  author       = {Junbin Kang and Kai Fan and Kuan Zhang and Xiaochun Cheng and Hui Li and Yintang Yang},
  doi          = {10.1016/j.comcom.2020.12.004},
  journal      = {Computer Communications},
  pages        = {48-54},
  shortjournal = {Comput. Commun.},
  title        = {An ultra light weight and secure RFID batch authentication scheme for IoMT},
  volume       = {167},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A multilevel bit vector minimization method for fast online
detection of conflicting flow entries in OpenFlow table.
<em>COMCOM</em>, <em>167</em>, 31–47. (<a
href="https://doi.org/10.1016/j.comcom.2020.12.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {OpenFlow implements flow-based control over switches with improved network management performance. However, a packet may match more than one flow entry due to the intra-table dependency phenomenon among flow entries. Moreover, different packets may incur different conflicting flow entries under the intra-table dependency. Forwarding packets by the first-match scheme for prioritized flow entries may not always produce the best outcome. Thus, an online conflict detection procedure executed for each incoming packet is needed to flag the conflicts to network administrators. In addition, the SDN controller may frequently update the service provisioning policies that are specified in the flow entries and deliver them to the switches in a large OpenFlow-based environment. This needs a high-performance conflict detection mechanism to support real-time updating. However, performing conflict detection within a large flow table will be very time consuming. This paper first develops a graph-based multilevel redundancy reduction scheme to construct highly compact matching trees that will be used in conflict detection for a large flow table. Then, a conflict detection algorithm with higher performance and lower cost, the Compact Bit Vector algorithm (CBV), is proposed. The performance of the CBV has been validated through an extensive mathematical performance analysis followed by simulations, with good results in terms of requiring less time for the search, lower memory requirement and lower incremental updating time. Obviously, the CBV is very suitable for the conflict detection task of a large and frequently updated flow table.},
  archive      = {J_COMCOM},
  author       = {Yau-Hwang Kuo and Jen-Sheng Tsai and TszKwong Leung},
  doi          = {10.1016/j.comcom.2020.12.008},
  journal      = {Computer Communications},
  pages        = {31-47},
  shortjournal = {Comput. Commun.},
  title        = {A multilevel bit vector minimization method for fast online detection of conflicting flow entries in OpenFlow table},
  volume       = {167},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Flow length and size distributions in campus internet
traffic. <em>COMCOM</em>, <em>167</em>, 15–30. (<a
href="https://doi.org/10.1016/j.comcom.2020.12.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The efficiency of flow-based networking mechanisms strongly depends on traffic characteristics and should thus be assessed using accurate flow models. For example, in the case of algorithms based on the distinction between elephant and mice flows, it is extremely important to ensure realistic flows’ length and size distributions. Credible models or data are not available in literature. Numerous works contain only plots roughly presenting empirical distribution of selected flow parameters, without providing distribution mixture models or any reusable numerical data. This paper aims to fill that gap and provide reusable models of flow length and size derived from real traffic traces. Traces were collected at the Internet-facing interface of the university campus network and comprise four billion layer-4 flow (275 TB). These models can be used to assess a variety of flow-oriented solutions under the assumption of realistic conditions. Additionally, this paper provides a tutorial on constructing network flow models from traffic traces. The proposed methodology is universal and can be applied to traffic traces gathered in any network. We also provide an open source software framework to analyze flow traces and fit general mixture models to them.},
  archive      = {J_COMCOM},
  author       = {Piotr Jurkiewicz and Grzegorz Rzym and Piotr Boryło},
  doi          = {10.1016/j.comcom.2020.12.016},
  journal      = {Computer Communications},
  pages        = {15-30},
  shortjournal = {Comput. Commun.},
  title        = {Flow length and size distributions in campus internet traffic},
  volume       = {167},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Unified scheduling for predictable communication reliability
in cellular networks with D2D links. <em>COMCOM</em>, <em>167</em>,
1–14. (<a href="https://doi.org/10.1016/j.comcom.2020.12.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cellular networks with device-to-device (D2D) links are increasingly being explored for mission-critical industrial applications which require predictable communication reliability. With interference being a major source of packet loss , it is thus critical to control interference among concurrent transmissions in a predictable manner to ensure the required communication reliability. To this end, we propose a Unified Cellular Scheduling (UCS) framework that, based on the Physical-Ratio-K (PRK) interference model, schedules uplink, downlink, and D2D transmissions in a unified manner to ensure predictable communication reliability while maximizing channel spatial reuse . UCS also provides a simple, effective approach to mode selection that maximizes the communication capacity for each involved communication pair. UCS effectively uses multiple channels for high throughput as well as resilience to channel fading and external interference. Leveraging the availability of base stations (BSes) as well as high-speed, out-of-band connectivity between BSes, UCS effectively orchestrates the functionalities of BSes and user equipment (UE) for light-weight control signaling and ease of incremental deployment and integration with existing cellular standards. We have implemented UCS using the open-source, standards-compliant cellular networking platform OpenAirInterface, and we have validated the UCS design and implementation using the USRP B210 software-defined radios in the ORBIT wireless testbed . We have also evaluated UCS through high-fidelity, at-scale simulation studies; we observe that UCS ensures predictable communication reliability while achieving a higher channel spatial reuse rate than existing mechanisms, and that the distributed UCS framework enables a channel spatial reuse rate statistically equal to that in the state-of-the-art centralized scheduling algorithm iOrder.},
  archive      = {J_COMCOM},
  author       = {Yuwei Xie and Hongwei Zhang and Pengfei Ren},
  doi          = {10.1016/j.comcom.2020.12.012},
  journal      = {Computer Communications},
  pages        = {1-14},
  shortjournal = {Comput. Commun.},
  title        = {Unified scheduling for predictable communication reliability in cellular networks with D2D links},
  volume       = {167},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Mobile network traffic pattern classification with
incomplete a priori information. <em>COMCOM</em>, <em>166</em>, 262–270.
(<a href="https://doi.org/10.1016/j.comcom.2020.11.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In complex networks systems like mobile edge infrastructures, real-time traffic classification according to application types is an enabling technique for network resource optimization and advanced security management. State-of-the-art schemes take advantage of machine learning techniques to train classification models based on behavioral characteristics of network traffic flows. Nonetheless, most existing studies assume complete a priori information of the application classes and formulate the task as a standalone multi-class classification problem. Such classification models cannot properly handle the unknown applications that are absent from the training set during the time of training. In this work, we propose a practical mobile network traffic classification scheme that builds robust classifiers based on incomplete a priori information . Specifically, the core idea is to extract the unknown patterns emerging in the network periodically to complement the initial labeled data set that only consists of a limited number of known applications. We propose two algorithms for the unknown pattern extraction step. One is based on iterative asymmetric binary classification and the other is based on constrained clustering. Empirical results based on a public data set show that the proposed scheme can effectively detect both known and unknown applications.},
  archive      = {J_COMCOM},
  author       = {Zhiping Jin and Zhibiao Liang and Yu Wang and Weizhi Meng},
  doi          = {10.1016/j.comcom.2020.11.003},
  journal      = {Computer Communications},
  pages        = {262-270},
  shortjournal = {Comput. Commun.},
  title        = {Mobile network traffic pattern classification with incomplete a priori information},
  volume       = {166},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Air–ground surveillance sensor network based on edge
computing for target tracking. <em>COMCOM</em>, <em>166</em>, 254–261.
(<a href="https://doi.org/10.1016/j.comcom.2020.10.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of Internet of Things (IoT), Unmanned Aerial Vehicle (UAV) target tracking recently has received lots of attention in research community. The two major research topics in UAV target tracking include loss of a tracked target and high tracking latency, especially in the case where tracking is conducted in an area of many sight-blocking obstacles that put restrictions on a UAV’s flight altitude and block its line of sight. Most recent work on these topics focuses on improving tracking accuracy through adjusting tracking algorithms based on deep learning . But the complexity of these algorithms requires a computation capacity that a regular UAV cannot afford, and therefore tracking failure probability is still non-negligible. To address this challenge, we propose a new target tracking system, referred to as an Air–Ground Surveillance Sensor Network (AGSSN). We build AGSSN by jointly optimizing the network establishment and data transmission, and we design an algorithm ARIT to achieve an optimal tracking performance. We further carry out a series of simulations by deploying our AGSSN on a university’s campus map, and our simulation results show that our proposed AGSSN system can achieve higher reliability and significantly better performance than regular tracking systems in an area with many visually blocking obstacles.},
  archive      = {J_COMCOM},
  author       = {Xiaoheng Deng and Yajun Liu and Congxu Zhu and Honggang Zhang},
  doi          = {10.1016/j.comcom.2020.10.012},
  journal      = {Computer Communications},
  pages        = {254-261},
  shortjournal = {Comput. Commun.},
  title        = {Air–Ground surveillance sensor network based on edge computing for target tracking},
  volume       = {166},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Energy-efficient computation offloading for vehicular edge
computing networks. <em>COMCOM</em>, <em>166</em>, 244–253. (<a
href="https://doi.org/10.1016/j.comcom.2020.12.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The demanding computing capacity of emerging vehicular applications has emerged as a challenge in Internet of vehicles (IoVs). Multi-access edge computing (MEC) can significantly enhance computing capability and prolong battery life of vehicles through offloading computation-intensive tasks for edge computing . Considering the impact of vehicles’ mobility on communication quality, this paper provides an energy-efficient computation offloading scheme for vehicular edge computing networks (VECN). An energy-efficiency cost (EEC) minimization problem is formulated to make a tradeoff between latency and energy consumption, for completing computational tasks in an effective manner. Since that multiple variables and time-varying channel conditions make the formulated problem difficult to solve, we transform the original non-convex problem into a two-level optimization problem and develop an iterative distributed algorithm to obtain an optimal solution. Numerical results verify the convergence and superiority of the proposed algorithm.},
  archive      = {J_COMCOM},
  author       = {Xiaohui Gu and Guoan Zhang},
  doi          = {10.1016/j.comcom.2020.12.010},
  journal      = {Computer Communications},
  pages        = {244-253},
  shortjournal = {Comput. Commun.},
  title        = {Energy-efficient computation offloading for vehicular edge computing networks},
  volume       = {166},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A rapid coarse-grained blind wideband spectrum sensing
method for cognitive radio networks. <em>COMCOM</em>, <em>166</em>,
234–243. (<a
href="https://doi.org/10.1016/j.comcom.2020.11.015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spectrum sensing aims to sense the potential spectrum resources available in the cognitive radio environment. It is also the premise of spectrum management and spectrum sharing in cognitive radio systems . To perceive the primary user’s activity and make full use of spectrum holes, rapid detection of a broad frequency span is an essential part of cognitive radio technology. Reducing the observation time for the data collection, the data storage requirements, and hardware/software computational complexity are urgent and challenging issues in wideband spectrum sensing. High accuracy power spectral density estimation is not the primary requirement; of course, the accuracy must be controlled within the appropriate range and can support the primary user activity’s determination. This paper proposes a sub-Nyquist wideband spectrum sensing method based on compressive covariance sensing for the rapid wideband spectrum sensing. Compared with the traditional Nyquist-rate method, this method can use low-speed ADC to detect wideband signals and effectively control the observation time and computational complexity . This paper’s main contributions include: (1) developing a sub-Nyquist sampling structure based on the multi-coset sampling banks, (2) proposing a coarse-grained power spectral density estimation method for wideband spectrum sensing with short observation time and low complexity. Simulations show that the proposed method exhibits this method is suitable for fast spectral detection. At the same time, the error of spectrum analysis is basically within the acceptable range.},
  archive      = {J_COMCOM},
  author       = {Peng Feng and Yuebin Bai and Yuhao Gu and Jun Huang and Xiaolin Wang and Chang Liu},
  doi          = {10.1016/j.comcom.2020.11.015},
  journal      = {Computer Communications},
  pages        = {234-243},
  shortjournal = {Comput. Commun.},
  title        = {A rapid coarse-grained blind wideband spectrum sensing method for cognitive radio networks},
  volume       = {166},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Designing the tactile support engine to assist time-critical
applications at the edge of a 5G network. <em>COMCOM</em>, <em>166</em>,
226–233. (<a
href="https://doi.org/10.1016/j.comcom.2020.12.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The fifth generation of communications networks (5G) is not an evolution of the previous generations, but will constitute a revolution. Not only it will allow improvement in terms of quality of existing services, but also will enable several new heterogeneous applications that are not feasible with the current networks. One of the most promising research direction in the context of 5G is the Tactile Internet, an Internet network aimed at providing ultra-low latency with ultra-high availability, reliability, and ultra-secure end-to-end communication. The focus of this paper is on the Tactile Support Engine (TSE) component of a Tactile Internet Network slice . To be specific, the objective of this paper is to propose an architecture of the TSE, and integrate it with the other components of the entire Tactile Internet framework. We also present one of the most promising use cases, consisting of a video game running on a tablet controlled by a mini-stylus touch pen moved by a Linear Actuator , that is controlled by a remote player. Experimental and simulation results are provided to measure performances and demonstrate the efficiency of the proposed TSE in low-latency application scenarios.},
  archive      = {J_COMCOM},
  author       = {Christian Grasso and Karthik Eswar K.N. and Prabagarane Nagaradjane and Mridhula Ramesh and Giovanni Schembra},
  doi          = {10.1016/j.comcom.2020.12.001},
  journal      = {Computer Communications},
  pages        = {226-233},
  shortjournal = {Comput. Commun.},
  title        = {Designing the tactile support engine to assist time-critical applications at the edge of a 5G network},
  volume       = {166},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A full-duplex MAC technique to improve spectrum-efficiency
on 5G mobile wireless networks. <em>COMCOM</em>, <em>166</em>, 216–225.
(<a href="https://doi.org/10.1016/j.comcom.2020.11.020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Full-duplex (FD) communications shall play an important role on the next generation (5G) mobile wireless networks as they are expected to enhance spectrum usage and throughput. Unleashing the benefits of FD communications, however, requires a fitted design of medium access control (MAC) schemes. In spite of that, existing full-duplex MAC schemes are build upon the IEEE 802.11 which is designed to operate on half-duplex radios. The main contribution of this work is to propose a full-duplex communication mechanism devised to improve spectrum usage and throughput in the context of FD communications. The proposed scheme, named Full-Duplex Dynamic Scheduling MAC (FDDS-MAC), uses a novel strategy to select a communicating pair that maximizes the probability of establishing a full-duplex communication between sending and receiving nodes. A mathematical analysis of the proposed strategy is presented to show the potential improvement that can be achieved using FDDS-MAC. Moreover, in order to compare FDDS-MAC throughput with state-of-art full-duplex communications mechanisms, an analytical model addressing the details of a FD communication is proposed. Analytical evaluation shows that the proposed scheme provides throughput gain up to 50\% as compared to the state-of-art full-duplex communications mechanisms. Furthermore, an enhanced version of FDDS-MAC (termed FDDS-MAC*) is proposed to further reduce the time spent selecting the receiver node that maximizes the probability of establishing a full-duplex communication. Numerical results reveals that FDDS-MAC* achieved an improvement over existing full-duplex MAC schemes up to 59\% in terms of throughput, thus showing the positive impact of FDDS-MAC* deployment.},
  archive      = {J_COMCOM},
  author       = {Lucas de Melo Guimarães and Jacir Luiz Bordim},
  doi          = {10.1016/j.comcom.2020.11.020},
  journal      = {Computer Communications},
  pages        = {216-225},
  shortjournal = {Comput. Commun.},
  title        = {A full-duplex MAC technique to improve spectrum-efficiency on 5G mobile wireless networks},
  volume       = {166},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Edge computing assisted privacy-preserving data computation
for IoT devices. <em>COMCOM</em>, <em>166</em>, 208–215. (<a
href="https://doi.org/10.1016/j.comcom.2020.11.018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Along with the ubiquitous deployment of IoT devices, requirements on sensing data computation and analysis increase rapidly. However, the traditional cloud-based architecture is no longer sustained the computation load from these tremendous IoT devices, which bring the paradox of delay tolerance and bandwidth insufficiency. Fortunately, the edge computing is emerged and incorporated with the IoT network. Meanwhile, new questions arises. When and how to select among edge computing servers, and also achieve a well balance between consumed energy, transmission delay and data privacy. In this paper, we consider the problem that how IoT devices allocate their computation loads among edge computing servers and their on-chip computation units, to balance energy efficiency and data privacy in physical layer . Firstly, the optimization function of IoT devices is derived which reflects the energy consumption, transmission delay and also privacy requirement; Secondly, the direct transmission scenario is analyzed, and optimal transmit power are derived with or without privacy factors; Thirdly, we extend the model to relay transmission scenario when edge computing servers are far away, and propose the relay selection algorithm for IoT devices; Finally, by extensive simulations, two main conclusions are verified: the energy consumption remains the same with data privacy protection, energy saved 54.9\% on average using relay IoT devices compared to direct transmission case.},
  archive      = {J_COMCOM},
  author       = {Gaofei sun and Xiaoshuang Xing and Zhenjiang Qian and Wei (Lisa) Li},
  doi          = {10.1016/j.comcom.2020.11.018},
  journal      = {Computer Communications},
  pages        = {208-215},
  shortjournal = {Comput. Commun.},
  title        = {Edge computing assisted privacy-preserving data computation for IoT devices},
  volume       = {166},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Improving transaction success rate in cryptocurrency payment
channel networks. <em>COMCOM</em>, <em>166</em>, 196–207. (<a
href="https://doi.org/10.1016/j.comcom.2020.12.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Blockchain-based cryptocurrencies has received a substantial interest in the last decade as Blockchain can ensure trust among users without relying on third parties. However, cryptocurrency adoption for micro-payments has been limited due to slow confirmation of transactions and unforeseeable high fees, especially in the case of Bitcoin . To this end, creating off-chain payment channels between users is proposed which enables instant and nearly free transactions without writing to blockchain. Off-chain channel idea is then extended to establish payment channel networks to scale the idea to allow payment routing among many users. However, due to the way these channels are designed, both sides of a channel have a fixed one-way capacity for making transactions. Consequently, if one side consumes the whole one-way capacity, the channel becomes non-transitive in that particular direction, which causes failures of payments that would like to pass through. Eventually, the network becomes partitioned with unevenly distributed funds. In this paper, we propose the adoption of three specific techniques that aim to increase the overall success rate of payments and address channel imbalance problem to keep the payment channel network sustainable in the long run. First, we show the effectiveness of balance-aware routing that better utilizes available funds in the channels. Second, we propose an efficient method for selection of the gateway (i.e., connection point) for a user by considering the gateway’s inbound and outbound capacity. It exploits the fact that end-users can connect the network through multiple gateways any of which can be used to initiate the payment. Finally, we propose proportional payment splitting method to further increase success rate especially for large transactions. We implemented the three approaches for assessing their effectiveness. Compared to existing approaches such as maximum flow or greedy, the proposed approaches can achieve much higher success rates with channels balanced better.},
  archive      = {J_COMCOM},
  author       = {Suat Mercan and Enes Erdin and Kemal Akkaya},
  doi          = {10.1016/j.comcom.2020.12.009},
  journal      = {Computer Communications},
  pages        = {196-207},
  shortjournal = {Comput. Commun.},
  title        = {Improving transaction success rate in cryptocurrency payment channel networks},
  volume       = {166},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Stochastic geometry approach towards interference management
and control in cognitive radio network: A survey. <em>COMCOM</em>,
<em>166</em>, 174–195. (<a
href="https://doi.org/10.1016/j.comcom.2020.12.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Interference management and control in the cognitive radio network (CRN) is a necessity if the activities of primary users must be protected from excessive interference resulting from the activities of neighboring users. Hence, interference experienced in wireless communication networks has earlier been characterized using the traditional grid model. Such models, however, lead to non-tractable analyses, which often require unrealistic assumptions, leading to inaccurate results. These limitations of the traditional grid models mean that the adoption of stochastic geometry (SG) continues to receive a lot of attention owing to its ability to capture the distribution of users properly, while producing scalable and tractable analyses for various performance metrics of interest. Despite the importance of CRN to next-generation networks, no survey of the existing literature has been done when it comes to SG-based interference management and control in the domain of CRN. Such a survey is, however, necessary to provide the current state of the art as well as future directions. This paper hence presents a comprehensive survey related to the use of SG to effect interference management and control in CRN. We show that most of the existing approaches in CRN failed to capture the relationship between the spatial location of users and temporal traffic dynamics and are only restricted to interference modeling among non-mobile users with full buffers. This survey hence encourages further research in this area. Finally, this paper provides open problems and future directions to aid in finding more solutions to achieve efficient and effective usage of the scarce spectral resources for wireless communications.},
  archive      = {J_COMCOM},
  author       = {Samuel D. Okegbile and Bodhaswar T. Maharaj and Attahiru S. Alfa},
  doi          = {10.1016/j.comcom.2020.12.011},
  journal      = {Computer Communications},
  pages        = {174-195},
  shortjournal = {Comput. Commun.},
  title        = {Stochastic geometry approach towards interference management and control in cognitive radio network: A survey},
  volume       = {166},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Flexible and anonymous network slicing selection for c-RAN
enabled 5G service authentication. <em>COMCOM</em>, <em>166</em>,
165–173. (<a
href="https://doi.org/10.1016/j.comcom.2020.12.014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The fifth generation (5G) mobile communication technologies significantly promote the development of attractive applications such as automatic driving and telemedicine due to its lower latency, higher data rate and massive connectivities. In addition, 5G network slices can be used to realize tailored transmission network according to users’ different requirements. Nevertheless, 5G still suffers from security, privacy and performance issues exemplified by authenticated key agreement , identity and network slice privacy, and the flexibility and efficiency of network slice selection. In this paper, we tackle these challenges by proposing FANS, a Flexible and Anonymous Network Slicing method for cloud radio access network enabled authentication of emerging 5G service. FANS achieves users’ identity privacy protection by hiding the public key associated with the actual identity in transmitted messages. The privacy, flexibility and efficiency of network slice selection are realized by adopting the idea of privacy-aware one-to-many matching which has been used in anonymous attribute-based encryption. Based on comprehensive security and performance analysis, FANS is shown to be secure and efficient.},
  archive      = {J_COMCOM},
  author       = {Yinghui Zhang and Axin Wu and Zhenwei Chen and Dong Zheng and Jin Cao and Xiaohong Jiang},
  doi          = {10.1016/j.comcom.2020.12.014},
  journal      = {Computer Communications},
  pages        = {165-173},
  shortjournal = {Comput. Commun.},
  title        = {Flexible and anonymous network slicing selection for C-RAN enabled 5G service authentication},
  volume       = {166},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A privacy and session key based authentication scheme for
medical IoT networks. <em>COMCOM</em>, <em>166</em>, 154–164. (<a
href="https://doi.org/10.1016/j.comcom.2020.11.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to rapid increase rate of smart medical devices , the existing security internet of things (IoT) protocols cannot guaranty to perform better in-term of various threats. In this paper, the Secure Addressing and Mutual Authentication protocol (SAMA) scheme is proposed to protect the network from multiple attacks. The SAMA scheme uses the unique addressing and identification method to authenticates the smart medical monitoring devices, so that they can uniquely identifies in medical IoT network. Additionally, the proposed scheme also preserves anonymity with the help of session key establishment to secure communication between the user and medical server. The performance of SAMA scheme has been evaluated in-term of functionality, computation and communication cost, and results are compared with existing schemes. Finally for security, the proposed scheme is also analyzed formally and informally using AVISPA tool and widely-accepted BAN logic model. The security analysis shows that the SAMA scheme ensures security against, such as, impersonation, password guessing , man-in-the-middle attack replay, etc.},
  archive      = {J_COMCOM},
  author       = {Pankaj Kumar and Lokesh Chouhan},
  doi          = {10.1016/j.comcom.2020.11.017},
  journal      = {Computer Communications},
  pages        = {154-164},
  shortjournal = {Comput. Commun.},
  title        = {A privacy and session key based authentication scheme for medical IoT networks},
  volume       = {166},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Role recommender-RBAC: Optimizing user-role assignments in
RBAC. <em>COMCOM</em>, <em>166</em>, 140–153. (<a
href="https://doi.org/10.1016/j.comcom.2020.12.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In a rapidly changing IT environment, access to the resources involved in various projects might change randomly based on the role-based access control (RBAC) system. Hence, the security administrator needs to dynamically maintain the role assignments to users for optimizing user-role assignments. The manual updation of user-role assignments is prone to error and increases administrative workload. Therefore, a role recommendation model is introduced for the RBAC system to optimize user-role assignments based on user behaviour patterns. It is shown that the model automatically revokes and refurbishes the user-role assignments by observing user access behaviour. This model is used in the cloud for providing Role-Assignment-as-a-Service to optimize the cost of built-in roles. Several experiments are conducted to verify the proposed model using the Amazon access sample dataset . The experimental results show that the efficiency of the proposed model is 50\% higher than the state-of-the-art.},
  archive      = {J_COMCOM},
  author       = {K. Rajesh Rao and Ashalatha Nayak and Indranil Ghosh Ray and Yogachandran Rahulamathavan and Muttukrishnan Rajarajan},
  doi          = {10.1016/j.comcom.2020.12.006},
  journal      = {Computer Communications},
  pages        = {140-153},
  shortjournal = {Comput. Commun.},
  title        = {Role recommender-RBAC: Optimizing user-role assignments in RBAC},
  volume       = {166},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Industrial internet of things and its applications in
industry 4.0: State of the art. <em>COMCOM</em>, <em>166</em>, 125–139.
(<a href="https://doi.org/10.1016/j.comcom.2020.11.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Industrial Internet of Things (IIoT) is a convincing stage by interfacing different sensors around us to the Internet, giving incredible chances for the acknowledgment of brilliant living. It is a fast growing technology in the present scenario. IIoT has its effect on almost every advanced field in the society. It has impact not only on work, but also on the living style of individual and organization. Due to high availability of internet, the connecting cost is decreasing and more advanced systems has been developed with Wi-Fi capabilities. The concept of connecting any device with internet is “IIoT”, which is becoming new rule for the future. This manuscript discusses about the applications of Internet of Things in different areas like — automotive industries, embedded devices, environment monitoring, agriculture, construction, smart grid, health care, etc. A regressive review of the existing systems of the automotive industry, emergency response, and chain management on IIoT has been carried out, and it is observed that IIoT found its place almost in every field of technology.},
  archive      = {J_COMCOM},
  author       = {Praveen Kumar Malik and Rohit Sharma and Rajesh Singh and Anita Gehlot and Suresh Chandra Satapathy and Waleed S. Alnumay and Danilo Pelusi and Uttam Ghosh and Janmenjoy Nayak},
  doi          = {10.1016/j.comcom.2020.11.016},
  journal      = {Computer Communications},
  pages        = {125-139},
  shortjournal = {Comput. Commun.},
  title        = {Industrial internet of things and its applications in industry 4.0: State of the art},
  volume       = {166},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An ensemble learning and fog-cloud architecture-driven
cyber-attack detection framework for IoMT networks. <em>COMCOM</em>,
<em>166</em>, 110–124. (<a
href="https://doi.org/10.1016/j.comcom.2020.12.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Internet of Medical Things (IoMT), an application of Internet of Things (IoT), is addressing countless limitation of traditional health-care systems such as quality of patient care, healthcare costs, shortage of medical staff and inadequate medical supplies in an efficient manner. With the use of the IoMT systems, there are unparalleled benefits that are enhancing the quality and efficiency of treatments and thereby are improving patients health . However, the 2018 Ransomware cyber-attack on Indiana hospital system exposed the critical fault-lines among IoMT environment. The gravity and frequency of cyber-attacks are expanding at an alarming rate. Motivated from aforementioned challenges, we propose an ensemble learning and fog-cloud architecture-driven cyber-attack detection framework for IoMT networks. The ensemble design, combines Decision Tree , Naive Bayes, and Random Forest as first-level individual learners . In the next level, the classification results are used by XGBoost for identifying normal and attack instances. Second, for dynamic and heterogeneous networks such as IoMT, fog, and cloud, we present a deployment architecture for the proposed framework as, Software as a Service (SaaS) in fog side and Infrastructure as a Service (IaaS) in cloud side. Further, most of the existing work is evaluated using KDD CUP99 or NSL-KDD dataset. These datasets lack modern IoMT-based attacks. Therefore, the proposed model uses a realistic dataset namely, ToN-IoT which is collected from a heterogeneous and large-scale IoT network. The experimental result shows that the proposed framework can achieve detection rate of 99.98\%, accuracy of 96.35\%, and can reduce false alarm rate up to 5.59\%.},
  archive      = {J_COMCOM},
  author       = {Prabhat Kumar and Govind P. Gupta and Rakesh Tripathi},
  doi          = {10.1016/j.comcom.2020.12.003},
  journal      = {Computer Communications},
  pages        = {110-124},
  shortjournal = {Comput. Commun.},
  title        = {An ensemble learning and fog-cloud architecture-driven cyber-attack detection framework for IoMT networks},
  volume       = {166},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Private blockchain-based access control mechanism for
unauthorized UAV detection and mitigation in internet of drones
environment. <em>COMCOM</em>, <em>166</em>, 91–109. (<a
href="https://doi.org/10.1016/j.comcom.2020.12.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Drones, which are also known as Unmanned Aerial Vehicles (UAVs), are very useful in delivering the packages, and real-time object detection and tracking with minimal human interference. However, there may be several security threats in such an environment, for instance, a malicious user can spy unauthorized drones, transfer malicious packages, or even damage the network reliability that can have direct impact on drones control. This may lead to a potential threat for people, governments, and business sectors. To deal with these issues, in this paper, we propose a novel access control scheme for unauthorized UAV detection and mitigation in an Internet of Drones (IoD) environment, called ACSUD-IoD. With the help of the blockchain-based solution incorporated in ACSUD-IoD, the transactional data having both the normal secure data from a drone (UAV) to the Ground Station Server ( G S S ) (GSS) and the abnormal (suspected) data for detection of unauthorized UAVs by the G S S GSS are stored in private blockchain , that are authentic and genuine. As a result, the Big data analytics can be performed on the authenticated transactional data stored in the blockchain . Through the detailed security analysis including formal security under the broadly-accepted Real-Or-Random (ROR) model, formal security verification using the widely-applied Automated Validation of Internet Security Protocols and Applications (AVISPA) tool and non-mathematical security analysis show the robustness of the proposed scheme against a number of potential attacks needed in an IoD environment. The testbed experiments for various cryptographic primitives using the broadly-accepted Multiprecision Integer and Rational Arithmetic Cryptographic Library (MIRACL) have been performed under both server and Raspberry PI 3 configurations. Furthermore, a detailed comparative analysis among the proposed scheme and other existing competing schemes shows the efficacy and more robustness as compared to the existing schemes. Finally, the blockchain-based practical demonstration shows the effectiveness of the proposed scheme.},
  archive      = {J_COMCOM},
  author       = {Basudeb Bera and Ashok Kumar Das and Anil Kumar Sutrala},
  doi          = {10.1016/j.comcom.2020.12.005},
  journal      = {Computer Communications},
  pages        = {91-109},
  shortjournal = {Comput. Commun.},
  title        = {Private blockchain-based access control mechanism for unauthorized UAV detection and mitigation in internet of drones environment},
  volume       = {166},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Pricing-based interference management scheme in LTE-V2V
communication with imperfect channel state information. <em>COMCOM</em>,
<em>166</em>, 81–90. (<a
href="https://doi.org/10.1016/j.comcom.2020.12.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, an effective LTE-V2V (long-term-evolution vehicle-to-vehicle) communication system is studied, where the uplink channel of the cellular user equipment (CUE) is reused by the multiple V2V links. Considering the co-channel interference caused by channel reusing between CUE and V2V links, a pricing framework of interference management for V2V links and CUE is proposed. In the LTE-V2V communication networks, the base station (BS) protects the serving CUE by pricing the cross-tier interference caused by V2V links. A Stackelberg game is presented to model the interaction between the BS and V2V links. In order to ensure the communication quality of CUE, the total interference generated by V2V links has to be lower than the interference threshold. Specifically, the BS prices the tolerable interference to maximize its revenue. For the given prices, the V2V links competitively adapt their power allocation strategies to maximize the individual utility. Two pricing iterative algorithms , uniform pricing scheme and the non-uniform pricing scheme, are proposed to incorporate with the theory of noncooperative game, in order to analyze the competition between V2V links. In addition, the time-varying characteristics of vehicle communication are considered due to the high-speed mobility of the V2V users. The imperfect channel state information (CSI) fading model is constructed with the large-scale fading and small-scale fading jointly. Numerical simulation results validate the reliability and effectiveness of the proposed algorithms.},
  archive      = {J_COMCOM},
  author       = {Zhixin Liu and Yongkang Wang and Yazhou Yuan and Kit Yan Chan},
  doi          = {10.1016/j.comcom.2020.12.002},
  journal      = {Computer Communications},
  pages        = {81-90},
  shortjournal = {Comput. Commun.},
  title        = {Pricing-based interference management scheme in LTE-V2V communication with imperfect channel state information},
  volume       = {166},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Long-term optimization for MEC-enabled HetNets with
device–edge–cloud collaboration. <em>COMCOM</em>, <em>166</em>, 66–80.
(<a href="https://doi.org/10.1016/j.comcom.2020.11.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For effective computation offloading with multi-access edge computing (MEC), both communication and computation resources should be properly managed, considering the dynamics of mobile users such as the time-varying demands and user mobility. Most existing works regard the remote cloud server as a special edge server. However, service quality cannot be met when some of the edge servers cannot be connected. Besides, the computation capability of the cloud has not been fully exploited especially when edge servers are congested. We develop an on-line offloading decision and computational resource management algorithm with joint consideration of collaborations between device–cloud, edge–edge and edge–cloud. The objective is to minimize the total energy consumption of the system, subject to computational capability and task buffer stability constraints. Lyapunov optimization technique is used to jointly deal with the delay-energy trade-off optimization and load balancing. The optimal CPU-cycle frequencies, best transmission powers and offloading scheduling policies are jointly handled in the three-layer system. Extensive simulation results demonstrate that, with V V varies in [ 0 . 1 , 5 ] × 1 0 9 [0.1,5]×109 , the proposed algorithm can save more than 50\% energy and over 120\% task processing time than three existing benchmark algorithms averagely.},
  archive      = {J_COMCOM},
  author       = {Long Chen and Jigang Wu and Jun Zhang},
  doi          = {10.1016/j.comcom.2020.11.011},
  journal      = {Computer Communications},
  pages        = {66-80},
  shortjournal = {Comput. Commun.},
  title        = {Long-term optimization for MEC-enabled HetNets with device–edge–cloud collaboration},
  volume       = {166},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Class consistent and joint group sparse representation model
for image classification in internet of medical things. <em>COMCOM</em>,
<em>166</em>, 57–65. (<a
href="https://doi.org/10.1016/j.comcom.2020.11.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The amount of data handled by Internet of Medical Things (IoMT) devices grows exponentially, which means higher exposure of sensitive data. The security and privacy of the data collected from IoMT devices, either during their transmission to a cloud or while stored in a cloud, are major unresolved matters. Automated human larynx carcinoma (HEp-2) cell classification is critical for medical diagnosis, but most of traditional HEp-2 cell classification algorithms dramatically rely on a single modal feature or fuse different modality features based on fixed weighted schemes, with the result that the complementary information of multimodal features will be not reasonably utilized. In this paper, a class consistent and joint group sparse representation model ( CCJGSR ) is proposed, expresses the test data through the sparse linear combination of training data and constrains the observations from different modalities of the test object to share their sparse statements. Group sparse representation can fully explore the complementary relationships among different modality features. At the same time, the objective function embeds both the group regularization terms and class consistent, where they enforce the intuitive constraint which the predicted class labels are consistent across all modalities. The experimental results on the HEp2 cell dataset indicate that our proposed algorithm is robust and efficient, and it outperforms existing approaches.},
  archive      = {J_COMCOM},
  author       = {Zan Gao and Yuchan Yang and Mohammad R. Khosravi and Shaohua Wan},
  doi          = {10.1016/j.comcom.2020.11.013},
  journal      = {Computer Communications},
  pages        = {57-65},
  shortjournal = {Comput. Commun.},
  title        = {Class consistent and joint group sparse representation model for image classification in internet of medical things},
  volume       = {166},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Dynamic path planning for unmanned surface vehicle in
complex offshore areas based on hybrid algorithm. <em>COMCOM</em>,
<em>166</em>, 49–56. (<a
href="https://doi.org/10.1016/j.comcom.2020.11.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {According to its planning scope, path planning for unmanned surface vehicle (USV) can be divided into global and local path planning . Many scholars have improved the classic algorithms, including grids method, visibility graph method, A* algorithm and artificial potential field method (APF), But the global planning algorithm still has outstanding problems such as long calculation time and large computational overhead in large task space, local planning algorithms usually ignore the global optimal constraints. Aiming at the problem of dynamic path planning of environmental monitoring USV under complicated offshore navigation conditions, based on the idea of bi-level planning, a hybrid algorithm which combines global and local path planning is proposed. This paper first proposes an improved Particle Swarm Optimization (PSO) for global path planning according to the given information about marine environment, and introduces Opposition-based Learning (OBL) and improves the inertia weight as well as search step size to effectively avoid the precocity of PSO. Then on the basis of global optimized path and sensor information, the improved Artificial Potential Field (APF) algorithm is adopted for local dynamic obstacle avoidance, so as to solve the local minimum problem. The results of simulation indicated that the improved PSO can effectively avoid the precocity of particles and enhance the optimization capability and stability of the PSO; the improved APF would not be restricted by local minimum point and achieve dynamic obstacle avoidance under the constraints of global optimization path. Therefore, the combination of these two algorithms can effectively solve the problems of path optimization and dynamic obstacle avoidance for environment monitoring USV when it is executing missions in complex offshore areas.},
  archive      = {J_COMCOM},
  author       = {Zheng Wang and Guangfu Li and Jia Ren},
  doi          = {10.1016/j.comcom.2020.11.012},
  journal      = {Computer Communications},
  pages        = {49-56},
  shortjournal = {Comput. Commun.},
  title        = {Dynamic path planning for unmanned surface vehicle in complex offshore areas based on hybrid algorithm},
  volume       = {166},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Combined diffusion approximation–simulation model of AQM’s
transient behavior. <em>COMCOM</em>, <em>166</em>, 40–48. (<a
href="https://doi.org/10.1016/j.comcom.2020.11.014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The article introduces an approach combining diffusion approximation and simulation ones. Furthermore, it describes how it can be used to evaluate active queue management (AQM) mechanisms. Based on the obtained queue distributions, the simulation part of the model decides on package losses and modifies the flow intensity sent by the transmitter. The diffusion is used to estimate queue distributions and the goal of the simulation part of the model is to represent the AQM mechanism. On the one hand, the use of the diffusion part considerably accelerates the performance of the whole model. On the other hand, the simulation increases the accuracy of the diffusion part. We apply the model to compare the performance of fractional order P I η PIη controller used in AQM with the performance of RED , a well known active queue management mechanism.},
  archive      = {J_COMCOM},
  author       = {Dariusz Marek and Adam Domański and Joanna Domańska and Tadeusz Czachórski and Jerzy Klamka and Jakub Szyguła},
  doi          = {10.1016/j.comcom.2020.11.014},
  journal      = {Computer Communications},
  pages        = {40-48},
  shortjournal = {Comput. Commun.},
  title        = {Combined diffusion approximation–simulation model of AQM’s transient behavior},
  volume       = {166},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Analysis of backlog and delay in downlink power-domain
non-orthogonal multiple access wireless networks. <em>COMCOM</em>,
<em>166</em>, 26–39. (<a
href="https://doi.org/10.1016/j.comcom.2020.11.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As important quality-of-service (QoS) performance indicators, backlog and delay in wireless networks must be in compliance with the requirement of low-latency and high-reliability scenarios. Non-orthogonal multiple access (NOMA) is a novel and key wireless technology for the next generation of mobile communications. Its potential impacts on backlog and delay deserve to be specially studied. Meanwhile, the stochastic network calculus is an effective tool for analyzing network performances such as backlog and delay. In this paper, for both orthogonal multiple access (OMA) scheme and NOMA scheme, we utilize the stochastic network calculus to characterize respectively cumulative service processes of channels in a downlink network. Based on moment generating functions , the closed-form expressions of the upper bounds on backlog and delay are derived through the definite integral and special function. Simulation results validate reasonableness and effectiveness of the proposed approach. We show that in terms of backlog and delay, performances cannot be always improved by substituting NOMA scheme for OMA scheme, except when the channel gain gap between users is significantly big. Moreover, the sensitivity to the same factor such as arrival rate, transmission power and power allocation , differs from user to user in NOMA. By simulations, it is further demonstrated that the performance loss due to a finite buffer in practical scenarios is acceptable and sometimes negligible, as long as the buffer size is set to be just moderate.},
  archive      = {J_COMCOM},
  author       = {Yunpei Chen and Qi Zhu and Chunyan Feng and Xiaohui Li},
  doi          = {10.1016/j.comcom.2020.11.005},
  journal      = {Computer Communications},
  pages        = {26-39},
  shortjournal = {Comput. Commun.},
  title        = {Analysis of backlog and delay in downlink power-domain non-orthogonal multiple access wireless networks},
  volume       = {166},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A provably secure authentication scheme for RFID-enabled UAV
applications. <em>COMCOM</em>, <em>166</em>, 19–25. (<a
href="https://doi.org/10.1016/j.comcom.2020.11.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Advantages of Physically Uncloneable Functions (PUFs) have led to appearing a substantial number of novel identification and authentication based systems such as Radio frequency identification (RFID), which is expected to replace the conventional bar-code identification system due to its advantages such as real-time recognition of a considerable number of objects. For example, RFID can be used to identify an unmanned aerial vehicle (UAV) when it is attached with a tag. In this article, we propose a novel anonymous authentication scheme for RFID-enabled UAV applications using Physically Unclonable Functions. Security and the performance analyses demonstrate that our proposed scheme is secure and efficient. Hence, it can be useful for several RFID-based secure application systems.},
  archive      = {J_COMCOM},
  author       = {Prosanta Gope and Owen Millwood and Neetesh Saxena},
  doi          = {10.1016/j.comcom.2020.11.009},
  journal      = {Computer Communications},
  pages        = {19-25},
  shortjournal = {Comput. Commun.},
  title        = {A provably secure authentication scheme for RFID-enabled UAV applications},
  volume       = {166},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Do we need a contact tracing app? <em>COMCOM</em>,
<em>166</em>, 9–18. (<a
href="https://doi.org/10.1016/j.comcom.2020.11.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The goal of this paper is to shed some light on the usefulness of a contact tracing smartphone app for the containment of the COVID-19 pandemic. We review the basics of contact tracing during the spread of a virus, we contextualize the numbers to the case of COVID-19 and we analyze the state of the art for proximity detection using Bluetooth Low Energy . Our contribution is to assess if there is scientific evidence of the benefit of a contact tracing app in slowing down the spread of the virus using present technologies. Our conclusion is that such evidence is lacking, and we should re-think the introduction of such a privacy-invasive measure.},
  archive      = {J_COMCOM},
  author       = {Leonardo Maccari and Valeria Cagno},
  doi          = {10.1016/j.comcom.2020.11.007},
  journal      = {Computer Communications},
  pages        = {9-18},
  shortjournal = {Comput. Commun.},
  title        = {Do we need a contact tracing app?},
  volume       = {166},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Privacy-preserving compression model for efficient IoMT ECG
sharing. <em>COMCOM</em>, <em>166</em>, 1–8. (<a
href="https://doi.org/10.1016/j.comcom.2020.11.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electrocardiogram (ECG) signals are widely used in most remote IoMT systems. Continuous monitoring of patients is required, especially in a pandemic time where doctors recommend telemedicine . This means a massive amount of ECG data is generated, sent to cloud servers, and needs to be shared with legitimate professionals. Therefore, this paper proposes a novel privacy-preserving and efficient technique to reduce the burden on the network while ensuring the privacy of ECG. To ensure efficiency, we use a shallow neural network to learn/remember the ECG shape and represents that in a few neurons. To avoid any loss, the minor residuals between this representation and the original signal is measured and encoded to small footprint using Burrow–Wheeler transform (BWT), followed by move-to-front (MTF) and run-length encoding. To ensure the privacy, only representation neurons are encrypted using a S e s s i o n K e y SessionKey obtained from the health authority (HA) server along with S e s s i o n I D SessionID every-time an ECG signal needs to be transmitted. Hence, health authority alone is able to link that S e s s i o n I D SessionID to the patient. Whenever a doctor wants to diagnose an ECG of the patient, HA will share only those two parameters which allow the authorized doctor to see a specific ECG. The model is evaluated using raw ECG data collected from Physio-net. The results obtained are compared and analyzed with the widely used state of art techniques. The results show that the proposed technique outperforms the other techniques by an increase of 50\% in size reduction and 60\% in transmission time while ensuring the privacy.},
  archive      = {J_COMCOM},
  author       = {Ayman Ibaida and Alsharif Abuadbba and Naveen Chilamkurti},
  doi          = {10.1016/j.comcom.2020.11.010},
  journal      = {Computer Communications},
  pages        = {1-8},
  shortjournal = {Comput. Commun.},
  title        = {Privacy-preserving compression model for efficient IoMT ECG sharing},
  volume       = {166},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An intelligent recommendation algorithm for red team
strategy in edge computing powered massive cyber defense exercise.
<em>COMCOM</em>, <em>165</em>, 141–148. (<a
href="https://doi.org/10.1016/j.comcom.2020.10.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The recent surge in the frequency and seriousness of cyber attacks is alarming and poses a critical threat against the stability of our society. Previously, most effort to mitigate cyber attacks has focused on the technical countermeasures . However, a number of recent cyber attacks showed the necessity of constantly offering proper massive Cyber Defense eXercise (CDX) to the workforce in a timely manner. In order to meet the ever growing demand, the most recent massive CDX platform utilizes various edge computing concepts to locally manage the overhead related to the trainees (blue team members) in real time unlike the traditional centralized CDX platform. So far, such massive CDX platform cannot be fully operational without sufficient number of qualified trainers (red team members) who have strong expertise in cyber offense and are willing to participate the CDX. Unfortunately, securing enough number of such red team members is greatly challenging in practice. To address this issue, this paper introduces an intelligent recommendation algorithm for the red team in a massive CDX so that such massive CDX can be organized without enough number of red team members with a strong expertise in cyber offense. Given a known attack graph for each cyber defense training module , we formally define the problem of identifying a subgraph including a victorious strategy for the red team as the victory subgraph computation problem. Then, we introduce a new algorithm to solve this problem as well as a new strategy to obtain a winning strategy for the offense team to assist such red team members. Besides, we also discuss about various approach to utilize our result to organize massive CDXs in an efficient manner.},
  archive      = {J_COMCOM},
  author       = {Moonsu Jang and Donghyun Kim and Daehee Seo and Yongmin Ju and Seungho Ryu and Hyunsoo Yoon},
  doi          = {10.1016/j.comcom.2020.10.008},
  journal      = {Computer Communications},
  pages        = {141-148},
  shortjournal = {Comput. Commun.},
  title        = {An intelligent recommendation algorithm for red team strategy in edge computing powered massive cyber defense exercise},
  volume       = {165},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Lightweight blockchain assisted secure routing of swarm UAS
networking. <em>COMCOM</em>, <em>165</em>, 131–140. (<a
href="https://doi.org/10.1016/j.comcom.2020.11.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The prominent capacities of 5G New Radio (5G NR) cellular networking drive the rapid development of many fields. The ubiquitous implementations of 5G NR cellular networking also provide swarm Unmanned Aircraft System (UAS) networking the feasibility of scalable deployment and smart control. However, the conveniences derived from 5G NR also bring other vulnerabilities to swarm UAS networking. The advanced capacities of 5G NR enable attackers to commit disruptive attacks to swarm UAS networking more severely and quickly. The requirement for the security of swarm UAS networking is imminent. In this paper, we propose a lightweight Blockchain-based secure routing algorithm for swarm UAS networking. We leverage the lightweight Blockchain to enhance the security of routing of swarm UAS networking which is based on 5G NR cellular networking. Different from the conventional routing algorithms, the proposed algorithm with lightweight Blockchain can avoid the malicious connections from attackers, recognize the malicious UASs and mitigate the attacks from malicious UASs. Concurrently, the proposed algorithm are swarm UAS oriented which aims to extend the deployment of swarm UAS networking on a large scale. Compared with Proof-of-Work (PoW) and Proof-of-Stake(PoS), we adopt pheromone to estimate the traffic status of each UAS in swarm UAS networking, construct consensus for swarm UAS networking with Proof-of-Traffic (PoT) and synchronize the updated blocks for lightweight Blockchain passively under the constraints of energy consumption. The evaluation shows PoT can reduce the routing consumption in the processes of consensus construction and blocks synchronization. Compatible with the constrained resource of swarm UASs, the lightweight Blockchain-assisted approach, proposed in this paper, can maintain the efficiency of swarm UAS networking.},
  archive      = {J_COMCOM},
  author       = {Jian Wang and Yongxin Liu and Shuteng Niu and Houbing Song},
  doi          = {10.1016/j.comcom.2020.11.008},
  journal      = {Computer Communications},
  pages        = {131-140},
  shortjournal = {Comput. Commun.},
  title        = {Lightweight blockchain assisted secure routing of swarm UAS networking},
  volume       = {165},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Quality of service provisioning through resource
optimisation in heterogeneous cognitive radio sensor networks.
<em>COMCOM</em>, <em>165</em>, 122–130. (<a
href="https://doi.org/10.1016/j.comcom.2020.11.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, cognitive radio sensor networks (CRSN) have evolved as a result of the introduction of cognitive capabilities to conventional wireless sensor networks . In most CRSN designs, secondary users and/or sensor nodes are permitted, under certain constraints, to use the limited resources of a primary network. One major challenge with CRSN is how to optimally appropriate and use the limited resources available in driving their communication demands. To overcome this challenge, in this paper, we develop a resource allocation (RA) model that is capable of achieving a target quality of service (QoS) demand for the heterogeneous CRSN, despite the huge resource constraints imposed on the network. The RA problem developed is a complex optimisation problem . We analyse and solve the complex RA problem using the optimisation approaches of integer linear programming , Lagrangian duality and by a heuristic. We then study the performance of the RA model for the different solution approaches investigated. The results obtained are used to establish the optimality-complexity trade-off, which is a critical criterion for QoS decision-making in practical CRSN applications.},
  archive      = {J_COMCOM},
  author       = {Babatunde S. Awoyemi and Bodhaswar T. Maharaj},
  doi          = {10.1016/j.comcom.2020.11.006},
  journal      = {Computer Communications},
  pages        = {122-130},
  shortjournal = {Comput. Commun.},
  title        = {Quality of service provisioning through resource optimisation in heterogeneous cognitive radio sensor networks},
  volume       = {165},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Routing optimization with path cardinality constraints in a
hybrid SDN. <em>COMCOM</em>, <em>165</em>, 112–121. (<a
href="https://doi.org/10.1016/j.comcom.2020.11.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The emergence of Software Defined Networking (SDN) increases the flexibility of routing and provides an efficient approach to balance network flows. Due to the economical and technical challenges in transiting to a full SDN-enabled network, a hybrid SDN, with a partial deployment of SDN switches in a traditional network, has been a prevailing network architecture . For a hybrid SDN, the routing flexibility is influenced by the expensive and limited Ternary Content Addressable Memory (TCAM) resource, where SDN switches store the flow entries dispatched from SDN controllers. Considering the limited TCAM resource, to reduce the abundant flow entries in TCAM, we propose to impose the constraints on the number of routing paths (i.e., path cardinality constraints) when optimize flows routing. To solve this problem, in this paper, we first formulate the routing optimization problem with the path cardinality constraints in a hybrid SDN as a Mixed Integer Non-Linear Programming (MINLP) problem. Then, we propose an incremental deployment method for obtaining a hybrid SDN and an H-permissible Paths Routing Scheme (HPRS) to effectively route traffic flows under the path cardinality constraints. After that, the theoretic analysis is given to prove that the approximation ratio of HPRS is O ( l o g L ) O(logL) . Finally, through extensive experiments, we demonstrate that our proposed algorithm HPRS can efficiently reduce flow entries and approximates optimal routing under different network topologies .},
  archive      = {J_COMCOM},
  author       = {Yingya Guo and Huan Luo and Zhiliang Wang and Xia Yin and Jianping Wu},
  doi          = {10.1016/j.comcom.2020.11.004},
  journal      = {Computer Communications},
  pages        = {112-121},
  shortjournal = {Comput. Commun.},
  title        = {Routing optimization with path cardinality constraints in a hybrid SDN},
  volume       = {165},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Privacy-preserving using homomorphic encryption in mobile
IoT systems. <em>COMCOM</em>, <em>165</em>, 105–111. (<a
href="https://doi.org/10.1016/j.comcom.2020.10.022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The data privacy concerns are increasingly affecting the Internet of things (IoT) and artificial intelligence (AI) applications, in which it is very challenging to protect the privacy of the underlying data. In recent, the advancements in the performances of homomorphic encryption (HE) make it possible to help protect sensitive and personal data in IoT applications using homomorphic encryption based schemes. This paper proposed a practical homomorphic encryption scheme that can enable data users in IoT systems to securely operate data over encrypted data , which can effectively protect the privacy of key data in the system. The experimental results demonstrated the effectiveness proposed scheme.},
  archive      = {J_COMCOM},
  author       = {Wang Ren and Xin Tong and Jing Du and Na Wang and Shan Cang Li and Geyong Min and Zhiwei Zhao and Ali Kashif Bashir},
  doi          = {10.1016/j.comcom.2020.10.022},
  journal      = {Computer Communications},
  pages        = {105-111},
  shortjournal = {Comput. Commun.},
  title        = {Privacy-preserving using homomorphic encryption in mobile IoT systems},
  volume       = {165},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A segment-graph algorithm for two-objective wireless
spectrum allocation in cognitive networks. <em>COMCOM</em>,
<em>165</em>, 97–104. (<a
href="https://doi.org/10.1016/j.comcom.2020.10.024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A segment-graph algorithm is provided for wireless spectrum allocation in cognitive networks based on the cooperation of the secondary users, which aim to maximize the utilization of the limited spectrum bands and minimize the total cost of all the secondary users to buy (or lease) the spectrum bands . The segment-graph of the complement graph of the original interference graph is defined. The proposed segment-graph algorithm is based on finding the complete subgraph of the segment-graph repeatedly. It is proved that the proposed algorithm always obtains the optimal solution if one of the segment-graphs is complete in each iteration. In general cases, the proposed algorithm dramatically reduces the total cost of all the secondary users. Comparative simulations agree with the theoretical results obtained.},
  archive      = {J_COMCOM},
  author       = {Jian Gao and Chubing Guo and Mingfeng Pu and Xin Zhang and Ying Li and Jianshe Wu and Xin Yu},
  doi          = {10.1016/j.comcom.2020.10.024},
  journal      = {Computer Communications},
  pages        = {97-104},
  shortjournal = {Comput. Commun.},
  title        = {A segment-graph algorithm for two-objective wireless spectrum allocation in cognitive networks},
  volume       = {165},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A secure and lightweight authentication scheme for next
generation IoT infrastructure. <em>COMCOM</em>, <em>165</em>, 85–96. (<a
href="https://doi.org/10.1016/j.comcom.2020.11.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While the 6G/IoT transition is on the cards, the real advantage of this transition can be realized only if the user privacy and security are guaranteed. The smartcard and password based authentication protocols can help the transition in a rapid way. However, due to insecurities and/or heavy computation, many such protocols cannot cope with the dynamic requirements of future generation networks. Recently, Kaul and Awasthi presented a robust and secure user authentication protocol based on resource friendly symmetric cryptography primitives. They declared that their introduced protocol is convenient, efficient, and secure for the applications in real-world. In contrast, this article describes that protocol of Kaul and Awasthi is not secure because an attacker can easily find the identity of a legal user that is being sent on the public channel. Further, by using the identity of a legitimate user, an attacker can impersonate himself as a legitimate user of the system and can enjoy the services given by the server. So, their protocol is susceptible to user impersonation attacks, and their claim of being secure is proven to be wrong. Therefore, we have extended their work and presented an upgraded scheme by ensuring secure communication over the entire channel. Moreover, our proposed scheme is safe not solely against user impersonation attack but also major security attacks with reasonable communication, computation, and storage costs and is a better candidate for deployment in 6G/IoT networks.},
  archive      = {J_COMCOM},
  author       = {Minahil Rana and Akasha Shafiq and Izwa Altaf and Mamoun Alazab and Khalid Mahmood and Shehzad Ashraf Chaudhry and Yousaf Bin Zikria},
  doi          = {10.1016/j.comcom.2020.11.002},
  journal      = {Computer Communications},
  pages        = {85-96},
  shortjournal = {Comput. Commun.},
  title        = {A secure and lightweight authentication scheme for next generation IoT infrastructure},
  volume       = {165},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Sharing is caring: A collaborative framework for sharing
security alerts. <em>COMCOM</em>, <em>165</em>, 75–84. (<a
href="https://doi.org/10.1016/j.comcom.2020.09.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Collaboration is a keystone of defense in the field of cybersecurity. A collaborative detection system allows multiple collaborators or service providers to share their security-incident-response data, in order to effectively identify and isolate stealthy malicious actors who hide their traffic under the umbrella of legitimate Internet data transmissions. The fundamental challenge in the design of a collaborative system is ensuring the privacy of collaborators in a decentralized setting without incurring substantial computation and communication overheads . In this paper, we use healthcare as a case study and present Sharing Is Caring (SIC), a framework that allows multiple healthcare organizations to share their security defense and attack data with other organizations for the collaborative defense against common attackers without compromising the privacy of their system configurations and user data. The SIC framework ensures two essential properties: (1) it ensures that no party should learn how a particular healthcare organization has reacted to suspected IP addresses, attacks or security incidents; and (2) it performs operations in a decentralized setting, without relying on a trusted third party. We provide an analysis of the privacy and security properties of our framework against honest-but-curious as well as malicious players. We prototype the proposed system and evaluate its performance in terms of computation time and communication bandwidth . The reasonable computation cost and bandwidth overhead make the SIC framework a feasible choice for the privacy-preserving exchange of security information among the collaborating healthcare organizations.},
  archive      = {J_COMCOM},
  author       = {Muhammad Ajmal Azad and Samiran Bag and Farhan Ahmad and Feng Hao},
  doi          = {10.1016/j.comcom.2020.09.013},
  journal      = {Computer Communications},
  pages        = {75-84},
  shortjournal = {Comput. Commun.},
  title        = {Sharing is caring: A collaborative framework for sharing security alerts},
  volume       = {165},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Internet of flying things (IoFT): A survey. <em>COMCOM</em>,
<em>165</em>, 53–74. (<a
href="https://doi.org/10.1016/j.comcom.2020.10.023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unmanned Aerial Vehicles (UAVs) have recently received significant attention by the civilian and military community, mostly due to the fast growth of UAV technologies supported by wireless communications and networking. UAVs can be used to improve the efficiency and performance of the Internet of Things (IoT) in terms of connectivity, coverage, reliability, stability, etc. In particular, to support IoT applications in an efficient manner, UAVs should be organized as a Flying Ad-hoc NETwork (FANET). FANET is a subclass of Mobile Ad-hoc Network (MANET) where nodes are Unmanned Artifact Systems (UAS). However, the deployment of UAVs in IoT is limited by several constraints, such as limited resource capacity of UAVs and ground devices, signal collision and interference, intermittent availability of the IoT infrastructure, etc. In the Internet of Flying Things (IoFT) literature, there are no survey or study that exhaustively covers and discusses all key concepts and recent works on IoFT. In this paper a comprehensive survey on the IoFT is presented, covering the state of the art in flying things with a focus on IoFT. A taxonomy of related literature on IoFT is proposed, including a classification, description and comparative study of different work on IoFT. Furthermore, the paper presents IoFT applications, IoFT challenges and future perspectives. This survey aims to provide the basic concepts and a complete overview of the recent studies on IoFT for the scientific researchers.},
  archive      = {J_COMCOM},
  author       = {Sofiane Zaidi and Mohammed Atiquzzaman and Carlos T. Calafate},
  doi          = {10.1016/j.comcom.2020.10.023},
  journal      = {Computer Communications},
  pages        = {53-74},
  shortjournal = {Comput. Commun.},
  title        = {Internet of flying things (IoFT): A survey},
  volume       = {165},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Market-based dynamic resource allocation in mobile edge
computing systems with multi-server and multi-user. <em>COMCOM</em>,
<em>165</em>, 43–52. (<a
href="https://doi.org/10.1016/j.comcom.2020.11.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile Edge Computing (MEC) is critical to the development of the Internet of things (IoTs) and 5G networks . However, the computation and communication resources of edge servers are limited, so it is challenging to perform resource allocation especially when the competition among edge servers is also taken into consideration. In this paper, we propose a trading model to investigate both the computation and communication resources allocation in MEC systems with multi-server and multi-user. We model the dynamic behavior of mobile users (MUs) using an evolutionary game, and then we build the deterministic and stochastic models to study the evolution of MUs where the evolutionary equilibrium is considered as the solution. We propose an evolution algorithm to obtain the evolutionary equilibrium. Furthermore, we analyze the competition among edge cloud servers (ECSs) by a noncooperative game, and propose an iteration algorithm to obtain Nash equilibrium where the ECSs can adjust the amount of resources provided to MUs and the corresponding price charged in order to attract more MUs. The existences of evolutionary equilibrium and Nash equilibrium are validated in performance evaluation.},
  archive      = {J_COMCOM},
  author       = {Xiaowen Huang and Wenjie Zhang and Jingmin Yang and Liwei Yang and Chai Kiat Yeo},
  doi          = {10.1016/j.comcom.2020.11.001},
  journal      = {Computer Communications},
  pages        = {43-52},
  shortjournal = {Comput. Commun.},
  title        = {Market-based dynamic resource allocation in mobile edge computing systems with multi-server and multi-user},
  volume       = {165},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Joint routing and scheduling for large-scale deterministic
IP networks. <em>COMCOM</em>, <em>165</em>, 33–42. (<a
href="https://doi.org/10.1016/j.comcom.2020.10.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the advent of 5G and the evolution of Internet protocols , industrial applications are moving from vertical solutions to general purpose IP-based infrastructures that need to meet deterministic Quality of Service (QoS) requirements. The IETF DetNet working group aims at providing an answer to this need with support for (i) deterministic worst-case latency and jitter, and (ii) zero packet loss for time-sensitive traffic. In this paper we focus on the joint routing and scheduling problem in large-scale deterministic networks using Cycle Specified Queuing and Forwarding (CSQF), an extension of Cyclic Queuing and Forwarding (CQF) with multiple transmission queues and support of segment routing. In this context, we present two centralized algorithms to maximize traffic acceptance for network planning and online flow admission. We propose an effective solution based on column generation and dynamic programming . Thanks to the reinforcement of the model with valid inequalities , we improve the upper bound and the solution. We demonstrate on realistic instances that we reach an optimality gap smaller than 10\% in a few seconds. Finally, we also derive an ultra-fast adaptive greedy algorithm to solve the problem at the cost of a small extra gap.},
  archive      = {J_COMCOM},
  author       = {Jonatan Krolikowski and Sébastien Martin and Paolo Medagliani and Jérémie Leguay and Shuang Chen and Xiaodong Chang and Xuesong Geng},
  doi          = {10.1016/j.comcom.2020.10.016},
  journal      = {Computer Communications},
  pages        = {33-42},
  shortjournal = {Comput. Commun.},
  title        = {Joint routing and scheduling for large-scale deterministic IP networks},
  volume       = {165},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An energy efficient and reliable routing scheme to enhance
the stability period in wireless body area networks. <em>COMCOM</em>,
<em>165</em>, 20–32. (<a
href="https://doi.org/10.1016/j.comcom.2020.10.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wireless Body Area Network (WBAN) is a wireless network of wearable sensing and computing devices connected through a wireless communication channel, thereby offering a plethora of enticing applications in the area of remote health monitoring, sports, and entertainment. However, WBANs nodes are highly resource-constrained; therefore, energy-efficient and reliable data transmission is very vital in the design and implementation of most of its applications. Furthermore, on time and accurate data delivery with minimum delay is also highly required. Over time, numerous energy-efficient routing solutions have been proposed for WBANs; however, the significant feature of reliability in these solutions has not been adequately addressed. Therefore, in this paper, we propose a new Energy-Efficient and Reliable Routing Scheme (ERRS) to enhance the stability period and reliability for resource-constrained WBAN. ERRS comprises two novel solutions, namely, the Forwarder Node Selection and Forwarder Node Rotation techniques. The proposed ERRS takes advantage of the adaptive static clustering routing technique and achieves enhanced stability period and longer network lifetime, ultimately maximizing reliability. Through extensive simulation-based evaluation using MATLAB, ERRS showed an improvement of 26\% over the benchmark protocol in terms of network stability and throughput. Whereas the end-to-end delay of the proposed ERRS is improved by 17\% and 40\% than by SIMPLE and M-ATTEMPT protocols, respectively, which proves ERRS to be an efficient and reliable routing solution for WBANs.},
  archive      = {J_COMCOM},
  author       = {Farman Ullah and M. Zahid Khan and Mohammad Faisal and Haseeb Ur Rehman and Sohail Abbas and Foad S. Mubarek},
  doi          = {10.1016/j.comcom.2020.10.017},
  journal      = {Computer Communications},
  pages        = {20-32},
  shortjournal = {Comput. Commun.},
  title        = {An energy efficient and reliable routing scheme to enhance the stability period in wireless body area networks},
  volume       = {165},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). RDP-based lateral movement detection using machine learning.
<em>COMCOM</em>, <em>165</em>, 9–19. (<a
href="https://doi.org/10.1016/j.comcom.2020.10.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Detecting cyber threats has been an on-going research endeavor. In this era, Advanced Persistent Threats (APTs) can incur significant costs for organizations and businesses. The ultimate goal of cybersecurity is to thwart attackers from achieving their malicious intent , whether it is credential stealing, infrastructure takeover, or program sabotage. Every cyber attack goes through several stages before its termination. Lateral Movement (LM) is one of those stages that is of particular importance. Remote Desktop Protocol (RDP) is a method used in LM to successfully authenticate to an unauthorized host that leaves footprints on both host and network logs. In this paper, we propose to detect evidence of LM using Machine Learning (ML) and Windows RDP event logs. We explore different feature sets extracted from these logs and evaluate various supervised ML techniques for classifying RDP sessions with high precision and recall. We also compare the performance of our proposed approach to a state-of-the-art approach and demonstrate that our ML model outperforms in classifying RDP sessions in Windows event logs. In addition, we show that our model is robust against certain types of adversarial attacks .},
  archive      = {J_COMCOM},
  author       = {Tim Bai and Haibo Bian and Mohammad A. Salahuddin and Abbas Abou Daya and Noura Limam and Raouf Boutaba},
  doi          = {10.1016/j.comcom.2020.10.013},
  journal      = {Computer Communications},
  pages        = {9-19},
  shortjournal = {Comput. Commun.},
  title        = {RDP-based lateral movement detection using machine learning},
  volume       = {165},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-hop routing under short contact in delay tolerant
networks. <em>COMCOM</em>, <em>165</em>, 1–8. (<a
href="https://doi.org/10.1016/j.comcom.2020.10.018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As technologies evolve, mobile devices are capable of storing, communicating, and disseminating large data files across the network. Communicating large data is particularly challenging in Delay Tolerant Networks because of lack of connectivity and short contacts among network nodes. To simplify the routing, existing works often ignore the data size and duration of a contact. That is, once transmitted, the data always successfully arrives at the receiver. Thus, these protocols are not suitable in the data-intensive mobile era. In this work, we propose a large data routing (LDR) protocol that chops large data into chunks and performs forwarding at the chunk level over multiple successive contacts. We also build a probabilistic model integrating the inter-contact time, contact frequency, and contact duration. The model is used to compute the edge weights in a contact graph and multi-hop delivery probabilities among network nodes. Simulations using real-world mobility traces show that our scheme can achieve up to 53\% higher delivery rate compared to other routing strategies.},
  archive      = {J_COMCOM},
  author       = {Tuan Le},
  doi          = {10.1016/j.comcom.2020.10.018},
  journal      = {Computer Communications},
  pages        = {1-8},
  shortjournal = {Comput. Commun.},
  title        = {Multi-hop routing under short contact in delay tolerant networks},
  volume       = {165},
  year         = {2021},
}
</textarea>
</details></li>
</ul>

</body>
</html>
