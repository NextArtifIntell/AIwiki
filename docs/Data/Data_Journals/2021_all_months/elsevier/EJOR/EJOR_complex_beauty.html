<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>EJOR_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="ejor---652">EJOR - 652</h2>
<ul>
<li><details>
<summary>
(2021). Acknowledgement to referees 2021. <em>EJOR</em>,
<em>295</em>(3), 1211–1226. (<a
href="https://doi.org/10.1016/j.ejor.2021.07.039">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_EJOR},
  doi          = {10.1016/j.ejor.2021.07.039},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1211-1226},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Acknowledgement to referees 2021},
  volume       = {295},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). On the optimality of joint periodic and extraordinary
dividend strategies. <em>EJOR</em>, <em>295</em>(3), 1189–1210. (<a
href="https://doi.org/10.1016/j.ejor.2021.04.033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we model the cash surplus (or equity) of a risky business with a Brownian motion (with a drift). Owners can take cash out of the surplus in the form of “dividends”, subject to transaction costs. However, if the surplus hits 0 then ruin occurs and the business cannot operate any more. We consider two types of dividend distributions: (i) periodic, regular ones (that is, dividends can be paid only at countably many points in time, according to a specific arrival process); and (ii) extraordinary dividend payments that can be made immediately at any time (that is, the dividend decision time space is continuous and matches that of the surplus process). Both types of dividends attract proportional transaction costs, but extraordinary distributions also attract fixed transaction costs, which is a realistic feature. A dividend strategy that involves both types of distributions (periodic and extraordinary) is qualified as “hybrid”. We determine which strategies (either periodic, immediate, or hybrid) are optimal, that is, we show which are the strategies that maximise the expected present value of dividends paid until ruin, net of transaction costs. Sometimes, a liquidation strategy (which pays out all monies and stops the process) is optimal. Which strategy is optimal depends on the profitability of the business, and the level of (proportional and fixed) transaction costs. Results are illustrated.},
  archive      = {J_EJOR},
  author       = {Benjamin Avanzi and Hayden Lau and Bernard Wong},
  doi          = {10.1016/j.ejor.2021.04.033},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1189-1210},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {On the optimality of joint periodic and extraordinary dividend strategies},
  volume       = {295},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Nash-stable coalition partition and potential functions in
games with coalition structure. <em>EJOR</em>, <em>295</em>(3),
1180–1188. (<a
href="https://doi.org/10.1016/j.ejor.2021.03.066">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work proves the existence of a coalition structure that is both Nash-stable and strongly permutation-stable for classes of coalition partition games. Among them are games where player’s payoff are Aumann-Drze value or the weighted value. These results are obtained by adapting the definition of a potential function for coalition partition games.},
  archive      = {J_EJOR},
  author       = {Vasily V. Gusev},
  doi          = {10.1016/j.ejor.2021.03.066},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1180-1188},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Nash-stable coalition partition and potential functions in games with coalition structure},
  volume       = {295},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Practical application of reference class forecasting for
cost and time estimations: Identifying the properties of similarity.
<em>EJOR</em>, <em>295</em>(3), 1161–1179. (<a
href="https://doi.org/10.1016/j.ejor.2021.03.063">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many project managers underestimate that todays projects are subject to various risks, which might lead to enormous cost overruns and project delays. In the domain of project forecasting, Reference Class Forecasting has been introduced as a method to bypass human judgement by applying an uplift that is based on the forecast errors of similar historical projects. In this research study, we aim to identify the possible drivers of project similarity based on interviews with 76 project managers. Also, we evaluate the performance of Reference Class Forecasting as a project forecasting technique from both a cost and time perspective. Based on an empirical study of 52 real projects, the accuracy of Reference Class Forecasting is successfully demonstrated by implementing a method that considers both the intra- and inter-accuracy of reference classes. The accuracy increases when more project properties are considered, however, a higher number of project properties decreases the size of the reference classes and thus reduces the reliability of the results.},
  archive      = {J_EJOR},
  author       = {Tom Servranckx and Mario Vanhoucke and Tarik Aouam},
  doi          = {10.1016/j.ejor.2021.03.063},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1161-1179},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Practical application of reference class forecasting for cost and time estimations: Identifying the properties of similarity},
  volume       = {295},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Price mediated contagion through capital ratio requirements
with VWAP liquidation prices. <em>EJOR</em>, <em>295</em>(3), 1147–1160.
(<a href="https://doi.org/10.1016/j.ejor.2021.03.053">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We develop a framework for price-mediated contagion in financial systems where banks are forced to liquidate assets to satisfy a risk-weight based capital adequacy requirement. In constructing this modeling framework, we introduce a two-tier pricing structure: the volume weighted average price that is obtained by any bank liquidating assets and the terminal mark-to-market price used to account for all assets held at the end of the clearing process. We consider the case of multiple illiquid assets and develop conditions for the existence and uniqueness of clearing prices. We provide a closed-form representation for the sensitivity of these clearing prices to the system parameters, and use this result to quantify: (1) the cost of regulation, in stress scenarios, faced by the system as a whole and the individual banks, and (2) the value of providing bailouts to consider when such notions are financially advisable. Numerical case studies are provided to study the application of this model to data.},
  archive      = {J_EJOR},
  author       = {Tathagata Banerjee and Zachary Feinstein},
  doi          = {10.1016/j.ejor.2021.03.053},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1147-1160},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Price mediated contagion through capital ratio requirements with VWAP liquidation prices},
  volume       = {295},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Optimal investment for a retirement plan with deferred
annuities allowing for inflation and labour income risk. <em>EJOR</em>,
<em>295</em>(3), 1132–1146. (<a
href="https://doi.org/10.1016/j.ejor.2021.03.052">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We construct an optimal investment portfolio model for an individual investor saving in a retirement plan. The investor earns stochastic labour income with both permanent and temporary shocks, and has access to equity, conventional bond, inflation-indexed bond and cash, as well as two types of deferred annuities: nominal and inflation-protected. The objective function consists of power utility in terms of real retirement income from the annuities as well as bequest from remaining wealth in tradable securities. Asset returns are represented by a vector autoregressive model underpinned by Nelson–Siegel real and nominal yield curves. The optimization problem is solved numerically using multi-stage stochastic programming with a hybrid scenario structure combining a scenario tree with scenario fans. Our numerical results show that deferred annuities are bought early and in increasing amounts during the working lifetime of the investor, with portfolio risk declining with age. Welfare is diminished by 40\% if deferred annuities are not available. Inflation-protected deferred annuities are marginally more important in the presence of real labour income risk, but nominal deferred annuities are bought as a cheaper alternative if real yields are low or negative. Portfolio composition and annuity allocation vary depending on financial market expectations, but our central result about the importance of deferred annuities is robust to a variety of financial market conditions.},
  archive      = {J_EJOR},
  author       = {Iqbal Owadally and Chul Jang and Andrew Clare},
  doi          = {10.1016/j.ejor.2021.03.052},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1132-1146},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Optimal investment for a retirement plan with deferred annuities allowing for inflation and labour income risk},
  volume       = {295},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Joint condition-based maintenance and load-sharing
optimization for two-unit systems with economic dependency.
<em>EJOR</em>, <em>295</em>(3), 1119–1131. (<a
href="https://doi.org/10.1016/j.ejor.2021.03.044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many production facilities consist of multiple and functionally exchangeable units of equipment, such as pumps or turbines, that are jointly used to satisfy a given production target. Such systems often have to ensure high levels of reliability and availability. The deterioration rates of the units typically depend on their production rates, implying that the operator can control deterioration by dynamically reallocating load among units. In this study, we examine the value of condition-based load-sharing decisions for two-unit systems with economic dependency. We formulate the system as a Markov decision process and provide optimal joint condition-based maintenance and production policies. Our numerical results show that, dependent on the system characteristics, substantial cost savings of up to 40\% can be realized compared to the optimal condition-based maintenance policy under equal load-sharing. The structure of the optimal policy particularly depends on the maintenance setup cost and the penalty that is incurred if the production target is not satisfied. For systems with high setup costs, the clustering of maintenance interventions is improved by synchronizing the deterioration of the units. On the contrary, for low setup costs, the deterioration levels are desynchronized and the maintenance interventions are alternated.},
  archive      = {J_EJOR},
  author       = {Michiel A.J. Uit Het Broek and Ruud H. Teunter and Bram de Jonge and Jasper Veldman},
  doi          = {10.1016/j.ejor.2021.03.044},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1119-1131},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Joint condition-based maintenance and load-sharing optimization for two-unit systems with economic dependency},
  volume       = {295},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Climate‐aware generation and transmission expansion
planning: A three‐stage robust optimization approach. <em>EJOR</em>,
<em>295</em>(3), 1099–1118. (<a
href="https://doi.org/10.1016/j.ejor.2021.03.035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a three-stage robust generation and transmission expansion planning model considering generation profiles of renewable energy sources (RES) affected by different long-term climate states. Essentially, we extend the broadly utilized two-stage modeling approach to properly consider partial information of climate states with conditional short-term scenarios of RES output and outages. The proposed model is formulated as a five-level optimization problem. The first level determines the optimal generation and transmission expansion plan under uncertainty in climate conditions, RES generation, and contingencies. Given the selected expansion plan, the second level identifies the most severe climate state. Following the decision-information hierarchy, in the third level, the system operator optimizes the generation schedule of energy and reserves under perfect information of the climate state, but yet under uncertainty in the RES generation and contingencies. Then, the fourth level identifies the worst-case combination of contingency and conditional short-term RES generation adjusted to the current climate condition. Finally, the fifth level determines the optimal redispatch of reserves to react against the worst-case RES generation and contingency scenario considering the uppermost decisions. Within this multi-level structure, the optimal investment plan considers a more realistic decision setting, where system operators adapt RES forecasts based on the observed climate conditions before planning the operational schedule. To solve the problem, a variant of the nested column-and-constraint-generation algorithm is proposed with global-optimality guarantee in a finite number of steps. A case study based on the Chilean system illustrates the applicability of the model in a realistic network.},
  archive      = {J_EJOR},
  author       = {Alexandre Moreira and David Pozo and Alexandre Street and Enzo Sauma and Goran Strbac},
  doi          = {10.1016/j.ejor.2021.03.035},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1099-1118},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Climate‐aware generation and transmission expansion planning: A three‐stage robust optimization approach},
  volume       = {295},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An inverse optimization approach for a capacitated vehicle
routing problem. <em>EJOR</em>, <em>295</em>(3), 1087–1098. (<a
href="https://doi.org/10.1016/j.ejor.2021.03.031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The capacitated vehicle routing problem studied in this paper stems from an e-commerce company in China. Efficient delivery is crucial for the logistic service of the company. It was observed that experienced drivers (experts) planned better delivery routes than those from optimization tools. This is largely due to the fact that the objectives (or the cost matrices) in real life are highly complicated and the experts use more practical objectives while making decisions. In this paper, we propose an inverse optimization formulation to derive a proper cost matrix by learning from the experts experience. Thus, the routing model with respect to the learned cost matrix could provide solutions as good as those given by experts. A multiplicative weights updates algorithm is applied to achieve a fast and convergent learning process. Experimental analyses based on randomly generated instances and real-world instances demonstrate the effectiveness of the approach.},
  archive      = {J_EJOR},
  author       = {Lu Chen and Yuyi Chen and André Langevin},
  doi          = {10.1016/j.ejor.2021.03.031},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1087-1098},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {An inverse optimization approach for a capacitated vehicle routing problem},
  volume       = {295},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Adaptive online portfolio selection with transaction costs.
<em>EJOR</em>, <em>295</em>(3), 1074–1086. (<a
href="https://doi.org/10.1016/j.ejor.2021.03.023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As an application of machine learning techniques in financial fields, online portfolio selection has been attracting great attention from practitioners and researchers, which makes timely sequential decision making available when market information is constantly updated. For online portfolio selection, transaction costs incurred by changes of investment proportions on risky assets have a significant impact on the investment strategy and the return in long-term investment horizon. However, in many online portfolio selection studies, transaction costs are usually neglected in the decision making process. In this paper, we consider an adaptive online portfolio selection problem with transaction costs. We first propose an adaptive online moving average method (AOLMA) to predict the future returns of risky assets by incorporating an adaptive decaying factor into the moving average method, which improves the accuracy of return prediction. The net profit maximization model (NPM) is then constructed where transaction costs are considered in each decision making process. The adaptive online net profit maximization algorithm (AOLNPM) is designed to maximize the cumulative return by integrating AOLMA and NPM together. Numerical experiments show that AOLNPM dominates several state-of-the-art online portfolio selection algorithms in terms of various performance metrics, i.e., cumulative return, mean excess return, Sharpe ratio, Information ratio and Calmar ratio.},
  archive      = {J_EJOR},
  author       = {Sini Guo and Jia-Wen Gu and Wai-Ki Ching},
  doi          = {10.1016/j.ejor.2021.03.023},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1074-1086},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Adaptive online portfolio selection with transaction costs},
  volume       = {295},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Price-region bids in electricity markets. <em>EJOR</em>,
<em>295</em>(3), 1056–1073. (<a
href="https://doi.org/10.1016/j.ejor.2021.03.024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Current bid formats in pool-based electricity markets are ill-equipped to accommodate the broad range of non-conventional sources of flexibility, such as demand response and interconnected heating, natural gas and water infrastructure networks. To address this issue, this paper introduces the novel price-region bid format to be used in both forward electricity markets and financial right auctions. We show that price-region bids are able to accommodate a broad range of techno-economic characteristics, including complex spatial and temporal couplings, and facilitate market access to non-conventional flexibility providers. We then show that this new bid format is compatible with existing market structures, and satisfies desirable market properties under common assumptions. Three numerical studies are provided: two motivating examples based on a district heating utility and a cascaded hydro power plant, and a case study based on an integrated power and heat system. These studies illustrate the inability of existing bid formats to accommodate flexible resources, and show how price-region bids overcome this shortcoming.},
  archive      = {J_EJOR},
  author       = {Lucien Bobo and Lesia Mitridati and Josh A. Taylor and Pierre Pinson and Jalal Kazempour},
  doi          = {10.1016/j.ejor.2021.03.024},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1056-1073},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Price-region bids in electricity markets},
  volume       = {295},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A novel version of the TODIM method based on the exponential
model of prospect theory: The ExpTODIM method. <em>EJOR</em>,
<em>295</em>(3), 1042–1055. (<a
href="https://doi.org/10.1016/j.ejor.2021.03.055">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The adherence of the TODIM method and its variations, including two new versions of TODIM with the use of the exponential and logarithmic functions, to prospect theory was compared based on performance indicators with a very frequently used MCDM method, namely TOPSIS and its variation, Behavioral TOPSIS. It was hypothesized that the use of methods with mathematical models more adherent to prospect theory would provide more accurate predictions of individual decision making. A hundred students from the University of São Paulo in Ribeirão Preto were invited to participate in a field study where three different cases should be solved without the support of any method. Then, performance indicators were used to evaluate the prediction capacity of the methods with the ones provided by the volunteers, having the TODIM method with the new mathematical function presented in this paper, hereafter named Exponential TODIM (ExpTODIM), reached the best scores in all three performance indicators. The main contribution of the present paper is the proposal of a novel version of TODIM method that fits among the low implementation complexity multicriteria methods with high predictive power, since it is based on a value function that is more adherent to prospect theory.},
  archive      = {J_EJOR},
  author       = {Alexandre Bevilacqua Leoneti and Luiz Flavio Autran Monteiro Gomes},
  doi          = {10.1016/j.ejor.2021.03.055},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1042-1055},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A novel version of the TODIM method based on the exponential model of prospect theory: The ExpTODIM method},
  volume       = {295},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Market segmentation in online platforms. <em>EJOR</em>,
<em>295</em>(3), 1025–1041. (<a
href="https://doi.org/10.1016/j.ejor.2021.03.056">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies ranking policies in a stylized trial-offer marketplace model, in which a single firm offers multiple products and has consumers who express heterogeneous preferences. Consumer trials are influenced by past purchases, the inherent appeal of the products, and the ranking of each product. Consumer purchases conditional on trying the product are dependent on the inherent quality for the given consumer segment. The platform owner needs to devise a ranking policy to display the products to maximize the number of purchases in the long run, and to decide whether to display the number of past purchases. The model proposed attempts to understand the impact of market segmentation in a trial-offer market with position bias and social influence. Under our model, consumer choices are based on a very general choice model known as the mixed multinomial logit model, which embeds product appeal, ranking, and past purchases into the taste parameters. We analyze the long-term dynamics of this highly complex stochastic model and we quantify the expected benefits of market segmentation as well as the value of social influence. When past purchases are displayed, consumer heterogeneity makes buyers try the sub-optimal products, reducing the overall sales rate. We show that consumer heterogeneity makes the ranking problem NP-hard. We then analyze the benefits of market segmentation. We find tight bounds to the expected benefits of offering a distinct ranking to each consumer segment. Finally, we show that the market segmentation strategy always benefits from social influence when the average quality ranking is used. One of the managerial implications is that the firm is better off using an aggregate ranking policy when the variety of consumer preference is limited, but it should perform a market segmentation policy when consumers are highly heterogeneous. We also show that this result is robust to relatively small consumer classification mistakes; when these are large, an aggregate ranking is preferred.},
  archive      = {J_EJOR},
  author       = {Franco Berbeglia and Gerardo Berbeglia and Pascal Van Hentenryck},
  doi          = {10.1016/j.ejor.2021.03.056},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1025-1041},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Market segmentation in online platforms},
  volume       = {295},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Ride solo or pool: Designing price-service menus for a
ride-sharing platform. <em>EJOR</em>, <em>295</em>(3), 1008–1024. (<a
href="https://doi.org/10.1016/j.ejor.2021.03.058">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A ride-sharing platform (RSP), such as Uber or Lyft, can sometimes offer passengers an option to share (pool) the ride with fellow passengers. On the one hand, a passenger who pools benefits from paying a lower fare and the RSP benefits from increasing occupancy per car, thereby serving more passengers. On the other hand, a passenger who pools takes more time, on average, to reach her destination and may have to share the ride with a stranger, and the RSP gets a lower profit margin per passenger than from solo rides. We develop a queueing model to find the RSP’s optimal revenue in equilibrium when passengers are strategic and drivers are independent agents, and design the RSP’s revenue-maximizing price-service menu. We find that offering both solo and pooled rides is optimal when the distribution of passenger-type is not skewed and congestion is not high. Counter intuitively, when congestion is high, the RSP benefits from offering only one ride choice. Simulation-based results extend these findings when more than one route exists. We provide a numerical example based on real-life data. When the number of drivers is endogenous, equilibrium revenue per driver can decrease when the passenger arrival rate increases.},
  archive      = {J_EJOR},
  author       = {Jagan Jacob and Ricky Roet-Green},
  doi          = {10.1016/j.ejor.2021.03.058},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1008-1024},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Ride solo or pool: Designing price-service menus for a ride-sharing platform},
  volume       = {295},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An extended goal programming model for the multiobjective
integrated lot-sizing and cutting stock problem. <em>EJOR</em>,
<em>295</em>(3), 996–1007. (<a
href="https://doi.org/10.1016/j.ejor.2021.03.049">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lot sizing and cutting stock problems generally arise in manufacturing as a two stage connected process. Although these two problems have been addressed separately by many authors, recently, inspired by practical applications, some studies have emerged analyzing their integration. The mono-objective version of the integrated lot-sizing and cutting stock problem can be considered as an enhancement that minimizes the global production cost. However, it does not include the multiple criteria that can arise from the inclusion of multiple stakeholders in a modern, distributed manufacturing process. This paper aims to introduce a new extended goal programming model for the integrated lot-sizing and cutting stock problem which models the arising multiple criteria by a set of goals representing the interests of different stakeholders in the manufacturing process. This formulation allows for the consideration of the balance between the conflicting goals of multiple stakeholders and the cost efficiency of the overall process. In order to efficiently solve the proposed model, a column generation based heuristic procedure is applied. The trade-offs among the various criteria related to the problem are assessed, and a series of computational experiments are performed. The computational results compare individual criteria weighting schemes and evaluate the goals’ sensitivity using performance profiles and time-to-target plots methodologies.},
  archive      = {J_EJOR},
  author       = {Washington A. Oliveira and Diego J. Fiorotto and Xiang Song and Dylan F. Jones},
  doi          = {10.1016/j.ejor.2021.03.049},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {996-1007},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {An extended goal programming model for the multiobjective integrated lot-sizing and cutting stock problem},
  volume       = {295},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Compatibility effects in the prescriptive application of
psychological heuristics: Inhibition, integration and selection.
<em>EJOR</em>, <em>295</em>(3), 982–995. (<a
href="https://doi.org/10.1016/j.ejor.2021.03.046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent studies have proposed the use of “fast and frugal” strategies as viable alternatives to support decision-processes in cases where time or other operational constraints preclude the application of standard decision-analytic methods. While a growing body of evidence shows that such procedures can be highly accurate, limited research has evaluated how well decision-makers can execute the prescriptive recommendations of aids based on such strategies in practice. Drawing on the behavioural, neuropsychological and decision-analytic literatures, we propose that an alignment between individual, model and task features will influence the effectiveness with which decision-makers can execute strategies that draw on prescriptive psychological heuristics – “fast and frugal” or otherwise. Our findings suggest that strategy execution is highly sensitive to task characteristics however, the effects of the number of alternatives and attributes on individuals’ ability to deploy a given strategy, differ in magnitude and direction depending on which decision-strategy is prescribed. A more compensatory decision-style positively affected overall task performance. Subjects’ ability to regulate inhibitory control was found to positively affect non-compensatory strategy execution, while having no discernible bearing on comparable compensatory tasks. Our findings reinforce that rather than an aspect of the prescriptive model, synergies between individual, model and task features are more instrumental in driving task performance in aided MCDM contexts. We discuss these findings in light of calls from OR scholars for the development of decision-aids that draw on prescriptive “fast and frugal” principles.},
  archive      = {J_EJOR},
  author       = {Shashwat M. Pande and K. Nadia Papamichail and Peter Kawalek},
  doi          = {10.1016/j.ejor.2021.03.046},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {982-995},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Compatibility effects in the prescriptive application of psychological heuristics: Inhibition, integration and selection},
  volume       = {295},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Feature information prediction algorithm for dynamic
multi-objective optimization problems. <em>EJOR</em>, <em>295</em>(3),
965–981. (<a href="https://doi.org/10.1016/j.ejor.2021.01.028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic multi-objective optimization problems (DMOPs) contain multiple conflicting goals while tracking the changing Pareto-optimal front (PF) or Pareto-optimal set (PS). Most algorithms treat the solutions of DMOPs as if they were dealing with static multi-objective optimization problems. However, solutions under different environments may obey different distributions. To solve some of the existing limitations of currently available methods, a dynamic multi-objective optimization algorithm based on feature information prediction (FIP) is proposed. To identify the distribution of solutions after an environmental change, joint distribution adaptation (JDA) is used to construct a mapping function. The feature information, which is extracted from the objective space at the current time step, is mapped to a higher dimensional space. Then the feature information of decision space at the next time step is obtained using the interior point method. Based on this information, the initial population at the next time step is generated when a change is detected. The performance of FIP is validated by comparing it with respect to four state-of-the-art evolutionary algorithms on eight benchmark functions. Experimental results demonstrate that FIP can quickly cover the front with rapidly changing environments.},
  archive      = {J_EJOR},
  author       = {Xuemin Ma and Jingming Yang and Hao Sun and Ziyu Hu and Lixin Wei},
  doi          = {10.1016/j.ejor.2021.01.028},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {965-981},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Feature information prediction algorithm for dynamic multi-objective optimization problems},
  volume       = {295},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Designing smart replenishment systems: Internet-of-things
technology for vendor-managed inventory at end consumers. <em>EJOR</em>,
<em>295</em>(3), 949–964. (<a
href="https://doi.org/10.1016/j.ejor.2021.03.042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Motivated by recent advances in Internet-of-Things (IoT) technology for household appliances, we analyze a Smart Replenishment system that leverages point-of-consumption (POC) information at end consumers to decide on deliveries of consumables. As such, we extend the classic Vendor-Managed Inventory (VMI) concept to end consumers. We model the system for a single manufacturer who directly serves N N end consumers with uncertain demand. End consumers partially adopt the new Smart Replenishment mode, which results in a mix of VMI and non-VMI customers. We assume that unfulfilled demand is lost and that the manufacturer’s dispatch capacity is constrained. Customers compete for the same capacity while featuring different out-of-stock risks and service-level expectations, both of which are costly to the manufacturer. Considering various adoption levels, we decide on the design of such a system and focus on (i) inventory control, (ii) customer prioritization, and (iii) degree of smart, integrated decision-making. Using discrete-event simulation and a full-factorial experiment, we show that replenishment decisions can be significantly enhanced with POC information. It leads to substantial improvements in service levels and capacity utilization without loading customers with inventories. This improvement potential is highest for a low demand coverage of the replenishment quantity, a high gap in the ordering behavior of manufacturer and end consumers, and a long lead time. To realize this improvement potential, we propose a flexible reorder corridor to manage inventories at VMI customers that balances the trade-off between out-of-stock risk and service-level expectation inherent in the system.},
  archive      = {J_EJOR},
  author       = {Sandria Weißhuhn and Kai Hoberg},
  doi          = {10.1016/j.ejor.2021.03.042},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {949-964},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Designing smart replenishment systems: Internet-of-things technology for vendor-managed inventory at end consumers},
  volume       = {295},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Promoting end-of-season product through online channel in an
uncertain market. <em>EJOR</em>, <em>295</em>(3), 935–948. (<a
href="https://doi.org/10.1016/j.ejor.2021.03.043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Firms typically introduce online promotional channels based on the cooperative format of agency selling or reselling to promote end-of-season products. The selection of the agency selling or reselling format is greatly affected by a firm’s pricing timing between traditional and online promotional channels, particularly in an uncertain market. Within this context, we examine how the pricing timings in an online promotional channel relative to a traditional channel impact a firm’s selection between agency selling and reselling formats in an uncertain market. We find that the promotional pricing timings have no effect on the firm’s price decisions under the agency selling format, whereas they might lead to downward prices under the reselling format—even lower than those under the agency selling format. We show that considering promotional pricing timing in an uncertain market fundamentally changes the general intuition that the firm prefers the agency selling to reselling format due to the double-marginalization effect. Specifically, the reselling format might be more profitable for the firm when it sets traditional-channel promotional price prior to introducing the online promotional channel in an optimistic market (i.e., a market more likely to have high demand) or adopts the opposite promotional pricing timing of channels in a pessimistic market (i.e., a market more likely to have low demand). Our findings complement the emerging online retail literature by underscoring the interacting forces of promotional pricing timing and uncertain demand on a firm’s reselling versus agency selling format choice in promoting end-of-season product online.},
  archive      = {J_EJOR},
  author       = {Pingping Chen and Ruiqing Zhao and Yingchen Yan and Chi Zhou},
  doi          = {10.1016/j.ejor.2021.03.043},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {935-948},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Promoting end-of-season product through online channel in an uncertain market},
  volume       = {295},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Enhance load forecastability: Optimize data sampling policy
by reinforcing user behaviors. <em>EJOR</em>, <em>295</em>(3), 924–934.
(<a href="https://doi.org/10.1016/j.ejor.2021.03.032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Load forecasting has long been a key task for reliable power systems planning and operation. Over the recent years, advanced metering infrastructure has proliferated in industry. This has given rise to many load forecasting methods based on frequent measurements of power states obtained by smart meters. Meanwhile, real-world constraints arising in this new setting present both challenges and opportunities to achieve high load forecastability. The bandwidth constraints often imposed on the transmission between data concentrators and utilities are one of them, which limit the amount of data that can be sampled from customers. There lacks a sampling-rate control policy that is self-adaptive to users’ load behaviors through online data interaction with the smart grid environment. In this paper, we formulate the bandwidth-constrained sampling-rate control problem as a Markov decision process (MDP) and provide a reinforcement learning (RL)-based algorithm to solve the MDP for an optimal sampling-rate control policy. The resulting policy can be updated in real time to accommodate volatile load behaviors observed in the smart grid. Numerical experiments show that the proposed RL-based algorithm outperforms competing algorithms and delivers superior predictive performance.},
  archive      = {J_EJOR},
  author       = {Guangrui Xie and Xi Chen and Yang Weng},
  doi          = {10.1016/j.ejor.2021.03.032},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {924-934},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Enhance load forecastability: Optimize data sampling policy by reinforcing user behaviors},
  volume       = {295},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Exact and heuristic algorithms for the fleet composition and
periodic routing problem of offshore supply vessels with berth
allocation decisions. <em>EJOR</em>, <em>295</em>(3), 908–923. (<a
href="https://doi.org/10.1016/j.ejor.2021.03.022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a branch-and-cut algorithm and an adaptive large neighborhood search (ALNS) heuristic for the periodic supply vessel planning problem (PSVPP) arising in the upstream offshore petroleum logistics chain. Platform supply vessels support the offshore oil and gas exploration and production activities by transporting all the necessary material and equipment back and forth between offshore units and an onshore supply base according to a delivery schedule. The PSVPP consists of solving a periodic vehicle routing problem and simultaneously determining an optimal fleet size and mix of heterogeneous offshore supply vessels, their weekly routes and schedules for servicing the offshore oil and gas installations, and the berth allocations at the supply base. The branch-and-cut algorithm considers a reduced formulation for the problem which performs much better than the complete one, and easily finds optimal solutions for the smaller and most of the clustered instances. The ALNS heuristic contains new features which include multiple starts and spaced local searches. These algorithms were tested on instances with up to 79 offshore units, providing better results than the best available.},
  archive      = {J_EJOR},
  author       = {Bruno S. Vieira and Glaydston M. Ribeiro and Laura Bahiense and Roberto Cruz and André B. Mendes and Gilbert Laporte},
  doi          = {10.1016/j.ejor.2021.03.022},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {908-923},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Exact and heuristic algorithms for the fleet composition and periodic routing problem of offshore supply vessels with berth allocation decisions},
  volume       = {295},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An efficient variable neighborhood search for the space-free
multi-row facility layout problem. <em>EJOR</em>, <em>295</em>(3),
893–907. (<a href="https://doi.org/10.1016/j.ejor.2021.03.027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Space-Free Multi-Row Facility Layout problem (SF-MRFLP) seeks for a non-overlapping layout of departments (facilities) on a given number of rows satisfying the following constraints: no space is allowed between two adjacent facilities and the left-most department of the arrangement must have zero abscissa. The objective is to minimize the total communication cost among facilities. In this paper, a Variable Neighborhood Search (VNS) algorithm is proposed to solve this NP NP -Hard problem. It has practical applications in the context of the arrangement of rooms in buildings, semiconductor wafer fabrication, or flexible manufacturing systems. A thorough set of preliminary experiments is conducted to evaluate the influence of the proposed strategies and to tune the corresponding search parameters. The best variant of our algorithm is tested over a large set of 528 instances previously used in the related literature. Experimental results show that the proposed algorithm improves the state-of-the-art methods, reaching all the optimal values or, alternatively, the best-known values (if the optimum is unknown) but in considerably shorter computing times. These results are further confirmed by conducting a Bayesian statistical analysis.},
  archive      = {J_EJOR},
  author       = {Alberto Herrán and J. Manuel Colmenar and Abraham Duarte},
  doi          = {10.1016/j.ejor.2021.03.027},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {893-907},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {An efficient variable neighborhood search for the space-free multi-row facility layout problem},
  volume       = {295},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Valid inequalities, preprocessing, and an effective
heuristic for the uncapacitated three-level lot-sizing and replenishment
problem with a distribution structure. <em>EJOR</em>, <em>295</em>(3),
874–892. (<a href="https://doi.org/10.1016/j.ejor.2021.03.029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the uncapacitated three-level lot-sizing and replenishment problem with a distribution structure. In this problem, a single production plant sends the produced items to replenish warehouses from where they are dispatched to the retailers in order to satisfy their demands over a finite planning horizon. Transfers between warehouses or retailers are not permitted, each retailer has a single predefined warehouse from which it receives its items, and there is no restriction on the amount that can be produced or transported in a given period. The goal of the problem is to determine an integrated production and distribution plan minimizing the total costs, which comprehends fixed production and transportation setup as well as variable inventory holding costs. We describe new valid inequalities both in the space of a standard mixed integer programming (MIP) formulation and in that of a new alternative extended MIP formulation. We show that using such extended formulation, valid inequalities having similar structures to those in the standard one allow achieving tighter linear relaxation bounds. Furthermore, we propose a preprocessing approach to reduce the size of an extended multi-commodity MIP formulation available in the literature. Such preprocessing relies on the removal of variables based on the problem’s cost structure while preserving optimality guarantees. We also propose a multi-start randomized bottom-up dynamic programming-based heuristic. The heuristic employs greedy randomization via changes in certain costs and solves subproblems related to each level using dynamic programming. Computational experiments indicate that the use of the valid inequalities in a branch-and-cut approach significantly increase the ability of a MIP solver to solve instances to optimality. Additionally, the valid inequalities for the new alternative extended formulation outperform those for the standard one in terms of number of solved instances, running time and number of enumerated nodes. Moreover, the proposed heuristic is able to generate solutions with considerably low optimality gaps within very short computational times even for large instances. Combining the preprocessing approach with the heuristic, one can achieve an increase in the number of solutions solved to optimality within the time limit together with significant reductions on the average times for solving them.},
  archive      = {J_EJOR},
  author       = {Jesus O. Cunha and Rafael A. Melo},
  doi          = {10.1016/j.ejor.2021.03.029},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {874-892},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Valid inequalities, preprocessing, and an effective heuristic for the uncapacitated three-level lot-sizing and replenishment problem with a distribution structure},
  volume       = {295},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). SALSA: Combining branch-and-bound with dynamic programming
to smoothen workloads in simple assembly line balancing. <em>EJOR</em>,
<em>295</em>(3), 857–873. (<a
href="https://doi.org/10.1016/j.ejor.2021.03.021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a version of the well-known simple assembly line balancing problem (called SALBP-SX) where, given the cycle time and the number of stations, the workloads of the stations are to be leveled according to an adequately defined smoothness index SX. Our index SX involves for each station the quadratic deviation of its workload from the average (or ideal ) workload and is therefore closely related to the variance, which is a common measure of dispersion in statistics. Contrary to the existing literature on workload smoothing in ALB, which often treats the optimization of a prespecified smoothness index as a secondary objective, we consider our SX-objective as the single one in order to account for the practical relevance of fair workload distributions and avoiding overloaded bottleneck stations. To optimally solve SALBP-SX, we develop a tailored branch-and-bound procedure. It contains a new station-oriented branching scheme, new lower bound arguments, logical tests and, in particular, a dynamic programming scheme for the pre-calculation of potential workloads, which accelerates the procedure greatly. In comprehensive computational experiments, we show that our method clearly outperforms a class of recently developed task-oriented branch-and-bound procedures and also the mathematical programming solver Gurobi.},
  archive      = {J_EJOR},
  author       = {Rico Walter and Philipp Schulze and Armin Scholl},
  doi          = {10.1016/j.ejor.2021.03.021},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {857-873},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {SALSA: Combining branch-and-bound with dynamic programming to smoothen workloads in simple assembly line balancing},
  volume       = {295},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The minimal covering location and sizing problem in the
presence of gradual cooperative coverage. <em>EJOR</em>,
<em>295</em>(3), 838–856. (<a
href="https://doi.org/10.1016/j.ejor.2021.03.015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces the capacitated gradual and cooperative minimal covering location problem with distance constraints (cGC-MCLPD). The cGC-MCLPD extends the location literature by implementing the concepts of gradual and cooperative coverage in the context of undesirable facility location problem with distance constraints. It also allows for variable coverage radii and capacity of facilities to assess the effect of facility size on the network performance. For the defined problem, we first develop a nonlinear mathematical model which seeks to determine the number, location and size of facilities such that the total population covered is minimized while the overall service requirement is met. Next, we propose three integer linear programming formulations that can be solved with off-the-shelf solvers. The first two are linear approximations that are based on a separable programming approach and a tangent line approximation method. The third is an exact reformulation which uses a special network mapping technique. Upon investigating the impact of linearization approximation error on the performance of the first two formulations, we carry out numerical experiments to compare formulations with respect to their solution time and quality. Solving them for a set of reasonably large problem instances, we found that approximations outperform the exact reformulation since they prove to achieve higher quality solutions at the expense of an acceptable level of objective function value error. Overall, the formulations developed for the cGC-MCLPD constitute a powerful portfolio of facility location selection techniques, enabling decision-makers to select the most appropriate balance of solution quality and computational speed.},
  archive      = {J_EJOR},
  author       = {Mumtaz Karatas and Levent Eriskin},
  doi          = {10.1016/j.ejor.2021.03.015},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {838-856},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {The minimal covering location and sizing problem in the presence of gradual cooperative coverage},
  volume       = {295},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Solution methods for scheduling problems with
sequence-dependent deterioration and maintenance events. <em>EJOR</em>,
<em>295</em>(3), 823–837. (<a
href="https://doi.org/10.1016/j.ejor.2021.03.067">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we study the problem of scheduling jobs and maintenance activities on a set of unrelated parallel machines, by considering that the processing time of a job increases according to a deterioration factor that depends both on the machine and on the set of jobs the machine has processed since its last maintenance. The objective we consider is to minimize the makespan. We introduce four mixed integer linear programming models, two of which using big-M constraints and the other two using an exponential number of variables. We also propose an iterated local search metaheuristic to tackle large size instances and we provide empirical evidence of the performance of the proposed approaches by means of extensive computational experiments.},
  archive      = {J_EJOR},
  author       = {Maxence Delorme and Manuel Iori and Nilson F.M. Mendes},
  doi          = {10.1016/j.ejor.2021.03.067},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {823-837},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Solution methods for scheduling problems with sequence-dependent deterioration and maintenance events},
  volume       = {295},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Fatigue, personnel scheduling and operations: Review and
research opportunities. <em>EJOR</em>, <em>295</em>(3), 807–822. (<a
href="https://doi.org/10.1016/j.ejor.2021.03.036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Work-related fatigue is a multidimensional phenomenon with significant effects on operational performance. Our work focuses on how the literature of operational research measures and models fatigue and its effects on operational performance, and on how it mitigates those effects. We position the literature of fatigue relative to that of work-rest scheduling, shift scheduling, multitasking, ergonomics, deterioration scheduling, and occupational health and safety. We classify the literature of fatigue across multiple dimensions: the methods by which it is identified and measured; the operational research methodology applied for fatigue prevention or mitigation; the flexibility allowed in work-rest scheduling and in shift scheduling; applications within manufacturing, construction, transportation, hospitals, and services; and the extent to which real data is used and results are implemented. Our work shows that operational research has contributed numerous effective algorithms and heuristic solution procedures to fatigue mitigation. We also identify several important research directions for operational research, to promote its broader and more effective use to identify and mitigate the effects of fatigue on operational performance.},
  archive      = {J_EJOR},
  author       = {Shuling Xu and Nicholas G. Hall},
  doi          = {10.1016/j.ejor.2021.03.036},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {807-822},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Fatigue, personnel scheduling and operations: Review and research opportunities},
  volume       = {295},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Nash equilibria in nonzero-sum differential games with
impulse control. <em>EJOR</em>, <em>295</em>(2), 792–805. (<a
href="https://doi.org/10.1016/j.ejor.2021.03.025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we introduce a class of deterministic finite-horizon two-player nonzero-sum differential games where one player uses ordinary controls while the other player uses impulse controls. We use the word ‘ordinary’ to mean that Player 1 uses control strategies that are piecewise continuous functions of time. We formulate the necessary and sufficient conditions for the existence of an open-loop Nash equilibrium for this class of differential games. We specialize these results to linear-quadratic games, and show that the open-loop Nash equilibrium strategies can be computed by solving a constrained non-linear optimization problem. In particular, for the impulse player, the equilibrium timing and level of impulses can be obtained. Furthermore, for the special case of linear-state differential games, we obtain analytical characterization of equilibrium number, timing, and the level of impulse in terms of the problem data. We illustrate our results using numerical experiments.},
  archive      = {J_EJOR},
  author       = {Utsav Sadana and Puduru Viswanadha Reddy and Georges Zaccour},
  doi          = {10.1016/j.ejor.2021.03.025},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {792-805},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Nash equilibria in nonzero-sum differential games with impulse control},
  volume       = {295},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Revealing pairs-trading opportunities with long short-term
memory networks. <em>EJOR</em>, <em>295</em>(2), 772–791. (<a
href="https://doi.org/10.1016/j.ejor.2021.03.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work examines a deep learning approach to complement investors’ practices for the identification of pairs-trading opportunities among cointegrated stocks. We refer to the reversal effect, consisting in the fact that temporarily market deviations are likely to correct and finally converge again, to generate valuable pairs-trading signals based on the application of Long Short-Term Memory networks (LSTM). Specifically, we propose to use the LSTM to estimate the probability of a stock to exhibit increasing market returns in the near future compared to its peers, and we compare and combine these predictions with trading practices based on sorting stocks according to either price or returns gaps. In so doing, we investigate the ability of our proposed approach to provide valuable signals under different perspectives including variations in the investment horizons, transaction costs and weighting schemes. Our analysis shows that strategies including such predictions can contribute to improve portfolio performances providing predictive signals whose information content goes above and beyond the one embedded in both price and returns gaps.},
  archive      = {J_EJOR},
  author       = {Andrea Flori and Daniele Regoli},
  doi          = {10.1016/j.ejor.2021.03.009},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {772-791},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Revealing pairs-trading opportunities with long short-term memory networks},
  volume       = {295},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The value of text for small business default prediction: A
deep learning approach. <em>EJOR</em>, <em>295</em>(2), 758–771. (<a
href="https://doi.org/10.1016/j.ejor.2021.03.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Compared to consumer lending, Micro, Small and Medium Enterprise (mSME) credit risk modelling is particularly challenging, as, often, the same sources of information are not available. Therefore, it is standard policy for a loan officer to provide a textual loan assessment to mitigate limited data availability. In turn, this statement is analysed by a credit expert alongside any available standard credit data. In our paper, we exploit recent advances from the field of Deep Learning and Natural Language Processing (NLP), including the BERT (Bidirectional Encoder Representations from Transformers) model, to extract information from 60,000 textual assessments provided by a lender. We consider the performance in terms of the AUC (Area Under the receiver operating characteristic Curve) and Brier Score metrics and find that the text alone is surprisingly effective for predicting default. However, when combined with traditional data, it yields no additional predictive capability, with performance dependent on the text’s length. Our proposed Deep Learning model does, however, appear to be robust to the quality of the text and therefore suitable for partly automating the mSME lending process. We also demonstrate how the content of loan assessments influences performance, leading us to a series of recommendations on a new strategy for collecting future mSME loan assessments.},
  archive      = {J_EJOR},
  author       = {Matthew Stevenson and Christophe Mues and Cristián Bravo},
  doi          = {10.1016/j.ejor.2021.03.008},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {758-771},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {The value of text for small business default prediction: A deep learning approach},
  volume       = {295},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Gender effect on microfinance social efficiency: A robust
nonparametric approach. <em>EJOR</em>, <em>295</em>(2), 744–757. (<a
href="https://doi.org/10.1016/j.ejor.2021.03.020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The main objective of this study is to assess the impact of gender on microfinance social efficiency. Our methodology is based on nonparametric techniques to estimate the gender effect. We use a conditional directional free disposal hull (FDH) approach as well as its robust version of order- α α ; we study the effect of the heterogeneity factor on the difference of conditional and non conditional inefficiencies as well as on the inefficiency level using a local linear regression and we test the significance of its effect using a wild double bootstrap procedure. Using a cross-country sample of 680 microfinance institutes (MFIs) in 2011 from six main regions of the world, our findings suggest that gender diversity has globally a positive impact on the microfinance social efficiency. However, the nature of the effect depends on the considered heterogeneity factor and we find that the boardroom gender diversity effect is linear, whereas the effect of the percentage of women loan officers is non linear (U-shaped on the difference of inefficiencies and inverted U-shaped on the inefficiency levels). We assess the robustness of our findings on various subsamples (global or regional scale, and also depending on the considered profit oriented status). Our findings reinforce the importance of the role played by women in MFI social efficiency.},
  archive      = {J_EJOR},
  author       = {F.S. Fall and H. Tchakoute Tchuigoua and A. Vanhems and L. Simar},
  doi          = {10.1016/j.ejor.2021.03.020},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {744-757},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Gender effect on microfinance social efficiency: A robust nonparametric approach},
  volume       = {295},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Predicting the national football league potential of college
quarterbacks. <em>EJOR</em>, <em>295</em>(2), 733–743. (<a
href="https://doi.org/10.1016/j.ejor.2021.03.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We use college football data and, in some cases, ESPN scout grades to estimate (1) attributes that are likely to result in a college quarterback being selected by a national football league (NFL) team, and (2) the performance of rookie quarterbacks in the NFL. We find that both college passing and rushing ability are significantly correlated with NFL selection, with strong passing ability the most important trait for making the NFL. Among quarterbacks selected for the NFL, college rushing ability is significantly correlated with NFL performance, but college passing ability is not. College rushing ability is also a significant determinant of NFL performance when scout grades are included as an explanatory variable. We conclude that rushing prowess is the key determinant of the NFL success of quarterbacks with sufficient passing skills to warrant NFL selection. Our findings also indicate that scouts systematically undervalue rushing ability when assessing the NFL potential of college quarterbacks.},
  archive      = {J_EJOR},
  author       = {J. Dean Craig and Niven Winchester},
  doi          = {10.1016/j.ejor.2021.03.013},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {733-743},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Predicting the national football league potential of college quarterbacks},
  volume       = {295},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Optimal insurance contract specification in the upstream
sector of the oil and gas industry. <em>EJOR</em>, <em>295</em>(2),
718–732. (<a href="https://doi.org/10.1016/j.ejor.2021.03.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The upstream sector of the Oil and Gas (O&amp;G) industry is recognized by its capital-intensive projects and complex and hazardous associated recovery and production processes, thus susceptible for large and financially damaging accidents. In this context, to avoid the risk and impact of high expenses, O&amp;G companies usually acquire insurance contracts. In practice, although the contract format is typically pre-specified, its parameter magnitudes can be adjusted aiming at maximizing the company total wealth. Therefore, this work proposes a holistic methodology to assess the optimal parameter specification of an insurance contract in the upstream sector of the O&amp;G industry. A non-convex stochastic optimization problem is constructed aiming at maximizing a risk-adjusted measure of the policyholder total wealth. The modeling takes into account the uncertainty on the financial loss of an accident by making use of the safety barriers and precursor information framework. The non-convex optimization problem is cast as an equivalent mixed-integer linear programming problem by combining the scenario-based representation approach with a set of binary reformulation procedures. We illustrate the applicability of the proposed methodology with a set of numerical experiments. In a nutshell, we found that the proposed parameter specification methodology resulted in greater predictability when compared to two quantile-based specification policies and an uninsured company. In fact, the second best policy presented a standard deviation 103\% higher than the proposed methodology. Furthermore, the model also provided greater protection against extreme events, since the second best policy presented a Conditional Value-at-Risk 41\% higher than the proposed methodology.},
  archive      = {J_EJOR},
  author       = {Ana Patrícia Torraca and Bruno Fanzeres},
  doi          = {10.1016/j.ejor.2021.03.011},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {718-732},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Optimal insurance contract specification in the upstream sector of the oil and gas industry},
  volume       = {295},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A finite-horizon condition-based maintenance policy for a
two-unit system with dependent degradation processes. <em>EJOR</em>,
<em>295</em>(2), 705–717. (<a
href="https://doi.org/10.1016/j.ejor.2021.03.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper analyzes a condition-based maintenance (CBM) model for a system with two heterogeneous components in which degradation follows a bivariate gamma process. Unlike the traditional CBM formulation that assumes an infinite planning horizon, this paper evaluates the maintenance cost in a finite planning horizon, which is the practical case for most systems. In the proposed CBM policy, both components are periodically inspected and a preventive or corrective replacement might be carried out based on the state of degradation at inspection. The CBM model is formulated as a Markov decision process (MDP) and dynamic programming is used to compute the expected maintenance cost over a finite planning horizon. The expected maintenance cost is minimized with respect to the preventive replacement thresholds for the two components. Unlike an infinite-horizon CBM problem, which leads to a stationary maintenance policy, the optimal policy in the finite-horizon case turns out to be non-stationary in the sense that the optimal actions vary at each inspection epoch. A numerical example is presented to illustrate the proposed model and investigate the influence of economic dependency and correlation between the degradation processes on the optimal maintenance policy. Numerical results show that a higher dependence between the degradation processes actually reduces the maintenance cost, while a higher economic dependence leads to higher preventive replacement thresholds.},
  archive      = {J_EJOR},
  author       = {Bin Liu and Mahesh D. Pandey and Xiaolin Wang and Xiujie Zhao},
  doi          = {10.1016/j.ejor.2021.03.010},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {705-717},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A finite-horizon condition-based maintenance policy for a two-unit system with dependent degradation processes},
  volume       = {295},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Revisiting discrete time age replacement policy for
phase-type lifetime distributions. <em>EJOR</em>, <em>295</em>(2),
699–704. (<a href="https://doi.org/10.1016/j.ejor.2021.03.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For a system (or unit) whose lifetime is measured by the number cycles, according to the discrete time age replacement policy, it is replaced preventively after n n cycles or correctively at failure, whichever occurs first. In this paper, discrete time age replacement policy is revisited when the lifetime of the system is modeled by a discrete phase-type distribution. In particular, the necessary conditions for the unique and finite replacement cycle which minimizes the expected cost per unit of time are obtained. The necessary conditions are mainly based on the behavior of the hazard rate. The results are illustrated for some special discrete phase-type lifetime distributions. Computational results are also presented for the optimal replacement cycle under specific real life setups.},
  archive      = {J_EJOR},
  author       = {Serkan Eryilmaz},
  doi          = {10.1016/j.ejor.2021.03.007},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {699-704},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Revisiting discrete time age replacement policy for phase-type lifetime distributions},
  volume       = {295},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Relax-tighten-round algorithm for optimal placement and
control of valves and chlorine boosters in water networks.
<em>EJOR</em>, <em>295</em>(2), 690–698. (<a
href="https://doi.org/10.1016/j.ejor.2021.03.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a new mixed integer nonlinear programming formulation is proposed for optimally placing and operating pressure reducing valves and chlorine booster stations in water distribution networks. The objective is the minimization of average zone pressure, while penalizing deviations from a target chlorine concentration. We propose a relax-tighten-round algorithm based on tightened polyhedral relaxations and a rounding scheme to compute feasible solutions, with bounds on their optimality gaps. This is because off-the-shelf global optimization solvers failed to compute feasible solutions for the considered non-convex mixed integer nonlinear program. The implemented algorithm is evaluated using three benchmarking water networks, and they are shown to outperform off-the-shelf solvers, for these case studies. The proposed heuristic has enabled the computation of good quality feasible solutions in most instances, with bounds on the optimality gaps that are comparable to the order of uncertainty observed in operational water network models.},
  archive      = {J_EJOR},
  author       = {Filippo Pecci and Ivan Stoianov and Avi Ostfeld},
  doi          = {10.1016/j.ejor.2021.03.004},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {690-698},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Relax-tighten-round algorithm for optimal placement and control of valves and chlorine boosters in water networks},
  volume       = {295},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Introduction of an underground waste container system–model
and solution approaches. <em>EJOR</em>, <em>295</em>(2), 675–689. (<a
href="https://doi.org/10.1016/j.ejor.2021.02.060">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In Germany, household waste is collected via a door-to-door collection system. This form of waste collection is already reaching its limits due to the increasing volume of household waste and lack of space for even more dustbins, especially in densely populated cities. In this paper we investigate an alternative collection system: an underground waste collection system in which waste would be collected at central locations in so-called underground containers with a much larger capacity. If an underground container system is to be introduced to replace the present door-to-door waste collection system, a number of decisions of varying scope have to be made: Where should the underground containers be placed? How much capacity should be provided at which collection site? Which household should dispose of its waste where? How often, when and in what order should the waste collection vehicles empty the containers? In this paper we develop a model to illustrate the combination of the underlying problems by extending a problem known from literature. We present both hierarchical and integrated approaches to solve it. The proposed solution approaches combine in different ways two variable neighborhood search heuristics and a mixed integer programming-based exact method. We show that great benefits can be achieved through the use of integrated solution approaches. But we show too that integrated solution approaches do not necessarily dominate hierarchical ones.},
  archive      = {J_EJOR},
  author       = {Sina Gläser and Mareike Stücken},
  doi          = {10.1016/j.ejor.2021.02.060},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {675-689},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Introduction of an underground waste container system–model and solution approaches},
  volume       = {295},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). How training on multiple time slices improves performance in
churn prediction. <em>EJOR</em>, <em>295</em>(2), 664–674. (<a
href="https://doi.org/10.1016/j.ejor.2021.05.035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Customer churn prediction models using machine learning classification have been developed predominantly by training and testing on one time slice of data. We train models on multiple time slices of data and refer to this approach as multi-slicing. Our results show that given the same time frame of data, multi-slicing significantly improves churn prediction performance compared to training on the entire data set as one time slice. We demonstrate that besides an increased training set size, the improvement is driven by training on samples from different time slices. For data from a convenience wholesaler, we show that multi-slicing addresses the rarity of churn samples and the risk of overfitting to the distinctive situation in a single training time slice. Multi-slicing makes a model more generalizable, which is particularly relevant whenever conditions change or fluctuate over time. We also discuss how to choose the number of time slices.},
  archive      = {J_EJOR},
  author       = {Theresa Gattermann-Itschert and Ulrich W. Thonemann},
  doi          = {10.1016/j.ejor.2021.05.035},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {664-674},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {How training on multiple time slices improves performance in churn prediction},
  volume       = {295},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). On sparse ensemble methods: An application to short-term
predictions of the evolution of COVID-19. <em>EJOR</em>,
<em>295</em>(2), 648–663. (<a
href="https://doi.org/10.1016/j.ejor.2021.04.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Since the seminal paper by Bates and Granger in 1969, a vast number of ensemble methods that combine different base regressors to generate a unique one have been proposed in the literature. The so-obtained regressor method may have better accuracy than its components, but at the same time it may overfit, it may be distorted by base regressors with low accuracy, and it may be too complex to understand and explain. This paper proposes and studies a novel Mathematical Optimization model to build a sparse ensemble, which trades off the accuracy of the ensemble and the number of base regressors used. The latter is controlled by means of a regularization term that penalizes regressors with a poor individual performance. Our approach is flexible to incorporate desirable properties one may have on the ensemble, such as controlling the performance of the ensemble in critical groups of records, or the costs associated with the base regressors involved in the ensemble. We illustrate our approach with real data sets arising in the COVID-19 context.},
  archive      = {J_EJOR},
  author       = {Sandra Benítez-Peña and Emilio Carrizosa and Vanesa Guerrero and M. Dolores Jiménez-Gamero and Belén Martín-Barragán and Cristina Molero-Río and Pepa Ramírez-Cobo and Dolores Romero Morales and M. Remedios Sillero-Denamiel},
  doi          = {10.1016/j.ejor.2021.04.016},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {648-663},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {On sparse ensemble methods: An application to short-term predictions of the evolution of COVID-19},
  volume       = {295},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Robust low-rank multiple kernel learning with compound
regularization. <em>EJOR</em>, <em>295</em>(2), 634–647. (<a
href="https://doi.org/10.1016/j.ejor.2020.12.024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Kernel learning is widely used in nonlinear models during the implementation of forecasting tasks in analytics. However, existing forecasting models lack robustness and accuracy. Therefore, in this study, a novel supervised forecasting approach based on robust low-rank multiple kernel learning with compound regularization is investigated. The proposed method extracts the benefits from robust regression, multiple kernel learning with low-rank approximation, and sparse learning systems. Unlike existing hybrid forecasting methods, which frequently combine different models in parallel, we embed a Huber or quantile loss function and a compound regularization composed of smoothly clipped absolute deviation and ridge regularizations in a support vector machine with predefined number of kernels. To select the optimal kernels, L 1 L1 penalization with positive constraint is also considered. The proposed model exhibits robustness, forecasting accuracy, and sparsity in the reproducing kernel Hilbert space. For computation, a simple algorithm is designed based on local quadratic approximation to implement the proposed method. Theoretically, the forecasting and estimation error bounds of the proposed estimators are derived under a null consistency assumption. Real data experiments using datasets from various scientific research fields demonstrate the superior performances of the proposed approach compared with other state-of-the-art competitors.},
  archive      = {J_EJOR},
  author       = {He Jiang and Changqi Tao and Yao Dong and Ren Xiong},
  doi          = {10.1016/j.ejor.2020.12.024},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {634-647},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Robust low-rank multiple kernel learning with compound regularization},
  volume       = {295},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Stochastic multi-attribute acceptability analysis with
numerous alternatives. <em>EJOR</em>, <em>295</em>(2), 621–633. (<a
href="https://doi.org/10.1016/j.ejor.2021.03.037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stochastic multi-attribute acceptability analysis (SMAA) is a method for assisting multi-attribute decision-making with unknown preference information and inaccurate or uncertain attribute values. The traditional Monte Carlo simulation-based SMAA can calculate the rank acceptability of each alternative for small data sets. However, computation time exhibits a geometric growth as the number of alternatives increases. Thus, decision makers are facing a problem of efficiently running SMAA procedure on large data sets. In this paper, we propose a novel algorithm for solving this problem. In particular, we divide large alternative set into small groups on the basis of studying of the relationships of alternatives’ k -best rank acceptability and holistic acceptability between whole alternative sets and their subsets. Lastly, the proposed method is applied to simulated data sets and real-world data sets in the express industry.},
  archive      = {J_EJOR},
  author       = {Shiling Song and Feng Yang and Pingxiang Yu and Jianhui Xie},
  doi          = {10.1016/j.ejor.2021.03.037},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {621-633},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Stochastic multi-attribute acceptability analysis with numerous alternatives},
  volume       = {295},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Robustness of farrell cost efficiency measurement under data
perturbations: Evidence from a US manufacturing application.
<em>EJOR</em>, <em>295</em>(2), 604–620. (<a
href="https://doi.org/10.1016/j.ejor.2021.03.019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Measuring economic and cost efficiency receives ever-increasing attention of the executives and managers of small-and medium-sized enterprises (SMEs) to minimise total production costs. The conventional Farrell cost efficiency (CE) as a key determinant requires the precise information on inputs, outputs and input prices, while in praxis uncertainty is inherent and inevitable in data and its negligence conceivably results in a dire approximation for CE measures. This paper is concerned with Farrell CE in situations of both endogenous and exogenous uncertainty. The source of uncertainty allows us to define two different scenarios; ( i ) in situations of endogenous uncertainty in input and output data where the uncertainty is affected by the decision maker&#39;s decisions, and (ii) in situations of uncertain prices for inputs where the uncertainty is exogenously given. In the first scenario, the theory of robust optimisation is adopted to develop the robust data envelopment analysis (DEA) models with the aim of grappling uncertainties in input and output data when measuring technical and cost efficiencies. The second scenario aims to accommodate uncertainties on price information by developing a pair of robust DEA models based upon robust optimisation estimating the upper and lower bounds for CE measures. This unprecedented study helps us to provide a generalised framework for economic efficiency with uncertainties in which conventional properties of Farrell measures are fulfilled. In addition to comparing the developed approach in this paper with other existing approaches through a simple numerical example, the usefulness and applicability of the suggested framework are minutely studied in an empirical application in the context of allocation problems.},
  archive      = {J_EJOR},
  author       = {Adel Hatami-Marbini and Aliasghar Arabmaldar},
  doi          = {10.1016/j.ejor.2021.03.019},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {604-620},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Robustness of farrell cost efficiency measurement under data perturbations: Evidence from a US manufacturing application},
  volume       = {295},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Risk sharing with multiple indemnity environments.
<em>EJOR</em>, <em>295</em>(2), 587–603. (<a
href="https://doi.org/10.1016/j.ejor.2021.03.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optimal risk sharing arrangements have been substantially studied in the literature, from the aspects of generalizing objective functions, incorporating more business constraints, and investigating different optimality criteria. This paper proposes an insurance model with multiple risk environments. We study the case where the two agents are endowed with the Value-at-Risk or the Tail Value-at-Risk, or when both agents are risk-neutral but have heterogeneous beliefs regarding the underlying probability distribution. We show that layer-type indemnities, within each risk environment, are Pareto optimal, which may be environment-specific. From Pareto optimality, we get that the premium can be chosen in a given interval, and we propose to allocate the gains from risk sharing equally between the buyer and seller.},
  archive      = {J_EJOR},
  author       = {Alexandru V. Asimit and Tim J. Boonen and Yichun Chi and Wing Fung Chong},
  doi          = {10.1016/j.ejor.2021.03.012},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {587-603},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Risk sharing with multiple indemnity environments},
  volume       = {295},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Filtered poisson process bandit on a continuum.
<em>EJOR</em>, <em>295</em>(2), 575–586. (<a
href="https://doi.org/10.1016/j.ejor.2021.03.033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a version of the continuum armed bandit where an action induces a filtered realisation of a non-homogeneous Poisson process. Point data in the filtered sample are then revealed to the decision-maker, whose reward is the total number of revealed points. Using knowledge of the function governing the filtering, but without knowledge of the Poisson intensity function, the decision-maker seeks to maximise the expected number of revealed points over T T rounds. We propose an upper confidence bound algorithm for this problem utilising data-adaptive discretisation of the action space. This approach enjoys O ˜ ( T 2 / 3 ) O˜(T2/3) regret under a Lipschitz assumption on the reward function. We provide lower bounds on the regret of any algorithm for the problem, via new lower bounds for related finite-armed bandits, and show that the orders of the upper and lower bounds match up to a logarithmic factor.},
  archive      = {J_EJOR},
  author       = {James A. Grant and Roberto Szechtman},
  doi          = {10.1016/j.ejor.2021.03.033},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {575-586},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Filtered poisson process bandit on a continuum},
  volume       = {295},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Optimal bookmaking. <em>EJOR</em>, <em>295</em>(2), 560–574.
(<a href="https://doi.org/10.1016/j.ejor.2021.03.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce a general framework for continuous-time betting markets, in which a bookmaker can dynamically control the prices of bets on outcomes of random events. In turn, the prices set by the bookmaker affect the rate or intensity of bets placed by gamblers. The bookmaker seeks an optimal price process that maximizes his expected (utility of) terminal wealth. We obtain explicit solutions or characterizations to the bookmaker’s optimal bookmaking problem in various interesting models.},
  archive      = {J_EJOR},
  author       = {Matthew Lorig and Zhou Zhou and Bin Zou},
  doi          = {10.1016/j.ejor.2021.03.005},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {560-574},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Optimal bookmaking},
  volume       = {295},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An almost robust model for minimizing disruption exposures
in supply systems. <em>EJOR</em>, <em>295</em>(2), 547–559. (<a
href="https://doi.org/10.1016/j.ejor.2021.03.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies two-stage disruption exposure minimization problems, motivated by the supply disruption issues in the energy and water supply systems. In particular, we address the ambiguity in both the probability distribution and risk preference of decision-makers towards disruption exposures. First, we propose a two-stage distributionally robust model with adjustable uncertainty sets , which solves a supply system solution with the least possible disruption exposures. We show that this two-stage robust disruption exposure model can be reduced to a computationally attractive single-stage mixed-integer linear program. We then propose an extended almost-robust disruption guarantee model to account for the ambiguity in the risk preference of decision-makers. We demonstrate that this almost-robust guarantee model can reveal clear preferences of most decision-makers under limited distribution information, which however does not resort to any particular disutility function specification and can be solved efficiently using a binary search algorithm. A decision support framework is also developed to guide users on how to apply the proposed disruption exposure models. Finally, we apply the proposed models to a distributed energy supply system design problem. Numerical results show that our models significantly outperform a risk-neutral model in hedging against a broad set of supply distributions. Moreover, the almost-robust guarantee model exhibits its advantages in hedging against high disruption levels, and performs the best under the vast majority of distributions regarding all tested statistical criteria.},
  archive      = {J_EJOR},
  author       = {Kena Zhao and Tsan Sheng Ng and Chin Hon Tan and Chee Khiang Pang},
  doi          = {10.1016/j.ejor.2021.03.003},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {547-559},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {An almost robust model for minimizing disruption exposures in supply systems},
  volume       = {295},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Buyer selection and service pricing in an electric fleet
supply chain. <em>EJOR</em>, <em>295</em>(2), 534–546. (<a
href="https://doi.org/10.1016/j.ejor.2021.03.018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Much attention has been focused on supplier selection in operations. There has been less research on the supplier selecting buyers in a two-echelon supplier-buyer chain, which we study for downstream taxicab vehicle fleets. We consider the problem of pricing infrastructure services by an electric vehicles (EVs) service provider (SP), which determines the group of taxicab companies (TCs) that will adopt EVs. We study SP’s pricing decisions in a decentralized supply chain under a general infrastructure cost function, multiple TCs, and symmetric information. We extend the modeling to the case with (i) endogenous demand and EV-taxicab end-consumer pricing and (ii) asymmetric information between SP and TC. We analyze the factors that influence SP’s profits and the set of participating TCs who adopt EVs. We find that when the fleet size of TCs increases, SP prefers to serve more low-mile TCs than the high-mile TCs and even removes some high-mile TCs in exchange for low-mile TCs, where low and high-miles correspond to average miles driven in a time period (shift). When the coefficient of variation of miles driven increases, SP prefers to serve more high-mile TCs than the low-mile TCs. In general, the set of TCs that adopt EVs cannot be simply characterized using inputs such as average miles driven by different TCs. This study provides a modeling framework and managerial implications for TC selection and pricing contracts by an EV infrastructure service provider.},
  archive      = {J_EJOR},
  author       = {Saravanan Kuppusamy and Michael J. Magazine and Uday Rao},
  doi          = {10.1016/j.ejor.2021.03.018},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {534-546},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Buyer selection and service pricing in an electric fleet supply chain},
  volume       = {295},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Does implementing trade-in and green technology together
benefit the environment? <em>EJOR</em>, <em>295</em>(2), 517–533. (<a
href="https://doi.org/10.1016/j.ejor.2021.03.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In modern manufacturing operations, green technologies are becoming increasingly popular. Meanwhile, trade-in programs are widely implemented to boost sales and enhance product recycling, which would benefit the environment. It is widely observed that many companies implement the green technology (GT) and trade-in program together. However, whether this act is always beneficial to the environment is unclear. We hence build analytical models to address this issue. To conduct a comprehensive study, we follow the real-world practices and examine both the retailer collects (R-collect) and manufacturer collects (M-collect) scenarios in a supply chain. Our results show that the “R-collect scheme with GT” leads to the highest levels of supply chain profit and social welfare but more emissions may be generated. Besides, implementing GT does not always benefit the environment in both R-collect and M-collect schemes. Considering from the environment perspective, we interestingly show that governments should advocate the “M-collect with GT” and “R-collect without GT” schemes. Correspondingly, to motivate both the supply chain and consumers to accept the advocated strategies, we characterize the carbon tax and subsidy based “carrot-and-stick” policy. We further show in the extended analyses that our main results hold under competition, when the emission abatement cost takes different analytical forms, and when consumers are environmentally conscious.},
  archive      = {J_EJOR},
  author       = {Guowei Dou and Tsan-Ming Choi},
  doi          = {10.1016/j.ejor.2021.03.017},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {517-533},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Does implementing trade-in and green technology together benefit the environment?},
  volume       = {295},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An exact robust approach for the integrated berth allocation
and quay crane scheduling problem under uncertain arrival times.
<em>EJOR</em>, <em>295</em>(2), 499–516. (<a
href="https://doi.org/10.1016/j.ejor.2021.03.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider an integrated berth allocation and quay crane assignment and scheduling problem where the arrival times of the vessels may be affected by uncertainty. The problem is modelled as a two-stage robust mixed integer program where the berth allocation decisions are taken before the exact arrival times are known, and the crane assignment and scheduling operations are adjusted to the arrival times. To solve the robust two-stage model, we follow a decomposition algorithm that decomposes the problem into a master problem and a separation problem. A new scenario reduction procedure for solving the separation problem is proposed as well as a warm start technique for reducing the number of iterations performed by the decomposition algorithm. To scale the proposed decomposition algorithm for large size instances, it is combined with a rolling horizon heuristic.The efficiency and effectiveness of the proposed algorithms are demonstrated through extensive computational experiments carried out on randomly generated instances with both homogeneous and heterogeneous cranes as well as on instances from the literature.},
  archive      = {J_EJOR},
  author       = {Filipe Rodrigues and Agostinho Agra},
  doi          = {10.1016/j.ejor.2021.03.016},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {499-516},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {An exact robust approach for the integrated berth allocation and quay crane scheduling problem under uncertain arrival times},
  volume       = {295},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Integrated optimization of bus bridging routes and
timetables for rail disruptions. <em>EJOR</em>, <em>295</em>(2),
484–498. (<a href="https://doi.org/10.1016/j.ejor.2021.03.014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A rail disruption may lead to rapid degradation of the public transportation system. In response to rail disruptions, this study focuses on bus bridging service design considering a routing strategy that combines express and short-turn routes. An integrated optimization framework is proposed to jointly optimize the bus bridging routes and timetables under time-varying demand. A brute-force search method is developed to identify all candidate bus bridging routes. A mixed integer linear programming model is then formulated to solve the route selection, bus deployment, and bus timetabling problem simultaneously. To handle the arising computational challenges in solving this large-scale problem, a tabu search-based heuristic with LP rounding is developed. Numerical studies based on Cranbourne Line, Melbourne, demonstrates the applicability of the proposed approach in practice. The results indicate that the proposed framework can generate high-quality bus bridging solutions in a reasonable time, which allows quick response to rail line disruptions. The bus bridging strategy with multiple routes outperforms the standard bridging route in terms of bus line capacity and passenger travel time.},
  archive      = {J_EJOR},
  author       = {Yao Chen and Kun An},
  doi          = {10.1016/j.ejor.2021.03.014},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {484-498},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Integrated optimization of bus bridging routes and timetables for rail disruptions},
  volume       = {295},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Quantile estimation of stochastic frontiers with the
normal-exponential specification. <em>EJOR</em>, <em>295</em>(2),
475–483. (<a href="https://doi.org/10.1016/j.ejor.2021.03.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There has been increased interest in estimation of the stochastic frontier model via quantile regression. Two main approaches currently exist, one that ignores distributional assumptions and selects arbitrary quantiles and another that attempts to estimate the frontier by recognizing that it aligns with a specific quantile of the conditional distribution of output. We add to this second vein of literature by developing the necessary tools to estimate the quantile which is consistent with the location of the frontier under the Normal-Exponential distributional setting. We show that this can be accomplished by evaluating the Normal-Exponential cumulative distribution function at the expected value of OLS residuals to directly estimate the stochastic frontier model parameters. Both simulations and an empirical illustration showcase the performance of the method.},
  archive      = {J_EJOR},
  author       = {Samah Jradi and Christopher F. Parmeter and John Ruggiero},
  doi          = {10.1016/j.ejor.2021.03.002},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {475-483},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Quantile estimation of stochastic frontiers with the normal-exponential specification},
  volume       = {295},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Robust inventory management with multiple supply sources.
<em>EJOR</em>, <em>295</em>(2), 463–474. (<a
href="https://doi.org/10.1016/j.ejor.2021.03.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study a robust rolling horizon model for a periodically reviewed inventory system with multiple supply sources with general lead times. We restrict the demands in an uncertainty set without knowing the distributions. We prove that under some appropriate conditions, the robust optimal policy for multiple sourcing is a combination of the base-stock policy and a gap-of-base-stock policy with capping effect on supply sources except the fastest source. In particular, the structure of this policy is not a natural extension of the robust optimal policy for the system with two supply sources, for which the recent literature shows that the robust optimal policy is a dual-index, dual-base-stock policy that caps the slow order. We also derive closed-form expressions of the robust optimal policy for the central limit theorem (CLT) uncertainty set. We numerically testify to the effectiveness of the structure of the robust optimal policy for more than two supply sources using both simulation demand and real sales data. The computational results are promising.},
  archive      = {J_EJOR},
  author       = {Chen Xie and Liangquan Wang and Chaolin Yang},
  doi          = {10.1016/j.ejor.2021.03.001},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {463-474},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Robust inventory management with multiple supply sources},
  volume       = {295},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A mixed-integer linear programming approach for the t-row
and the multi-bay facility layout problem. <em>EJOR</em>,
<em>295</em>(2), 443–462. (<a
href="https://doi.org/10.1016/j.ejor.2021.02.044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce a new facility layout problem, the so-called T-Row Facility Layout Problem (TRFLP). The TRFLP consists of a set of one-dimensional departments with pairwise transport weights between them and two orthogonal rows which form a T such that departments in different rows cannot overlap. The aim is to find a non-overlapping assignment of the departments to the rows such that the sum of the weighted center-to-center distances measured in rectilinear directions is minimized. The TRFLP is a generalization of the well-known Multi-Bay Facility Layout Problem with three rows (3-BFLP). Both problems, the TRFLP and the 3-BFLP, have wide applications, e.g., factory planning, semiconductor fabrication and arranging rooms in hospitals. In this work we present a mixed-integer linear programming approach for the TRFLP and the 3-BFLP based on an extension of the well-known betweenness variables which now can be equal to one if the corresponding departments lie in different rows. One advantage of our formulation is the calculation of inter-row distances without big-M-type constraints. We provide cutting planes exploiting the crossroad structure in the layout, and hence T-row (3-Bay) instances with up to 18 (17) departments are solved to optimality in less than 7 h. The best known approach for the 3-BFLP is clearly outperformed. Additionally, tight lower bounds for larger instances are calculated to evaluate our heuristically determined layouts.},
  archive      = {J_EJOR},
  author       = {Mirko Dahlbeck},
  doi          = {10.1016/j.ejor.2021.02.044},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {443-462},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A mixed-integer linear programming approach for the T-row and the multi-bay facility layout problem},
  volume       = {295},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Optimizing large on-demand transportation systems through
stochastic conic programming. <em>EJOR</em>, <em>295</em>(2), 427–442.
(<a href="https://doi.org/10.1016/j.ejor.2020.10.053">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {On-demand transportation systems (OTS) are increasingly popular worldwide. Prior literature has studied how to control vehicle fleet in queueing-networks to rebalance excess supply or demand in OTS. This aggregated setting models the stochastic demand process and decompose large-scale networks for which product-form equilibrium distributions exist. However, such an approach is unsatisfactory in terms of computational complexity for its dependence on vehicle numbers. This paper presents a stochastic conic programming approach that obtains the near-optimal vehicle repositioning controls with endogenous demand with mild computational complexity and high fidelity. This global framework covers most existing queueing-network-based OTS models in the literature. Leveraging this approach, we explore day-to-day vehicle repositioning problems for on-demand vehicle operations in New York City. These results support the potential for providing a more accessible and sustainable on-demand mobility service, which is of particular significance as multimodal transport continues to emerge.},
  archive      = {J_EJOR},
  author       = {Shukai Li and Qi Luo and Robert Cornelius Hampshire},
  doi          = {10.1016/j.ejor.2020.10.053},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {427-442},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Optimizing large on-demand transportation systems through stochastic conic programming},
  volume       = {295},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Four decades of research on the open-shop scheduling problem
to minimize the makespan. <em>EJOR</em>, <em>295</em>(2), 399–426. (<a
href="https://doi.org/10.1016/j.ejor.2021.03.026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the basic scheduling problems, the open-shop scheduling problem has a broad range of applications across different sectors. The problem concerns scheduling a set of jobs, each of which has a set of operations, on a set of different machines. Each machine can process at most one operation at a time and the job processing order on the machines is immaterial, i.e., it has no implication for the scheduling outcome. The aim is to determine a schedule, i.e., the completion times of the operations processed on the machines, such that a performance criterion is optimized. While research on the problem dates back to the 1970s, there have been reviving interests in the computational complexity of variants of the problem and solution methodologies in the past few years. Aiming to provide a complete road map for future research on the open-shop scheduling problem, we present an up-to-date and comprehensive review of studies on the problem that focuses on minimizing the makespan, and discuss potential research opportunities.},
  archive      = {J_EJOR},
  author       = {Mohammad Mahdi Ahmadian and Mostafa Khatami and Amir Salehipour and T.C.E. Cheng},
  doi          = {10.1016/j.ejor.2021.03.026},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {399-426},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Four decades of research on the open-shop scheduling problem to minimize the makespan},
  volume       = {295},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Some comments on improving discriminating power in data
envelopment models based on deviation variables framework.
<em>EJOR</em>, <em>295</em>(1), 394–397. (<a
href="https://doi.org/10.1016/j.ejor.2021.02.056">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ghasemi, Ignatius, and Rezaee (2019) (Improving discriminating power in data envelopment models based on deviation variables framework. European Journal of Operational Research 278, 442– 447) propose a procedure for ranking efficient units in data envelopment analysis (DEA) based on the deviation variables framework. They claim that their procedure improves the discriminating power of DEA and can be an alternative to the super-efficiency model that is well-known to have the infeasibility problem and the cross-efficiency approach which suffers from the presence of multiple optimal solutions. However, we demonstrate, in this short note, that their procedure is developed based upon inappropriate use of deviation variables which leads to the development of a ranking approach that does not meet their expectations and as a result, an unreasonable ranking of decision making units (DMUs). We also show that the use of deviation variables, if interpreted and used correctly, can lead to developing a cross-inefficiency matrix and approach.},
  archive      = {J_EJOR},
  author       = {Mahdi Mahdiloo and Sungmook Lim and Thach-Thao Duong and Charles Harvie},
  doi          = {10.1016/j.ejor.2021.02.056},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {394-397},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Some comments on improving discriminating power in data envelopment models based on deviation variables framework},
  volume       = {295},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Diversification benefits in the cryptocurrency market under
mild explosivity. <em>EJOR</em>, <em>295</em>(1), 378–393. (<a
href="https://doi.org/10.1016/j.ejor.2021.02.058">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We investigate whether cryptocurrencies provide diversification benefits to risk averters via a stochastic spanning methodology. We avoid the conceptual and statistical problems of non-stationary returns by providing a modification of the second order stochastic dominance relation and of the related notion of stochastic spanning. These are compatible with a mildly explosive framework for the logarithm prices, along with conditions for asymptotic negligibility of bubbles. In the empirical application, we construct optimal portfolios, both with and without cryptocurrencies, and evaluate their comparative performance both in- and out-of-sample. A conservative modification of a t-test is presented to test the null hypothesis of non-dominance of an optimal portfolio that includes cryptocurrencies over the traditional portfolio of only stocks, bonds and cash. The augmented portfolio is found to be a good diversification option for some risk averse investors in the full sample period and in a sub-period of high cryptocurrency returns.},
  archive      = {J_EJOR},
  author       = {Sofia Anyfantaki and Stelios Arvanitis and Nikolas Topaloglou},
  doi          = {10.1016/j.ejor.2021.02.058},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {378-393},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Diversification benefits in the cryptocurrency market under mild explosivity},
  volume       = {295},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A one-sided vysochanskii-petunin inequality with financial
applications. <em>EJOR</em>, <em>295</em>(1), 374–377. (<a
href="https://doi.org/10.1016/j.ejor.2021.02.041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We derive a one-sided Vysochanskii-Petunin inequality, providing probability bounds for random variables analogous to those given by Cantelli’s inequality under the additional assumption of unimodality, potentially relevant for applied statistical practice across a wide range of disciplines. As a possible application of this inequality in a financial context, we examine refined bounds for the individual risk measure of Value-at-Risk, providing a potentially useful alternative benchmark with interesting regulatory implications for the Basel multiplier.},
  archive      = {J_EJOR},
  author       = {Mathieu Mercadier and Frank Strobel},
  doi          = {10.1016/j.ejor.2021.02.041},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {374-377},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A one-sided vysochanskii-petunin inequality with financial applications},
  volume       = {295},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Equilibrium selection for multi-portfolio optimization.
<em>EJOR</em>, <em>295</em>(1), 363–373. (<a
href="https://doi.org/10.1016/j.ejor.2021.02.033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We analyze a Nash equilibrium problem arising when trades from different accounts are pooled for execution. We introduce a new general multi-portfolio model and state sufficient conditions for the monotonicity of the underlying Nash equilibrium problem. Monotonicity makes it possible to treat the problem numerically and, for the case of nonunique equilibria, to solve hierarchical problems of equilibrium selection. We also give sufficient conditions for the Nash equilibrium problem formulation to be a potential game. Our computational experience confirms the theoretical insights and substantiates the significance of the equilibrium selection.},
  archive      = {J_EJOR},
  author       = {Lorenzo Lampariello and Christoph Neumann and Jacopo M. Ricci and Simone Sagratella and Oliver Stein},
  doi          = {10.1016/j.ejor.2021.02.033},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {363-373},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Equilibrium selection for multi-portfolio optimization},
  volume       = {295},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Regulation adaptive strategy and bank efficiency: A network
slacks-based measure with shared resources. <em>EJOR</em>,
<em>295</em>(1), 348–362. (<a
href="https://doi.org/10.1016/j.ejor.2021.02.050">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Banks have two primary strategies for adapting to a regulation change in the era of big data which can be characterized as natural disposability and managerial disposability. Natural disposability implies a negative strategy by which a bank attempts to decreases its vector of inputs to decrease undesirable outputs. In contrast, managerial disposability indicates a positive strategy by which a bank considers a regulation change as an opportunity and adapt the regulation change by utilizing big data technology. The operational process of a bank can be decomposed into a productivity stage and a profitability stage. Furthermore, the operation costs, a shared resource, can be used to characterize natural disposability and managerial disposability. Based on natural disposability and managerial disposability, this paper proposes two network models to estimate the efficiencies of banks. To test their practical implications, the proposed models were applied to examine the efficiencies of Chinese commercial banks in the period 2014−2018. Our key findings are as follows. (1) There exist great disparities in the inefficiencies between two adaptive strategies. The inefficiencies are primarily driven by the profitability stage under natural disposability, whereas the inefficiencies are equally attributed to both stages under managerial disposability. (2) The efficiency differences among different types of banks are insignificant under natural disposability but are significant under managerial disposability. (3) Joint-stock commercial banks are more oveall efficient than state-owned commercial banks, city commercial banks and rural commercial banks, while state-owned commercial banks show worst practice for overall efficiency and profitability stage efficiency.},
  archive      = {J_EJOR},
  author       = {Linlin Zhao and Qingyuan Zhu and Lin Zhang},
  doi          = {10.1016/j.ejor.2021.02.050},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {348-362},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Regulation adaptive strategy and bank efficiency: A network slacks-based measure with shared resources},
  volume       = {295},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An exact model for a slitting problem in the steel industry.
<em>EJOR</em>, <em>295</em>(1), 336–347. (<a
href="https://doi.org/10.1016/j.ejor.2021.02.048">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {From an economic point of view, the steel industry plays an important role and, when it comes to responding to new challenges, innovation is a crucial factor. This paper proposes a mathematical methodology to solve the slitting problem in a steel company located in Europe. The slitting problem occurs when large width steel coils are slit into narrower coils, known as strips, to meet the requirements of the customers. A major challenge here is defining a slitting plan to fulfil all these requirements, as well as ongoing operational constraints and customer demands. The company looks for a reduction of the leftovers generated in the entire process, while maximising the overall accuracy of the orders. These leftovers may be used in the future as part of new orders provided they are able to respond to specific requirements, or otherwise they are discarded and considered as scrap. This paper introduces a novel mixed integer linear optimisation model to respond to a specific slitting problem. The model is validated with real data and it outperforms the results obtained by the company in different ways: by adjusting the orders that are to be served, by reducing the amount of scrap and by using the retails for future orders. Furthermore, the model is solved in only a few minutes, while the company needs several hours to prepare the scheduling in the current operating process.},
  archive      = {J_EJOR},
  author       = {María Sierra-Paradinas and Óscar Soto-Sánchez and Antonio Alonso-Ayuso and F. Javier Martín-Campo and Micael Gallego},
  doi          = {10.1016/j.ejor.2021.02.048},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {336-347},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {An exact model for a slitting problem in the steel industry},
  volume       = {295},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Supporting brazilian smallholder farmers decision making in
supplying institutional markets. <em>EJOR</em>, <em>295</em>(1),
321–335. (<a href="https://doi.org/10.1016/j.ejor.2021.02.047">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Smallholder farmers are amongst the most vulnerable communities in developing countries, lacking a stable income due to inconsistent access to markets. Aiming to tackle rural poverty, the Brazilian government established institutional markets for smallholder farmers to supply their produce to schools through a non-competitive bidding mechanism. However, participation of farmers is still limited due to the challenging decision-making process. Aspiring to contribute towards increasing their participation, this study aims to support farmers into two key decisions they face during sequential stages of the bidding process, namely whether to bid for each available school and product combination and whether subsequently to accept the awarded bids once the bids’ outcome is known. A decision support system, based on two sequential MILP optimisation models, was developed and applied to the case study of Canudos settlement, guiding farmers on the optimal bidding and contract acceptance strategy. This study contributes to the decision support systems field by applying OR methods to a real-life problem within a new context. It is the first application of an OR-based decision support system in the non-competitive bid/no-bid literature, defining an optimal bidding strategy through the application of optimisation methods to maximise profitability while removing subjectivity from the decision-making process. Moreover, it is the first decision support system within the bid/no-bid decision-making field being applied to the agricultural and institutional market context. The proposed approach could have a significant social impact for smallholder farmers in Brazil, improving their living conditions by providing security of income and strengthening inclusive agricultural growth.},
  archive      = {J_EJOR},
  author       = {Helio Yochihiro Fuchigami and Andrea Tuni and Luísa Queiroz Barbosa and Maico Roris Severino and Athanasios Rentizelas},
  doi          = {10.1016/j.ejor.2021.02.047},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {321-335},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Supporting brazilian smallholder farmers decision making in supplying institutional markets},
  volume       = {295},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Identifying proactive ICU patient admission, transfer and
diversion policies in a public-private hospital network. <em>EJOR</em>,
<em>295</em>(1), 306–320. (<a
href="https://doi.org/10.1016/j.ejor.2021.02.045">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Management of hospital beds is a high-impact issue for two-tier healthcare systems, due principally to their critical importance and high costs. Bed capacity in the public sector is generally insufficient to provide immediate care to all critical patients and thus a significant proportion of public expenditure is assigned to the diversion of patients for treatment in the private sector. We formulate and approximately solve a discounted infinite-horizon Markov Decision Process (MDP) that seeks to identify cost-effective policies for transferring ICU patients between hospitals or diverting them to private clinics. The solution approach employs an affine architecture for approximating the value function of the MDP model and solves the equivalent linear programming model using column generation. The approach can handle a high level of dimensionality, enabling it to consider the arriving patients’ many different diagnostic groups and their corresponding lengths of stay. The decisions generated through this approach often differ from the intuitive ones produced in a typical day-by-day decision process, that does not consider the impact of the current day’s decisions on the future performance of the system. In particular, the resulting policies will in many cases proactively transfer patients to a different public facility or divert them to a private one even though the hospital they first arrived at had beds available. The performance of the proposed method was evaluated by simulating a case study based on data from a hospital network in Santiago, Chile, producing savings of almost 49\% due mostly to reduced usage of private services.},
  archive      = {J_EJOR},
  author       = {José Tomás Marquinez and Antoine Sauré and Alejandro Cataldo and Juan-Carlos Ferrer},
  doi          = {10.1016/j.ejor.2021.02.045},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {306-320},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Identifying proactive ICU patient admission, transfer and diversion policies in a public-private hospital network},
  volume       = {295},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Deep learning for credit scoring: Do or don’t?
<em>EJOR</em>, <em>295</em>(1), 292–305. (<a
href="https://doi.org/10.1016/j.ejor.2021.03.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Developing accurate analytical credit scoring models has become a major focus for financial institutions. For this purpose, numerous classification algorithms have been proposed for credit scoring. However, the application of deep learning algorithms for classification has been largely ignored in the credit scoring literature. The main motivation for this research is to consider the appropriateness of deep learning algorithms for credit scoring. To this end two deep learning architectures are constructed, namely a multilayer perceptron network and a deep belief network, and their performance compared to that of two conventional methods and two ensemble methods for credit scoring. The models are then evaluated using a range of credit scoring data sets and performance measures. Furthermore, Bayesian statistical testing procedures are introduced in the context of credit scoring and compared to frequentist non-parametric testing procedures which have traditionally been considered best practice in credit scoring. This comparison will highlight the benefits of Bayesian statistical procedures and secure empirical findings. Two main conclusions emerge from comparing the different classification algorithms for credit scoring. Firstly, the ensemble method, XGBoost, is the best performing method for credit scoring of all the methods considered here. Secondly, deep neural networks do not outperform their shallower counterparts and are considerably more computationally expensive to construct. Therefore, deep learning algorithms do not seem to be appropriate models for credit scoring based on this comparison and XGBoost should be preferred over the other credit scoring methods considered here when classification performance is the main objective of credit scoring activities.},
  archive      = {J_EJOR},
  author       = {Björn Rafn Gunnarsson and Seppe vanden Broucke and Bart Baesens and María Óskarsdóttir and Wilfried Lemahieu},
  doi          = {10.1016/j.ejor.2021.03.006},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {292-305},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Deep learning for credit scoring: Do or don’t?},
  volume       = {295},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Standardized cargo network revenue management with dual
channels under stochastic and time-dependent demand. <em>EJOR</em>,
<em>295</em>(1), 275–291. (<a
href="https://doi.org/10.1016/j.ejor.2021.02.046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the network resource allocation problem, faced by sea freight operators, for standardized cargo transportation networks with time-dependent and stochastic demand. Standardized cargo capacity is sold through allotment contracts and on the spot market. The objective is to decide on the allotment contracts to select at the beginning of the booking horizon, as well as investigate dynamic booking control policies based on which spot market requests are accepted (booked) over the booking horizon before departure. This problem is formulated and solved in two stages: In the first stage, the allotment selection problem is formulated as an integer program in which the objective is to maximize the expected profit generated from the realized utilization of each resource in the network. The optimal solution to the allotment selection problem becomes the input to the spot booking control problem in the second stage. We formulate the spot booking problem as a dynamic program, and provide an efficient heuristic as an alternative to the computationally prohibitive dynamic programming (DP) approach. The DP is solved optimally for a small-size problem and for a variety of numerical cases. For large size problems, heuristics are proposed and tested via simulation. Also extensive sensitivity analysis is performed to test the heuristics, gain managerial insights and provide practical recommendations. We recommend a well-performing heuristic that outperforms the trivial first-come first-serve policy for large-sized problems. This leading heuristic is within 2.75\%, on average, of the optimal DP solution for small problems and 3.9\% for large problems.},
  archive      = {J_EJOR},
  author       = {Lama Moussawi-Haidar and Walid Nasr and Maya Jalloul},
  doi          = {10.1016/j.ejor.2021.02.046},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {275-291},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Standardized cargo network revenue management with dual channels under stochastic and time-dependent demand},
  volume       = {295},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Negotiation mechanisms for the multi-agent multi-mode
resource investment problem. <em>EJOR</em>, <em>295</em>(1), 261–274.
(<a href="https://doi.org/10.1016/j.ejor.2021.02.023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Carrying out complex projects often involves several collaborating parties (agents) with conflicting goals. We consider project scheduling problems, where each activity belongs to one of several agents, with a given deadline on the project completion while one aims at a schedule with an efficient use of resources. As there are precedence relations among activities and the activity execution requires varying amounts of resources, the need for coordination among the agents arises. For the execution of activities, an agent can choose from several modes that determine the processing time and resource usage. Each agent aims to minimise his/her individual resource costs associated with the project. Hence, the problem at hand is the multi-agent generalisation of the multi-mode resource investment problem. Here, we consider local as well as global resources. The latter ones are shared among the agents, thus the problem involves the need for a suitable allocation of respective resource costs. As agents are unwilling to share critical and sensitive information (or are not expected to always provide truthful information), the employed solution procedure should not rely on such information under consideration of the agents’ incentives. We propose and extend such decentralised negotiation mechanisms which facilitate the allocation of global resources. We analyse their potential to overcome information asymmetry and yield high quality solutions utilising a distributed scheduling procedure and a representation which aids in learning effective mode decisions.},
  archive      = {J_EJOR},
  author       = {Andreas Fink and Patrick Gerhards},
  doi          = {10.1016/j.ejor.2021.02.023},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {261-274},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Negotiation mechanisms for the multi-agent multi-mode resource investment problem},
  volume       = {295},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Appointment scheduling and real-time sequencing strategies
for patient unpunctuality. <em>EJOR</em>, <em>295</em>(1), 246–260. (<a
href="https://doi.org/10.1016/j.ejor.2021.02.055">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Patient unpunctuality causes perturbations in healthcare operations, compromising productivity and service quality. In this paper, we propose an approach that mitigates the negative impacts of unpunctuality using both appointment scheduling and real-time sequencing taking into account patient unpunctuality, no-shows, random service durations, and multiple providers. The objective is to minimize the total cost incurred by patient waiting and provider overtime. An optimal real-time sequencing strategy is established to serve the waiting patient with the smallest “LAR” index, which is defined as the Larger of Appointment time and Real arrival time for a patient. The optimal appointment schedule is determined by a simulation optimization approach with unbiased gradient estimators. Sample path discontinuities are smoothed by smoothed perturbation analysis. Properties of the optimal real-time sequencing strategies are used for the efficient sample path gradient estimation. Extensive experiments demonstrate the effectiveness of the proposed algorithm. Using real data, numerical experiments illustrate that the optimal appointment schedule depends on the system parameters and differs significantly from those of the existing literature. Specifically, the pattern of the appointment schedule is determined by the number of providers and the real-time sequencing strategy. The length of the appointment intervals is sensitive to the degree of unpunctuality and no-shows. Compared with the schedules in the previous studies, our schedule can achieve a significant cost reduction. Further, the optimal real-time sequencing strategy outperforms the commonly-used strategies in practice (e.g., appointment order, arrival order). Managerial insights are also provided for hospital managers to schedule unpunctual patients.},
  archive      = {J_EJOR},
  author       = {Xingwei Pan and Na Geng and Xiaolan Xie},
  doi          = {10.1016/j.ejor.2021.02.055},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {246-260},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Appointment scheduling and real-time sequencing strategies for patient unpunctuality},
  volume       = {295},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-criteria mission abort policy for systems subject to
two-stage degradation process. <em>EJOR</em>, <em>295</em>(1), 233–245.
(<a href="https://doi.org/10.1016/j.ejor.2021.02.043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Failures of mission-critical systems may result in irretrievable economic losses and significant damages. Mission abort is an effective way to reduce the risk of casualties and enhance the system survivability. A core concern in real operation is how to balance the mission reliability and the system survivability via elaborate mission abort plans. This paper investigates the condition based mission abort policies for systems subject to two-stage degradation process with normal and defective stages. Dynamic mission abort decisions are considered based on the degradation level together with the duration in the defective stage. The degradation control limit and time threshold are both dependent on the duration in the normal stage. Mission reliability and system survivability are derived and the structural properties of the optimal abort thresholds minimizing the expected costs of mission failure and system failure are investigated. In addition, we also compare the optimal policy against several heuristic policies where mission reliability and system survivability are evaluated. Numerical studies are presented to validate the obtained results.},
  archive      = {J_EJOR},
  author       = {Xian Zhao and Yu Fan and Qingan Qiu and Ke Chen},
  doi          = {10.1016/j.ejor.2021.02.043},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {233-245},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Multi-criteria mission abort policy for systems subject to two-stage degradation process},
  volume       = {295},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Constant depth decision rules for multistage optimization
under uncertainty. <em>EJOR</em>, <em>295</em>(1), 223–232. (<a
href="https://doi.org/10.1016/j.ejor.2021.02.042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we introduce a new class of decision rules, referred to as Constant Depth Decision Rules (CDDRs), for multistage optimization under linear constraints with uncertainty-affected right-hand sides. We consider two uncertainty classes: discrete uncertainties which can take at each stage at most a fixed number d d of different values, and polytopic uncertainties which, at each stage, are elements of a convex hull of at most d d points. Given the depth μ μ of the decision rule, the decision at stage t t is expressed as the sum of t t functions of μ μ consecutive values of the underlying uncertain parameters. These functions are arbitrary in the case of discrete uncertainties and are poly-affine in the case of polytopic uncertainties. For these uncertainty classes, we show that when the uncertain right-hand sides of the constraints of the multistage problem are of the same additive structure as the decision rules, these constraints can be reformulated as a system of linear inequality constraints where the numbers of variables and constraints is O ( 1 ) ( n + m ) d μ N 2 O(1)(n+m)dμN2 with n n the maximal dimension of control variables, m m the maximal number of inequality constraints at each stage, and N N the number of stages. As an illustration, we discuss an application of the proposed approach to a Multistage Stochastic Program arising in the problem of hydro-thermal production planning with interstage dependent inflows. For problems with a small number of stages, we present the results of a numerical study in which optimal CDDRs show similar performance, in terms of optimization objective, to that of Stochastic Dual Dynamic Programming (SDDP) policies, often at much smaller computational cost.},
  archive      = {J_EJOR},
  author       = {Vincent Guigues and Anatoli Juditsky and Arkadi Nemirovski},
  doi          = {10.1016/j.ejor.2021.02.042},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {223-232},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Constant depth decision rules for multistage optimization under uncertainty},
  volume       = {295},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Stochastic joint homecare service and capacity planning with
nested decomposition approaches. <em>EJOR</em>, <em>295</em>(1),
203–222. (<a href="https://doi.org/10.1016/j.ejor.2021.02.021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study a joint service authorization and capacity planning problem for the home health care (HHC) system with demand uncertainty. We formulate the problem as a two-stage stochastic programming with recourse which maximizes the expected total revenue. The service authorization and capacity planning are the mixed binary-and-continuous first stage decisions, and the service hour (resource) allocation is modeled as the second-stage decision which adapts to the demand realizations. The resulting sample average approximation problem (of the stochastic program) could be a large scaled mixed integer linear program. To solve the model in a more scalable fashion, we propose a supergradient-based nested decomposition algorithm that exploits the nice decomposable structure of the problem to cope with the binary and continuous variables separately. The proposed nested decomposition scheme consists of two-layer of decomposition, where the outer decomposition solves for the authorization decision (binaries) with the supergradient cuts and each supergradient can be computed iteratively in the inner decomposition scheme. The proposed nested decomposition algorithm is feasibility-cut-free and is guaranteed to reach the exact optimality in finite steps. Furthermore, we extend our stochastic HHC planning model to a more general framework of Conditional Value-at-Risk (CV@R), and by model transformation with variable change we show that the CV@R model can actually be reformulated in a structure that the proposed nested decomposition scheme can be applied almost directly. Finally, a comprehensive computational study is performed which demonstrates the effectiveness of our model and the performance of the algorithm.},
  archive      = {J_EJOR},
  author       = {Chenyang Zheng and Shuming Wang and Ningxin Li and Yuanhao Wu},
  doi          = {10.1016/j.ejor.2021.02.021},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {203-222},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Stochastic joint homecare service and capacity planning with nested decomposition approaches},
  volume       = {295},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Timetable coordination in a rail transit network with
time-dependent passenger demand. <em>EJOR</em>, <em>295</em>(1),
183–202. (<a href="https://doi.org/10.1016/j.ejor.2021.02.059">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the expansion of urban rail networks and the increase of passengers demand, the coordination of strongly connected lines becomes more and more important, because passengers transfer several times during their trips and major transfer stations in the rail network often suffer from over-crowdedness, especially during peak-hours. In this paper, we study the optimization of coordinated train timetables for an urban rail network, which is a tactical timetabling problem and includes several operational constraints and time-dependent passenger-related data. We propose a mathematical formulation with the objective of minimizing the crowdedness of stations during peak hours to synchronously generate the optimal coordinated train timetables. By introducing several sets of passenger flow variables, the timetable coordination problem is formulated as a mixed-integer linear programming problem, that is possible to solve to optimum. To capture the train carrying capacity constraints, we explicitly incorporate the number of in-vehicle passengers in the modelling framework by considering the number of boarding and alighting passengers as passenger flow variables. To improve the computational efficiency of large-scale instances, we develop an Adaptive Large Neighborhood Search (ALNS) algorithm with a set of destroying and repairing operators and a decomposition-based ALNS algorithm. Real-world case studies based on the operational data of Beijing urban rail network are conducted to verify the effectiveness of timetable coordination. The computational results illustrate that the proposed approaches reduce the level of crowdedness of metro stations by around 8\% in comparison with the current practical timetable of the investigated Beijing urban rail network.},
  archive      = {J_EJOR},
  author       = {Jiateng Yin and Andrea D’Ariano and Yihui Wang and Lixing Yang and Tao Tang},
  doi          = {10.1016/j.ejor.2021.02.059},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {183-202},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Timetable coordination in a rail transit network with time-dependent passenger demand},
  volume       = {295},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The impacts of money-back guarantees in the presence of
parallel importation. <em>EJOR</em>, <em>295</em>(1), 170–182. (<a
href="https://doi.org/10.1016/j.ejor.2021.02.057">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the impacts of money-back guarantees (MBGs) in the presence of parallel importation, where a manufacturer sells a product facing customer fit uncertainties in two markets and a parallel importer diverts unauthorized products from the low-price market to the high-price one. The two firms compete in both pricing and MBG strategies. We consider two types of parallel importers, a third-party agent and an authorized retailer in the low-price market, respectively. By applying the certainty equivalent pricing approach, we show that offering MBGs only changes firms’ marginal costs without affecting customers’ purchasing decisions directly. When the net salvage values of returned products are positive in the high-price market, both the manufacturer and the third-party agent offer MBGs. Whenever the manufacturer offers an MBG in the low-price market, there is a price inflation effect that counters parallel importation. Therefore the manufacturer may offer the MBG even if the net salvage value is negative. When the authorized retailer decides refund policies in two markets, the MBG strategy in one market changes the retailer’s profit from the authorized channel and that from the gray market in opposite directions, and has an interaction with the refund policy in another market. No refund may be preferred in either market even if the net salvage value is positive. We find that the manufacturer’s MBG strategy in the high-price market always deters parallel importation while other MBG strategies may achieve Pareto improvements in the equilibrium.},
  archive      = {J_EJOR},
  author       = {Yong Zhang and Sheng Hao Zhang and Haofang Feng},
  doi          = {10.1016/j.ejor.2021.02.057},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {170-182},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {The impacts of money-back guarantees in the presence of parallel importation},
  volume       = {295},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Directed particle swarm optimization with
gaussian-process-based function forecasting. <em>EJOR</em>,
<em>295</em>(1), 157–169. (<a
href="https://doi.org/10.1016/j.ejor.2021.02.053">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Particle swarm optimization (PSO) is an iterative search method that moves a set of candidate solution around a search-space towards the best known global and local solutions with randomized step lengths. PSO frequently accelerates optimization in practical applications, where gradients are not available and function evaluations expensive. Yet the traditional PSO algorithm ignores the potential knowledge that could have been gained of the objective function from the observations by individual particles. Hence, we draw upon concepts from Bayesian optimization and introduce a stochastic surrogate model of the objective function. That is, we fit a Gaussian process to past evaluations of the objective function, forecast its shape and then adapt the particle movements based on it. Our computational experiments demonstrate that baseline implementations of PSO (i. e., SPSO2011) are outperformed. Furthermore, compared to, state-of-art surrogate-assisted evolutionary algorithms, we achieve substantial performance improvements on several popular benchmark functions. Overall, we find that our algorithm attains desirable properties for exploratory and exploitative behavior.},
  archive      = {J_EJOR},
  author       = {Johannes Jakubik and Adrian Binding and Stefan Feuerriegel},
  doi          = {10.1016/j.ejor.2021.02.053},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {157-169},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Directed particle swarm optimization with gaussian-process-based function forecasting},
  volume       = {295},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Coordinating a closed loop supply chain with fairness
concern by a constant wholesale price contract. <em>EJOR</em>,
<em>295</em>(1), 140–156. (<a
href="https://doi.org/10.1016/j.ejor.2021.02.052">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The literature on closed loop supply chains (CLSCs) has ignored advantageous inequality aversion while modelling the fairness concern of channel partners and demonstrated that coordinating a decentralised channel requires complex price contracts. In this paper, we show that a constant wholesale price contract can coordinate a decentralised channel in a manufacturer-led CLSC if the retailer&#39;s advantageous inequality aversion is sufficiently strong. The result is valid for a range of equitable shares of the channel profit, such that the allocated share of the manufacturer is larger than that of the retailer, and the retailer&#39;s share is greater than a minimum threshold. Used product collection rate and channel profit are higher when the retailer is inequality averse compared to when she is a profit maximiser. The results are independent of whether the end-of-use products are collected by the manufacturer or the retailer. We also show that the collection rate is higher, and both channel partners are better-off, under the manufacturer collection model. To obtain these results, we solve multistage sequential move games under the two collection models. We apply Karush–Kuhn–Tucker conditions for constrained optimisation, to determine the boundaries for the existence of the subgame perfect Nash equilibrium.},
  archive      = {J_EJOR},
  author       = {Sumit Sarkar and Shrey Bhala},
  doi          = {10.1016/j.ejor.2021.02.052},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {140-156},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Coordinating a closed loop supply chain with fairness concern by a constant wholesale price contract},
  volume       = {295},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Implications of green optimism upon sustainable supply chain
management. <em>EJOR</em>, <em>295</em>(1), 131–139. (<a
href="https://doi.org/10.1016/j.ejor.2021.02.036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, managers have increasingly integrated sustainability into their business models. However, they might overestimate the premium that average consumers are willing to pay for the environment. In this paper, we formulate a game-theoretical model that illustrates the impacts of green optimism which refers to managers’ optimistic bias about consumer environmental awareness. We consider a sustainable supply chain in which one manufacturer invests in green product development and sells the green product through one retailer. Each firm within the supply chain is operated by one manager who is either realistic or optimistic. Contrary to conventional wisdom, we find that managers’ optimistic bias might discourage investment in green product development. We also find that green optimism is always detrimental to the upstream manufacturer, but might be beneficial to the downstream retailer. Surprisingly, under certain conditions, green optimism can be detrimental to all stakeholders, i.e., firms in the supply chain, consumers, and the environment. This study suggests an interesting link between supply chain management and human resource management; that is, within a sustainable supply chain those managers who are optimistic about the future of green business might be an obstacle to the success of green business.},
  archive      = {J_EJOR},
  author       = {Minyue Jin and Xueqing Zhang and Yu Xiong and Yu Zhou},
  doi          = {10.1016/j.ejor.2021.02.036},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {131-139},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Implications of green optimism upon sustainable supply chain management},
  volume       = {295},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The spatial dimension of competition among airports at the
worldwide level: A spatial stochastic frontier analysis. <em>EJOR</em>,
<em>295</em>(1), 118–130. (<a
href="https://doi.org/10.1016/j.ejor.2021.02.035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper analyses the potential impact of airport competition on technical efficiency by applying the spatial stochastic frontier approach (SSFA) rather than the traditional model (SFA). The SSFA allows for isolating the cross-sectional spatial dependence and evaluating the role of intangible factors in influencing an airport&#39;s economic performance through the inclusion of the distance matrix and the shared destinations matrix calibrated for different distances. By analysing the statistical differences between the traditional and the spatial model, it is possible to identify the competition effects. This study includes 206 airports at the worldwide level. The results show the existence of the spatial component: we detected a different influence of airports’ efficiency levels according to the geographical distances. This could have not been captured by the traditional SFA. We conclude that when incorporating spatial spillover effects into the airport efficiency analysis, the efficiency dynamics are strongly dependent on the spatial distance among airports.},
  archive      = {J_EJOR},
  author       = {Angela Stefania Bergantino and Mario Intini and Nicola Volta},
  doi          = {10.1016/j.ejor.2021.02.035},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {118-130},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {The spatial dimension of competition among airports at the worldwide level: A spatial stochastic frontier analysis},
  volume       = {295},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Terminal inventory level constraints for online production
scheduling. <em>EJOR</em>, <em>295</em>(1), 102–117. (<a
href="https://doi.org/10.1016/j.ejor.2021.02.029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study online production scheduling, that is, the iterative solution of scheduling optimization problems taking into account feedback, to ensure high quality of implemented, as opposed to predicted, production schedules. While the addition of terminal constraints on inventory levels can be used to obtain high quality implemented schedules, traditional approaches based on safety stocks may be ineffective. Accordingly, we first propose a framework for the analysis of general classes of terminal constraints, and then propose new classes of linear terminal constraints for specific production environments. We provide proofs on the validity of these constraints as well as extensions to more general environments. Finally, through a computational study, we show that the implementation of the proposed constraints leads to better implemented solutions.},
  archive      = {J_EJOR},
  author       = {Yachao Dong and Christos T. Maravelias},
  doi          = {10.1016/j.ejor.2021.02.029},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {102-117},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Terminal inventory level constraints for online production scheduling},
  volume       = {295},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Efficient primal heuristic updates for the blocking job shop
problem. <em>EJOR</em>, <em>295</em>(1), 82–101. (<a
href="https://doi.org/10.1016/j.ejor.2021.02.051">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The blocking job shop problem is a variant of the classical job shop problem, where a job continues to block a machine after being serviced, until the downstream machine needed by the job becomes available. Many real world problems have been modeled as blocking job shop problems, and local search heuristics have been shown to produce good quality solutions. Existing literature shows that the computational complexity of these local search algorithms is very high, severely limiting their practical performance. In this work, we present new theoretical results for blocking job shop and show how these results can be used to significantly improve the computational efficiency of existing local search procedures. We empirically evaluate the proposed algorithm updates on existing benchmarks. The results demonstrate that our approach outperforms the current state-of-the-art, by consistently matching or improving previous best known results, usually within a fraction of the time reported for blocking job shop benchmarks. Due to the efficiency in neighborhood computations, our approach scales up to larger size problems than have been considered in prior studies. In particular, for the first time for blocking job shop, we show results for the 100 x 20 instances in Taillard’s benchmark.},
  archive      = {J_EJOR},
  author       = {Jayanth Krishna Mogali and Laura Barbulescu and Stephen F. Smith},
  doi          = {10.1016/j.ejor.2021.02.051},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {82-101},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Efficient primal heuristic updates for the blocking job shop problem},
  volume       = {295},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A matheuristic approach for the b-coloring problem using
integer programming and a multi-start multi-greedy randomized
metaheuristic. <em>EJOR</em>, <em>295</em>(1), 66–81. (<a
href="https://doi.org/10.1016/j.ejor.2021.02.049">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given a graph G = ( V , E ) , G=(V,E), the b b -coloring problem consists in attributing a color to every vertex in V V such that adjacent vertices receive different colors, every color has a b b -vertex, and the number of colors is maximized. A b b -vertex is a vertex adjacent to vertices colored with all used colors but its own. The b b -coloring problem is known to be NP-Hard and its optimal solution determines the b b -chromatic number of G , G, denoted X b ( G ) Xb(G) . This paper presents an integer programming formulation and a very effective multi-greedy randomized heuristic which can be used in a multi-start metaheuristic. In addition, a matheuristic approach is proposed combining the multi-start multi-greedy randomized metaheuristic with a MIP (mixed integer programming) based local search procedure using the integer programming formulation. Computational experiments establish the proposed multi-start metaheuristic as very effective in generating high quality solutions, along with the matheuristic approach successfully improving several of those results. Moreover, the computational results show that the multi-start metaheuristic outperforms a state-of-the-art hybrid evolutionary metaheuristic for a subset of the large instances which were previously considered in the literature. An additional contribution of this work is the proposal of a benchmark instance set, which consists of newly generated instances as well as others available in the literature for classical graph problems, with the aim of standardizing computational comparisons of approaches for the b b -coloring problem in future works.},
  archive      = {J_EJOR},
  author       = {Rafael A. Melo and Michell F. Queiroz and Marcio C. Santos},
  doi          = {10.1016/j.ejor.2021.02.049},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {66-81},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A matheuristic approach for the b-coloring problem using integer programming and a multi-start multi-greedy randomized metaheuristic},
  volume       = {295},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Weighted online minimum latency problem with edge
uncertainty. <em>EJOR</em>, <em>295</em>(1), 51–65. (<a
href="https://doi.org/10.1016/j.ejor.2021.02.038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the minimum latency problem, an undirected connected graph and a root node together with non-negative edge distances are given to an agent. The agent looks for a tour starting at the root node and visiting all the nodes to minimise the sum of the latencies of the nodes, where the latency of a node is the distance from the root node to the node at its first visit on the tour by the agent. We study an online variant of the problem, where there are k k blocked edges in the graph which are not known to the agent in advance. A blocked edge is learned online when the agent arrives at one of its end-nodes. Furthermore, we investigate another online variant of the minimum latency problem involving k k blocked edges where each node is associated with a weight to express its priority and the objective is to minimise the summation of the weighted latency of the nodes. In this paper, we prove that the lower bound of 2 k + 1 2k+1 on the competitive ratio of deterministic online algorithms is tight for both weighted and non-weighted variations by introducing an optimal deterministic online algorithm which meets this lower bound. We also present a lower bound of k + 1 k+1 on the expected competitive ratio of randomized online algorithms for both problems. We then develop two polynomial time heuristic algorithms to solve these online problems. We test our algorithms on real life as well as randomly generated instances that are partially adopted from the literature.},
  archive      = {J_EJOR},
  author       = {Vahid Akbari and Davood Shiri},
  doi          = {10.1016/j.ejor.2021.02.038},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {51-65},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Weighted online minimum latency problem with edge uncertainty},
  volume       = {295},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Robust strategic planning for mobile medical units with
steerable and unsteerable demands. <em>EJOR</em>, <em>295</em>(1),
34–50. (<a href="https://doi.org/10.1016/j.ejor.2021.02.037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile medical units (MMUs) are customized vehicles fitted with medical equipment that are used to provide primary care in rural environments. As MMUs can be easily relocated, they enable a demand-oriented, flexible, and local provision of health services. In this paper, we investigate the strategic planning of an MMU service by deciding where MMU operation sites should be set up and how often these should be serviced. To that end, we study the strategic planning problem for MMUs ( SPMMU SPMMU ) – a capacitated set covering problem that includes existing practices and two types of patient demands: (i) steerable demands representing patients who seek health services through a centralized appointment system and can be steered to any treatment facility within a given consideration set and (ii) unsteerable demands representing walk-in patients who always visit the closest available treatment facility. We propose an integer linear program for the SPMMU SPMMU that can be solved via Benders decomposition and constraint generation. Starting from this formulation, we focus on the uncertain version of the problem in which steerable and unsteerable demands are modeled as random variables that may vary within a given interval. Using methods from robust optimization and duality theory, we devise exact constraint generation methods to solve the robust counterparts for interval and budgeted uncertainty sets. All our results transfer to the session-specific SPMMU SPMMU and we evaluate our models in a computational study based on a set of instances generated from a rural primary care system in Germany.},
  archive      = {J_EJOR},
  author       = {Christina Büsing and Martin Comis and Eva Schmidt and Manuel Streicher},
  doi          = {10.1016/j.ejor.2021.02.037},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {34-50},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Robust strategic planning for mobile medical units with steerable and unsteerable demands},
  volume       = {295},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Dominance-based linear formulation for the anchor-robust
project scheduling problem. <em>EJOR</em>, <em>295</em>(1), 22–33. (<a
href="https://doi.org/10.1016/j.ejor.2021.02.034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In project scheduling under processing times uncertainty, the Anchor-Robust Project Scheduling Problem is to find a baseline schedule of bounded makespan and a max-weight subset of jobs whose starting times are guaranteed. The problem was proven NP-hard even for budgeted uncertainty. In the present work we design mixed-integer programming (MIP) formulations that are valid for a variety of uncertainty sets encompassing budgeted uncertainty. A new dominance among solutions is proposed, resulting into an MIP formulation. We further study the combinatorial structure of the problem. Non-trivial polynomial cases under budgeted uncertainty are exhibited, where the dominance-based formulation yields a polyhedral characterization of integer solutions. In more general cases, the dominance-based formulation is shown to be tighter than all previously known formulations. In numerical experiments we investigate how the formulation performs on instances around the polynomial cases, for both budgeted uncertainty sets and more elaborate uncertainty sets involving several budgets.},
  archive      = {J_EJOR},
  author       = {Pascale Bendotti and Philippe Chrétienne and Pierre Fouilhoux and Adèle Pass-Lanneau},
  doi          = {10.1016/j.ejor.2021.02.034},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {22-33},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Dominance-based linear formulation for the anchor-robust project scheduling problem},
  volume       = {295},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Open shop scheduling games. <em>EJOR</em>, <em>295</em>(1),
12–21. (<a href="https://doi.org/10.1016/j.ejor.2021.02.030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper takes a game theoretical approach to open shop scheduling problems to minimize the sum of completion times. We assume that there is an initial schedule to process the jobs (consisting of a number of operations) on the machines and that each job is owned by a different player. Thus, we can associate a cooperative TU-game to any open shop scheduling problem, assigning to each coalition the maximal cost savings it can obtain through admissible rearrangements of jobs’ operations. A number of different approaches to admissible schedules for a coalition are introduced and, in the main result of the paper, a core allocation rule is provided for games arising from unit (execution times and weights) open shop scheduling problems for the most of these approaches. To sharpen the bounds of the set of open shop scheduling problems that result in games that are balanced, we provide two counterexamples: one for general open shop problems and another for further relaxations of the definition of admissible rearrangements for a coalition.},
  archive      = {J_EJOR},
  author       = {Ata Atay and Pedro Calleja and Sergio Soteras},
  doi          = {10.1016/j.ejor.2021.02.030},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {12-21},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Open shop scheduling games},
  volume       = {295},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Inefficiency in stochastic queueing systems with strategic
customers. <em>EJOR</em>, <em>295</em>(1), 1–11. (<a
href="https://doi.org/10.1016/j.ejor.2021.03.065">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper summarizes the literature on efficiency loss when agents selfishly optimize their utility in stochastic queueing systems. The price of anarchy is the most popular measure for quantifying this loss, but we also discuss other measures. The queueing models are introduced briefly and results on the loss of efficiency are discussed.},
  archive      = {J_EJOR},
  author       = {Souvik Ghosh and Refael Hassin},
  doi          = {10.1016/j.ejor.2021.03.065},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {1-11},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Inefficiency in stochastic queueing systems with strategic customers},
  volume       = {295},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Performance benchmarking of achievements in the olympics: An
application of data envelopment analysis with restricted multipliers.
<em>EJOR</em>, <em>294</em>(3), 1202–1212. (<a
href="https://doi.org/10.1016/j.ejor.2021.02.040">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data envelopment analysis (DEA) is a useful tool for measuring the relative efficiencies of participating nations in the Olympic Games. DEA models with restricted multipliers have been used to refine efficiency evaluations by imposing additional information. Existing DEA models for evaluating Olympic medals do not focus on multiplier restrictions regarding input. To fill this research gap, this study incorporates a data fitting technique of medal prediction using ordinary least squares regression in input multiplier restrictions of the conventional DEA model. We show that the efficiency of the proposed model can be decomposed into the achievement ratio of substantial medal total and the unit value index of medals. Such decompositions can be used to analyze the effectiveness of host nations and athlete development initiatives. For an illustrative empirical application, we examine the target that the Brazilian Olympic Committee (BOC) set for the 2016 Summer Olympic Games (Rio 2016). Our results explain the extremely high feasibility of Brazil’s target of being in the top 10 medals table in Rio 2016.},
  archive      = {J_EJOR},
  author       = {Kazuyuki Sekitani and Yu Zhao},
  doi          = {10.1016/j.ejor.2021.02.040},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1202-1212},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Performance benchmarking of achievements in the olympics: An application of data envelopment analysis with restricted multipliers},
  volume       = {294},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Improved delivery policies for future drone-based delivery
systems. <em>EJOR</em>, <em>294</em>(3), 1181–1201. (<a
href="https://doi.org/10.1016/j.ejor.2021.02.039">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is expected that commercial use of drones in the near future will involve delivery service operations by e-commerce companies. We consider relevant strategic and tactical decisions that these retailers will face in drone-based delivery operations, and derive policies on when to offer drone delivery, what delivery capacity to maintain, and what amount to charge for such deliveries. To this end, we develop a Markov decision process (MDP) framework, and introduce two heuristic procedures, through which near-optimal closed-form solutions can be obtained. The results are aimed at helping online retailers to determine in real time whether and to what extent to offer drone-based delivery for given product categories in different service zones. In addition, we study delivery fee structures and identify drone-based delivery pricing strategies under two widely used delivery pricing schemes. For capacity planning decisions, we describe an algorithm to identify the fleet size to utilize to fulfill uncertain demand in a given service region. We also identify structural characteristics on how these decisions and the expected profit are affected by changes in various problem parameters, which can generate generic insights on drone-based delivery operations for e-commerce companies. We find that retailers should prioritize more profitable items when allocating drone delivery capacity, and invest in adding more drones when per order opportunity costs are higher and promised delivery time thresholds are shorter. Retailers can potentially boost their net profits by increasing the effective promised delivery time threshold and/or decreasing the effective delivery delay costs and per order opportunity costs.},
  archive      = {J_EJOR},
  author       = {Heng Chen and Zhangchen Hu and Senay Solak},
  doi          = {10.1016/j.ejor.2021.02.039},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1181-1201},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Improved delivery policies for future drone-based delivery systems},
  volume       = {294},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An adaptive large neighborhood search heuristic for the
vehicle routing problem with time windows and delivery robots.
<em>EJOR</em>, <em>294</em>(3), 1164–1180. (<a
href="https://doi.org/10.1016/j.ejor.2021.02.027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Considering autonomous delivery robots in urban logistics has attracted a great deal of attention in recent years. In the meantime, new technology has led to new operational challenges, such as the routing and scheduling of vehicles and delivery robots together that are currently outside the logistics service providers’ capability. In this paper, a vehicle routing problem with time windows and delivery robots (VRPTWDR) as a variant of the classical VRP is studied. The investigated problem is concerned with the routing of a set of delivery vans equipped with a number of self-driving parcel delivery robots. To tackle the VRPTWDR, an Adaptive Large Neighborhood Search heuristic algorithm is developed. Experiments show the performance and effectiveness of the algorithm for solving the VRPTWDR, and provide insights on the use of self-driving parcel delivery robots as an alternative last mile service.},
  archive      = {J_EJOR},
  author       = {Cheng Chen and Emrah Demir and Yuan Huang},
  doi          = {10.1016/j.ejor.2021.02.027},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1164-1180},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {An adaptive large neighborhood search heuristic for the vehicle routing problem with time windows and delivery robots},
  volume       = {294},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Inbound and outbound flow integration for cross-docking
operations. <em>EJOR</em>, <em>294</em>(3), 1153–1163. (<a
href="https://doi.org/10.1016/j.ejor.2021.02.031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the optimization of the cross-docking operations at three INtermodal LOgistics Platforms (INLOPs) of a large European car manufacturer (ECM). The planning horizon is a week and the time bucket is a day. An inbound flow of products is gradually received over the week by truck from inland suppliers, and has to be loaded into containers which are then shipped to offshore production plants. The full content of a container must be available at the INLOP to enable its loading operations to start, hence temporary storage is needed. The objective is to minimize an inventory penalty, computed as the largest daily volume of temporary product storage observed over the planning horizon. The current practice at ECM is to first optimize the content of the inbound trucks and of the outbound containers independently, and then determine the loading day of each container to be shipped based on these fixed contents. We propose to integrate, within the same optimization framework, the decisions on both truck and container contents, which involve complex loading constraints related to the dimensions and weights of the products, with those on the scheduling of container loading. We model the resulting problem as a mixed integer linear program, and we develop a decomposition scheme for it, as well as a fix-and-optimize matheuristic. We perform extensive computational experiments on real instances provided by ECM. Results show that a combination of these two matheuristics is able to generate solutions that reduce the average inventory penalty by 40\%.},
  archive      = {J_EJOR},
  author       = {Marc-Antoine Coindreau and Olivier Gallay and Nicolas Zufferey and Gilbert Laporte},
  doi          = {10.1016/j.ejor.2021.02.031},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1153-1163},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Inbound and outbound flow integration for cross-docking operations},
  volume       = {294},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). On the value of information sharing in the presence of
information errors. <em>EJOR</em>, <em>294</em>(3), 1139–1152. (<a
href="https://doi.org/10.1016/j.ejor.2021.02.028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Errors may occur in the information received by a manufacturer from the retailer. There are two types of information errors: transmission error that occurs in the transmission of information from the retailer to the manufacturer, and source error that occurs in the data observed by the retailer. This paper studies the value of information sharing in the presence of either or both types of information errors. In particular, when information is shared, the manufacturer may use both the shared demand information and the retailer&#39;s order quantity to make decisions, or it may rely solely on the shared demand information and disregard the retailer&#39;s order quantity when forecasting demand for the future. We analyze the values of information sharing for both settings, and characterize the lowest forecast error information sharing strategy for the manufacturer. Our results suggest that transmission error and source error have significantly different impacts on the value of information sharing and the manufacturer&#39;s optimal strategy.},
  archive      = {J_EJOR},
  author       = {Lu Jizhou and Feng Gengzhong and Stephen Shum and Lai Kin Keung},
  doi          = {10.1016/j.ejor.2021.02.028},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1139-1152},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {On the value of information sharing in the presence of information errors},
  volume       = {294},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Capacitated strategic assortment planning under explicit
demand substitution. <em>EJOR</em>, <em>294</em>(3), 1120–1138. (<a
href="https://doi.org/10.1016/j.ejor.2021.02.026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Buyers have easier access to a variety of products with the rise of multi-channel distribution strategies and the increase in new product introductions. On the other hand, firms experience greater pressure in offering the correct product variety given that the manufacturing infrastructure often imposes physical and financial constraints in attaining variety. This study examines a firm’s optimal assortment planning problem under an exogenous demand model, where each customer has a predetermined preference for each product from a potential set. Proportional demand substitutions are allowed from out-of-assortment products to those available. We show that the problem is NP-complete. We also show that an optimal assortment is composed of some number of the highest margin products, if one product having a higher margin than another implies that the former product has a lower demand rate than the latter. The firm’s assortment capacity is fully utilized at the optimum if the customers’ substitution ratio does not exceed a particular threshold. We also introduce several approximate assortment policies that can be easily implemented, and test these policies through extensive numerical analyses. The results reveal that some of the policies can provide less than a 1\% profit gap with an optimal solution for a 20-product set. The policy’s performance highly depends on the firm’s assortment capacity-to-product set size ratio. Moreover, we provide performance bounds for two of these well-performing approximate policies.},
  archive      = {J_EJOR},
  author       = {Nagihan Çömez-Dolgan and Nilgun Fescioglu-Unver and Ecem Cephe and Alper Şen},
  doi          = {10.1016/j.ejor.2021.02.026},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1120-1138},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Capacitated strategic assortment planning under explicit demand substitution},
  volume       = {294},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A hybrid adaptive iterated local search with diversification
control to the capacitated vehicle routing problem. <em>EJOR</em>,
<em>294</em>(3), 1108–1119. (<a
href="https://doi.org/10.1016/j.ejor.2021.02.024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Metaheuristics are widely employed to solve hard optimization problems, like vehicle routing problems (VRP), for which exact solution methods are impractical. In particular, local search-based metaheuristics have been successfully applied to the capacitated VRP (CVRP). The CVRP aims at defining the minimum-cost delivery routes for a given set of identical vehicles since each vehicle only travels one route and there is a single (central) depot. The best metaheuristics to the CVRP avoid getting stuck in local optima by embedding specific hill-climbing mechanisms such as diversification strategies into the solution methods. This paper introduces a hybridization of a novel adaptive version of Iterated Local Search with Path-Relinking (AILS-PR) to the CVRP. The major contribution of this paper is an automatic mechanism to control the diversity step of the metaheuristic to allow it to escape from local optima. The results of experiments with 100 benchmark CVPR instances show that AILS-PR outperformed the state-of-the-art CVRP metaheuristics.},
  archive      = {J_EJOR},
  author       = {Vinícius R. Máximo and Mariá C.V. Nascimento},
  doi          = {10.1016/j.ejor.2021.02.024},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1108-1119},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A hybrid adaptive iterated local search with diversification control to the capacitated vehicle routing problem},
  volume       = {294},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Negotiation-sequence, pricing, and ordering decisions in a
three-echelon supply chain: A coopetitive-game analysis. <em>EJOR</em>,
<em>294</em>(3), 1096–1107. (<a
href="https://doi.org/10.1016/j.ejor.2021.02.020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We investigate a three-echelon supply chain in which a distributor at the middle echelon negotiates two wholesale price contracts with his upstream manufacturer and downstream retailer. In the first stage, the distributor decides on whether to first negotiate with the manufacturer or with the retailer; in the second (combined, noncooperative-cooperative, game) stage, the two negotiations are conducted sequentially. We find that the supply chain can be coordinated if the distributor first negotiates with the retailer. The distributor should choose the negotiation sequence for supply chain coordination, if he has a sufficiently large (small) relative bargaining power in the negotiation with the manufacturer (the retailer). We also extend our analysis to the cases in which the distributor and the manufacturer negotiate a buyback or two-part tariff contract, and draw similar outcomes when the distributor first negotiates with the retailer. In addition, under the two-part tariff contract, the distributor prefers to first negotiate with the retailer if the manufacturer has a sufficiently high disagreement payoff whereas, under the buyback contract, the distributor always prefers to first negotiate with the firm with a stronger bargaining power. Moreover, the two-part tariff (buyback) contract cannot (can) always coordinate the supply chain.},
  archive      = {J_EJOR},
  author       = {Feimin Zhong and Zhongbao Zhou and Mingming Leng},
  doi          = {10.1016/j.ejor.2021.02.020},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1096-1107},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Negotiation-sequence, pricing, and ordering decisions in a three-echelon supply chain: A coopetitive-game analysis},
  volume       = {294},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Ground-vehicle and unmanned-aerial-vehicle routing problems
from two-echelon scheme perspective: A review. <em>EJOR</em>,
<em>294</em>(3), 1078–1095. (<a
href="https://doi.org/10.1016/j.ejor.2021.02.022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {More and more studies have aimed to optimize the ground vehicle (GV) and unmanned aerial vehicle (UAV) system in which GVs function as mobile satellites and UAVs are dispatched from GVs for last-mile deliveries. From the two-echelon scheme perspective, GV routes originating at the depot are on one echelon, and UAV routes originating at satellites are on the other echelon. A change in a GV route may affect some UAV routes, which indicates the satellite synchronization. In the past decade, the optimization of vehicle routes in two-echelon networks has attracted increasing attention in the operations research community. We classify routing problems of two-echelon networks based on the modeling mechanism connecting the two echelons. Different formulations for describing connection mechanisms of the two-echelon scheme, especially constraints on capacitated satellites, satellite synchronization, vehicle coupling/decoupling at satellites, etc., are briefly introduced. There are several modeling challenges of optimizing delivery routes for a fleet of GV–UAV combinations that include new connection mechanisms between the two echelons. Some important variants, especially those involving mobile satellite synchronization, and GV–UAV flexibly coupling/decoupling, require new mathematical formulations and algorithms catering to more general and practical situations.},
  archive      = {J_EJOR},
  author       = {Hongqi Li and Jun Chen and Feilong Wang and Ming Bai},
  doi          = {10.1016/j.ejor.2021.02.022},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1078-1095},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Ground-vehicle and unmanned-aerial-vehicle routing problems from two-echelon scheme perspective: A review},
  volume       = {294},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Designing multi-tier, multi-service-level, and multi-modal
last-mile distribution networks for omni-channel operations.
<em>EJOR</em>, <em>294</em>(3), 1059–1077. (<a
href="https://doi.org/10.1016/j.ejor.2020.08.043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The fast and dynamic evolution of e-retailing is driving structural changes in the way companies are reaching the urban consumer. Companies are offering faster delivery services, deploying collection-and-delivery points and multi-echelon distribution networks with a range of facility types, diversifying last-mile transportation modes with new types of vehicles and contracting third-party and crowd-sourcing-based transportation. In this paper, we propose an integrated modeling framework for strategic last-mile design of three-tiered multi-modal networks in omni-channel environment, with customer demand differentiated according to multiple time-differentiated delivery services and multiple product-exchange alternatives. In order to apply this framework in a large-scale demand setting and capture the granularity of customer demand and distribution network features, we extend the route cost estimation formulae from the literature and incorporate them in a three-echelon capacitated location-routing problem that optimizes the configuration of distribution networks in an integrated way. Through a number of numerical experiments, we show the impact of the diversified customer demand and the novel distribution network features on the overall network performance and demonstrate the economic benefit of an integrated approach. A real-world case study, inspired by the ongoing operations of a major omni-channel retailer in São Paulo, Brazil, serves to illustrate the real-world impact of our work.},
  archive      = {J_EJOR},
  author       = {Milena Janjevic and Daniel Merchán and Matthias Winkenbach},
  doi          = {10.1016/j.ejor.2020.08.043},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1059-1077},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Designing multi-tier, multi-service-level, and multi-modal last-mile distribution networks for omni-channel operations},
  volume       = {294},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Distribution network deployment for omnichannel retailing.
<em>EJOR</em>, <em>294</em>(3), 1042–1058. (<a
href="https://doi.org/10.1016/j.ejor.2020.04.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article studies the distribution problem of brick-and-mortar retailers aiming to integrate the online channel into their operations. The article presents an integrated modeling approach addressing the online channel-driven distribution network deployment (e-DND) problem under uncertainty. The e-DND involves decisions on operating fulfillment platforms and on assigning a fulfillment mission to those platforms, while anticipating the revenues and costs induced by order fulfillment, replenishment, delivery, and inventory holding. To model this problem while taking into account the uncertain nature of multi-item online orders, store sales, and capacities, a two-stage stochastic program with mixed-integer recourse is developed. Two alternative deployment strategies, characterized by allocation of orders, inventory positioning, delivery schema, and inbound flow pattern decisions, are investigated using this model. The first deployment strategy investigates the ship-from stores practice where the on-hand inventory is used for all sales channels. The second deployment strategy additionally considers the advanced positioning of inventory at a fulfillment center in the urban area where the online orders are requested. To solve the two-stage stochastic model with integer recourse, an exact solution approach combining scenario sampling and the integer L-shaped method is proposed. Numerical results, inspired by the case of a European retailer, are provided to evaluate the performance of the deployment strategies and the efficiency of the proposed solution approach.},
  archive      = {J_EJOR},
  author       = {Ayşe N. Arslan and Walid Klibi and Benoit Montreuil},
  doi          = {10.1016/j.ejor.2020.04.016},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1042-1058},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Distribution network deployment for omnichannel retailing},
  volume       = {294},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Dynamic pricing of flexible time slots for attended home
delivery. <em>EJOR</em>, <em>294</em>(3), 1022–1041. (<a
href="https://doi.org/10.1016/j.ejor.2020.03.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In e-commerce, customers are usually offered a menu of home delivery time windows of which they need to select exactly one, even though at least some customers may be more flexible. To exploit the flexibility of such customers, we propose to introduce flexible delivery time slots, defined as any combination of such regular time windows (not necessarily adjacent). In selecting a flexible time slot (out of a set of windows that form the flexible product), the customer agrees to be informed only shortly prior to the dispatching of the delivery vehicle in which regular time window the goods will arrive. In return for providing this flexibility, the company may offer the customer a reduced delivery charge and/or highlight the environmental benefits. Our framework also can accommodate customized flexible slots where customers can self-select a set of regular slots in which a delivery may take place. The vehicle routing problem (VRP) in the presence of flexible time slots bookings corresponds to a VRP with multiple time windows. We build on literature on demand management and vehicle routing for attended home delivery, as well as on flexible products. These two concepts have not yet been combined, and indeed the results from the flexible products literature do not carry over directly because future expected vehicle routing implications need to be taken into account. The main methodological contribution is the development of a tractable linear programming formulation that links demand management decisions and routing cost implications, whilst accounting for customer choice behavior. The output of this linear program provides information on the (approximate) opportunity cost associated with specific orders and informs a tractable dynamic pricing policy for regular and flexible slots. Numerical experiments, based on realistically-sized scenarios, indicate that expected profit may increase significantly depending on demand intensity when adding flexible slots rather than using only regular slots.},
  archive      = {J_EJOR},
  author       = {Arne Strauss and Nalan Gülpınar and Yijun Zheng},
  doi          = {10.1016/j.ejor.2020.03.007},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1022-1041},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Dynamic pricing of flexible time slots for attended home delivery},
  volume       = {294},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Integrated order batching and vehicle routing operations in
grocery retail – a general adaptive large neighborhood search algorithm.
<em>EJOR</em>, <em>294</em>(3), 1003–1021. (<a
href="https://doi.org/10.1016/j.ejor.2020.03.075">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, established and well-known grocery retailers have increasingly been investing in the business of micro stores and petrol station shops. Supplying these stores with perishable and durable goods leads to noticeable logistics challenges for the retailers. Since the total sales volumes of these shops are typically low and the respective sales areas are very limited, highly frequent deliveries of small sizes are required. These noticeably affect a number of operational planning problems. In the warehouse, the items requested have to be collected in small order sizes. In order to achieve efficient picking operations, orders are therefore combined into larger picking orders, i.e., batches. Afterwards the orders have to be delivered to the stores at high frequency. In practice, all the planning problems mentioned are heavily interconnected due to the short planning horizon. Despite the practical relevance, order batching, order picking and delivery operations have not so far been investigated as an integrative planning problem. This paper therefore presents a novel modeling and solution approach to solve practically relevant problem sizes. The combinatorial complexity of the problem requires a heuristic solution approach. We propose an extension of the well-known Adaptive Large Neighborhood Search (ALNS) metaheuristic that we call General ALNS (GALNS), and show that a GALNS approach outperforms a similar ALNS algorithm in 96.35\% of the problem instances generated. Managerial insights from general problem data and a case study with a large German grocery retailer support the applicability of the modeling and solution approach suggested in retail practice.},
  archive      = {J_EJOR},
  author       = {Heinrich Kuhn and Daniel Schubert and Andreas Holzapfel},
  doi          = {10.1016/j.ejor.2020.03.075},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1003-1021},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Integrated order batching and vehicle routing operations in grocery retail – a general adaptive large neighborhood search algorithm},
  volume       = {294},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Order fulfillment policies for ship-from-store
implementation in omni-channel retailing. <em>EJOR</em>,
<em>294</em>(3), 987–1002. (<a
href="https://doi.org/10.1016/j.ejor.2020.01.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the recent trends in omni-channel retailing is ship-from-store which allows a retailer to fulfill online orders by using inventory from a nearby store. The benefits of this fulfillment model include faster delivery, lower shipment costs, higher in-stock probability, increased sales and customer satisfaction, etc. Despite its many benefits, this fulfillment model introduces many new operational challenges to the retailer, including the need to identify from which location to fulfill an online order when it arrives. In this study, we consider a retailer having both online and store operations, with each channel carrying its own inventory. Store orders are fulfilled from store inventories, whereas an online order can be shipped either from an online fulfillment center or from any other store that maximizes the retailer’s overall profit. Our study investigates dynamic fulfillment decisions: from which location to fulfill an online order when it arrives. We incorporate the uncertainty both in demand and in the cost of shipment to individual customers to characterize the optimal cross-channel fulfillment policy. Due to the optimal policy being computationally intractable for large-sized problems, we construct an intuitive heuristic policy to guide the retailers in their fulfillment decisions. We find that the proposed heuristic method is effective and obtains solutions within a reasonable amount of time for the cross-channel fulfillment problem.},
  archive      = {J_EJOR},
  author       = {Armagan Bayram and Bahriye Cesaret},
  doi          = {10.1016/j.ejor.2020.01.011},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {987-1002},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Order fulfillment policies for ship-from-store implementation in omni-channel retailing},
  volume       = {294},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Facilitating consumer preferences and product shelf life
data in the design of e-grocery deliveries. <em>EJOR</em>,
<em>294</em>(3), 976–986. (<a
href="https://doi.org/10.1016/j.ejor.2019.09.039">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To assist setting up e-grocery operations, this work presents a decision support system integrating product shelf life data and consumer preferences. Based on a conjoint analysis of 432 urban consumers, an agent-based simulation is developed to model preferences, demand patterns and logistics processes. The focus is set on fresh fruits and vegetables and the impact of food quality on customer satisfaction and logistics performance. Computational experiments based on the urban distribution of strawberries investigate the impact of varying service offers throughout multiple weeks of operations. Results highlight potentials of integrating preference and shelf life data as well as the importance of closely considering interactions between service offers and logistics performance within e-grocery operations.},
  archive      = {J_EJOR},
  author       = {Christian Fikar and Andreas Mild and Martin Waitz},
  doi          = {10.1016/j.ejor.2019.09.039},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {976-986},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Facilitating consumer preferences and product shelf life data in the design of e-grocery deliveries},
  volume       = {294},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Retailer’s vertical integration strategies under different
business modes. <em>EJOR</em>, <em>294</em>(3), 965–975. (<a
href="https://doi.org/10.1016/j.ejor.2020.07.054">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Currently, increasingly more retailers wish to gain a competitive advantage through vertical integration. We consider a three-echelon supply chain comprising a retailer, a service supplier, and a manufacturer. The service supplier is responsible for the service level, and the manufacturer is responsible for product quality. The retailer has two business modes: reseller mode and platform mode. The retailer chooses one of three strategies, i.e., no vertical integration, forward integration, or backward integration, for these two business modes. By comparing the retailer&#39;s equilibrium profit under these vertical integration strategies, we obtain the optimal choice for the retailer and a high profit for the supply chain under different business modes. Moreover, we characterize the effects of the proportional fee, product quality, service level and business mode on vertical integration. We find that the cost effect is determined by product quality and service level and that the income distribution effect is determined by the proportional fee. The cost effect is a key factor affecting the retailer&#39;s vertical integration strategy under the reseller mode, and both of these effects jointly affect the retailer&#39;s choice under the platform mode. Furthermore, we design a cost-sharing contract to improve vertical integration efficiency and investigate the effect of vertical integration decisions on improvement strategies. Lastly, we consider an extension to analyse the effect of an endogenous proportional fee on retailers&#39; vertical integration strategies.},
  archive      = {J_EJOR},
  author       = {Pei Li and Dan Tan and Guangyong Wang and Hang Wei and Jilan Wu},
  doi          = {10.1016/j.ejor.2020.07.054},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {965-975},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Retailer&#39;s vertical integration strategies under different business modes},
  volume       = {294},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Power structure and channel integration strategy for online
retailers. <em>EJOR</em>, <em>294</em>(3), 951–964. (<a
href="https://doi.org/10.1016/j.ejor.2019.10.050">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the boom of e-commerce, express delivery has been increasingly regarded as a bottleneck and key factor for achieving success. Additionally, whether to include such express delivery service or not is an important yet outstandingly unsolved problem for online retailers. In this regard, this paper uses a game-theoretic framework to investigate the channel structure, in which an offline retailer competes with an online retailer selling products to consumers through its partner express company. The consumers purchase from either an online or offline channel considering the delivery service as well as the inconvenience of shopping from physical stores. We consider three power structures: online retailer Stackelberg game, offline retailer Stackelberg game and Nash game. Under each power structure, we characterize the channel integration strategy for the online retailer. Interestingly, our results show that the online channel integration is not beneficial for the online retailer in most cases. Online retailers prefer to use express companies as intermediaries to avoid large logistics operations costs in the offline retailer Stackelberg game and Nash game. Only in the online retailer Stackelberg game, where the online retailer has the first-move advantage in the market, together with a moderate store-visiting inconvenience cost and a delivery service cost coefficient, will vertical integration improve the online channel’s profit. Dominant market power ensures sufficient profit to cover the logistics cost, and the moderate inconvenience cost and service cost coefficient promise a moderate logistics cost. Under this condition, the online retailer will choose the vertical integration strategy. We show in the extension that this strict condition can be relaxed when the online retailer owns a mixed channel. The online retailer with a mixed channel has more incentive to integrate than a pure online retailer does, as the mixed channel adds his power and helps to gain more market shares and profit. Our analysis generates managerial insights into the relationship between online retailers and express companies and provides a guide for implementing the vertical integration strategy in the online retailing industry.},
  archive      = {J_EJOR},
  author       = {Yihong Hu and Shengnan Qu and Guo Li and Suresh P. Sethi},
  doi          = {10.1016/j.ejor.2019.10.050},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {951-964},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Power structure and channel integration strategy for online retailers},
  volume       = {294},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Omnichannel retail move in a dual-channel supply chain.
<em>EJOR</em>, <em>294</em>(3), 936–950. (<a
href="https://doi.org/10.1016/j.ejor.2020.12.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A growing number of retailers are now moving to omnichannel sales and adopting new technologies to integrate the store and the web to offer customers a seamless shopping experience. We develop a stylized model where a manufacturer distributes products through two separate retailers in two market segments, e.g., online vs. offline. The aim of this study is to investigate the impacts of competing retailers’ omnichannel moves on supply chain performance. Our model combines pricing interactions and channel move strategies from a supply-side perspective. We obtain three main results. First, though it is suitable for the traditional brick-and-mortar retailer to adopt an omnichannel strategy, it may not be always good for the e-tailer. Second, omnichannel retail does not always lead to lower retail prices and enhanced consumer welfare. It may result in a lower price for the offline segment, but for the online segment, a higher price will be charged. Finally, omnichannel retail may not be good for the manufacturer. An equilibrium { Omnichannel, Digital channel only } strategy outcome of the retailers’ channel move game results in a higher demand and more profits for the manufacturer. However, the manufacturer is indeed hurt by the { Omnichannel, Omnichannel } equilibrium. Our study provides useful managerial insights into retailers’ omnichannel moves in a supply chain.},
  archive      = {J_EJOR},
  author       = {Xiaofeng Shao},
  doi          = {10.1016/j.ejor.2020.12.008},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {936-950},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Omnichannel retail move in a dual-channel supply chain},
  volume       = {294},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Impact of a “buy-online-and-pickup-in-store” channel on
price and quality decisions in a supply chain. <em>EJOR</em>,
<em>294</em>(3), 922–935. (<a
href="https://doi.org/10.1016/j.ejor.2020.03.064">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the impact of a “buy-online-and-pickup-in-store (BOPS)” channel on quality, prices, and profits of a manufacturer and a retailer. We analyze a Stackelberg game-theoretic model where the manufacturer produces and sells a product with a quality level to the retailer at a wholesale price, and the retailer sells the product to end customers at a selling price through a Store channel, an Online channel or a BOPS channel (if available). The retailer would incur an extra handling cost if opening the BOPS channel, and customers would incur a shipping and transaction cost if purchasing from the Online channel and the Store channel, respectively. We find that both the manufacturer and the retailer can benefit from adding the BOPS channel under certain conditions. Moreover, when the BOPS channel is not available, adding the Store channel is beneficial for both parties and results in lower quality and wholesale price but higher selling price when the shipping cost is relatively high. When the Store channel is dominated by the available BOPS channel, however, opening the Store channel cannot benefit both parties. We also show that adding the BOPS channel would increase (reduce) both consumer surplus and social welfare for a sufficiently low (high) handling cost. We further observe that it is profitable for a centralized decision maker to add the BOPS channel via increasing both the price and quality under some simple conditions. Finally, we extend our base model to a more general one and illustrate our main results remain valid.},
  archive      = {J_EJOR},
  author       = {Xiaogang Lin and Yong-Wu Zhou and Rui Hou},
  doi          = {10.1016/j.ejor.2020.03.064},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {922-935},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Impact of a “Buy-online-and-pickup-in-store” channel on price and quality decisions in a supply chain},
  volume       = {294},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). “Buy online and pick up in-store”: Implications for the
store inventory. <em>EJOR</em>, <em>294</em>(3), 906–921. (<a
href="https://doi.org/10.1016/j.ejor.2020.10.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {‘Buy online and pick up in-store’ (BOPS), wherein a customer buys the product online and picks it up from the physical store at her convenience, is fast gaining popularity. However, BOPS service complicates the store&#39;s inventory policy as BOPS orders, while waiting to be picked up, block inventory and thus delay replenishment requests. The store now has to maintain a base-stock level that is optimal considering both walk-in and BOPS orders. We discuss an inventory control policy that suits this situation. The problem is accentuated when the online channel and the physical store are under different ownerships, since the revenue from BOPS orders will now get shared between the two. In such a scenario, the store may opt for an inventory policy that favours walk-in orders over BOPS requests, as every BOPS order fetches less revenue than every walk-in customer. The extent of restriction on BOPS orders will depend on the revenue-sharing policy and also on the relative frequencies of walk-in and BOPS demands. We discuss two inventory policies that can help the store prioritize walk-in demands over BOPS demands. We compare the performances of the policies proposed, and show that each policy has its claim to supremacy over others in different operating environments, characterized by the input parameters.},
  archive      = {J_EJOR},
  author       = {Kushal Saha and Subir Bhattacharya},
  doi          = {10.1016/j.ejor.2020.10.006},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {906-921},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {‘Buy online and pick up in-store’: Implications for the store inventory},
  volume       = {294},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Showcasing optimization in omnichannel retailing.
<em>EJOR</em>, <em>294</em>(3), 895–905. (<a
href="https://doi.org/10.1016/j.ejor.2020.03.081">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With recent breakthroughs in technology and digitalization, omnichannel retailing has now become the norm, and shoppers are able to seamlessly make the switch between different channels for one purchase. Retailers can leverage the blurred lines between the channels and adopt a business model that best suits the industry, such as having a virtual online showcase and letting the customers pick up the products in person or having an offline showroom and having products delivered to customers. The latter concept, in which information about products is gathered in a store or a showroom and fulfillment is made via delivery to customers, is particularly suitable when the customers prefer to experience the products in person to gain sufficient confidence in their potential purchase. This is often the case for high-value large products with high shipping costs. In this context, we propose a quantitative approach to optimize the showcasing portfolio for a given retailer to maximize the exposure of the features that customers expect to experience from a visit to a showroom. The problem is formulated as a mixed-integer optimization problem to maximize the expected customer showcasing utility through module and product showcasing and product testing. To demonstrate the practicality of our approach, we conduct a case study based on real data obtained from 17 dealerships of our industrial partner, a manufacturer of recreational vehicles. The numerical results of this case study show that the expected showcasing utility for a retailer can significantly increase, even in the presence of spatial and/or budget constraints.},
  archive      = {J_EJOR},
  author       = {Jisoo Park and Iman Dayarian and Benoit Montreuil},
  doi          = {10.1016/j.ejor.2020.03.081},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {895-905},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Showcasing optimization in omnichannel retailing},
  volume       = {294},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). On the value of subscription models for online grocery
retail. <em>EJOR</em>, <em>294</em>(3), 874–894. (<a
href="https://doi.org/10.1016/j.ejor.2020.05.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Omnichannel retailers are increasingly introducing subscription-based delivery services. By subscribing to this service and paying fees upfront, customers are entitled to have orders delivered to their home for a given period without paying any extra delivery charge. We analyze the resulting changes in customer behavior from two perspectives:(i) ordering behavior and (ii) delivery preferences. The model is estimated from the online transactional data of a grocery retailer and combines matching and difference-in-differences approaches. We confirm that subscription customers spend more per month and purchase more frequently online than customers without subscriptions. However, this outcome is compromised by shifts towards narrower time slots in the mornings and at night, where slots are requested with less advance notice. When weighing the increased revenue and higher operational costs, we show that subscriptions have a negative impact on a retailer’s incremental profit. This remains valid for a wide range of assumptions about (i) the cannibalisation of sales from the retailer’s offline business, (ii) picking cost and (iii) delivery cost. To mitigate the impact of subscriptions on retailer profits, we develop a data-driven algorithm that predicts whether certain customers should receive promotions for the subscription plan, rather than it being advertised to all customers. As an extension, we also study whether the addition of a minimum order threshold to subscription plans changes consumer behaviour. We find that this introduction encourages customers to seek more variety and increase their basket size, but does not reduce their order frequency, a phenomena which may be ascribed to cross-selling.},
  archive      = {J_EJOR},
  author       = {Laura Wagner and Catarina Pinto and Pedro Amorim},
  doi          = {10.1016/j.ejor.2020.05.011},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {874-894},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {On the value of subscription models for online grocery retail},
  volume       = {294},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Catch me if you scan: Data-driven prescriptive modeling for
smart store environments. <em>EJOR</em>, <em>294</em>(3), 860–873. (<a
href="https://doi.org/10.1016/j.ejor.2020.12.047">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasing adoption of omnichannel strategies in recent years has led retail companies worldwide to fundamentally rethink the future role of their network of brick-and-mortar stores. One strategic option being pursued by many retailers is the transformation of the stationary store into a “smart store,” augmented by various digital services. However, an essential prerequisite for the success of smart store services is high quality of the underlying data generated through the use of technologies for tracking products and customer behavior. As a means of investigating the use of machine learning to improve data quality, the present study considers the example of Radio Frequency Identification (RFID) as a technological infrastructure for tracking products in fashion retail. We examine electronic article surveillance and automated checkouts as practical use cases enabled by a classification model for the detection of product movements on the store floor. In order to identify an economically optimal configuration of the classifier, we develop a complementary service operations model that allows for determining the respective cost impact. In addition to the specific results for the considered use cases, the study thus points to a general and novel prescriptive analytics approach.},
  archive      = {J_EJOR},
  author       = {Matthias Hauser and Christoph M. Flath and Frédéric Thiesse},
  doi          = {10.1016/j.ejor.2020.12.047},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {860-873},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Catch me if you scan: Data-driven prescriptive modeling for smart store environments},
  volume       = {294},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Modeling price response from retail sales: An empirical
comparison of models with different representations of heterogeneity.
<em>EJOR</em>, <em>294</em>(3), 843–859. (<a
href="https://doi.org/10.1016/j.ejor.2020.07.055">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We assess the performance of store sales models with discrete versus continuous representations of heterogeneity. Specifically, we compare the general heterogeneity model introduced by Allenby et al. (1998) and Lenk and DeSarbo (2000) to its nested versions, a homogeneous model ignoring heterogeneity in marketing effects, a hierarchical Bayes model and a latent class model within a fully Bayesian framework. In an empirical application with scanner data of a large retail chain, we analyze the possible improvements in model fit and predictive validity for approaches that allow for heterogeneity compared to the homogeneous model, and illustrate differences between the various model versions regarding price elasticities. We further compare the performance of the different models to the zone pricing model practiced by the retailer. We find that the more parsimonious models with discrete representations of heterogeneity clearly outperform their continuous counterparts in terms of the model likelihood. Moreover, incorporating heterogeneity does not improve the model fit for many brands compared to the homogeneous model. The prediction accuracy of models with discrete representations of heterogeneity is comparable or even superior to that of continuous heterogeneity models. Noticeably, the predictive performance of the retailer’s zone model is considerably worse than that of the best model for the majority of brands. Our empirical study further demonstrates that models with different representations of heterogeneity provide similar implications for price elasticities, suggesting that there is little benefit from using more complex continuous heterogeneity models from a managerial point of view, at least for the present data.},
  archive      = {J_EJOR},
  author       = {Anett Weber and Winfried J. Steiner},
  doi          = {10.1016/j.ejor.2020.07.055},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {843-859},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Modeling price response from retail sales: An empirical comparison of models with different representations of heterogeneity},
  volume       = {294},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Distributional regression for demand forecasting in
e-grocery. <em>EJOR</em>, <em>294</em>(3), 831–842. (<a
href="https://doi.org/10.1016/j.ejor.2019.11.029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {E-grocery offers customers an alternative to traditional store grocery retailing. Customers select e-grocery for convenience, making use of the home delivery at a selected time slot. In contrast to store retailing, in e-grocery in-stock information for stock keeping units (SKUs) becomes transparent to the customer before substantial shopping effort has been invested, thus reducing the personal cost of switching to another supplier. As a consequence, in-stock availability of SKUs has a particularly strong impact on the customer’s order decision, resulting in higher strategic service level targets for the e-grocery retailer. To account for these high service level targets, we propose a suitable model for accurately predicting the extreme right tail of the demand distribution, rather than providing point forecasts of its mean. Specifically, we propose the application of distributional regression methods — so-called Generalised Additive Models for Location, Scale and Shape (GAMLSS) — to arrive at the cost-minimising solution according to the newsvendor model. As benchmark models we consider various regression models as well as popular methods from machine learning. The models are evaluated in a case study, where we compare their out-of-sample predictive performance with respect to the service level provided by the e-grocery retailer analysed.},
  archive      = {J_EJOR},
  author       = {Matthias Ulrich and Hermann Jahnke and Roland Langrock and Robert Pesch and Robin Senge},
  doi          = {10.1016/j.ejor.2019.11.029},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {831-842},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Distributional regression for demand forecasting in e-grocery},
  volume       = {294},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Here comes the sun: Fashion goods retailing under weather
fluctuations. <em>EJOR</em>, <em>294</em>(3), 820–830. (<a
href="https://doi.org/10.1016/j.ejor.2020.01.064">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The weather has been identified as an important driver of demand and constitutes a major risk for retailers, especially in goods for which usage is affected by weather conditions, such as soft drinks or fashion apparel. Specifically, weather variations change the propensity to visit the point of sales, because travel cost is affected by weather conditions; and they impact differently different product categories, because the reference utility in the mind of the consumer is affected by current weather. We empirically study these two impact dimensions at a large fashion apparel retailer. We find that rain has a large effect on footfall, increasing it in shopping mall stores and decreasing it in street stores, which suggest that it is a first-order factor for channel choice. Temperature has a milder effect on footfall. In contrast, temperature has a large impact on conversion, increasing sales of the “appropriate” categories: summer items are sold more under positive temperature shocks, and winter items less. Finally, although theory suggests that the weather should have a moderating effect on price sensitivity, we find that it is unaffected by the weather.},
  archive      = {J_EJOR},
  author       = {Victor Martínez-de-Albéniz and Abdel Belkaid},
  doi          = {10.1016/j.ejor.2020.01.064},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {820-830},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Here comes the sun: Fashion goods retailing under weather fluctuations},
  volume       = {294},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Digitalization and omnichannel retailing: Innovative OR
approaches for retail operations. <em>EJOR</em>, <em>294</em>(3),
817–819. (<a href="https://doi.org/10.1016/j.ejor.2021.04.049">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Omnichannel retailing and digitalization result in considerable challenges for the management and optimization of retail operations. The continued demand of quantitative insights, their practical need, and the growing availability of data motivates an increasing number of scientists and practitioners to intensify research on demand and supply-related issues in retailing. This featured cluster provides the state-of-the art literature on forecasting and digitalization technologies, channel structures and delivery concepts as well as logistics in omnichannel and online retailing. The featured cluster contains 17 articles that deal with such topics.},
  archive      = {J_EJOR},
  author       = {Alexander Hübner and Pedro Amorim and Jan Fransoo and Dorothee Honhon and Heinrich Kuhn and Victor Martinez de Albeniz and David Robb},
  doi          = {10.1016/j.ejor.2021.04.049},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {817-819},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Digitalization and omnichannel retailing: Innovative OR approaches for retail operations},
  volume       = {294},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Analytic formulas for futures and options for a linear
quadratic jump diffusion model with seasonal stochastic volatility and
convenience yield: Do fish jump? <em>EJOR</em>, <em>294</em>(2),
801–815. (<a href="https://doi.org/10.1016/j.ejor.2021.02.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article we derive tractable analytic solutions for futures and options prices for a linear-quadratic jump-diffusion model with seasonal adjustments in stochastic volatility and convenience yield. We then calibrate our model to data from the fish pool futures market, using the extended Kalman filter and a quasi-maximum likelihood estimator and alternatively using an implied-state quasi-maximum likelihood estimator. We find no statistical evidence of jumps. However, we do find evidence for positive correlation between salmon spot prices and volatility, seasonality in volatility and convenience yield. In addition we observe a positive relationship between seasonal risk premium and uncertainty of EU salmon demand. We further show that our model produces option prices that are conform with the observation of implied volatility smiles and skews. Our work connects to a number of results that have recently appeared in the Operations Research literature.},
  archive      = {J_EJOR},
  author       = {Christian Ewald and Yihan Zou},
  doi          = {10.1016/j.ejor.2021.02.004},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {801-815},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Analytic formulas for futures and options for a linear quadratic jump diffusion model with seasonal stochastic volatility and convenience yield: Do fish jump?},
  volume       = {294},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Optimal combinations of stochastic frontier and data
envelopment analysis models. <em>EJOR</em>, <em>294</em>(2), 790–800.
(<a href="https://doi.org/10.1016/j.ejor.2021.02.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent research has shown that combination approaches, such as taking the maximum or the mean over different methods of estimating efficiency scores, have practical merits and offer a useful alternative to adopting only one technique. This recent research shows that taking the maximum minimizes the risk of underestimation, and improves the precision of efficiency estimation. In this paper, we propose and implement a formal criterion of weighting based on maximizing proper criteria of model fit (viz. log predictive scoring) and show how it can be applied in Stochastic Frontier as well as in Data Envelopment Analysis models, where the problem is more difficult. Monte Carlo simulations show that the new techniques perform very well and a substantive application to large U.S. banks shows some important differences with traditional models. The Monte Carlo simulations are also substantive as it is for the first time that proper and coherent optimal model pools are subjected to extensive testing in finite samples.},
  archive      = {J_EJOR},
  author       = {Mike G. Tsionas},
  doi          = {10.1016/j.ejor.2021.02.003},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {790-800},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Optimal combinations of stochastic frontier and data envelopment analysis models},
  volume       = {294},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Configuring and pricing smart coproductive services.
<em>EJOR</em>, <em>294</em>(2), 779–789. (<a
href="https://doi.org/10.1016/j.ejor.2021.01.041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Coproductive services involve the active participation of customers by exerting physical/mental effort as a part of the service process to co-create value. While the demand for coproduction models is surging, there are complaints about customer experience and service system design. Owing to these dissatisfaction issues, providers are now shifting away from self-service models, towards the notion of smart service; where service tasks are efficiently divided between the provider and the customer. This study addresses the business problem of the configuration and pricing of such a smart coproduction service channel targeted at a segment within an incumbent provider&#39;s captive customer base. We analyze the relative preference of the popular uniform pricing policy against a new proposed policy that accounts for the strategic behaviour of customers. This study uses a suite of analytical modelling tools to address this problem. We analyze the applicability of the alternate pricing regimes when providers are pursuing certain prevalent marketing strategies. We also analyze the influence of relative co-creation productivity between the provider and customer on the choice of pricing regime. We find that the popularity of the uniform pricing model can be explained with its simplicity in configuration and applicability. On the other hand, we find that the proposed strategic pricing regime not only induces customers to adopt coproduction channels but also enables providers to charge a price premium where possible. Furthermore, our analysis explains several observations in practice w.r.t. uptake and proliferation of coproduction channels. We also present useful guidelines to managers for configuring and pricing coproduction service channels.},
  archive      = {J_EJOR},
  author       = {S. Sivakumar and B. Mahadevan},
  doi          = {10.1016/j.ejor.2021.01.041},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {779-789},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Configuring and pricing smart coproductive services},
  volume       = {294},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Rail platooning: Scheduling trains along a rail corridor
with rapid-shunting facilities. <em>EJOR</em>, <em>294</em>(2), 760–778.
(<a href="https://doi.org/10.1016/j.ejor.2021.02.019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Several technological developments are on the way to substantially impact future railway operations. Distributed traction power enables operating longer and heavier trains. The use of automatic couplings allows to quickly join formerly separately operated trains to longer units. Such a platooning on rails promises a much better utilization of congested rail corridors, but requires some upgrades of classical rail infrastructure as well. Rapid shunting tracks are necessary to form platoons and the railway lines have to be prepared to accommodate longer trains. This paper evaluates the rail platooning concept for German railway operator Deutsche Bahn and one of its most-frequented rail corridors. To do so, we formulate the rail platooning problem, which schedules the traversal of freight trains and their assignment to rail platoons along a rail corridor equipped with rapid-shunting facilities. To solve the resulting optimization problem, we apply a three-layered time-space network approach. Our solution procedure optimizing platoon building is benchmarked with conventional (non-platooned) solutions and our results show that considerably more trains can be channeled through a congested rail corridor.},
  archive      = {J_EJOR},
  author       = {Stefan Schwerdfeger and Alena Otto and Nils Boysen},
  doi          = {10.1016/j.ejor.2021.02.019},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {760-778},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Rail platooning: Scheduling trains along a rail corridor with rapid-shunting facilities},
  volume       = {294},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Optimal portfolio deleveraging under market impact and
margin restrictions. <em>EJOR</em>, <em>294</em>(2), 746–759. (<a
href="https://doi.org/10.1016/j.ejor.2021.02.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the problem of optimally deleveraging a high net-worth long-short portfolio in a short time period to position the fund favorably with respect to leverage and margin risks, in the face of an adverse outlook on future uncertainty. We develop a generalized mean-variance deleveraging optimization model that accounts for market impact costs in portfolio trading under market illiquidity. Due to asset price impact stemming from both volume and intensity of trading, the model has significant non-convexities. For portfolios with a large number of assets, the model is not solvable using standard software, and thus, we employ an efficient solution scheme based on dual optimization, along with a sequence of progressively-improving feasible portfolios computed under convex approximation. Our computational analysis using real data on ETF assets provides new insights on performance sensitivity. In particular, ignoring market impact severely downgrades portfolio performance depending on leverage and margin policies, as well as market liquidity conditions. Such insights can guide portfolio managers in setting deleveraging policy parameters ex-ante when faced with potential market turbulence. We also test the solution algorithm using random problem instances under thousands of assets to demonstrate the scalability and solvability of the deleveraging model.},
  archive      = {J_EJOR},
  author       = {Chanaka Edirisinghe and Jaehwan Jeong and Jingnan Chen},
  doi          = {10.1016/j.ejor.2021.02.016},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {746-759},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Optimal portfolio deleveraging under market impact and margin restrictions},
  volume       = {294},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Sequencing situations and games with non-linear cost
functions under optimal order consistency. <em>EJOR</em>,
<em>294</em>(2), 734–745. (<a
href="https://doi.org/10.1016/j.ejor.2021.02.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper considers sequencing situations with non-linear cost functions under optimal order consistency. Specifically, we study sequencing situations with discounting cost functions and logarithmic cost functions of the completion time. In both settings, we show that the neighbor switching gains are non-negative and non-decreasing for every misplaced pair of players. We derive new conditions on the time-dependent neighbor switching gains in a sequencing situation under optimal order consistency to guarantee convexity of the associated sequencing game. Furthermore, we define two types of gain splitting rules for the class of sequencing situations under optimal order consistency. Each one of them is based on a procedure that specifies a path from the initial order to an optimal order, dividing the neighbor switching gains in every step among the two involved players. We prove that these allocations are stable under the same conditions that are required for convexity. These requirements are fulfilled for discounting and logarithmic sequencing situations, as well as in other settings, such as in sequencing situations with exponential cost functions.},
  archive      = {J_EJOR},
  author       = {Jop Schouten and Alejandro Saavedra-Nieves and M. Gloria Fiestras-Janeiro},
  doi          = {10.1016/j.ejor.2021.02.013},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {734-745},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Sequencing situations and games with non-linear cost functions under optimal order consistency},
  volume       = {294},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A robust decision-support method based on optimization and
simulation for wildfire resilience in highly renewable power systems.
<em>EJOR</em>, <em>294</em>(2), 723–733. (<a
href="https://doi.org/10.1016/j.ejor.2021.02.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wildfires can pose a major threat to the secure operation of power networks. Chile, California, and Australia have suffered from recent wildfires that have induced considerable power supply cuts. Further, as power systems move to a significant integration of variable renewable energy sources, successfully managing the impact of wildfires on the power supply can become even more challenging due to the joint uncertainty in wildfire trajectories and the power injections from wind and solar farms. Motivated by this, this paper develops a practical decision-support approach that concatenates a stochastic wildfire simulation method with an attacker-defender model that aims to find a worst-case realization for (i) transmission line and generator contingencies, out of those that can potentially be affected by a given wildfire scenario, and for (ii) wind and solar power trajectories, based on a max-min structure where the inner min problem represents a best adaptive response on generator dispatch actions. Further, this paper proposes an evaluation framework to assess the power supply security of various power system topology configurations, under the assumption of limited transmission switching capabilities, and based on the simulation of several wildfire evolution scenarios. Extensive computational experiments are carried out on two representations of the Chilean power network with up to 278 buses, showing the practical effectiveness of the proposed approach for enhancing wildfire resilience in highly renewable power systems.},
  archive      = {J_EJOR},
  author       = {Tomás Tapia and Álvaro Lorca and Daniel Olivares and Matías Negrete-Pincetic and Alberto J. Lamadrid L},
  doi          = {10.1016/j.ejor.2021.02.008},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {723-733},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A robust decision-support method based on optimization and simulation for wildfire resilience in highly renewable power systems},
  volume       = {294},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). How can lenders prosper? Comparing machine learning
approaches to identify profitable peer-to-peer loan investments.
<em>EJOR</em>, <em>294</em>(2), 711–722. (<a
href="https://doi.org/10.1016/j.ejor.2021.01.047">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Successful Peer-to-Peer (P2P) lending requires an evaluation of loan profitability from a large universe of loans. Predictions of loan profitability may be useful to rank potential investments. We investigate whether various types of prediction methods and the types of information contained in loan listing features matter for profitable investment. A range of methods and performance metrics are used to benchmark predictive performance, based on a large dataset of P2P loans issued on Lending Club. Robust linear mixed models are used to investigate performance differences between models, according to whether they assume linearity, whether they build ensembles, and which types of predictors they use. The main findings are that: linear methods perform surprisingly well on several (but not all) criteria; whether ensemble methods perform better than individual methods is measure dependent; the use of alternative text-based information does not improve profit scoring outcomes. We conclude that P2P lenders could potentially increase their investment returns by applying linear methods that directly predict the internal rate of return instead of other dependent variables such as loan default.},
  archive      = {J_EJOR},
  author       = {Trevor Fitzpatrick and Christophe Mues},
  doi          = {10.1016/j.ejor.2021.01.047},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {711-722},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {How can lenders prosper? comparing machine learning approaches to identify profitable peer-to-peer loan investments},
  volume       = {294},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Retail channel management decisions under collusion.
<em>EJOR</em>, <em>294</em>(2), 700–710. (<a
href="https://doi.org/10.1016/j.ejor.2021.01.046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In unprofitable business circumstances, collusion may work to save investment and operations costs, which could fight off fierce business competition. However, collusive behavior may incur adverse impacts on consumers and multi-channel decisions in a supply chain. A common approach to deterring collusive behavior involves setting financial penalties. However, severe punishment could limit economic activities. To align with regulations and boost market vitality, in this paper, we investigate how the manufacturer chooses a competitive selling channel in a complex environment, and how it can design a compensation plan that can effectively mitigate such unethical behavior and coordinate the whole supply chain (channel). We find that collusion is an ‘unstable equilibrium’ and only works when both retailers are comparable. That is, when the retail market is extremely dominated by a stronger retailer, the profit of a smaller retailer would be gobbled up by the stronger one. Retailers’ collusion against the manufacturer seems like an advantageous strategy to maximize their profits, but we find that the retailers’ profits may be reduced because of collusion unless they are facing a greater market base. We then show that the profit margins of the manufacturer and the whole supply chain are squeezed; thus, introducing the online platform is one essential way for the manufacturer to address such collusion. We further propose a compensation and incentive contract with effective penalties through differentiating wholesale prices for retailers, which benefits the whole supply chain in terms of high profits. The key findings can provide useful decision support and operational guidelines for manufacturers with respect to making strategic retail channel management decisions.},
  archive      = {J_EJOR},
  author       = {Jing Lin and Xin Ma and Srinivas Talluri and Cheng-Hu Yang},
  doi          = {10.1016/j.ejor.2021.01.046},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {700-710},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Retail channel management decisions under collusion},
  volume       = {294},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Production planning and equity investment decisions in
agriculture with closed membership cooperatives. <em>EJOR</em>,
<em>294</em>(2), 684–699. (<a
href="https://doi.org/10.1016/j.ejor.2021.02.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper examines the production planning and equity investment decisions of a cash-constrained farmer who processes a raw commodity into a value-added product through a closed-membership agricultural cooperative (closed co-op). The farmer is required to purchase a certain amount of shares within specific limits to join in the co-op. The equity investment entitles the right to deliver a particular amount of qualified raw commodity in proportion, and the shares are transferable and appreciable. We consider a multi-period model in which the farmer first considers a one-time decision on participation (whether to join in the co-op). If yes, the farmer determines the production capacity and the initial equity investment in addition to the periodic production planning and equity investment adjustment when yield, spot prices, and share price are uncertain. We propose the condition under which the farmer shall participate in the co-op and characterize the optimal capacity and equity investment policies in closed form. We also investigate how the transferability of shares affects the farmer’s optimal decisions and profitability by fixing the initial equity investment. Further, we examine the performance of a variety of heuristic policies when the quality requirement or the yield uncertainty is ignored. The results provide insights into a farmer’s decision making, production planning, and cash management.},
  archive      = {J_EJOR},
  author       = {Xiaoyan Qian},
  doi          = {10.1016/j.ejor.2021.02.007},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {684-699},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Production planning and equity investment decisions in agriculture with closed membership cooperatives},
  volume       = {294},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Fixing match-fixing: Optimal schedules to promote
competitiveness. <em>EJOR</em>, <em>294</em>(2), 673–683. (<a
href="https://doi.org/10.1016/j.ejor.2021.02.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the last round of the FIFA World Cup group stage, games for which the outcome does not affect the selection of the qualified teams are played with little enthusiasm. Furthermore, a team that has already qualified may take into account other factors, such as the opponents it will face in the next stage of the competition so that, depending on the results in the other groups and the scheduling of the next stage, winning the game may not be in its best interest. Even more critically, there may be situations in which a simple draw will qualify both teams for the next stage of the competition. Any situation in which the two opposing teams do not play competitively is detrimental to the sport, and, above all, can lead to collusion and match-fixing opportunities. We here develop a relatively general method of evaluating competitiveness and apply it to the current format of the World Cup group stage. We then propose changes to the current format in order to increase the stakes in the last round of games of the group stage, making games more exciting to watch and, at the same time, reducing any collusion opportunities. We appeal to the same method to evaluate a “groups of 3” format which will be introduced in the 2026 World Cup edition as well as a format similar to the one of the current Euro UEFA Cup.},
  archive      = {J_EJOR},
  author       = {Mario Chater and Luc Arrondel and Jean-Pascal Gayant and Jean-François Laslier},
  doi          = {10.1016/j.ejor.2021.02.006},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {673-683},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Fixing match-fixing: Optimal schedules to promote competitiveness},
  volume       = {294},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Comparing group performance over time through the luenberger
productivity indicator: An application to school ownership in european
countries. <em>EJOR</em>, <em>294</em>(2), 651–672. (<a
href="https://doi.org/10.1016/j.ejor.2021.02.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper extends the Camanho and Dyson (2006) one-period Malmquist-type index (CDMI) and the recent pseudo-panel Malmquist index (PPMI) by Aparicio et al. (2017) and Aparicio and Santín (2018) to a context where additive efficiency measures are used. In particular, we apply the Luenberger productivity indicator. Unlike the CDMI, the new approach is based upon the directional distance function, allowing non-equiproportional changes in the input and output mix and variable returns to scale for comparing the efficiency and technology gaps of two or more groups of production units over time. To illustrate this methodology, we estimate how the productivity gaps between publicly funded private schools (PFPS) and public schools (PS) in eight European Union countries changed over the 2009–15 period using PISA data. Our results suggest that the performance of PFPS is better in Belgium, Ireland, the Netherlands and Spain in both waves, while PS productivity outperforms PFPS in the Czech Republic, Hungary and Slovakia. Both school types operate with a productivity gap close to zero in Denmark. In addition, we observe that despite being less efficient, PS are more productive than PFPS, thanks to their better production technology. Finally, we find that school autonomy is positively related to school productivity explaining why PFPS present higher productivity than PS in some countries.},
  archive      = {J_EJOR},
  author       = {Juan Aparicio and Lidia Ortiz and Daniel Santín},
  doi          = {10.1016/j.ejor.2021.02.005},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {651-672},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Comparing group performance over time through the luenberger productivity indicator: An application to school ownership in european countries},
  volume       = {294},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Incorporating preference information in a range directional
composite indicator: The case of portuguese public hospitals.
<em>EJOR</em>, <em>294</em>(2), 633–650. (<a
href="https://doi.org/10.1016/j.ejor.2021.01.045">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Grasping the intricacy and diversity of complex systems dealing with ever-growing amounts of data is essential to public and private institutions’ continuous improvement. Composite indicators (CIs) emerge as aggregators of key performance indicators, providing a single measure that reflects those multidimensional performance aspects. One way to build such measures is based on the use of data envelopment analysis (DEA). Several DEA models can be used to generate CIs. Still, not many of them can deal concurrently with desirable and undesirable outputs, and incorporate the decision-making actors’ preference information. Based on the directional ‘Benefit-of-the-Doubt’ model, we propose a novel approach consisting of the simultaneous use of weight restrictions and an artificial target reached via a range directional vector. The resulting CI assesses the Portuguese public hospitals’ performance under two perspectives of hospital activity: users and providers. In the end, managerial and policy implications are withdrawn from the results of this study conducted in cooperation with the Portuguese Ministry of Health.},
  archive      = {J_EJOR},
  author       = {Miguel Alves Pereira and Ana Santos Camanho and José Rui Figueira and Rui Cunha Marques},
  doi          = {10.1016/j.ejor.2021.01.045},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {633-650},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Incorporating preference information in a range directional composite indicator: The case of portuguese public hospitals},
  volume       = {294},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Logical efficiency decomposition for general two-stage
systems in view of cross efficiency. <em>EJOR</em>, <em>294</em>(2),
622–632. (<a href="https://doi.org/10.1016/j.ejor.2021.01.044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most of the previous cross efficiency evaluation methods consider the evaluated system as a “black box” system. This probably leads to misleading results. For example, the system is efficient but all of its divisions are inefficient. This paper firstly investigates the cross efficiency for a general two-stage system. In such system, some outputs of one stage are taken as inputs of the other stage, and some other outputs directly become the final products. Since the optimal weight vector for the self-evaluation of a decision making unit (DMU) may be non-unique, we apply the leader-follower method for the decomposition of the system&#39;s efficiency and then adopt the optimal weights to obtain the peer-evaluation. Then, multiplicative hesitant fuzzy elements (MHFEs) are applied to denote the ratio of all possible cross efficiencies of any two DMUs. Based on MHFEs, multiplicative hesitant fuzzy preference relations (MHFPRs) are used to express these relationships comprehensively. Furthermore, the optimization models for deriving acceptably consistent MHFPRs with the minimum total adjustment and the minimum number of adjusted elements are built when the consistency of MHFPRs is unacceptable. An algorithm for decomposing the overall efficiency according to the cross efficiency and acceptably consistent MHFPRs in the setting of the general two-stage system is provided. Finally, our method is applied to the analysis of nine top universities in China.},
  archive      = {J_EJOR},
  author       = {Fanyong Meng and Beibei Xiong},
  doi          = {10.1016/j.ejor.2021.01.044},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {622-632},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Logical efficiency decomposition for general two-stage systems in view of cross efficiency},
  volume       = {294},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A quantitative approach for the long-term assessment of
railway rapid transit network construction or expansion projects.
<em>EJOR</em>, <em>294</em>(2), 604–621. (<a
href="https://doi.org/10.1016/j.ejor.2021.02.018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the main issues to address in the analysis of a public railway rapid transit network construction project is the assessment of expected revenue and cost. On a network topology already defined, the problem considered in this paper consists on finding the construction schedule that maximizes the project long-term net profit, not only deciding on the construction schedule and the network operation but also determining the subsidy to compensate the service operator along the considered long-term planning horizon. Aiming at early attending the demand of citizens, partial pieces of the constructed lines are put into service as soon as they were finished. Hence, in order to determine a subsidy to compensate service operators from a possible non-profitable network operation, it is necessary to measure the variable operation costs that emerge along with the progressive enlargement of a connected network. Further, the problem can be viewed as a particular case of a multiple resource-constrained scheduling problem, where both, the budget and the construction equipment availability act as limiting resources. We propose a non-linear mixed integer programming model which is fully linearized and solved by using a two-phase branch-and-cut procedure. We illustrate the proposed methodology within a real case, the Metro network project of the city of Seville.},
  archive      = {J_EJOR},
  author       = {David Canca and José Luis Andrade-Pineda and Alicia De-Los-Santos and Pedro Luis González-R},
  doi          = {10.1016/j.ejor.2021.02.018},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {604-621},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A quantitative approach for the long-term assessment of railway rapid transit network construction or expansion projects},
  volume       = {294},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Integrated express shipment service network design with
customer choice and endogenous delivery time restrictions.
<em>EJOR</em>, <em>294</em>(2), 590–603. (<a
href="https://doi.org/10.1016/j.ejor.2021.02.014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Express parcel carriers offer a wide range of guaranteed delivery times in order to separate customers who value quick delivery from those that are less time but more price sensitive. To reflect the additional complexity this segmentation adds to the task of optimizing the logistics operations, we present a new model that accounts for the interplay between pricing of due times, customer decisions and the associated restrictions in the distribution process. This profit-maximizing express shipment service network design problem is solved by a heuristic solution approach that simultaneously determines the ideal set of offered delivery times, the associated pricing scheme and the load plan in order to maximize profit. High-quality solutions for realistically-sized instances are derived by a genetic-algorithm-based heuristic that exploits information of previously evaluated iterations. Using this new integrated approach, we provide insight on the potential benefit of an integrated model over sequential optimization of revenue and delivery cost. We also investigate the impact of tighter delivery due times on resource requirements and whether more granular service segmentation can be considered a profitable strategy in multimodal express parcel delivery networks.},
  archive      = {J_EJOR},
  author       = {Florian Martin and Vera C. Hemmelmayr and Tina Wakolbinger},
  doi          = {10.1016/j.ejor.2021.02.014},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {590-603},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Integrated express shipment service network design with customer choice and endogenous delivery time restrictions},
  volume       = {294},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Solving an integrated scheduling and routing problem with
inventory, routing and penalty costs. <em>EJOR</em>, <em>294</em>(2),
571–589. (<a href="https://doi.org/10.1016/j.ejor.2021.02.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper considers an integrated routing and scheduling problem where the routing part takes into account routing costs and tardiness penalties and the scheduling part is modelled by a permutation flow shop with inventory costs. We assume that each batch is served by a dedicated vehicle, and that the number of batches and their compositions (the number of jobs and the parameters of those jobs) are known in advance. The problem is to determine the starting times of the jobs on each machine in the flow shop, the departure dates of the batches and their delivery route, such that the total cost (sum of inventory, routing and penalty costs) is minimised. A two-step approach is proposed. In a first step, the optimal delivery routes for each batch and each possible departure date are calculated. This is possible as determining the min cost route for a particular delivery batch and a particular departure date is easy. In a second step, we use the delivery cost function for each batch, depending on the departure date, from the first step, to find a schedule that minimises the total cost. Computational experiments are performed on randomly generated instances.},
  archive      = {J_EJOR},
  author       = {Hugo Chevroton and Yannick Kergosien and Lotte Berghman and Jean-Charles Billaut},
  doi          = {10.1016/j.ejor.2021.02.012},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {571-589},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Solving an integrated scheduling and routing problem with inventory, routing and penalty costs},
  volume       = {294},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Scheduled service network design with resource management
for two-tier multimodal city logistics. <em>EJOR</em>, <em>294</em>(2),
558–570. (<a href="https://doi.org/10.1016/j.ejor.2021.02.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We address the tactical-planning problem for an extended two-tiered City Logistics system. This more realistic problem setting, compared to the literature, integrates inbound and outbound demands, different transportation modes combining traditional, road-based, carriers with modes and vehicles of mass transport, such as light and regular rail. Aside from the assignment of customers to consolidation distribution centers and satellites, we manage a number of major resources, such as the multiple satellite capacity measures and the structure, allocation, and size of the heterogeneous fleets. We propose a scheduled service network design formulation for the tactical planning of such extended systems, and develop an efficient Benders decomposition algorithm, which includes a tailored partial decomposition technique for deterministic mixed-integer linear-programming formulations. The results of extensive numerical experiments show the efficiency of the proposed solution method, as well as the benefits of integrating several demand types and multimodal transportation networks into a single formulation.},
  archive      = {J_EJOR},
  author       = {Pirmin Fontaine and Teodor Gabriel Crainic and Ola Jabali and Walter Rei},
  doi          = {10.1016/j.ejor.2021.02.009},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {558-570},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Scheduled service network design with resource management for two-tier multimodal city logistics},
  volume       = {294},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Dilemma of quality information disclosure in technology
licensing. <em>EJOR</em>, <em>294</em>(2), 543–557. (<a
href="https://doi.org/10.1016/j.ejor.2021.02.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study investigates the technology licensing decision of an incumbent patentor with quality-improving technology in duopoly model with heterogenous consumers, and quality information disclosure strategies of the patentor and the licensee that compete in quantity. A patentor is faced with a dilemma whether to disclose product quality information to consumers when technology licensing occurs and whether to encourage the licensee to disclose its quality information. While few scholars study the quality information disclosure in the background of technology licensing, these problems are of importance for the technology licensing because the disclosure decision can significantly influence the consumer belief about product quality and generate different effects on patentor&#39;s profitability. We find that the patentor can benefit from choosing information disclosure strategies. Under per-unit royalty licensing, we show that the patentor may choose not to disclose its quality information but encourage the licensee to disclose quality information. However, we find, under fixed fee licensing, when the disclosure cost is sufficiently low and quality difference is not large, only a large prior probability of the product being of high-quality can motivate the choice that the patentor disclose information and require the licensee to disclose. Interestingly, our results also suggest that per-unit royalty licensing leads to more information disclosure and higher profits than fixed-fee licensing. Our work identifies the optimal conditions under which the patentor can deal with the dilemma in quality information disclosure, proposes decision support tools in evaluating the values of quality information disclosure, and provides new management insights in quality disclosure strategy under technology licensing.},
  archive      = {J_EJOR},
  author       = {Hong Xianpei and Zhou Menghuan and Gong Yeming},
  doi          = {10.1016/j.ejor.2021.02.002},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {543-557},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Dilemma of quality information disclosure in technology licensing},
  volume       = {294},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Mean-variance analysis of wholesale price contracts with a
capital-constrained retailer: Trade credit financing vs. Bank credit
financing. <em>EJOR</em>, <em>294</em>(2), 525–542. (<a
href="https://doi.org/10.1016/j.ejor.2021.01.042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies wholesale price contracts with risk constraints in a supply chain consisting of a supplier and a capital-constrained retailer. A newsvendor-like retailer may borrow from a bank or use trade credit to fund his business. We construct a mean-variance model to analyze the decisions involved in the design of the wholesale price contract under both trade credit financing and bank credit financing. We characterize the conditions under which the supplier is willing to provide trade credit and those under which the retailer prefers bank credit or trade credit. We find that the supply chain member&#39;s risk aversion attitude plays an important role in determining the financing equilibrium. Contrasting with some existing studies, our results show that trade credit financing may lead to a win-win result only when the supplier&#39;s risk aversion threshold is moderate.},
  archive      = {J_EJOR},
  author       = {Honglin Yang and Wenyan Zhuo and Lusheng Shao and Srinivas Talluri},
  doi          = {10.1016/j.ejor.2021.01.042},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {525-542},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Mean-variance analysis of wholesale price contracts with a capital-constrained retailer: Trade credit financing vs. bank credit financing},
  volume       = {294},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Optimal sales and production rollover strategies under
capacity constraints. <em>EJOR</em>, <em>294</em>(2), 507–524. (<a
href="https://doi.org/10.1016/j.ejor.2021.01.040">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Firms regularly replace their old product generation by a newer generation to sustain and increase their market share and profit. The product rollover problem of deciding on the number of old products to be pre-produced before the introduction of the new generation, and then deciding on the prices, sales volumes, and production volumes of the old and the new generation during the introduction under capacity constraint is considered. Production capacity limitations are common during the introduction period of a new product. We provide the first study that examines how a production capacity constraint affects the optimal decisions. The optimal decisions for a deterministic period-based model are provided in closed-form. A single sales/production rollover strategy implies that the sales/production of the old generation is discontinued before introducing the new generation. With a dual sales/production rollover strategy, the old and the new generation are sold/produced simultaneously. Depending on the capacity shortage, there are two types of mitigation actions: (i) increasing the prices, (ii) changing the sales and/or production rollover strategies with pre-production while adjusting the prices accordingly. If the capacity is unlimited, aligned sales and production rollover strategies are always optimal. We establish the conditions under which limited capacity leads to a combination of a single production rollover with a dual sales rollover strategy. We show that the selection of optimal rollover strategies is non-monotone in the available capacity. This implies that a change in the rollover strategy in response to limiting capacity has to be revoked for more severe capacity shortages.},
  archive      = {J_EJOR},
  author       = {Justus Arne Schwarz and Barış Tan},
  doi          = {10.1016/j.ejor.2021.01.040},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {507-524},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Optimal sales and production rollover strategies under capacity constraints},
  volume       = {294},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The rank pricing problem with ties. <em>EJOR</em>,
<em>294</em>(2), 492–506. (<a
href="https://doi.org/10.1016/j.ejor.2021.02.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the Rank Pricing Problem (RPP), a firm intends to maximize its profit through the pricing of a set of products to sell. Customers are interested in purchasing at most one product among a subset of products. To do so, they are endowed with a ranked list of preferences and a budget. Their choice rule consists in purchasing the highest-ranked product in their list and whose price is below their budget. In this paper, we consider an extension of RPP, the Rank Pricing Problem with Ties (RPPT), in which we allow for indifference between products in the list of preferences of the customers. Considering the bilevel structure of the problem, this generalization differs from the RPP in that it can lead to multiple optimal solutions for the second level problems associated to the customers. In such cases, we look for pessimistic optimal solutions of the bilevel problem : the customer selects the cheapest product. We present a new three-indexed integer formulation for RPPT and introduce two resolution approaches. In the first one, we project out the customer decision variables, obtaining a reduced formulation that we then strengthen with valid inequalities from the former formulation. Alternatively, we follow a Benders decomposition approach leveraging the separability of the problem into a master problem and several subproblems. The separation problems to include the valid inequalities to the master problem dynamically are shown to reduce to min-cost flow problems. We finally carry out extensive computational experiments to assess the performance of the resolution approaches.},
  archive      = {J_EJOR},
  author       = {Concepción Domínguez and Martine Labbé and Alfredo Marín},
  doi          = {10.1016/j.ejor.2021.02.017},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {492-506},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {The rank pricing problem with ties},
  volume       = {294},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An improved configuration checking-based algorithm for the
unicost set covering problem. <em>EJOR</em>, <em>294</em>(2), 476–491.
(<a href="https://doi.org/10.1016/j.ejor.2021.02.015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Configuration Checking (CC) is a simple tool that can be added to local search algorithms to prevent cycling. The generic forms of CC and local search may not be suitable to solve large-scale unicost set covering problem (USCP) instances. Thus, in this study, we introduce an improved CC-based algorithm to solve USCPs. Unlike previous CC implementations that only consider subset states to prevent cycling, the proposed algorithm also checks the element states to minimize the number of subsets, in order to cut down unnecessary search spaces. Therefore, we refer to this technique as the element-state configuration checking (ES-CC) algorithm. Moreover, in our proposed algorithm, the score value (a numerical measure to differentiate between subsets) considers multiple levels of element covering. This multi-level scoring (MLS) value is a new powerful contribution compared to the single-level scoring used in previous CC algorithms. Using these two novel ideas, MLS and ES-CC, we implement the new MLSES-CC algorithm to solve the USCP. The MLSES-CC algorithm also implements a more aggressive local search routine that simultaneously changes the status of the three subsets. We use the MLSES-CC algorithm to solve 176 USCP instances that belong to standard and novel benchmarking sets and compare our results to the best-known USCP algorithms, in terms of solution quality and computation time. Computational experiments indicate that the MLSES-CC algorithm can be considered as a new state-of-the-art algorithm to solve USCPs.},
  archive      = {J_EJOR},
  author       = {Yiyuan Wang and Shiwei Pan and Sameh Al-Shihabi and Junping Zhou and Nan Yang and Minghao Yin},
  doi          = {10.1016/j.ejor.2021.02.015},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {476-491},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {An improved configuration checking-based algorithm for the unicost set covering problem},
  volume       = {294},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multistage robust mixed-integer optimization under
endogenous uncertainty. <em>EJOR</em>, <em>294</em>(2), 460–475. (<a
href="https://doi.org/10.1016/j.ejor.2021.01.048">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Endogenous, i.e. decision-dependent, uncertainty has received increased interest in the stochastic programming community. In the robust optimization context, however, it has rarely been considered. This work addresses multistage robust mixed-integer optimization with decision-dependent uncertainty sets. The proposed framework allows us to consider both continuous and integer recourse, including recourse decisions that affect the uncertainty set. We derive a tractable reformulation of the problem by leveraging recent advances in the construction of nonlinear decision rules, and introduce discontinuous piecewise linear decision rules for continuous recourse. Computational experiments are performed to gain insights on the impact of endogenous uncertainty, the benefit of discrete recourse, and computational performance. Our results indicate that the level of conservatism in the solution can be significantly reduced if endogenous uncertainty and mixed-integer recourse are properly modeled.},
  archive      = {J_EJOR},
  author       = {Wei Feng and Yiping Feng and Qi Zhang},
  doi          = {10.1016/j.ejor.2021.01.048},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {460-475},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Multistage robust mixed-integer optimization under endogenous uncertainty},
  volume       = {294},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Scheduling for gathering multitype data with local
computations. <em>EJOR</em>, <em>294</em>(2), 453–459. (<a
href="https://doi.org/10.1016/j.ejor.2021.01.043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we analyze scheduling gathering multitype data in a star network. Certain numbers of datasets of different types have to be collected on a single computer, either by downloading them from remote nodes, or by producing them locally. The time required to download a dataset depends on its type and initial location, and the time needed to produce a dataset depends only on its type. The scheduling problem is to decide which datasets should be downloaded from which nodes, and how many datasets of each type should be generated locally, in order to minimize the total time necessary for gathering all data. We show that this problem is NP-hard, indicate special cases solvable in polynomial time, and propose a fully polynomial time approximation scheme for a special case which is still NP-hard. For the general case, we present an integer linear programming formulation, a dynamic programming algorithm and a polynomial 2-approximation algorithm. The performance of these algorithms is tested in computational experiments.},
  archive      = {J_EJOR},
  author       = {Joanna Berlińska and Bartłomiej Przybylski},
  doi          = {10.1016/j.ejor.2021.01.043},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {453-459},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Scheduling for gathering multitype data with local computations},
  volume       = {294},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Maximizing the expected net present value in a project with
uncertain cash flows. <em>EJOR</em>, <em>294</em>(2), 442–452. (<a
href="https://doi.org/10.1016/j.ejor.2021.01.039">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper considers the problem of maximizing the expected net present value of a project under uncertain cash flows, which are described by a supporting set of discrete scenarios. While cash flows are often considered more or less stable in countries with stable economy, they can be quite uncertain in countries with financial and/or political crisis. In these countries, cash flows may drastically rise after a certain political event or a financial crisis. Therefore, we assume that the price changes may well occur after a predictable time (e.g., an election or the date on which a deal is agreed or broken). Such an assumption has never been made in project scheduling under uncertainty. We propose two integer linear programming (ILP) formulations and develop two-stage stochastic programming approaches that use Benders decomposition to solve the problem efficiently. Since the number of generated scenarios may be large and thus intractable, we also employ a forward scenario reduction technique to construct a rather tractable set of scenarios. Computational results indicate that the developed Benders-based methods outperform the ILP formulations.},
  archive      = {J_EJOR},
  author       = {Mahboobeh Peymankar and Morteza Davari and Mohammad Ranjbar},
  doi          = {10.1016/j.ejor.2021.01.039},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {442-452},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Maximizing the expected net present value in a project with uncertain cash flows},
  volume       = {294},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An almost exact solution to the min completion time variance
in a single machine. <em>EJOR</em>, <em>294</em>(2), 427–441. (<a
href="https://doi.org/10.1016/j.ejor.2021.01.038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a single machine scheduling problem to minimize the completion time variance of n n jobs. This problem is known to be NP-hard and our contribution is to establish a novel bounding condition for a characterization of an optimal sequence. Specifically, we prove a necessary and sufficient condition (which can be verified in O ( n log n ) O(nlogn) ) for the characterization of five scheduling positions in the optimal sequence. Applying this characterization, we propose a new approach to derive the highest lower bound for the minimal completion time variance, outperforming the existing bounds for this problem. The numerical tests indicate that the novel lower bound is, on average, less than 0.01\% 0.01\% far away from the optimal solution, outperforming all the existing lower bounds on the minimum completion time variance.},
  archive      = {J_EJOR},
  author       = {Stefano Nasini and Rabia Nessah},
  doi          = {10.1016/j.ejor.2021.01.038},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {427-441},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {An almost exact solution to the min completion time variance in a single machine},
  volume       = {294},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Planning and control of autonomous mobile robots for
intralogistics: Literature review and research agenda. <em>EJOR</em>,
<em>294</em>(2), 405–426. (<a
href="https://doi.org/10.1016/j.ejor.2021.01.019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autonomous mobile robots (AMR) are currently being introduced in many intralogistics operations, like manufacturing, warehousing, cross-docks, terminals, and hospitals. Their advanced hardware and control software allow autonomous operations in dynamic environments. Compared to an automated guided vehicle (AGV) system in which a central unit takes control of scheduling, routing, and dispatching decisions for all AGVs, AMRs can communicate and negotiate independently with other resources like machines and systems and thus decentralize the decision-making process. Decentralized decision-making allows the system to react dynamically to changes in the system state and environment. These developments have influenced the traditional methods and decision-making processes for planning and control. This study identifies and classifies research related to the planning and control of AMRs in intralogistics. We provide an extended literature review that highlights how AMR technological advances affect planning and control decisions. We contribute to the literature by introducing an AMR planning and control framework to guide managers in the decision-making process, thereby supporting them to achieve optimal performance. Finally, we propose an agenda for future research within this field.},
  archive      = {J_EJOR},
  author       = {Giuseppe Fragapane and René de Koster and Fabio Sgarbossa and Jan Ola Strandhagen},
  doi          = {10.1016/j.ejor.2021.01.019},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {405-426},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Planning and control of autonomous mobile robots for intralogistics: Literature review and research agenda},
  volume       = {294},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Corrigendum to “group decisions from individual rankings:
The borda–condorcet rule” [european journal of operational research,
volume 291, issue 2, 1 june 2021, pages 757-765]. <em>EJOR</em>,
<em>294</em>(1), 404. (<a
href="https://doi.org/10.1016/j.ejor.2021.02.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_EJOR},
  author       = {Carmen Herrero and Antonio Villar},
  doi          = {10.1016/j.ejor.2021.02.001},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {404},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Corrigendum to ‘Group decisions from individual rankings: The Borda–Condorcet rule’ [European journal of operational research, volume 291, issue 2, 1 june 2021, pages 757-765]},
  volume       = {294},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Managing the intake of new patients into a physician panel
over time. <em>EJOR</em>, <em>294</em>(1), 391–403. (<a
href="https://doi.org/10.1016/j.ejor.2021.01.035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article focuses on balancing supply and demand for physicians and panel patients on a tactical level to ensure a manageable workload for the physician and access to care for patients. Patients are part of the physician’s panel if they visit the physician somewhat regularly. For the first time, we propose deterministic integer linear programs that decide on the intake of new patients into panels over time, taking into account the future panel development. The main objective is to minimize the deviation between the expected panel workload and the physician’s capacity over time. We classify panel patients with respect to age and the number of visits in a period and assume a transition probability from one visit category to another from one period to the next. We can include stationary patient attributes and consider several physicians together. The programs work with aggregation levels for the new patients’ demand concerning the patient attributes. We conduct experiments with parameters based on real-world data. We consider the transition between visit categories and the new patients’ demand to be stochastic in a discrete-event simulation. We define upper bounds on the number of patients in a patient class to be accepted in a period through solving the programs several times with different demand inputs. Even in this uncertain environment, we can significantly reduce the expected differences between workload and capacity over time, taking into account several future periods instead of one. Using a detailed classification of new patients decreases the expected differences further.},
  archive      = {J_EJOR},
  author       = {Anne Zander and Stefan Nickel and Peter Vanberkel},
  doi          = {10.1016/j.ejor.2021.01.035},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {391-403},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Managing the intake of new patients into a physician panel over time},
  volume       = {294},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The crop growth planning problem in vertical farming.
<em>EJOR</em>, <em>294</em>(1), 377–390. (<a
href="https://doi.org/10.1016/j.ejor.2021.01.034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study the problem of planning the growth of crops on shelves in vertical farming cabinets under controlled growth conditions. By adjusting temperature, humidity, light, and other environmental conditions in different parts of the cabinets, a planner must ensure that crop growth is able to satisfy some deterministic demand. We prove this problem to be NP -hard and propose an integer programming formulation able to capture real-life operational characteristics, including changes of growth conditions on a daily, shelf-by-shelf basis, over a planning horizon of months. We compare four objective functions from which a planner can choose, depending on the specific operations of the company. A computational study on realistic instances, which we make available as a public dataset, shows that the choice of objective function heavily influences both the difficulty of solving the model with a standard solver and the solution characteristics.},
  archive      = {J_EJOR},
  author       = {Alberto Santini and Enrico Bartolini and Michael Schneider and Vinicius Greco de Lemos},
  doi          = {10.1016/j.ejor.2021.01.034},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {377-390},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {The crop growth planning problem in vertical farming},
  volume       = {294},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A bin packing approach to solve the aircraft maintenance
task allocation problem. <em>EJOR</em>, <em>294</em>(1), 365–376. (<a
href="https://doi.org/10.1016/j.ejor.2021.01.027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the scheduling of aircraft maintenance tasks that must be carried out in multiple maintenance checks to keep a fleet of aircraft airworthy. The allocation of maintenance tasks to maintenance opportunities, also known as the task allocation problem (TAP), is a complex combinatorial problem that needs to be solved daily by maintenance operators. We propose a novel approach capable of efficiently solving the multi-year task allocation problem for a fleet of aircraft in a few minutes. We formulate this problem as a time-constrained variable-sized bin packing problem (TC-VS-BPP), extending the well-known variable-sized bin packing problem (VS-BPP) by adding deadlines, intervals, and arrivals for the repetition of tasks. In particular, we divide the planning horizon into variable size bins to which multidimensional tasks are allocated, subject to available labor power and task deadlines. To solve this problem, we propose a constructive heuristic based on the worst-fit decreasing (WFD) algorithm for TC-VS-BPP. The heuristic is tested and validated using the maintenance data of 45 aircraft from a European airline. Compared with the solution obtained with an approach using an exact method, the proposed heuristic is more than 30\% faster for all the test cases discussed with the airline. Most of the cases have optimality gaps below 3\%. Even for the extreme case, the optimality gap is still smaller than 5\%.},
  archive      = {J_EJOR},
  author       = {Max Witteman and Qichen Deng and Bruno F. Santos},
  doi          = {10.1016/j.ejor.2021.01.027},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {365-376},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A bin packing approach to solve the aircraft maintenance task allocation problem},
  volume       = {294},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Improving connectivity of compromised digital networks via
algebraic connectivity maximisation. <em>EJOR</em>, <em>294</em>(1),
353–364. (<a href="https://doi.org/10.1016/j.ejor.2021.01.015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automation and digitalisation in the logistics industry enhance the performance of customer service, while sabotage of the digital logistics network adversely deteriorates the performance. Although precautionary strategies are implemented to protect critical assets in the digital logistics network, a high-level adversary can still penetrate the network and launch attacks inside the organisation. Thus, real-time recovery plays an important role in facing real-time cyberattacks. This paper proposes a novel max-min integer programming model subject to a budget constraint to improve network connectivity of a compromised digital logistics network via a strategy of maximising algebraic connectivity. Due to the NP-hardness of the maximisation problem, the optimal solution may not be found quickly. Thus, several heuristic algorithms, including greedy algorithms, tabu search and relaxed semidefinite programming (SDP) with rounding, are proposed. Verification of these heuristic algorithms is achieved by applying them, firstly to a hypothetical network, then to a large scale-free network which mimics a digital logistics network.},
  archive      = {J_EJOR},
  author       = {Kam-Fung Cheung and Michael G.H. Bell},
  doi          = {10.1016/j.ejor.2021.01.015},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {353-364},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Improving connectivity of compromised digital networks via algebraic connectivity maximisation},
  volume       = {294},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Underground mine scheduling under uncertainty.
<em>EJOR</em>, <em>294</em>(1), 340–352. (<a
href="https://doi.org/10.1016/j.ejor.2021.01.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Underground mine schedules seek to determine start dates for activities related to the extraction of ore, often with an objective of maximizing net present value; constraints enforce geotechnical precedence between activities, and restrict resource consumption on a per-time-period basis, e.g., development footage and extracted tons. Strategic schedules address these start dates at a coarse level, whereas tactical schedules must account for the day-to-day variability of underground mine operations, such as unanticipated equipment breakdowns and ground conditions, both of which might slow production. At the time of this writing, the underground mine scheduling literature is dominated by a deterministic treatment of the problem, usually modeled as a Resource Constrained Project Scheduling Problem (RCPSP), which precludes mine operators from reacting to unforeseen circumstances. Therefore, we propose a stochastic integer programming framework that: (i) characterizes uncertainty in duration and economic value for each underground mining activity; (ii) formulates a new stochastic variant of the RCPSP; (iii) suggests an optimization-based heuristic; and, (iv) produces implementable, tactical schedules in a practical amount of time and provides corresponding managerial insights.},
  archive      = {J_EJOR},
  author       = {Peter Nesbitt and Lewis R. Blake and Patricio Lamas and Marcos Goycoolea and Bernardo K. Pagnoncelli and Alexandra Newman and Andrea Brickey},
  doi          = {10.1016/j.ejor.2021.01.011},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {340-352},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Underground mine scheduling under uncertainty},
  volume       = {294},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Modelling a multi-period production process: Evidence from
the japanese regional banks. <em>EJOR</em>, <em>294</em>(1), 327–339.
(<a href="https://doi.org/10.1016/j.ejor.2021.01.036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper applies the additive relational network DEA model to examine the multi-period efficiency and productivity of Regional Banks I and II in Japan between 2002 and 2017. The examined timeframe covers two turbulent periods; the Global Financial Crisis and the economic recession in the aftermath of the Great East Japan Earthquake. We extend the additive relational network DEA model into a multi-period structure in order to evaluate the overall efficiency for the time period in question, as well as the annual period efficiencies. We show that the overall efficiency can be expressed as a weighted average of the period efficiencies. In addition, we examine the implications of different returns to scale assumptions. The newly proposed model is able to calculate common-weight Malmquist Productivity Indices. The results reveal a dispersion of inefficiency levels for Japanese Regional Banks in general, and a difference between Regional Banks I and II in particular. Furthermore, the Global Financial Crisis caused a significant negative effect on the productivity growth and the technical progress of Japanese Regional Banks, while the Great East Japan Earthquake had a negative effect on the technical efficiency change.},
  archive      = {J_EJOR},
  author       = {Stavros Kourtzidis and Roman Matousek and Nickolaos G. Tzeremes},
  doi          = {10.1016/j.ejor.2021.01.036},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {327-339},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Modelling a multi-period production process: Evidence from the japanese regional banks},
  volume       = {294},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Making inference of british household’s happiness
efficiency: A bayesian latent model. <em>EJOR</em>, <em>294</em>(1),
312–326. (<a href="https://doi.org/10.1016/j.ejor.2021.01.031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a novel approach whereby happiness for British households is identified within a latent model frontier analysis using longitudinal data. By doing so we overcome issues related to the measurement of happiness. To estimate happiness frontier and thereby happiness efficiency, we employ a Bayesian inference procedure organized around Sequential Monte Carlo (SMC) particle filtering techniques. In addition, we propose to consider individual-specific characteristics by estimating happiness efficiency models with individual-specific thresholds to happiness. This is the first study that treats happiness as a latent variable and departs from restrictions that happiness efficiency would be time invariant. Our results show that happiness efficiency is related to the welfare loss associated with potentially misusing the resources that British individuals have at their disposal. Key to happiness is to have certain personality traits, such as being agreeable and extravert as they assist efforts to enhance happiness efficiency. On the other hand, being neurotic impairs happiness efficiency.},
  archive      = {J_EJOR},
  author       = {Emmanuel C. Mamatzakis and Mike G. Tsionas},
  doi          = {10.1016/j.ejor.2021.01.031},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {312-326},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Making inference of british household&#39;s happiness efficiency: A bayesian latent model},
  volume       = {294},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Strong, weak and farrell efficient frontiers of technologies
satisfying different production assumptions. <em>EJOR</em>,
<em>294</em>(1), 295–311. (<a
href="https://doi.org/10.1016/j.ejor.2021.01.022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The literature on data envelopment analysis (DEA) and, more broadly, production theory employs different notions of efficiency for the characterization of boundary points of production technologies. These include the strong and weak (Pareto) efficiency, and the Farrell input and output efficiency. For the conventional constant and variable returns-to-scale technologies, the relationship between the different notions of efficiency has been explored in the literature and is well understood now. In this paper we show that, in the general case, which includes many recently developed technologies, the conventional relationship between the different notions of efficiency is no longer valid. We show that such relationship depends on the properties of a particular technology such as convexity, disposability and returns-to-scale characteristics. Our results are applicable to many new technologies for which the different notions of efficiency and methods of their testing have not been fully explored.},
  archive      = {J_EJOR},
  author       = {Mahmood Mehdiloo and Victor V. Podinovski},
  doi          = {10.1016/j.ejor.2021.01.022},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {295-311},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Strong, weak and farrell efficient frontiers of technologies satisfying different production assumptions},
  volume       = {294},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Production scale-based two-stage network data envelopment
analysis. <em>EJOR</em>, <em>294</em>(1), 283–294. (<a
href="https://doi.org/10.1016/j.ejor.2021.01.020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We develop a new network data envelopment analysis (DEA) approach for two-stage network systems considering a match between the production scale of the substages and the intermediate measure levels. Several explicit production axioms are introduced to build a production possibility set. New models are developed based on the production possibility set and a frontier projection procedure with the production scale matching process. Unlike the existing approach which assumes the intermediate measures are free-setting decision variables, the new envelopment network DEA models project the intermediate measures of a unit using the radial projection technique. Correspondingly, the resulting multiplier network DEA models allow for weight flexibility on the intermediate measures while holding a total value flow equivalence between a unit&#39;s two stages. We show that our approach does not suffer the known network DEA pitfalls. It identifies the overall efficiency, divisional efficiencies, and frontier projection using either an envelopment or a multiplier network DEA model, i.e., the primal-dual correspondence holds in our approach. Our approach also avoids uncertainties in determining divisional efficiencies by generating a unique pair of divisional efficiencies for each unit. Additionally, the adoption of the production scale matching process explains clearly the frontier projection procedure from the practical point of view. The proposed approach is illustrated with a numerical example and compared with the existing approaches with a case study of commercial bank branches.},
  archive      = {J_EJOR},
  author       = {Junfei Chu and Joe Zhu},
  doi          = {10.1016/j.ejor.2021.01.020},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {283-294},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Production scale-based two-stage network data envelopment analysis},
  volume       = {294},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Effects of decision training on individuals’ decision-making
proactivity. <em>EJOR</em>, <em>294</em>(1), 264–282. (<a
href="https://doi.org/10.1016/j.ejor.2021.01.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Decision sciences are in general agreement on the theoretical relevance of decision training. From an empirical standpoint, however, only a few studies test its effectiveness or practical usefulness, and even less address the impact of decision training on the structuring of problems systematically. Yet that task is widely considered to be the most crucial in decision-making processes, and current research suggests that effectively structuring problems and generating alternatives—as epitomized by the concept of proactive decision making —increases satisfaction with the decision as well as life satisfaction more generally. This paper empirically tests the effect of decision training on two facets of proactive decision making—cognitive skills and personality traits—and on decision satisfaction. In quasi-experimental field studies based on three distinct decision-making courses and two control groups, we analyze longitudinal data on 1,013 decision makers/analysts with different levels of experience. The results reveal positive training effects on proactive cognitive skills and decision satisfaction, but we find no effect on proactive personality traits and mostly non-significant interactions between training and experience. These results imply the practical relevance of decision training as a means to promote effective decision making even by more experienced decision makers. The findings presented here may be helpful for operations research scholars who advocate for specific instruction concerning proactive cognitive skills in courses dedicated to decision quality and/or decision theory and also for increasing, in such courses, participants’ proactive decision making and decision satisfaction. Our results should also promote more positive decision outcomes.},
  archive      = {J_EJOR},
  author       = {Johannes Ulrich Siebert and Reinhard E. Kunz and Philipp Rolf},
  doi          = {10.1016/j.ejor.2021.01.010},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {264-282},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Effects of decision training on individuals’ decision-making proactivity},
  volume       = {294},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Designing interagency responses to wicked problems: Creating
a common, cross-agency understanding. <em>EJOR</em>, <em>294</em>(1),
250–263. (<a href="https://doi.org/10.1016/j.ejor.2020.11.045">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wicked problems are open-ended, highly interdependent issues that cross agency, stakeholder, jurisdictional, and geopolitical boundaries. In response, there has been advocacy for interagency working. However, this confounds conventional approaches to government because policies and budgets tend to be aligned within organizational boundaries and not across them, making it difficult to bring the appropriate talent, knowledge and assets into an interagency approach to tackle the interdependencies of whatever wicked problem is at hand. In addition, the purposes, perspectives and values of the various government agencies and other stakeholders can often be in conflict. This paper reports on research to develop and evaluate a systemic intervention approach involving the use of multiple methods underpinned by boundary critique to address a wicked problem. The major focus is how to create a common understanding of a wicked problem among multiple agencies using a participatory problem structuring method called ‘systemic perspective mapping’. The wicked problem we tackled was international organized drug crime and its intersection with local urban gang activity (using Chicago, USA, as a representative city). Perspectives on the problem were structured with participation from various local, regional and federal agencies involved in countering illegal drug trafficking. Our research found that the combined use of boundary critique and systemic perspective mapping was able to generate enough of a common understanding to provide a foundation for the design of an interagency organization using the viable system model (the latter is reported elsewhere in the literature).},
  archive      = {J_EJOR},
  author       = {Pamela Sydelko and Gerald Midgley and Angela Espinosa},
  doi          = {10.1016/j.ejor.2020.11.045},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {250-263},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Designing interagency responses to wicked problems: Creating a common, cross-agency understanding},
  volume       = {294},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Principal component analysis: A generalized gini approach.
<em>EJOR</em>, <em>294</em>(1), 236–249. (<a
href="https://doi.org/10.1016/j.ejor.2021.02.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A principal component analysis based on the generalized Gini correlation index is proposed (Gini PCA). The Gini PCA generalizes the standard PCA based on the variance. It is shown, in the Gaussian case, that the standard PCA is equivalent to the Gini PCA. It is also proven that the dimensionality reduction based on the generalized Gini correlation matrix, that relies on city-block distances, is robust to outliers. Monte Carlo simulations and an application on cars data (with outliers) show the robustness of the Gini PCA and provide different interpretations of the results compared with the variance PCA.},
  archive      = {J_EJOR},
  author       = {Arthur Charpentier and Stéphane Mussard and Téa Ouraga},
  doi          = {10.1016/j.ejor.2021.02.010},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {236-249},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Principal component analysis: A generalized gini approach},
  volume       = {294},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Dynamic routing in a distributed parallel many-server
service system: The effect of ξ-choice. <em>EJOR</em>, <em>294</em>(1),
219–235. (<a href="https://doi.org/10.1016/j.ejor.2021.01.026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a queueing system with multiple stations serving a single class of customers. Each station has many servers, and its own dedicated queue. The system manager must decide to which station each new customer is routed. We propose and analyze a minimum-expected-delay faster-server-first with ξ ξ -choice ( MED-FSF ( ξ ) MED-FSF(ξ) ) routing policy, under which an integer ξ , ξ, with P { ξ ≥ 2 } &gt; 0 , P{ξ≥2}&amp;gt;0, is randomly generated for each new customer. Then, a subset of ξ ξ stations will be randomly collected, with state information being retrieved. Among these collected stations, the system manager assigns the new customer to: (i) the one with minimum expected delay if all these ξ ξ stations are fully occupied; or (ii) the one with fastest available server. We prove that in the Halfin–Whitt regime this policy is asymptotically equivalent to the MED-FSF policy, which only works when full information of the system state is available. Moreover, we compare the MED-FSF ( ξ ) MED-FSF(ξ) policy with the random routing policy, which uses no information and routes each incoming customer to a station in a random manner. Using simulation experiments, we validate the theoretical results, and find that our proposed policy significantly outperforms the random routing policy. This suggests that a slight increase in information at each routing epoch can substantially improve system performance.},
  archive      = {J_EJOR},
  author       = {Ping Cao and Zhiheng Zhong and Junfei Huang},
  doi          = {10.1016/j.ejor.2021.01.026},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {219-235},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Dynamic routing in a distributed parallel many-server service system: The effect of ξ-choice},
  volume       = {294},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Discriminant analysis of distributional data via fractional
programming. <em>EJOR</em>, <em>294</em>(1), 206–218. (<a
href="https://doi.org/10.1016/j.ejor.2021.01.025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We address classification of distributional data, where units are described by histogram or interval-valued variables. The proposed approach uses a linear discriminant function where distributions or intervals are represented by quantile functions, under specific assumptions. This discriminant function allows defining a score for each unit, in the form of a quantile function, which is used to classify the units in two a priori groups, using the Mallows distance. There is a diversity of application areas for the proposed linear discriminant method. In this work we classify the airline companies operating in NY airports based on air time and arrival/departure delays, using a full year flights.},
  archive      = {J_EJOR},
  author       = {Sónia Dias and Paula Brito and Paula Amaral},
  doi          = {10.1016/j.ejor.2021.01.025},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {206-218},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Discriminant analysis of distributional data via fractional programming},
  volume       = {294},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Exact algorithms for the multi-compartment vehicle routing
problem with flexible compartment sizes. <em>EJOR</em>, <em>294</em>(1),
188–205. (<a href="https://doi.org/10.1016/j.ejor.2021.01.037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The multi-compartment vehicle routing problem with flexible compartment sizes is a variant of the classical vehicle routing problem in which customers demand different product types and the vehicle capacity can be separated into different compartments each dedicated to a specific product type. The size of each compartment is not fixed beforehand but the number of compartments is limited. We consider two variants for dividing the vehicle capacity: On the one hand the vehicle capacity can be discretely divided into compartments and on the other hand compartment sizes can be divided continuously. The objective is to minimize the total distance of all vehicle routes such that all customer demands are met and vehicle capacities are respected. Modifying a branch-and-cut algorithm based on a three-index formulation for the discrete problem variant from the literature, we introduce an exact solution approach that is tailored to the continuous problem variant. Moreover, we propose two other exact solution approaches, namely a branch-and-cut algorithm based on a two-index formulation and a branch-price-and-cut algorithm based on a route-indexed formulation, that can tackle both problem variants with small adaptions and can be combined into an effective two-stage approach. Extensive computational tests have been conducted to compare the different algorithms. For the continuous variant, we can solve instances with up to 50 customers to optimality and for the discrete variant, several previously open instances can now be solved to proven optimality. Moreover, we analyze the cost savings of using continuously flexible compartment sizes instead of discretely flexible compartment sizes.},
  archive      = {J_EJOR},
  author       = {Katrin Heßler},
  doi          = {10.1016/j.ejor.2021.01.037},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {188-205},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Exact algorithms for the multi-compartment vehicle routing problem with flexible compartment sizes},
  volume       = {294},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Benefits of third-party logistics firms as financing
providers. <em>EJOR</em>, <em>294</em>(1), 174–187. (<a
href="https://doi.org/10.1016/j.ejor.2021.01.024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We investigate the design of a supplier’s wholesale price contract and a third-party logistics (3PL) firm’s joint logistics and financing services contract in a three-tier supply chain comprising a supplier, a 3PL firm, and a newsvendor-like retailer with capital constraints. The retailer can apply for bank financing or 3PL financing for purchasing when necessary. All members engage in a Stackelberg game with the supplier functioning as the leader. Our analysis indicates that the 3PL who finances the retailer with a low interest rate induces the retailer to order more, thereby causing the 3PL to obtain more profit from logistics services. The supplier benefits from 3PL financing by receiving a larger order from the retailer. Compared with bank financing, a retailer whose working capital level is not too low can benefit more with 3PL financing owing to lower purchasing (ordering and transportation costs) and financing costs. We further conclude that all members’ optimal decisions remain unchanged when the 3PL is also capital constrained but can borrow from a bank. We examine the retailer and supplier’s issues when the 3PL functions as the game leader instead of the supplier, and numerically demonstrate that the retailer and 3PL are better off while the supplier is worse off under 3PL leadership. Our results explain why 3PLs are willing to finance retailers’ inventories in business practice and suggest that 3PLs should set low financing interest rates to improve channel performances.},
  archive      = {J_EJOR},
  author       = {Shengya Hua and Shuxiao Sun and Zhongyi Liu and Xin Zhai},
  doi          = {10.1016/j.ejor.2021.01.024},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {174-187},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Benefits of third-party logistics firms as financing providers},
  volume       = {294},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A comparison of pure manufacturing and hybrid
manufacturing–remanufacturing systems under carbon tax policy.
<em>EJOR</em>, <em>294</em>(1), 161–173. (<a
href="https://doi.org/10.1016/j.ejor.2021.01.018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Collection and remanufacturing of used products can be considered as one of the options to improve the sustainability of a manufacturing system. In this study, we focus on production and sustainability level decisions in pure manufacturing and hybrid manufacturing–remanufacturing systems and compare the systemwide performances and the performances of supply chain actors under different settings in terms of economic and environmental performance measures. We consider four settings as follows. In the first setting, no remanufacturing is made and only the manufactured products are sold via the retailer, whereas in the second, the third and the fourth settings, used products are collected and remanufactured by the manufacturer, the retailer and a third-party remanufacturer, respectively. Under all settings, we put the emissions resulting from the manufacturing and remanufacturing processes into account and consider one of the well-known emission policies, the carbon tax policy. We propose stylized models for the centralized and decentralized cases of each setting and analyze the decisions obtained under optimal or equilibrium solution. Based on our analysis, we observe that since the upper bound on the remanufacturing quantity depends on the manufacturing quantity, the manufacturer uses manufacturing quantity as a strategic power to compete with the retailer or the third-party remanufacturer. Moreover, in the same condition, the manufacturer always remanufactures less products compared to retailer or third-party remanufacturer since he considers the negative effect of remanufactured products on manufactured products.},
  archive      = {J_EJOR},
  author       = {Mehmet Alegoz and Onur Kaya and Z. Pelin Bayindir},
  doi          = {10.1016/j.ejor.2021.01.018},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {161-173},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A comparison of pure manufacturing and hybrid manufacturing–remanufacturing systems under carbon tax policy},
  volume       = {294},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Understanding forecast reconciliation. <em>EJOR</em>,
<em>294</em>(1), 149–160. (<a
href="https://doi.org/10.1016/j.ejor.2021.01.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A series of recent papers introduce the concept of Forecast Reconciliation, a process by which independently generated forecasts of a collection of linearly related time series are reconciled via the introduction of accounting aggregations that naturally apply to the data. Aside from its clear presentational and operational virtues, the reconciliation approach generally improves the accuracy of the combined forecasts. In this paper, we examine the mechanisms by which this improvement is generated by re-formulating the reconciliation problem as a combination of direct forecasts of each time series with additional indirect forecasts derived from the linear constraints. Our work establishes a direct link between the nascent Forecast Reconciliation literature and the extensive work on Forecast Combination. In the original hierarchical setting, our approach clarifies for the first time how unbiased forecasts for the entire collection can be generated from base forecasts made at any level of the hierarchy, and we illustrate more generally how simple robust combined forecasts can be generated in any multivariate setting subject to linear constraints. In an empirical example, we show that simple combinations of such forecasts generate significant improvements in forecast accuracy where it matters most: where noise levels are highest and the forecasting task is at its most challenging.},
  archive      = {J_EJOR},
  author       = {Ross Hollyman and Fotios Petropoulos and Michael E. Tipping},
  doi          = {10.1016/j.ejor.2021.01.017},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {149-160},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Understanding forecast reconciliation},
  volume       = {294},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Strategic substitutes or complements? The relationship
between capacity sharing and postponement flexibility. <em>EJOR</em>,
<em>294</em>(1), 138–148. (<a
href="https://doi.org/10.1016/j.ejor.2021.01.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To address supply-demand mismatch, firms can develop postponement flexibility in advance, which can shorten their production lead-time by allowing for production after demand is observed, or they can reach capacity sharing agreements and share the leftover capacity with each other. We develop a game model of two symmetric firms, and compare their optimal capacity strategies under two scenarios: with and without capacity sharing. In particular, we focus on the relationship between postponement flexibility and capacity sharing. We find that postponement flexibility and capacity sharing may be either complements or substitutes. Specifically, counter intuitively, when capacity costs are relatively high, these two methods are complemented; otherwise, they are substituted. Moreover, we show that a higher demand correlation between firms always decreases substitutability while increases complementarity when the capacity transfer price is relatively low. In addition, a higher capacity transfer price also reduces substitutability and reinforces complementarity. Finally, we find that capacity sharing stimulates firms to invest at a medium capacity level to largely achieve broad supply-demand matching between firms and may incentivize them to adopt different capacity types.},
  archive      = {J_EJOR},
  author       = {Liqun Wei and Jianxiong Zhang},
  doi          = {10.1016/j.ejor.2021.01.016},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {138-148},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Strategic substitutes or complements? the relationship between capacity sharing and postponement flexibility},
  volume       = {294},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A dynamic perspective of government intervention in a
competitive closed-loop supply chain. <em>EJOR</em>, <em>294</em>(1),
122–137. (<a href="https://doi.org/10.1016/j.ejor.2021.01.014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Changes in environmental burden are inherently dynamic because a steady state cannot be instantaneously reached, and the current state is associated with the previous state and continuously evolves. In this study, we examine a dynamic closed-loop supply chain (CLSC) consisting of an original equipment manufacturer (OEM) selling new products and an independent remanufacturer (IR) selling recovered products generated from end-of-life (EOL) products. The government intervenes in the CLSC by imposing taxes or subsidies to reduce the environmental burden. We propose a baseline model without government intervention and six different policies: a fixed tax or subsidy on the firm side, a unit tax or subsidy on the firm side, and a unit tax or subsidy on the consumer side. We derive the firms’ closed-form instantaneous and steady-state decisions at the subgame perfect Nash equilibrium. Finally, we conduct a comparative study to explore the effects of the policies on the environmental burden, firm profits (producer surpluses), consumer surplus, and social welfare. We find that the proposed policies can effectively reduce the environmental burden and mitigate the intensity of price competition, except for the policy with the fixed subsidy to the IR. The policies are all profitable for the IR and, thus, effective in encouraging recovery; however, the policies are not necessarily profitable for the OEM. The policies with a unit tax for consumers and fixed subsidy for the OEM are more conducive to social welfare. Moreover, the degree of dynamics improves the effectiveness of the policies in reducing the environmental burden.},
  archive      = {J_EJOR},
  author       = {Cheng-Han Wu},
  doi          = {10.1016/j.ejor.2021.01.014},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {122-137},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A dynamic perspective of government intervention in a competitive closed-loop supply chain},
  volume       = {294},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Channel efficiency and retailer tier dominance in a supply
chain with a common manufacturer. <em>EJOR</em>, <em>294</em>(1),
100–121. (<a href="https://doi.org/10.1016/j.ejor.2021.01.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a two-tier supply chain with manufacturing as the upstream tier and retailing as the downstream tier. We focus on investigating the impact of the retailers’ competition vis-à-vis their relative positioning within the retailing tier on the performance of the supply chain. Further, we develop a stylized game-theoretic model, where a manufacturer is the leader, while multiple competing retailers are its followers. We look to generate three distinct supply chain structures by varying the positioning (tier dominance) of one retailer with the other retailer(s): (i) simultaneous setting, (ii) sequential setting, and (iii) cooperative setting. Our analysis reveals some interesting insights regarding the impact of these distinct supply chain structures on channel efficiency. For instance, we find that the supply chain becomes the most efficient under the sequential setting. The economic rationale behind this non-intuitive result is rooted in how retailers’ relative positioning in the retailing tier interacts with double marginalization. Additionally, our results suggest that retailers’ tier dominance leads to a “win-win” outcome where both the supply chain and consumers are better off. Under the sequential setting, we determine the optimal number of tier-dominant retailers while maximizing channel efficiency. Finally, using numerical studies, we investigate the impact of the degree of product substitution on channel efficiency, whereby, we find that, under the simultaneous setting, channel efficiency monotonically increases in the degree of product differentiation, which essentially is not always monotone in the sequential setting. We also demonstrate how the power imbalance between retailers complements the theory of countervailing power.},
  archive      = {J_EJOR},
  author       = {Abhishek Chakraborty and Prasenjit Mandal},
  doi          = {10.1016/j.ejor.2021.01.013},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {100-121},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Channel efficiency and retailer tier dominance in a supply chain with a common manufacturer},
  volume       = {294},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Computing optimal (r,s,s) policy parameters by a hybrid of
branch-and-bound and stochastic dynamic programming. <em>EJOR</em>,
<em>294</em>(1), 91–99. (<a
href="https://doi.org/10.1016/j.ejor.2021.01.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A well-known control policy in stochastic inventory control is the ( R , s , S ) (R,s,S) policy, in which inventory is raised to an order-up-to-level S at a review instant R whenever it falls below reorder-level s . To date, little or no work has been devoted to developing approaches for computing ( R , s , S ) (R,s,S) policy parameters. In this work, we introduce a hybrid approach that exploits tree search to compute optimal replenishment cycles, and stochastic dynamic programming to compute ( s , S ) (s,S) levels for a given cycle. Up to 99.8\% of the search tree is pruned by a branch-and-bound technique with bounds generated by dynamic programming. A numerical study shows that the method can solve instances of realistic size in a reasonable time.},
  archive      = {J_EJOR},
  author       = {Andrea Visentin and Steven Prestwich and Roberto Rossi and S. Armagan Tarim},
  doi          = {10.1016/j.ejor.2021.01.012},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {91-99},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Computing optimal (R,s,S) policy parameters by a hybrid of branch-and-bound and stochastic dynamic programming},
  volume       = {294},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An efficient lagrangian-based heuristic to solve a
multi-objective sustainable supply chain problem. <em>EJOR</em>,
<em>294</em>(1), 70–90. (<a
href="https://doi.org/10.1016/j.ejor.2021.01.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sustainable Supply Chain (SSC) management aims at integrating economic, environmental and social goals to assist in the long-term planning of a company and its supply chains. There is no consensus in the literature as to whether social and environmental responsibilities are profit-compatible. However, the conflicting nature of these goals is explicit when considering specific assessment measures and, in this scenario, multi-objective optimization is a way to represent problems that simultaneously optimize the goals. This paper proposes a Lagrangian matheuristic method, called AugMathLagr , to solve a hard and relevant multi-objective problem found in the literature. AugMathLagr was extensively tested using artificial instances defined by a generator presented in this paper. The results show a competitive performance of AugMathLagr when compared with an exact multi-objective method limited by time and a matheuristic recently proposed in the literature and adapted here to address the studied problem. In addition, computational results on a case study are presented and analyzed, and demonstrate the outstanding performance of AugMathLagr .},
  archive      = {J_EJOR},
  author       = {Camila P.S. Tautenhain and Ana Paula Barbosa-Povoa and Bruna Mota and Mariá C.V. Nascimento},
  doi          = {10.1016/j.ejor.2021.01.008},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {70-90},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {An efficient lagrangian-based heuristic to solve a multi-objective sustainable supply chain problem},
  volume       = {294},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A branch-and-cut algorithm for the edge interdiction clique
problem. <em>EJOR</em>, <em>294</em>(1), 54–69. (<a
href="https://doi.org/10.1016/j.ejor.2021.01.030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given a graph G and an interdiction budget k∈N, the Edge Interdiction Clique Problem (EICP) asks to find a subset of at most k edges to remove from G so that the size of the maximum clique, in the interdicted graph, is minimized. The EICP belongs to the family of interdiction problems with the aim of reducing the clique number of the graph. The EICP optimal solutions, called optimal interdiction policies, determine the subset of most vital edges of a graph which are crucial for preserving its clique number. We propose a new set-covering-based Integer Linear Programming (ILP) formulation for the EICP with an exponential number of constraints, called the clique-covering inequalities . We design a new branch-and-cut algorithm which is enhanced by a tailored separation procedure and by an effective heuristic initialization phase. Thanks to the new exact algorithm, we manage to solve the EICP in several sets of instances from the literature. Extensive tests show that the new exact algorithm greatly outperforms the state-of-the-art approaches for the EICP.},
  archive      = {J_EJOR},
  author       = {Fabio Furini and Ivana Ljubić and Pablo San Segundo and Yanlu Zhao},
  doi          = {10.1016/j.ejor.2021.01.030},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {54-69},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A branch-and-cut algorithm for the edge interdiction clique problem},
  volume       = {294},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The balanced maximally diverse grouping problem with block
constraints. <em>EJOR</em>, <em>294</em>(1), 42–53. (<a
href="https://doi.org/10.1016/j.ejor.2021.01.029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paper investigates the assignment of items to groups such that all groups are balanced, i.e. all groups contain the same number of items and all pairs of groups are as homogeneous as possible regarding the attribute values of the assigned items. Therefore, we adapt the maximally diverse grouping problem (MDGP). It is especially known in the context of students being assigned to groups. We describe the set of optimal solutions for the MDGP for realistic input data and develop a new linear objective function to determine the best balanced solution amongst all optimal solutions for the MDGP by weighting the biggest diversity between two groups with a higher value than the second biggest and so on. Furthermore, an integer program, a detailed complexity analysis, and a computational study are presented.},
  archive      = {J_EJOR},
  author       = {Arne Schulz},
  doi          = {10.1016/j.ejor.2021.01.029},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {42-53},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {The balanced maximally diverse grouping problem with block constraints},
  volume       = {294},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Nash equilibrium solutions in multi-agent project scheduling
with milestones. <em>EJOR</em>, <em>294</em>(1), 29–41. (<a
href="https://doi.org/10.1016/j.ejor.2021.01.023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses a project scheduling environment in which the activities are partitioned among a set of agents. The project owner is interested in completing the project as soon as possible. Therefore, she/he defines rewards and penalties to stimulate the agents to complete the project faster. The project owner offers a per-day reward for early project completion and defines intermediate project milestones to be met within specific due dates, with associated per-day penalties. Each agent can, therefore, decide the duration of her/his activities, taking into account linear activity crashing costs, the reward for early project completion, and the penalty arising from violating milestone due-dates. We consider Nash equilibria, i.e., situations in which no agent has an interest in individually changing the duration of any of her/his activities, and in particular, the problem of finding a minimum-makespan equilibrium. This problem is known to be NP-hard, and in this paper, we ( i ) (i) propose a new and efficient exact algorithmic approach for finding the minimum-makespan equilibrium and ( i i ) (ii) through an extensive computational campaign we evaluate the role played by milestones in driving the project towards the owner’s goal.},
  archive      = {J_EJOR},
  author       = {Přemysl Šůcha and Alessandro Agnetis and Marko Šidlovský and Cyril Briand},
  doi          = {10.1016/j.ejor.2021.01.023},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {29-41},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Nash equilibrium solutions in multi-agent project scheduling with milestones},
  volume       = {294},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Evaluating solutions and solution sets under multiple
objectives. <em>EJOR</em>, <em>294</em>(1), 16–28. (<a
href="https://doi.org/10.1016/j.ejor.2021.01.021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study we address evaluating solutions and solution sets that are defined by multiple objectives based on a function. Although any function can be used, we focus on mostly weighted Tchebycheff functions that can be used for a variety of purposes when multiple objectives are considered. One such use is to approximate a decision maker’s preferences with a Tchebycheff utility function. Different solutions can be evaluated in terms of expected utility conditional on weight values. Another possible use is to evaluate a set of solutions that approximate a Pareto set. It is not straightforward to find the Pareto set, especially for large-size multi-objective combinatorial optimization problems. To measure the representation quality of approximate Pareto sets and to compare such sets with each other, there are some performance indicators such as the hypervolume measure, the ε ε indicator, and the integrated preference functional (IPF) measure. A Tchebycheff function based IPF measure can be used to estimate how well a set of solutions represents the Pareto set. We develop the necessary theory to practically evaluate solutions and solution sets. We develop a general algorithm and demonstrate it for two, three, and four objectives.},
  archive      = {J_EJOR},
  author       = {G. Karakaya and M. Köksalan},
  doi          = {10.1016/j.ejor.2021.01.021},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {16-28},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Evaluating solutions and solution sets under multiple objectives},
  volume       = {294},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A review of DEA approaches applying a common set of weights:
The perspective of centralized management. <em>EJOR</em>,
<em>294</em>(1), 3–15. (<a
href="https://doi.org/10.1016/j.ejor.2021.01.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The vast majority of DEA approaches assume that the decision making units under assessment possess total autonomy in terms of resource allocation and production planning according to their individual preferences. In contrast to these cases of a fully decentralized management, our review focuses on DEA approaches that imply a certain kind of centralized management by applying a common set of input/output weights. In this scenario, a central authority has at least partial control over the resource usage and output production of the units under consideration. Based on a comparison of the aspects of centralization within the contexts of organization theory and DEA literature, we derive a scheme to classify respective DEA approaches according to the way they derive input/output weights. On this basis, a Scopus database search identifies 135 unique publications that implicate various degrees of centralization. We analyze these publications especially with respect to different research streams and citation patterns. In addition to reflecting the current state of the art of DEA approaches applying a common set of weights, our review also aims at enhancing the awareness of the topic amongst scientists as well as practitioners and at encouraging further research.},
  archive      = {J_EJOR},
  author       = {Mohsen Afsharian and Heinz Ahn and Sören Guntram Harms},
  doi          = {10.1016/j.ejor.2021.01.001},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {3-15},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A review of DEA approaches applying a common set of weights: The perspective of centralized management},
  volume       = {294},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Jaap spronk (1949 – 2021). <em>EJOR</em>, <em>294</em>(1),
1–2. (<a href="https://doi.org/10.1016/j.ejor.2021.03.057">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_EJOR},
  author       = {Benedetto Matarazzo},
  doi          = {10.1016/j.ejor.2021.03.057},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {1-2},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Jaap spronk (1949 – 2021)},
  volume       = {294},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Pricing american drawdown options under markov models.
<em>EJOR</em>, <em>293</em>(3), 1188–1205. (<a
href="https://doi.org/10.1016/j.ejor.2021.01.033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The drawdown in the price of an asset shows how much the price falls relative to its historical maximum. This paper considers the pricing problem of perpetual American style drawdown call options, which allow the holder to optimally choose the time to receive a call payoff written on the drawdown. Our pricing framework includes classical Russian options and American lookback puts as special cases after a suitable equivalent measure change. We approximate the original asset price model by a continuous time Markov chain and develop two types of algorithms to solve the optimal stopping problem for the drawdown process. The first one is a transform based algorithm which is applicable to general exponential Lévy models. The second approach solves the linear complementarity problem (LCP) associated with the variational inequalities for the value function and it applies to general Markov models. We propose an efficient Block-LCP (BLCP) method that reduces an LCP with big size to a sequence of sub-LCPs with mild size which can be solved by a variety of LCP solvers and we identify the best solver through numerical experiments. Convergence of Markov chain approximation is proved and various numerical examples are given to demonstrate their computational efficiency and convergence properties. An extension of the BLCP method to the finite maturity case is also provided.},
  archive      = {J_EJOR},
  author       = {Xiang Zhang and Lingfei Li and Gongqiu Zhang},
  doi          = {10.1016/j.ejor.2021.01.033},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1188-1205},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Pricing american drawdown options under markov models},
  volume       = {293},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Optimal bundle composition in competition for continuous
attributes. <em>EJOR</em>, <em>293</em>(3), 1168–1187. (<a
href="https://doi.org/10.1016/j.ejor.2021.01.032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a model to design bundles’ composition under competition, quantifying its effect in terms of profit and market share in a game among competing firms. According to our literature review, no previous models on optimal bundle composition can handle the competition as we do in this paper. Besides, we explain how a firm designing multiple bundles with equal price obtains a replication of identical bundles and an artificially increased estimation of the firm’s profit and market share, which is a consequence of the well-known Independence of Irrelevant Alternatives Property. To mitigate this effect, we use the Constrained Multinomial Logit Model, which induces differentiation in composition through soft constraints that represent the minimum quantity of the attributes offered in bundles. Although this methodology helps, its use implies more effort to estimate its parameters; nevertheless, these are feasible to be assessed. Firms can use our model to identify the bundles in which they should focus their commercial efforts, given the characteristics of their consumers.},
  archive      = {J_EJOR},
  author       = {Kenneth Page and Juan Pérez and Claudio Telha and Andrés García-Echalar and Héctor López-Ospina},
  doi          = {10.1016/j.ejor.2021.01.032},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1168-1187},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Optimal bundle composition in competition for continuous attributes},
  volume       = {293},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A model of investment under uncertainty with time to build,
market incompleteness and risk aversion. <em>EJOR</em>, <em>293</em>(3),
1155–1167. (<a
href="https://doi.org/10.1016/j.ejor.2020.12.052">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper I develop a theoretical framework of irreversible investment under uncertainty in which there is time to build (TTB). The novel aspects of this framework, compared with TTB models in the extant literature, are that the market is incomplete in that not all the uncertainty associated with investing can be diversified away by trading an appropriate spanning asset, and the decision-maker, who acts in the interest of an organisation, is risk averse. I show that models of investment under uncertainty with a TTB, and models of investment under uncertainty with market incompleteness and risk aversion, ought not to be mutually exclusive as they have been in research to date because the recognised results of market incompleteness and risk aversion on the optimal investment strategy are challenged when we incorporate a TTB feature. Conversely, there are also implications on the effect of a TTB when we incorporate market incompleteness and risk aversion. The framework I develop in this paper provides a robust and parsimonious means of facilitating this.},
  archive      = {J_EJOR},
  author       = {Laura Delaney},
  doi          = {10.1016/j.ejor.2020.12.052},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1155-1167},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A model of investment under uncertainty with time to build, market incompleteness and risk aversion},
  volume       = {293},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Conflict resolving – a local search algorithm for solving
large scale conflict graphs in freight railway timetabling.
<em>EJOR</em>, <em>293</em>(3), 1143–1154. (<a
href="https://doi.org/10.1016/j.ejor.2021.01.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the problem of planning the annual timetable for all freight trains in Germany simultaneously. That is, for each train, construct a slot through the network such that no two slots of different trains have a conflict. We denote this task by the Train Path Assignment Problem (TPAP) and present a column generation approach where iteratively, the set of possible slots grows. In each iteration, we look for a maximum subset without any conflicts. Modelling the slots as vertices joint by an edge if they have a conflict, this problem is the Maximum Independent Set problem (MIS). Due to the many slots that are constructed, hence variables that are generated, we deal with large scale MIS instances. Therefore, the MIS is solved heuristically with a local search algorithm called Conflict Resolving (CR) that is tailored to the specially structured instances from the application. CR iteratively perturbs the current solution in order to leave local optima and then repeatedly improves the solution by replacing k − 1 k−1 solution vertices by k k non-solution vertices. These steps are embedded in a simulated annealing framework. In this paper, we present the column generation approach and numerically compare three MIS solution methods, CR, a MIP solver and Iterated Local Search (ILS), a state-of-the-art MIS heuristics. It turns out that CR performs best for the instances from real-world timetabling, and is also comparable to the ILS on MIS benchmark instances. With this approach, we can solve the TPAP for more than 5000 freight trains.},
  archive      = {J_EJOR},
  author       = {Julian Reisch and Peter Großmann and Daniel Pöhle and Natalia Kliewer},
  doi          = {10.1016/j.ejor.2021.01.006},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1143-1154},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Conflict resolving – a local search algorithm for solving large scale conflict graphs in freight railway timetabling},
  volume       = {293},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A generalized true random-effects model with spatially
autocorrelated persistent and transient inefficiency. <em>EJOR</em>,
<em>293</em>(3), 1131–1142. (<a
href="https://doi.org/10.1016/j.ejor.2021.01.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study extends the generalized true random-effects model to account for spatial dependence in persistent and transient inefficiency. For this purpose, a model with spatially autocorrelated persistent and transient inefficiency components is specified. Additionally, spatial dependence is also modeled in the noise component to account for uncontrolled spatial correlations. The proposed model is applied to a panel dataset of Wisconsin dairy farms observed between 2009 and 2017 and estimated using Bayesian techniques. Apart from the traditional output-input quantities, the utilized dataset also contains information on the exact location of farms based on their latitude and longitude coordinates as well as on environmental factors. The empirical findings suggest low levels of both persistent and transient inefficiency for farms. Additionally, all components exhibit spatial dependence with its magnitude being more than double for persistent inefficiency.},
  archive      = {J_EJOR},
  author       = {Ioannis Skevas and Theodoros Skevas},
  doi          = {10.1016/j.ejor.2021.01.004},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1131-1142},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A generalized true random-effects model with spatially autocorrelated persistent and transient inefficiency},
  volume       = {293},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An efficient column generation approach for practical
railway crew scheduling with attendance rates. <em>EJOR</em>,
<em>293</em>(3), 1113–1130. (<a
href="https://doi.org/10.1016/j.ejor.2020.12.058">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The crew scheduling problem with attendance rates is highly relevant for regional passenger rail transport in Germany. Its major characteristic is that only a certain percentage of trains have to be covered by crew members or conductors, causing a significant increase in complexity. Despite being commonly found in regional transport networks, discussions regarding this issue remain relatively rare in the literature. We propose a novel hybrid column generation approach for a real-world problem in railway passenger transport. To the best of our knowledge, several realistic requirements that are necessary for successful application of generated schedules in practice have been integrated for the first time in this study. A mixed integer programming model is used to solve the master problem, whereas a genetic algorithm is applied for the pricing problem. Several improvement strategies are applied to accelerate the solution process; these strategies are analyzed in detail and are exemplified. The effectiveness of the proposed algorithm is proven by a comprehensive computational study using real-world instances, which are made publicly available. Further we provide real optimality gaps on average less than 10\% based on lower bounds generated by solving an arc flow formulation. The developed approach is successfully used in practice by DB Regio AG.},
  archive      = {J_EJOR},
  author       = {Janis S. Neufeld and Martin Scheffler and Felix Tamke and Kirsten Hoffmann and Udo Buscher},
  doi          = {10.1016/j.ejor.2020.12.058},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1113-1130},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {An efficient column generation approach for practical railway crew scheduling with attendance rates},
  volume       = {293},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Optimizing carpool formation along high-occupancy vehicle
lanes. <em>EJOR</em>, <em>293</em>(3), 1097–1112. (<a
href="https://doi.org/10.1016/j.ejor.2020.12.053">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High-occupancy vehicle (HOV) lanes are restricted traffic lanes that are reserved for vehicles with multiple car occupants. Depending on the current number of passengers, a driver must either travel slower on the often-congested general-purpose lane or can access the faster HOV lane. In this paper, we provide optimization approaches for matching supply and demand when building carpools along HOV lanes. In current applications, carpools form spontaneously in slugging areas where potential passengers queue. However, internet-enabled mobile phones that are connected to a central ride sharing platform enable dynamic carpool formation based on sophisticated scheduling procedures. We investigate various versions of the carpool formation problem. The computational complexity is analyzed in depth, and suitable solution procedures are developed. These procedures are applied to quantify the benefit of an optimized carpool formation process. In a comprehensive computational study, we compare our optimization approaches with spontaneous ride sharing and show that substantially better solutions for all stakeholders can be obtained.},
  archive      = {J_EJOR},
  author       = {Nils Boysen and Dirk Briskorn and Stefan Schwerdfeger and Konrad Stephan},
  doi          = {10.1016/j.ejor.2020.12.053},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1097-1112},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Optimizing carpool formation along high-occupancy vehicle lanes},
  volume       = {293},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Locomotive fuel management with inline refueling.
<em>EJOR</em>, <em>293</em>(3), 1077–1096. (<a
href="https://doi.org/10.1016/j.ejor.2020.12.042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fuel and fuel-related expenses constitute a major part of the operating costs of railway companies. Hence, improvements in fuel management often lead to significant annual operational cost savings. The traditional approach to reduce the fueling costs is to fill the locomotives at inexpensive stations to bypass the more expensive stations. However, this approach is not applicable to rail networks with long-haul operations. Railway companies have started adopting inline refueling tanks, a supplementary reservoir which can refuel locomotives during a trip, and can be refueled, attached, detached, and swapped at any station, independently of locomotives. This new technology offers many opportunities for railway companies, in particular to facilitate long-hauls and to leverage fuel cost differences. As always, new opportunities mean new challenges, as inline tanks engender combinatorially many new possible refueling plans. Moreover, since the inline tanks are a substantial investment, the number of available inline tanks is limited. To tackle this, we design a first optimization model that determines the assignment to trains and refueling plans for a fleet of inline tanks. Our analysis shows on an Australian case study and on the INFORMS data set for the USA that inline tanks can lead to a substantial return on investment, thereby informing strategic-level decisions such as the purchase of inline tanks or the closing down of fuel stations. Furthermore, we provide analyses that reveal further managerial insights on the benefits of inline refueling. Finally, we empirically demonstrate the difficulty of this problem and develop a heuristic to tackle large instances.},
  archive      = {J_EJOR},
  author       = {Ahmad Kazemi and Andreas T. Ernst and Mohan Krishnamoorthy and Pierre Le Bodic},
  doi          = {10.1016/j.ejor.2020.12.042},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1077-1096},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Locomotive fuel management with inline refueling},
  volume       = {293},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Optimal in-store fulfillment policies for online orders in
an omni-channel retail environment. <em>EJOR</em>, <em>293</em>(3),
1058–1076. (<a
href="https://doi.org/10.1016/j.ejor.2021.01.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The explosive growth of e-commerce creates a need for increasingly responsive omni-channel fulfillment capabilities, which raises new challenges in inventory management and order fulfillment for retailers. In response to these challenges, many retailers attempt to establish so-called ship-from-store concepts, which leverage their physical store networks to fulfill online orders. In this study, we analyze the optimal setup of these in-store fulfillment processes of online orders for an omni-channel retailer. We use a simulation-based approach combined with exploratory modeling to prescribe optimal fulfillment policies under a variety of sources of uncertainty. We apply our proposed model to a case study informed by real data from a leading sports fashion retailer in New York City in order to illustrate the practical applicability and value of our approach. Our results determine (i) the optimal amount of time to allow for batching of online orders prior to starting the in-store picking process; (ii) the optimal amount of time to allow for readily picked orders prior to starting the delivery process; (iii) the optimal number of pickers; and (iv) the optimal number of packers, and the related performance measures. Finally, we build on our analysis results to derive a set of managerial implications applicable to many omni-channel problems.},
  archive      = {J_EJOR},
  author       = {Rita Maria Difrancesco and Isabelle M. van Schilt and Matthias Winkenbach},
  doi          = {10.1016/j.ejor.2021.01.007},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1058-1076},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Optimal in-store fulfillment policies for online orders in an omni-channel retail environment},
  volume       = {293},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multiplier dynamic data envelopment analysis based on
directional distance function: An application to mutual funds.
<em>EJOR</em>, <em>293</em>(3), 1043–1057. (<a
href="https://doi.org/10.1016/j.ejor.2021.01.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper extends the multiplier dynamic data envelopment analysis (DEA) by using directional distance function (DDF). Based on the duality theory, a multiplier network DDF model is proposed for the dynamic system which consists of a sequence of periods linked by carryovers. The proposed multiplier dynamic model is non-oriented and is able to handle negative data that possibly exist in inputs, carryovers and outputs. The overall efficiency score calculated by the proposed multiplier dynamic model can be decomposed into a weighted average of period efficiency scores. The approach that determines a unique efficiency score for each period is also proposed. To demonstrate the validity and practicality of the proposed dynamic model, we apply it to evaluate the performance of mutual funds in the American market. The empirical results show that the proposed multiplier dynamic model has strong ability to discriminate performance and good practice value for the actual portfolio selection.},
  archive      = {J_EJOR},
  author       = {Ruiyue Lin and Qian Liu},
  doi          = {10.1016/j.ejor.2021.01.005},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1043-1057},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Multiplier dynamic data envelopment analysis based on directional distance function: An application to mutual funds},
  volume       = {293},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Managing competitive levers in a collaborative distribution
channel. <em>EJOR</em>, <em>293</em>(3), 1031–1042. (<a
href="https://doi.org/10.1016/j.ejor.2021.01.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies a distribution channel where a national brand manufacturer and a dominant retailer collaborate to promote the national brand product. To obtain an advantageous competitive position, the dominant retailer may introduce a store brand, whereas the national brand manufacturer may distribute its products through an alternative channel (e.g., a weak retailer). We study how the two channel members should manage their competitive levers (i.e., the store brand for the dominant retailer and the manufacturer’s weak retailer) in such a collaborative distribution channel. On the one hand, we show that the channel members should use the competitive levers as long as they are efficient enough so that the manufacturer and dominant retailer can obtain higher margins from these levers than that from the national brand at the dominant retailer. On the other hand, we also find that the manufacturer and dominant retailer may not necessarily benefit from more efficient competitive levers. That is, the dominant retailer may prefer a less efficient source to procure the store brand product, and the manufacturer may choose a less efficient weak retailer. Moreover, we discover an interesting observation driven by the network externality effect: a firm may benefit when its competitor becomes more efficient (e.g., more efficient store brand procurement at the dominant retailer will increase the weak retailer’s profit). All the above findings hinge upon the collaboration between the national brand manufacturer and dominant retailer, which cautions firms on how to manage their competitive levers in a collaborative distribution channel.},
  archive      = {J_EJOR},
  author       = {Ehsan Bolandifar and Zhong Chen and Kaijie Zhu},
  doi          = {10.1016/j.ejor.2021.01.003},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1031-1042},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Managing competitive levers in a collaborative distribution channel},
  volume       = {293},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Identifying and responding to outlier demand in revenue
management. <em>EJOR</em>, <em>293</em>(3), 1015–1030. (<a
href="https://doi.org/10.1016/j.ejor.2021.01.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Revenue management strongly relies on accurate forecasts. Thus, when extraordinary events cause outlier demand, revenue management systems need to recognise this and adapt both forecast and controls. Many passenger transport service providers, such as railways and airlines, control the sale of tickets through revenue management. State-of-the-art systems in these industries rely on analyst expertise to identify outlier demand both online (within the booking horizon) and offline (in hindsight). So far, little research focuses on automating and evaluating the detection of outlier demand in this context. To remedy this, we propose a novel approach, which detects outliers using functional data analysis in combination with time series extrapolation. We evaluate the approach in a simulation framework, which generates outliers by varying the demand model. The results show that functional outlier detection yields better detection rates than alternative approaches for both online and offline analyses. Depending on the category of outliers, extrapolation further increases online detection performance. We also apply the procedure to a set of empirical data to demonstrate its practical implications. By evaluating the full feedback-driven system of forecast and optimisation, we generate insight on the asymmetric effects of positive and negative demand outliers. We show that identifying instances of outlier demand and adjusting the forecast in a timely fashion substantially increases revenue compared to what is earned when ignoring outliers.},
  archive      = {J_EJOR},
  author       = {Nicola Rennie and Catherine Cleophas and Adam M. Sykulski and Florian Dost},
  doi          = {10.1016/j.ejor.2021.01.002},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1015-1030},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Identifying and responding to outlier demand in revenue management},
  volume       = {293},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Exponential distance function and duality theory.
<em>EJOR</em>, <em>293</em>(3), 1002–1014. (<a
href="https://doi.org/10.1016/j.ejor.2020.11.037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Charnes, Cooper, Seiford, and Stutz (1982, 1983) and Banker and Maindiratta (1986) suggested multiplicative radial measures for efficiency gauging. More recently, Peyrache and Coelli (2009) presented a multiplicative directional distance function that was elaborated by Mehdiloozad, Sahoo, and Roshdi (2014). In this paper, we extend these studies and propose an exponential approach based upon a new exponential distance function endowed with a multiplicative production structure. The main purposes of this paper are twofold: one is to provide a general production theoretic basis for the approach and the other is to extend it to a nonparametric framework. The first purpose is accomplished as follows: (1) the exponential distance function is formally defined and its properties are established; (2) it is shown how the exponential distance function is characterized under a Napierian technology; (3) a duality relationship between Napierian profit and the exponential distance functions is established; (4) shadow prices of inputs and outputs are derived based on the Napierian technology. The second purpose is accomplished by providing nonparametric programming extensions, which include data envelopment analysis (DEA) models, productivity indexes and returns to scale models. Here, the efficacy of our nonparametric theoretical results is demonstrated by applying DEA to the data on accommodation establishments in OECD.},
  archive      = {J_EJOR},
  author       = {Walter Briec and Hirofumi Fukuyama and Paola Ravelojaona},
  doi          = {10.1016/j.ejor.2020.11.037},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1002-1014},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Exponential distance function and duality theory},
  volume       = {293},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Type II failure and specification testing in the stochastic
frontier model. <em>EJOR</em>, <em>293</em>(3), 990–1001. (<a
href="https://doi.org/10.1016/j.ejor.2020.12.065">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The distributional specifications for the composite regression error term most often used in stochastic frontier analysis are inherently bounded as regards their skewness and excess kurtosis coefficients. We derive general expressions for the skewness and excess kurtosis of the composed error term in the stochastic frontier model based on the ratio of standard deviations of the two separate error components as well as theoretical ranges for the most popular empirical specifications. While these simple expressions can be used directly to assess the credibility of an assumed distributional pair, they are likely to over reject. Therefore, we develop a formal test based on the implied ratio of standard deviations for the skewness and the kurtosis. This test is shown to have impressive power compared with other tests of the specification of the composed error term. We deploy this test on a range of well-known datasets that have been used across the efficiency community. For many of them we find that the classic distribution assumptions cannot be rejected.},
  archive      = {J_EJOR},
  author       = {Alecos Papadopoulos and Christopher F. Parmeter},
  doi          = {10.1016/j.ejor.2020.12.065},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {990-1001},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Type II failure and specification testing in the stochastic frontier model},
  volume       = {293},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Universal distribution of batch completion times and
time-cost tradeoff in a production line with arbitrary buffer size.
<em>EJOR</em>, <em>293</em>(3), 980–989. (<a
href="https://doi.org/10.1016/j.ejor.2020.12.050">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the distribution of batch completion times in a serial line of processing stations with a finite buffer—a flow shop. Batch completion times in these lines are distributed according to the Tracy-Widom type 2 distribution from random matrix theory when there is no limitation on buffer size, and all processing durations are identically and exponentially distributed. We significantly extend this result to the case of finite and inhomogeneous buffers and general distributions of processing durations. Using numerically exact computation, we demonstrate the Tracy-Widom distribution matches the observed distribution of batch completion times even when the size of the buffer is finite or inhomogeneous or the distribution of processing durations differs from exponential. This universality is explained by observing that asymptotically batch completion times can be described by directed last passage percolation on the plane, a process whose asymptotic limit falls in the Tracy-Widom universality class. A generic tradeoff is found between the cost of the work-in-process and the average batch completion time, which arises because small buffers cost less but cause more blocking while large buffers are costly but cause less blocking. The maximal improvement in average batch completion time is bounded by ∼12 percent for a line with many exponential processing stations. In this case a small increase in the size of the buffers is sufficient for reaching the unlimited buffer regime. More generally, we found that the maximal improvement monotonically increases with the coefficient of variation of the processing duration distribution.},
  archive      = {J_EJOR},
  author       = {Ruth Sagron and Rami Pugatch},
  doi          = {10.1016/j.ejor.2020.12.050},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {980-989},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Universal distribution of batch completion times and time-cost tradeoff in a production line with arbitrary buffer size},
  volume       = {293},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A simulation-based decomposition approach for two-stage
staffing optimization in call centers under arrival rate uncertainty.
<em>EJOR</em>, <em>293</em>(3), 966–979. (<a
href="https://doi.org/10.1016/j.ejor.2020.12.049">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study a solution approach for a staffing problem in multi-skill call centers. The objective is to find a minimal-cost staffing solution while meeting a target level for the quality of service to customers. We consider a common situation in which the arrival rates are unobserved random variables for which preliminary forecasts are available in a first stage when making the initial staffing decision. In a second stage, more accurate forecasts are obtained and the staffing may have to be modified at a cost, to meet the constraints. This leads to a challenging two-stage stochastic optimization problem in which the quantities involved in the (nonlinear) constraints can only be estimated via simulation, so several independent simulations are required for each first-level scenario. We propose a solution approach that combines sample average approximation with a decomposition method. We provide numerical illustrations to show the practical efficiency of our approach. The proposed method could be adapted to several other staffing problems with uncertain demand, e.g., in retail stores, restaurants, healthcare facilities, and other types of service systems.},
  archive      = {J_EJOR},
  author       = {Thuy Anh Ta and Wyean Chan and Fabian Bastin and Pierre L’Ecuyer},
  doi          = {10.1016/j.ejor.2020.12.049},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {966-979},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A simulation-based decomposition approach for two-stage staffing optimization in call centers under arrival rate uncertainty},
  volume       = {293},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The collaborative consistent vehicle routing problem with
workload balance. <em>EJOR</em>, <em>293</em>(3), 955–965. (<a
href="https://doi.org/10.1016/j.ejor.2020.12.064">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rising competition in the logistics sector forces companies to be more economically efficient. One of the major sources of inefficiency is the incomplete usage of available resources, such as vehicles’ capacities. Mechanism that allow to better exploit such resources by enabling carrier collaborations are on the rise. Our study examines a centrally organized multi-period collaborative vehicle routing problem, where carriers can exchange customers who have to be serviced on a regular basis. Collaborations, where carriers serve frequent customers, are supposed to face the problem of (i) time consistency in terms of visiting time, and of (ii) service consistency. The latter ensures that customers are visited by the same collaboration partner throughout the whole planning horizon. Additionally, carriers might only be willing to enter a collaboration if a minimum market share can be guaranteed. In order to take all these issues into account, we introduce the collaborative vehicle routing problem with time and service consistency and workload balance. The mathematical model including several valid inequalities is presented. In a computational study, we solve small-sized instances to optimality. In order to tackle larger instances, we propose an efficient and effective matheuristic and an iterated local search algorithm. We show that both methods reach near optimal solutions within very short computational times. Managerial insights on the cost of imposing time and service consistency as well as workload balancing constraints are presented and discussed. We show that, according to our computational study, consistency constraints can be imposed for almost no additional cost, while workload balancing constraints do not have any negative effect on the total collaboration profit. This is a meaningful insight and might be a strong argument for carriers to enter collaborations.},
  archive      = {J_EJOR},
  author       = {Simona Mancini and Margaretha Gansterer and Richard F. Hartl},
  doi          = {10.1016/j.ejor.2020.12.064},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {955-965},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {The collaborative consistent vehicle routing problem with workload balance},
  volume       = {293},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Levelling crane workload in multi-yard rail-road container
terminals. <em>EJOR</em>, <em>293</em>(3), 941–954. (<a
href="https://doi.org/10.1016/j.ejor.2020.12.063">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In modern rail-road container terminals, container transshipment between trains and trucks is carried out by large gantry cranes that span over rail tracks and road lanes. Prior optimization approaches have mainly focused on the short-term scheduling of these crucial transshipment resources. In this work, we focus on a midterm planning level that assigns inbound trains to yard tracks such that trains can be serviced by yard resources on schedule. This planning task is especially crucial in larger terminal settings which comprise more than a single yard, which is increasingly typical in growing intermodal networks. We describe the planning situation we encountered at a large rail-road terminal in Germany and propose a mixed-integer model formulation that captures the core of the decision problem. Further, we carry out a complexity analysis of problem variants and develop a heuristic solution procedure in a simulated annealing framework based on these structural insights. The approach is tested in a comprehensive computational study which demonstrates the viability of the approach to solve instances of real-world size.},
  archive      = {J_EJOR},
  author       = {Arne Schulz and Malte Fliedner and Benedikt Fiedrich and Christian Pfeiffer},
  doi          = {10.1016/j.ejor.2020.12.063},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {941-954},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Levelling crane workload in multi-yard rail-road container terminals},
  volume       = {293},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Long-term resource planning in the high-tech industry:
Capacity or inventory? <em>EJOR</em>, <em>293</em>(3), 926–940. (<a
href="https://doi.org/10.1016/j.ejor.2020.12.062">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Volatile and non-stationary demand, very complex production processes, long production and capacity acquisition leadtimes, and extremely high and rarely reversible capacity acquisition costs make capacity planning in the high-tech industry a particularly challenging managerial task. To cope with demand surges and hedge against its uncertainty, firms can invest in order to expand their capacity for the long-term. For the short-term, however, demand is often fixed due to committed orders, and excess capacity might be available that may be used to build up inventory as a complementary means of hedging against these demand surges and uncertainty. In multi-echelon systems, these decisions need to be made simultaneously and must be aligned over the echelons. We address the strategic problem of determining the optimal inventory buildup and capacity expansion timing and amount across locations of a multi-echelon supply chain, as well as the operational problem of production planning. We model the problem as a two-stage stochastic program (SP), with strategic decisions at the first stage and operational decisions at the second stage. We enumerate the capacity expansion timing and use the deterministic equivalent formulation to optimize the other strategic decisions. Through an extensive numerical study, we provide practical managerial insights into the system behavior.},
  archive      = {J_EJOR},
  author       = {Dina Smirnov and Willem van Jaarsveld and Zümbül Atan and Ton de Kok},
  doi          = {10.1016/j.ejor.2020.12.062},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {926-940},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Long-term resource planning in the high-tech industry: Capacity or inventory?},
  volume       = {293},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Decisions and coordination of retailer-led low-carbon supply
chain under altruistic preference. <em>EJOR</em>, <em>293</em>(3),
910–925. (<a href="https://doi.org/10.1016/j.ejor.2020.12.060">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A low-carbon supply chain formed by a dominant retailer and a small and medium-sized manufacturer (SMM) is considered. Because the SMM faces the high cost pressure of adopting carbon emission reduction (CER) technologies, the retailer may take an altruistic preference for the long-term sustainability of the chain. Three decision-making models, centralized, decentralized without altruistic preference, and decentralized with altruistic preference, are constructed to compare decisions and profits of both parties. Since neither decentrailized models can lead to a coordinated solution that is incentive compitable, a coordination contract, referred to as the cost sharing contract with altruistic preference, is proposed. Numerical study shows that the altruistic preference can help increase the SMM&#39;s profit and system efficiency but decrease the retailer&#39;s profit. The coordination contract requires the retailer to adjust the unit profit and share more than half of the CER cost. It is found that the wholesale price is the lowest in the coordination contract and the comparison of unit profit depends on the coefficient of CER cost.},
  archive      = {J_EJOR},
  author       = {Yuyan Wang and Zhaoqing Yu and Mingzhou Jin and Jiafu Mao},
  doi          = {10.1016/j.ejor.2020.12.060},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {910-925},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Decisions and coordination of retailer-led low-carbon supply chain under altruistic preference},
  volume       = {293},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Integrated laycan and berth allocation and time-invariant
quay crane assignment problem in tidal ports with multiple quays.
<em>EJOR</em>, <em>293</em>(3), 892–909. (<a
href="https://doi.org/10.1016/j.ejor.2020.12.056">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Efficient management of port resources plays a crucial role in reducing vessel stay times and avoiding the payment of demurrage charges. In this paper, we focus on the integrated Laycan and Berth Allocation and Quay Crane Assignment Problem, which considers three main decision problems in port management in an integrated way: the Laycan Allocation Problem, the dynamic continuous Berth Allocation Problem and the time-invariant Quay Crane Assignment Problem. In a second part, the integrated problem is extended to the Specific Quay Crane Assignment, which includes the assignment of a set of specific quay cranes to each vessel, considering the productivity of quay cranes and their maximum outreach. The proposed integer programming models are original in several ways. First, the formulation of the models uses predicates which ensure flexibility in the implementation, and significantly improve the computational performance. The numerical study shows that the problems of practical size can be solved to optimality in a reasonable time using commercial software. Second, since the studied problems have different decision levels, a change of decision time-interval is incorporated inside the planning horizon for seamless decision-making. Third, to ensure that this integrated problem is as close as possible to reality, we consider both physical characteristics of the ports rarely studied together (tidal ports with multiple quays and different water depths) and contractual clauses (non-working periods and Charter Party clauses). The output of the models is an efficient schedule for berthing chartered vessels with an efficient quay crane assignment, and laycans to new vessels to charter.},
  archive      = {J_EJOR},
  author       = {Hamza Bouzekri and Gülgün Alpan and Vincent Giard},
  doi          = {10.1016/j.ejor.2020.12.056},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {892-909},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Integrated laycan and berth allocation and time-invariant quay crane assignment problem in tidal ports with multiple quays},
  volume       = {293},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Supply chain game theory network modeling under labor
constraints: Applications to the covid-19 pandemic. <em>EJOR</em>,
<em>293</em>(3), 880–891. (<a
href="https://doi.org/10.1016/j.ejor.2020.12.054">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Covid-19 pandemic has brought attention to supply chain networks due to disruptions for many reasons, including that of labor shortages as a consequences of illnesses, death, risk mitigation, as well as travel restrictions. Many sectors of the economy from food to healthcare have been competing for workers, as a consequence. In this paper, we construct a supply chain game theory network framework that captures labor constraints under three different scenarios. The appropriate equilibrium constructs are defined, along with their variational inequality formulations. Computed solutions to numerical examples inspired by shortages of migrant labor to harvest fresh produce; specifically, blueberries, in the United States, reveal the impacts of a spectrum of disruptions to labor on the product flows and the profits of the firms in the supply chain network economy. This research adds to the literature in both economics and operations research.},
  archive      = {J_EJOR},
  author       = {Anna Nagurney},
  doi          = {10.1016/j.ejor.2020.12.054},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {880-891},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Supply chain game theory network modeling under labor constraints: Applications to the covid-19 pandemic},
  volume       = {293},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). System optimal routing of traffic flows with user
constraints using linear programming. <em>EJOR</em>, <em>293</em>(3),
863–879. (<a href="https://doi.org/10.1016/j.ejor.2020.12.043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For static traffic assignment problems, it is well known that (1) for some users the experienced travel time in a system optimum assignment can be substantially higher than the experienced travel time in a user equilibrium assignment, and (2) the total travel time in user equilibrium can be substantially higher than the total travel time in system optimum. By seeking system optimal traffic flows subject to user constraints, a compromise assignment can be obtained that balances system and user objectives. To this aim, a linear model and an efficient heuristic algorithm are proposed in this paper. A computational study shows that the proposed model, along with the heuristic algorithm, is able to provide fair solutions with near-optimal total travel time within very short computational time.},
  archive      = {J_EJOR},
  author       = {E. Angelelli and V. Morandi and M. Savelsbergh and M.G. Speranza},
  doi          = {10.1016/j.ejor.2020.12.043},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {863-879},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {System optimal routing of traffic flows with user constraints using linear programming},
  volume       = {293},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Solving the maximum edge disjoint path problem using a
modified lagrangian particle swarm optimisation hybrid. <em>EJOR</em>,
<em>293</em>(3), 847–862. (<a
href="https://doi.org/10.1016/j.ejor.2021.01.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a new method to solve the Maximum Edge Disjoint Paths (MEDP) problem. Given a set of node pairs within a network, the MEDP problem is the task of finding the largest number of pairs that can be connected by paths, using each edge within the network at most once. We present a heuristic algorithm that builds a hybridisation of Lagrangian Relaxation and Particle Swarm Optimisation, referred to as LaPSO. This hybridisation is combined with a new repair heuristic, called Largest Violation Perturbation (LVP). We show that our LaPSO method produces better heuristic solutions than both current state-of-the-art heuristic methods, as well as the primal solution found by a standard Mixed Integer Programming (MIP) solver within a limited runtime. Significantly, when run with a limited runtime, our LaPSO method also produces strong bounds which are superior to a standard MIP solver for the larger instances tested, whilst being competitive for the remainder. This allows our LaPSO method to prove optimality for many instances and provide optimality gaps for the remainder, making it a “quasi-exact” method. In this way our LaPSO algorithm, which draws on ideas from both mathematical programming and evolutionary algorithms, is able to outperform both MIP and metaheuristic solvers that only use ideas from one of these areas.},
  archive      = {J_EJOR},
  author       = {Jake Weiner and Andreas T. Ernst and Xiaodong Li and Yuan Sun and Kalyanmoy Deb},
  doi          = {10.1016/j.ejor.2021.01.009},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {847-862},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Solving the maximum edge disjoint path problem using a modified lagrangian particle swarm optimisation hybrid},
  volume       = {293},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Minimizing total late work on a single machine with
generalized due-dates. <em>EJOR</em>, <em>293</em>(3), 837–846. (<a
href="https://doi.org/10.1016/j.ejor.2020.12.061">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study single machine scheduling problems with generalized due-dates. The scheduling measure is minimum total late work. We show that unlike the classical version (assuming job-specific due-dates), this problem has a polynomial time solution. Then, the problem is extended to allow job rejection. First, an upper bound on the total permitted rejection cost is assumed. Then we study the setting whereby the rejection cost is part of the objective function, which becomes minimizing the sum of total late work and rejection cost. We prove that both versions are NP-hard, and introduce pseudo-polynomial dynamic programming solution algorithms. We then consider a setting in which the machine is not available for some period (e.g., due to maintenance). Again, a pseudo-polynomial dynamic programming is introduced for the (NP-hard) problem of minimizing total late work with generalized due-dates and unavailability period. These dynamic programming algorithms are tested numerically, and proved to perform well on problems of various input parameters. Then, the extension to the weighted case, i.e., the problem of minimizing total weighted late work with generalized due-dates is proved to be NP-hard. Finally, we study a slightly different setting, in which the given due-dates are assigned to jobs, but there is no restriction on their order, i.e., the j j -th due-date is not necessarily assigned to the j j -th job in the sequence. We show that this problem (known as scheduling assignable due-dates) to minimize total late work is NP-hard as well.},
  archive      = {J_EJOR},
  author       = {Gur Mosheiov and Daniel Oron and Dvir Shabtay},
  doi          = {10.1016/j.ejor.2020.12.061},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {837-846},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Minimizing total late work on a single machine with generalized due-dates},
  volume       = {293},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Partitioning a graph into balanced connected classes:
Formulations, separation and experiments. <em>EJOR</em>,
<em>293</em>(3), 826–836. (<a
href="https://doi.org/10.1016/j.ejor.2020.12.059">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work addresses the balanced connected k k -partition problem ( BCP k BCPk ), which is formally defined as follows. Given a connected graph G = ( V , E ) G=(V,E) with nonnegative weights on the vertices, find a partition { V i } i = 1 k {Vi}i=1k of V V such that each class V i Vi induces a connected subgraph of G , G, and the weight of a class with the minimum weight is as large as possible. This problem, known to be NP NP -hard, has been largely investigated under different approaches and perspectives: exact algorithms, approximation algorithms for some values of k k or special classes of graphs, and inapproximability results. On the practical side, BCP k BCPk is used to model many applications arising in image processing, cluster analysis, operating systems and robotics. We propose three linear programming formulations for BCP k BCPk . The first one contains only binary variables and a potentially large number of constraints that can be separated in polynomial time in the corresponding linear relaxation. We introduce new valid inequalities and design polynomial-time separation algorithms for them. The other two formulations are based on flows and have a polynomial number of constraints and variables. Our computational experiments show that the exact algorithms based on the proposed formulations outperform the other exact approaches presented in the literature.},
  archive      = {J_EJOR},
  author       = {Flávio K. Miyazawa and Phablo F.S. Moura and Matheus J. Ota and Yoshiko Wakabayashi},
  doi          = {10.1016/j.ejor.2020.12.059},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {826-836},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Partitioning a graph into balanced connected classes: Formulations, separation and experiments},
  volume       = {293},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Portfolio decision analysis: Recent developments and future
prospects. <em>EJOR</em>, <em>293</em>(3), 811–825. (<a
href="https://doi.org/10.1016/j.ejor.2020.12.015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Portfolio decision analysis (PDA) refers to the body of theory, methods and practice which support decision makers in making informed multiple selections from a set of alternatives with the help of mathematical models that account for relevant constraints, preferences and uncertainties. In this review, we take stock of recent advances in PDA research, based on a representative sample of 148 PDA articles in operations research and management science journals from 2006 to 2019. In particular, we analyse relevant methodologies and discuss prominent PDA application areas. Our analysis indicates that PDA is a vibrant research field with close ties to practice, as a substantial share of articles present real applications or contain illustrative examples which are motivated by such applications. For continued knowledge accumulation, there is substantial promise in exploiting PDA concepts in deriving recommendations from decision models for problems which may not have been viewed as PDA problems; fostering the cross-fertilization of conceptual and methodological advances across application areas; and ensuring that new methodological advances are systematically evaluated through engagements with real decision makers.},
  archive      = {J_EJOR},
  author       = {Juuso Liesiö and Ahti Salo and Jeffrey M. Keisler and Alec Morton},
  doi          = {10.1016/j.ejor.2020.12.015},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {811-825},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Portfolio decision analysis: Recent developments and future prospects},
  volume       = {293},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). 2021 editors’ awards for excellence in reviewing.
<em>EJOR</em>, <em>293</em>(3), 809–810. (<a
href="https://doi.org/10.1016/j.ejor.2021.03.039">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_EJOR},
  author       = {Roman Slowinski , Co-ordinating Editor},
  doi          = {10.1016/j.ejor.2021.03.039},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {809-810},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {2021 editors’ awards for excellence in reviewing},
  volume       = {293},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Note on the dominance rules in the exact algorithm for the
container pre-marshalling problem by tanaka &amp; tierney (2018).
<em>EJOR</em>, <em>293</em>(2), 802–807. (<a
href="https://doi.org/10.1016/j.ejor.2020.12.041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this note, we identify an over-pruning issue that occurs in the iterative deepening branch-and-bound algorithm by Tanaka and Tierney (2018). We show that this over-pruning issue is caused by an inconsistency between two dominance rules, namely, the transitive move rule and the empty stack rule, and it will in turn cause the exact algorithm to produce incorrect optimal solutions. To address this issue, we propose a new concept termed the lexicographic dominance principle, and prove that all dominance rules under the lexicographic dominance principle are mutually consistent. Finally, we re-examine all the dominance rules described in the referred paper, and present a compatible set of dominance rules to guarantee mutual consistency.},
  archive      = {J_EJOR},
  author       = {Bo Jin and Mingzhu Yu},
  doi          = {10.1016/j.ejor.2020.12.041},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {802-807},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Note on the dominance rules in the exact algorithm for the container pre-marshalling problem by tanaka &amp; tierney (2018)},
  volume       = {293},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Bayesian value-at-risk backtesting: The case of annuity
pricing. <em>EJOR</em>, <em>293</em>(2), 786–801. (<a
href="https://doi.org/10.1016/j.ejor.2020.12.051">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose new Unconditional, Independence and Conditional Coverage VaR-forecast backtests for the case of annuity pricing under a Bayesian framework that significantly minimise the direct and indirect effects of p p -hacking or other biased outcomes in decision-making, in general. As a consequence of the global financial crisis during 2007–09, regulatory demands arising from Solvency II has required a stricter assessment setting for the internal financial risk models of insurance companies. To put our newly proposed backtesting technique into practice we employ linear and nonlinear Bayesianised variants of two typically used mortality models in the context of annuity pricing. In this regard, we explore whether the stressed longevity scenarios are enough to capture the experienced liability over the forecasted time horizon. Most importantly, we conclude that our Bayesian decision theoretic framework quantitatively produce a strength of evidence favouring one decision over the other.},
  archive      = {J_EJOR},
  author       = {Melvern Leung and Youwei Li and Athanasios A. Pantelous and Samuel A. Vigne},
  doi          = {10.1016/j.ejor.2020.12.051},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {786-801},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Bayesian value-at-risk backtesting: The case of annuity pricing},
  volume       = {293},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Achieving a sustainable cost-efficient business model in
banking: The case of european commercial banks. <em>EJOR</em>,
<em>293</em>(2), 773–785. (<a
href="https://doi.org/10.1016/j.ejor.2020.12.039">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We analyze banks’ abilities to achieve a sustainable business model. We first argue that assessment of the sustainability of a business model on the market requires consideration of the broad set of choices bank managers face, because such a set of business strategies and their adjustment affect performance in both the short and long-run. By measuring the variety of bank business strategies using a diversity index, we present a new framework to analyze the effect of a business model on bank performance (measured by a state-of-the-art stochastic frontier model). In particular, our method links the business model to performance by taking into account the long- and short-run effects. Using data that includes European commercial banks over the period 1993–2016, we find that a combination of (i) a persistent income business model together with the adjustment of an asset-focused business model in the long-run and (ii) diversification of the funding and income portfolios in the short run describes a sustainable cost-efficient business model. Our findings are robust to alternative specifications.},
  archive      = {J_EJOR},
  author       = {Oleg Badunenko and Subal C. Kumbhakar and Ana Lozano‐Vivas},
  doi          = {10.1016/j.ejor.2020.12.039},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {773-785},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Achieving a sustainable cost-efficient business model in banking: The case of european commercial banks},
  volume       = {293},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). On coincidence of feedback and global stackelberg equilibria
in a class of differential games. <em>EJOR</em>, <em>293</em>(2),
761–772. (<a href="https://doi.org/10.1016/j.ejor.2020.12.022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper shows for a class of differential games that the global Stackelberg equilibrium (GSE) coincides with the feedback Stackelberg equilibrium (FSE), although the GSE assumes that the leader/regulator announces at the initial time the regulatory instrument rule she will follow for the rest of the game, while in the FSE, the regulator at any time chooses the optimal level of the regulatory instrument rate. This coincidence is based on the fact that the FSE is calculated using dynamic programming what implies that although the regulator chooses the regulatory instrument rate level that maximizes social welfare, the first-order condition for the maximization of the right-hand side of the Hamilton-Jacobi-Bellman equation implicitly defines a rule for the regulatory instrument. Then, as the regulatory instrument rule defined by the FSE implements the efficient outcome as the GSE does, the rules defined by both equilibria must be the same. In the second part of the paper, we check that this is the case for two examples. The first is an operations research model, while the second is an economic model. The first example fits in a linear-state differential game structure, while the second example presents a linear-quadratic specification. In both cases the regulatory instrument rules for both equilibria (GSE and FSE) are calculated and identical expressions are obtained.},
  archive      = {J_EJOR},
  author       = {Guiomar Martín-Herrán and Santiago J. Rubio},
  doi          = {10.1016/j.ejor.2020.12.022},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {761-772},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {On coincidence of feedback and global stackelberg equilibria in a class of differential games},
  volume       = {293},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Goal programming models with interval coefficients for the
sustainable selection of marine renewable energy projects in the UK.
<em>EJOR</em>, <em>293</em>(2), 748–760. (<a
href="https://doi.org/10.1016/j.ejor.2020.12.038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a strategic decision making model for the sustainable development of marine renewable energy is proposed, and a specific application to the United Kingdom (UK) is demonstrated. As an island nation the UK benefits from significant marine energy potential which is providing an increasing contribution to UK&#39;s renewable energy portfolio. The paper investigates the question of how decision makers can be aided to reach a decision on which types of marine renewable energy projects should be chosen for development given that strategic energy planning is subject to a number of uncertain parameters and multiple sustainability objectives. In this context, the contribution of this paper lies in the combination of renewable energy portfolio selection and the application of multi-objective methods. Interval coefficient goal programming models are adopted in order to address the impreciseness and uncertainty associated with the goals and coefficients of the models in the context of renewable energy selection. The potential renewable energy projects are clustered in order to aid the decision making process and preferential weight sensitivity methods are employed. Conclusions are drawn for optimistic and pessimistic scenarios in the context of UK marine renewable energy planning.},
  archive      = {J_EJOR},
  author       = {Negar Akbari and Dylan Jones and Farzad Arabikhan},
  doi          = {10.1016/j.ejor.2020.12.038},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {748-760},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Goal programming models with interval coefficients for the sustainable selection of marine renewable energy projects in the UK},
  volume       = {293},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Efficient formulation for transportation scheduling of
single refinery multiproduct pipelines. <em>EJOR</em>, <em>293</em>(2),
731–747. (<a href="https://doi.org/10.1016/j.ejor.2020.12.034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multiproduct pipeline transportation scheduling is a complex operations research problem that is characterized by the movement of the cargo rather than the carrier. Hence, it cannot be solved using vehicle routing methods. While most formulations for short-term scheduling adopt a continuous-time representation, they often lead to suboptimal solutions because of the dependence on the number of time slots in the grid, which is difficult to predict. Furthermore, some of these formulations have poor linear relaxations due to the presence of inefficient big-M constraints. In this paper, we develop a discrete-time mixed integer linear programming (MILP) model for the detailed scheduling of a straight pipeline with a single refinery and multiple depots. The proposed formulation rigorously detects interface material generated between adjacent products and considers planned shutdowns in pipeline segments due to maintenance operations, as well as local market demands occurring at multiple intermediate due dates. The main novelty is that continuous tasks can span multiple time slots to enforce minimum batch sizes on injection and delivery nodes, which allows for the model to generate better schedules than those obtained with previously proposed formulations. To ensure an efficient model by design, we rely on generalized disjunctive programming (GDP) and on the convex hull reformulation of disjunctions, which results in stronger and often more computationally efficient formulations. We present numerical results for a set of benchmark instances and show that the proposed model applies to large-scale industrial cases.},
  archive      = {J_EJOR},
  author       = {Hossein Mostafaei and Pedro M. Castro and Fabricio Oliveira and Iiro Harjunkoski},
  doi          = {10.1016/j.ejor.2020.12.034},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {731-747},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Efficient formulation for transportation scheduling of single refinery multiproduct pipelines},
  volume       = {293},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A risk-constrained time-dependent cash-in-transit routing
problem in multigraph under uncertainty. <em>EJOR</em>, <em>293</em>(2),
703–730. (<a href="https://doi.org/10.1016/j.ejor.2020.12.020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Cash-in-Transit (CIT) deals with the transportation of banknotes, coins, and other valuable items. Due to the high-value density of these products, incorporating security strategies in the carrier operations is crucial. This paper proposes new CIT models involving deterministic and stochastic time-varying traffic congestion. Since risk exposure of a vehicle is proportional to the time-dependent travel time, a new formula is introduced to measure the risk of traveling. Moreover, this study covers one of the important weaknesses of previous CIT routing models by investigating the problem in multigraph networks. Multigraph representation maintains a set of non-dominated parallel arcs, which are differentiated by two attributes including travel time and robbery risk. Considering maximum allowable time duration together with a risk threshold yields to design a more balanced routing scheme. Multi-attribute parallel arcs in a stochastic time-dependent network bring high computational challenges. Herein, we introduce efficient algorithms including a novel flexible restricted Dynamic Programming and a self-adaptive caching Genetic Algorithm. The proposed algorithms are tested on both a real case study in Isfahan metropolis and generated instances. Ultimately, sensitivity analyses are conducted to assess the importance of the use of multigraph networks in the CIT and to provide significant managerial insights for administrators and practitioners.},
  archive      = {J_EJOR},
  author       = {Hamid Tikani and Mostafa Setak and Emrah Demir},
  doi          = {10.1016/j.ejor.2020.12.020},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {703-730},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A risk-constrained time-dependent cash-in-transit routing problem in multigraph under uncertainty},
  volume       = {293},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The facts on the ground: Evaluating humanitarian fleet
management policies using simulation. <em>EJOR</em>, <em>293</em>(2),
681–702. (<a href="https://doi.org/10.1016/j.ejor.2020.12.019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In humanitarian fleet management, the performance of purchase, assignment, and sales decisions is determined by dynamic interactions between the fleet composition, the time-varying and uncertain demands on the fleet, and the depreciation of the vehicles as they are exploited. We propose to evaluate purchase, assignment, and sales policies in a holistic simulation environment that directly models heterogeneous vehicle attributes and tracks their evolution over time. Using data from a large international humanitarian organization (LIHO), the simulator can identify the rationale behind seemingly ad-hoc decisions by field managers at LIHO. For instance, by selling vehicles later than LIHO recommends, managers are actually reducing their costs; similarly, managers decline to switch vehicles between mission types because the benefits to the operational cost turn out to be marginal at best.},
  archive      = {J_EJOR},
  author       = {Liyi Gu and Ilya O. Ryzhov and Mahyar Eftekhar},
  doi          = {10.1016/j.ejor.2020.12.019},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {681-702},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {The facts on the ground: Evaluating humanitarian fleet management policies using simulation},
  volume       = {293},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Active learning strategies for interactive elicitation of
assignment examples for threshold-based multiple criteria sorting.
<em>EJOR</em>, <em>293</em>(2), 658–680. (<a
href="https://doi.org/10.1016/j.ejor.2020.12.055">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider an interactive elicitation of holistic preference information for multiple criteria sorting approached with a threshold-based value-driven procedure. We introduce several active learning strategies for selecting, in each stage of interaction, an alternative that the Decision Maker (DM) should assign to its desired class. To identify the best assignment-based question, we evaluate each candidate alternative in terms of either ambiguity in its possible assignments at the current stage of interaction or its potential contribution to reducing uncertainty in the assignments of all alternatives once the question is answered. The performance of the proposed heuristic strategies is experimentally verified in view of computational time as well as the average and maximal numbers of questions that need to be answered by the DM until the classification recommended by all compatible preference models is sufficiently robust. We demonstrate that competitive results can be obtained with the heuristics that select the next question based on the analysis of current classification results as compared to the strategies looking ahead the current stage, which takes significantly more time. We also show how the performance of the questioning strategies is affected when, e.g., considering various problem sizes, imposing different stopping criteria for the preference elicitation, or reducing the flexibility of an assumed preference model by fixing the class thresholds.},
  archive      = {J_EJOR},
  author       = {Miłosz Kadziński and Krzysztof Ciomek},
  doi          = {10.1016/j.ejor.2020.12.055},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {658-680},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Active learning strategies for interactive elicitation of assignment examples for threshold-based multiple criteria sorting},
  volume       = {293},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Time-consistency of optimal investment under smooth
ambiguity. <em>EJOR</em>, <em>293</em>(2), 643–657. (<a
href="https://doi.org/10.1016/j.ejor.2020.12.046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study portfolio choice in a Black–Scholes world under drift uncertainty. Preferences towards risk and ambiguity are modeled using the smooth ambiguity approach under a double power utility assumption and a normal distribution assumption on the unknown drift. Optimal investment in this setting is time-inconsistent. Utility is maximized by a time-inconsistent pre-commitment strategy resembling the classical Merton solution. In contrast, the optimal dynamically consistent investment strategy accounts for variations in the perceived severity of drift uncertainty, increasing the riskiness of the strategy gradually over time. We provide a detailed comparative analysis of the mechanics and interplay of ambiguity, myopia and optimal decisions in this setting. We show that an investor who pre-commits will regret that decision from some time point onwards, wishing that she had followed the dynamically consistent strategy.},
  archive      = {J_EJOR},
  author       = {Anne G. Balter and Antje Mahayni and Nikolaus Schweizer},
  doi          = {10.1016/j.ejor.2020.12.046},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {643-657},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Time-consistency of optimal investment under smooth ambiguity},
  volume       = {293},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A hierarchical consensus reaching process for group decision
making with noncooperative behaviors. <em>EJOR</em>, <em>293</em>(2),
632–642. (<a href="https://doi.org/10.1016/j.ejor.2020.12.028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of technological and societal paradigms, we witness a trend where a large number of experts participate in decision-making processes, and large-scale group decision making has become a much researched topic. A large-scale group decision-making problem usually involves many experts with various backgrounds and experiences. In these cases, an effective consensus reaching process is essential to guarantee the support of all experts, especially in large-scale group decision-making settings. This study proposes a hierarchical consensus model that allows the number of adjusted opinions to vary depending on the specific level of consensus in each iterative round. Furthermore, this study also introduces a method to detect and manage noncooperative behaviors by means of the hierarchical consensus model. The minimum spanning tree clustering algorithm is used to classify experts. A weight determination method combining the size of the subgroup and the sum of squared errors is developed for subgroups. Finally, an illustrative example is provided to demonstrate the practicality of the proposed model.},
  archive      = {J_EJOR},
  author       = {Ming Tang and Huchang Liao and Xiaomei Mi and Benjamin Lev and Witold Pedrycz},
  doi          = {10.1016/j.ejor.2020.12.028},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {632-642},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A hierarchical consensus reaching process for group decision making with noncooperative behaviors},
  volume       = {293},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Non-dominated sorting genetic-based algorithm for exploiting
a large-sized fuzzy outranking relation. <em>EJOR</em>, <em>293</em>(2),
615–631. (<a href="https://doi.org/10.1016/j.ejor.2020.12.026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electre III is a well-known multiple criteria decision aiding method based on pairwise comparisons. However, it cannot be applied to ranking problems involving many alternatives, because the number of pairwise comparisons can then be rather large. In this paper, we present an evolution-based approach for exploiting large fuzzy outranking relations and deriving a crisp outranking relation with desirable properties. Therefore, the utilization of a fuzzy outranking relation is modeled as a three-objective optimization problem, which is solved by an evolutionary algorithm. The proposed ranking algorithm is a hybrid of the elitist non-dominated sorting genetic algorithm-II (NSGA-II) and a reference point method with the repeated use of a choice mechanism. In addition, a method that portrays the obtained ranking in a Hasse diagram is used for recommendation purposes. We designate the new method RP 2 2 -NSGA-II+H. In our experiments, the proposed ranking procedure demonstrates a better performance in terms of ranking error rates than other ranking procedures based on multi-objective evolutionary algorithms. Our experimental results also demonstrate that, with the new procedure, this method can be scaled for hundreds of alternatives.},
  archive      = {J_EJOR},
  author       = {Juan Carlos Leyva López and Jesús Jaime Solano Noriega and José Rui Figueira and Jun Liu and Diego Alonso Gastélum Chavira},
  doi          = {10.1016/j.ejor.2020.12.026},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {615-631},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Non-dominated sorting genetic-based algorithm for exploiting a large-sized fuzzy outranking relation},
  volume       = {293},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). On sales effort and pricing decisions under alternative risk
criteria. <em>EJOR</em>, <em>293</em>(2), 603–614. (<a
href="https://doi.org/10.1016/j.ejor.2020.12.025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the literature, different risk criteria are proposed for risk-averse decision-making, but it is often unclear which risk criteria should be used and what their differences may be. This study investigates this problem when a risk-averse, make-to-order firm decides its pricing and sales effort, two factors affecting demand. We consider alternative risk criteria commonly used in the literature, namely expected utility theory (EUT), mean-variance (MV), mean-semideviation (MS), value-at-risk (VaR), conditional value-at-risk (CVaR), and loss aversion (LA). We find that all of these criteria lead to similar qualitative behaviors regarding how risk-/loss-averse decisions deviate from risk-neutral ones. A particularly interesting result is that the form of demand randomness, i.e., additive or multiplicative, can completely reverse the effect of risk/loss aversion in certain cases. We also find that the risk aversion models, i.e., EUT, MV, MS, VaR, and CVaR, are essentially equivalent in inducing the same set of optimal solutions under adverse market states. However, loss aversion is a mild version of risk aversion in that the LA model can only lead to a subset of the solutions generated by other models. These results may not be valid for other applications, such as the newsvendor pricing problem, so we can conclude that the relationship between alternative risk criteria is case-sensitive and should be evaluated more carefully.},
  archive      = {J_EJOR},
  author       = {Xiang Li and Xiangtong Qi and Yongjian Li},
  doi          = {10.1016/j.ejor.2020.12.025},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {603-614},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {On sales effort and pricing decisions under alternative risk criteria},
  volume       = {293},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Joint pricing and inventory decisions for substitutable and
perishable products under demand uncertainty. <em>EJOR</em>,
<em>293</em>(2), 594–602. (<a
href="https://doi.org/10.1016/j.ejor.2020.08.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we develop a model for dynamic pricing and inventory decisions for multiple substitutable and perishable products under a multiple-period lifetime. Retailers place orders at the beginning of the first period, and products will be sold at full price during that period. All leftover products will then be carried over to the subsequent periods and sold at discounted prices. Demands for leftover products are assumed to follow a linear stochastic model depending on the discounted prices of the substitutable products. The optimal order quantities and prices are obtained by maximizing the total expected profit over the lifetime, taking into account the revenue, the backorder cost and the holding cost. We provide analytical properties of the optimal policy such as the concavity of the value functions and then utilise these in the numerical scheme for finding the optimal prices and ordering quantities. Experimental results are reported through a case study of a high-street fashion company, demonstrating the benefits of considering pricing and inventory decisions simultaneously for substitutable products.},
  archive      = {J_EJOR},
  author       = {Fei Fang and Tri-Dung Nguyen and Christine S.M. Currie},
  doi          = {10.1016/j.ejor.2020.08.002},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {594-602},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Joint pricing and inventory decisions for substitutable and perishable products under demand uncertainty},
  volume       = {293},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Efficient optimization algorithms for surgical scheduling
under uncertainty. <em>EJOR</em>, <em>293</em>(2), 579–593. (<a
href="https://doi.org/10.1016/j.ejor.2020.12.048">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we develop a stochastic optimization model for a surgical scheduling problem considering a single operating room. We arrange a set of elective surgeries into appropriate time blocks, and determine their planned start time and specific sequence. Due to the complexity of the original formulation, we reformulate our model as a two-stage mixed-integer problem. We consider the planning decision in the first stage and the sequencing decision in the second stage (based on the first one). The goal of this paper is to obtain a nearly optimal schedule in reasonable computational time. The term “optimal” is defined as the lowest surgically related cost while achieving the given threshold with respect to some specific deterministic or stochastic performance measures. The optimization model involves expected and probabilistic formulations that are analytically intractable. This implies that traditional mathematical programming techniques cannot be used directly. Therefore, we propose adapted rapid-screening and stochastic-approximation algorithms to deal with the first-stage and the second-stage problems, respectively. In both algorithms, we can apply either the Laplace transform or simulation methods to either evaluate or estimate the desired performance measures. The experimental results demonstrate that the proposed algorithms are more favorable compared to existing approaches.},
  archive      = {J_EJOR},
  author       = {Shing Chih Tsai and Yingchieh Yeh and Chen Yun Kuo},
  doi          = {10.1016/j.ejor.2020.12.048},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {579-593},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Efficient optimization algorithms for surgical scheduling under uncertainty},
  volume       = {293},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Preemptible queues with advance reservations: Strategic
behavior and revenue management. <em>EJOR</em>, <em>293</em>(2),
561–578. (<a href="https://doi.org/10.1016/j.ejor.2020.12.044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Consider an M / G / 1 M/G/1 queuing system that supports advance reservations. In this system, strategic customers must decide whether to reserve a server in advance (thereby gaining higher priority) or forgo reservations. Reserving a server in advance bears a cost. The provider can further impact the customers’ reservation decisions via implementation of one of several priority-based preemption policies: (i) one in which any customer is subject to service preemption by a higher priority customer (PR); (ii) one in which service preemption does not occur (NP); and (iii) a hybrid policy in which only customers without a priority reservation are subject to service preemption (HPR). In this work, we characterize the strategic behavior of customers, equilibrium outcomes, and provider’s revenue maximization under each of these policies. In all the cases, we prove that (i) the only possible type of Nash equilibria is a threshold one based on the customers’ priorities; and (ii) the system load impacts both the structure and number of Nash equilibria. We also prove that HPR is the only policy in which (i) an equilibrium where all customers make reservations may exist; and (ii) the second moment of service impacts the equilibria. Finally, we prove that for any system load and any service distribution, the HPR policy yields the highest maximum revenue, followed in turn by the PR policy and the NP policy. We further show that the relative difference in the performance of the HPR and PR policies is greatest at low system load and under low service variance.},
  archive      = {J_EJOR},
  author       = {Jonathan Chamberlain and Eran Simhon and David Starobinski},
  doi          = {10.1016/j.ejor.2020.12.044},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {561-578},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Preemptible queues with advance reservations: Strategic behavior and revenue management},
  volume       = {293},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Simplified stochastic calculus with applications in
economics and finance. <em>EJOR</em>, <em>293</em>(2), 547–560. (<a
href="https://doi.org/10.1016/j.ejor.2020.12.037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paper introduces a simple way of recording and manipulating general stochastic processes without explicit reference to a probability measure. In the new calculus, operations traditionally presented in a measure-specific way are instead captured by tracing the behaviour of jumps (also when no jumps are physically present). The calculus is fail-safe in that, under minimal assumptions, all informal calculations yield mathematically well-defined stochastic processes. The calculus is also intuitive as it allows the user to pretend all jumps are of compound Poisson type. The new calculus is very effective when it comes to computing drifts and expected values that possibly involve a change of measure. Such drift calculations yield, for example, partial integro–differential equations, Hamilton–Jacobi–Bellman equations, Feynman–Kac formulae, or exponential moments needed in numerous applications. We provide several illustrations of the new technique, among them a novel result on the Margrabe option to exchange one defaultable asset for another.},
  archive      = {J_EJOR},
  author       = {Aleš Černý and Johannes Ruf},
  doi          = {10.1016/j.ejor.2020.12.037},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {547-560},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Simplified stochastic calculus with applications in economics and finance},
  volume       = {293},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Optimal scheduling of emergency resources for major maritime
oil spills considering time-varying demand and transportation networks.
<em>EJOR</em>, <em>293</em>(2), 529–546. (<a
href="https://doi.org/10.1016/j.ejor.2020.12.040">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {During an emergency response to a major oil spill accident, the features of the motion of the oil films affect the response decisions. A highly dynamic optimal solution is needed to tackle the continuous changes in the demand for emergency resources and transportation networks for logistics deliveries that must occur. To effectively balance the responsiveness and the total response cost in emergency operations, this paper proposes a dynamic multi-objective location-routing model to address new challenges, such as the time-varying conditions in the response to oil spills and the interrelationship between the decision-making environment and emergency operations. Since the problem is NP-hard, to efficiently obtain Pareto solutions, a novel implementation of a heuristic framework based on particle swarm optimization is developed to conduct numerical experiments. Additionally, to handle the multi-objective model, an alternative solution based on the cost performance method is adopted to help decision makers select the ideal options for Pareto solutions. A case study of a major oil spill accident that occurred in the Bohai Bay is conducted to demonstrate the application of the proposed model and approaches and the real-world implications.},
  archive      = {J_EJOR},
  author       = {Lingye Zhang and Jing Lu and Zaili Yang},
  doi          = {10.1016/j.ejor.2020.12.040},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {529-546},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Optimal scheduling of emergency resources for major maritime oil spills considering time-varying demand and transportation networks},
  volume       = {293},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Modelling dynamic freshness-keeping effort over a finite
time horizon in a two-echelon online fresh product supply chain.
<em>EJOR</em>, <em>293</em>(2), 511–528. (<a
href="https://doi.org/10.1016/j.ejor.2020.12.035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A fresh product deteriorates over the finite time horizon and may lose its intended commercial value due to delays in transportation or improper management of temperature in its production and distribution. Seamless collaborations in freshness-keeping actions among supply chain members are critical to ensure that the product is delivered with the desired level of freshness. However, due to concerns about the recovery of the costly investments in the freshness-keeping actions, the members of the supply chain may not fully engage in the actions. In this paper, we propose a dynamic control model comprising an online retailer and an off-line producer, who collaborate to deliver a fresh product to their customers. Having received the orders from its online platform, the retailer will procure the product from the producer, who will be responsible for the delivery of the product to the retailer. The retailer decides the optimal level of advertising effort, while the producer decides the optimal freshness-keeping effort. We show that in decentralized decision mode, the optimal levels of both freshness state and effort decrease significantly because of the shrink in the profit margin. In particular, the producer may abandon the effort and leave the product to deteriorate naturally after the transaction. This will jeopardize the goodwill of the retailer afterwards. To address the issue, we devise a linear-bonus scheme and demonstrate its effectiveness in dynamically motivating an optimal level of the producer’s freshness-keeping effort. Three specific circumstances are identified for setting an appropriate bonus to lead to the highest level of the freshness-keeping effort. Further, we develop a decision matrix for managerial practitioners to choose the appropriate bonus according to particular situations. In addition, the results counter-intuitively show that an increase in the marginal bonus does not necessarily result in a higher level of freshness of the delivered product.},
  archive      = {J_EJOR},
  author       = {Chao Liu and Weidong Chen and Qian Zhou and Jing Mu},
  doi          = {10.1016/j.ejor.2020.12.035},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {511-528},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Modelling dynamic freshness-keeping effort over a finite time horizon in a two-echelon online fresh product supply chain},
  volume       = {293},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Optimizing routing and delivery patterns with
multi-compartment vehicles. <em>EJOR</em>, <em>293</em>(2), 495–510. (<a
href="https://doi.org/10.1016/j.ejor.2020.12.033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Retailers usually apply repetitive weekly delivery patterns when scheduling the workforce for shelf replenishment, defining cyclic transportation routes and managing warehouse capacities. In doing so, all logistics subsystems are jointly scheduled. Grocery products require different temperature zones. As long as transport was in separated vehicles due to temperature requirements, it was not possible to coordinate deliveries across different temperature zones. The recent introduction of multi-compartment trucks has changed this and allows joint deliveries. This simultaneous delivery of multiple product segments impacts repetitive weekly delivery patterns as, for example, low volume segments can be delivered more frequently if they are transported together with high volume segments. We address the problem of defining delivery patterns for delivery with multi-compartment vehicles. After deriving decision-relevant costs, we propose a novel model that defines the Periodic Multi-Compartment Vehicle Routing Problem. The model is solved by an integrated framework that determines delivery patterns within an Adaptive Large Neighborhood Search in combination with a Large Neighborhood Search for solving the routing problem. We analyze the impact of selecting delivery patterns across product segments and show the efficiency of our integrated planning approach using numerical studies. Joint planning generates cost savings of up to 15\%. Furthermore, we show that the algorithm provided can also improve single-segment problems by 3\% compared to a state-of-the art benchmark. Beyond that we demonstrate the applicability and advantage of our approach in a case study with a large German grocery retailer.},
  archive      = {J_EJOR},
  author       = {Markus Frank and Manuel Ostermeier and Andreas Holzapfel and Alexander Hübner and Heinrich Kuhn},
  doi          = {10.1016/j.ejor.2020.12.033},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {495-510},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Optimizing routing and delivery patterns with multi-compartment vehicles},
  volume       = {293},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Contracting for technology improvement: The effect of
asymmetric bargaining power and investment uncertainty. <em>EJOR</em>,
<em>293</em>(2), 481–494. (<a
href="https://doi.org/10.1016/j.ejor.2020.12.031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Investment in technology improvement (TI) measures that reduce the consumption rate of input commodities (like fuel, energy, water, etc.) yields significant economic and sustainability benefits. Yet, evidence shows that the so-called holdup problem leads to inefficient levels of investment in TI. The suppliers refrain from investing in TI because they fear that a buyer with greater bargaining power will use TI-related cost reductions to push prices down—in the purchase bargaining process—and thereby further reduce the supplier’s profit margin. Conventional wisdom suggests that higher bargaining power on the buyer’s side aggravates this problem. In a two-tier supplier–buyer setting, we study the role of relative bargaining power along with technology uncertainty—i.e., the risk associated with investment return—on TI investment levels by the supplier. We challenge conventional wisdom to show that there is an inverse U-shaped relationship between buyer bargaining power and TI investment by the supplier and characterize how technology uncertainty moderates this relationship. We study and rank various contracting arrangements commonly used in industry, including the price commitment and shared investment contracts to remedy the investment inefficiencies resulting from the bargaining process.},
  archive      = {J_EJOR},
  author       = {Ali Shantia and Sam Aflaki and Andrea Masini},
  doi          = {10.1016/j.ejor.2020.12.031},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {481-494},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Contracting for technology improvement: The effect of asymmetric bargaining power and investment uncertainty},
  volume       = {293},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Effects of corporate social responsibility activities in a
two-stage assembly production system with multiple components and
imperfect processes. <em>EJOR</em>, <em>293</em>(2), 469–480. (<a
href="https://doi.org/10.1016/j.ejor.2020.12.027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Implementation of corporate social responsibility (CSR) activities has been shown to improve the financial performance of many firms, and the effects are particularly evident in original brand manufacturers (OBMs). This paper studies the effects of two common CSR activities (social donations and green industrial development) on a two-stage assembly production system with multiple components and imperfect processes under the assumption that demand depends on selling price and CSR impact. The proposed problem is formulated as an economic production quantity (EPQ) model aimed at profit maximization, in which the decision variables include the production run time of each process, expenditures on social donations, and green industrial development. Our results prove that an optimal solution exists, and that it is unique. An algorithm for the computation of the optimal solution is also provided. The efficacy of the proposed model is demonstrated via numerical modeling of a footwear OBM in Taiwan. Sensitivity analysis revealed a number of managerial insights. For example, the results obtained under CSR operations can be compared with those obtained under non-CSR operations (under various parameters settings) to determine an opportune moment for the execution of CSR.},
  archive      = {J_EJOR},
  author       = {Rung-Hung Su and Ming-Wei Weng and Chih-Te Yang},
  doi          = {10.1016/j.ejor.2020.12.027},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {469-480},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Effects of corporate social responsibility activities in a two-stage assembly production system with multiple components and imperfect processes},
  volume       = {293},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Single-machine scheduling with an external resource.
<em>EJOR</em>, <em>293</em>(2), 457–468. (<a
href="https://doi.org/10.1016/j.ejor.2020.12.045">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the complexity of single-machine scheduling with an external resource, which is rented for a non-interrupted period. Jobs that need this external resource are executed only when the external resource is available. There is a cost associated with the scheduling of jobs and a cost associated with the duration of the renting period of the external resource. We look at four classes of problems with an external resource: a class of problems where the renting period is budgeted and the scheduling cost needs to be minimized, a class of problems where the scheduling cost is budgeted and the renting period needs to be minimized, a class of two-objective problems where both, the renting period and the scheduling cost, are to be minimized, and a class of problems where a linear combination of the scheduling cost and the renting period is minimized. We provide a thorough complexity analysis (NP-hardness proofs and (pseudo-)polynomial algorithms) for different members of these four classes.},
  archive      = {J_EJOR},
  author       = {Dirk Briskorn and Morteza Davari and Jannik Matuschke},
  doi          = {10.1016/j.ejor.2020.12.045},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {457-468},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Single-machine scheduling with an external resource},
  volume       = {293},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An iterative dynamic programming approach for the temporal
knapsack problem. <em>EJOR</em>, <em>293</em>(2), 442–456. (<a
href="https://doi.org/10.1016/j.ejor.2020.12.036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we address the temporal knapsack problem (TKP), a generalization of the classical knapsack problem, where selected items enter and leave the knapsack at fixed dates. We model the TKP with a dynamic program of exponential size, which is solved using a method called Successive Sublimation Dynamic Programming (SSDP). This method starts by relaxing a set of constraints from the initial problem, and iteratively reintroduces them when needed. We show that a direct application of SSDP to the temporal knapsack problem does not lead to an effective method, and that several improvements are needed to compete with the best results from the literature.},
  archive      = {J_EJOR},
  author       = {F. Clautiaux and B. Detienne and G. Guillot},
  doi          = {10.1016/j.ejor.2020.12.036},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {442-456},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {An iterative dynamic programming approach for the temporal knapsack problem},
  volume       = {293},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Metaheuristics for the online printing shop scheduling
problem. <em>EJOR</em>, <em>293</em>(2), 419–441. (<a
href="https://doi.org/10.1016/j.ejor.2020.12.021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, the online printing shop scheduling problem is considered. This challenging real-world scheduling problem, that emerged in the present-day printing industry, corresponds to a flexible job shop scheduling problem with sequencing flexibility; and it presents several complicating requirements such as resumable operations, periods of unavailability of the machines, sequence-dependent setup times, partial overlapping between operations with precedence constraints, and fixed operations, among others. A local search strategy and metaheuristics are proposed and evaluated. Based on a common representation scheme, trajectory and populational metaheuristics are considered. Extensive numerical experiments on large-sized instances show that the proposed methods are suitable for solving practical instances of the problem; and that they outperform a half-heuristic-half-exact off-the-shelf solver by a large extent. In addition, numerical experiments on classical instances of the flexible job shop scheduling problem show that the proposed methods are also competitive when applied to this particular case.},
  archive      = {J_EJOR},
  author       = {Willian T. Lunardi and Ernesto G. Birgin and Débora P. Ronconi and Holger Voos},
  doi          = {10.1016/j.ejor.2020.12.021},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {419-441},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Metaheuristics for the online printing shop scheduling problem},
  volume       = {293},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Taking stock of behavioural OR: A review of behavioural
studies with an intervention focus. <em>EJOR</em>, <em>293</em>(2),
401–418. (<a href="https://doi.org/10.1016/j.ejor.2020.11.031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This review maps the body of behavioural OR studies that focus on interventions. The term ‘intervention’ is used here to refer to a designed problem-solving system in which individuals or groups engage with OR methods, processes and tools in order to complete a set task or address a real-world problem. We surveyed the relevant OR literature covering a 30-year period, and develop a typology to organise our corpus of reviewed studies. The typology is comprised of four types of studies, each type representing a distinctive approach in terms of its assumptions about behaviour ( determinist or voluntarist ) and the research methodologies they use ( variance or process ), and each type is concerned with different research questions that do not cut across other approaches. By categorising studies in this way, and drawing on research in associated cognate areas where relevant, eight empirically-generated knowledge themes emerge: intervention configurations, individual differences, model-driven support impacts, (un)intended use, model building process, engagement paths and strategies, facilitated modelling practice, and sociomaterial dynamics. Each of these knowledge themes provides important insights into the behavioural factors that affect, or are affected by, OR-supported activity. We conclude our review with ten suggestions for further developing the behavioural OR agenda concerned with interventions.},
  archive      = {J_EJOR},
  author       = {L. Alberto Franco and Raimo P. Hämäläinen and Etiënne A.J.A. Rouwette and Ilkka Leppänen},
  doi          = {10.1016/j.ejor.2020.11.031},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {401-418},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Taking stock of behavioural OR: A review of behavioural studies with an intervention focus},
  volume       = {293},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Parameter-free robust optimization for the maximum-sharpe
portfolio problem. <em>EJOR</em>, <em>293</em>(1), 388–399. (<a
href="https://doi.org/10.1016/j.ejor.2020.11.052">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {How can we optimize for the Sharpe ratio if we only have limited training data? Estimates of mean asset returns are noisy, and this noise hurts the out-of-sample Sharpe ratio of current methods. The minimum-variance portfolio, which ignores mean returns, often has a better Sharpe ratio. We develop a parameter-free and scalable method called AlphaRob for this problem. AlphaRob ’s portfolio is a convex combination of two prespecified portfolios. To select the best combination, AlphaRob fuses robust optimization with a new notion of a portfolio’s regret that accounts for the training data’s size. Our analysis only needs mild assumptions on the distribution of asset returns. AlphaRob significantly outperforms competing methods on several simulated and real-world datasets, even after adjusting for transaction costs. AlphaRob is 7.5\% 7.5\% better on average than the nearest competitor, and 28\% 28\% better than the next-best combination portfolio method. Using our regret of regret, we are also able to explain the performance of the minimum-variance portfolio.},
  archive      = {J_EJOR},
  author       = {Deepayan Chakrabarti},
  doi          = {10.1016/j.ejor.2020.11.052},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {388-399},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Parameter-free robust optimization for the maximum-sharpe portfolio problem},
  volume       = {293},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Economic measures of capacity utilization: A nonparametric
short-run cost function analysis. <em>EJOR</em>, <em>293</em>(1),
375–387. (<a href="https://doi.org/10.1016/j.ejor.2020.12.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Measures of capacity utilization and capacity output are important metrics for evaluating firm performance. This is true whether capacity is considered from a cost accounting framework, an engineering standpoint, or an economics orientation. Ultimately, the crux of the capacity question is about resources not being used to their fullest extent. In an economics context, understanding where firms are producing on their average cost curve provides information about whether capacity utilization is greater than, less than or equal to unity. In real life, most firms are multi-output, multi-input in nature which makes estimation of capacity utilization and capacity output challenging if a cost based measure is desired. This is further complicated in a short run analysis incorporating multiple outputs and multiple fixed inputs where the relevant concept is the minimum of ray average cost. This paper develops appropriate mathematical programming models for measuring capacity utilization in the short-run for multiple-outputs and multiple fixed inputs. We offer a simple transformation that linearizes the non-linear DEA problem to estimate average, or ray average cost, and to determine capacity utilization and optimal output. The models are empirically tested on data from a number of U.S. electricity producers for the single output case, and a sample of dental practices for the multi-output case. Results show that for both industries, most firms were operating at less than full capacity, and needed to expand output to minimize their average costs.},
  archive      = {J_EJOR},
  author       = {Subhash C. Ray and John Walden and Lei Chen},
  doi          = {10.1016/j.ejor.2020.12.012},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {375-387},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Economic measures of capacity utilization: A nonparametric short-run cost function analysis},
  volume       = {293},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Option valuation under no-arbitrage constraints with neural
networks. <em>EJOR</em>, <em>293</em>(1), 361–374. (<a
href="https://doi.org/10.1016/j.ejor.2020.12.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we start from the no-arbitrage constraints in option pricing and develop a novel hybrid gated neural network (hGNN) based option valuation model. We adopt a multiplicative structure of hidden layers to ensure model differentiability. We also select the slope and weights of input layers to satisfy the no-arbitrage constraints. Meanwhile, a separate neural network is constructed for predicting option-implied volatilities. Using S&amp;P 500 options, our empirical analyses show that the hGNN model substantially outperforms well-established alternative models in the out-of-sample forecasting and hedging exercises. The superior prediction performance stems from our model’s ability in describing options on the boundary, and in offering analytical expressions for option Greeks which generate better hedging results.},
  archive      = {J_EJOR},
  author       = {Yi Cao and Xiaoquan Liu and Jia Zhai},
  doi          = {10.1016/j.ejor.2020.12.003},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {361-374},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Option valuation under no-arbitrage constraints with neural networks},
  volume       = {293},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The complete gaussian kernel in the multi-factor heston
model: Option pricing and implied volatility applications.
<em>EJOR</em>, <em>293</em>(1), 336–360. (<a
href="https://doi.org/10.1016/j.ejor.2020.11.050">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose two new representation formulas for the conditional marginal probability density of the multi-factor Heston model. The two formulas express the marginal density as a convolution with suitable Gaussian kernels whose variances are related to the conditional moments of price returns. Via asymptotic expansion of the non-Gaussian function in the convolutions, we derive explicit formulas for European-style option prices and implied volatility. The European option prices can be expressed as Black–Scholes style terms plus corrections at higher orders in the volatilities of volatilities, given by the Black–Scholes Greeks. The explicit formula for the implied volatility clearly identifies the effect of the higher moments of the price on the implied volatility surface. Further, we derive the relationship between the VIX index and the variances of the two Gaussian kernels. As a byproduct, we provide an explanation of the bias between the VIX and the volatility of total returns, which offers support to recently proposed methods to compute the variance risk premium. Via a series of numerical exercises, we analyse the accuracy of our pricing formula under different parameter settings for the one- and two-factor models applied to index options on the S&amp;P500 and show that our approximation substantially reduces the computational time compared to that of alternative closed-form solution methods. In addition, we propose a simple approach to calibrate the parameters of the multi-factor Heston model based on the VIX index, and we apply the approach to the double and triple Heston models.},
  archive      = {J_EJOR},
  author       = {Maria Cristina Recchioni and Giulia Iori and Gabriele Tedeschi and Michelle S. Ouellette},
  doi          = {10.1016/j.ejor.2020.11.050},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {336-360},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {The complete gaussian kernel in the multi-factor heston model: Option pricing and implied volatility applications},
  volume       = {293},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Impact of timing in post-warning prepositioning decisions on
performance measures of disaster management: A real-life application.
<em>EJOR</em>, <em>293</em>(1), 312–335. (<a
href="https://doi.org/10.1016/j.ejor.2020.11.051">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This research analyzes the impact of timing of post-warning and pre-disaster stock prepositioning decisions in disasters with an advance warning, such as hurricanes. From the warning time to the landfall time, disaster planners receive updated information regarding the hurricane&#39;s trajectory and the potential target region iteratively. The planners should decide when the best trigger time (TT) is to start the preparedness activities (prepositioning stocks of emergency goods). The quality of a given TT is evaluated concerning two performance measures: (i) the total logistics cost in the preparedness and response phases; and (ii) the minimum response time (RT) needed to transfer goods from the response facilities to affected areas in the response phase. A stochastic optimization model is designed to determine the best TT, preparedness decisions, and response operations. The computational complexity of the model is reduced using a graph-theoretic conversion. We test the converted model on experimental data based on major hurricanes from 2001 to 2017 on the United States southeastern coast. Sensitivity analysis of the model shows that delaying TT makes a non-linear reduction in the total logistics cost and non-linear increment in the shortest possible RT. The optimal TT makes the best compromise between the total logistics cost and the speed of the response operations, according to the preference of disaster planners.},
  archive      = {J_EJOR},
  author       = {Shabnam Rezapour and Reza Zanjirani Farahani and Nazanin Morshedlou},
  doi          = {10.1016/j.ejor.2020.11.051},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {312-335},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Impact of timing in post-warning prepositioning decisions on performance measures of disaster management: A real-life application},
  volume       = {293},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Optimal investment under ambiguous technology shocks.
<em>EJOR</em>, <em>293</em>(1), 304–311. (<a
href="https://doi.org/10.1016/j.ejor.2020.11.047">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper analyzes the behavior of a firm facing an ambiguous technology shock and the effects of the attitude toward ambiguity on optimal capital investment using the smooth ambiguity model of Klibanoff et al. (2005). Although it seems intuitive that an increase in ambiguity aversion always reduces the optimal capital investment, this is not necessarily true because the shape of the production function plays a key role in determining the effect. Under some conditions, we show that the optimal amount of capital investment increases ( decreases ) in ambiguity aversion if the production function is substitute (complement), and that this result is counterintuitive when the production function is substitute. Furthermore, our main results hold if we assume the α α -maxmin preferences in Ghirardato et al. (2004).},
  archive      = {J_EJOR},
  author       = {Takao Asano and Yusuke Osaki},
  doi          = {10.1016/j.ejor.2020.11.047},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {304-311},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Optimal investment under ambiguous technology shocks},
  volume       = {293},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Modeling and solving the multimodal car- and ride-sharing
problem. <em>EJOR</em>, <em>293</em>(1), 290–303. (<a
href="https://doi.org/10.1016/j.ejor.2020.11.046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce the multimodal car- and ride-sharing problem (MMCRP), in which a pool of cars is used to cover a set of ride requests while uncovered requests are assigned to other modes of transport (MOT). A car’s route consists of one or more trips. Each trip must have a specific but non-predetermined driver, start in a depot and finish in a (possibly different) depot. Ride-sharing between users is allowed, even when two rides do not have the same origin and/or destination. A user has always the option of using other modes of transport according to an individual list of preferences. The problem can be formulated as a vehicle scheduling problem. In order to solve the problem, an auxiliary graph is constructed in which each trip starting and ending in a depot, and covering possible ride-shares, is modeled as an arc in a time-space graph. We propose a two-layer decomposition algorithm based on column generation, where the master problem ensures that each request can only be covered at most once, and the pricing problem generates new promising routes by solving a kind of shortest-path problem in a time-space network. Computational experiments based on realistic instances are reported. The benchmark instances are based on demographic, spatial, and economic data of Vienna, Austria. We solve large instances with the column generation based approach to near optimality in reasonable time, and we further investigate various exact and heuristic pricing schemes.},
  archive      = {J_EJOR},
  author       = {Miriam Enzi and Sophie N. Parragh and David Pisinger and Matthias Prandtstetter},
  doi          = {10.1016/j.ejor.2020.11.046},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {290-303},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Modeling and solving the multimodal car- and ride-sharing problem},
  volume       = {293},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Towards understanding socially influenced vaccination
decision making: An integrated model of multiple criteria belief
modelling and social network analysis. <em>EJOR</em>, <em>293</em>(1),
276–289. (<a href="https://doi.org/10.1016/j.ejor.2020.12.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Understanding the socially influenced decision-making process that determines voluntary vaccination is essential for developing strategies and interventions of vaccine-preventable diseases. Both theoretical and experimental studies have suggested that a variety of factors, such as safety of vaccines, severity of diseases, information and advice from healthcare professionals, influence an individual&#39;s intention to vaccinate. However, limited research has been conducted on analysing systematically how individuals’ vaccine acceptance decisions are made from their beliefs and judgements on the influential factors. In particular, there is lack of quantitative analysis on how individuals’ beliefs and judgements may evolve from the spreading of vaccination-related information in a social network, which further affects their decision making. In this paper, an integrated model is first proposed to characterise the socially influenced vaccination decision-making process, in which each individual&#39;s beliefs and subjective judgements on the decision criteria are formulated as belief distributions in the framework of multiple criteria decision analysis (MCDA). The spreading of social influence in the network environment is further incorporated into the information aggregation process for supporting informed vaccination decision analysis. A series of simulation-based analyses on a real-world social network is conducted to demonstrate that the overall vaccination coverage is determined primarily by individuals’ beliefs and judgements on the decision criteria, and is also affected sensitively by the characteristics of influence spreading (including the content and amount of vaccination-related information) in the social network.},
  archive      = {J_EJOR},
  author       = {Lei Ni and Yu-wang Chen and Oscar de Brujin},
  doi          = {10.1016/j.ejor.2020.12.011},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {276-289},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Towards understanding socially influenced vaccination decision making: An integrated model of multiple criteria belief modelling and social network analysis},
  volume       = {293},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A new measure of technical efficiency in data envelopment
analysis based on the maximization of hypervolumes: Benchmarking,
properties and computational aspects. <em>EJOR</em>, <em>293</em>(1),
263–275. (<a href="https://doi.org/10.1016/j.ejor.2020.12.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The measurement of technical efficiency attracts considerable interest in the literature. In fact, following on from the seminal works by Koopmans (1951) , Debreu (1951) , Shephard (1953) and Farrell (1957), a substantial amount of literature has been dedicated to methods for estimating production frontiers and measuring the technical efficiency of production units. Data Envelopment Analysis (DEA) has an important role among current techniques for determining technical efficiency due to its flexibility when it comes to confronting multiple inputs and outputs as well as its non-parametric nature. Many different DEA-based technical efficiency measures have evolved over the last forty years, including radial, hyperbolic, directional, (weighted) additive, slacks-based measures, etc. Nevertheless, there is still room for harnessing new measures that are capable of satisfying interesting properties. For instance, slacks-based measures generally yield solutions with zero values in some slacks, which may mean overloading some of the other dimensions to reach the efficient frontier, thereby involving unbalanced efforts that are unrealistic. Moreover, the projection point determined by standard measures is not unique which is a further weakness from a benchmarking perspective. The purpose of this paper is to propose a novel technical efficiency performance measure in DEA on the premise of maximizing the hypervolume, while dealing with these problems and satisfying additional properties at the same time. In particular, we prove that the new approach yields unique projection points, which is not a usual property of DEA technical efficiency measures. From a computational perspective, second-order cone programming is capable of solving the new measure. Finally, an empirical example extracted from the literature serves to illustrate the new methodology.},
  archive      = {J_EJOR},
  author       = {Juan Aparicio and Juan F. Monge and Nuria Ramón},
  doi          = {10.1016/j.ejor.2020.12.002},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {263-275},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A new measure of technical efficiency in data envelopment analysis based on the maximization of hypervolumes: Benchmarking, properties and computational aspects},
  volume       = {293},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A bayesian learning model for estimating unknown demand
parameter in revenue management. <em>EJOR</em>, <em>293</em>(1),
248–262. (<a href="https://doi.org/10.1016/j.ejor.2020.11.049">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article proposes a series of Bayesian learning and pricing models to uncover the unknown demand parameter through a data driven process and in the meantime to achieve a good regret bound for revenue. Treating the unknown demand sensitivity as a multinomial random variable whose parameters follow a Dirichlet prior, we take an advantage of conjugate property and derive the analytical form of posterior parameters. We show that the proposed learning process ensures the asymptotic convergence of the parameters. In addition to exploration, with few restrictive assumptions we develop a heuristic algorithm for revenue exploitation and establish a regret bound that is comparable to the best bounds available in the literature. We also show that if the estimated parameter falls into the neighborhood of its true value with sufficient learning, the heuristic can switch to the dynamic programming process. The revenue gap between the optimal dynamic programming process and its approximate counterpart becomes negligible. Numerical experiments confirm the theoretical conclusion. The heuristic algorithms, including a simplified two-price policy and an approximate dynamic programming heuristic, generally lead to an expected revenue with a small gap from its optimal level.},
  archive      = {J_EJOR},
  author       = {Baichun Xiao and Wei Yang},
  doi          = {10.1016/j.ejor.2020.11.049},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {248-262},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A bayesian learning model for estimating unknown demand parameter in revenue management},
  volume       = {293},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Online incentive-compatible mechanisms for traffic
intersection auctions. <em>EJOR</em>, <em>293</em>(1), 229–247. (<a
href="https://doi.org/10.1016/j.ejor.2020.12.030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present novel online mechanisms for traffic intersection auctions in which users bid for priority service. We assume that users at the front of their lane are requested to declare their delay cost, i.e. value of time, and that users are serviced in decreasing order of declared delay cost. Since users are expected to arrive dynamically at traffic intersections, static pricing approaches may fail to estimate user expected waiting time accurately, and lead to non-strategyproof payments. To address this gap, we propose two Markov chain models to determine the expected waiting time of participants in the auction. Both models take into account the probability of future arrivals at the intersection. In a first model, we assume that the probability of future arrivals is uniform across lanes of the intersection. This queue-based model only tracks the number of lower- and higher-bidding users on access lanes, and the number of empty lanes. The uniformness assumption is relaxed in a second, lane-based model which accounts for lane-specific user arrival probabilities at the expense of an extended state space. We then design a mechanism to determine incentive-compatible payments in the dynamic sense. The resulting online mechanisms maximize social welfare in the long run. Numerical experiments on a four-lane traffic intersection are reported and compared to a static incentive-compatible mechanism. Our findings show that static incentive-compatible mechanisms may lead users to misreport their delay costs. In turn, the proposed online mechanisms are shown to be incentive-compatible in the dynamic sense.},
  archive      = {J_EJOR},
  author       = {David Rey and Michael W. Levin and Vinayak V. Dixit},
  doi          = {10.1016/j.ejor.2020.12.030},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {229-247},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Online incentive-compatible mechanisms for traffic intersection auctions},
  volume       = {293},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Selective linearization for multi-block statistical
learning. <em>EJOR</em>, <em>293</em>(1), 219–228. (<a
href="https://doi.org/10.1016/j.ejor.2020.12.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the problem of minimizing a sum of several convex non-smooth functions and discuss the selective linearization method (SLIN), which iteratively linearizes all but one of the functions and employs simple proximal steps. The algorithm is a form of multiple operator splitting in which the order of processing partial functions is not fixed, but rather determined in the course of calculations. SLIN is globally convergent for an arbitrary number of component functions without artificial duplication of variables. We report results from extensive numerical experiments in two statistical learning settings such as large-scale overlapping group Lasso and doubly regularized support vector machine. In each setting, we introduce novel and efficient solutions for solving sub-problems. The numerical results demonstrate the efficacy and accuracy of SLIN.},
  archive      = {J_EJOR},
  author       = {Yu Du and Xiaodong Lin and Minh Pham and Andrzej Ruszczyński},
  doi          = {10.1016/j.ejor.2020.12.010},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {219-228},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Selective linearization for multi-block statistical learning},
  volume       = {293},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The effect of measurement errors on the performance of the
exponentially weighted moving average control charts for the ratio of
two normally distributed variables. <em>EJOR</em>, <em>293</em>(1),
203–218. (<a href="https://doi.org/10.1016/j.ejor.2020.11.042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Investigating the effect of measurement errors on the control chart monitoring the ratio of two normal random variables is an important task to facilitate the use of this kind of control chart in practice. Moreover, a deep insight into the problem can help practitioners to find a way to reduce unexpected impacts of measurement errors on the chart performance. This paper provides a study on the performance of the exponentially weighted moving average control chart monitoring the ratio in the presence of measurement errors. We extend the linear covariate error model applied in previous studies to a more general situation, which makes the study more realistic. The numerical results show that although the precision error and the accuracy error have negative influences on the proposed chart performance when these errors are not large these influences are not significant.},
  archive      = {J_EJOR},
  author       = {H.D. Nguyen and K.P. Tran and K.D. Tran},
  doi          = {10.1016/j.ejor.2020.11.042},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {203-218},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {The effect of measurement errors on the performance of the exponentially weighted moving average control charts for the ratio of two normally distributed variables},
  volume       = {293},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Robust multi-product newsvendor model with uncertain demand
and substitution. <em>EJOR</em>, <em>293</em>(1), 190–202. (<a
href="https://doi.org/10.1016/j.ejor.2020.12.023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work studies a Robust Multi-product Newsvendor Model with Substitution (R-MNMS), where the demand and the substitution rates are stochastic and are subject to cardinality-constrained uncertainty sets. The goal of this work is to determine the optimal order quantities of multiple products to maximize the worst-case total profit. To achieve this, we first show that for given order quantities, computing the worst-case total profit, in general, is NP-hard. Therefore, we derive the closed-form optimal solutions for the following three special cases: (1) if there are only two products, (2) if there is no substitution among different products, and (3) if the budget of demand uncertainty is equal to the number of products. For a general R-MNMS, we formulate it as a mixed-integer linear program with an exponential number of constraints and develop a branch and cut algorithm to solve it. For large-scale problem instances, we further propose a conservative approximation of R-MNMS and prove that under some certain conditions, this conservative approximation yields an exact optimal solution to R-MNMS. The numerical study demonstrates the effectiveness of the proposed approaches and the robustness of our model.},
  archive      = {J_EJOR},
  author       = {Jie Zhang and Weijun Xie and Subhash C. Sarin},
  doi          = {10.1016/j.ejor.2020.12.023},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {190-202},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Robust multi-product newsvendor model with uncertain demand and substitution},
  volume       = {293},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A win–win strategy analysis for an original equipment
manufacturer and a contract manufacturer in a competitive market.
<em>EJOR</em>, <em>293</em>(1), 177–189. (<a
href="https://doi.org/10.1016/j.ejor.2020.12.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the outsourcing relationship between an original equipment manufacturer (OEM) and a contract manufacturer (CM) when both compete in the same product market. We identify optimal solutions and the favorable conditions that both players may benefit from outsourcing when either one is the dominant player in the Cournot competition in the base setting. In the extended models, we include a supplier in the game who sells the key component to the CM and explore all players’ decisions on pricing and/or quantity. We find that the optimal wholesale price for outsourcing is normally higher when the CM is dominant than that when the OEM is dominant. The Win–win conditions that both the OEM and the CM favor outsourcing in various scenarios are identified. There exist some scenarios that no outsourcing will be formed due to conflicting interests between the OEM and the CM. The supplier may benefit from outsourcing due to additional OEM&#39;s quantity when the OEM&#39;s production cost is high. In that case, a Win–Win–Win result for outsourcing occurs for all three players in the extended model.},
  archive      = {J_EJOR},
  author       = {Yuwen Chen and Gulver Karamemis and Jiayuan Zhang},
  doi          = {10.1016/j.ejor.2020.12.016},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {177-189},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A Win–Win strategy analysis for an original equipment manufacturer and a contract manufacturer in a competitive market},
  volume       = {293},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Warehousing platform’s revenue management: A dynamic model
of coordinating space allocation for self-use and rent. <em>EJOR</em>,
<em>293</em>(1), 167–176. (<a
href="https://doi.org/10.1016/j.ejor.2020.12.014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, some giant retail platforms have begun to invest large amounts of money in building warehouses. With abundant warehousing space, these platforms are renting out space to third-party retailers (TPRs) with insufficient storage space. However, such rental programs generate a new operational problem for these platforms, namely, how to divide their space between space for self-use and space for rent. To address the optimal space allocation decisions for this operational problem, we study a finite horizon and periodic review warehouse model where some items are sold by the platform, and other items are sold by TPRs. More specifically, we start with a base model with two items and prove the optimality of a base stock policy for the base model and the monotonicity of the optimal space allocation decisions regarding several key system parameters (such as inventory and capacity parameters). We then study several extensions of the base model by considering demand forecasts, demand correlation, and multiple items (more than two). Particularly, when addressing the extension with multiple items, we propose a heuristic based on the idea of approximate dynamic programming to overcome the curse of dimensionality. To examine the effectiveness of our heuristic, we present a computational study that is based on real-life datasets provided by the largest furniture retail platform in China (Red-Star Macalline). The numerical results demonstrate that our heuristic has the potential to solve medium- and large-scale problems effectively and efficiently.},
  archive      = {J_EJOR},
  author       = {Ye Shi and Yugang Yu and Yuxuan Dong},
  doi          = {10.1016/j.ejor.2020.12.014},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {167-176},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Warehousing platform’s revenue management: A dynamic model of coordinating space allocation for self-use and rent},
  volume       = {293},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Joint optimization of container slot planning and truck
scheduling for tandem quay cranes. <em>EJOR</em>, <em>293</em>(1),
149–166. (<a href="https://doi.org/10.1016/j.ejor.2020.12.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper examines the loading operations of a new type of quay crane, the tandem quay crane (TQC), which has been designed to increase the terminal productivity by lifting more containers simultaneously. Due to the special characteristics of the TQC, more than one truck is required to serve a tandem-lift of it, and the containers handled in a tandem-lift must be loaded into two neighboring rows in the same tier of the containership. Of particular importance in schedules at the terminal is to coordinate the truck scheduling and container stowage slot plan with the TQCs, which is a key challenge in practice. This paper is an attempt to tackle this issue by developing a mixed integer linear programming (MILP) model with an objective of minimizing the completion time of the loading operation under the full utilization of the TQC. Due to the complexity of the MILP model, we then propose a model to derive lower bounds of the problem, and a greedy randomized adaptive search procedure (GRASP) to solve the problem. Computational experiments are conducted with a variety of instances. The results derived by GRASP for solving small size problems are within 0.04\% of the optimal results obtained by the Gurobi. For large scale instances, GRASP outperforms the Gurobi in terms of the solution quality and computation time. Additionally, on average results derived by GRASP are within 8.2\% of the lower bound. Further experiments demonstrate the advantage of the integrated optimization of container slot planning and truck scheduling for TQCs.},
  archive      = {J_EJOR},
  author       = {Lingrui Kong and Mingjun Ji and Zhendi Gao},
  doi          = {10.1016/j.ejor.2020.12.005},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {149-166},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Joint optimization of container slot planning and truck scheduling for tandem quay cranes},
  volume       = {293},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Pessimistic evasive flow capturing problems. <em>EJOR</em>,
<em>293</em>(1), 133–148. (<a
href="https://doi.org/10.1016/j.ejor.2020.12.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The evasive flow capturing problem (EFCP) is to locate a set of law enforcement facilities to intercept unlawful flows. One application of the EFCP is the location problem of weigh-in-motion systems deployed by authorities to detect overloaded vehicles characterized by evasive behavior. In contrast to the existing literature, this study focuses on the bounded-rationality of drivers and represents the most generic form of the EFCP. We present two pessimistic formulations of the problem to capture various degrees of ambiguity in the route choice of drivers. In particular, we look at the worst-case scenario, when drivers select roads with the highest damage costs. The resulting formulations yield a robust network design and represent the realistic behavior of drivers. The pessimistic formulations introduce another level in the optimization problem, for which we propose a cutting plane algorithm. The proposed solution methods demonstrate their effectiveness on real and randomly generated networks. We also provide numerical analysis to measure the value of considering pessimistic formulations and demonstrate the vulnerability of optimizing and optimistic assumptions on the behavior of drivers.},
  archive      = {J_EJOR},
  author       = {Aigerim Bogyrbayeva and Changhyun Kwon},
  doi          = {10.1016/j.ejor.2020.12.001},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {133-148},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Pessimistic evasive flow capturing problems},
  volume       = {293},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Manufacturer encroachment and product assortment under
vertical differentiation. <em>EJOR</em>, <em>293</em>(1), 120–132. (<a
href="https://doi.org/10.1016/j.ejor.2020.11.044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To study channel choice and assortment selection under vertical differentiation, we propose game-theoretic models in a supply chain consisting of a two-product manufacturer and a retailer. The manufacturer can encroach to build an online channel to sell directly to consumers, in addition to selling indirectly via an offline channel operated by the retailer. This dual-channel supply chain incorporates both product competition and channel competition. Product competition exists no matter whether the manufacturer encroaches, because the products compete for same end consumers. Channel competition (i.e., the competition between the online and offline channels) occurs when the manufacturer encroaches. Although incurring channel competition, manufacturer encroachment alleviates product competition, because the dual-channel supply chain can distribute different products via different channels. We find that manufacturer encroachment causes a win-lose situation for the manufacturer and the retailer, and may benefit or harm the supply chain. When the initial product competition is fierce or the disutility of online shopping is trivial, the positive effect of alleviated product competition dominates the negative effect of incurred channel competition, and thus manufacturer encroachment benefits the supply chain. Our extended models show that the main results are robust.},
  archive      = {J_EJOR},
  author       = {Zhang Ting and Feng Xiaohui and Wang Ningning},
  doi          = {10.1016/j.ejor.2020.11.044},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {120-132},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Manufacturer encroachment and product assortment under vertical differentiation},
  volume       = {293},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Branch-and-cut approach based on generalized benders
decomposition for facility location with limited choice rule.
<em>EJOR</em>, <em>293</em>(1), 109–119. (<a
href="https://doi.org/10.1016/j.ejor.2020.12.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the exact solution approaches for a generalized competitive facility location problem. We consider a company that plans to introduce a service by opening a set of facilities. The objective is to maximize the profit taking into account the revenue and the fixed cost. It is assumed that when customers are offered with a set of open facilities, they first form the consideration set, i.e., the subset of open facilities that the customers are willing to patronize. They then split the buying power among the facilities in the set plus some outside option, according to Luce’s choice axiom. The resulting location problem provides a generalized framework that covers many existing models in competitive facility location problems where customers follow either the proportional choice rule or the partially binary choice rule. As our main contribution, we propose a branch-and-cut algorithm based on the generalized Benders decomposition scheme (B&amp;C-Benders), which projects out high-dimensional continuous variables in modeling the consideration set and only works on the projected decision space. Our extensive computational experiment shows that B&amp;C-Benders outperforms state-of-the-art exact approaches, both in terms of the computational time, and in terms of the number of instances solved to optimality. In the special case where customers follow the partially binary choice rule, B&amp;C-Benders turns out to be efficient for large-scale instances with thousands of customer zones and hundreds of facilities.},
  archive      = {J_EJOR},
  author       = {Yun Hui Lin and Qingyun Tian},
  doi          = {10.1016/j.ejor.2020.12.017},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {109-119},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Branch-and-cut approach based on generalized benders decomposition for facility location with limited choice rule},
  volume       = {293},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Real-time bi-objective personnel re-scheduling in the retail
industry. <em>EJOR</em>, <em>293</em>(1), 93–108. (<a
href="https://doi.org/10.1016/j.ejor.2020.12.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Personnel scheduling consists of determining least-cost work schedules to cover the demand of multiple jobs expressed in number of employees per job and period of a given horizon. During the operations, minor disruptions to the planned schedule, such as employee lateness, often occur and must be addressed in real time without changing too much the schedule. In this paper, we develop a fast re-scheduling heuristic that can be used to correct such minor disruptions in a retail industry context where employees can be assigned to a wide variety of shifts, starting and ending at numerous times. This heuristic can compute a set of approximate Pareto-optimal solutions that achieve a good compromise between cost and number of shift changes. It can be seen as a labeling algorithm that partially explores the network defined by the edges of the convex hull of the solutions of an integer program. Theoretical insights are provided to support certain speedup rules. Computational experiments conducted on instances derived from real-life datasets involving up to 95 employees show the heuristic efficiency. In less than one second on average, it can compute Pareto-optimal solutions for more than 98\% of the tested scenarios.},
  archive      = {J_EJOR},
  author       = {Rachid Hassani and Guy Desaulniers and Issmail Elhallaoui},
  doi          = {10.1016/j.ejor.2020.12.013},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {93-108},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Real-time bi-objective personnel re-scheduling in the retail industry},
  volume       = {293},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Single-machine hierarchical scheduling with release dates
and preemption to minimize the total completion time and a regular
criterion. <em>EJOR</em>, <em>293</em>(1), 79–92. (<a
href="https://doi.org/10.1016/j.ejor.2020.12.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we consider the single-machine hierarchical scheduling problems with release dates and preemption, where the primary criterion is the total completion time and the secondary criterion is an arbitrarily regular scheduling criterion, which is of either the sum-form or the max-form. We aim to find a feasible preemptive schedule that minimizes the secondary criterion, subject to the condition that the primary criterion is minimized. We show that the variants of the problems under study are polynomially solvable. To address these problems, we develop new solution techniques that establish some hereditary properties for the feasible schedules and instances, and present a complete description of the feasible schedules through some elaborately constructed job-permutations.},
  archive      = {J_EJOR},
  author       = {Rubing Chen and Jinjiang Yuan and C.T. Ng and T.C.E. Cheng},
  doi          = {10.1016/j.ejor.2020.12.006},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {79-92},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Single-machine hierarchical scheduling with release dates and preemption to minimize the total completion time and a regular criterion},
  volume       = {293},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Solving integrated operating room planning and scheduling:
Logic-based benders decomposition versus branch-price-and-cut.
<em>EJOR</em>, <em>293</em>(1), 65–78. (<a
href="https://doi.org/10.1016/j.ejor.2020.12.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Integrated operating room planning and scheduling (IORPS) allocates patients optimally to different days in a planning horizon, assigns the allocated set of patients to ORs, and sequences/schedules these patients within the list of ORs and surgeons to maximize the total scheduled surgical time. The state-of-the-art model in the IORPS literature is a hybrid constraint programming (CP) and integer programming (IP) technique that is efficiently solved by a multi-featured Branch-Price-&amp;Cut (BP&amp;C) algorithm. We extend the IORPS literature in two ways: (i) we develop new mixed-integer programming (MIP) and CP models that improve the existing CP-IP model and (ii) we develop various combinatorial Benders decomposition algorithms that outperform the existing BP&amp;C algorithm. Using the same dataset as used for the existing methods, we show that our MIP model achieves an average optimality gap of 3.84\%, outperforming the existing CP-IP model that achieves an average optimality gap of 11.84\%. Furthermore, our MIP model is 54–92 times faster than the CP-IP model in some of the optimally solved instances of the problem. We demonstrate that our best Benders decomposition approach achieves an average optimality gap of 0.88\%, whereas the existing BP&amp;C algorithm achieves an average optimality gap of 2.81\%.},
  archive      = {J_EJOR},
  author       = {Vahid Roshanaei and Bahman Naderi},
  doi          = {10.1016/j.ejor.2020.12.004},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {65-78},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Solving integrated operating room planning and scheduling: Logic-based benders decomposition versus branch-price-and-cut},
  volume       = {293},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Maximizing perturbation radii for robust convex
quadratically constrained quadratic programs. <em>EJOR</em>,
<em>293</em>(1), 50–64. (<a
href="https://doi.org/10.1016/j.ejor.2020.12.032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Under the assumption that uncertain coefficients corresponding to each constraint are perturbed in an ellipsoidal set, we consider the problem of maximizing the perturbation radius of the ellipsoidal set associated to a robust convex quadratically constrained quadratic programming problem to maintain some properties of a pre-decision. To this end, a fractional programming problem is first formulated to solve the problem, and then equivalently reformulated into linear conic programs over positive semi-definite, second-order cones that are solvable in polynomial time. Numerical experiments in connection with the robust Markowitz’s portfolio selection problem are provided to demonstrate the proposed concept of sensitivity analysis. Additionally, certain numerical results are also presented to compare the efficiency of direct solutions of the proposed linear conic programs with that of a bisection method for the corresponding fractional programming problem.},
  archive      = {J_EJOR},
  author       = {Pengfei Yu and Ruotian Gao and Wenxun Xing},
  doi          = {10.1016/j.ejor.2020.12.032},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {50-64},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Maximizing perturbation radii for robust convex quadratically constrained quadratic programs},
  volume       = {293},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Ellipsoidal one-class constraint acquisition for
quadratically constrained programming. <em>EJOR</em>, <em>293</em>(1),
36–49. (<a href="https://doi.org/10.1016/j.ejor.2020.12.018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose Ellipsoidal One-Class Constraint Acquisition (EOCCA), a fast and scalable algorithm for the acquisition of constraints for Mixed-Integer Quadratically Constrained Programming (MIQCP) models from data. EOCCA acquires a well-formed MIQCP model using solely the examples of the feasible solutions to this model. It combines x-means partitioning, standardization, and principal components analysis to preprocess the training set and then wraps the preprocessed data into several hyper-ellipsoids expressed using MIQCP constraints. These MIQCP constraints are projected back to the space of the original training set, and their further use does not require data preprocessing. Experimental evaluation shows that EOCCA scores better than a state-of-the-art algorithm in terms of fidelity of the acquired constraints to ground-truth constraints and achieves this in few orders of magnitude shorter time. We demonstrate the practical use case of EOCCA in a fully automated workflow of modeling and optimization of a rice farm using real-world data.},
  archive      = {J_EJOR},
  author       = {Tomasz P. Pawlak and Bartosz Litwiniuk},
  doi          = {10.1016/j.ejor.2020.12.018},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {36-49},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Ellipsoidal one-class constraint acquisition for quadratically constrained programming},
  volume       = {293},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A novel embedded min-max approach for feature selection in
nonlinear support vector machine classification. <em>EJOR</em>,
<em>293</em>(1), 24–35. (<a
href="https://doi.org/10.1016/j.ejor.2020.12.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, feature selection has become a challenging problem in several machine learning fields, such as classification problems. Support Vector Machine (SVM) is a well-known technique applied in classification tasks. Various methodologies have been proposed in the literature to select the most relevant features in SVM. Unfortunately, all of them either deal with the feature selection problem in the linear classification setting or propose ad-hoc approaches that are difficult to implement in practice. In contrast, we propose an embedded feature selection method based on a min-max optimization problem, where a trade-off between model complexity and classification accuracy is sought. By leveraging duality theory, we equivalently reformulate the min-max problem and solve it without further ado using off-the-shelf software for nonlinear optimization. The efficiency and usefulness of our approach are tested on several benchmark data sets in terms of accuracy, number of selected features and interpretability.},
  archive      = {J_EJOR},
  author       = {Asunción Jiménez-Cordero and Juan Miguel Morales and Salvador Pineda},
  doi          = {10.1016/j.ejor.2020.12.009},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {24-35},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A novel embedded min-max approach for feature selection in nonlinear support vector machine classification},
  volume       = {293},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Typology and literature review on multiple supplier
inventory control models. <em>EJOR</em>, <em>293</em>(1), 1–23. (<a
href="https://doi.org/10.1016/j.ejor.2020.11.023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper reviews the literature on inventory models with multiple sourcing options and presents a typology for classification. By means of the classification, the progression of the literature (policies and modeling assumptions) is illustrated, the main decision trade-offs in multiple sourcing are identified and avenues for future research are pointed out. Multiple sourcing decision models trade off the added costs of backup sourcing against higher inventory or shortage costs under single sourcing. The value of multiple over single sourcing is found to increase in the uncertainty to be buffered, in inventory holding and shortage costs, as well as in the constraints of the primary source. The literature evolved from small, restrictive models to larger problems and more realism. Accordingly, replenishment policies progressed from optimal policies to more heuristic decision rules. Three areas for future research are suggested for moving the field forward and towards more practical applicability. (1) Further integration of model aspects such as the extension of replenishment policies to more than two suppliers and to multi-echelon models. (2) Focusing on supply chain resilience with decision making disruption events or demand spikes under consideration of risk preferences. (3) Utilizing industry data in machine learning and data-driven methodologies.},
  archive      = {J_EJOR},
  author       = {Josef Svoboda and Stefan Minner and Man Yao},
  doi          = {10.1016/j.ejor.2020.11.023},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {1-23},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Typology and literature review on multiple supplier inventory control models},
  volume       = {293},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Corrigendum to “weighted network search games with multiple
hidden objects and multiple search teams” [european journal of
operational research, vol. 289 (1) 2021, 338-349]. <em>EJOR</em>,
<em>292</em>(3), 1209. (<a
href="https://doi.org/10.1016/j.ejor.2020.12.057">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_EJOR},
  author       = {Abdolmajid Yolmeh and Melike Baykal-Gürsoy},
  doi          = {10.1016/j.ejor.2020.12.057},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1209},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Corrigendum to “Weighted network search games with multiple hidden objects and multiple search teams” [European journal of operational research, vol. 289 (1) 2021, 338-349]},
  volume       = {292},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Degradation data analysis based on gamma process with
random effects. <em>EJOR</em>, <em>292</em>(3), 1200–1208. (<a
href="https://doi.org/10.1016/j.ejor.2020.11.036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper focuses on investigating the Gamma degradation model with random effects. A generalized p -value procedure is proposed to test whether there exist some heterogeneities among the degradation processes of different units. Using the Cornish-Fisher expansion, an approximate confidence interval (CI) is obtained for the shape parameter. The generalized confidence intervals (GCIs) are derived for model parameters and commonly used reliability metrics (e.g., the quantile, the reliability function of the lifetime) based on the generalized pivotal quantity method. Those inference procedures are also extended to the accelerated degradation case. The performances of the proposed GCIs are assessed by Monte Carlo simulations. In the simulation, we compared our methods with the Wald CIs and bootstrap-p CIs under moderate and large sample sizes. It is found that the performance of the GCI procedures is better than the Wald CIs and bootstrap-p CIs in terms of coverage probabilities. Finally, the proposed procedures are illustrated by two examples.},
  archive      = {J_EJOR},
  author       = {Xiaofei Wang and Bing Xing Wang and Yili Hong and Pei Hua Jiang},
  doi          = {10.1016/j.ejor.2020.11.036},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1200-1208},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Degradation data analysis based on gamma process with random effects},
  volume       = {292},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Loss given default decomposition using mixture distributions
of in-default events. <em>EJOR</em>, <em>292</em>(3), 1187–1199. (<a
href="https://doi.org/10.1016/j.ejor.2020.11.034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modeling loss in the case of default is a crucial task for financial institutions to support the decision making process in the risk management framework. It has become an inevitable part of modern debt collection strategies to keep promising loans on the banking book and to write off those that are not expected to be recovered at a satisfactory level. Research tends to model Loss Given Default directly or to decompose it based on the dependent variable distribution. Such an approach neglects the patterns which exist beneath the recovery process and are mainly driven by the activities made by collectors in the event of default. To overcome this problem, we propose a decomposition of the LGD model that integrates cures, partial recoveries, and write-offs into one equation, defined based on common collection strategies. Furthermore, various levels of data aggregation are applied to each component to reflect the domain that influences each stage of the default process. To assess the robustness of our approach, we propose a comparison with two benchmark models on two different datasets. We assess the goodness of fit on out-of-sample data and show that the proposed decomposition is more effective than state-of-the-art methods, maintaining a strong level of interpretability.},
  archive      = {J_EJOR},
  author       = {Wojciech Starosta},
  doi          = {10.1016/j.ejor.2020.11.034},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1187-1199},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Loss given default decomposition using mixture distributions of in-default events},
  volume       = {292},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Generalized estimation of productivity with multiple bad
outputs: The importance of materials balance constraints. <em>EJOR</em>,
<em>292</em>(3), 1165–1186. (<a
href="https://doi.org/10.1016/j.ejor.2020.11.025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Previous research has frequently estimated the directional technology distance function (DTDF) to more flexibly model multiple-input and multiple-output production, firm inefficiency, and productivity growth. For example, with firms such as electric utilities, one must model the production of good and bad outputs using good and bad inputs. Typically, all inputs and outputs are potentially endogenous. In previous work, we show how to identify a DTDF system using price equations based on profit maximization and compute optimal directions for measuring productivity change. However, this work has not imposed restrictions that limit substitution possibilities among inputs and outputs to a feasible set that is consistent with materials-balance constraints. Such constraints require that the weight of all inputs equals the weight of all outputs. The major innovation of this paper is that we include two types of functional relationships that impose the parametric analog of materials balance by modeling the generation of bad outputs and the use of bad inputs. The first requires that bad outputs are functionally related to good inputs and bad inputs. The second requires that bad inputs are functionally related to good inputs. We illustrate these methods using a balanced panel of 80 U.S. coal-fired electric generating plants from 1995–2005. Substantial differences are observed between the specification that includes the materials-balance constraints and the conventional approach that omits them, based on Bayes factors as well as measures of productivity and inefficiency. For many plants, improved management practices can reduce substantial inefficiencies in meeting emission constraints without reducing productivity growth.},
  archive      = {J_EJOR},
  author       = {Scott E. Atkinson and Mike G. Tsionas},
  doi          = {10.1016/j.ejor.2020.11.025},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1165-1186},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Generalized estimation of productivity with multiple bad outputs: The importance of materials balance constraints},
  volume       = {292},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Markov chain lumpability and applications to credit risk
modelling in compliance with the international financial reporting
standard 9 framework. <em>EJOR</em>, <em>292</em>(3), 1146–1164. (<a
href="https://doi.org/10.1016/j.ejor.2020.11.014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The aim of this paper is threefold. Firstly, we define the necessary quantities associated to the lumpability of a Markov chain and study their fundamental properties. Secondly, we examine the case of approximate lumpability of a non-lumpable Markov and an efficient method of minimizing the error in the approximation. Finally, we introduce a family of general minimization problems that can be approached using this method and examine applications in credit risk modelling, particularly under recent regulatory changes related to loan classification and provision calculations under IFRS 9.},
  archive      = {J_EJOR},
  author       = {K. Georgiou and G.N. Domazakis and D. Pappas and A.N. Yannacopoulos},
  doi          = {10.1016/j.ejor.2020.11.014},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1146-1164},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Markov chain lumpability and applications to credit risk modelling in compliance with the international financial reporting standard 9 framework},
  volume       = {292},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Magnitude of inefficiency. <em>EJOR</em>, <em>292</em>(3),
1133–1145. (<a
href="https://doi.org/10.1016/j.ejor.2020.11.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Various types of inefficiencies of a system state like the Nash equilibrium (NE) exist, such as social inefficiency, Pareto inefficiency, etc. (A system state is inefficient if it is inferior to another realizable state.) Firstly, this article presents a general procedure to obtain each inefficiency measure. The procedure brings as each inefficiency measure, the maximum degree of corresponding inferiority of the state to some other. We examine the procedure in the game-theory context. Vastly-many people use the social-inefficiency measure (represented by the price of anarchy [PoA]). However, it cannot always serve as a Pareto-inefficiency measure. Contrarily, the Pareto-inefficiency measures are yet to establish. Secondly, we follow the procedure (to which PoA also conforms) and obtain Pareto-inefficiency measures. We confirm that they distinguish Pareto inefficiencies that PoA cannot always distinguish. We show a fixed relation between the values of the measures. Further, if a state is proportional to a Pareto-optimal state, proposed measures of strict Pareto inefficiency and Pareto inefficiency behave in identical and straightforward ways. Then, their value is the proportionality constant. Using examples, we examine the measures.},
  archive      = {J_EJOR},
  author       = {Hisao Kameda},
  doi          = {10.1016/j.ejor.2020.11.011},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1133-1145},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Magnitude of inefficiency},
  volume       = {292},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Stochastic frontier models with time-varying conditional
variances. <em>EJOR</em>, <em>292</em>(3), 1115–1132. (<a
href="https://doi.org/10.1016/j.ejor.2020.11.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we introduce stochastic frontier models in which either the inefficiency or the noise component or both the components follow Generalized AutoRegressive Conditional Heteroskedasticity GARCH(1,1) process. Bayesian estimation of the technology parameters are proposed using a half-normal (exponential) distribution for the inefficiency component, and a normal distribution for the noise component. We show, in simulations, that predictions of inefficiency ignoring the GARCH(1,1) process are not aligned with their true values. We use real panel data on electricity distribution and show how to estimate our proposed model, and predict inefficiency. Moreover, we examine the effect of ignoring GARCH specification on economic measures like input elasticities, technical change and returns to scale. We also provide test for GARCH vs no GARCH models using Bayes factors. Finally, we examine variants of the GARCH family such as the ARCH and EGARCH models and we compared GARCH models of different orders.},
  archive      = {J_EJOR},
  author       = {Mike G. Tsionas and Subal C. Kumbhakar},
  doi          = {10.1016/j.ejor.2020.11.008},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1115-1132},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Stochastic frontier models with time-varying conditional variances},
  volume       = {292},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Accelerated degradation tests with inspection effects.
<em>EJOR</em>, <em>292</em>(3), 1099–1114. (<a
href="https://doi.org/10.1016/j.ejor.2020.11.041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study proposes a framework to analyze accelerated degradation testing (ADT) data in the presence of inspection effects. Motivated by a real dataset from the electric industry, we study two types of effects induced by inspections. After each inspection, the system degradation level instantaneously reduces by a random value. Meanwhile, the degrading rate is elevated afterwards. Considering the absence of observations due to practical reasons, we employ the expectation–maximization (EM) algorithm to analytically estimate the unknown parameters in a stepwise Wiener degradation process with covariates. Moreover, to maintain the level of generality for the adaption of the method in various scenarios, a confidence density approach is utilized to hierarchically estimate the parameters in the acceleration link function. The proposed methods can provide efficient parameter estimation under complex link functions with multiple stress factors. Further, confidence intervals are derived based on the large-sample approximation. Simulation studies and a case study from Schneider Electric are used to illustrate the proposed methods. The results show that the proposed model yields a remarkably better fit to the Schneider data in comparison to the conventional Wiener ADT model.},
  archive      = {J_EJOR},
  author       = {Xiujie Zhao and Piao Chen and Olivier Gaudoin and Laurent Doyen},
  doi          = {10.1016/j.ejor.2020.11.041},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1099-1114},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Accelerated degradation tests with inspection effects},
  volume       = {292},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Routing automated lane-guided transport vehicles in a
warehouse handling returns. <em>EJOR</em>, <em>292</em>(3), 1085–1098.
(<a href="https://doi.org/10.1016/j.ejor.2020.11.038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Faced with high return rates, many e-commerce retailers are considering novel technical solutions to expedite the processing of returned items in their warehouses. One such solution consists of lane-guided transport (LGT) vehicles. These small, electric vehicles follow optical markers on the floor, picking up boxes of returned items at a depot and dropping them off at workstations, releasing the logistics workers to focus on the productive task of actually processing the items instead of carrying them through the warehouse. These types of systems are simple to set up from a technical perspective; however, the routes on the warehouse floor still need to be carefully planned. This gives rise to the following routing problem. Given a set of stations to be served from multiple depots by a fleet of LGT vehicles, which stations doing what type of work should be visited on what route? Only one route per depot is allowed, but multiple vehicles may use the same route. Moreover, since routes cannot be changed on short notice, we consider an infinite planning horizon where the demand rate of the stations depends on the type of work they are assigned to do (e.g., handling defective items or refurbishing). We develop a decomposition heuristic, which solves instances derived from industry data to near-optimality in less than a minute. We also show that the depot location is rather unimportant for the overall system performance, but that the depot count can have a significant influence.},
  archive      = {J_EJOR},
  author       = {Simon Emde and Nail Tahirov and Michel Gendreau and Christoph H. Glock},
  doi          = {10.1016/j.ejor.2020.11.038},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1085-1098},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Routing automated lane-guided transport vehicles in a warehouse handling returns},
  volume       = {292},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Quadratic assignment problem variants: A survey and an
effective parallel memetic iterated tabu search. <em>EJOR</em>,
<em>292</em>(3), 1066–1084. (<a
href="https://doi.org/10.1016/j.ejor.2020.11.035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the Quadratic Assignment Problem (QAP), facilities are assigned to sites in order to minimize interactions between pairs of facilities. Although easy to define, it is among the hardest problems in combinatorial optimization, due to its non-linear nature. After decades of research on the QAP, many variants of this problem arose to deal with different applications. Along with the QAP, we consider four variants – the Quadratic Bottleneck Assignment Problem, the Biquadratic Assignment Problem, the Quadratic Semi-Assignment Problem, and the Generalized QAP – and develop a single framework to solve them all. Our parallel memetic iterated tabu search (PMITS) extends the most successful heuristics to solve the QAP. It combines the diversification phase of generating new local optima found after solutions modified by a new crossover operator that is biased towards one of the parents, with the intensification phase of an effective tabu search which uses a simplified tabu list structure to reduce the number of parameters and a new long-term memory that saves solutions previously visited to speed up the search. Solutions are improved concurrently using parallelism, and a convergence criterion determines whether the search stops according to the best solutions in each parallel search. Computational experiments using the hardest benchmark instances from the literature attest the effectiveness of the PMITS, showing its competitiveness when compared to the state-of-the-art methods, sequential and parallel, to solve the QAP. We also show that PMITS significantly outperforms the best methods found for all four variants of the QAP, significantly updating their literature.},
  archive      = {J_EJOR},
  author       = {Allyson Silva and Leandro C. Coelho and Maryam Darvish},
  doi          = {10.1016/j.ejor.2020.11.035},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1066-1084},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Quadratic assignment problem variants: A survey and an effective parallel memetic iterated tabu search},
  volume       = {292},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Surveying applications of strategic options development and
analysis (SODA) from 1989 to 2018. <em>EJOR</em>, <em>292</em>(3),
1051–1065. (<a
href="https://doi.org/10.1016/j.ejor.2020.11.032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Strategic Options Development and Analysis (SODA) is a well-established problem structuring method (PSM) used to tackle problematic situations for at least 30 years within the discipline of Operational Research (OR) and other fields. The aim of this study is to assess the ways academics have been implementing SODA methodology in different fields of knowledge and practice. We started by exploring the SODA history followed by the evaluation of published articles associated with the practical applications of SODA from 1989 (publication date of Rational Analysis for a Problematic World) to 2018. We searched relevant databases and studied 200 SODA-related articles, we examined the scope of each application, whether as a sole SODA application or as a combination with other methodologies. We also investigated which elements of the methodology have been used. Our findings suggest that SODA through its associated technique of cognitive mapping has been used in conjunction with other methods. SODA is a participative methodology designed to provide dialogue, reflection, learning, consensus and commitment, but the sample of articles surveyed indicate that its use has been limited to helping modelling the problematic situation and providing a common understanding to participants. Other core activities, such as group negotiation support, have not been fully used. Our findings suggest that SODA is a methodology suitable to different contexts and its practice has grown steadily over time but that to exploit the full use of its activities, its creators need to produce a set of constitutive rules to guide the applications.},
  archive      = {J_EJOR},
  author       = {Leila Abuabara and Alberto Paucar-Caceres},
  doi          = {10.1016/j.ejor.2020.11.032},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1051-1065},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Surveying applications of strategic options development and analysis (SODA) from 1989 to 2018},
  volume       = {292},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). New data envelopment analysis models for classifying
flexible measures: The role of non-archimedean epsilon. <em>EJOR</em>,
<em>292</em>(3), 1037–1050. (<a
href="https://doi.org/10.1016/j.ejor.2020.11.029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Some input-output classifier data envelopment analysis (DEA) models in multiplier and envelopment forms were developed to designate the status of flexible measures, playing either input or output roles. These models ignore the role of non-Archimedean epsilon in the input-output classification process. We show that these epsilon-free models may ignore some flexible measures in the performance evaluation process and hence the status of such flexible measure(s) can be randomly and inappropriately identified. To fill this gap, we develop a pair of epsilon-based multiplier and envelopment classifier models. We also develop an approach to find a suitable epsilon value for our developed classifier models. A case study of the supplier selection problem in the Iranian Space Research Center (ISRC) is provided to illustrate the potential application of our new epsilon-based approach.},
  archive      = {J_EJOR},
  author       = {Mehdi Toloo and Bohlool Ebrahimi and Gholam R. Amin},
  doi          = {10.1016/j.ejor.2020.11.029},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1037-1050},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {New data envelopment analysis models for classifying flexible measures: The role of non-archimedean epsilon},
  volume       = {292},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Improving multi-objective algorithms performance by
emulating behaviors from the human social analogue in candidate
solutions. <em>EJOR</em>, <em>292</em>(3), 1019–1036. (<a
href="https://doi.org/10.1016/j.ejor.2020.11.028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The fundamental unit of each evolutionary algorithm is the individual. Each individual represents a potential solution to the problem at hand. Despite the importance of individual solution for multi-objective algorithms’ performance the majority of the existing implementations select a simplistic approach by assuming identical behavior for all candidate solutions of a population. However, from the biological analogue we know that individuals do not react similarly to the same stimulus. This is called character and it is lacking from existing implementations. In this paper, we emulate the corresponding human social analogue by generating individuals that exhibit different behavior when are subject to the same stimulus. The implementation of different behaviors is facilitated through a novel mutation operator. The experimental results favor the proposed approach when compared with other state-of-the-art algorithms for a number of test instances.},
  archive      = {J_EJOR},
  author       = {Konstantinos Liagkouras and Konstantinos Metaxiotis},
  doi          = {10.1016/j.ejor.2020.11.028},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1019-1036},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Improving multi-objective algorithms performance by emulating behaviors from the human social analogue in candidate solutions},
  volume       = {292},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multiple kernel learning-aided robust optimization: Learning
algorithm, computational tractability, and usage in multi-stage
decision-making. <em>EJOR</em>, <em>292</em>(3), 1004–1018. (<a
href="https://doi.org/10.1016/j.ejor.2020.11.027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robust optimization (RO) has been broadly utilized for decision-making under uncertainty; however, as a key issue in RO the design of the uncertainty set could exert significant influence on both the conservatism of solutions and tractability of induced problems. In this paper, we propose a novel multiple kernel learning (MKL)-aided RO framework for data-driven decision-making, by developing an efficient approach for uncertainty set construction from data based on one-class support vector machine. The learnt polyhedral uncertainty set not only achieves a compact encircling of empirical data, which alleviates the pessimism and reduces the gap between the model and real-world performance, but also ensures structural sparsity and computational tractability. The data-driven RO framework enables a handy adjustment of the conservatism and complexity by simply manipulating two hyper-parameters, thereby being user-friendly in practice. In addition, the proposed framework applies to adjustable RO (ARO) with the extended affine decision rule adopted, which helps improving the optimization performance without too much additional effort. Numerical and application case studies demonstrate the effectiveness of the proposed data-driven RO framework.},
  archive      = {J_EJOR},
  author       = {Biao Han and Chao Shang and Dexian Huang},
  doi          = {10.1016/j.ejor.2020.11.027},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1004-1018},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Multiple kernel learning-aided robust optimization: Learning algorithm, computational tractability, and usage in multi-stage decision-making},
  volume       = {292},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Measuring the effects of undesirable outputs on the
efficiency of production units. <em>EJOR</em>, <em>292</em>(3),
996–1003. (<a href="https://doi.org/10.1016/j.ejor.2020.11.026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The data envelopment analysis technique produces higher efficiency scores for the assessed decision making units (DMUs) when more input/output factors are considered. This feature generates an intuitively unreasonable result in which the efficiency of a DMU measured considering the accompanying undesirable outputs is greater than or equal to that measured without considering them. In order to obtain a reasonable measure of efficiency, this paper proposes a concept for determining the minimum amount of undesirable outputs that a DMU is allowed to generate based on the assertion of weak disposability, and the results are used to construct the production frontier. The efficiency of the DMUs measured from this frontier can be decomposed into two parts, one of which shows the efficiency of consuming the observed inputs to produce the observed desirable outputs and the other of which, a reduction factor, shows the effect of producing excessive amounts of undesirable outputs on efficiency. A case of thirty paper mills taken from the literature is used to illustrate this idea. The results are helpful for DMU decision-makers to identify sources of inefficiency and for the government to formulate standards for generating allowable amounts of undesirable outputs.},
  archive      = {J_EJOR},
  author       = {Chiang Kao and Shiuh-Nan Hwang},
  doi          = {10.1016/j.ejor.2020.11.026},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {996-1003},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Measuring the effects of undesirable outputs on the efficiency of production units},
  volume       = {292},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Achieving compromise solutions in nurse rostering by using
automatically estimated acceptance thresholds. <em>EJOR</em>,
<em>292</em>(3), 980–995. (<a
href="https://doi.org/10.1016/j.ejor.2020.11.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite the multi-objective nature of the nurse rostering problem (NRP), most NRP formulations employ a single evaluation function that minimizes the weighted sum of constraint violations. When solving the NRP in practice, the focus should be on obtaining compromise solutions: those with appropriate trade-offs between different constraints. Due to the real-world characteristics of the problem, appropriate trade-offs may vary substantially across instances, and quantifying these trade-offs does not necessarily translate well into a single evaluation function. This paper introduces a new multi-objective approach for the NRP that promotes controlled trade-offs and guides the solver towards acceptable compromise solutions. The method consists of two phases. The first phase quantifies the characteristics of acceptable compromise solutions by estimating acceptance thresholds that implicitly incorporate trade-offs. This quantification is performed automatically by drawing upon the instance at hand and identifying appropriate trade-offs. The second phase solves the NRP by employing these acceptance thresholds in a lexicographic goal programming framework. By automatically estimating instance-specific acceptance thresholds, we not only require minimal information from the user but also obtain a realistic prediction for solution quality. A case study shows that the methodology produces rosters with little or no deviations from acceptance thresholds, within only a few minutes. Furthermore, this methodology provides the user with clear reasoning behind the trade-offs made, as opposed to methods employing a single evaluation function.},
  archive      = {J_EJOR},
  author       = {Elín Björk Böðvarsdóttir and Pieter Smet and Greet Vanden Berghe and Thomas J.R. Stidsen},
  doi          = {10.1016/j.ejor.2020.11.017},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {980-995},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Achieving compromise solutions in nurse rostering by using automatically estimated acceptance thresholds},
  volume       = {292},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). The optimal investment decision for an innovative supplier
in a supply chain. <em>EJOR</em>, <em>292</em>(3), 967–979. (<a
href="https://doi.org/10.1016/j.ejor.2020.11.040">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study a supply chain consisting of an upstream supplier who invests in innovation, which increases the value of products to users, and downstream manufacturers who sell to users. Analyzing a bargaining model, we find that the supplier should invest more in innovation under downstream competition than under a downstream monopoly if the supplier does not have strong bargaining power. However, if the supplier already has strong bargaining power, the supplier should make more innovation investment only if the downstream competition is relatively mild. Interestingly, we find that, if the supplier has strong bargaining power, intense competition between downstream manufacturers negatively impacts the supplier’s profit. Finally, we show that a stronger bargaining power may not always benefit manufacturers.},
  archive      = {J_EJOR},
  author       = {Jingqi Wang and Hyoduk Shin and Qin Zhou},
  doi          = {10.1016/j.ejor.2020.11.040},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {967-979},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {The optimal investment decision for an innovative supplier in a supply chain},
  volume       = {292},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Conic programming models for production planning with
clearing functions: Formulations and duality. <em>EJOR</em>,
<em>292</em>(3), 953–966. (<a
href="https://doi.org/10.1016/j.ejor.2020.11.039">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Concave clearing functions that model the expected throughput of a production resource as a function of its planned workload have yielded promising results when used in production planning models. The most common of these models take the form of linear programs (LPs) obtained by piecewise linearization of the clearing function constraints, leading to large formulations and inaccurate estimates of dual prices for resources. We show that several clearing function forms considered in the literature to date can be reformulated as conic programs (CPs), for which efficient solution methods and an elegant duality theory analogous to that for linear programming exist. We derive expressions for the optimal values of the dual variables and present computational experiments showing that the dual prices obtained from the CP formulation are more accurate than those obtained from the piecewise linearized LP models. In addition, the CP solution outperforms the LP solutions with respect to nervousness.},
  archive      = {J_EJOR},
  author       = {Karthick Gopalswamy and Reha Uzsoy},
  doi          = {10.1016/j.ejor.2020.11.039},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {953-966},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Conic programming models for production planning with clearing functions: Formulations and duality},
  volume       = {292},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Integrated product and packaging decisions with secondary
packaging returns and protective packaging management. <em>EJOR</em>,
<em>292</em>(3), 930–952. (<a
href="https://doi.org/10.1016/j.ejor.2020.11.022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The generation of packaging waste has fast become a supply chain management concern, especially with the growth of e-commerce. This calls for an integrated understanding of the product-packaging-supply chain system, which is currently nascent in the research literature. The present study considers a two-stage, profit-oriented supply chain that employs disposable primary packaging, disposable protective packaging, and returnable secondary packaging in supplying the product to a price-conscious consumer. With a special emphasis on the return of last-mile packaging, an analytical model is developed to examine the integrated lot-sizing and pricing decisions for the product and its secondary packaging. The model is developed for a decentralized channel with a Retailer-Stackelberg power structure and a centralized channel. In both the channels, it is shown that the retail price not only drives the equilibrium decisions and profits but also the total waste generated across different packaging types. It is found that the decentralized channel produces lower channel profits, however, it also generates lesser packaging waste when compared to a centralized channel. The study identifies the economic improvements in reverse channel operations that can encourage channels to adopt the take-back of secondary packaging in the last-mile for reuse. The findings also support the intuitive understanding that channels that adopt larger sized products can reduce packaging waste. Additionally, penalizing protective packaging in the last-mile is shown to have the potential to reduce total packaging waste by inducing the channels to supply larger products. Scope for contracts and regulatory mechanisms are identified, along with future research directions.},
  archive      = {J_EJOR},
  author       = {Lavanya Meherishi and Sushmita A. Narayana and K.S. Ranjani},
  doi          = {10.1016/j.ejor.2020.11.022},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {930-952},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Integrated product and packaging decisions with secondary packaging returns and protective packaging management},
  volume       = {292},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-product supply networks: Implications of
intermediaries. <em>EJOR</em>, <em>292</em>(3), 909–929. (<a
href="https://doi.org/10.1016/j.ejor.2020.11.019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We examine the implications of vertical augmentation – delegation and strategic decentralization – by involving an intermediary in a supply network of competing firms with limited supply capacity offering multiple product brands. We identify (i) the conditions for the competing firms to characterize their single- versus multi-product incentives, and (ii) the conditions for network sustainability. We develop a game-theoretic model to analyze equilibrium outcomes for competing firms in a decentralized network where the firms respond to horizontal and vertical competition in a multi-product setting. In examining the role of an intermediary in the network, we provide insights into the network setting from the perspectives of (i) consumer valuation for the firms’ products, (ii) size disparity between the network firms, (iii) the intermediary’s efforts in marketing and brand-building, and (iv) the network firms’ mandate for the intermediary. We show that vertical augmentation can be a viable alternative to manage the competing firms’ multi-product incentives, provided a suitable mandate is given to the intermediary. We highlight the importance of the marketing agent in managing the network firms’ multi-product incentives favorably when the firms’ supply capacities are quite disparate, and the consumer valuation for the shared product of the network is relatively high. Our work explores an alternate business model that is relevant for empowering small and micro-entrepreneurs in developing countries.},
  archive      = {J_EJOR},
  author       = {Omkar D. Palsule-Desai},
  doi          = {10.1016/j.ejor.2020.11.019},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {909-929},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Multi-product supply networks: Implications of intermediaries},
  volume       = {292},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Partial outsourcing from a rival: Quality decision under
product differentiation and information asymmetry. <em>EJOR</em>,
<em>292</em>(3), 886–908. (<a
href="https://doi.org/10.1016/j.ejor.2020.11.018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Firms along with producing components in-house source some requirements from a supplier competing in the downstream market (encroachment). However, the supplier may strategically choose not to compete with the manufacturer (no-encroachment). In a stylized game-theoretic model, we characterize component quality decisions of the supplier, a two-part tariff contracting structure, and the market output decisions of both players. We focus on investigating the effect of product quality differentiation and partial outsourcing strategy on the above decisions. We find that product quality may increase or decrease with the increase in product differentiation. Further, we find that the increase in the fraction of requirements outsourced by the manufacturer to the supplier may increase or decrease the product quality. Later, our analysis reveals that when a manufacturer’s in-house quality cost is very low, or the degree of product differentiation is in the moderate range, the supplier encroachment could lead to a “win-win” outcome for both players},
  archive      = {J_EJOR},
  author       = {Prasenjit Mandal and Tarun Jain},
  doi          = {10.1016/j.ejor.2020.11.018},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {886-908},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Partial outsourcing from a rival: Quality decision under product differentiation and information asymmetry},
  volume       = {292},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Time-dependent stochastic vehicle routing problem with
random requests: Application to online police patrol management in
brussels. <em>EJOR</em>, <em>292</em>(3), 869–885. (<a
href="https://doi.org/10.1016/j.ejor.2020.11.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Static and Stochastic Vehicle Routing Problem with Random Requests (SS-VRP-R) describes realistic operational contexts in which a fleet of vehicles has to serve customer requests appearing dynamically. Based on a probabilistic knowledge about the appearance of requests, the SS-VRP-R seeks a priori sequences of vehicle relocations, optimizing the expected responsiveness to the requests. In this paper, an existing computational framework, based on recourse strategies, is adapted to meet the objectives of the SS-VRP-R. The resulting models are applied to a real case study of the management of police units in Brussels. In this context, the expected average response time is minimized. To cope with the reality of the urban context, a time-dependent variant is also studied (TD-SS-VRP-R) in which the travel time between two locations is a function that depends on the departure time at the first location. Experiments confirm the contribution and the adaptability of the recourse strategies to a real-life, complex operational context. Provided an adequate solution method, simulation-based results show the high quality of the a priori solutions designed, even when compared to those designed by field experts. Finally, the experiments provide evidence that there is no potential gain in considering time-dependency in such an operational context.},
  archive      = {J_EJOR},
  author       = {Michael Saint-Guillain and Célia Paquay and Sabine Limbourg},
  doi          = {10.1016/j.ejor.2020.11.007},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {869-885},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Time-dependent stochastic vehicle routing problem with random requests: Application to online police patrol management in brussels},
  volume       = {292},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A fast exact method for the capacitated facility location
problem with differentiable convex production costs. <em>EJOR</em>,
<em>292</em>(3), 855–868. (<a
href="https://doi.org/10.1016/j.ejor.2020.11.048">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper considers the capacitated facility location problem with convex and differentiable production costs functions, an optimization problem that finds numerous real-world applications such as queues in call-centers, server queuing or when production is pushed beyond normal capacity limits leading to over proportional growth in production costs. As opposed to most other solution methods for this and similar problems, we propose an exact method that instead of linearizing the cost functions deals directly with the nonlinear costs. To this end, we use a Lagrangian relaxation of the demand constraints leading to a Lagrangian subproblem with a nonlinear objective function. The Lagrangian dual is (approximately) solved by means of subgradient optimization. Proven optimal solutions to the facility location problem are then found by employing this lower bounding scheme in a branch and bound algorithm. We use this method for solving a large number of test problem instances with production costs that either follow a quadratic or an inverse cost function. Our computational experiments show that the proposed solution method is in most cases superior to other solution methods for this problem.},
  archive      = {J_EJOR},
  author       = {Tue Rauff Lind Christensen and Andreas Klose},
  doi          = {10.1016/j.ejor.2020.11.048},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {855-868},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A fast exact method for the capacitated facility location problem with differentiable convex production costs},
  volume       = {292},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A biased random-key genetic algorithm for the set
orienteering problem. <em>EJOR</em>, <em>292</em>(3), 830–854. (<a
href="https://doi.org/10.1016/j.ejor.2020.11.043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the Set Orienteering Problem which is a generalization of the Orienteering Problem where the customers are grouped in clusters, and the profit associated with each cluster is collected by visiting at least one of the customers in the respective cluster. The problem consists of finding a tour that maximizes the collected profit but, since the cost of the tour is limited by a threshold, only a subset of clusters can usually be visited. We propose a Biased Random-Key Genetic Algorithm for solving the Set Orienteering Problem in which three local search procedures are applied to improve the fitness of the chromosomes. In addition, we introduced three rules useful to reduce the size of the instances and to speed up the resolution of the problem. Finally, a hashtable is used to quickly retrieve the information that are required several times during the computation. The computational results, carried out on benchmark instances, show that our algorithm is significantly faster than the other algorithms, proposed in the literature, and it provides solutions very close to the best-known ones.},
  archive      = {J_EJOR},
  author       = {Francesco Carrabs},
  doi          = {10.1016/j.ejor.2020.11.043},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {830-854},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A biased random-key genetic algorithm for the set orienteering problem},
  volume       = {292},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The multiple shortest path problem with path deconfliction.
<em>EJOR</em>, <em>292</em>(3), 818–829. (<a
href="https://doi.org/10.1016/j.ejor.2020.11.033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To address the increasingly relevant challenge of routing autonomous agents within contested environments, this research formulates and examines the Multiple Shortest Path Problem with Path Deconfliction (MSPP-PD) to balance agent routing efficiency with group vulnerability. Within the general model formulation, multiple agents are routed between respective source and terminus nodes while minimizing both the total distance travelled and a measure of path conflict, where path conflict occurs for any instance of more than one agent traversing an arc and/or node. Within this modeling structure, this research presents and inspects a set of alternative, conceptually-motivated penalty metrics to inhibit path conflict between agents. Illustrative testing demonstrates the distinguishability of different MSPP-PD variants as they relate to optimal agent routing solutions, as well as the non-dominated solutions attainable via different relative priorities over the objective functions. Subsequent empirical testing over a set of synthetic instances demonstrates the effect of different penalty function metrics on both optimal solutions and the computational effort required to identify them. Concluding the work are recommendations about the utility of the MSPP-PD model variants, both individually and collectively.},
  archive      = {J_EJOR},
  author       = {Michael S. Hughes and Brian J. Lunday and Jeffrey D. Weir and Kenneth M. Hopkinson},
  doi          = {10.1016/j.ejor.2020.11.033},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {818-829},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {The multiple shortest path problem with path deconfliction},
  volume       = {292},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-compartment vehicle routing problems:
State-of-the-art, modeling framework and future directions.
<em>EJOR</em>, <em>292</em>(3), 799–817. (<a
href="https://doi.org/10.1016/j.ejor.2020.11.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Among the many extensions of the classical capacitated vehicle routing problem, multi-compartment vehicle routing problems have been studied extensively only in recent years. Vehicles with multiple compartments enable the joint delivery or collection of goods with differing characteristics in separate compartments that would otherwise need separate transportation with single-compartment vehicles. This enables greater flexibility in routing decisions and order assignment to tours. The versatile use of these vehicles is leading to increasing relevance in both research and industry, and consequently in an increasing number of related publications. The available studies, however, consider substantially different problem variants. As no survey on multi-compartment vehicle routing problems is available so far, the identification of common problem features and research opportunities has been difficult. This paper aims at overcoming this difficulty by proposing an extended typology for multi-compartment vehicle routing problems and extensively reviewing the existing literature. Although only few identical problems can be identified, common attributes among similar applications (regarding compartment flexibility, for example) are observed. Suggestions for future research directions are also proposed.},
  archive      = {J_EJOR},
  author       = {Manuel Ostermeier and Tino Henke and Alexander Hübner and Gerhard Wäscher},
  doi          = {10.1016/j.ejor.2020.11.009},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {799-817},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Multi-compartment vehicle routing problems: State-of-the-art, modeling framework and future directions},
  volume       = {292},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A dynamic model of knowledge management in innovative
technology companies: A case from the energy sector. <em>EJOR</em>,
<em>292</em>(2), 784–797. (<a
href="https://doi.org/10.1016/j.ejor.2020.11.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents fresh insights into how medium to large innovative technology companies in the energy business evolve their knowledge management (KM) capability. To date existing models of KM have been static, while this work provides a more dynamic approach. The primary data is analysed using a combination of an operational research (OR) approach (causal mapping) with a well-established generic qualitative research method (the Gioia method). This paper contributes to KM literature by developing a dynamic model of KM, which shows how KM capability evolves over time within an organisation. In this model, KM evolves from managing explicit knowledge through knowledge sharing to creating new knowledge. Such understanding of KM as a process can help managers in decision making with respect to both KM and innovation activities.},
  archive      = {J_EJOR},
  author       = {Agnessa Spanellis and Jillian MacBryde and Viktor Dӧrfler},
  doi          = {10.1016/j.ejor.2020.11.003},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {784-797},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A dynamic model of knowledge management in innovative technology companies: A case from the energy sector},
  volume       = {292},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Sometimes more, sometimes less: Prudence and the
diversification of risky insurance coverage. <em>EJOR</em>,
<em>292</em>(2), 770–783. (<a
href="https://doi.org/10.1016/j.ejor.2020.10.046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We analyze the optimal coverage level for an unreliable insurance contract if a utility-maximizing policyholder can transfer the intrinsic nonperformance risk to several co-insurers. Our discussion starts with an insurance demand model under default risk and the introduction of a multiple risk-sharing instrument called co-insurance policy. Subsequently, we examine the interrelation between the recovery rate and the optimal coverage level, the utility of the policyholder, and the optimal coverage level in the limit. We then consider the monotonicity of the optimal coverage level for a changing number of co-insurers and an increasing default correlation. Our proposed criteria indicate that the policyholders’ preferences for more or less coverage are primarily determined by their degree of prudence. We conclude that more prudent policyholders are more likely to accept the costs for any risk management measure intended to provide a hedge against default rik in insurance contracts.},
  archive      = {J_EJOR},
  author       = {Lukas Reichel and Hato Schmeiser and Florian Schreiber},
  doi          = {10.1016/j.ejor.2020.10.046},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {770-783},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Sometimes more, sometimes less: Prudence and the diversification of risky insurance coverage},
  volume       = {292},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Large portfolio losses in a turbulent market. <em>EJOR</em>,
<em>292</em>(2), 755–769. (<a
href="https://doi.org/10.1016/j.ejor.2020.10.043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Consider a large credit portfolio of defaultable obligors in a turbulent market. Accordingly, the credit quality process of each obligor is described by a stochastic differential equation consisting of a drift term reflecting the trend, an individual volatility term reflecting the idiosyncratic risk, and a common volatility term reflecting the systematic risk. Moreover, for each obligor a market beta is used to measure its loading on the systematic risk. The obligor defaults at the first passage time of the credit quality process. We approximate the portfolio loss as the portfolio size becomes large. For the usual case where the individual defaults do not become rare, we establish a limit theorem for the portfolio loss, while for the other case where the individual defaults become rare, which is due to portfolio effect, we establish an asymptotic estimate for its tail probability. Both results show that the portfolio loss is driven by the systematic risk, while this driving force is amplified by the market beta. As an application, we derive asymptotic estimates for the value at risk and expected shortfall of the portfolio loss. Moreover, we implement intensive numerical studies to examine the accuracy of the obtained approximations and conduct some sensitivity analysis.},
  archive      = {J_EJOR},
  author       = {Qihe Tang and Zhiwei Tong and Yang Yang},
  doi          = {10.1016/j.ejor.2020.10.043},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {755-769},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Large portfolio losses in a turbulent market},
  volume       = {292},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Robust stochastic sorting with interacting criteria
hierarchically structured. <em>EJOR</em>, <em>292</em>(2), 735–754. (<a
href="https://doi.org/10.1016/j.ejor.2020.11.024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we propose a multiple criteria decision aiding method to deal with sorting problems in which alternatives are evaluated on criteria structured in a hierarchical way and presenting interactions. The underlying preference model is the Choquet integral, while the hierarchical structure of the criteria is taken into account by applying the Multiple Criteria Hierarchy Process. Considering the Choquet integral based on a 2-additive capacity (non additive weights for considered criteria), we present a procedure to find all minimal sets of pairs of interacting criteria representing the preference information provided by the Decision Maker (DM). Robustness concerns are also addressed applying the Robust Ordinal Regression and the Stochastic Multicriteria Acceptability Analysis. Even if in different ways, both of them provide recommendations on the hierarchical sorting problem at hand by exploring the whole set of capacities compatible with the preferences provided by the DM. The applicability of the considered method to real world problems is demonstrated by an example regarding rating of European countries evaluated on economic, governmental and financial data provided by Standard &amp; Poor’s Global Inc.},
  archive      = {J_EJOR},
  author       = {Sally Giuseppe Arcidiacono and Salvatore Corrente and Salvatore Greco},
  doi          = {10.1016/j.ejor.2020.11.024},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {735-754},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Robust stochastic sorting with interacting criteria hierarchically structured},
  volume       = {292},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The capacitated directed cycle hub location and routing
problem under congestion. <em>EJOR</em>, <em>292</em>(2), 714–734. (<a
href="https://doi.org/10.1016/j.ejor.2020.11.021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper deals with hub-and-spoke network design in the liner shipping sector. It introduces a capacitated directed cycle hub location and cargo routing problem under congestion. The problem involves four decisions: location of hub ports; allocation of non-hub ports to hub ports; construction of a directed cyclic route at the hub port network level; and the routing of cargo between all origin-destination demand pairs in the network. The objective is to minimize the cost which includes fixed hub opening, feeder collection and distribution, inter-hub transportation, cargo handling, and non-linear hub port congestion costs. We present a mixed integer linear programming model in which the non-linear congestion costs at the hub ports are approximated through a (semi-continuous) piecewise linear function and use this model to calculate lower bounds on the objective function. We also develop a Tabu Search algorithm, which employs a hierarchical approach for the different decisions in the hub-and-spoke network design problem, with customized procedures for the generation of the initial solution and the selection of the search moves. The neighborhood search is diversified by randomly changing the locations of hubs based on their location frequency history in previous solutions. Computational experiments, using instances from the literature and problems based on real-world data, demonstrate that the algorithm finds high quality solutions in a reasonable time. The experiments show that the network design can be highly influenced by scale economies in mainline vs. feeder transportation costs, the port locations and hinterland flows, and congestion at the hub ports.},
  archive      = {J_EJOR},
  author       = {Cihan Bütün and Sanja Petrovic and Luc Muyldermans},
  doi          = {10.1016/j.ejor.2020.11.021},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {714-734},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {The capacitated directed cycle hub location and routing problem under congestion},
  volume       = {292},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The impact of neighboring markets on renewable locations,
transmission expansion, and generation investment. <em>EJOR</em>,
<em>292</em>(2), 696–713. (<a
href="https://doi.org/10.1016/j.ejor.2020.10.055">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many long-term investment planning models for liberalized electricity markets either optimize for the entire electricity system or focus on confined jurisdictions, abstracting from adjacent markets. In this paper, we provide models for analyzing the impact of the interdependencies between a core electricity market and its neighboring markets on key long-run decisions. This we do both for zonal and nodal pricing schemes. The identification of welfare optimal investments in transmission lines and renewable capacity within a core electricity market requires a spatially restricted objective function, which also accounts for benefits from cross-border electricity trading. This leads to mixed-integer nonlinear multilevel optimization problems with bilinear nonconvexities for which we adapt a Benders-like decomposition approach from the literature. In a case study, we use a stylized six-node network to disentangle different effects of optimal regional (as compared to supra-regional) investment planning. Regional planning alters investment in transmission and renewable capacity in the core region, which affects private investment in generation capacity also in adjacent regions and increases welfare in the core region at the cost of system welfare. Depending on the congestion-pricing scheme, the regulator of the core region follows different strategies to increase welfare causing distributional effects among stakeholders.},
  archive      = {J_EJOR},
  author       = {Jonas Egerer and Veronika Grimm and Thomas Kleinert and Martin Schmidt and Gregor Zöttl},
  doi          = {10.1016/j.ejor.2020.10.055},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {696-713},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {The impact of neighboring markets on renewable locations, transmission expansion, and generation investment},
  volume       = {292},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Approachability with constraints. <em>EJOR</em>,
<em>292</em>(2), 687–695. (<a
href="https://doi.org/10.1016/j.ejor.2020.11.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study approachability theory in the presence of constraints. Given a repeated game with vector payoffs, we study the pairs of sets ( A , D ) (A,D) in the payoff space such that Player 1 can guarantee that the long-run average payoff converges to the set A , A, while the average payoff always remains in D D . We provide a full characterization of these pairs when D D is convex and open, and a sufficient condition when D D is not convex.},
  archive      = {J_EJOR},
  author       = {Gaëtan Fournier and Eden Kuperwasser and Orin Munk and Eilon Solan and Avishay Weinbaum},
  doi          = {10.1016/j.ejor.2020.11.013},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {687-695},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Approachability with constraints},
  volume       = {292},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A DEA-based incentive approach for allocating common
revenues or fixed costs. <em>EJOR</em>, <em>292</em>(2), 675–686. (<a
href="https://doi.org/10.1016/j.ejor.2020.11.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In practice, the concept of incentives is extensively applied in the allocation process for guiding the behaviours of an organization&#39;s units to satisfy the goals of the organization. However, this concept is rarely considered in data envelopment analysis (DEA)-based allocation research. This paper proposes a two-step incentive approach for allocating common revenues or fixed costs. The first step is performance evaluation. Considering the noncooperative game relationship of decision-making units (DMUs), a DEA game cross-efficiency method is selected to measure the efficiency scores of DMUs in this paper. The second step is incentive allocation. Based on the performance evaluation, we propose our incentive method for allocating revenues or fixed costs. We further provide simple equations to calculate the global optimal solution for our nonlinear programme allocation models. Several properties are explored, and we i) obtain the allocation interval rule of DMUs with the incentives, ii) investigate the quantitative relationship between the allocation gap and the optimal allocation plan, and iii) prove that the optimal allocation plan obtained by our allocation model is unique. The results of an empirical application highlight the applicability of our allocation method and solution approach. In this study, we obtain several important practical insights, including that (i) our method has positive effects on performance improvement and (ii) our method can work well even in an information asymmetric decision-making environment.},
  archive      = {J_EJOR},
  author       = {Qianzhi Dai and Yongjun Li and Xiyang Lei and Dengsheng Wu},
  doi          = {10.1016/j.ejor.2020.11.006},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {675-686},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A DEA-based incentive approach for allocating common revenues or fixed costs},
  volume       = {292},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Russell graph efficiency measures in data envelopment
analysis: The multiplicative approach. <em>EJOR</em>, <em>292</em>(2),
663–674. (<a href="https://doi.org/10.1016/j.ejor.2020.11.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The measurement of technical efficiency is a topic of great interest. Since the beginning, many researchers have developed new approaches to gauge technical efficiency, mainly in the non-parametric area of Data Envelopment Analysis (DEA). However, the first measures in DEA, the well-known radial models, only accounted for radial inefficiency, which motivated the introduction in the literature of the so-called Global Efficiency Measures (GEMs); non-oriented and non-radial in nature. Two famous GEMs are the Russell Graph Measure and the Enhanced Russell Graph Measure, also known as the Slacks-Based Measure. These approaches aggregate input and output specific efficiencies through the arithmetic mean, which may not be the most appropriate aggregator function when input and output efficiency ratios are considered, as will be shown. In this paper, in contrast, we propose aggregating input and output specific inefficiencies by applying the geometric average, which will allow us to define new multiplicative versions of the Russell Graph Measures. We also prove some theoretical results and introduce an iterative algorithm, based upon Second Order Cone Programming, to solve the new models. Finally, the implementation of the introduced approaches is empirically illustrated through a data set taken from the literature.},
  archive      = {J_EJOR},
  author       = {Javier Alcaraz and Laura Anton-Sanchez and Juan Aparicio and Juan F. Monge and Nuria Ramón},
  doi          = {10.1016/j.ejor.2020.11.001},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {663-674},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Russell graph efficiency measures in data envelopment analysis: The multiplicative approach},
  volume       = {292},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Impacts of store-brand introduction on a multiple-echelon
supply chain. <em>EJOR</em>, <em>292</em>(2), 652–662. (<a
href="https://doi.org/10.1016/j.ejor.2020.10.044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Observing that store brands are often introduced in multiple-echelon supply chains, however, the common wisdom from analytical models on store brands has been obtained from two-echelon supply chains, we investigate the strategic interaction in a three-echelon supply chain (manufacturer-distributer-retailer) with a store brand and its corresponding impacts. This research reveals the ways in which store brand affects the interaction and performance of the three-echelon supply chain, as it is significantly different from the two-echelon case. In particular, when the store brand is moderately competitive, the nature of the interaction between the national-brand manufacturer and the distributer can change from dependence to independence, enabling the national-brand manufacturer to manipulate its price leadership to increase its wholesale price instead, leaving the distributer itself to deter the SB introduction. Consequently, the distributer plays a special role as a buffer between the national-brand manufacturer and the retailer. When the store brand is competitive enough and finally introduced, all channel members may benefit from the store brand introduction, but this phenomenon never occurs in the two-echelon case under the same conditions. Therefore, this study increases our understanding of how store brand affects the multiple-echelon supply chain and provides another important theoretical explanation for why executive managers of national brand products need not overreact to the introduction of their retailers’ store brands.},
  archive      = {J_EJOR},
  author       = {Rong Cheng and Yongrui Duan and Jianguang Zhang and Hua Ke},
  doi          = {10.1016/j.ejor.2020.10.044},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {652-662},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Impacts of store-brand introduction on a multiple-echelon supply chain},
  volume       = {292},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Forays into omnichannel: An online retailer’s strategies for
managing product returns. <em>EJOR</em>, <em>292</em>(2), 633–651. (<a
href="https://doi.org/10.1016/j.ejor.2020.10.042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {E-commerce has witnessed a steady growth with advances in digital technologies. However, one of the challenges faced by online retail is its inability to provide customers with the opportunity to “touch-and-feel” a product before purchasing, thereby resulting in a higher rate of product returns. To address this, online retailers, nowadays, are adopting various omnichannel configurations. Using a stylized model, we study three such omnichannel configurations: selling the product online, establishing a showroom while selling the product online (‘Experience-in-Store-and-Buy-Online (ESBO)’), and selling the product through both a brick-and-mortar (B&amp;M) store and the online channel while allowing in-store product returns (‘Buy-Online-and-Return-In-Store (BORS)’). Based on product attributes such as product standardization and valuation we recommend optimal omnichannel strategies. Our results show that depending on whether a premium product is highly personalized or standardized, opening an additional showroom or a B&amp;M store becomes optimal for the retailer. In contrast, for a low-valued, highly personalized product, the retailer prefers opening an exclusive showroom. Otherwise, for a low-valued, standardized product, the retailer opens an additional B&amp;M store or continues to operate only online based on the product return rate and valuation. If the unit cost of transporting the returned products from customers is low, the retailer prefers to sell the product online only. Moreover, if the hassle cost of online purchase is too high, the strategy of in-store return becomes uneconomic. We also analyze the impact of customers’ exchanging returned items at the B&amp;M store and their product fitness heterogeneity on the retailer’s optimal omnichannel strategy.},
  archive      = {J_EJOR},
  author       = {Prasenjit Mandal and Preetam Basu and Kushal Saha},
  doi          = {10.1016/j.ejor.2020.10.042},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {633-651},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Forays into omnichannel: An online retailer’s strategies for managing product returns},
  volume       = {292},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Dynamic advance scheduling of outpatient appointments in a
moving booking window. <em>EJOR</em>, <em>292</em>(2), 622–632. (<a
href="https://doi.org/10.1016/j.ejor.2020.11.030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the dynamic advance scheduling for outpatient medical appointments in a moving booking window. To address this problem, a finite-horizon Markov decision process (MDP) model is proposed to maximize the total expected net reward comprising the reward for accepting outpatients and the capacity usage cost. Structural properties of the optimal value function and the optimal control policy are established. For the special cases in which the lengths of the booking window are equal to 1 and to 2 periods, the antimultimodularity of the optimal value function is proved while the monotonicity and bounded sensitivity of the optimal control policy are established. For the general cases, partial characterization of the optimal policy is performed. Based on insights from the theoretical results, two efficient heuristic policies are devised, including the assignment-sequence policy and multiple-threshold policy. Numerical experiments show that both policies perform consistently well and outperform the other benchmarking heuristic policies.},
  archive      = {J_EJOR},
  author       = {Jiajun Dai and Na Geng and Xiaolan Xie},
  doi          = {10.1016/j.ejor.2020.11.030},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {622-632},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Dynamic advance scheduling of outpatient appointments in a moving booking window},
  volume       = {292},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Optimal inspection and mission abort policies for systems
subject to degradation. <em>EJOR</em>, <em>292</em>(2), 610–621. (<a
href="https://doi.org/10.1016/j.ejor.2020.11.015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Safety-critical systems are commonly required to perform missions in various engineering fields. Failures of safety-critical systems may result in irretrievable economic losses and significant damages. To enhance the system survivability, mission abort is usually conducted if the failure risk becomes too high. This paper investigates the joint optimization of inspection and condition based mission abort policies for systems subject to continuous degradation. Dynamic mission abort decisions are considered based on the degradation level together with the time in mission. The problem is formulated within the framework of Markov decision process to minimize the expected costs of inspection, mission failure and system failure. In addition to deriving some structural properties, we also numerically evaluate several heuristic policies where mission reliability and system survivability are derived. Numerical studies are presented to validate the obtained results.},
  archive      = {J_EJOR},
  author       = {Xian Zhao and Jinglei Sun and Qingan Qiu and Ke Chen},
  doi          = {10.1016/j.ejor.2020.11.015},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {610-621},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Optimal inspection and mission abort policies for systems subject to degradation},
  volume       = {292},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). To clean or not to clean: Malware removal strategies for
servers under load. <em>EJOR</em>, <em>292</em>(2), 596–609. (<a
href="https://doi.org/10.1016/j.ejor.2020.10.036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider how to best schedule reparative downtime for a customer-facing online service that is vulnerable to cyber attacks such as malware infections. These infections can cause performance degradation (i.e., a slower service rate) and facilitate data theft, both of which have monetary repercussions. Infections may go undetected and can only be removed by time-consuming cleanup procedures, which require temporarily taking the service offline. From a security-oriented perspective, cleanups should be undertaken as frequently as possible. From a performance-oriented perspective, frequent cleanups are desirable because they maintain faster service, but they are simultaneously undesirable because they lead to more frequent downtimes and subsequent loss of revenue. We ask when and how often cleanups should happen. In order to analyze various downtime scheduling policies, we combine queueing-theoretic techniques with a revenue model to capture the problem’s tradeoffs. Unlike classical repair problems, this problem necessitates the analysis of a quasi-birth-death Markov chain, tracking the number of customer requests in the system and the (possibly unknown) infection state. We adapt a recent analytic technique, Clearing Analysis on Phases (CAP), to determine the exact steady-state distribution of the underlying Markov chain, which we then use to compute revenue rates and make recommendations. Prior work on downtime scheduling under cyber attacks relies on heuristic approaches, with our work being the first to address this problem analytically.},
  archive      = {J_EJOR},
  author       = {Sherwin Doroudi and Thanassis Avgerinos and Mor Harchol-Balter},
  doi          = {10.1016/j.ejor.2020.10.036},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {596-609},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {To clean or not to clean: Malware removal strategies for servers under load},
  volume       = {292},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A performance-centred approach to optimising maintenance of
complex systems. <em>EJOR</em>, <em>292</em>(2), 579–595. (<a
href="https://doi.org/10.1016/j.ejor.2020.11.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces performance-centred maintenance (PCM) as a novel approach to maintain systems when dual consideration is given to operational performance and degradation condition. We consider situations where performance and condition do not necessarily deteriorate at the same rate typified by, say, an ageing system still achieving good performance or a new system performing poorly. In this problem context, competing interests may arise between different decision-makers, such as operators and maintainers, since alternative strategies may benefit either performance or condition at the expense of the other. To address this challenge we introduce a theoretical framework for the PCM approach and discuss key characteristics of the modelling problem. The general PCM approach is motivated by a real-world industrial system for which maintenance decisions required to be optimised. A specific application is shown for the industry problem which we model by a Markov decision process capable of interrogating decisions over multiple time-scales. We obtain an exact solution using dynamic programming. We also explore a less computationally challenging heuristic using a reinforcement learning algorithm and evaluate its accuracy for the large-scale industry model. We show that optimal maintenance policies from a PCM model can provide decision support to both maintainers and operators taking account of both perspectives of the problem.},
  archive      = {J_EJOR},
  author       = {E. Barlow and T. Bedford and M. Revie and J. Tan and L. Walls},
  doi          = {10.1016/j.ejor.2020.11.005},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {579-595},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A performance-centred approach to optimising maintenance of complex systems},
  volume       = {292},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The effect of information asymmetry on ordering and capacity
decisions in supply chains. <em>EJOR</em>, <em>292</em>(2), 562–578. (<a
href="https://doi.org/10.1016/j.ejor.2020.11.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We revisit the problem of contracting under asymmetric information in a supply chain and highlight a few important properties that have not been reported previously. In our setting, a newsvendor retailer is endowed with superior information about the demand; the retailer may signal this information to the supplier by committing to purchasing a certain quantity in advance. Previous research has focused on characterizing the minimum quantity that convinces the supplier that demand is high. In this work, we claim that in some cases, the retailer prefers to order an even greater quantity than this minimum separating quantity, since committing to an advance purchase can result in incentives for the retailer to finance the entire capacity in the market—a choice that the retailer may not adopt absent information asymmetry. Such an outcome carries important implications regarding the efficiency of the supply chain and consumer welfare. In particular, our analysis shows that asymmetric information can result in a higher capacity in the market than the complete-information case; thus, asymmetric information can mitigate the double-marginalization problem and result in higher consumer welfare. We further conduct a comparison between the incentives of the retailer to signal the demand state to the supplier (resulting in a separating equilibrium) and the incentives of the retailer to withhold her private information from the supplier (resulting in a pooling equilibrium).},
  archive      = {J_EJOR},
  author       = {Tal Avinadav and Noam Shamir},
  doi          = {10.1016/j.ejor.2020.11.004},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {562-578},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {The effect of information asymmetry on ordering and capacity decisions in supply chains},
  volume       = {292},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Distributionally robust facility location problem under
decision-dependent stochastic demand. <em>EJOR</em>, <em>292</em>(2),
548–561. (<a href="https://doi.org/10.1016/j.ejor.2020.11.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While the traditional facility location problem considers exogenous demand, in some applications, locations of facilities could affect the willingness of customers to use certain types of services, e.g., carsharing, and therefore they also affect realizations of random demand. Moreover, a decision maker may not know the exact distribution of such endogenous demand and how it is affected by location choices. In this paper, we consider a distributionally robust facility location problem, in which we interpret the moments of stochastic demand as functions of facility-location decisions. We reformulate a two-stage decision-dependent distributionally robust optimization model as a monolithic formulation, and then derive exact mixed-integer linear programming reformulation as well as valid inequalities when the means and variances of demand are piecewise linear functions of location solutions. We conduct extensive computational studies, in which we compare our model with a decision-dependent deterministic model, as well as stochastic programming and distributionally robust models without the decision-dependent assumption. The results show superior performance of our approach with remarkable improvement in profit and quality of service under various settings, in addition to computational speed-ups given by formulation enhancements. These results draw attention to the need of considering the impact of location decisions on customer demand within this strategic-level planning problem.},
  archive      = {J_EJOR},
  author       = {Beste Basciftci and Shabbir Ahmed and Siqian Shen},
  doi          = {10.1016/j.ejor.2020.11.002},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {548-561},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Distributionally robust facility location problem under decision-dependent stochastic demand},
  volume       = {292},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Preemptive stacker crane problem: Extending tree-based
properties and construction heuristics. <em>EJOR</em>, <em>292</em>(2),
532–547. (<a href="https://doi.org/10.1016/j.ejor.2020.10.051">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The stacker crane problem (SCP) considers the cost-minimal routing of a single unit-capacity vehicle that needs to satisfy a given set of one-to-one pickup and delivery requests. In the preemptive stacker crane problem (PSCP), the vehicle is additionally allowed to temporarily drop its payload at arbitrary intermediate locations. While a payload is stored at an intermediate location, other requests may be performed. Prior work in the literature has shown that a specific tree structure is sufficient to represent optimal solutions for the PSCP. Building on this tree structure, this work establishes bounds on the benefits of preemption and additional drop locations that are neither associated with a pickup nor a delivery location, proposes reduced solution representations and describes algorithms for subproblems solvable in polynomial time. Furthermore, heuristic construction methods adapted for the PSCP from well-known heuristics for the asymmetric traveling salesman problem (ATSP) and capacitated vehicle routing problem (CVRP) are presented. The previously described and newly proposed adapted heuristics are evaluated and compared in a large scale computational study with respect to computation time, solution quality and other solution characteristics.},
  archive      = {J_EJOR},
  author       = {Benjamin Graf},
  doi          = {10.1016/j.ejor.2020.10.051},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {532-547},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Preemptive stacker crane problem: Extending tree-based properties and construction heuristics},
  volume       = {292},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Smart supply chains with vendor managed inventory,
coordination, and environmental performance. <em>EJOR</em>,
<em>292</em>(2), 515–531. (<a
href="https://doi.org/10.1016/j.ejor.2020.10.049">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A dynamic brick-and-mortar Supply Chain (SC) evaluates the benefits of implementing smart applications and intelligent systems to improve the efficiency of a Vendor Managed Inventory (VMI). In the SC game, the manufacturer sets the production rate and replenishes the inventory at the retailer’s store. The retailer sets the price, which affects both the sales and the inventory. Firms share the revenues and the inventory costs through a sharing agreement. The inventory dynamics increase in the production rate, decrease in the sales and vary according to some stochastic and time-independent error terms. The adoption of a smart application allows the SC to remove these error terms. Nevertheless, the consulting company implementing the intelligent system charges fees that depend on the error term amplitude and inventory level. Furthermore, intelligent solutions allow the SC to better satisfy the consumers, although their impact on production and emissions may be detrimental questioning whether they lead to a responsible digitalization. We identify the conditions under which the adoption of a smart system is economically beneficial for the whole SC as well as its operational, environmental, and SC coordination implications.},
  archive      = {J_EJOR},
  author       = {Pietro De Giovanni},
  doi          = {10.1016/j.ejor.2020.10.049},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {515-531},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Smart supply chains with vendor managed inventory, coordination, and environmental performance},
  volume       = {292},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A hybrid pricing and cutting approach for the multi-shift
full truckload vehicle routing problem. <em>EJOR</em>, <em>292</em>(2),
500–514. (<a href="https://doi.org/10.1016/j.ejor.2020.10.037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Full truckload transportation (FTL) in the form of freight containers represents one of the most important transportation modes in international trade. Due to large volume and scale, in FTL, delivery time is often less critical but cost and service quality are crucial. Therefore, efficiently solving large scale multiple shift FTL problems is becoming more and more important and requires further research. In one of our earlier studies, a set covering model and a three-stage solution method were developed for a multi-shift FTL problem. This paper extends the previous work and presents a significantly more efficient approach by hybridising pricing and cutting strategies with metaheuristics (a variable neighbourhood search and a genetic algorithm). The metaheuristics were adopted to find promising columns (vehicle routes) guided by pricing and cuts are dynamically generated to eliminate infeasible flow assignments caused by incompatible commodities. Computational experiments on real-life and artificial benchmark FTL problems showed superior performance both in terms of computational time and solution quality, when compared with previous MIP based three-stage methods and two existing metaheuristics. The proposed cutting and heuristic pricing approach can efficiently solve large scale real-life FTL problems.},
  archive      = {J_EJOR},
  author       = {Ning Xue and Ruibin Bai and Rong Qu and Uwe Aickelin},
  doi          = {10.1016/j.ejor.2020.10.037},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {500-514},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A hybrid pricing and cutting approach for the multi-shift full truckload vehicle routing problem},
  volume       = {292},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A multi-period analysis of the integrated item-sharing and
crowdshipping problem. <em>EJOR</em>, <em>292</em>(2), 483–499. (<a
href="https://doi.org/10.1016/j.ejor.2020.10.034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The integrated item-sharing and crowdshipping problem arises from the operational planning of sharing platforms that coordinate diverse services offered by individuals to peers. Item-sharing means to rent-out items whereas crowdshipping describes the willingness of private drivers to conduct deliveries on their planned trips. Integrating both concepts on a single platform can lead to higher profits and better service quality by transferring items through crowdshippers. We investigate a multi-period variant of the problem to facilitate more foresighted assignments of items to requests and crowdshippers. Thereby, items can be used to sequentially serve multiple requests without being returned to their initial locations. This so-called ’request chaining’ cuts transportation effort and improves the availability of items to customers. From a modeling perspective, the planning problem is an example for the rarely investigated many-to-many pickup and delivery problems. We present a binary program and we address problem inherent dynamics due to new incoming announcements by both deterministic and stochastic problem solving approaches that are based on a rolling horizon framework. Furthermore, a simulation environment is set up to investigate the effect of a responsive requesting behavior due to word-of-mouth. Our experiments show that some look-ahead in the planning is particularly useful for scenarios with few requests. The consideration of stochastic information can improve operational performance and word-of-mouth can best be dealt with when consumers interact locally. We also derive managerial insights on the number of items that should be provided in such a community, subject to consumer preferences.},
  archive      = {J_EJOR},
  author       = {Moritz Behrend and Frank Meisel and Kjetil Fagerholt and Henrik Andersson},
  doi          = {10.1016/j.ejor.2020.10.034},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {483-499},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A multi-period analysis of the integrated item-sharing and crowdshipping problem},
  volume       = {292},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Planning a multi-sensors search for a moving target
considering traveling costs. <em>EJOR</em>, <em>292</em>(2), 469–482.
(<a href="https://doi.org/10.1016/j.ejor.2020.11.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the optimization problem of managing the research efforts of a set of sensors in order to minimize the probability of non-detection of a target. A novel formulation of the problem taking into account the traveling costs between the searched areas is proposed; it is more realistic and extends some previous problems addressed in the literature. A greedy heuristic algorithm is devised, it builds a solution gradually, using a linear approximation of the objective function refined at each step. The heuristic algorithm is complemented by a lower bound based on a piecewise linear approximation of the objective function with a parametric error, and extended to the case where the target is moving. Finally, a set of numerical experiments is performed to analyze and evaluate the proposed contributions.},
  archive      = {J_EJOR},
  author       = {Florian Delavernhe and Patrick Jaillet and André Rossi and Marc Sevaux},
  doi          = {10.1016/j.ejor.2020.11.012},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {469-482},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Planning a multi-sensors search for a moving target considering traveling costs},
  volume       = {292},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A dynamic programming framework for optimal delivery time
slot pricing. <em>EJOR</em>, <em>292</em>(2), 456–468. (<a
href="https://doi.org/10.1016/j.ejor.2020.11.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the dynamic programming approach to revenue management in the context of attended home delivery. We draw on results from dynamic programming theory for Markov decision problems to show that the underlying Bellman operator has a unique fixed point. We then provide a closed-form expression for the resulting fixed point and show that it admits a natural interpretation. Moreover, we also show that – under certain technical assumptions – the value function, which has a discrete domain and a continuous codomain, admits a continuous extension, which is a finite-valued, concave function of its state variables, at every time step. Furthermore, we derive results on the monotonicity of prices with respect to the number of orders placed in our setting. These results open the road for achieving scalable implementations of the proposed formulation, as it allows making informed choices of basis functions in an approximate dynamic programming context. We illustrate our findings on a low-dimensional and an industry-sized numerical example using real-world data, for which we derive an approximately optimal pricing policy based on our theoretical results.},
  archive      = {J_EJOR},
  author       = {Denis Lebedev and Paul Goulart and Kostas Margellos},
  doi          = {10.1016/j.ejor.2020.11.010},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {456-468},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A dynamic programming framework for optimal delivery time slot pricing},
  volume       = {292},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Bi-objective parallel machine scheduling with additional
resources during setups. <em>EJOR</em>, <em>292</em>(2), 443–455. (<a
href="https://doi.org/10.1016/j.ejor.2020.10.052">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a bi-objective parallel machine scheduling problem with machine and job sequence dependent setup times, with the additional consideration of resources needed during setups. The availability of such resources is limited. This models many practical situations where setup times imply, for example, cleaning and/or the reconfiguration of productive equipment. These setups are performed by personnel, who are of course limited in number. The objectives considered are the minimization of the makespan and the minimization of the number of resources. Fewer available resources reduce production costs but inevitably increase the makespan. On the contrary, a greater number of resources increase costs but allow for more setups to be done in parallel and a reduced makespan. An algorithm based on iterated greedy approaches is proposed to search for the Pareto front of the problem. This algorithm is compared with state-of-the art methods adapted to the problem. Computational experiments, supported by statistical analyses, indicate that the proposed approach outperforms all other tested procedures.},
  archive      = {J_EJOR},
  author       = {Juan C. Yepes-Borrero and Federico Perea and Rubén Ruiz and Fulgencia Villa},
  doi          = {10.1016/j.ejor.2020.10.052},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {443-455},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Bi-objective parallel machine scheduling with additional resources during setups},
  volume       = {292},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Meta-analysis of metaheuristics: Quantifying the effect of
adaptiveness in adaptive large neighborhood search. <em>EJOR</em>,
<em>292</em>(2), 423–442. (<a
href="https://doi.org/10.1016/j.ejor.2020.10.045">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Research on metaheuristics has focused on (novel) algorithmic development and on competitive testing, both of which have been frequently argued to yield little generalizable knowledge. The main goal of this paper is to promote meta-analysis — a systematic statistical examination that combines the results of several independent studies — as a more suitable way to obtain problem- and implementation-independent insights on metaheuristics. Meta-analysis is widely used in several scientific domains, most notably the medical sciences (e.g., to establish the efficacy of a certain treatment). To the best of our knowledge, this is the first meta-analysis in the field of metaheuristics. To illustrate the approach, we carry out a meta-analysis to gain insights into the importance of the adaptive layer in adaptive large neighborhood search (ALNS). Although ALNS has been widely used to solve a broad range of problems, it has not yet been established whether or not adaptiveness actually contributes to the performance of an ALNS algorithm. A total of 134 studies were identified through Google Scholar or personal e-mail correspondence with researchers in the domain, 63 of which fit our eligibility criteria. After sending requests for data to the authors of the eligible studies, we obtained results for 25 different implementations of ALNS, which were analysed using a random effects model. On average, the addition of an adaptive layer in an ALNS algorithm improves the objective function value by 0.14\% (95\% confidence interval 0.06–0.21\%). Although the adaptive layer can (and in a limited number of studies does) have an added value, it also adds complexity and can therefore only be recommended in some specific situations. These findings underline the importance of evaluating the contribution of metaheuristic components.},
  archive      = {J_EJOR},
  author       = {Renata Turkeš and Kenneth Sörensen and Lars Magnus Hvattum},
  doi          = {10.1016/j.ejor.2020.10.045},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {423-442},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Meta-analysis of metaheuristics: Quantifying the effect of adaptiveness in adaptive large neighborhood search},
  volume       = {292},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Performance indicators in multiobjective optimization.
<em>EJOR</em>, <em>292</em>(2), 397–422. (<a
href="https://doi.org/10.1016/j.ejor.2020.11.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, the development of new algorithms for multiobjective optimization has considerably grown. A large number of performance indicators has been introduced to measure the quality of Pareto front approximations produced by these algorithms. In this work, we propose a review of a total of 63 performance indicators partitioned into four groups according to their properties: cardinality, convergence, distribution and spread. Applications of these indicators are presented as well.},
  archive      = {J_EJOR},
  author       = {Charles Audet and Jean Bigeon and Dominique Cartier and Sébastien Le Digabel and Ludovic Salomon},
  doi          = {10.1016/j.ejor.2020.11.016},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {397-422},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Performance indicators in multiobjective optimization},
  volume       = {292},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Sequential bankruptcy problems. <em>EJOR</em>,
<em>292</em>(1), 388–395. (<a
href="https://doi.org/10.1016/j.ejor.2020.10.038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we analyze sequential bankruptcy problems, which generalize bankruptcy problems. They cover the problems of sharing water in a transboundary river and of allocating expedition rewards in projects. We propose the upwards mechanism for generalizing rules for bankruptcy problems to rules for sequential bankruptcy problems. Further, we characterize the upwards constrained equal awards, the upwards constrained equal losses, and the upwards proportional rules on the basis of upwards composition and upwards path independence.},
  archive      = {J_EJOR},
  author       = {Arantza Estévez-Fernández and José-Manuel Giménez-Gómez and María José Solís-Baltodano},
  doi          = {10.1016/j.ejor.2020.10.038},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {388-395},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Sequential bankruptcy problems},
  volume       = {292},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Omega ratio optimization with actuarial and financial
applications. <em>EJOR</em>, <em>292</em>(1), 376–387. (<a
href="https://doi.org/10.1016/j.ejor.2020.10.023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The omega ratio is an interesting performance measure because it focuses on both downside losses and upside gains, and actuarial/financial instruments are reflecting more and more asymmetry and heavy tails. This paper focuses on the omega ratio optimization in general Banach spaces, which applies for both infinite-dimensional approaches and more classical ones. New Fritz John-like and Karush Kuhn Tucker-like optimality conditions and duality results will be provided, despite the fact that omega is neither differentiable nor convex. Then, the focus is on both portfolio selection and optimal reinsurance, classic problems in Financial Mathematics and Actuarial Mathematics, respectively. The new duality results apply in order to study the potential ill-posedness of the financial problem. It will be provided further evidence about the relationship between the ill-posedness of problems involving omega and the ill-posedness of alternative problems avoiding omega and only involving coherent risk measures. The new optimality conditions apply in order to characterize and solve the actuarial problem. The solution is often a “bang-bang reinsurance contract”, i.e., a contract saturating the constraints of the ceded risk sensitivity with respect to the global (ceded plus retained) risk. In this sense, omega may be “essentially similar” to other deviation/downside risk measures previously studied, though the use of omega will also provoke some modifications in the final optimal results.},
  archive      = {J_EJOR},
  author       = {Alejandro Balbás and Beatriz Balbás and Raquel Balbás},
  doi          = {10.1016/j.ejor.2020.10.023},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {376-387},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Omega ratio optimization with actuarial and financial applications},
  volume       = {292},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Pseudospectral optimal train control. <em>EJOR</em>,
<em>292</em>(1), 353–375. (<a
href="https://doi.org/10.1016/j.ejor.2020.10.018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the last decade, pseudospectral methods have become popular for solving optimal control problems. Pseudospectral methods do not need prior knowledge about the optimal control structure and are thus very flexible for problems with complex path constraints, which are common in optimal train control, or train trajectory optimization. Practical optimal train control problems are nonsmooth with discontinuities in the dynamic equations and path constraints corresponding to gradients and speed limits varying along the track. Moreover, optimal train control problems typically include singular solutions with a vanishing Hessian of the associated Hamiltonian. These characteristics make these problems hard to solve and also lead to convergence issues in pseudospectral methods. We propose a computational framework that connects pseudospectral methods with Pontryagin’s Maximum Principle allowing flexible computations, verification and validation of the numerical approximations, and improvements of the continuous solution accuracy. We apply the framework to two basic problems in optimal train control: minimum-time train control and energy-efficient train control, and consider cases with short-distance regional trains and long-distance intercity trains for various scenarios including varying gradients, speed limits, and scheduled running time supplements. The framework confirms the flexibility of the pseudospectral method with regards to state, control and mixed algebraic inequality path constraints, and is able to identify conditions that lead to inconsistencies between the necessary optimality conditions and the numerical approximations of the states, costates, and controls. A new approach is proposed to correct the discrete approximations by incorporating implicit equations from the optimality conditions. In particular, the issue of oscillations in the singular solution for energy-efficient driving as computed by the pseudospectral method has been solved.},
  archive      = {J_EJOR},
  author       = {Rob M.P. Goverde and Gerben M. Scheepmaker and Pengling Wang},
  doi          = {10.1016/j.ejor.2020.10.018},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {353-375},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Pseudospectral optimal train control},
  volume       = {292},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Strategies for microgrid operation under real-world
conditions. <em>EJOR</em>, <em>292</em>(1), 339–352. (<a
href="https://doi.org/10.1016/j.ejor.2020.10.041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Microgrids are an increasingly relevant technology for integrating renewable energy sources into electricity systems. Based on a microgrid implementation in California, we investigate microgrid operation under real-world conditions. These conditions have not yet been considered in combination and encompass energy charges, demand charges, export limits, as well as uncertainty about future electricity demand and generation in the microgrid. Under these conditions, we evaluate the performance of two frequently applied groups of strategies for microgrid operation. The first group is composed of proactive strategies that optimize decisions based on forecasts of future electricity generation and demand. The second group includes reactive strategies that make operational decisions based exclusively on the current state of the microgrid. We evaluate the performance of the strategies under varying operational parameters, forecast accuracies, and microgrid configurations—well beyond our Californian showcase. Our results confirm the expectation that proactive strategies outperform reactive ones in the majority of settings. Yet, reactive strategies can perform better under short control intervals or under moderate prediction errors of PV generation or demand. Furthermore, the interplay between real-world conditions and operational strategies reveals several additional insights for research on microgrid operation. First, we find that demand charges and export limits decisively affect microgrid performance. Second, the impact of forecast errors is highly non-linear and non-monotonous. Third, escalating negative interactions between forecast errors and demand charges make proactive strategies benefit from longer control intervals. This result is contrary to existing best practice, which promotes short control intervals to minimize the impact of uncertainty.},
  archive      = {J_EJOR},
  author       = {Gunther Gust and Tobias Brandt and Salman Mashayekh and Miguel Heleno and Nicholas DeForest and Michael Stadler and Dirk Neumann},
  doi          = {10.1016/j.ejor.2020.10.041},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {339-352},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Strategies for microgrid operation under real-world conditions},
  volume       = {292},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The traveling salesman puts-on a hard hat – tower crane
scheduling in construction projects. <em>EJOR</em>, <em>292</em>(1),
327–338. (<a href="https://doi.org/10.1016/j.ejor.2020.10.029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Effective use of site equipment is an essential aspect of construction projects. In particular, tower cranes are critical in large scale projects. This research aims to optimize the cranes’ usage in construction projects by efficiently scheduling the sequence of activities that are processed by each crane on the site while addressing several constraints such as crane collisions and tasks precedence constraints. An integer linear program is developed that is based on the Multiple Travelling Salesmen Problem (MTSP). Two sets of valid inequalities have been added to improve the tractability of the model. This model is then tested on a real-world case study of a large construction site with two tower cranes. In addition, heuristic approaches are introduced to increase the tractability of the model and are compared to the integer program in terms of solution quality and computation time by generating a large data-set of problems with different sizes. The heuristics are based on the cluster-first, route-second idea, where an optimization-based clustering method is used to pre-assign activities to cranes.},
  archive      = {J_EJOR},
  author       = {Hussein Tarhini and Bacel Maddah and Farook Hamzeh},
  doi          = {10.1016/j.ejor.2020.10.029},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {327-338},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {The traveling salesman puts-on a hard hat – tower crane scheduling in construction projects},
  volume       = {292},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A vehicle routing problem with distribution uncertainty in
deadlines. <em>EJOR</em>, <em>292</em>(1), 311–326. (<a
href="https://doi.org/10.1016/j.ejor.2020.10.026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article considers a stochastic vehicle routing problem with probability constraints. The probability that customers are served before their (uncertain) deadlines must be higher than a pre-specified target. It is unrealistic to expect that the perfect knowledge on the probability distributions of deadlines is always available. To this end, we propose a distributionally robust optimisation framework to study worst bounds of the problem, which exploits the moment information of the historical observations. This framework includes two steps. We first use Conditional Value-at-Risk (CVaR) as a risk approximation to the probability of missing customer deadlines. The resulting nonlinear model is then transformed into a semi-infinite mixed integer program, using the dual form of the CVaR approximation. A sample approximation approach is then used to address the computational challenges. As the standard CVaR approximation to probability constraints is rather conservative, we suggest a relaxation to the approximation and develop an iterative algorithm to find the right value of the parameter that is introduced to the relaxed CVaR constraints. The extensive numerical experiments show that the routing policies developed by the proposed solution framework are robust and able to achieve the required target, regardless of deadline distributions.},
  archive      = {J_EJOR},
  author       = {Dali Zhang and Dong Li and Hailin Sun and Liwen Hou},
  doi          = {10.1016/j.ejor.2020.10.026},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {311-326},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A vehicle routing problem with distribution uncertainty in deadlines},
  volume       = {292},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The impacts of mergers, capacity expansion and adoptions on
animal shelter performance: A queuing analysis. <em>EJOR</em>,
<em>292</em>(1), 299–310. (<a
href="https://doi.org/10.1016/j.ejor.2020.10.022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {According to the American Society for the Prevention of Cruelty to Animals (ASPCA), approximately 23\% of the animals that enter shelters each year are euthanized. Many animal shelters strive to reduce euthanization and the stray animal population through capacity expansion, adoption increasing programs, and mergers. In this paper, we define, compare and perform sensitivity analysis of performance metrics for animal shelter involving loss queues. We ultimately provide recommendations for animal shelters on the most efficient investments, and analyze the effects of mergers and capacity expansion on various performance metrics. We represent animal shelters by utilizing loss queues with and without reneging and perform sensitivity analysis by calculating the asymptotic expansion of the performance metrics for various cases. We find that the euthanization in traditional shelters is not monotonically decreasing with increases in the demand for animals. A counterintuitive result shows that increasing the capacity in a traditional shelter (or merging two traditional shelters together) does not necessarily decrease the number of animals euthanized. Our results related to the performance metrics Erlang loss queues can be utilized for any type of queuing system with involuntary departures.},
  archive      = {J_EJOR},
  author       = {Nazli Turken and Janice E. Carrillo and Anand Paul},
  doi          = {10.1016/j.ejor.2020.10.022},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {299-310},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {The impacts of mergers, capacity expansion and adoptions on animal shelter performance: A queuing analysis},
  volume       = {292},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Pareto set estimation with guaranteed probability of correct
selection. <em>EJOR</em>, <em>292</em>(1), 286–298. (<a
href="https://doi.org/10.1016/j.ejor.2020.10.021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the ranking and selection problem with multiple objectives and present a procedure to estimate a Pareto set. We provide three different formulations, namely, simultaneously retaining all desirable systems and eliminating all undesirable systems, or achieving either one of the two aforementioned goals. We address situations where all systems and objectives have either independent or correlated observations (e.g., due to the use of common random numbers). In each case, we identify appropriate choices of parameter values and prove that the resulting algorithm guarantees the desired probability of correct selection in a finite amount of time. Numerical experiments are provided to support the validity and efficiency of the algorithms.},
  archive      = {J_EJOR},
  author       = {Sigrún Andradóttir and Judy S. Lee},
  doi          = {10.1016/j.ejor.2020.10.021},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {286-298},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Pareto set estimation with guaranteed probability of correct selection},
  volume       = {292},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Inland waterway efficiency through skipper collaboration and
joint speed optimization. <em>EJOR</em>, <em>292</em>(1), 276–285. (<a
href="https://doi.org/10.1016/j.ejor.2020.10.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We address the problem of minimizing the aggregated fuel consumption by the vessels in an inland waterway, e.g., a river, with a single lock. The fuel consumption of a vessel depends on its velocity and the slower it moves, the less fuel it consumes. Given entry times of the vessels into the waterway and the deadlines before which they need to leave the waterway, we start from the optimal velocities of the vessels that minimize their private fuel consumption, where we assume selfish behavior of the skippers. Presence of the lock and possible congestion on the waterway make the problem computationally challenging. First, we prove that in general, a Nash equilibrium might not exist, i.e., if there is no supervision on the vessels’ velocities, there might not exist a strategy profile from which no vessel can unilaterally deviate to decrease its private fuel consumption. Next, we introduce simple supervision methods to guarantee the existence of a Nash equilibrium. Unfortunately, though a Nash equilibrium can be computed, the aggregated fuel consumption of such a stable solution can be high compared to the social optimum, where the total fuel consumption is minimized. Therefore, we propose a mechanism involving payments between vessels, guaranteeing a Nash equilibrium while minimizing the fuel consumption. This mechanism is studied for both the offline setting, where all information is known beforehand, and online setting, where we only know the entry time and deadline of a vessel when it enters the waterway.},
  archive      = {J_EJOR},
  author       = {Christof Defryn and Julian Arthur Pawel Golak and Alexander Grigoriev and Veerle Timmermans},
  doi          = {10.1016/j.ejor.2020.10.017},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {276-285},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Inland waterway efficiency through skipper collaboration and joint speed optimization},
  volume       = {292},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Building disaster preparedness and response capacity in
humanitarian supply chains using the social vulnerability index.
<em>EJOR</em>, <em>292</em>(1), 250–275. (<a
href="https://doi.org/10.1016/j.ejor.2020.10.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a novel humanitarian supply chain approach to address disaster preparedness and build response capacity in humanitarian supply chains when people’s vulnerability matters. Our primary motivation comes from the fact that disasters in Brazil are often associated with unequal distribution of opportunities and social inequalities that end up pushing more vulnerable people to risky areas or informal settlements. Moreover, investment in disaster management has dropped over the past few years in Brazil. In this way, we wonder: how to use the somewhat limited financial budget as effectively as possible towards meeting those that need the most while addressing disaster preparedness activities? To answer this question, we develop an optimization model to address location, capacity planning, prepositioning, local procurement, and relief aid flows’ decisions. Differently from most existing research, we adopt the so-called Social Vulnerability Index (SoVI) in the objective function to build enhanced response capacity in more vulnerable areas when the lack of resources makes impassable to fulfil all victims’ needs at once. Through a rich and real case-study based on the Brazilian Humanitarian Supply Chain, we come up with critical insights that can help to improve the humanitarian supply chain practices in the country. In particular, we show that the social benefit of using SoVI is as more significant as the vulnerability increases, which reveals the importance of considering this index to design more social-effective humanitarian supply chains.},
  archive      = {J_EJOR},
  author       = {Douglas Alem and Hector F. Bonilla-Londono and Ana Paula Barbosa-Povoa and Susana Relvas and Deisemara Ferreira and Alfredo Moreno},
  doi          = {10.1016/j.ejor.2020.10.016},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {250-275},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Building disaster preparedness and response capacity in humanitarian supply chains using the social vulnerability index},
  volume       = {292},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Efficiency intervals, rank intervals and dominance relations
of decision-making units with fixed-sum outputs. <em>EJOR</em>,
<em>292</em>(1), 238–249. (<a
href="https://doi.org/10.1016/j.ejor.2020.10.024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {How to evaluate the performance of decision-making units (DMUs) with fixed-sum outputs is a timely and challenging question in data envelopment analysis (DEA). Two major challenges are (1) how to determine a common equilibrium efficient frontier and (2) how to deal with multiple feasible equilibrium efficient frontiers. This paper first uses a simple dataset to illustrate the possibility of multiple equilibrium efficient frontiers and the corresponding major differences in the DMUs’ efficiencies and rankings resulting from these frontiers. We address these challenges by considering all feasible equilibrium efficient frontiers and develop several models to obtain the corresponding efficiency intervals, ranking intervals and dominance relations for the DMUs with fixed-sum outputs. We illustrate the proposed approach with two numerical examples and show that it gives more informative results than previous DEA approaches. For example, there are interesting dominance relations between DMUs under the fixed-sum outputs; yet these relations do not exist when there are no fixed-sum outputs. In addition, the efficiency ranges and ranking intervals can be narrowed by accounting for policy suggestions such as adjustment constraints of fixed-sum outputs for DMUs.},
  archive      = {J_EJOR},
  author       = {Lifan Chen and Mengyu Guo and Yongjun Li and Liang Liang and Ahti Salo},
  doi          = {10.1016/j.ejor.2020.10.024},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {238-249},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Efficiency intervals, rank intervals and dominance relations of decision-making units with fixed-sum outputs},
  volume       = {292},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). On the monotonicity of the eigenvector method.
<em>EJOR</em>, <em>292</em>(1), 230–237. (<a
href="https://doi.org/10.1016/j.ejor.2020.10.020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pairwise comparisons are used in a wide variety of decision situations where the importance of alternatives should be measured on a numerical scale. One popular method to derive the priorities is based on the right eigenvector of a multiplicative pairwise comparison matrix. We consider two monotonicity axioms in this setting. First, increasing an arbitrary entry of a pairwise comparison matrix is not allowed to result in a counter-intuitive rank reversal, that is, the favoured alternative in the corresponding row cannot be ranked lower than any other alternative if this was not the case before the change (rank monotonicity). Second, the same modification should not decrease the normalised weight of the favoured alternative (weight monotonicity). Both properties are satisfied by the geometric mean method but violated by the eigenvector method. The axioms do not uniquely determine the geometric mean. The relationship between the two monotonicity properties and the Saaty inconsistency index are investigated for the eigenvector method via simulations. Even though their violation turns out not to be a usual problem even for heavily inconsistent matrices, all decision-makers should be informed about the possible occurrence of such unexpected consequences of increasing a matrix entry.},
  archive      = {J_EJOR},
  author       = {László Csató and Dóra Gréta Petróczy},
  doi          = {10.1016/j.ejor.2020.10.020},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {230-237},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {On the monotonicity of the eigenvector method},
  volume       = {292},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Advertisement revenue management: Determining the optimal
mix of skippable and non-skippable ads for online video sharing
platforms. <em>EJOR</em>, <em>292</em>(1), 213–229. (<a
href="https://doi.org/10.1016/j.ejor.2020.10.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Skippable video advertisements (ads), which allow uninterested users to skip the ad after a few seconds, have witnessed rapid growth in the past few years. While their advantages for viewers and advertisers are obvious, they pose an ad revenue optimization problem for their publishers, i.e., the Video Sharing Platforms (VSPs). The VSPs need to critically balance the higher but uncertain revenue from skippable ads with the lower but guaranteed revenue from non-skippable ads. This problem is particularly challenging because non-skippable ads cause higher disutility to viewers. Moreover, due to network effect, this disutility has a long term impact on the VSPs’ revenue. In this paper we study the revenue management problem faced by a VSP in determining the optimal mix of skippable and non-skippable ads. We model VSP as a two sided platform, identify conditions under which an advertiser would prefer skippable ads over non-skippable ones, and derive the optimality conditions for VSP’s optimal ad mix. Our model reveals the existence of an upper bound on number of non-skippable ads, such that continued violation of this upper bound leads to a cascading effect, resulting in a reduction of both skippable and non-skippable ads over time. Our analysis helps a VSP in determining the incentive it should provide to the advertisers to switch to its preferred ad type. Our study reveals that non-skippable ads are essential for VSPs with niche or low content, and the proportion of skippable ads increases as the content increases or becomes more general.},
  archive      = {J_EJOR},
  author       = {Soumyakanti Chakraborty and Sumanta Basu and Saibal Ray and Megha Sharma},
  doi          = {10.1016/j.ejor.2020.10.012},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {213-229},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Advertisement revenue management: Determining the optimal mix of skippable and non-skippable ads for online video sharing platforms},
  volume       = {292},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Innovation performance evaluation for high-tech companies
using a dynamic network data envelopment analysis approach.
<em>EJOR</em>, <em>292</em>(1), 199–212. (<a
href="https://doi.org/10.1016/j.ejor.2020.10.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study examines innovation performance of high-tech companies in China, using a dynamic network data envelopment analysis (DEA) approach. The innovation process is decomposed into a research and development (R&amp;D) stage and a commercialization stage. In addition, innovation is conceptualized as a consecutive event that goes through multiple time intervals, requiring a dynamic structure of the methodological framework. Using a newly developed dynamic network DEA, the current study calculates a R&amp;D performance index and a commercialization index for the R&amp;D stage and commercialization stage, respectively. The multi-process innovation system is integrated with dynamic carryover items. This results in a highly non-linear dynamic network DEA model. Second order cone programming and nested partitions strategies are employed to solve the nonlinear dynamic network DEA model. Our empirical study indicates disparities in innovation performance among different Chinese high-tech companies. The innovation heterogeneity and inefficient performance sources are also investigated.},
  archive      = {J_EJOR},
  author       = {Anyu Yu and Yu Shi and Jianxin You and Joe Zhu},
  doi          = {10.1016/j.ejor.2020.10.011},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {199-212},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Innovation performance evaluation for high-tech companies using a dynamic network data envelopment analysis approach},
  volume       = {292},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Managing service-level contracts in sales hierarchies.
<em>EJOR</em>, <em>292</em>(1), 184–198. (<a
href="https://doi.org/10.1016/j.ejor.2020.10.033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Service-level contracts are increasingly common in the B2B relationships of manufacturers and their customers. Service-level contracts allow a certain part of demand to remain unfilled without incurring penalties, thus making allocation planning particularly difficult because the value of an allocation becomes clear only after all demands have realized. Oftentimes the hierarchical structure of sales organizations adds another level of complexity: Instead of having a central planner determining the allocations to all customers simultaneously, allocation planning must be performed decentrally along the individual levels of the sales hierarchy. We show that the resulting allocation problem is composed of two hierarchical subproblems, where the base-level problem is that of allocating supply to individual customers (customer-allocation problem—CAP), and the top-level problem is that of allocating along the individual levels of the hierarchy (hierarchy-allocation problem—HAP). We propose several new allocation approaches for the HAP and analyze their performance in an extensive numerical experiment. Our analyses suggest that with appropriate allocation approaches the performance of decentral planning can be close to that of central planning. Based on our results we also provide a useful guideline to decision makers to choose “appropriate” allocation approaches based on structural properties of the sales hierarchy.},
  archive      = {J_EJOR},
  author       = {Konstantin Kloos},
  doi          = {10.1016/j.ejor.2020.10.033},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {184-198},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Managing service-level contracts in sales hierarchies},
  volume       = {292},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The direct and cross effects in a supply chain with
consumers sensitive to both carbon emissions and delivery time.
<em>EJOR</em>, <em>292</em>(1), 172–183. (<a
href="https://doi.org/10.1016/j.ejor.2020.10.031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study a supply chain consisting of an upstream manufacturer who faces carbon tax regulation from the government, and a downstream retailer who sells the product to consumers via an online channel. The consumers are sensitive to the product&#39;s carbon emission as well as its delivery time. Building Stackelberg game models, we explore how consumers’ dual sensitivities to carbon emission and delivery time impact the two firms’ optimal decisions and profits. Our major findings are as follow. First, as expected, there are “direct effects” of consumer&#39;s dual sensitivities: the retailer&#39;s optimal delivery time decreases as consumers’ sensitivity to delivery time increases; the manufacturer&#39;s optimal carbon emission reduction effort level increases as consumers’ sensitivity to carbon emissions increases. Second and more importantly, there are distinct “cross effects” of consumers’ dual sensitivities: when the sensitivity to delivery time increases, the manufacturer&#39;s optimal carbon emission reduction effort level first decreases and then increases; if carbon tax rate increases, the retailer&#39;s optimal delivery time first increases and then decreases; if the sensitivity to the product&#39;s carbon emissions increases, the retailer&#39;s optimal delivery time always decreases. To address the potential free riding problem due to these “cross effects”, we propose a two-way cost sharing contract for the supply chain, where each firm shares a certain proportion of the other&#39;s investment cost. We show that this contract can achieve Pareto improvement for the supply chain.},
  archive      = {J_EJOR},
  author       = {Ping He and Zheng Wang and Victor Shi and Yi Liao},
  doi          = {10.1016/j.ejor.2020.10.031},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {172-183},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {The direct and cross effects in a supply chain with consumers sensitive to both carbon emissions and delivery time},
  volume       = {292},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Shelf space dimensioning and product allocation in retail
stores. <em>EJOR</em>, <em>292</em>(1), 155–171. (<a
href="https://doi.org/10.1016/j.ejor.2020.10.030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Retail shelves are adjustable by varying the number of shelf boards as well as the height and depth of each shelf board. Shelf planners adjust the boards accordingly at regular intervals when they create the shelf plans and allocate products. Current shelf planning models assume given shelf configurations and allocate only products. However, the dimensioning of a shelf segment and product allocation are interdependent. For instance, the height of one segment may be reduced if only small products are allocated or products cannot be stacked. This paper proposes the first integrated approach for shelf segment dimensioning and product allocation. It jointly determines the number of facings for each product, the shelf quantity and the size and number of shelf segments. We also identify and consider several restrictions for the shelf structure (e.g., technical options), allocation rules (e.g., maximum inventory reach) and allocation- and shelf-layout-dependent demand. We formulate the decision problem at hand which is an Integer Non-linear Program and apply a solution algorithm based on the application of bounds that are obtained by transferring constraints to a preprocessing stage. Doing so, we can reformulate the problem as Binary Integer Program, provide an exact approach and generate practical applicable and optimal solutions in a time-efficient manner. We show that integrating shelf dimensioning into product allocation results in up to 5\% higher profits than benchmarks available in literature. By means of a case study we show how planning can be improved, and that the retailer’s profit margin can be improved by up to 7\%.},
  archive      = {J_EJOR},
  author       = {Alexander Hübner and Tobias Düsterhöft and Manuel Ostermeier},
  doi          = {10.1016/j.ejor.2020.10.030},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {155-171},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Shelf space dimensioning and product allocation in retail stores},
  volume       = {292},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Modelling and multi-criteria analysis of the sustainability
dimensions for the green vehicle routing problem. <em>EJOR</em>,
<em>292</em>(1), 143–154. (<a
href="https://doi.org/10.1016/j.ejor.2020.10.028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The transport sector leads to detrimental effects on the economy, environment, and citizens quality of life. During recent years, some key-performance indicators have been proposed to quantify these negative impacts on the economic, environmental, and social dimensions of the sustainability concept. In this paper, we consider the sustainable vehicle routing problem that takes into account the aforementioned dimensions. We propose a weighted sum model and an epsilon-constraint model that combine the three dimensions, as well as a biased-randomised iterated greedy algorithm to solve the integrated problem. A comprehensive set of experiments and sensitivity analysis have been carried out with newly generated instances, which were adapted from existing vehicle routing benchmark instances. The sensitivity analysis is performed to measure the impact of each sustainability dimension and investigate trade-offs among them.},
  archive      = {J_EJOR},
  author       = {Hassana Abdullahi and Lorena Reyes-Rubiano and Djamila Ouelhadj and Javier Faulin and Angel A. Juan},
  doi          = {10.1016/j.ejor.2020.10.028},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {143-154},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Modelling and multi-criteria analysis of the sustainability dimensions for the green vehicle routing problem},
  volume       = {292},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Green credit financing versus trade credit financing in a
supply chain with carbon emission limits. <em>EJOR</em>,
<em>292</em>(1), 125–142. (<a
href="https://doi.org/10.1016/j.ejor.2020.10.025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Green credit financing (GCF) is a type of financial service provided by banks to encourage borrowers to commit green investment and achieve sustainable development. This study investigates a supply chain system consisting of a capital-constrained manufacturer and a well-funded supplier facing uncertain demand, in which the manufacturer may seek GCF from banks. An important prerequisite for obtaining a green loan is that the borrower must make green upgrades and ensure compliance with pre-specified environmental standards. We design a GCF model for a supply chain by imposing a hard constraint on carbon emissions. To determine the effectiveness of GCF, we conduct an in-depth analysis comparing the GCF with traditional trade credit financing (TCF), in which excessive carbon emissions are penalized. The optimal equilibrium solutions under GCF and TCF mode are obtained and their sensitivities to key parameters analyzed. Concerning the preferences of the two financing strategies, we find that under a relatively strict carbon emission policy, the manufacturer can set an appropriate green investment range to achieve a win-win situation with the supplier. Finally, we compare the social welfare of the supply chain for the different financing modes and find that there are regions in which both the social welfare and profit of the manufacturer can be a win-win. The government can guide manufacturers to make a win-win choice by setting different carbon caps.},
  archive      = {J_EJOR},
  author       = {Simin An and Bo Li and Dongping Song and Xue Chen},
  doi          = {10.1016/j.ejor.2020.10.025},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {125-142},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Green credit financing versus trade credit financing in a supply chain with carbon emission limits},
  volume       = {292},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Benders’ decomposition for the balancing of assembly lines
with stochastic demand. <em>EJOR</em>, <em>292</em>(1), 108–124. (<a
href="https://doi.org/10.1016/j.ejor.2020.10.019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The quality of the balancing of mixed-model assembly lines is intimately related to the defined production sequence. The two problems are, however, incompatible in time, as balancing takes place when planning the line, while sequencing is an operational problem closely related to market demand fluctuations. In this paper, an exact procedure to solve the integrated balancing and sequencing problem with stochastic demand is presented. The searched balancing solution must be flexible enough to cope with different demand scenarios. A paced assembly line is considered and utility work is used as a recourse for station border violations. A Benders’ decomposition algorithm is developed along with valid inequalities and preprocessing as a solution procedure. Three datasets are proposed and used to test algorithm performance and the value of treating uncertainty in mixed-model assembly lines. The integration of the strategic balancing problem with the operational sequencing problem results in more robust assembly lines.},
  archive      = {J_EJOR},
  author       = {Celso Gustavo Stall Sikora},
  doi          = {10.1016/j.ejor.2020.10.019},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {108-124},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Benders’ decomposition for the balancing of assembly lines with stochastic demand},
  volume       = {292},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Counterfactual regret minimization for integrated cyber and
air defense resource allocation. <em>EJOR</em>, <em>292</em>(1), 95–107.
(<a href="https://doi.org/10.1016/j.ejor.2020.10.015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This research presents a new application of optimal and approximate solution techniques to solve resource allocation problems with imperfect information in the cyber and air-defense domains. We develop a two-player, zero-sum, extensive-form game to model attacker and defender roles in both physical and cyber space. We reformulate the problem to find a Nash equilibrium using an efficient, sequence-form linear program. Solving this linear program produces optimal defender strategies for the multi-domain security game. We address large problem instances with an application of the approximate counterfactual regret minimization algorithm. This approximation reduces computation time by 95\% while maintaining an optimality gap of less than 3\%. Our application of discounted counterfactual regret results in a further 36\% reduction in computation time from the base algorithm. We develop domain insights through a designed experiment to explore the parameter space of the problem and algorithm. We also address robust opponent exploitation by combining existing techniques to extend the counterfactual regret algorithm to include a discounted, constrained variant. A comparison of robust linear programming, data-biased response, and constrained counterfactual regret approaches clarifies trade-offs between exploitation and exploitability for each method. The robust linear programming approach is the most effective, producing an exploitation to exploitability ratio of 10.8 to 1.},
  archive      = {J_EJOR},
  author       = {Andrew Keith and Darryl Ahner},
  doi          = {10.1016/j.ejor.2020.10.015},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {95-107},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Counterfactual regret minimization for integrated cyber and air defense resource allocation},
  volume       = {292},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Simultaneous node and link districting in transportation
networks: Model, algorithms and railway application. <em>EJOR</em>,
<em>292</em>(1), 73–94. (<a
href="https://doi.org/10.1016/j.ejor.2020.10.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Partitioning a large network into multiple subnetworks is adopted extensively in various practical applications involving the architecture of distributed management. In this study, we consider strategic simultaneous node and link districting to partition the nodes and links of a given transportation network into a fixed number of mutually disjoint districts, based on the districting criteria of integrity, contiguity, balance, and independence. We first formulate the resulting problem as a mixed integer linear programming model to minimize the weighted sum of the total size deviation of districts and total cooperation between districts. An improved network flow-based technique is proposed to incorporate the complicated contiguity criterion by using a polynomial number of constraints. Valid inequalities, which break the symmetry within and between districts, are designed to strengthen the model. To solve this challenge problem, we reformulate it as a binary linear programming model, and develop a column generation-based algorithm to find tight lower bounds and good-quality solutions. Then, an iterative search algorithm is designed to obtain good-quality solutions rapidly. Furthermore, a more efficient hybrid algorithm is proposed by using the results of the iterative search algorithm to initialize the column generation-based algorithm. We assess the proposed model and algorithms by using various scales of instances derived from the train dispatcher desk districting problem, which is a practical application of the investigated problem in the context of railway. The computational results reveal that our approaches outperform existing approaches and a commercial solver, and our best algorithm can solve almost all the investigated instances to optimality within a considerably short average computation time. The districting solutions of our approaches are also better than the empirical solutions designed by railway managers mainly based on experience.},
  archive      = {J_EJOR},
  author       = {Dian Wang and Jun Zhao and Andrea D’Ariano and Qiyuan Peng},
  doi          = {10.1016/j.ejor.2020.10.013},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {73-94},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Simultaneous node and link districting in transportation networks: Model, algorithms and railway application},
  volume       = {292},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Solving the length constrained k-drones rural postman
problem. <em>EJOR</em>, <em>292</em>(1), 60–72. (<a
href="https://doi.org/10.1016/j.ejor.2020.10.035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we address the Length Constrained K K -Drones Rural Postman Problem (LC K K -DRPP). This is a continuous optimization problem where a fleet of homogeneous drones have to jointly service (traverse) a set of (curved or straight) lines of a network. Unlike the vehicles in classical arc routing problems, a drone can enter a line through any of its points, service a portion of that line, exit through another of its points, then travel directly to any point on another line, and so on. Moreover, since the range of the drones is restricted, the length of each route is limited by a maximum distance. Some applications for drone arc routing problems include inspection of pipelines, railway or power transmission lines and traffic monitoring. To deal with this problem, LC K K -DRPP instances are digitized by approximating each line by a polygonal chain with a finite number of points and allowing drones to enter and exit each line only at these points. In this way we obtain an instance of the Length Constrained K K -vehicles Rural Postman Problem (LC K K -RPP). If the number of points used to discretize the lines is large, the LC K K -RPP instance can be extremely large and, hence, very difficult to solve optimally. Even heuristic algorithms can fail in providing feasible solutions in reasonable computing times. An alternative is to generate smaller LC K K -RPP instances by approximating each line with few but “significant” segments. We present a formulation and some valid inequalities for the LC K K -RPP. Based on this, we have designed and implemented a branch-and-cut algorithm for its solution. Moreover, in order to be capable of providing good solutions for large LC K K -RPP instances, we propose a matheuristic algorithm that begins by finding good solutions for the LC K K -RPP instance obtained by approximating each line by a single segment. Then, to find better solutions, some promising intermediate points are sequentially incorporated. Extensive computational experiments to assess the performance of both algorithms are performed on several sets of instances from the literature.},
  archive      = {J_EJOR},
  author       = {James F. Campbell and Ángel Corberán and Isaac Plana and José M. Sanchis and Paula Segura},
  doi          = {10.1016/j.ejor.2020.10.035},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {60-72},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Solving the length constrained K-drones rural postman problem},
  volume       = {292},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A new algorithm for resource-constrained project scheduling
with breadth and depth of skills. <em>EJOR</em>, <em>292</em>(1), 43–59.
(<a href="https://doi.org/10.1016/j.ejor.2020.10.032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses a multi-skilled extension of the resource-constrained project scheduling problem (RCPSP). Although a handful of papers dealt with the multi-skilled RCPSP (MSRCPSP), little to no attention is given to the ideal levels of skills for multi-skilled resources. In this paper, skills are measured along two dimensions known as breadth and depth. In a project environment, the breadth of a resource is perceived as the amount of skills an employee masters. The depth of a skill is the efficiency level at which work can be performed by a resource that masters that skill. The MSRCPSP with breadth and depth consists of scheduling activities with skill requirements and assigning multi-skilled resources to those activities. To be able to efficiently solve the MSRCPSP, a genetic algorithm is developed. Using the created activity schedules and resources assignments, the best workforce characteristics are analysed. Key aspects in this analysis are the breadth and depth. The problem-specific procedure combines a new representation, a new crossover and tailor-made local searches. Computational experiments measure the impact of different multi-skilled resources and their efficiency levels on the makespan of the project.},
  archive      = {J_EJOR},
  author       = {Jakob Snauwaert and Mario Vanhoucke},
  doi          = {10.1016/j.ejor.2020.10.032},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {43-59},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A new algorithm for resource-constrained project scheduling with breadth and depth of skills},
  volume       = {292},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A new mathematical formulation for a potash-mine shift
scheduling problem with a simultaneous assignment of machines and
workers. <em>EJOR</em>, <em>292</em>(1), 27–42. (<a
href="https://doi.org/10.1016/j.ejor.2020.10.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we introduce a mixed-integer linear program for a shift scheduling problem in a German potash mine. In particular, we consider a short-term (work shift) production scheduling problem, where drill-and-blast mining operations have to be assigned to machines and workers simultaneously. Since we deal with several sequence-dependent setup, changeover, and removal times, TSP-variables are used in the mathematical program to determine the processing-sequence of the operations on each worker and each machine, respectively. In addition, several mining-specific requirements are taken into account to obtain a solution that can be put into practice. Computational experiments are conducted on problem instances of realistic size derived from real-world data. The results show that our new mixed-integer linear formulation outperforms both existing solution procedures for the problem at hand.},
  archive      = {J_EJOR},
  author       = {Cinna Seifi and Marco Schulze and Jürgen Zimmermann},
  doi          = {10.1016/j.ejor.2020.10.007},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {27-42},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A new mathematical formulation for a potash-mine shift scheduling problem with a simultaneous assignment of machines and workers},
  volume       = {292},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Applications of stochastic modeling in air traffic
management: Methods, challenges and opportunities for solving air
traffic problems under uncertainty. <em>EJOR</em>, <em>292</em>(1),
1–26. (<a href="https://doi.org/10.1016/j.ejor.2020.10.039">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we provide a wide-ranging review of the literature on stochastic modeling applications within aviation, with a particular focus on problems involving demand and capacity management and the mitigation of air traffic congestion. From an operations research perspective, the main techniques of interest include analytical queueing theory, stochastic optimal control, robust optimization and stochastic integer programming. Applications of these techniques include the prediction of operational delays at airports, pre-tactical control of aircraft departure times, dynamic control and allocation of scarce airport resources and various others. We provide a critical review of recent developments in the literature and identify promising research opportunities for stochastic modelers within air traffic management.},
  archive      = {J_EJOR},
  author       = {Rob Shone and Kevin Glazebrook and Konstantinos G. Zografos},
  doi          = {10.1016/j.ejor.2020.10.039},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {1-26},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Applications of stochastic modeling in air traffic management: Methods, challenges and opportunities for solving air traffic problems under uncertainty},
  volume       = {292},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Crowdfunding mechanism comparison if there are altruistic
donors. <em>EJOR</em>, <em>291</em>(3), 1198–1211. (<a
href="https://doi.org/10.1016/j.ejor.2020.10.014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies how the crowdfunding price, funding goal, and mechanism selection are influenced by the participation of altruistic donors who contribute money to help a crowdfunding campaign reach its goal instead of being motivated by rewards. A creator can choose either the All-or-Nothing (AON) mechanism, where the creator keeps the pledges only if the total amount pledged exceeds the funding goal, or the Keep-it-All (KIA) mechanism, where the creator keeps the pledges regardless of the outcome of the campaign. We show that when the creator raises funds only through crowdfunding, the contributions from donors encourage the creator to choose AON, while when the creator will approach a venture capitalist (VC) for further investment after crowdfunding, donor contributions encourage the creator to choose KIA. Our analysis also shows that the creator is more likely to exploit the contributions from donors by setting a high target number of backers under KIA than under AON. Furthermore, we explore two extensions, scenarios in which consumers arrive at the crowdfunding campaign sequentially or the creator can choose a mixed mechanism.},
  archive      = {J_EJOR},
  author       = {Xihan Guo and Gongbing Bi and Jiancheng Lv},
  doi          = {10.1016/j.ejor.2020.10.014},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1198-1211},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Crowdfunding mechanism comparison if there are altruistic donors},
  volume       = {291},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Accounting for risk factors on health outcomes: The case of
luxembourg. <em>EJOR</em>, <em>291</em>(3), 1180–1197. (<a
href="https://doi.org/10.1016/j.ejor.2020.09.040">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a two-parameter family of health indicators. First, these operational research indicators are axiomatically derived and allow a Boolean risk factor to be linked to different health dimensions. Second, the behavior of the social planner with respect to the risk factor (risk insensibility, risk sensibility and extreme risk sensibility) is introduced. We demonstrate that these indicators are consistent with a stochastic dominance rule, which is an operational research rule for decision making. Using data from the Survey of Health, Ageing and Retirement in Europe, we show that, among the different childhood circumstances of individuals having an impact on the health status in adulthood, having parents with a migration background and low educated constitutes the risk factors that aggravate the most the overall level of socio-economic health inequality in Luxembourg.},
  archive      = {J_EJOR},
  author       = {Stéphane Mussard and María Noel Pi Alperin},
  doi          = {10.1016/j.ejor.2020.09.040},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1180-1197},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Accounting for risk factors on health outcomes: The case of luxembourg},
  volume       = {291},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Pairwise stable networks in homogeneous societies with weak
link externalities. <em>EJOR</em>, <em>291</em>(3), 1164–1179. (<a
href="https://doi.org/10.1016/j.ejor.2020.09.025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study general properties of pairwise stable and pairwise Nash stable networks when players are ex-ante homogeneous. Rather than assuming a particular functional form of utility, we impose general link externality conditions on utility such as ordinal convexity and ordinal strategic complements. Depending on these rather weak notions of link externalities, we show that pairwise Nash stable networks of various structure exist. For stronger versions of the convexity and strategic complements conditions, we are even able to characterize all pairwise stable networks: they are nested split graphs. We illustrate these results with many examples from the literature, including utility functions that arise from games with strategic complements played on the network and utility functions that depend on centrality measures such as Bonacich centrality.},
  archive      = {J_EJOR},
  author       = {Tim Hellmann},
  doi          = {10.1016/j.ejor.2020.09.025},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1164-1179},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Pairwise stable networks in homogeneous societies with weak link externalities},
  volume       = {291},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Risk parity with expectiles. <em>EJOR</em>, <em>291</em>(3),
1149–1163. (<a
href="https://doi.org/10.1016/j.ejor.2020.10.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A recent popular approach to portfolio selection aims at diversifying risk by looking for the so called Risk Parity portfolios. These are defined by the condition that the risk contributions of all assets to the global risk of the portfolio are equal. The Risk Parity approach has been originally introduced for the volatility risk measure. In this paper we consider expectiles as risk measures, we refine results on their differentiability and additivity, and we show how to define Risk Parity portfolios when the expectiles are used. Furthermore, we propose three different classes of methods for practically finding Risk Parity portfolios with respect to expectiles, and we compare the accuracy and efficiency of these methods on real-world data. Expectiles are also used as risk measures in the classical risk-return approach to portfolio selection, where we present a new linear programming formulation.},
  archive      = {J_EJOR},
  author       = {Fabio Bellini and Francesco Cesarone and Christian Colombo and Fabio Tardella},
  doi          = {10.1016/j.ejor.2020.10.009},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1149-1163},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Risk parity with expectiles},
  volume       = {291},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Analysis of futures and spot electricity markets under risk
aversion. <em>EJOR</em>, <em>291</em>(3), 1132–1148. (<a
href="https://doi.org/10.1016/j.ejor.2020.10.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We analyze the procurement problem in the electricity supply chain, focusing on the interaction between futures and spot prices. The supply chain network analyzed in our study includes risk-averse generators and retailers, both with the ability to use conditional value at risk (CV@R) in their decision processes. In this supply chain, the futures price is computed to clear the futures market, without imposing the constraint that the expected spot price equals the futures price. As major methodological contributions: we compute the Nash equilibrium of the problem using CV@R and considering conjectural variations; we derive analytical relationships between the futures and the spot market outcomes and study the implications of demand and marginal cost uncertainty, as well as the level of the players’ risk aversion, on market equilibrium; we introduce the concept of risk-adjusted expectation to derive the futures market price as a function of the players’ expected losses or profits in the spot market; and we use consistent spot and wholesale price derivatives to calculate the players’ reaction functions. Finally, we illustrate our model with several numerical examples in the context of the Spanish electricity market, studying how the shape of the forward curve and the relationship between spot and futures prices depend on seasonality, risk aversion, generators’ market power, and hydrological resources. Surprisingly we observed that risk aversion increases the profit and reduces firms’ risk, and that the consumer utility is higher in the scenarios in which retailers behave a la Cournot in the wholesale market.},
  archive      = {J_EJOR},
  author       = {Fernando S. Oliveira and Carlos Ruiz},
  doi          = {10.1016/j.ejor.2020.10.005},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1132-1148},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Analysis of futures and spot electricity markets under risk aversion},
  volume       = {291},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Ripple effect in the supply chain network: Forward and
backward disruption propagation, network health and firm vulnerability.
<em>EJOR</em>, <em>291</em>(3), 1117–1131. (<a
href="https://doi.org/10.1016/j.ejor.2020.09.053">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A local disruption can propagate to forward and downward through the material flow and eventually influence the entire supply chain network (SCN). This phenomenon of ripple effect, immensely existing in practice, has received great interest in recent years. Moreover, forward and backward disruption propagations became major stressors for SCNs during the COVID-19 pandemic triggered by simultaneous and sequential supply and demand disruptions. However, current literature has paid less attention to the different impacts of the directions of disruption propagation. This study examines the disruption propagation through simulating simple interaction rules of firms inside the SCN. Specifically, an agent-based computational model is developed to delineate the supply chain disruption propagation behavior. Then, we conduct multi-level quantitative analysis to explore the effects of forward and backward disruption propagation, moderated by network structure, network-level health and node-level vulnerability. Our results demonstrate that it is practically important to differentiate between forward and backward disruption propagation, as they are distinctive in the associated mitigation strategies and in the effects on network and individual firm performance. Forward disruption propagation generally can be mitigated by substitute and backup supply and has greater impact on firms serving the assembly role and on the supply/assembly networks, whereas backward disruption propagation is normally mitigated by flexible operation and distribution and has bigger impact on firms serving the distribution role and on distribution networks. We further analyze the investment strategies in a dual-focal supply network under disruption propagation. We provide propositions to facilitate decision-making and summarize important managerial implications.},
  archive      = {J_EJOR},
  author       = {Yuhong Li and Kedong Chen and Stephane Collignon and Dmitry Ivanov},
  doi          = {10.1016/j.ejor.2020.09.053},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1117-1131},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Ripple effect in the supply chain network: Forward and backward disruption propagation, network health and firm vulnerability},
  volume       = {291},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A data-driven optimization approach for multi-period
resource allocation in cholera outbreak control. <em>EJOR</em>,
<em>291</em>(3), 1106–1116. (<a
href="https://doi.org/10.1016/j.ejor.2020.09.052">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cholera, a water-borne bacteria infectious disease, shows clear spatial variation in its transmission pattern. It is thus important to incorporate understanding on the spatial variability of its transmission when making transmission prediction and intervention decisions. However, for an emerging cholera outbreak, transmission dynamics models are often uncertain as model parameters are indeterminate and epidemic state can only be partially observed. Hence, ensuing intervention decisions have to be made under uncertainty and thus the resultant optimization problem is challenging. In this paper, we study a multi-period location-specific resource allocation problem for cholera outbreak intervention with periodically acquired state information from different locations and increasingly understood transmission parameters over time. We formulate the problem as a nonlinear optimization model on a set of ordinary-differential-equations governing location-specific disease transmission dynamics. We propose a data-driven optimization approach to determine the optimal strategy of intervention resource allocation at each period and each community in a rolling-horizon manner. At each period, we integrate single-period model parameter fitting and scenario-based stochastic programming to make decisions under uncertainty with newly acquired system understanding. We conduct comparative studies to assess the performance of our data-driven optimization approach and offer insights into intervention resource allocation policy development. We conclude that our data-driven optimization approach is effective to multi-period decision problems under system dynamics with indeterminate parameters.},
  archive      = {J_EJOR},
  author       = {Mu Du and Aditya Sai and Nan Kong},
  doi          = {10.1016/j.ejor.2020.09.052},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1106-1116},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A data-driven optimization approach for multi-period resource allocation in cholera outbreak control},
  volume       = {291},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Renewable auctions: Bidding for real options. <em>EJOR</em>,
<em>291</em>(3), 1091–1105. (<a
href="https://doi.org/10.1016/j.ejor.2020.09.047">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Procurement auctions for renewable energy support have become a standard policy instrument to stimulate investment in clean energy. Winning bidders have the right but not the obligation to realize their projects during a grace period following the auction. Currently, the nexus of award prices and the realization rate is not well understood in the literature. We combine auction theory and real options theory to model bidders who view the right to build subsidized renewable capacity as real option. Using asymptotic theory for multi-unit auctions, we derive optimal bidding strategies and analyze how auction design and bidder characteristics impact equilibrium bids, award prices, and realization rates. In particular, we show that bidders who value the flexibility of non-realization higher bid more aggressively and exhibit lower realization rates. We analyze determinants of these effects and illustrate how auction design can trade-off procurement cost and realization rates by adjusting pre-qualification payments and the grace period for construction. Finally, we test our results on real-world auctions in UK and Germany and show that our model explains auction outcomes and observed realization rates.},
  archive      = {J_EJOR},
  author       = {David Matthäus and Sebastian Schwenen and David Wozabal},
  doi          = {10.1016/j.ejor.2020.09.047},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1091-1105},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Renewable auctions: Bidding for real options},
  volume       = {291},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Hybrid models as transdisciplinary research enablers.
<em>EJOR</em>, <em>291</em>(3), 1075–1090. (<a
href="https://doi.org/10.1016/j.ejor.2020.10.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modelling and simulation (M&amp;S) techniques are frequently used in Operations Research (OR) to aid decision-making. With growing complexity of systems to be modelled, an increasing number of studies now apply multiple M&amp;S techniques or hybrid simulation (HS) to represent the underlying system of interest. A parallel but related theme of research is extending the HS approach to include the development of hybrid models (HM). HM extends the M&amp;S discipline by combining theories, methods and tools from across disciplines and applying multidisciplinary, interdisciplinary and transdisciplinary solutions to practice. In the broader OR literature, there are numerous examples of cross-disciplinary approaches in model development. However, within M&amp;S, there is limited evidence of the application of conjoined methods for building HM. Where a stream of such research does exist, the integration of approaches is mostly at a technical level. In this paper, we argue that HM requires cross-disciplinary research engagement and a conceptual framework. The framework will enable the synthesis of discipline-specific methods and techniques, further cross-disciplinary research within the M&amp;S community, and will serve as a transcending framework for the transdisciplinary alignment of M&amp;S research with domain knowledge, hypotheses and theories from diverse disciplines. The framework will support the development of new composable HM methods, tools and applications. Although our framework is built around M&amp;S literature, it is generally applicable to other disciplines, especially those with a computational element. The objective is to motivate a transdisciplinarity-enabling framework that supports the collaboration of research efforts from multiple disciplines, allowing them to grow into transdisciplinary research.},
  archive      = {J_EJOR},
  author       = {Andreas Tolk and Alison Harper and Navonil Mustafee},
  doi          = {10.1016/j.ejor.2020.10.010},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1075-1090},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Hybrid models as transdisciplinary research enablers},
  volume       = {291},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Partial refunds as a strategic price commitment device in
advance selling in a service industry. <em>EJOR</em>, <em>291</em>(3),
1062–1074. (<a
href="https://doi.org/10.1016/j.ejor.2020.10.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Over the past decade, consumers’ strategic waiting behavior in anticipation of a price markdown has become increasingly common when advance selling is used. Recently, studies in the durable goods industry show that a partial refund strategy can activate the price-commitment mechanism to counter consumers’ strategic waiting, which is primarily driven by both consumers’ and retailers’ behaviors that discount the future. In this research, we investigate the possibility of using this partial refund strategy in a service industry context in which demand uncertainty and consumption state uncertainty act as major influential factors. We study analytical models that consider the demand uncertainty of later arrivals and the consumption state uncertainty of early arrivals over two selling periods (advance and spot selling). Our results show a consistent pattern reflecting that a partial refund strategy in which the cancellation fee acts as a price-commitment mechanism is capable of emerging as the optimal strategy. Other than the strategic commitment mechanism, the cancellation fee paid by the advance buyers who choose to cancel their advance purchase also plays a profit-enhancer role. Combining these two mechanisms, a partial refund strategy dominates both a price-matching strategy and a dynamic pricing strategy, and they are only special cases of that type of strategy. Finally, comparative statistical analyses are conducted and reveal the impacts of demand-related parameters on the optimality of the partial refund strategy. These results provide instructive guidance for sellers when utilizing the partial refund strategy in their marketing practices.},
  archive      = {J_EJOR},
  author       = {Zelin Zhang and Weishi Lim and Haitao Cui and Ze Wang},
  doi          = {10.1016/j.ejor.2020.10.001},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1062-1074},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Partial refunds as a strategic price commitment device in advance selling in a service industry},
  volume       = {291},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Fostering long-term care planning in practice: Extending
objectives and advancing stochastic treatment within location-allocation
modelling. <em>EJOR</em>, <em>291</em>(3), 1041–1061. (<a
href="https://doi.org/10.1016/j.ejor.2020.09.055">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many countries are currently concerned with the planning of networks of Long-Term Care (LTC), which requires considering a multiplicity of policy objectives and anticipating the impact of key uncertainties. Nevertheless, location-allocation literature has not been modelling key health policy objectives, and the use of stochastic planning models entails low practical usability due to prohibitive computational times. This study tackles these issues by proposing an approach that supports the reorganization of LTC networks (in terms of services location, capacity planning and patients allocation) while exploring different health policy objectives and considering uncertainty within a reasonable computational time, leading to the development of a stochastic multi-objective mathematical programming model – the LTCNetPlanner. The LTCNetPlanner builds upon health economics and policy concepts to model the maximization of health and wellbeing together with cost- and equity-related objectives within location-allocation literature. Concerning uncertainty, a scenario-based stochastic approach is developed and alternative scenario reduction methods enabling a faster model resolution are explored within the LTCNetPlanner . Specifically, it is proposed a novel Morphol-KMG method able to reduce the number of scenarios while accounting for experts’ knowledge. A case study in the Great Lisbon region is explored, showing the usefulness of the proposed scenario reduction method to reduce computational times, and how planning decisions change when health and wellbeing benefits are considered.},
  archive      = {J_EJOR},
  author       = {Teresa Cardoso-Grilo and Mónica Duarte Oliveira and Ana Barbosa-Póvoa},
  doi          = {10.1016/j.ejor.2020.09.055},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1041-1061},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Fostering long-term care planning in practice: Extending objectives and advancing stochastic treatment within location-allocation modelling},
  volume       = {291},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Strategic customer behavior in a queueing system with
alternating information structure. <em>EJOR</em>, <em>291</em>(3),
1024–1040. (<a
href="https://doi.org/10.1016/j.ejor.2020.10.054">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Strategic customer behavior is strongly influenced by the level of information that is provided to customers. Hence, to optimize the design of queueing systems, many studies consider various versions of the same service model and compare them under different information structures. In particular, two extreme versions are usually considered and compared: the observable in which customers are informed about the number of customers in the system and the unobservable in which they are only informed about the system parameters, e.g., arrival and service rates. In the present work, we study a model that bridges these two versions. More concretely, we assume that the system alternates between observable and unobservable periods. We characterize and compute customer equilibrium joining/balking strategies and show that the present model unifies and extends existing approaches of both heterogeneously observable models and models with delayed observations. More importantly, our findings indicate that an alternating information structure implies in general higher equilibrium throughput and social welfare in comparison to both the observable and unobservable cases. We complement our results with numerical experiments and provide managerial insight on the optimal control of the system parameters.},
  archive      = {J_EJOR},
  author       = {Yiannis Dimitrakopoulos and Antonis Economou and Stefanos Leonardos},
  doi          = {10.1016/j.ejor.2020.10.054},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1024-1040},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Strategic customer behavior in a queueing system with alternating information structure},
  volume       = {291},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Resource allocation for contingency planning: An inexact
proximal bundle method for stochastic optimization. <em>EJOR</em>,
<em>291</em>(3), 1008–1023. (<a
href="https://doi.org/10.1016/j.ejor.2020.10.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Resource contingency planning aims to mitigate the effects of unexpected disruptions in supply chains. While these failures occur infrequently, they often have disastrous consequences. This paper formulates the resource allocation problem in contingency planning as a two-stage stochastic optimization problem with a risk-averse recourse function. The solution method proposed relies on an inexact proximal bundle method with subgradient approximations through a scenario reduction mechanism. The paper extends the inexact oracle to a more general risk-averse setting, and proves that it meets the requirements of the oracle in the inexact bundle method, ensuring convergence to an optimal solution. The practical performance of the developed inexact bundle method under risk aversion is investigated for our resource allocation problem. We create a library of test problems and obtain their optimal values by applying the exact bundle method. The computed solutions from the developed inexact bundle method are compared against these optimal values, under different coherent risk measures. Our analyses indicate that our inexact bundle method significantly reduces the computational time of solving the resource allocation problem in comparison to the exact bundle method, and is capable of achieving a high percentage of optimality within a much shorter time.},
  archive      = {J_EJOR},
  author       = {Somayeh Moazeni and Ricardo A. Collado},
  doi          = {10.1016/j.ejor.2020.10.008},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1008-1023},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Resource allocation for contingency planning: An inexact proximal bundle method for stochastic optimization},
  volume       = {291},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Data-driven distributionally robust capacitated facility
location problem. <em>EJOR</em>, <em>291</em>(3), 995–1007. (<a
href="https://doi.org/10.1016/j.ejor.2020.09.026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study a distributionally robust version of the classical capacitated facility location problem with a distributional ambiguity set defined as a Wasserstein ball around an empirical distribution constructed based on a small data sample. Both single- and two-stage problems are addressed, with customer demands being the uncertain parameter. For the single-stage problem, we provide a direct reformulation into a mixed-integer program. For the two-stage problem, we develop two iterative algorithms, based on column generation, for solving the problem exactly. We also present conservative approximations based on support set relaxation for the single- and two-stage problems, an affine decision rule approximation of the two-stage problem, and a relaxation of the two-stage problem based on support set restriction. Numerical experiments on benchmark instances show that the exact solution algorithms are capable of solving large scale problems efficiently. The different approximation schemes are numerically compared and the performance guarantee of the two-stage problem’s solution on out-of-sample data is analyzed.},
  archive      = {J_EJOR},
  author       = {Ahmed Saif and Erick Delage},
  doi          = {10.1016/j.ejor.2020.09.026},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {995-1007},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Data-driven distributionally robust capacitated facility location problem},
  volume       = {291},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Robust car sequencing for automotive assembly.
<em>EJOR</em>, <em>291</em>(3), 983–994. (<a
href="https://doi.org/10.1016/j.ejor.2020.10.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Just-in-sequence material supply is the status quo in the automotive industry. In this process, the assembly sequence of vehicles is set several days prior to production, and communicated to the suppliers. The committed sequence is essential for efficient operations both at the original equipment manufacturer and its suppliers. In practice, however, sequence stability is insufficient. Short-term disruptions, such as quality problems and missing parts, put the sequence at risk. If a disruption occurs, the affected vehicle is removed from the sequence. The resulting gap is closed by bringing the succeeding vehicles forward. Such sequence alterations, however, cause workload changes and potentially work overloads at the assembly stations. As a remedial measure, additional sequence alterations are necessary, which further disturb material supply. Robustness against short-term sequence alterations is currently a key objective of automotive manufacturers. In this paper, we propose a sequencing approach that includes the vehicles’ failure probabilities in order to generate robust sequences. Robust sequences are sequences that can be operated without modifications, even when vehicles fail. We develop a branch-and-bound algorithm that optimally solves small-sized instances. For large-sized instances, we design a sampling-based adaptive large neighborhood search heuristic. The superiority of our approach is validated in a simulation study using real-world data from a major European manufacturer. We find reductions in the expected work overloads of 72\% and 80\%, compared to the industry solution, and compared to an approach taken from literature which does not take failures into account.},
  archive      = {J_EJOR},
  author       = {Andreas Hottenrott and Leon Waidner and Martin Grunow},
  doi          = {10.1016/j.ejor.2020.10.004},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {983-994},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Robust car sequencing for automotive assembly},
  volume       = {291},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Optimal scheduling of slots with season segmentation.
<em>EJOR</em>, <em>291</em>(3), 961–982. (<a
href="https://doi.org/10.1016/j.ejor.2020.10.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Capacity at overly congested airports is managed through the allocation of slots for landing and take-off according to the IATA Worldwide Slot Guidelines. Under this scheme, slots are allocated over a six month scheduling season, and requests are typically made in series i.e. requests are made for the same time and days of the week over a given period. Although allocating slots in series has the advantage of preserving schedule regularity, it causes blocking with a detrimental effect on capacity utilization. Blocking occurs when the allocation of a given series of slots prevents the allocation of another series due to capacity constraints even though the days of the two requests do no coincide. In this paper we investigate blocking mitigation strategies. We introduce a model and solution framework that minimises blocking while maintaining a desirable level of schedule regularity. We also investigate a strategy that reduces the effect of blocking by changing parametrically the length of the period defining a series a slots. We test both strategies under hierarchical and holistic slot allocation policies using real slot request data from a congested airport. We compare the two strategies in terms of their effect on slot scheduling efficiency and schedule regularity, and we provide slot allocation policy recommendations.},
  archive      = {J_EJOR},
  author       = {Jamie Fairbrother and Konstantinos G. Zografos},
  doi          = {10.1016/j.ejor.2020.10.003},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {961-982},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Optimal scheduling of slots with season segmentation},
  volume       = {291},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Integrated planning for electric commercial vehicle fleets:
A case study for retail mid-haul logistics networks. <em>EJOR</em>,
<em>291</em>(3), 944–960. (<a
href="https://doi.org/10.1016/j.ejor.2020.09.054">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electric commercial vehicles can contribute significantly to sustainable transportation. However, they are still perceived as being less economically viable than internal combustion engine vehicles. To this end, we analyze the deployment of electric commercial vehicles in retail mid-haul logistics fleets for current and future technology scenarios. We develop a novel assessment methodology that combines total cost of ownership calculations with a rich location-routing model. We consider integrated strategic network design and operational routing decisions over a multi-period time horizon, accounting for mixed fleets of electric and conventional vehicles and battery degradation. To solve this problem, we develop a novel matheuristic that embeds a state-of-the-art metaheuristic to take operational routing decisions. With this framework, we analyze a possible transition towards electrified logistics fleets. Starting with a real-world case, we perform sensitivity analyses based on a technology roadmap and further network structures. We discuss cost structures, the time-dependent nature of investment decisions, operational characteristics, and potential emissions savings. We show that in certain cases an electrification of mid-haul logistics fleets is operationally feasible, economically viable, and provides environmental advantages.},
  archive      = {J_EJOR},
  author       = {Maximilian Schiffer and Patrick S. Klein and Gilbert Laporte and Grit Walther},
  doi          = {10.1016/j.ejor.2020.09.054},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {944-960},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Integrated planning for electric commercial vehicle fleets: A case study for retail mid-haul logistics networks},
  volume       = {291},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Decomposition and shortest path problem formulation for
solving the hydro unit commitment and scheduling in a hydro valley.
<em>EJOR</em>, <em>291</em>(3), 935–943. (<a
href="https://doi.org/10.1016/j.ejor.2020.12.029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we tackle the hydro unit commitment problem and scheduling in a hydro valley. We first decompose the problem into several simpler subproblems, one for each reservoir/plant. Then, we model each of them as an optimization problem on graphs with or without resource constraints. We compare our method with a commercial solver for mixed integer linear programming, run on a formulation of the problem and show promising results.},
  archive      = {J_EJOR},
  author       = {Wim van Ackooij and Claudia D’Ambrosio and Dimitri Thomopulos and Renan Spencer Trindade},
  doi          = {10.1016/j.ejor.2020.12.029},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {935-943},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Decomposition and shortest path problem formulation for solving the hydro unit commitment and scheduling in a hydro valley},
  volume       = {291},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Operational research: A multidisciplinary approach for the
management of infectious disease in a global context. <em>EJOR</em>,
<em>291</em>(3), 929–934. (<a
href="https://doi.org/10.1016/j.ejor.2020.07.037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Infectious diseases, both established and emerging, impose a significant burden globally. Successful management of infectious diseases requires considerable effort and a multidisciplinary approach to tackle the complex web of interconnected biological, public health and economic systems. Through a wide range of problem-solving techniques and computational methods, operational research can strengthen health systems and support decision-making at all levels of disease control. From improved understanding of disease biology, intervention planning and implementation, assessing economic feasibility of new strategies, identifying opportunities for cost reductions in routine processes, and informing health policy, this paper highlights areas of opportunity for operational research to contribute to effective and efficient infectious disease management and improved health outcomes.},
  archive      = {J_EJOR},
  author       = {Sheetal Prakash Silal and Modelling and Simulation Hub, Africa (MASHA)},
  doi          = {10.1016/j.ejor.2020.07.037},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {929-934},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Operational research: A multidisciplinary approach for the management of infectious disease in a global context},
  volume       = {291},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A distributionally robust analysis of the program evaluation
and review technique. <em>EJOR</em>, <em>291</em>(3), 918–928. (<a
href="https://doi.org/10.1016/j.ejor.2020.09.027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditionally, stochastic project planning problems are modeled using the Program Evaluation and Review Technique (PERT). PERT is an attractive technique that is commonly used in practice as it requires specification of only a few characteristics of the activities’ duration. Moreover, its computational burden is extremely low. Over the years, four main disadvantages of PERT have been voiced and much research has been devoted to analyzing them. The effect of the beta distribution and corresponding variance PERT assumes is investigated in numerous studies, through analyzing the results for a variety of other distributions. In this paper, we propose a more general method of analyzing PERT’s sensitivity to its assumptions regarding the beta distribution. In particular, we do not assume a singular distribution for the activity duration, but instead assume this distribution to only be partially specified by its support, mean and possibly its mean absolute deviation. The exact worst- and best-case expected project durations over this set of distributions can be calculated through results from distributionally robust optimization on the worst- and best-case distributions themselves. A numerical study of project planning instances from PSPLIB shows that the effect of PERT’s assumption regarding an underlying beta distribution is limited. Furthermore, we find that the added value of knowing the exact mean absolute deviation is also modest.},
  archive      = {J_EJOR},
  author       = {Ernst Roos and Dick den Hertog},
  doi          = {10.1016/j.ejor.2020.09.027},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {918-928},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A distributionally robust analysis of the program evaluation and review technique},
  volume       = {291},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The responsibility of social media in times of societal and
political manipulation. <em>EJOR</em>, <em>291</em>(3), 906–917. (<a
href="https://doi.org/10.1016/j.ejor.2020.09.020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The way electorates were influenced to vote for the Brexit referendum, and in presidential elections both in Brazil and the USA, has accelerated a debate about whether and how machine learning techniques can influence citizens’ decisions. The access to balanced information is endangered if digital political manipulation can influence voters. The techniques of profiling and targeting on social media platforms can be used for advertising as well as for propaganda: Through tracking of a person&#39;s online behaviour, algorithms of social media platforms can create profiles of users. These can be used for the provision of recommendations or pieces of information to specific target groups. As a result, propaganda and disinformation can influence the opinions and (election) decisions of voters much more powerfully than previously. In order to counter disinformation and societal polarization, the paper proposes a responsibility-based approach for social media platforms in diverse political contexts. Based on the implementation requirements of the “Ethics Guidelines for Trustworthy Artificial Intelligence” of the European Commission, the ethical principles will be operationalized, as far as they are directly relevant for the safeguarding of democratic societies. The resulting suggestions show how the social media platform providers can minimize risks for societies through responsible action in the fields of human rights, education and transparency of algorithmic decisions.},
  archive      = {J_EJOR},
  author       = {Ulrike Reisach},
  doi          = {10.1016/j.ejor.2020.09.020},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {906-917},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {The responsibility of social media in times of societal and political manipulation},
  volume       = {291},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). International human migration networks under regulations.
<em>EJOR</em>, <em>291</em>(3), 894–905. (<a
href="https://doi.org/10.1016/j.ejor.2020.04.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {International human migration has transformed economies and societies. The new millennium, with climate change and its impacts, and increasing conflicts and displacements, has experienced a great increase in international migrants, with associated challenges faced by governments. In this paper, we advance the modeling, analysis, and solution of international human migration problems by developing a network model with regulations. The formalism uses the theory of variational inequalities, coupled with Lagrange analysis, in order to gain insights as to the impacts of the regulations on utilities of multiple classes of migrants, and on the equilibrium flows. Our results add to the literature on operations research for societal impact, inspired by the real world.},
  archive      = {J_EJOR},
  author       = {Anna Nagurney and Patrizia Daniele},
  doi          = {10.1016/j.ejor.2020.04.008},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {894-905},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {International human migration networks under regulations},
  volume       = {291},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An anytime tree search algorithm for the 2018 ROADEF/EURO
challenge glass cutting problem. <em>EJOR</em>, <em>291</em>(3),
883–893. (<a href="https://doi.org/10.1016/j.ejor.2020.10.050">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we present the anytime tree search algorithm we designed for the 2018 ROADEF/EURO challenge glass cutting problem proposed by the French company Saint-Gobain. The resulting program was ranked first among 64 participants. Its key components are: a new search algorithm called Iterative Memory Bounded A* (IMBA*) with guide functions, a symmetry breaking strategy, and a pseudo-dominance rule. We perform a comprehensive study of these components showing that each of them contributes to the algorithm global performances. In addition, we designed a second tree search algorithm fully based on the pseudo-dominance rule and dedicated to some of the challenge instances with strong precedence constraints. On these instances, it finds the best-known solutions very quickly.},
  archive      = {J_EJOR},
  author       = {Luc Libralesso and Florian Fontan},
  doi          = {10.1016/j.ejor.2020.10.050},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {883-893},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {An anytime tree search algorithm for the 2018 ROADEF/EURO challenge glass cutting problem},
  volume       = {291},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Polynomial-size formulations and relaxations for the
quadratic multiple knapsack problem. <em>EJOR</em>, <em>291</em>(3),
871–882. (<a href="https://doi.org/10.1016/j.ejor.2020.10.047">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Quadratic Multiple Knapsack Problem generalizes, simultaneously, two well-known combinatorial optimization problems that have been intensively studied in the literature: the (single) Quadratic Knapsack Problem and the Multiple Knapsack Problem. The only exact algorithm for its solution uses a formulation based on an exponential-size number of variables, that is solved via a Branch-and-Price algorithm. This work studies polynomial-size formulations and upper bounds. We derive linear models from classical reformulations of 0-1 quadratic programs and analyze theoretical properties and dominances among them. We define surrogate and Lagrangian relaxations, and we compare the effectiveness of the Lagrangian relaxation when applied to a quadratic formulation and to a Level 1 reformulation linearization that leads to a decomposable structure. The proposed methods are evaluated through extensive computational experiments.},
  archive      = {J_EJOR},
  author       = {Laura Galli and Silvano Martello and Carlos Rey and Paolo Toth},
  doi          = {10.1016/j.ejor.2020.10.047},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {871-882},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Polynomial-size formulations and relaxations for the quadratic multiple knapsack problem},
  volume       = {291},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). On the optimized design of next-generation wind farms.
<em>EJOR</em>, <em>291</em>(3), 862–870. (<a
href="https://doi.org/10.1016/j.ejor.2020.10.048">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A transformation from fossil fuels to renewable energy has been ongoing in recent years, driven by growing environmental and sustainability demands from customers and society. An increased use of renewable sources can, in particular, help during climate change, which is a very sensitive topic right now. Because demand for green energy is increasing, while competition is also growing, innovation and optimization are of key importance in this business. In particular, because the offshore wind energy market is based on an auction system: the company that can construct and operate the farm with the lowest subsidies will win the auction and capitalize on its investment. It is therefore extremely important to both minimize costs and increase profits at the design phase of new farms. In this paper we will illustrate how Operational Research techniques can help companies be more competitive on the market. To be specific, we address two of the main design challenges arising in the design of new offshore wind farms, the optimal allocation of wind turbines (to minimize interference between them and position-related costs) and their electrical interconnection. We show that a synergic use of mixed integer programming models and heuristic methods in the so-called matheuristic framework can be used to solve both problems efficiently. The optimization tools that we will describe have been used also for the design of Hollande Kust Zuid, the first offshore wind farm in the world to be constructed subsidy-free. We report results on a number of real instances, showing the impact of these techniques in decreasing costs and increasing profitability, with average gains of more than € 10 M for each wind farm.},
  archive      = {J_EJOR},
  author       = {Martina Fischetti},
  doi          = {10.1016/j.ejor.2020.10.048},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {862-870},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {On the optimized design of next-generation wind farms},
  volume       = {291},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Coordinating resources in stackelberg security games.
<em>EJOR</em>, <em>291</em>(3), 846–861. (<a
href="https://doi.org/10.1016/j.ejor.2019.11.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work we formulate a Stackelberg Security Game that coordinates resources in a border patrol problem. In this security domain, resources from different precincts have to be paired to conduct patrols in the border due to logistic constraints. Given this structure, models that enumerate the pure defender strategies scale poorly. We describe the set of mixed strategies using a polynomial number of variables but exponentially many constraints that come from the matching polytope. We then include this description in a mixed integer formulation to compute the Strong Stackelberg Equilibrium efficiently with a branch and cut scheme. Since the optimal patrol solution is a probability distribution over the set of exponential size, we also introduce an efficient sampling method that can be used to deploy the security resources every shift. Our computational results evaluate the efficiency of the branch and cut scheme developed and the accuracy of the sampling method.},
  archive      = {J_EJOR},
  author       = {Víctor Bucarey L. and Carlos Casorrán and Martine Labbé and Fernando Ordoñez and Oscar Figueroa},
  doi          = {10.1016/j.ejor.2019.11.002},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {846-861},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Coordinating resources in stackelberg security games},
  volume       = {291},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An exact method for assortment optimization under the nested
logit model. <em>EJOR</em>, <em>291</em>(3), 830–845. (<a
href="https://doi.org/10.1016/j.ejor.2020.12.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the problem of finding an optimal assortment of products maximizing the expected revenue, in which customer preferences are modeled using a nested logit choice model. This problem is known to be polynomially solvable in a specific case and NP-hard otherwise, with only approximation algorithms existing in the literature. We provide an exact general method that embeds a tailored Branch-and-Bound algorithm into a fractional programming framework. In contrast to the existing literature, in which assumptions are imposed on either the structure of nests or the combination and characteristics of products, no assumptions on the input data are imposed. Although our approach is not polynomial in input size, it can solve the most general problem setting for large-size instances. We show that the fractional programming scheme’s parameterized subproblem, a highly non-linear binary optimization problem, is decomposable by nests, which is the primary advantage of the approach. To solve the subproblem for each nest, we propose a two-stage approach. In the first stage, we fix a large set of variables based on the single-nest subproblem’s newly-derived structural properties. This can significantly reduce the problem size. In the second stage, we design a tailored Branch-and-Bound algorithm with problem-specific upper bounds. Numerical results show that the approach is able to solve assortment instances with five nests and with up to 5000 products per nest. The most challenging instances for our approach are those with a mix of nests’ dissimilarity parameters, where some of them are smaller than one and others are greater than one.},
  archive      = {J_EJOR},
  author       = {Laurent Alfandari and Alborz Hassanzadeh and Ivana Ljubić},
  doi          = {10.1016/j.ejor.2020.12.007},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {830-845},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {An exact method for assortment optimization under the nested logit model},
  volume       = {291},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A review of transport market modeling using game-theoretic
principles. <em>EJOR</em>, <em>291</em>(3), 808–829. (<a
href="https://doi.org/10.1016/j.ejor.2020.11.020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Transport markets involve interactions between multiple groups of decision-makers, hence they are good candidates to be analyzed through the prism of game theory. The many models and algorithms published to date tend to reflect different academic disciplines, including operations research, economics and engineering approaches. Models published in the operations research oriented journals often involve large network components in order to provide relatively specific insights, building on Stackelberg, Wardrop and traffic assignment formulations. Game-theoretic models published in economics journals are frequently conceptual with stylized assumptions, such as Cournot, Bertrand and Hotelling, all of which have been applied to transportation markets. We present the more common models and highlight the differences in the equilibria outcomes drawing from the choice of model and beliefs of the players in the market. We discuss the most widely applied algorithms and formulations utilized to solve network-based transport markets. Finally, we review the published literature with real-world applications and discuss potential new areas yet to be explored substantially, including the analysis of multi-modal markets involving both competition and cooperation across transport modes.},
  archive      = {J_EJOR},
  author       = {Nicole Adler and Amir Brudner and Stef Proost},
  doi          = {10.1016/j.ejor.2020.11.020},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {808-829},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A review of transport market modeling using game-theoretic principles},
  volume       = {291},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Introduction to special issue. <em>EJOR</em>,
<em>291</em>(3), 807. (<a
href="https://doi.org/10.1016/j.ejor.2021.02.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_EJOR},
  author       = {Luis Gouveia and Seán McGarraghy and Cathal MacSwiney Brugha},
  doi          = {10.1016/j.ejor.2021.02.011},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {807},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Introduction to special issue},
  volume       = {291},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Combining multiple criteria analysis, mathematical
programming and monte carlo simulation to tackle uncertainty in research
and development project portfolio selection: A case study from greece.
<em>EJOR</em>, <em>291</em>(2), 794–806. (<a
href="https://doi.org/10.1016/j.ejor.2020.09.051">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Research and Development (R&amp;D) is a substantial activity in the modern economy of knowledge and therefore funding R&amp;D activities is a challenging task for private and public institutions. The difficulty in evaluation of R&amp;D projects is mainly the inherent uncertainty that has to be dealt with. In addition, when we have funding programs, various policy constraints for the allocation of funds must be also taken into account. In this paper we propose an R&amp;D project portfolio selection method that deals with the inherent uncertainty of R&amp;D project evaluation. Using decision rounds with multicriteria analysis, mathematical programming and Monte Carlo simulation in the framework of the Iterative Trichotomic Approach (ITA), we manage to tackle large problems. The method is applied in a case study from Greece with 2437 project proposals from the funding action “Research-Create-Innovate” with European and National resources. Groups of experts evaluate the projects in three criteria and complex policy constraints (geographical, sectoral etc.) are also applied. The iterative nature of ITA allows for gradually converging to the final portfolio of R&amp;D projects. The results provide information not only about the acceptance or not of an R&amp;D project to the final portfolio, but also deal with the main source of uncertainty which is the experts’ evaluation, providing a degree of certainty for the selected and rejected projects.},
  archive      = {J_EJOR},
  author       = {George Mavrotas and Evangelos Makryvelios},
  doi          = {10.1016/j.ejor.2020.09.051},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {794-806},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Combining multiple criteria analysis, mathematical programming and monte carlo simulation to tackle uncertainty in research and development project portfolio selection: A case study from greece},
  volume       = {291},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The price of multiobjective robustness: Analyzing solution
sets to uncertain multiobjective problems. <em>EJOR</em>,
<em>291</em>(2), 782–793. (<a
href="https://doi.org/10.1016/j.ejor.2020.09.045">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Defining and finding robust efficient solutions to uncertain multiobjective optimization problems has been an issue of growing interest recently. Different concepts have been published defining what a “robust efficient” solution is. Each of these concepts leads to a different set of solutions, but it is difficult to visualize and understand the differences between these sets. In this paper we develop an approach for comparing such sets of robust efficient solutions, namely we analyze their outcomes under the nominal scenario and in the worst case using the upper set-less order from set-valued optimization. Analyzing the set of nominal efficient solutions, the set of minmax robust efficient solutions and different sets of lightly robust efficient solutions gives insight into robustness and nominal objective function values of these sets of solutions. Among others we can formally prove that lightly robust efficient solutions are good compromises between nominal efficient solutions and minmax robust efficient solutions. In addition, we also propose a measure to quantify the price of robustness of a single solution. Based on the measure, we propose two strategies which can be used to support a decision maker to find solutions to a multiobjective optimization problem under uncertainty. All our results are illustrated by examples.},
  archive      = {J_EJOR},
  author       = {Anita Schöbel and Yue Zhou-Kangas},
  doi          = {10.1016/j.ejor.2020.09.045},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {782-793},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {The price of multiobjective robustness: Analyzing solution sets to uncertain multiobjective problems},
  volume       = {291},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Nested dynamic network data envelopment analysis models with
infinitely many decision making units for portfolio evaluation.
<em>EJOR</em>, <em>291</em>(2), 766–781. (<a
href="https://doi.org/10.1016/j.ejor.2020.09.044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Portfolio performance evaluation is a major data envelopment analysis (DEA) application in the finance field. Most proposed DEA approaches focus on single-period portfolio performance assessment based on aggregated historical data. However, such an evaluation setting may result in the loss of valuable information in past individual time periods, and violate real-world portfolio managers’ and investors’ decision making, which generally involves multiple time periods. Furthermore, to our knowledge, all proposed DEA approaches treat the financial assets comprising a portfolio as a “black box”: thus there is no information about their individual performance. Moreover, ideal portfolio evaluation models should enable the target portfolio to compare with all possible portfolios, i.e., enabling full diversification of portfolios across all financial assets. Hence, this research aims at developing nested dynamic network DEA models, an additive model being nested within a slacks-based measure (SBM) DEA model, that explicitly utilizes the information in each individual time period to fully and simultaneously measure the multi-period efficiency of a portfolio and its comprised financial assets. The proposed nested dynamic network DEA models, referred to as NDN DEA models, are linear programs with conditional value-at-risk (CVaR) constraints, and infinitely many decision making units (DMUs). In conducting the empirical study, this research applies the NDN DEA models to a real-world case study, in which Markov chain Monte Carlo Bayesian algorithms are used to obtain future performance forecasts in today&#39;s highly volatile investment environments.},
  archive      = {J_EJOR},
  author       = {Tsung-Sheng Chang and Kaoru Tone and Chen-Hui Wu},
  doi          = {10.1016/j.ejor.2020.09.044},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {766-781},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Nested dynamic network data envelopment analysis models with infinitely many decision making units for portfolio evaluation},
  volume       = {291},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Group decisions from individual rankings: The
borda–condorcet rule. <em>EJOR</em>, <em>291</em>(2), 757–765. (<a
href="https://doi.org/10.1016/j.ejor.2020.09.043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents an evaluation protocol that transforms a collection of rankings, defined over a set of alternatives, into a complete, transitive, and cardinal assessment. It combines the ideas of Borda and Condorcet by computing the support that each alternative receives on average when confronted with any other. The protocol evaluates those alternatives in terms of pairwise comparisons but weighs the outcomes differently depending on how each alternative fares with respect to the others. The evaluation appears as the stable distribution of an iterative process in which each alternative competes randomly with any other, and results in a vector of positive numbers that tells us the relative support of the different options. We show that this protocol does not require linear orderings and can also be applied in the presence of incomplete rankings and when dealing with several issues simultaneously.},
  archive      = {J_EJOR},
  author       = {Carmen Herrero and Antonio Villar},
  doi          = {10.1016/j.ejor.2020.09.043},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {757-765},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Group decisions from individual rankings: The Borda–Condorcet rule},
  volume       = {291},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Pairwise comparison tables within the deck of cards method
in multiple criteria decision aiding. <em>EJOR</em>, <em>291</em>(2),
738–756. (<a href="https://doi.org/10.1016/j.ejor.2020.09.036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper deals with an improved version of the deck of cards method to render the construction of ratio and interval scales more “accurate” compared to the ones built in the original version. The improvement comes from the fact that we can account for a richer and finer preference information provided by the decision-maker, which permits a more accurate modeling of the strength of preference between different levels of a scale. Instead of considering only the number of blank cards between consecutive positions in the ranking of objects, such as criteria and scale levels, we consider also the number of blank cards between not consecutive positions in the ranking. This information is collected in a pairwise comparison table that is not necessarily built with precise values. We can consider imprecise information provided in the form of intervals and missing values. Since the provided information is not necessarily consistent, we propose also some procedures to help the decision-maker to make consistent her evaluations in a co-constructive way interacting with an analyst and reflecting and revising her judgments. A didactic example will illustrate the application of the method.},
  archive      = {J_EJOR},
  author       = {S. Corrente and J.R. Figueira and S. Greco},
  doi          = {10.1016/j.ejor.2020.09.036},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {738-756},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Pairwise comparison tables within the deck of cards method in multiple criteria decision aiding},
  volume       = {291},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Optimal postponement contracting decisions in crowdsourced
manufacturing: A three-level game-theoretic model for product family
architecting considering subcontracting. <em>EJOR</em>, <em>291</em>(2),
722–737. (<a href="https://doi.org/10.1016/j.ejor.2020.09.049">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Crowdsourced manufacturing enables companies to outsource and share manufacturing resources based on demand and capacity across the value chain. A postponement strategy is well recognized as an effective means to deal with supply chain risks and uncertainties of producing customized products. However, coordinated decision-making among product design, postponement contracting and subcontracting is a challenging problem area that requires innovative modeling and decision support. This study develops a model that emphasizes interactive decisions within a three-level non-cooperative game that determines the optimal solutions for a single manufacturer, multiple distributors, and multiple subcontractors by maximizing their net profits. This study formulates a postponement contracting with subcontracting (PCS) problem for product family architecting to interact with postponement contracting and subcontracting decisions based on optimal planning of crowdsourced manufacturing activities. The PCS problem differs from traditional postponement design models that assume a (fixed) product architecture is given at the outset. In this study, interaction among different stakeholders is modeled as a non-linear, mixed-integer, three-level game-theoretic model based on the Stackelberg game theory. A novel virtual postponement structure is introduced to concretize optimization of the PCS problem and to justify which product module(s) should be postponed. Analytical solutions are developed incorporating a nested genetic algorithm. A practical case study of postponement contracting decisions in an electric vehicle company is reported to verify the feasibility and potential of the proposed approach for product family architecting. The optimal product family design, the types of postponed product modules, some parts in the postponed product modules that need to be further subcontracted, and other decision results are determined simultaneously in the case study. The sensitivity analyses on the proposed postponement cost and demand parameters indicate that the changes of their values greatly influence the decision makers’ net profit, and the net profit situation of each decision maker in different regions is obtained by the sensitivity analysis of the union of the two parameters. Thus, the PCS problem for product family architecting in crowdsourced manufacturing provides a more complete solution for the current implementation of the postponement strategy, and our proposed three-level game-theoretic model can handle well the coordination among the PCS problem.},
  archive      = {J_EJOR},
  author       = {Jun Wu and Gang Du and Roger J. Jiao},
  doi          = {10.1016/j.ejor.2020.09.049},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {722-737},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Optimal postponement contracting decisions in crowdsourced manufacturing: A three-level game-theoretic model for product family architecting considering subcontracting},
  volume       = {291},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The beauty of dutch: Bidding behavior in combinatorial
first-price procurement auctions. <em>EJOR</em>, <em>291</em>(2),
711–721. (<a href="https://doi.org/10.1016/j.ejor.2020.09.048">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ex-post split-award auctions are a frequently used form of combinatorial auction mechanism in practice. The procurement quantity is split into several shares and suppliers can submit bids on separate shares as well as on the entire quantity. Markets with diseconomies of scale are wide-spread, but strategically challenging. In a game-theoretical equilibrium analysis, Kokott et al. (2019) have recently shown that in contrast to single-object auctions, there is no strategic equivalence between first-price sealed-bid (FPSB) and Dutch combinatorial auctions. The FPSB auctions are characterized by efficient and inefficient equilibria while the Dutch auctions only possess efficient equilibria. We report the results of extensive laboratory experiments and show that the theory explains the bid data surprisingly well. Importantly, a compound Dutch auction format weakly outperforms the wide-spread combinatorial first-price sealed-bid auction in efficiency and total procurement costs. The results provide guidance for procurement managers in the field.},
  archive      = {J_EJOR},
  author       = {Per Paulsen and Martin Bichler and Gian-Marco Kokott},
  doi          = {10.1016/j.ejor.2020.09.048},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {711-721},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {The beauty of dutch: Bidding behavior in combinatorial first-price procurement auctions},
  volume       = {291},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Forecasting swiss exports using bayesian forecast
reconciliation. <em>EJOR</em>, <em>291</em>(2), 693–710. (<a
href="https://doi.org/10.1016/j.ejor.2020.09.046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a novel forecast reconciliation framework using Bayesian state-space methods. It allows for the joint reconciliation at all forecast horizons and uses predictive distributions rather than past variation of forecast errors. Informative priors are used to assign weights to specific predictions, which makes it possible to reconcile forecasts such that they accommodate specific judgmental predictions or managerial decisions. The reconciled forecasts adhere to hierarchical constraints, which facilitates communication and supports aligned decision-making at all levels of complex hierarchical structures. An extensive forecasting study is conducted on a large collection of 13,118 time series that measure Swiss merchandise exports, grouped hierarchically by export destination and product category. We find strong evidence that in addition to producing coherent forecasts, reconciliation also leads to substantial improvements in forecast accuracy. The use of state-space methods is particularly promising for optimal decision-making under conditions with increased model uncertainty and data volatility.},
  archive      = {J_EJOR},
  author       = {Florian Eckert and Rob J. Hyndman and Anastasios Panagiotelis},
  doi          = {10.1016/j.ejor.2020.09.046},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {693-710},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Forecasting swiss exports using bayesian forecast reconciliation},
  volume       = {291},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Using intellectual property agreements in the presence of
supplier and third-party copycatting. <em>EJOR</em>, <em>291</em>(2),
680–692. (<a href="https://doi.org/10.1016/j.ejor.2020.09.041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When a manufacturer outsources the production of a product, it distributes its intellectual property (IP) into a supply chain that it may not be able to fully control. An IP agreement between a manufacturer and its suppliers is a popular solution to address the challenge of supplier-copycatting. The goal of this paper is to examine the impact of copycatting, from both the supplier and third-party firms, and the effectiveness of an IP agreement. Specifically, we use a game-theoretic approach to examine a system where a manufacturer outsources to a supplier. The supplier and a third-party firm decide whether or not to enter the market with copycat products while the manufacturer selects the level of marketing investment. The manufacturer can reduce the threat of supplier-copycatting by signing an IP agreement. However, we find that the manufacturer can be worse off from signing an IP agreement with its supplier, even if the IP agreement is costless and perfectly enforceable. We show that a manufacturer can deter copycat products through vertical integration and IP agreements and we outline the instances where each method is preferred. Furthermore, we find that the manufacturer may choose not to invest in quality improvements as a copycat deterrence strategy. We show that the supplier can benefit from the manufacturer&#39;s decision to sign an IP agreement and that the supplier and the consumers can benefit from IP regulations against copycat products. Our paper demonstrates the strengths and limitations of various copycat deterrence strategies when a supplier and third-party may produce copycat products.},
  archive      = {J_EJOR},
  author       = {Salar Ghamat and Hubert Pun and Greg Critchley and Pengwen Hou},
  doi          = {10.1016/j.ejor.2020.09.041},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {680-692},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Using intellectual property agreements in the presence of supplier and third-party copycatting},
  volume       = {291},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An enhanced branch-and-bound algorithm for bilevel integer
linear programming. <em>EJOR</em>, <em>291</em>(2), 661–679. (<a
href="https://doi.org/10.1016/j.ejor.2020.10.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bilevel integer linear programming (BILP) problems have been studied for decades. Many exact algorithms have been proposed in recent years for small- or medium-sized instances. However, few of these algorithms were shown to be efficient on large-sized instances. In this paper, we present an enhanced branch-and-bound algorithm for a class of BILP problems, which can discard a subspace from the search space in each iteration larger than that in a benchmark branch-and-bound algorithm. The corresponding enhanced branching rule can efficiently slow down the creation of new node problems so as to significantly reduce the computation time. Our scheme may be suboptimal if the lower-level problem is not unique optimal as the enhanced branching rule may discard bilevel feasible solutions that may turn out to be optimal to the bilevel programming. We present computational studies to evaluate the algorithm speedup and solution quality of our algorithm, compared with state-of-the-art algorithms from the literature on a large testbed of general BILP instances, some of which are still unsolved. The computational results show that our enhanced branching rule can achieve significant speedup on the benchmark branching rule with satisfying solution quality. In particular, our algorithm shows superior performance on large-sized BILP instances with a relatively complex lower-level problem.},
  archive      = {J_EJOR},
  author       = {Shaonan Liu and Mingzheng Wang and Nan Kong and Xiangpei Hu},
  doi          = {10.1016/j.ejor.2020.10.002},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {661-679},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {An enhanced branch-and-bound algorithm for bilevel integer linear programming},
  volume       = {291},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A matheuristic for parallel machine scheduling with tool
replacements. <em>EJOR</em>, <em>291</em>(2), 640–660. (<a
href="https://doi.org/10.1016/j.ejor.2020.09.050">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the problem of scheduling a set of jobs with tool requirements on identical parallel machines in a work center. This problem considers the following characteristics. First, each job may consist of an ordered set of operations due to reentrance to the work center. Moreover, operations have release times and due dates, and the processing of operations requires different tool sets of different sizes. Last, the objective is to minimize both tardiness of operations and tool setup times. Decisions concern the assignment of operations to machines, sequencing of operations, and replacement of tool sets on machines. We propose a mathematical model for the problem and a new matheuristic that combines a genetic algorithm and an integer linear programming formulation to solve industry-size instances. In the matheuristic, we propose two crossover operators which exploit the structure of the problem. We illustrate this approach through real-world case studies. Computational experiments show that our matheuristic outperforms the mathematical model and a practitioner heuristic. We also generate managerial insights by quantifying the potential room for improvement in current practice.},
  archive      = {J_EJOR},
  author       = {Quang-Vinh Dang and Thijs van Diessen and Tugce Martagan and Ivo Adan},
  doi          = {10.1016/j.ejor.2020.09.050},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {640-660},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A matheuristic for parallel machine scheduling with tool replacements},
  volume       = {291},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Single-machine scheduling with release times, deadlines,
setup times, and rejection. <em>EJOR</em>, <em>291</em>(2), 629–639. (<a
href="https://doi.org/10.1016/j.ejor.2020.09.042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Single-machine scheduling where jobs have a penalty for being late or for being rejected altogether is an important (sub)problem in manufacturing, logistics, and satellite scheduling. It is known to be NP-hard in the strong sense, and there is no polynomial-time algorithm that can guarantee a constant-factor approximation (unless P=NP). We provide an exact algorithm that is fixed-parameter tractable in the slack and the maximum number of time windows overlapping at any point in time, i.e., the width . This algorithm has a runtime exponential in these parameters, but quadratic in the number of jobs, even when modeling sequence-dependent setup times. We further provide a fixed-parameter fully-polynomial time approximation scheme (FPTAS) with only this width as a parameter, having a runtime bound that is cubic. Finally, we propose a neighbourhood heuristic similar to the Balas-Simonetti neighbourhood. All algorithms use an efficient representation of the state space inspired by decision diagrams, where partial solutions that are provably dominated are excluded from further consideration. Experimental evidence shows that the exact method significantly outperforms the state-of-the-art on instances where the width is smaller than one third of the number of jobs and finds optimal solutions to previously unsolved instances. The FPTAS is competitive to state-of-the-art heuristics only when the width is significantly smaller, but the neighbourhood heuristic outperforms most other heuristics in runtime or quality.},
  archive      = {J_EJOR},
  author       = {Mathijs de Weerdt and Robert Baart and Lei He},
  doi          = {10.1016/j.ejor.2020.09.042},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {629-639},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Single-machine scheduling with release times, deadlines, setup times, and rejection},
  volume       = {291},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Complexity of finding pareto-efficient allocations of
highest welfare. <em>EJOR</em>, <em>291</em>(2), 614–628. (<a
href="https://doi.org/10.1016/j.ejor.2020.03.018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We allocate objects to agents as exemplified primarily by school choice. Welfare judgments of the object-allocating agency are encoded as edge weights in the acceptability graph. The welfare of an allocation is the sum of its edge weights. We introduce the constrained welfare-maximizing solution , which is the allocation of highest welfare among the Pareto-efficient allocations. We identify conditions under which this solution is easily determined from a computational point of view. For the unrestricted case, we formulate an integer program and find this to be viable in practice as it quickly solves a real-world instance of kindergarten allocation and large-scale simulated instances. Incentives to report preferences truthfully are discussed briefly.},
  archive      = {J_EJOR},
  author       = {Péter Biró and Jens Gudmundsson},
  doi          = {10.1016/j.ejor.2020.03.018},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {614-628},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Complexity of finding pareto-efficient allocations of highest welfare},
  volume       = {291},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Decision analysis for sustainable development: The case of
renewable energy planning under uncertainty. <em>EJOR</em>,
<em>291</em>(2), 601–613. (<a
href="https://doi.org/10.1016/j.ejor.2020.02.037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-Criteria Decision Analysis (MCDA) methods are increasingly used to aid decision-making for sustainable development. However, although uncertainty is present in all decision environments, dealing with incomplete and vague information in decision analysis remains a challenge. Our objective is to simplify the incorporation of uncertainty in the scoring of alternatives in MCDA processes. We present a modified ELimination and Choice Translating REality (ELECTRE) III model, in which the uncertainty in the performance scores is expressed as lower/upper bounds and then added to the model’s discrimination thresholds. Unlike other uncertainty approaches developed in the literature (such as those based on fuzzy set theory), our approach does not require additional knowledge apart from understanding the ELECTRE III model. To test its validity and suitability, we apply it for the evaluation of renewable energy resources for Turkey – hydro, wind, geothermal, solar, and biomass – under five main criteria: technological, technical, economic, environmental, and socio-politic. Our results indicate that wind energy is the best alternative for Turkey, followed by solar energy, which is in line with country’s Vision 2023 energy targets.},
  archive      = {J_EJOR},
  author       = {Fatine Ezbakhe and Agustí Pérez-Foguet},
  doi          = {10.1016/j.ejor.2020.02.037},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {601-613},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Decision analysis for sustainable development: The case of renewable energy planning under uncertainty},
  volume       = {291},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The financial efficiency of small food and drink producers
across selected european union countries using data envelopment
analysis. <em>EJOR</em>, <em>291</em>(2), 586–600. (<a
href="https://doi.org/10.1016/j.ejor.2020.01.066">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There is an increasing awareness about the importance of the role that small food and beverage producers play in the socio-economic development in many countries. However, since they face many specific problems which create obstacles for their existence, small producers should be identified and supported. To properly analyze their position, one should consider multiple criteria within their operational, financial, marketing and strategic activities. This paper analyzes small food and drink producers from selected countries in the European Union and estimates their financial efficiency using raw financial variables instead of financial ratios. The research is based on the data obtained from the Amadeus database for the period from 2011 to 2015. The relative efficiency is determined by using the data envelopment analysis (DEA). The results show that the number of efficient small companies in the sample had varied throughout the analyzed period. The same holds for the number of efficient companies within countries and within the food and drink industry. Approximately 23\% of food producers were relatively efficient, while the share of efficient drink producers increased over time from approximately 20\% to 23\%. Moreover, we detect countries having the greatest percentage of efficient small producers in the sample. The DEA approach identified efficient producers which have better liquidity, efficiency, leverage and profitability and pointed out cash liquidity as the area of inefficiency for the inefficient companies. This analysis provides policy makers with information for developing policies which could improve the strength of small food and drink producers on a country level.},
  archive      = {J_EJOR},
  author       = {Margareta Gardijan Kedžo and Zrinka Lukač},
  doi          = {10.1016/j.ejor.2020.01.066},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {586-600},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {The financial efficiency of small food and drink producers across selected european union countries using data envelopment analysis},
  volume       = {291},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Incorporating preferential weights as a benchmark into a
sequential reference point method. <em>EJOR</em>, <em>291</em>(2),
575–585. (<a href="https://doi.org/10.1016/j.ejor.2020.01.019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In multi-objective optimization models, it is common that the decision maker expresses the relative importance of objectives through a weighting scheme. However, many solving techniques do not assure that the corresponding solution fits the preferential weights. It could be the case that an objective with a very low weight achieves a good value, whereas another with a high weight yields a very poor achievement. In order to overcome the aforementioned drawback, this paper proposes a new resolution method based on the well-known Reference Point Method. The methodology consists in generating a sequence of Reference Point Method models which share the same reference point fixed at the vector of preferential weights. In the iterative process, the projection direction on the Pareto frontier changes in each iteration according to the deviations between the preferential weights and the current normalised objective values. In this way, a sequence of Pareto-efficient solutions is generated which converges towards a solution that best fits the decision maker&#39;s preferential weights. The proposed method is illustrated by means of a numerical example. In order to show its feasibility and usefulness, the methodology is applied to a portfolio selection problem where the corporate sustainability performance of each firm is taken into account.},
  archive      = {J_EJOR},
  author       = {Mariano Jiménez and Amelia Bilbao-Terol and Mar Arenas-Parra},
  doi          = {10.1016/j.ejor.2020.01.019},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {575-585},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Incorporating preferential weights as a benchmark into a sequential reference point method},
  volume       = {291},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Outlier detection and quasi-periodicity optimization
algorithm: Frequency domain based outlier detection (FOD).
<em>EJOR</em>, <em>291</em>(2), 560–574. (<a
href="https://doi.org/10.1016/j.ejor.2020.01.014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Outlier detection is one of the main challenges in the pre-processing stage of data analyses. In this study, we suggest a new non-parametric outlier detection technique which is based on the frequency-domain and Fourier Transform definitions and call it as the frequency-domain based outlier detection (FOD). From simulation results under various distributions and real data applications, we observe that our proposal approach is capable of detecting quasi-periodic outliers in time series data more successfully compared with other commonly used methods like z-score, box-plot and also faster than some specialized methods Grubbs method and autonomous anomaly detection (AAD) method. Therefore, we consider that our proposal approach can be an alternative approach to find quasi-periodic outliers in time series data.},
  archive      = {J_EJOR},
  author       = {Ekin Can Erkuş and Vilda Purutçuoğlu},
  doi          = {10.1016/j.ejor.2020.01.014},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {560-574},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Outlier detection and quasi-periodicity optimization algorithm: Frequency domain based outlier detection (FOD)},
  volume       = {291},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). We need to talk about intermittent demand forecasting.
<em>EJOR</em>, <em>291</em>(2), 549–559. (<a
href="https://doi.org/10.1016/j.ejor.2019.12.046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Operational Research (OR) is the ‘science of better’. People constantly try to get better, in practically all aspects of their personal and professional life, and thus OR is de facto a ubiquitous science. What might however not be that clear, is that the way we improve is driven by the very OR science, and the scientific results that constitute the respective body of literature, theory and practice. Of all the tasks, that can be related to the OR science, the one that more frequently we do, is forecasting. We do constantly try to estimate what is coming next, and we drive our decisions for each and every situation based on these forecasts: from where to put our money to who will be the best surgeon to operate us. Within the broad boundaries of OR, forecasting stands out as the most ubiquitous sub-discipline. In the forecasting literature, a lot of attention has been given to modeling fast-moving time series and building causal models; however, very limited attention has been given to intermittent time series and intermittent demand forecasting. In this research, we advocate for the broader use of intermittent demand forecasting methods for forecasting special events, as a simpler, faster, and robust alternative to more complex non-OR models. Furthermore, in a foresight context, we argue for a novel way of deciding the strategic planning horizon for phenomena prone to appearance of special events.},
  archive      = {J_EJOR},
  author       = {Konstantinos Nikolopoulos},
  doi          = {10.1016/j.ejor.2019.12.046},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {549-559},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {We need to talk about intermittent demand forecasting},
  volume       = {291},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A general property for time aggregation. <em>EJOR</em>,
<em>291</em>(2), 536–548. (<a
href="https://doi.org/10.1016/j.ejor.2019.12.045">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We classify all functions of multivariate stochastic processes having time-series estimates that are independent of data frequency. Such an estimator applied to high-frequency data may be used to infer properties of estimates relating to low-frequency data. Our property encompasses two previously-proposed time-aggregation properties (with limited solutions) as different special cases. Our general time-aggregating functions satisfy a pair of coupled second-order partial differential equations. We derive analytic solutions for arbitrary-dimensional martingales and log-martingales. The time-aggregation property of a time-series model is similar – indeed time-aggregating functions always correspond to point estimators based on expected values – but we do not propose a specific new forecasting model. However, we do derive time-aggregating unbiased and efficient estimators for nth -order moments of log returns, applying these results to problems facing portfolio managers who re-optimise portfolios or hedge their risks at lower frequencies than the frequency at which their risk premia are monitored.},
  archive      = {J_EJOR},
  author       = {Carol Alexander and Johannes Rauch},
  doi          = {10.1016/j.ejor.2019.12.045},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {536-548},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A general property for time aggregation},
  volume       = {291},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Warranty parameters for extended two-dimensional warranties
incorporating consumer preferences. <em>EJOR</em>, <em>291</em>(2),
525–535. (<a href="https://doi.org/10.1016/j.ejor.2019.12.035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Certain products, such as automobiles, typically have warranty policies that incorporate two dimensions, namely time since purchase of the product and usage based on mileage accumulated. If both of these parameters are less than stipulated values in the warranty policy, in case of product failure, the manufacturer replaces or repairs the product free of charge. In many consumer durable goods, while an initial warranty is offered during purchase of the product, options exist to renew the warranty in the event of no product failure during the initial warranty. In this paper we consider such extended warranties in the context of two-dimensional policies. The decision variables in the formulated model are the warranty time and usage in the initial policy, the warranty time and usage in the extended policy, the product price, and the premium to be charged by the manufacturer for extending the warranty. We assume, however, that not all customers will choose to renew the warranty even if the product did not fail during the initial warranty. Customer propensity to renew warranty could be influenced by the unit product price and the customer&#39;s threshold price level, above which the customer is motivated to purchase an extended warranty.},
  archive      = {J_EJOR},
  author       = {Amitava Mitra},
  doi          = {10.1016/j.ejor.2019.12.035},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {525-535},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Warranty parameters for extended two-dimensional warranties incorporating consumer preferences},
  volume       = {291},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Determining concession periods and minimum revenue
guarantees in public-private-partnership agreements. <em>EJOR</em>,
<em>291</em>(2), 512–524. (<a
href="https://doi.org/10.1016/j.ejor.2019.12.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Public–private partnership (PPP) schemes show strong capability in delivering infrastructure projects. One challenge in designing PPP contracts is optimising the length of the concession period and level of the minimum revenue guarantee (MRG) to satisfy both public and private parties’ interests. Existing research excludes interaction between the concession period and MRG, but a method that can determine their values simultaneously is needed. This study fills the research gap by proposing a synthetic measure to determine the values of the concession period and MRG. An imperfect information bargaining model is created to find the equilibrium return rate on investment. To achieve the equilibrium of the bargaining game, the required length of the concession period and level of the MRG are calculated based on Monte Carlo simulation and real option analysis. Project QJ is created as a numerical example to verify the applicability of the proposed method. The outcome shows the proposed determination process identifies the optimal length of the concession period and level of the MRG. The length of the concession period is inversely proportional to the level of the MRG and this correlation is influenced by the probability of achieving the equilibrium return rate on investment. When this probability equals 70\%, an MRG is not required once the concession period exceeds 24 years. The results also show the concession period decision range is sensitive to change in the concession price.},
  archive      = {J_EJOR},
  author       = {Hongyu Jin and Shijing Liu and Jide Sun and Chunlu Liu},
  doi          = {10.1016/j.ejor.2019.12.013},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {512-524},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Determining concession periods and minimum revenue guarantees in public-private-partnership agreements},
  volume       = {291},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Orthant-based variance decomposition in investment
portfolios. <em>EJOR</em>, <em>291</em>(2), 497–511. (<a
href="https://doi.org/10.1016/j.ejor.2019.11.028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A traditional and useful approach in portfolio theory is to consider the total risk of one security partitioned into two components: market risk and specific risk. In this paper, we propose a new variance decomposition based on a four-orthant partitioning of a bivariate normal distribution representing the returns on two stock portfolios. Four Euclidian quadrants around the central mean point are considered with their correspondent truncated distributions. We can consider stock pairs as events in which both stocks rise together, both decline or one rises and the other declines. The question that arises is what the contribution is of each quadrant to the overall mean return. And, what is the contribution of each quadrant to the total variance? We consider the mixture of four truncated bivariate normal distributions, where the weighting coefficients coincide with the quadrant probabilities. Through the law of total variance and the first and second moments of each truncated distribution, the requested decomposition formulas are deduced. These results are validated with straightforward simulations. The equations obtained here show higher variance concentration when considering diagonal quadrants, more than could be expected when compared to the subset probability mass. These results show that pair trading and low variance strategies could be better interpreted with this variance decomposition. Finally, a comparison with principal component theory is carried out showing that greater variance concentration can be found within this orthant scheme.},
  archive      = {J_EJOR},
  author       = {Javier Giner},
  doi          = {10.1016/j.ejor.2019.11.028},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {497-511},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Orthant-based variance decomposition in investment portfolios},
  volume       = {291},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Generalized derivatives of the optimal value of a linear
program with respect to matrix coefficients. <em>EJOR</em>,
<em>291</em>(2), 491–496. (<a
href="https://doi.org/10.1016/j.ejor.2019.11.020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present here a characterization of the Clarke subdifferential of the optimal value function of a linear program as a function of matrix coefficients. We generalize the result of Freund (1985) to the cases where derivatives may not be defined because of the existence of multiple primal or dual solutions.},
  archive      = {J_EJOR},
  author       = {Daniel De Wolf and Yves Smeers},
  doi          = {10.1016/j.ejor.2019.11.020},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {491-496},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Generalized derivatives of the optimal value of a linear program with respect to matrix coefficients},
  volume       = {291},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Integrating risk into estimations of project activities’
time and cost: A stratified approach. <em>EJOR</em>, <em>291</em>(2),
482–490. (<a href="https://doi.org/10.1016/j.ejor.2019.11.018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time and cost estimations of project activities are challenging tasks for project managers and planners. As a result of the high level of risk and uncertainty present during the early stages of projects, the reliability of these estimations during project planning remains poor. This study argues that this reliability can be improved through using the ‘concept of stratification’. This concept considers a set of states and describes a system that receives inputs (associated with outputs), based on which the system transitions from one state to another. This provides a unique structure that is capable of considering uncertainty related to events that may occur during a project. This paper explains how the concept of stratification can be used to compute estimations of the time and cost of activities involved in a project. The method is illustrated with a construction project that has uncertain events. By determining specific activities’ estimated time and cost, the project&#39;s estimated time and cost can also be calculated. Thus, the proposed method increases the reliability of estimations of projects’ completion time and cost.},
  archive      = {J_EJOR},
  author       = {Mehdi Rajabi Asadabadi and Ofer Zwikael},
  doi          = {10.1016/j.ejor.2019.11.018},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {482-490},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Integrating risk into estimations of project activities&#39; time and cost: A stratified approach},
  volume       = {291},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Attacker–defender model against quantal response adversaries
for cyber security in logistics management: An introductory study.
<em>EJOR</em>, <em>291</em>(2), 471–481. (<a
href="https://doi.org/10.1016/j.ejor.2019.10.019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Interest in cyber security in logistics and supply chain management has grown, but this has not been matched by academic research. Increasingly, the logistics industry is implementing the Internet-of-Things (IoT), namely sensors and actuators, to collect data, process orders and deliver materials and/or products. This automation reduces human errors in processing orders and enhances the efficiency of order deliveries. However, this can be interrupted by attacks from cyberspace, especially from the Internet. In this paper, we propose a novel attacker–defender model against a quantal response (QR) adversary to protect critical assets by considering the defending budget and the asset dependency. Each asset in the solution is represented by its security level indicating its desirability for being protected. Due to the non-convexity of our model, we propose a Method of Successive Average heuristic with randomised initial conditions (MSAR) to obtain a promising solution.},
  archive      = {J_EJOR},
  author       = {Cheung Kam-Fung and Michael G.H. Bell},
  doi          = {10.1016/j.ejor.2019.10.019},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {471-481},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Attacker–defender model against quantal response adversaries for cyber security in logistics management: An introductory study},
  volume       = {291},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A robust optimization approach for the multi-mode
resource-constrained project scheduling problem. <em>EJOR</em>,
<em>291</em>(2), 457–470. (<a
href="https://doi.org/10.1016/j.ejor.2019.09.052">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper suggests a robust optimization approach for the multi-mode resource-constrained project scheduling problem with uncertain activity durations. The objective is to minimize the worst-case project duration by deciding on activity modes, resource allocations and a schedule baseline. The problem is solved by a Benders decomposition approach with specialized cuts. We consider polyhedral uncertainty sets in which the level of conservatism can be adjusted. Using a computational study in which various problem instances are explored under varying levels of uncertainty, conservatism and several types of duration distributions, we provide insights about the price of robustness and the performance of the approach. The hope is that these insights can guide future multi-mode project scheduling implementations when there is partial information about the distribution of activity durations.},
  archive      = {J_EJOR},
  author       = {Noemie Balouka and Izack Cohen},
  doi          = {10.1016/j.ejor.2019.09.052},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {457-470},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A robust optimization approach for the multi-mode resource-constrained project scheduling problem},
  volume       = {291},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Modelling and optimisation in european kidney exchange
programmes. <em>EJOR</em>, <em>291</em>(2), 447–456. (<a
href="https://doi.org/10.1016/j.ejor.2019.09.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The complex multi-criteria optimisation problems arising in Kidney Exchange Programmes have received considerable attention both in practice and in the scientific literature. Whereas theoretical advancements are well reviewed and synthesised, this is not the case for practice. We present a synthesis of models and methods applied in present European Kidney Exchange Programmes, which is based on detailed descriptions we created for this purpose. Most descriptions address national programmes, yet we also present findings on emerging cross-national programmes. The synthesis provides a systematic and detailed description of the models and methods the programmes use, revealing important commonalities as well as considerable variation among them. Rather than distilling a single best practice from these results, we find that the variation in models and methods arises because of variation in country characteristics, policies, and ethics. The synthesised state of the art may benefit future national and cross-national initiatives and direct future theoretical contributions within and across the boundaries of the Operations Research discipline.},
  archive      = {J_EJOR},
  author       = {Péter Biró and Joris van de Klundert and David Manlove and William Pettersson and Tommy Andersson and Lisa Burnapp and Pavel Chromy and Pablo Delgado and Piotr Dworczak and Bernadette Haase and Aline Hemke and Rachel Johnson and Xenia Klimentova and Dirk Kuypers and Alessandro Nanni Costa and Bart Smeulders and Frits Spieksma and María O. Valentín and Ana Viana},
  doi          = {10.1016/j.ejor.2019.09.006},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {447-456},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Modelling and optimisation in european kidney exchange programmes},
  volume       = {291},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Dynamic robust orlicz premia and haezendonck–goovaerts risk
measures. <em>EJOR</em>, <em>291</em>(2), 438–446. (<a
href="https://doi.org/10.1016/j.ejor.2019.08.049">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we extend to a dynamic setting the robust Orlicz premia and Haezendonck–Goovaerts risk measures introduced in Bellini, Laeven and Rosazza Gianin (2018). We extensively analyze the properties of the resulting dynamic risk measures. Furthermore, we characterize dynamic Orlicz premia that are time-consistent, and establish some relations between the time-consistency properties of dynamic robust Orlicz premia and the corresponding dynamic robust Haezendonck–Goovaerts risk measures.},
  archive      = {J_EJOR},
  author       = {Fabio Bellini and Roger J.A. Laeven and Emanuela Rosazza Gianin},
  doi          = {10.1016/j.ejor.2019.08.049},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {438-446},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Dynamic robust orlicz premia and Haezendonck–Goovaerts risk measures},
  volume       = {291},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A heuristic approach for lactate threshold estimation for
training decision-making: An accessible and easy to use solution for
recreational runners. <em>EJOR</em>, <em>291</em>(2), 427–437. (<a
href="https://doi.org/10.1016/j.ejor.2019.08.023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, a heuristic as operational tool to estimate the lactate threshold and to facilitate its integration into the training process of recreational runners is proposed. To do so, we formalize the principles for the lactate threshold estimation from empirical data and an iterative methodology that enables experience based learning. This strategy arises as a robust and adaptive approach to solve data analysis problems. We compare the results of the heuristic with the most commonly used protocol by making a first quantitative error analysis to show its reliability. Additionally, we provide a computational algorithm so that this quantitative analysis can be easily performed in other lactate threshold protocols. With this work, we have shown that a heuristic (\%60 of endurance running speed reserve ), serves for the same purpose of the most commonly used protocol in recreational runners, but improving its operational limitations of accessibility and consistent use.},
  archive      = {J_EJOR},
  author       = {Urtats Etxegarai and Eva Portillo and Jon Irazusta and Lucien Koefoed and Nikola Kasabov},
  doi          = {10.1016/j.ejor.2019.08.023},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {427-437},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A heuristic approach for lactate threshold estimation for training decision-making: An accessible and easy to use solution for recreational runners},
  volume       = {291},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Extending the fama and french model with a long term memory
factor. <em>EJOR</em>, <em>291</em>(2), 421–426. (<a
href="https://doi.org/10.1016/j.ejor.2019.07.071">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a new long-term memory factor for extending the well-known Fama and French model is proposed and discussed thoroughly. The new long-term memory factor is based on the Hurst exponent and is calculated using the fractal dimension (FD) algorithm. The relevance of the new factor is illustrated using a sample of 1500 largest U.S. companies from different sectors.},
  archive      = {J_EJOR},
  author       = {M.N. López-García and J.E. Trinidad-Segovia and M.A. Sánchez-Granero and I. Pouchkarev},
  doi          = {10.1016/j.ejor.2019.07.071},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {421-426},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Extending the fama and french model with a long term memory factor},
  volume       = {291},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The ubiquitous nature of inventory: Vendor managed
consignment inventory in adverse market conditions. <em>EJOR</em>,
<em>291</em>(2), 411–420. (<a
href="https://doi.org/10.1016/j.ejor.2019.07.070">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inventories are ubiquitous in nature and inventory control is a crucial activity undertaken in the supply chain (SC) by a company’s management. The Vendor Managed Inventory (VMI) contract has become a common technique for supply chain management (SCM) since the 1980’s. In this technique, the decision about how much inventory to hold is made by the vendor. In the paper, we consider VMI with consignment (VMCI). Consignment is a frequently used form of business arrangement, in which the vendor retains the ownership of the inventory and gets paid by the retailer on actual units sold. Under VMCI, decisions are made in two steps. In the first step, the vendor specifies a consignment price and an order quantity with the objective to maximize the vendor’s expected profit. In the second step, the retailer chooses a retail price which maximizes the retailer’s expected profit. The customer demand is assumed to be stochastic, additive and price–sensitive. Additive uncertainty can produce negative demand realizations, which may occur in adverse market conditions. We prove that in this case an optimal and possibly non–unique solution to VMCI exists. We calculate closed–form formulas for optimal quantities for uniformly distributed demand. Finally, we demonstrate our approach through a numerical example and we show that the imposition of a non–negativity constraint can cause a higher vendor’s expected profit.},
  archive      = {J_EJOR},
  author       = {Milena Bieniek},
  doi          = {10.1016/j.ejor.2019.07.070},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {411-420},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {The ubiquitous nature of inventory: Vendor managed consignment inventory in adverse market conditions},
  volume       = {291},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). CISEF: A composite index of social, environmental and
financial performance. <em>EJOR</em>, <em>291</em>(1), 394–409. (<a
href="https://doi.org/10.1016/j.ejor.2020.09.035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a holistic evaluation framework that banks could adopt when screening corporate entities. The framework is based on the development of a composite indicator of social, environmental and financial performance. This integrated view of evaluation is conceptually aligned with ISO standards and empirical proposals of academics and market practitioners in defining inclusive performance. We complement those proposals with a methodological framework that permits incorporation of a plethora of viewpoints in the evaluation process, reflecting the expectations of the various stakeholders in the environment of a bank. We further enhance the evaluation process with analytics of a more detailed hierarchical view of performance, fine-tuning of the evaluation process, and provide implications and suggestions to the senior executive team of a bank’s clients.},
  archive      = {J_EJOR},
  author       = {Chrysovalantis Gaganis and Fotios Pasiouras and Menelaos Tasiou and Constantin Zopounidis},
  doi          = {10.1016/j.ejor.2020.09.035},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {394-409},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {CISEF: A composite index of social, environmental and financial performance},
  volume       = {291},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Prescriptive analytics in public-sector decision-making: A
framework and insights from charging infrastructure planning.
<em>EJOR</em>, <em>291</em>(1), 379–393. (<a
href="https://doi.org/10.1016/j.ejor.2020.09.034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we investigate the challenges public-sector organizations face when seeking to leverage prescriptive analytics and provide insights into the public value such data-driven tools and methods can provide. Using the strategic triangle of value, legitimacy, and operational capacity as a starting point, we derive a framework to assess public-sector prescriptive analytics initiatives, along with six guiding questions that structure the assessment process. We present a case study applying prescriptive analytics to the placement of charge points in urban areas, a critical challenge many municipalities are currently facing in the transition towards electric mobility. Reflecting on the analytics application as well as its development and implementation process through the guiding questions, we derive key lessons for public-sector organizations seeking to apply prescriptive analytics.},
  archive      = {J_EJOR},
  author       = {Tobias Brandt and Sebastian Wagner and Dirk Neumann},
  doi          = {10.1016/j.ejor.2020.09.034},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {379-393},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Prescriptive analytics in public-sector decision-making: A framework and insights from charging infrastructure planning},
  volume       = {291},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Measurement of eco-efficiency and convergence: Evidence from
a non-parametric frontier analysis. <em>EJOR</em>, <em>291</em>(1),
365–378. (<a href="https://doi.org/10.1016/j.ejor.2020.09.024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study applies a nonparametric model to estimate the eco-efficiency across the US states over the period 1990–2017. To capture the environmental damage caused by anthropogenic activities, we utilize one global (CO 2 ) and two local (SO 2 and NO X ) pollutants emitted by power plants to serve as inputs to the eco-efficiency analysis and states’ GDP levels as an output. The paper&#39;s primary contribution is to employ for the first time in the empirical literature a probabilistic frontier analysis (order-m estimators) to exemplify the US regional convergence/divergence patterns on eco-efficiency. The results based on the Phillips and Sul methodology (2007; 2009) indicate divergence for the whole sample. However, at least five regional convergence clubs are formulated dividing the US states into “ champions ” and “ laggards ” according to their eco-efficiency estimates. Moreover, we examine the convergence-divergence hypothesis by employing an alternative nonparametric distributional dynamics approach based on a Markov chain. Although the stochastic kernels uncover the presence of regional clustering among the US territory, they signify the existence of at least two convergence clubs. Our results survive robustness checks under the inclusion of two alternative eco-efficiency indicators, providing significant implications to government officials and policymakers.},
  archive      = {J_EJOR},
  author       = {Konstantinos E. Kounetas and Michael L. Polemis and Nickolaos G. Tzeremes},
  doi          = {10.1016/j.ejor.2020.09.024},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {365-378},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Measurement of eco-efficiency and convergence: Evidence from a non-parametric frontier analysis},
  volume       = {291},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Decision support model for cybersecurity risk planning: A
two-stage stochastic programming framework featuring firms, government,
and attacker. <em>EJOR</em>, <em>291</em>(1), 349–364. (<a
href="https://doi.org/10.1016/j.ejor.2020.09.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the decision-making problem in cybersecurity risk planning concerning resource allocation strategies by government and firms. Aiming to minimize the social costs incurred due to cyberattacks, we consider not only the monetary investment costs but also the deprivation costs due to detection and containment delays. We also consider the effect of positive externalities of the overall cybersecurity investment on an individual firm’s resource allocation attitude. The optimal decision guides the firms on the countermeasure portfolio mix (detection vs. prevention vs. containment) and government intelligence investments while accounting for actions of a strategic attacker and firm budgetary limitations. We accomplish this via a two-stage stochastic programming model. In the first stage, firms decide on prevention and detection investments aided by government intelligence investments that improve detection effectiveness. In the second stage, once the attacker’s actions are realized, firms decide on containment investments after evaluating the cyberattacks. We demonstrate the applicability of our model via a case study. We find that externality can reduce the government’s intelligence investment and that the firm’s detection investment receives priority over containment. We also note that while prevention effectiveness has a decreasing impact on intelligence, it is beneficial to spend more on intelligence given its increasing returns to the reduction of social costs related to cybersecurity.},
  archive      = {J_EJOR},
  author       = {Jomon A. Paul and Minjiao Zhang},
  doi          = {10.1016/j.ejor.2020.09.013},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {349-364},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Decision support model for cybersecurity risk planning: A two-stage stochastic programming framework featuring firms, government, and attacker},
  volume       = {291},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Decision making under uncertain and dependent system rates
in service systems. <em>EJOR</em>, <em>291</em>(1), 335–348. (<a
href="https://doi.org/10.1016/j.ejor.2020.09.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose decision analysis methods for determining the optimal number of agents of a service system where the system rates (arrival, service, and abandonment) are modeled as dependent random variables. In doing so, we take the Bayesian point of view of inference and obtain joint posterior distributions of the system rates. We solve the proposed stochastic staffing decision problem with augmented probability simulation based optimization methods. The novelty of our approach stems from the use of dependent system rates to determine optimal staffing in a constrained optimization setting for stochastic service systems. We demonstrate the implications of ignoring dependence and uncertainty in system rates on simulated data for general service systems, and illustrate the application of the proposed methodology on call center operations.},
  archive      = {J_EJOR},
  author       = {Tahir Ekin and Tevfik Aktekin},
  doi          = {10.1016/j.ejor.2020.09.005},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {335-348},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Decision making under uncertain and dependent system rates in service systems},
  volume       = {291},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Word-of-mouth and estimating demand based on network
structure and epidemic models. <em>EJOR</em>, <em>291</em>(1), 323–334.
(<a href="https://doi.org/10.1016/j.ejor.2020.09.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Word Of Mouth (WOM) is proved to be important in diffusing information to the uninformed people and affecting their buying intentions. In this paper, the social network built upon the trust between the members of a society is considered as the target market, and WOM is treated as a contagious infection whose diffusion depends on the social network’s structure. Accordingly, we construct a framework using Susceptible-Infected-Susceptible (SIS) epidemic model to derive demand functions based on the type of the network, price, average network density, and advertising level. For scale-free and regular (as a benchmark) networks, the demand functions are derived, and then the optimum pricing and advertising policies are obtained, accordingly. It is concluded that in a denser network, price and advertising levels are higher. Furthermore, network-based model shows that price sensitivity of demand is lower (higher) for lower (higher) prices. Moreover, it is concluded that the optimum price in a heterogeneous social network (i.e. with a few members having many links and many members having a few links) is higher than that of a homogeneous network.},
  archive      = {J_EJOR},
  author       = {Mostafa Pazoki and Hamed Samarghandi},
  doi          = {10.1016/j.ejor.2020.09.004},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {323-334},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Word-of-mouth and estimating demand based on network structure and epidemic models},
  volume       = {291},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Inequity aversion in dynamically complex supply chains.
<em>EJOR</em>, <em>291</em>(1), 309–322. (<a
href="https://doi.org/10.1016/j.ejor.2020.09.038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inequity aversion models developed by Fehr and Schmidt (1999) and Bolton and Ockenfels (2000) assume that, in addition to purely selfish subjects, there are subjects who dislike inequitable outcomes. Within the supply chain management literature, these models were used to study fairness concerns. A common limitation in this research area has been the use of rather simple settings, mainly dyadic channels with a single supplier and retailer. Thus, researching social preferences in different channel structures and the idea of multiple-player groups have been suggested as interesting future research areas. In this paper, we present dynamic analyses of the two inequity aversion models and their application in the Beer Distribution Game setting. Our simulation results challenge currently held assumptions about fairness perceptions among supply chain members. We provide some structural explanations for this and suggests future research areas.},
  archive      = {J_EJOR},
  author       = {Ivan Đula and Andreas Größler},
  doi          = {10.1016/j.ejor.2020.09.038},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {309-322},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Inequity aversion in dynamically complex supply chains},
  volume       = {291},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-agent reinforcement learning algorithm to solve a
partially-observable multi-agent problem in disaster response.
<em>EJOR</em>, <em>291</em>(1), 296–308. (<a
href="https://doi.org/10.1016/j.ejor.2020.09.018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Disaster response operations typically involve multiple decision-makers, and each decision-maker needs to make its decisions given only incomplete information on the current situation. To account for these characteristics – decision making by multiple decision-makers with partial observations to achieve a shared objective –, we formulate the decision problem as a decentralized-partially observable Markov decision process (dec-POMDP) model. To tackle a well-known difficulty of optimally solving a dec-POMDP model, multi-agent reinforcement learning (MARL) has been used as a solution technique. However, typical MARL algorithms are not always effective to solve dec-POMDP models. Motivated by evidence in single-agent RL cases, we propose a MARL algorithm augmented by pretraining. Specifically, we use behavioral cloning (BC) as a means to pretrain a neural network. We verify the effectiveness of the proposed method by solving a dec-POMDP model for a decentralized selective patient admission problem. Experimental results of three disaster scenarios show that the proposed method is a viable solution approach to solving dec-POMDP problems and that augmenting MARL with BC for its pretraining seems to offer advantages over plain MARL in terms of solution quality and computation time.},
  archive      = {J_EJOR},
  author       = {Hyun-Rok Lee and Taesik Lee},
  doi          = {10.1016/j.ejor.2020.09.018},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {296-308},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Multi-agent reinforcement learning algorithm to solve a partially-observable multi-agent problem in disaster response},
  volume       = {291},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A strong efficiency measure for CCR/BCC models.
<em>EJOR</em>, <em>291</em>(1), 284–295. (<a
href="https://doi.org/10.1016/j.ejor.2020.09.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Farrell technical efficiency measure computes the maximum proportional reduction that can be operated on inputs without affecting the level of output. In a multi-input and multi-output context, the first mathematical programming based reformulation of this problem is known as CCR/BCC efficiency measures. There are two drawbacks to this measure. First, it does not give value to any inefficiency resulting from the possibility of reducing some inputs and/or increasing some outputs in addition to the maximum proportional reduction in inputs. Second, as a result of the above, it does not unequivocally identify Pareto-Koopmans efficient activities. This article presents a strong efficiency measure similar to CCR/BCC models which overcome these drawbacks. It accounts for all non-zero slacks in inputs and outputs once the proportional reduction path in the inputs has been exhausted. This allows for the correct classification of production units in an efficiency ranking and facilitates the measurement of inefficiency by inputs and outputs, thereby helping to improve business management decision-making. We extend our model to deal with zero and negative input or output values. A numerical example shows the applicability of our approach.},
  archive      = {J_EJOR},
  author       = {David José Cova-Alonso and Juan José Díaz-Hernández and Eduardo Martínez-Budría},
  doi          = {10.1016/j.ejor.2020.09.006},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {284-295},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A strong efficiency measure for CCR/BCC models},
  volume       = {291},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An exact algorithm for the unidirectional quay crane
scheduling problem with vessel stability. <em>EJOR</em>,
<em>291</em>(1), 271–283. (<a
href="https://doi.org/10.1016/j.ejor.2020.09.033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the quay crane scheduling problem (QCSP) with vessel stability constraints. Vessel stability is essential to improve quay crane operations in container terminals, but it significantly complicates the basic QCSP and the corresponding solutions methods. We describe a novel mathematical formulation for the unidirectional QCSP with vessel stability, and we propose an exact algorithm based on logic-based Benders decomposition to solve the problem efficiently. The problem is decomposed into two subproblems, e.g., a task-assignment master problem without vessel stability constraints, and a time-allocation problem, aimed at determining the operation time of each task under the premise of the vessel stability requirements. The proposed algorithm is tested on benchmark instances derived from the literature, and the effectiveness of the proposed model and solution approach is demonstrated.},
  archive      = {J_EJOR},
  author       = {Defeng Sun and Lixin Tang and Roberto Baldacci and Andrew Lim},
  doi          = {10.1016/j.ejor.2020.09.033},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {271-283},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {An exact algorithm for the unidirectional quay crane scheduling problem with vessel stability},
  volume       = {291},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Optimizing voyage charterparty (VCP) arrangement: Laytime
negotiation and operations coordination. <em>EJOR</em>, <em>291</em>(1),
263–270. (<a href="https://doi.org/10.1016/j.ejor.2020.09.032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Voyage charter (VC) is a shipping arrangement between a shipowner and a charterer for the carriage of specific cargo from one port to another port on a per-ton or lump-sum basis. In this paper, we present innovative applications of operational models to optimize voyage charterparty (VCP) arrangement for commercial shipping from the contract negotiation stage to its execution stage. We develop novel models to support decision makings of stakeholders, charterer (he) and shipowner (she), under established admiralty law, considering essential terms such as laytime, demurrage and despatch. Firstly, we consider a risk-neutral charterer’s optimal laytime decision under uncertain berth availability and weather conditions. Following that, we study the impacts of speed adjustment on the related profit of the two parties. We show that under some circumstances, a shipowner can speed up to the extent that the increase in demurrage revenue compensates the extra cost of bunker fuel expenditure. Operations coordination leads to the mutual benefits of stakeholders.},
  archive      = {J_EJOR},
  author       = {Qinghe Sun and Qiang Meng and Mabel C. Chou},
  doi          = {10.1016/j.ejor.2020.09.032},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {263-270},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Optimizing voyage charterparty (VCP) arrangement: Laytime negotiation and operations coordination},
  volume       = {291},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Competition in dual-channel supply chains: The
manufacturers’ channel selection. <em>EJOR</em>, <em>291</em>(1),
244–262. (<a href="https://doi.org/10.1016/j.ejor.2020.09.031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Innovative selling channels have brought about opportunities as well as challenges for upstream manufacturers. The past few years have witnessed both the success and failure of manufacturers with different channel strategies. To explore the rationale of different channel strategies in various contexts, we develop a model to analyze a manufacturer&#39;s channel selection decision among three channel strategies, i.e., a direct-channel strategy, a retail-channel strategy, and a dual-channel strategy consisting of both direct and retail channels. The model rests on the channel differentiation in terms of consumers’ channel preferences and operating costs of retail and direct channels. Specifically, we incorporate the action of a competitor and track down its influence on the focal manufacturer&#39;s channel preference. Our research clarifies the role of competition in the market and offers insights into the competitive nature of business in real life. Results show that the manufacturer&#39;s channel preference depends not only on the channels’ operating costs and consumers’ channel preferences but also on the competitor&#39;s channel strategy. We find that symmetric manufacturers can adopt asymmetric strategies as Nash equilibria and also that there are situations where no Nash equilibrium exists. We characterize the Nash equilibria in the channel selection game based on the exogenous parameters of the model.},
  archive      = {J_EJOR},
  author       = {Yumeng Zhang and Behzad Hezarkhani},
  doi          = {10.1016/j.ejor.2020.09.031},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {244-262},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Competition in dual-channel supply chains: The manufacturers&#39; channel selection},
  volume       = {291},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Condition-based inspection policies for boiler heat
exchangers. <em>EJOR</em>, <em>291</em>(1), 232–243. (<a
href="https://doi.org/10.1016/j.ejor.2020.09.030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study considers the inspection and maintenance of boiler heat exchangers, which are examples of a system composed of degrading, non-repairable components in series whose operation can be restored by removing failed components from service (albeit at a performance loss). For such systems, the increased failure risk due to component degradation may be managed through inspections and preventive removal of high failure risk components from service (again at a performance loss for remaining life of systems). In this study, a new joint inspection and preventive maintenance policy is developed, which uses condition information obtained at an inspection to optimize decisions regarding maintenance and future inspections to optimally balance the risks of system failure, future performance losses, and maintenance costs. The policy is optimized using the Markov Decision Process paradigm and is applied to a case study of a boiler heat exchanger operating in an Australian sugar factory. The results show that the proposed policy yields significant savings compared to benchmark policies that represent the factory&#39;s current practice.},
  archive      = {J_EJOR},
  author       = {Huy Truong-Ba and Michael E. Cholette and Pietro Borghesani and Lin Ma and Geoff Kent},
  doi          = {10.1016/j.ejor.2020.09.030},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {232-243},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Condition-based inspection policies for boiler heat exchangers},
  volume       = {291},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-trip time-dependent vehicle routing problem with time
windows. <em>EJOR</em>, <em>291</em>(1), 218–231. (<a
href="https://doi.org/10.1016/j.ejor.2020.09.022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, we investigate a routing problem in urban transportation which considers time-dependent travel time, multiple trips per vehicle, and loading time at the depot simultaneously. Its objective is to minimize the total travel distance while satisfying the time windows, vehicle capacity, and maximum trip duration constraints. We model the problem as a multi-trip time-dependent vehicle routing problem with time windows (MT-TDVRPTW). We formulate the time-dependent ready time function and duration function for any segment of consecutive nodes as piecewise linear functions and develop an iterative algorithm to derive them efficiently. Then, these two functions are embedded in the segment-based evaluation scheme to accelerate the local search operators. Based on them, we design a hybrid meta-heuristic algorithm to solve the problem, leveraging the adaptive large neighborhood search (ALNS) for guided exploration and the variable neighborhood descend (VND) for intensive exploitation. Moreover, we propose problem-specific local search operators and removal operators to enhance the effectiveness of the algorithm. Extensive experiments are conducted to assess the performance of the algorithm on instances of varied sizes. The algorithm is shown to be robust and efficient under different speed profiles and maximum trip duration limits. Finally, we evaluate the performance of the algorithm on a special case: the multi-trip vehicle routing problem with time windows.},
  archive      = {J_EJOR},
  author       = {Binbin Pan and Zhenzhen Zhang and Andrew Lim},
  doi          = {10.1016/j.ejor.2020.09.022},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {218-231},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Multi-trip time-dependent vehicle routing problem with time windows},
  volume       = {291},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Benders decomposition for a stochastic three-level lot
sizing and replenishment problem with a distribution structure.
<em>EJOR</em>, <em>291</em>(1), 206–217. (<a
href="https://doi.org/10.1016/j.ejor.2020.09.019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We address a stochastic three-level lot sizing and replenishment problem with a distribution structure in a two-stage decision process. We consider one production plant that produces one type of item over a discrete and finite planning horizon. The items produced are transported to warehouses and then to retailers using direct shipments. Each retailer is linked to a unique warehouse and there are no transfers between warehouses nor between retailers. The stochasticity comes from the uncertainty in the demand at the retailer level and is modelled through scenarios. The setup decisions are made in the first stage and the production, transportation and inventory decisions are made in the second stage, once the demands are revealed. The objective is to minimize the sum of the fixed production and replenishment costs, and of the expected variable inventory holding costs among all scenarios. We also study an extension where we allow for lost sales at the retailer level. We use a Benders decomposition approach and develop a Benders-based branch-and-cut algorithm to efficiently solve the problem. We take advantage of the substructures identified in the decomposition and design efficient procedures to solve the subproblems obtained. We also propose computational enhancements to speed up the solution process. Finally, we perform extensive computational experiments to assess the performance of our decomposition approach and analyze the impact of the enhancements. The Benders-based branch-and-cut algorithm we propose clearly outperforms CPLEX.},
  archive      = {J_EJOR},
  author       = {Matthieu Gruson and Jean-François Cordeau and Raf Jans},
  doi          = {10.1016/j.ejor.2020.09.019},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {206-217},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Benders decomposition for a stochastic three-level lot sizing and replenishment problem with a distribution structure},
  volume       = {291},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Rawlsian fairness in push and pull supply chains.
<em>EJOR</em>, <em>291</em>(1), 194–205. (<a
href="https://doi.org/10.1016/j.ejor.2020.09.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study a dyadic supply chain with firms following the Rawlsian principle of fairness and examine its impact on chain performance and firms’ profits. Different from the inequality-aversion model in the distributional fairness literature, the participants with the Rawlsian fairness concern maximize the profit of the disadvantageous party according to their own fairness criteria. Our results show that the Rawlsian principle adopted by individual firms can achieve not only fairness but also Pareto efficiency. By studying both push and pull supply chains, we find that what matters is the decision sequence between the manufacturer and the retailer. The fair-minded Stackelberg follower can induce the Stackelberg leader, no matter fair-minded or not, to offer a coordinating wholesale price. The chain coordination can be achieved only if the follower is not too demanding (i.e., it does not demand an excessively high portion of chain profit according to its fairness criterion). Additionally, a win-win outcome can be achieved, provided the follower is not too humble. All else being equal, the win-win region is larger with a higher demand uncertainty. Last but not least, we compare our results with those under the inequality-averse fairness model on a push supply chain and find that the parameter ranges of coordination and win-win are wider when the participants follow the Rawlsian principle of fairness.},
  archive      = {J_EJOR},
  author       = {Yanmin Jiang and Xiaole Wu and Bo Chen and Qiying Hu},
  doi          = {10.1016/j.ejor.2020.09.016},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {194-205},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Rawlsian fairness in push and pull supply chains},
  volume       = {291},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A redistribution model with minimum backorders of spare
parts: A proposal for the defence sector. <em>EJOR</em>,
<em>291</em>(1), 178–193. (<a
href="https://doi.org/10.1016/j.ejor.2020.09.014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The operational availability of systems is the main performance measure in maintenance, repair and overhaul organisations focused on fleet maintenance. In these organisations, spare part inventory management is a crucial issue. Two key aspects set contexts such as the defence sector apart. First, shipment times between secondary warehouses are longer than shipment times between the main warehouse and any given secondary warehouse. Second, the cost of the shipment is fixed, so each new delivery incurs no extra cost. To investigate such a scenario, this study examines how best to redistribute stock amongst several secondary warehouses in a two-echelon network. The supply response time for spare parts due to backorders must be minimised to maximise the fleet&#39;s operational availability. For each spare part, the goal is to find the optimal allocation to each warehouse to minimise the expected waiting time in repair shops. A stochastic redistribution model is developed. Extensive numerical examples from real cases in Spanish Army are used to demonstrate the model&#39;s effectiveness. The results are satisfactory in terms of the number of positive cases, the reduction in waiting days and solution accuracy. The approach is valid in most cases, and it is particularly suitable in situations with non-negligible transport times where the organisation&#39;s own vehicles ply regular routes. The model is designed for the defence sector, thereby tackling a real problem, although it is equally applicable to other maintenance, repair and overhaul environments with similar characteristics. The proposed model offers an innovative application to operations research, describing a novel way to solve a real-life problem.},
  archive      = {J_EJOR},
  author       = {Juan Carlos García-Benito and María-Luz Martín-Peña},
  doi          = {10.1016/j.ejor.2020.09.014},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {178-193},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A redistribution model with minimum backorders of spare parts: A proposal for the defence sector},
  volume       = {291},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Models and algorithms for the delivery and installation
routing problem. <em>EJOR</em>, <em>291</em>(1), 162–177. (<a
href="https://doi.org/10.1016/j.ejor.2020.09.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a variant of the vehicle routing problem with time windows (VRPTW) in which one disposes of two heterogeneous fleets to serve the customers; the first fleet is in charge of deliveries with the possibility to install products while the second one only performs installations. Customers receive some furniture, electronics and home appliances, and may require an installation service according to the items received. Installation can be performed by the deliverymen or by a dedicated installation fleet which needs to be synchronized with the delivery one. Each worker (delivery or installer) has different skills, and thus different installation times. We first formulate the problem as a mixed-integer linear programming model and solve it through a branch-and-bound algorithm. Moreover, we propose a formulation for a variant of the problem which allows the installation service at a customer to be done by more than one worker. We also design a tailored adaptive large neighborhood search heuristic to quickly find good solutions. Several computational experiments with new instances generated for this problem are used to assess the performance of both methods. We also prove the performance of both methods on the test instances of the related VRP with multiple synchronization constraints and the VRP with time windows and driver-specific times, yielding high-quality solutions in a short time using the heuristic and providing new lower bounds with the exact method.},
  archive      = {J_EJOR},
  author       = {Ousmane Ali and Jean-François Côté and Leandro C. Coelho},
  doi          = {10.1016/j.ejor.2020.09.011},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {162-177},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Models and algorithms for the delivery and installation routing problem},
  volume       = {291},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Optimal production and inventory control of multi-class
mixed backorder and lost sales demand class models. <em>EJOR</em>,
<em>291</em>(1), 147–161. (<a
href="https://doi.org/10.1016/j.ejor.2020.09.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Manufacturers usually face customers with different service requirements. The challenge they face is how to determine which customers to serve when the inventory supply is limited. We consider the problem of a manufacturer serving two types of customers: those with long term commitment, divided into several backorder classes; and those without commitment consisting of a single lost sales class. We treat the problem within a continuous time integrated production and inventory control framework. We propose a two-step strategy to fully characterize the optimal policy. In a first step, we use the concept of L - natural convexity to partially describe the optimal policy. Based on these results, in a second step, we reformulate the problem and fully characterize the optimal policy. We show that the latter is characterized by state-dependent multidimensional thresholds. Due to the computational complexity of the problem, we propose three heuristic policies: The first uses linear thresholds that mimic the optimal policy. These thresholds are computed through a decomposition of the original problem into a series of single-lost sales, single-backorder class problems. The second heuristic treats all demand classes equally. The third heuristic uses static thresholds to control production and inventory rationing among demand classes. Extensive numerical results show that, for problems with one lost sales and two or three backorder classes, the first heuristic outperforms the other two with a cost deviation less than 1.25\%, from the optimal. Furthermore, computing the thresholds of this heuristic is orders of magnitude faster than computing the optimal policy.},
  archive      = {J_EJOR},
  author       = {Mohsen ElHafsi and Jianxin Fang and Essia Hamouda},
  doi          = {10.1016/j.ejor.2020.09.009},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {147-161},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Optimal production and inventory control of multi-class mixed backorder and lost sales demand class models},
  volume       = {291},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A combinatorial benders decomposition algorithm for parallel
machine scheduling with working-time restrictions. <em>EJOR</em>,
<em>291</em>(1), 128–146. (<a
href="https://doi.org/10.1016/j.ejor.2020.09.037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses a parallel machine scheduling problem with restrictions on employees’ working-times and break times. Tasks must be processed by employees nonpreemptively on unrelated parallel machines with different thresholds that specify for each employee the maximum total and consecutive working-time, and the minimum break time. The objective is to minimize the weighted sum of the makespan, the machine depreciation costs, and the labor costs. To solve this problem, a mixed integer linear programming model is formulated, and two different decomposition-based exact algorithms are implemented as well as a list scheduling (LS)-based heuristic method. Extensive computational experiments are performed on randomly generated instances, and the results demonstrate the efficiency of our proposed combinatorial Benders decomposition approach.},
  archive      = {J_EJOR},
  author       = {Kan Fang and Shijin Wang and Michael L. Pinedo and Lin Chen and Feng Chu},
  doi          = {10.1016/j.ejor.2020.09.037},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {128-146},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A combinatorial benders decomposition algorithm for parallel machine scheduling with working-time restrictions},
  volume       = {291},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). New exact algorithms for planar maximum covering location by
ellipses problems. <em>EJOR</em>, <em>291</em>(1), 114–127. (<a
href="https://doi.org/10.1016/j.ejor.2020.09.029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Planar Maximum Covering Location by Ellipses is an optimization problem where one wants to choose the location of ellipses given their major and minor axes to cover demand points, maximizing a function depending on the value of covered points. We propose new exact algorithms for two versions of this problem, one where the ellipses have to be parallel to the coordinate axes, and another where they can be freely rotated. Besides finding optimal solutions for previously published instances, including the ones where no optimal solution was known, both algorithms proposed by us were able to obtain optimal solutions for some new larger instances with up to seven hundred demand points and five ellipses.},
  archive      = {J_EJOR},
  author       = {Danilo Tedeschi and Marina Andretta},
  doi          = {10.1016/j.ejor.2020.09.029},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {114-127},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {New exact algorithms for planar maximum covering location by ellipses problems},
  volume       = {291},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Number of bins and maximum lateness minimization in
two-dimensional bin packing. <em>EJOR</em>, <em>291</em>(1), 101–113.
(<a href="https://doi.org/10.1016/j.ejor.2020.09.023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work we address an orthogonal non-oriented two-dimensional bin packing problem where items are associated with due-dates. Two objectives are considered: minimize ( i ) the number of bins and ( ii ) the maximum lateness of the items. We discuss basic properties of non-dominated solutions and propose a sequential value correction heuristic that outperforms two benchmark algorithms specifically designed for this problem. We also extend the benchmark dataset for this problem with new and larger industrial instances obtained from a major manufacturer of cutting machines. Finally, we give some insights into the structure of Pareto-optimal sets in the classes of instances here considered.},
  archive      = {J_EJOR},
  author       = {Claudio Arbib and Fabrizio Marinelli and Andrea Pizzuti},
  doi          = {10.1016/j.ejor.2020.09.023},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {101-113},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Number of bins and maximum lateness minimization in two-dimensional bin packing},
  volume       = {291},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Sparsest balanced packing of irregular 3D objects in a
cylindrical container. <em>EJOR</em>, <em>291</em>(1), 84–100. (<a
href="https://doi.org/10.1016/j.ejor.2020.09.021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sparsest packing for irregular 3D objects is introduced. This problem is motivated by the thermal deburring – modern clean and energy saving technology of removing burrs from machine parts (objects) by detonating gas mixtures in a deburring chamber. The objects in the chamber are placed in a vertical cylindrical rack (container) divided into sub-containers by horizontal shelves rigidly fixed on a thin rod passing through the centre of the rack. To achieve a stable processing quality and the most uniform distribution of thermal and power effects, the parts have to be placed sufficiently distant one from another, as well as from the lateral cylindrical surface of the container. The objects are assigned to specific shelves and are represented by a union of basic convex 3D shapes (e.g., cylinders, prisms, cuboids, cones). The sparsest packing is aimed to place the 3D objects as distant as possible, freely sliding and rotating on the shelves subject to balancing conditions. Using the phi-function technique a corresponding nonlinear programming model is constructed. A solution algorithm is proposed and computational results are presented.},
  archive      = {J_EJOR},
  author       = {Tatiana Romanova and Yurij Stoyan and Alexander Pankratov and Igor Litvinchev and Sergiy Plankovskyy and Yevgen Tsegelnyk and Olga Shypul},
  doi          = {10.1016/j.ejor.2020.09.021},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {84-100},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Sparsest balanced packing of irregular 3D objects in a cylindrical container},
  volume       = {291},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An exact cutting plane algorithm to solve the selective
graph coloring problem in perfect graphs. <em>EJOR</em>,
<em>291</em>(1), 67–83. (<a
href="https://doi.org/10.1016/j.ejor.2020.09.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the selective graph coloring problem, which is a generalization of the classical graph coloring problem. Given a graph together with a partition of its vertex set into clusters, we want to choose exactly one vertex per cluster so that the number of colors needed to color the selected set of vertices is minimized. This problem is known to be NP-hard. In this study, we focus on an exact cutting plane algorithm for selective graph coloring in perfect graphs. Since there exists no suite of perfect graph instances to the best of our knowledge, we also propose an algorithm to randomly (but not uniformly) generate perfect graphs, and provide a large collection of instances available online. We conduct computational experiments to test our method on graphs with varying size and densities, and compare our results with a state-of-the-art algorithm from the literature and with solving an integer programming formulation of the problem by CPLEX. Our experiments demonstrate that our solution strategy significantly improves the solvability of the problem.},
  archive      = {J_EJOR},
  author       = {Oylum Şeker and Tınaz Ekim and Z. Caner Taşkın},
  doi          = {10.1016/j.ejor.2020.09.017},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {67-83},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {An exact cutting plane algorithm to solve the selective graph coloring problem in perfect graphs},
  volume       = {291},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A deterministic bounding procedure for the global
optimization of a bi-level mixed-integer problem. <em>EJOR</em>,
<em>291</em>(1), 52–66. (<a
href="https://doi.org/10.1016/j.ejor.2020.09.015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a deterministic bounding procedure for the global optimization of a mixed-integer bi-level programming problem is proposed. The aim has been to develop an efficient algorithm to deal with a case study in the electricity retail market. In this problem, an electricity retailer wants to define a time-of-use tariff structure to maximize profits, but he has to take into account the consumers’ reaction by means of re-scheduling appliance operation to minimize costs. The problem has been formulated as a bi-level mixed-integer programming model. The algorithm we propose uses optimal-value-function reformulations based on similar principles as the ones that have been used by other authors, which are adapted to the characteristics of this type of (pricing optimization) problems where no upper (lower) level variables appear in the lower (upper) level constraints. The overall strategy consists of generating a series of convergent upper bounds and lower bounds for the upper-level objective function until the difference between these bounds is below a given threshold. Computational results are presented as well as a comparison with a hybrid approach combining a particle swarm optimization algorithm to deal with the upper-level problem and an exact solver to tackle the lower-level problem, which we have previously developed to address a similar case study. When the lower-level model is difficult, a significant relative MIP gap is unavoidable when solving the algorithm&#39;s subproblems. Novel reformulations of those subproblems using “elastic” variables are proposed trying to obtain meaningful lower/upper bounds within an acceptable computational time.},
  archive      = {J_EJOR},
  author       = {Inês Soares and Maria João Alves and Carlos Henggeler Antunes},
  doi          = {10.1016/j.ejor.2020.09.015},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {52-66},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A deterministic bounding procedure for the global optimization of a bi-level mixed-integer problem},
  volume       = {291},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). On the distance-constrained close enough arc routing
problem. <em>EJOR</em>, <em>291</em>(1), 32–51. (<a
href="https://doi.org/10.1016/j.ejor.2020.09.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Arc routing problems consist basically of finding one or several routes traversing a given set of arcs and/or edges that must be serviced. The Close-Enough Arc Routing Problem, or Generalized Directed Rural Postman Problem, does not assume that customers are located at specific arcs, but can be serviced by traversing any arc of a given subset. Real-life applications include routing for meter reading, in which a vehicle equipped with a receiver travels a street network. If the vehicle gets within a certain distance of a meter, the receiver collects its data. Therefore, only a few streets which are close enough to the meters need to be traversed. In this paper we study the generalization of this problem to the case in which a fleet of vehicles is available. This problem, the Distance-Constrained Close Enough Arc Routing Problem, consists of finding a set of routes with minimum total cost such that their length does not exceed a maximum distance. In this article, we propose a new formulation for the Distance-Constrained Close Enough Arc Routing Problem and present some families of valid inequalities that we use in a branch-and-cut algorithm for its solution. Extensive computational experiments have been performed on a set of benchmark instances and the results are compared with those obtained with other heuristic and exact methods.},
  archive      = {J_EJOR},
  author       = {Ángel Corberán and Isaac Plana and Miguel Reula and José M. Sanchis},
  doi          = {10.1016/j.ejor.2020.09.012},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {32-51},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {On the distance-constrained close enough arc routing problem},
  volume       = {291},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). On the stackelberg knapsack game. <em>EJOR</em>,
<em>291</em>(1), 18–31. (<a
href="https://doi.org/10.1016/j.ejor.2020.09.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work we consider a bilevel knapsack problem, in which one player, the follower, decides on the optimal utilization of a bounded resource. The second player, the leader, can offer incentives, or shared profits, so that the follower chooses options attractive also for the leader. Formally, each of the two players is associated with a subset of the knapsack items. The leader may offer profits for its items as incentives to the follower, before the follower selects a subset of all items in order to maximize its overall profit. The leader receives as pay-off only the profits from those of its items that are included by the follower in the overall knapsack solution. This pay-off is then reduced by the profits offered to the follower. The resulting setting is a Stackelberg strategic game. The leader has to resolve the trade-off between offering high profits as incentives to the follower and offering low profits to gain high pay-offs.We analyze the problem for the case in which the follower solves the resulting knapsack problem to optimality and obtain a number of strong complexity results. Then we invoke a common assumption of the literature, namely that the follower’s computing power is bounded. Under this condition, we study several natural Greedy-type heuristics applied by the follower. The solution structure and complexity of the resulting problems are investigated and solution strategies are derived, in particular an Integer Linear Programming (ILP) model, but also pseudopolynomial and polynomial algorithms, when possible.},
  archive      = {J_EJOR},
  author       = {Ulrich Pferschy and Gaia Nicosia and Andrea Pacifici and Joachim Schauer},
  doi          = {10.1016/j.ejor.2020.09.007},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {18-31},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {On the stackelberg knapsack game},
  volume       = {291},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Perspectives on modeling hub location problems.
<em>EJOR</em>, <em>291</em>(1), 1–17. (<a
href="https://doi.org/10.1016/j.ejor.2020.09.039">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The aim of this paper is to provide insights for better modeling hub location problems to help create a road map for future hub location research. We first present a taxonomy to provide a framework for the broad array of hub location models, and then seek to identify key gaps in the literature that provide opportunities for better models. We provide some new perspectives in several areas, including the historical evolution of hub location research, models for economies of scale, and relevant characteristics of different applications. We also provide a succinct summary of state-of-the-art formulation and solution approaches. We conclude with a set of themes that can be addressed in the future for better modeling hub location problems.},
  archive      = {J_EJOR},
  author       = {Sibel A. Alumur and James F. Campbell and Ivan Contreras and Bahar Y. Kara and Vladimir Marianov and Morton E. O’Kelly},
  doi          = {10.1016/j.ejor.2020.09.039},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {1-17},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Perspectives on modeling hub location problems},
  volume       = {291},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Second order of stochastic dominance efficiency vs mean
variance efficiency. <em>EJOR</em>, <em>290</em>(3), 1192–1206. (<a
href="https://doi.org/10.1016/j.ejor.2020.08.051">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we compare two of the main paradigms of portfolio theory: mean variance analysis and expected utility. In particular, we show empirically that mean variance efficient portfolios are typically sub-optimal for non satiable and risk averse investors. We illustrate that the second order stochastic dominance (SSD) efficient set is the solution of a multi-objective optimization problem. We further show that the market portfolio is not necessarily a solution to this optimization problem. We also conduct an empirical analysis, examining the ex ante and ex post performance of SSD and mean variance efficient portfolios, using a bootstrap approach. In an ex ante analysis, we compare empirical moments, the level of diversification and set distances of mean variance and SSD efficient sets. We also show that the global minimum variance (GMV) portfolio and the part of the mean variance efficient frontier (MVEF) composed of highly diversified portfolios is second order stochastically dominated. This result also provides a possible alternative explanation for the diversification puzzle. Conducting an ex post analysis, we construct second order stochastic dominating strategies that outperform the GMV portfolio in terms of wealth and various other performance measures, producing a positive ex post opportunity cost.},
  archive      = {J_EJOR},
  author       = {Matteo Malavasi and Sergio Ortobelli Lozza and Stefan Trück},
  doi          = {10.1016/j.ejor.2020.08.051},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1192-1206},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Second order of stochastic dominance efficiency vs mean variance efficiency},
  volume       = {290},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Agency problems in public-private partnerships investment
projects. <em>EJOR</em>, <em>290</em>(3), 1174–1191. (<a
href="https://doi.org/10.1016/j.ejor.2020.08.050">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper examines concession contracts between a private firm and a government in the presence of moral hazard within a real-options framework. The design of optimal contracts to provide incentives to the private firm to exert effort is analyzed. We show that although first-best investment timing can be implemented, contracts often do not provide firms with proper incentives to exert effort, resulting in high-cost projects being undertaken. This problem can be alleviated through the use of a monitoring technology that imposes a penalty on the shirking firm. Although monitoring distorts the investment timing leading to a delayed investment, it increases the government’s profits at the expense of the firm, so that the government finds it optimal to induce effort exertion, increasing the likelihood of low-cost projects. Considering jointly incentives and an exit option, we show that the regular compensation of firms and their compensation upon termination act as substitutes in providing incentives. Governments should set these remunerations jointly in order to minimize the cost of a bailout option for the society.},
  archive      = {J_EJOR},
  author       = {Florina Silaghi and Sudipto Sarkar},
  doi          = {10.1016/j.ejor.2020.08.050},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1174-1191},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Agency problems in public-private partnerships investment projects},
  volume       = {290},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Capacity investment choices under cost heterogeneity and
output flexibility in oligopoly. <em>EJOR</em>, <em>290</em>(3),
1154–1173. (<a
href="https://doi.org/10.1016/j.ejor.2020.08.046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study capacity investment decisions among oligopoly firms under conditions of cost heterogeneity and output flexibility within capacity constraints. Output flexibility causes the value of the firm to be convex in the state of demand, which implies that the firm invests in larger capacity when the economic environment is more uncertain. Under cost heterogeneity among oligopoly firms, a lower-cost firm invests in larger capacity, while a less efficient rival chooses lower capacity as capacities are strategic substitutes. Consequently, higher uncertainty leads to more dispersion of equilibrium capacities and greater industry concentration. More competition thus induces a welfare loss when uncertainty and cost heterogeneity are high.},
  archive      = {J_EJOR},
  author       = {Benoît Chevalier-Roignant and Christoph M. Flath and Peter M. Kort and Lenos Trigeorgis},
  doi          = {10.1016/j.ejor.2020.08.046},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1154-1173},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Capacity investment choices under cost heterogeneity and output flexibility in oligopoly},
  volume       = {290},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A model of river pollution as a dynamic game with network
externalities. <em>EJOR</em>, <em>290</em>(3), 1136–1153. (<a
href="https://doi.org/10.1016/j.ejor.2020.08.053">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In network games, a network is an important attribute of players’ strategies: each player adopts her behavior not only by taking into account standard information about her opponents such as objectives, game dynamics, and information structure; but also by evaluating the communication structure of players represented by the network. In this paper, we investigate a dynamic game with network externalities in which a state variable of each player is influenced by her own decision and the decisions of her predecessors in the network. For the game under consideration, we identify Nash equilibrium and cooperative behavior. Additionally, we examine the model under myopic equilibrium and myopic cooperation where players place no weight on their future gains. Next, we use our findings to take in the important environmental problem of river pollution. We suppose that firms, which are located along the river flow, produce goods and compete in a market. The production results in water pollution, and the pollution emissions of a firm can influence downstream counterparts. We analyze this model in detail by incorporating a firm’s location and analytically comparing the equilibrium and cooperative behavior.},
  archive      = {J_EJOR},
  author       = {Artem Sedakov and Han Qiao and Shouyang Wang},
  doi          = {10.1016/j.ejor.2020.08.053},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1136-1153},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A model of river pollution as a dynamic game with network externalities},
  volume       = {290},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). On shared use of renewable stocks. <em>EJOR</em>,
<em>290</em>(3), 1125–1135. (<a
href="https://doi.org/10.1016/j.ejor.2020.08.052">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Considered here is multi-party exploitation of common property, renewable resources. The parties play various dynamic games differing in degree of cooperation and commitment. Comparisons of steady states clarify issues on collective choice and individual welfare. Motivation stems from shared use of fish stocks which straddle the high seas between and in exclusive zones. An important instance, observed in the North-East Atlantic, is the object of computation and discussion. Not surprisingly, full cooperation yields efficiency but strategic instability. By contrast, fully noncooperative play comes out glaringly inefficient but stable. Interestingly, on middle ground, suitable quota transfers may substitute for side payments and, to tolerable measure, bring both efficiency and stability.},
  archive      = {J_EJOR},
  author       = {Nils-Arne Ekerhovd and Sjur Didrik Flåm and Stein Ivar Steinshamn},
  doi          = {10.1016/j.ejor.2020.08.052},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1125-1135},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {On shared use of renewable stocks},
  volume       = {290},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Impact evaluation in a multi-input multi-output setting:
Evidence on the effect of additional resources for schools.
<em>EJOR</em>, <em>290</em>(3), 1111–1124. (<a
href="https://doi.org/10.1016/j.ejor.2020.08.042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes an innovative approach to evaluate the causal impact of a policy change in a multi-input multi-output setting. It combines insights from econometric impact evaluation techniques and efficiency analysis. In particular, the current paper accounts for endogeneity issues by introducing a quasi-experimental setting within a conditional multi-input multi-output efficiency framework and by decomposing the overall efficiency between ‘group-specific’ efficiency (i.e., reflecting internal managerial inefficiency) and ‘program’ efficiency (i.e., explaining the impact of the policy intervention on performance). This framework allows the researcher to interpret the efficiency scores in terms of causality. The practical usefulness of the methodology is demonstrated through an application to secondary schools in Flanders, Belgium. By exploiting an exogenous threshold, the paper examines whether additional resources for disadvantaged students impact the efficiency of schools. The empirical results indicate that additional resources do not causally influence efficiency around the threshold.},
  archive      = {J_EJOR},
  author       = {Giovanna D’Inverno and Mike Smet and Kristof De Witte},
  doi          = {10.1016/j.ejor.2020.08.042},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1111-1124},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Impact evaluation in a multi-input multi-output setting: Evidence on the effect of additional resources for schools},
  volume       = {290},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A neutral cross-efficiency evaluation method based on
interval reference points in consideration of bounded rational behavior.
<em>EJOR</em>, <em>290</em>(3), 1098–1110. (<a
href="https://doi.org/10.1016/j.ejor.2020.08.055">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cross-efficiency evaluation methods have long been suggested as an alternative for the ranking of decision making units (DMUs) in data envelopment analysis (DEA). So far, little research on cross-efficiency evaluation takes the bounded rationality of DMUs into account. In this paper, we propose a neutral cross-efficiency evaluation method based on interval reference points (IRPs) to consider bounded rational behavior. As such, we take the prospect value, which reflects the bounded rationality of DMUs when facing gain and loss, as secondary goals. This approach allows us to determine the input and output weights for each DMU from its own point of view. Each reference point (RP) of the prospect value is defined as an elastic interval reference point (IRP), which can degenerate into a precise reference point (PRP) or an IRP by adjusting the parameters. As a result, the proposed cross-efficiency evaluation method not only takes the bounded rational behavior of DMUs into account, but is also more neutral and flexible. Numerical examples are provided to illustrate the applications of the cross-efficiency evaluation method based on IRPs in DEA ranking.},
  archive      = {J_EJOR},
  author       = {Hai-Liu Shi and Sheng-Qun Chen and Lei Chen and Ying-Ming Wang},
  doi          = {10.1016/j.ejor.2020.08.055},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1098-1110},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A neutral cross-efficiency evaluation method based on interval reference points in consideration of bounded rational behavior},
  volume       = {290},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Attracting artists to music streaming platforms.
<em>EJOR</em>, <em>290</em>(3), 1083–1097. (<a
href="https://doi.org/10.1016/j.ejor.2020.08.049">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we investigate the conditions under which it can be profitable for artists to distribute their music through a streaming platform. These conditions determine the royalty the streamer must award to artists in order to lure them to its platform. We find that the platform may exclude more popular artists when the extent of heterogeneity in the artist population is significant, namely when there is a big gap in the size of the artists’ fan bases. Our results also show that such exclusion is more likely when the negotiating position of the platform vis-à-vis the artists is weaker. A weaker position may arise, for instance, when subscribers value the variety offered by the platform to a lesser extent, when competition between the streaming platform and the digital music store is significant, and when perceived ownership results in a significantly greater consumer benefit when purchasing instead of streaming content. Our model accounts for a revenue sharing rule that considers an artist&#39;s share of streams on the platform when determining royalty payments. Interestingly, the benefit an artist derives from streaming her music is dependent upon the makeup of artists on the platform.},
  archive      = {J_EJOR},
  author       = {Mark Bender and Esther Gal-Or and Tansev Geylani},
  doi          = {10.1016/j.ejor.2020.08.049},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1083-1097},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Attracting artists to music streaming platforms},
  volume       = {290},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Optimal decisions on prices, order quantities, and returns
policies in a supply chain with two-period selling. <em>EJOR</em>,
<em>290</em>(3), 1063–1082. (<a
href="https://doi.org/10.1016/j.ejor.2020.08.044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Selling products in a regular period and a markdown period, in the presence of customer returns, is common practice in the retailing industry. It is critical for the retailer to manage returns by choosing appropriate returns policies for the two periods. This paper examines the retailer&#39;s customer returns policy strategy, and pricing and ordering decisions, in a supply chain selling seasonal products over two periods. The manufacturer is a Stackelberg pricing leader and sets wholesale prices at the beginning of each period. The retailer may carry over both returns and strategic inventory of new products from the regular period to the markdown period; we show that if the holding cost on new products is low it carries over strategic inventory; it also carries returns to the markdown period, if it offers a Money-Back Guarantee in the regular period. Interestingly, we find that customer returns can serve as a substitute for inventory, and the retailer is less likely to carry strategic inventory from the first period to the second when it offers an MBG returns policy, as compared to when it offers a no-refund policy. We also show that an MBG returns policy is not always a dominant returns strategy for the retailer, if it has the option to carry strategic inventory. We identify the conditions under which either a no-refund policy or an MBG over two periods can lead to a Pareto improvement for both the retailer and the manufacturer.},
  archive      = {J_EJOR},
  author       = {Dan Li and Jing Chen and Yi Liao},
  doi          = {10.1016/j.ejor.2020.08.044},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1063-1082},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Optimal decisions on prices, order quantities, and returns policies in a supply chain with two-period selling},
  volume       = {290},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Efficient simulation of generalized SABR and stochastic
local volatility models based on markov chain approximations.
<em>EJOR</em>, <em>290</em>(3), 1046–1062. (<a
href="https://doi.org/10.1016/j.ejor.2020.09.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a novel Monte Carlo simulation method for two-dimensional stochastic differential equation (SDE) systems based on approximation through continuous-time Markov chains (CTMCs). Specifically, we propose an efficient simulation framework for asset prices under general stochastic local volatility (SLV) models arising in finance, which includes the Heston and the stochastic alpha beta rho (SABR) models as special cases. Our simulation algorithm is constructed based on approximating the latent stochastic variance process by a CTMC. Compared with time-discretization schemes, our method exhibits several advantages, including flexible boundary condition treatment, weak continuity conditions imposed on coefficients, and a second order convergence rate in the spatial grids of the approximating CTMC under suitable regularity conditions. Replacing the stochastic variance process with a discrete-state approximation greatly simplifies the direct sampling of the integrated variance, thus enabling a highly efficient simulation scheme. Extensive numerical examples illustrate the accuracy and efficiency of our estimator, which outperforms both biased and unbiased simulation estimators in the literature in terms of root mean squared error (RMSE) and computational time. This paper is focused primarily on the simulation of SDEs which arise in finance, but this new simulation approach has potential for applications in other contextual areas in operations research, such as queuing theory.},
  archive      = {J_EJOR},
  author       = {Zhenyu Cui and J. Lars Kirkby and Duy Nguyen},
  doi          = {10.1016/j.ejor.2020.09.008},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1046-1062},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Efficient simulation of generalized SABR and stochastic local volatility models based on markov chain approximations},
  volume       = {290},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Impact of dependence on single-server queueing systems.
<em>EJOR</em>, <em>290</em>(3), 1031–1045. (<a
href="https://doi.org/10.1016/j.ejor.2020.09.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study uses advanced simulation input modeling – the Vector-Auto-Regressi-ve-to-Anything (VARTA) method – to study the impact of bivariate and temporal dependencies among interarrival and service times on the performance of single-server queues. Our initial experiments, with the M/M/1 queue, show that there is nonmonotonic behavior of average waiting time with respect to negative autocorrelation in interarrival and/or service times at high utilization levels; such nonmonotonic behavior with negative autocorrelation in service times is well-known in literature, we are first to show its existence for interarrival times. Our use of VARTA allows us to extend our simulation approach to study dependence among interarrival and service times in nonexponential distributions, enabling us to compare their effects to the M/M/1. We find that the impact of dependence on the performance under nonexponential distributions of interarrival and service times is primarily determined by the second moment of the distribution. Greater (lower) variance of the nonexponential distribution increases (decreases) the average waiting time.},
  archive      = {J_EJOR},
  author       = {Ismail Civelek and Bahar Biller and Alan Scheller-Wolf},
  doi          = {10.1016/j.ejor.2020.09.002},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1031-1045},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Impact of dependence on single-server queueing systems},
  volume       = {290},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Hybrid strategies using linear and piecewise-linear decision
rules for multistage adaptive linear optimization. <em>EJOR</em>,
<em>290</em>(3), 1014–1030. (<a
href="https://doi.org/10.1016/j.ejor.2020.08.054">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Decision rules offer a rich and tractable framework for solving certain classes of multistage adaptive optimization problems. Recent literature has shown the promise of using linear and nonlinear decision rules in which wait-and-see decisions are represented as functions, whose parameters are decision variables to be optimized, of the underlying uncertain parameters. Despite this growing success, solving real-world stochastic optimization problems can become computationally prohibitive when using nonlinear decision rules, and in some cases, linear ones. Consequently, decision rules that offer a competitive trade-off between solution quality and computational time become more attractive. Whereas the extant research has always used homogeneous (i.e., either linear or piecewise-linear) decision rules, the major contribution of this paper is a computational exploration of hybrid decision rules combining the benefits of the two classes of decision rules. We first verify empirically that having higher uncertainty resolution or more linear pieces in early stages is more significant than having it in late stages in terms of solution quality. Then, we compare non-increasing and non-decreasing (i.e., higher uncertainty resolution in early and late stages, respectively) hybrid decision rules in a computational study to illustrate the trade-off between solution quality and computational cost. We also demonstrate a case where, unexpectedly, a linear decision rule is superior to a more complex piecewise-linear decision rule within a simulator. This observation bolsters the need to assess the quality of decision rules obtained from a look-ahead model within a simulator rather than just using the optimal look-ahead objective function value.},
  archive      = {J_EJOR},
  author       = {Said Rahal and Dimitri J. Papageorgiou and Zukui Li},
  doi          = {10.1016/j.ejor.2020.08.054},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1014-1030},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Hybrid strategies using linear and piecewise-linear decision rules for multistage adaptive linear optimization},
  volume       = {290},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Quality differentiation in a dual-channel supply chain.
<em>EJOR</em>, <em>290</em>(3), 1000–1013. (<a
href="https://doi.org/10.1016/j.ejor.2020.09.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we investigate a dual-channel supply chain with a retailer (she) and a manufacturer (he) who manufactures a high-quality product and a low-quality one. The manufacturer can distribute the high-quality and low-quality products in a direct channel (e.g., its own online channel) and an indirect channel (e.g., a traditional retailer channel) respectively, or the opposite. Our analyses reveal that the manufacturer&#39;s optimal distribution strategy depends on the product type. If the product&#39;s customer demand is more sensitive to quality level than production cost, it can be classified as the demand type. For a demand-type product, it is optimal for the manufacturer to sell its premium product through the direct channel to attract more demand. Otherwise, the product can be classified as the cost type and it is optimal for the manufacturer to sell its premium product through the traditional channel. In this way, the relatively high manufacturing cost can be shared with the retailer. Furthermore, we demonstrate the robustness of our results by analyzing an alternate demand model for the dual channels. Finally, we find that the manufacturer&#39;s optimal quality differentiation is detrimental to the retailer. Hence, we extend our basic model and show that the retailer can adopt an effective countermeasure by introducing an alternative supplier, even when the supplier charges a higher wholesale price.},
  archive      = {J_EJOR},
  author       = {Zhe Zhang and Huaming Song and Victor Shi and Shilei Yang},
  doi          = {10.1016/j.ejor.2020.09.003},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1000-1013},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Quality differentiation in a dual-channel supply chain},
  volume       = {290},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A faster path-based algorithm with barzilai-borwein step
size for solving stochastic traffic equilibrium models. <em>EJOR</em>,
<em>290</em>(3), 982–999. (<a
href="https://doi.org/10.1016/j.ejor.2020.08.058">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Step size determination (also known as line search) is an important component in effective algorithmic development for solving the traffic assignment problem. In this paper, we explore a novel step size determination scheme, the Barzilai-Borwein (BB) step size, and adapt it for solving the stochastic user equilibrium (SUE) problem. The BB step size is a special step size determination scheme incorporated into the gradient method to enhance its computational efficiency. It is motivated by the Newton-type methods, but it does not need to explicitly compute the second-order derivative. We apply the BB step size in a path-based traffic assignment algorithm to solve two well-known SUE models: the multinomial logit (MNL) and cross-nested logit (CNL) SUE models. Numerical experiments are conducted on two real transportation networks to demonstrate the computational efficiency and robustness of the BB step size. The results show that the BB step size outperforms the current step size strategies, i.e., the Armijo rule and the self-regulated averaging scheme.},
  archive      = {J_EJOR},
  author       = {Muqing Du and Heqing Tan and Anthony Chen},
  doi          = {10.1016/j.ejor.2020.08.058},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {982-999},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A faster path-based algorithm with barzilai-borwein step size for solving stochastic traffic equilibrium models},
  volume       = {290},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Examining the value of flexible logistics offerings.
<em>EJOR</em>, <em>290</em>(3), 968–981. (<a
href="https://doi.org/10.1016/j.ejor.2020.08.056">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the order fulfilment and retail industry, the provision of fast and low cost delivery services has received significant focus over the last decade. What is often neglected is other factors that contribute to a customer’s overall experience like customisation and flexibility of deliveries, especially in cases when a customer’s needs and plans change between order placement and order delivery. This paper explores the value of a flexible type of logistics offering in which the customer is able to change the order requirements (such as delivery date) after the order has been placed. In particular, we focus on the interactions between a retailer and a customer in agreeing and executing such logistics orders. We examine the benefits of this type of flexible logistics offerings because flexibility and customisation are critical factors for the success of omni-channel commerce. Such offerings are clearly connected with recent developments in digital technologies as these technologies are essential for the implementation. Our results indicate that flexible logistics offerings can be beneficial both for retailers and for customers. They also highlight the importance of receiving orders that do not fully meet the requirements of a customer.},
  archive      = {J_EJOR},
  author       = {Vaggelis Giannikas and Duncan McFarlane},
  doi          = {10.1016/j.ejor.2020.08.056},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {968-981},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Examining the value of flexible logistics offerings},
  volume       = {290},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Altruistic profit allocation rules for joint replenishment
with carbon cap-and-trade policy. <em>EJOR</em>, <em>290</em>(3),
956–967. (<a href="https://doi.org/10.1016/j.ejor.2020.08.040">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study profit allocation rules for joint replenishment among retailers under a carbon cap-and-trade policy. In particular, we consider retailers’ altruistic behavior when designing the profit allocation rules. We show that joint replenishment can increase participants’ total profit and reduce their total amount of carbon emissions. To allocate the total profit from joint replenishment to the retailers, we introduce a joint replenishment game with the carbon cap-and-trade policy. We show this game is convex and propose a profit allocation rule lying in the core of this game. Based on this, we further design an altruistic profit allocation rule by categorizing retailers into efficient ones and non-efficient ones, with the efficient retailers being altruistic who will transfer their surplus carbon allowance to those non-efficient ones. We show that our proposed altruistic profit allocation rule lies in the core of this game. Moreover, we derive results concerning how much carbon allowance, to whom and at what price retailers are willing to transfer in the grand coalition, by considering their altruistic parameters. Our results show that the retailer with the highest altruistic parameter value obtains all the surplus carbon allowance from other retailers, and this particular retailer transfers his surplus carbon allowance to the retailer with the second-highest altruistic parameter value. These results indicate that people do not help other people uniformly; rather, they do so according to the generosity of other people. Based on these results, we derive another altruistic profit allocation rule which also belongs to the core of the game.},
  archive      = {J_EJOR},
  author       = {Hairong Feng and Yinlian Zeng and Xiaoqiang Cai and Qian Qian and Yongwu Zhou},
  doi          = {10.1016/j.ejor.2020.08.040},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {956-967},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Altruistic profit allocation rules for joint replenishment with carbon cap-and-trade policy},
  volume       = {290},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Robust balancing of transfer lines with blocks of uncertain
parallel tasks under fixed cycle time and space restrictions.
<em>EJOR</em>, <em>290</em>(3), 946–955. (<a
href="https://doi.org/10.1016/j.ejor.2020.08.038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper deals with an optimization problem, which arises when a new transfer line has to be designed subject to a limited number of available machines, cycle time constraint, and precedence relations between necessary production tasks. The studied problem consists in assigning a given set of tasks to blocks and then blocks to machines so as to find the most robust line configuration under task processing time uncertainty. The robustness of a given line configuration is measured via its stability radius, i.e. , as the maximal amplitude of deviations from the nominal value of the processing time of uncertain tasks that do not violate the solution admissibility. In this work, for considering different hypotheses on uncertainty, the stability radius is based upon the Manhattan and Chebyshev norms. For each norm, the problem is proven to be strongly NP-hard and a mixed-integer linear program (MILP) is proposed for addressing it. To accelerate the seeking of optimal solutions, two variants of a heuristic method as well as several reduction rules are devised for the corresponding MILP. Computational results are reported on a collection of instances derived from classic benchmark data used in the literature for the Transfer Line Balancing Problem.},
  archive      = {J_EJOR},
  author       = {Aleksandr Pirogov and Evgeny Gurevsky and André Rossi and Alexandre Dolgui},
  doi          = {10.1016/j.ejor.2020.08.038},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {946-955},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Robust balancing of transfer lines with blocks of uncertain parallel tasks under fixed cycle time and space restrictions},
  volume       = {290},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Revenue-sharing between developers of virtual products and
platform distributors. <em>EJOR</em>, <em>290</em>(3), 927–945. (<a
href="https://doi.org/10.1016/j.ejor.2020.08.036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We investigate consignment contracts with revenue-sharing for selling virtual products subject to information asymmetry. In practice, distribution platforms commonly use unified contracts with identical revenue-sharing terms across the developers whose products they offer. We analyze the case of a developer who is better informed than his distribution platform regarding the demand. First, we prove that the developer has no incentive to voluntarily disclose his private information and that cheap-talk is not informative, so the distribution platform can either extract this information by designing a revelation mechanism via a menu of contracts or propose a less complicated, suboptimal but commonly used unified contract. Based on optimal control theory, we develop a menu of contracts over a continuous demand domain, which includes a mechanism that leaves out some developers who reduce the expected profit of the distribution platform. We find that (i) the distribution platform is willing to share the developer&#39;s cost to make the developer act in accordance with the actual base demand; (ii) the menu of contracts is more supportive of small businesses than the unified contract; and (iii) the menu of contracts can significantly improve the distribution platform&#39;s expected profit compared with that of the unified contract when the app quality exceeds the minimum required level. In addition, we develop a mathematical model for the case of an app developer who has the option of bypassing the distribution platform and selling his app directly to end consumers, although he would then face a smaller market.},
  archive      = {J_EJOR},
  author       = {Tal Avinadav and Tatyana Chernonog and Eugene Khmelnitsky},
  doi          = {10.1016/j.ejor.2020.08.036},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {927-945},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Revenue-sharing between developers of virtual products and platform distributors},
  volume       = {290},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Analysis of firm CSR strategies. <em>EJOR</em>,
<em>290</em>(3), 914–926. (<a
href="https://doi.org/10.1016/j.ejor.2020.03.046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Corporate social responsibility (CSR) has become increasingly important. From the perspective of operations management, traditional non-CSR-compliant operations are less costly than CSR compliant operations but may be subject to the risk of being exposed to the public by third-party organizations such as Non-Governmental Organizations (NGOs) through external scrutiny. This exposure can negatively affect firms’ market share when customers are concerned about firms’ CSR compliance. This paper studies firms’ endogenous CSR compliance strategies, i.e., the incentive to adopt CSR compliant operations. We first consider a single firm&#39;s CSR compliance strategies, and then, we extend the analysis to the case of competition. We analyze how exogenous parameters, including the risk of exposure and cost premium, determine equilibrium CSR compliance strategies. We find that CSR compliant operations will be implemented either when the exposure risk is sufficiently high or when the cost premium is sufficiently low. We also discuss how competition affects firms’ CSR compliance strategies and whether firms perform better with CSR compliant operations in equilibrium. Our results show that, by adopting CSR compliant operations, firms will engage in a win-win equilibrium if the external risk is high or if the cost premium is low. Besides, we also conduct the analysis under Bertrand (price) competition. Based on these results, we provide managerial insights into when CSR compliant operations should be adopted in practice and how such adoption affects firms’ performance. Our results also imply that the practice of sustainability requires firms to consider both the external risk of exposure and cost premium.},
  archive      = {J_EJOR},
  author       = {Junsong Bian and Yi Liao and Yao-Yu Wang and Feng Tao},
  doi          = {10.1016/j.ejor.2020.03.046},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {914-926},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Analysis of firm CSR strategies},
  volume       = {290},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A distributionally robust optimization approach for
stochastic elective surgery scheduling with limited intensive care unit
capacity. <em>EJOR</em>, <em>290</em>(3), 901–913. (<a
href="https://doi.org/10.1016/j.ejor.2020.09.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study the decision process of assigning elective surgery patients to available surgical blocks in multiple operating rooms (OR) under random surgery durations, random postoperative length-of-stay in the intensive care unit (ICU), and limited capacity of ICU. The probability distributions of random parameters are assumed to be ambiguous, and only the mean values and ranges are known. We propose a d istributionally r obust e lective s urgery s cheduling (DRESS) model that seeks optimal surgery scheduling decisions to minimize the cost of performing and postponing surgeries and the worst-case expected costs associated with overtime and idle time of ORs and lack of ICU capacity (which causes premature discharges or transfers). We evaluate the worst-case over a family of distributions characterized by the known mean values and ranges of random parameters. We leverage the separability of DRESS formulation in deriving an exact mixed-integer nonlinear programming reformulation. We linearize and derive a family of symmetry breaking inequalities to improve the solvability of the reformulation using an adapted column-and-constraint generation algorithm. Finally, we conduct extensive numerical experiments that demonstrate the superior performance of our DR approach as compared to the stochastic programming approach, and provide insights into DRESS.},
  archive      = {J_EJOR},
  author       = {Karmel S. Shehadeh and Rema Padman},
  doi          = {10.1016/j.ejor.2020.09.001},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {901-913},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A distributionally robust optimization approach for stochastic elective surgery scheduling with limited intensive care unit capacity},
  volume       = {290},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multistage stochastic programming approach for joint
optimization of job scheduling and material ordering under endogenous
uncertainties. <em>EJOR</em>, <em>290</em>(3), 886–900. (<a
href="https://doi.org/10.1016/j.ejor.2020.08.057">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Job scheduling incorporated with material ordering can better meet practical needs and lead to overall cost reduction. In this paper, we present a stochastic approach for this joint optimization problem, considering uncertainties in job processing times and resource consumptions. We formulate this integrated problem as a multistage stochastic mixed-integer program involving endogenous uncertainties. Several theoretical properties that can reduce the model size are studied. Based on this, a branch-and-bound exact algorithm and a sampling-based approximate method are designed as solution algorithms. The effectiveness of the integrated scheduling approaches and the efficiency of the proposed solution algorithms are evaluated via numerical experiments. It is shown that our approach can greatly reduce the overall cost compared with the traditional separate production planning approach, especially when production resources are not very restricted.},
  archive      = {J_EJOR},
  author       = {Yue Sha and Junlong Zhang and Hui Cao},
  doi          = {10.1016/j.ejor.2020.08.057},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {886-900},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Multistage stochastic programming approach for joint optimization of job scheduling and material ordering under endogenous uncertainties},
  volume       = {290},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Improved branch-and-cut for the inventory routing problem
based on a two-commodity flow formulation. <em>EJOR</em>,
<em>290</em>(3), 870–885. (<a
href="https://doi.org/10.1016/j.ejor.2020.08.047">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper examines the Inventory Routing Problem (IRP) with Maximum Level inventory policy. The IRP is a broad class of hard to solve problems with numerous practical applications in the field of freight transportation and logistics. A supplier is responsible for determining the timing and the quantity of replenishment services offered to a set of customers over a multi-period time horizon. In addition, vehicle routes have to be defined jointly with the inventory related decisions. A novel two-commodity flow formulation is introduced together with a new set of valid inequalities. On this basis, a branch-and-cut algorithm that employs methods for separating various families of cuts is proposed. Extensive computational experiments are reported on well-established benchmark data sets. The proposed solution approach outmatches results of current state-of-the-art branch-and-cut, branch-and-price, metaheuristic and mathematical programming based heuristic approaches, especially for hard-to-solve instances. Notably, we report 116 new upper bounds out of 640 problems of a well-known benchmark data set. Moreover, for the first time, we present new lower and upper bounds for the same data set with a larger number of vehicles. Finally, we improve 139 upper bounds out of 200 hard-to-solve larger problems of the IRP literature.},
  archive      = {J_EJOR},
  author       = {Eleftherios Manousakis and Panagiotis Repoussis and Emmanouil Zachariadis and Christos Tarantilis},
  doi          = {10.1016/j.ejor.2020.08.047},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {870-885},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Improved branch-and-cut for the inventory routing problem based on a two-commodity flow formulation},
  volume       = {290},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A specialized interior-point algorithm for huge minimum
convex cost flows in bipartite networks. <em>EJOR</em>, <em>290</em>(3),
857–869. (<a href="https://doi.org/10.1016/j.ejor.2020.10.027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The computation of the Newton direction is the most time consuming step of interior-point methods. This direction was efficiently computed by a combination of Cholesky factorizations and conjugate gradients in a specialized interior-point method for block-angular structured problems. In this work we refine this algorithmic approach to solve very large instances of minimum cost flows problems in bipartite networks, for convex objective functions with diagonal Hessians (i.e., either linear, quadratic or separable nonlinear objectives). For this class of problems the specialized algorithm only required the solution of a system by conjugate gradients at each interior-point iteration, avoiding Cholesky factorizations. After analyzing the theoretical properties of the interior-point method for this kind of problems, we provide extensive computational experiments with linear and quadratic instances of up to one billion arcs (corresponding to 200 nodes and five million nodes in each subset of the node partition, respectively). For linear and quadratic instances our approach is compared with the barriers algorithms of CPLEX (both standard path-following and homogeneous-self-dual); for linear instances it is also compared with the different algorithms of the state-of-the-art network flow solver LEMON (namely: network simplex, capacity scaling, cost scaling and cycle canceling). The specialized interior-point approach significantly outperformed the other approaches in most of the linear and quadratic transportation instances tested. In particular, it always provided a solution within the time limit; and (like LEMON, and unlike CPLEX) it never exhausted the memory of the server used for the runs. For assignment problems the network algorithms in LEMON were the most efficient option.},
  archive      = {J_EJOR},
  author       = {Jordi Castro and Stefano Nasini},
  doi          = {10.1016/j.ejor.2020.10.027},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {857-869},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A specialized interior-point algorithm for huge minimum convex cost flows in bipartite networks},
  volume       = {290},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A dual reformulation and solution framework for regularized
convex clustering problems. <em>EJOR</em>, <em>290</em>(3), 844–856. (<a
href="https://doi.org/10.1016/j.ejor.2020.09.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Clustering techniques are powerful tools commonly used in statistical learning and data analytics. Most of the past research formulates clustering tasks as a non-convex problem, where a global optimum often cannot be found. Recent studies show that hierarchical clustering and k -means clustering can be relaxed and analyzed as a convex problem. Moreover, sparse convex clustering algorithms are proposed to extend the convex clustering framework to high-dimensional space by introducing an adaptive group-Lasso penalty term. Due to the non-smoothness nature of the associated objective functions, there are still no efficient fast-convergent algorithms for clustering problems even with convexity. In this paper, we first review the structure of convex clustering problems and prove the differentiability of their dual problems. We then show that such reformulated dual problems can be efficiently solved by the accelerated first-order methods with the feasibility projection. Furthermore, we present a general framework for convex clustering with regularization terms and discuss a specific implementation of this framework using L 1,1 -norm. We also derive the dual form for the regularized convex clustering problems and show that it can be efficiently solved by embedding a projection operator and a proximal operator in the accelerated gradient method. Finally, we compare our approach with several other co-clustering algorithms using a number of example clustering problems. Numerical results show that our models and solution methods outperform all the compared algorithms for both convex clustering and convex co-clustering.},
  archive      = {J_EJOR},
  author       = {J. Pi and Honggang Wang and Panos M. Pardalos},
  doi          = {10.1016/j.ejor.2020.09.010},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {844-856},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A dual reformulation and solution framework for regularized convex clustering problems},
  volume       = {290},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Inferring linear feasible regions using inverse
optimization. <em>EJOR</em>, <em>290</em>(3), 829–843. (<a
href="https://doi.org/10.1016/j.ejor.2020.08.048">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Consider a problem where a set of feasible observations are provided by an expert, and a cost function exists that characterizes which of the observations dominate the others and are hence, preferred. Assume the expert has an implicit optimization model in mind to identify the feasible observations, but the explicit constraints of this underlying model are unknown. Our goal is to infer the feasible region of such an optimization model that would render these observations feasible while making the best ones optimal for the cost (objective) function. Such feasible regions ( i ) build a baseline for a systematic categorization of future observations, and ( ii ) allow for using sensitivity analysis to discern changes in optimal solutions if the objective function changes in the future. In this paper, we propose a general inverse optimization methodology that recovers the complete constraint matrix of a linear model and then introduce a tractable equivalent reformulation. Furthermore, we provide and discuss several generalized loss functions to inform the desirable properties of the feasible region based on user preference and historical data. We demonstrate our approach using numerical examples and a realistic diet recommendation case study for imputing personalized diets. Our numerical examples verify the validity of our approach and emphasize the differences among the proposed loss functions. The diet recommendation case study shows that the proposed models can improve the palatability of the recommended diets for each user, and it provides further intuition for large-scale implementations of the proposed methodology.},
  archive      = {J_EJOR},
  author       = {Kimia Ghobadi and Houra Mahmoudzadeh},
  doi          = {10.1016/j.ejor.2020.08.048},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {829-843},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Inferring linear feasible regions using inverse optimization},
  volume       = {290},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Optimization problems for machine learning: A survey.
<em>EJOR</em>, <em>290</em>(3), 807–828. (<a
href="https://doi.org/10.1016/j.ejor.2020.08.045">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper surveys the machine learning literature and presents in an optimization framework several commonly used machine learning approaches. Particularly, mathematical optimization models are presented for regression, classification, clustering, deep learning, and adversarial learning, as well as new emerging applications in machine teaching, empirical model learning, and Bayesian network structure learning. Such models can benefit from the advancement of numerical optimization techniques which have already played a distinctive role in several machine learning settings. The strengths and the shortcomings of these models are discussed and potential research directions and open problems are highlighted.},
  archive      = {J_EJOR},
  author       = {Claudio Gambella and Bissan Ghaddar and Joe Naoum-Sawaya},
  doi          = {10.1016/j.ejor.2020.08.045},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {807-828},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Optimization problems for machine learning: A survey},
  volume       = {290},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). National security vs. Human rights: A game theoretic
analysis of the tension between these objectives. <em>EJOR</em>,
<em>290</em>(2), 790–805. (<a
href="https://doi.org/10.1016/j.ejor.2020.08.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We explore why human rights violations take place in the midst of a rebellion. Authoritarian governments may not care for human rights but surprisingly several democratic governments have also condoned such violations. We show that the primary cause of such violations is faulty intelligence. There are two type of defective intelligence that can occur viz., missed alarm and false alarm. We consider each of these cases and determine the optimal human rights standard of the government. We then examine the effect of a decrease in the human rights standard on the probability of quelling the rebellion. In our theoretical model, this effect is indeterminate (i.e. can be positive or negative). We empirically quantify this effect using the case of Armed Forces Special Powers Act in India. Since the probability of quelling the rebellion is not directly observable, we use the magnitude of violence as its indicator. The magnitude of violence should be negatively related to the probability of the government’s success. We find that a lowering of the standard of human rights increases violence (i.e. reduces the chance of quelling the rebellion) and this effect is statistically significant.},
  archive      = {J_EJOR},
  author       = {Aniruddha Bagchi and Jomon A. Paul},
  doi          = {10.1016/j.ejor.2020.08.017},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {790-805},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {National security vs. human rights: A game theoretic analysis of the tension between these objectives},
  volume       = {290},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A dynamic model for venture capitalists’ entry–exit
investment decisions. <em>EJOR</em>, <em>290</em>(2), 779–789. (<a
href="https://doi.org/10.1016/j.ejor.2020.08.014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we develop a dynamic model to study the entry and the exit decision for a VC facing the opportunity to invest and expand a start-up firm. Two settings are considered. A benchmark-setting, where no time constraints for exiting are in place, is compared with the one where, realistically, the VC has a finite time-window to disinvest. In both cases, we consider the trade sale (M&amp;A) as the exit route. The model returns the entry and the exit triggers, the optimal post-money ownerships, the expected cash multiple for the VC, and also proposes a new time-adjusted version of the cash multiple, useful for measuring, ex-ante , the expected performance of the investment. The model aims to guide the VCs when analyzing their investment opportunities, considering the entire VC’s business-cycle (entry–expand–exit). Finally, the model is applied to a hypothetical, but realistic, situation in order to discuss the main outcomes. A comparative statics analysis is also performed.},
  archive      = {J_EJOR},
  author       = {Ricardo M. Ferreira and Paulo J. Pereira},
  doi          = {10.1016/j.ejor.2020.08.014},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {779-789},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A dynamic model for venture capitalists’ entry–exit investment decisions},
  volume       = {290},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Redundancy in systems with heterogeneous dependent
components. <em>EJOR</em>, <em>290</em>(2), 766–778. (<a
href="https://doi.org/10.1016/j.ejor.2020.08.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study different redundancy mechanisms in coherent systems with possibly dependent heterogeneous components. The dependence is modelled through copulas. We use distortion functions to obtain general results for different redundancy procedures. This model includes the popular active redundancy and minimal repair procedures. The purpose is to determine where these redundant components should be located in the system, according to its structure. We study series and parallel systems in detail. In the first case (series systems), it is well known that active and minimal repair redundancies should be assigned to the weakest component. However, we show that, surprisingly, this is not always the case for all the redundancy mechanisms. Moreover, we give a condition on the redundancy mechanism to get this expected property. Similar results are obtained for parallel systems. In these systems one can think that the best option is to assign the redundancy to the strongest component. However, we prove that this is not always the case. We include results for other system structures as well and we show that these properties also depend on the copula (dependence structure).},
  archive      = {J_EJOR},
  author       = {Jorge Navarro and Pedro Fernández-Martínez},
  doi          = {10.1016/j.ejor.2020.08.011},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {766-778},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Redundancy in systems with heterogeneous dependent components},
  volume       = {290},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Cross docking for libraries with a depot. <em>EJOR</em>,
<em>290</em>(2), 749–765. (<a
href="https://doi.org/10.1016/j.ejor.2020.08.034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Library organizations in the Netherlands show an increasing interest to employ depots for low-cost storage and demand fulfillment of item requests. Typically, all libraries in an organization have a shared catalog, and, on local unavailability, requests can be shipped from elsewhere in the organization. The depot can be used to consolidate shipment requests by making tours along all libraries, delivering requested items, but also picking up items that have to be stored at the depot, or that have to be shipped from one library to another. Cross docking and delayed shipments are two preferred methods for fulfilling requests that cannot be directly met using on-hand stock at the depot. In this paper, we compare these two methods from an inventory control perspective. We model the library system as a Markov Decision process. For one- and two-location systems, we derive analytical results for the average-cost optimal policy, showing that the decision to store items from the location at the depot satisfies a threshold structure depending on the number of rented items. For larger instances, an effective heuristic is proposed exploiting this threshold structure. In numerical experiments, important managerial insights are obtained by comparing cross docking and delayed shipments in different situations. Cross docking is shown to add most value in systems with low total stock, however, delayed shipments may achieve similar costs as cross docking when stock is high or when tours frequently visit all locations. Furthermore, effective decisions can be based on simple model formulations with memoryless rental time distributions.},
  archive      = {J_EJOR},
  author       = {G. Van der Heide and K.J. Roodbergen and N.D. Van Foreest},
  doi          = {10.1016/j.ejor.2020.08.034},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {749-765},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Cross docking for libraries with a depot},
  volume       = {290},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Portfolio optimization with irreversible long-term
investments in renewable energy under policy risk: A mixed-integer
multistage stochastic model and a moving-horizon approach.
<em>EJOR</em>, <em>290</em>(2), 734–748. (<a
href="https://doi.org/10.1016/j.ejor.2020.08.033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Portfolio optimization is an ongoing hot topic of mathematical optimization and management science. Due to the current financial market environment with low interest rates and volatile stock markets, it is getting more and more important to extend portfolio optimization models by other types of investments than classical assets. In this paper, we present a mixed-integer multistage stochastic model that includes investment opportunities in irreversible and long-term infrastructure projects in the context of renewable energies, which are also subject to policy risk. On realistic time scales for investment problems of this type, the resulting instances are by far too large to be solved with today’s most evolved optimization software. Thus, we present a tailored moving-horizon approach together with suitable approximations and simplifications of the model. We evaluate these approximations and simplifications in a computational sensitivity analysis and derive a final model that can be tackled on a realistic instance by our moving-horizon approach.},
  archive      = {J_EJOR},
  author       = {Nadine Gatzert and Alexander Martin and Martin Schmidt and Benjamin Seith and Nikolai Vogl},
  doi          = {10.1016/j.ejor.2020.08.033},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {734-748},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Portfolio optimization with irreversible long-term investments in renewable energy under policy risk: A mixed-integer multistage stochastic model and a moving-horizon approach},
  volume       = {290},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An ordinal regression approach for analyzing consumer
preferences in the art market. <em>EJOR</em>, <em>290</em>(2), 718–733.
(<a href="https://doi.org/10.1016/j.ejor.2020.08.031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {From its origin at the Renaissance, the art market is part of the global economy. Arts and cultural production add significant real values on the Gross Domestic Product (GDP) of several countries and a strong symbolic contribution in prestige for owners, either private collectors or cities and countries. The significant price fluctuations that may be observed in the market of artistic goods can be explained not only by the uniqueness of works of art and the economic conditions, but also by the changing preferences of buyers. The main aim of this paper is to develop an ordinal regression analysis model for studying the preferences of artistic goods buyers. The applied approach assumes that the price of a work of art depends on a set of criteria aiming to infer additive value functions that aggregate these criteria in such a way that these functions are optimally consistent with a given price. The presented study uses a large set of auction data from the Art Deco furniture market and considers several different criteria that may influence buyers’ preferences. These criteria are related to the physical or intangible characteristics of artistic goods. The results are mainly focused on analyzing buyer&#39;s preferences (e.g., contribution of several factors to the price of artistic goods), while the ordinal regression model has been applied in different time periods in order to study how preferences evolve over time. Finally, stability analysis has been performed, with the aim of evaluating the robustness of the results.},
  archive      = {J_EJOR},
  author       = {Evangelos Grigoroudis and Laurent Noel and Emilios Galariotis and Constantin Zopounidis},
  doi          = {10.1016/j.ejor.2020.08.031},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {718-733},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {An ordinal regression approach for analyzing consumer preferences in the art market},
  volume       = {290},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The effect of farm genetics expenses on dynamic productivity
growth. <em>EJOR</em>, <em>290</em>(2), 701–717. (<a
href="https://doi.org/10.1016/j.ejor.2020.08.030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Genetic improvement of animals has been an important source of productivity growth in dairy farming. Studying the effect of genetic progress on productivity growth of farms requires a long-term dynamic perspective due to the long generation interval of dairy animals, and the slow, persistent and cumulative effects of genetics. It is also essential from a farm decision-making perspective to disentangle overall productivity growth in relation to each variable input and investment in quasi-fixed input while accounting for adjustment costs associated with the slow changes in quasi-fixed inputs. This paper contributes to the literature by combining input- and investment-specific dynamic productivity growth analysis with impulse response analysis. The application focuses on panel data of Dutch specialized dairy farms over 2007–2013. The results show that farms that adopt improved genetic materials, as proxied by farm expenses on artificial insemination and breeding stock investment spike, achieved higher input- and investment-specific productivity growth in the first two years after the year of the expenses/spike. That is, farms that produce more efficiently after adopting quality genetics are also those farms that utilise their resources efficiently. The positive relationships suggest a potential positive spill-over effect from using high quality genetics on managerial efficiencies.},
  archive      = {J_EJOR},
  author       = {Beshir M. Ali and Yann de Mey and Alfons G.J.M. Oude Lansink},
  doi          = {10.1016/j.ejor.2020.08.030},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {701-717},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {The effect of farm genetics expenses on dynamic productivity growth},
  volume       = {290},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). When does eco-efficiency rebound or backfire? An analytical
model. <em>EJOR</em>, <em>290</em>(2), 687–700. (<a
href="https://doi.org/10.1016/j.ejor.2020.08.039">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is known that an eco-efficiency strategy, which saves resources in the production process, may be offset by a rebound effect; it may even backfire. Less known are the exact conditions under which eco-efficiency rebounds or backfires. This article fills the gap by providing an analytical model of the rebound and backfire effects. We propose an optimal control framework of dynamic pricing and eco-efficiency investment, for which eco-efficiency reduces the unit production cost and boosts the demand of environmentally concerned consumers. Results, which hold with a general demand formulation, examine the analytic conditions for the rebound and backfire effects. They also highlight the possibility of a reverse rebound effect. Such results pave the way to sounder sustainability strategies.},
  archive      = {J_EJOR},
  author       = {Régis Y. Chenavaz and Stanko Dimitrov and Frank Figge},
  doi          = {10.1016/j.ejor.2020.08.039},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {687-700},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {When does eco-efficiency rebound or backfire? an analytical model},
  volume       = {290},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Decision-based model selection. <em>EJOR</em>,
<em>290</em>(2), 671–686. (<a
href="https://doi.org/10.1016/j.ejor.2020.08.025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A key step in data-driven decision making is the choice of a suitable mathematical model. Complex models that give an accurate description of reality may depend on many parameters that are difficult to estimate; in addition, the optimization problem corresponding to such models may be computationally intractable and only approximately solvable. Simple models with only a few unknown parameters may be misspecified, but also easier to estimate and optimize. With such different models and some initial data at hand, a decision maker would want to know which model produces the best decisions. In this paper we propose a decision-based model-selection method that addresses this question.},
  archive      = {J_EJOR},
  author       = {Arnoud V. den Boer and Dirk D. Sierag},
  doi          = {10.1016/j.ejor.2020.08.025},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {671-686},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Decision-based model selection},
  volume       = {290},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Methodology for calculating critical values of relevance
measures in variable selection methods in data envelopment analysis.
<em>EJOR</em>, <em>290</em>(2), 657–670. (<a
href="https://doi.org/10.1016/j.ejor.2020.08.021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The selection of input and output variables is a key step in evaluating the relative efficiency of decision-making units (DMUs) in data envelopment analysis (DEA). In this paper, we present a methodology based on Monte Carlo simulations and bootstrapping for calculating the critical values of relevance measures in variable selection methods in DEA. Additionally, we define a set of metrics to study the methods’ performance when using such critical values. We conducted an extensive simulation study, applying the proposed methodology to two variable selection methods in 28 single-output model specifications (i.e., different number of inputs and DMUs in the DEA model) under multiple scenarios, varying factors related to the functional form of the production function, the probability of an input being relevant in the model, the probability distribution of the inputs, and the theoretical efficiencies of the DMUs. The simulation study shows that (i) our proposed methodology yields consistent results for the two methods studied, in terms of the generated critical values and the performance metrics, and (ii) for most model specifications, the critical values can be estimated with a linear model with a high adjusted R 2 , using factors related to the input probability distribution and the probability of an input being relevant as independent variables. Furthermore, we describe and compare the performance of the two methods studied, provide guidelines for using our methodology and the results presented in this paper, and propose suggestions for future research.},
  archive      = {J_EJOR},
  author       = {Jeyms Villanueva-Cantillo and Manuel Munoz-Marquez},
  doi          = {10.1016/j.ejor.2020.08.021},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {657-670},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Methodology for calculating critical values of relevance measures in variable selection methods in data envelopment analysis},
  volume       = {290},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Statistical learning for probability-constrained stochastic
optimal control. <em>EJOR</em>, <em>290</em>(2), 640–656. (<a
href="https://doi.org/10.1016/j.ejor.2020.08.041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We investigate Monte Carlo based algorithms for solving stochastic control problems with local probabilistic constraints. Our motivation comes from microgrid management, where the controller tries to optimally dispatch a diesel generator while maintaining low probability of blackouts at each step. The key question we investigate are empirical simulation procedures for learning the state-dependent admissible control set that is specified implicitly through a probability constraint on the system state. We propose a variety of relevant statistical tools including logistic regression, Gaussian process regression, quantile regression and support vector machines, which we then incorporate into an overall Regression Monte Carlo (RMC) framework for approximate dynamic programming. Our results indicate that using logistic or Gaussian process regression to estimate the admissibility probability outperforms the other options. Our algorithms offer an efficient and reliable extension of RMC to probability-constrained control. We illustrate our findings with two case studies for the microgrid problem.},
  archive      = {J_EJOR},
  author       = {Alessandro Balata and Michael Ludkovski and Aditya Maheshwari and Jan Palczewski},
  doi          = {10.1016/j.ejor.2020.08.041},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {640-656},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Statistical learning for probability-constrained stochastic optimal control},
  volume       = {290},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An online algorithm for the risk-aware restless bandit.
<em>EJOR</em>, <em>290</em>(2), 622–639. (<a
href="https://doi.org/10.1016/j.ejor.2020.08.028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The multi-armed bandit (MAB) is a classical model for the exploration vs. exploitation trade-off. Among existing MAB models, the restless bandit model is of increasing interest because of its dynamic nature, which makes it highly applicable in practice. Like other MAB models, the traditional (risk-neutral) restless bandit model searches for the arm with the lowest mean cost and does not consider risk-aversion, which is critical in cases such as clinical trials and financial investment. This limitation thus hinders the application of the traditional restless bandit. Motivated by these concerns, we introduce a general risk measure that satisfies a mild restriction to formulate a risk-aware restless model; in particular, we set a risk measure as the criterion for the performance of each arm, instead of the expectation as in the traditional case. Compared with classical MAB models, we conclude that our model settings accommodate risk-aware researchers and decision makers. We present an index-based online algorithm for the problem, and derive an upper bound on the regret of this algorithm. Then, we conclude that our algorithm retains an instance-based regret of order O (log T / T ), which is consistent with the classical MAB model. Further, some specific risk measures, namely, mean-deviation, shortfall and the discrete Kusuoka risk measure, are used to demonstrate the details of our framework.},
  archive      = {J_EJOR},
  author       = {Jianyu Xu and Lujie Chen and Ou Tang},
  doi          = {10.1016/j.ejor.2020.08.028},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {622-639},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {An online algorithm for the risk-aware restless bandit},
  volume       = {290},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An accelerated directional derivative method for smooth
stochastic convex optimization. <em>EJOR</em>, <em>290</em>(2), 601–621.
(<a href="https://doi.org/10.1016/j.ejor.2020.08.027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider smooth stochastic convex optimization problems in the context of algorithms which are based on directional derivatives of the objective function. This context can be considered as an intermediate one between derivative-free optimization and gradient-based optimization. We assume that at any given point and for any given direction, a stochastic approximation for the directional derivative of the objective function at this point and in this direction is available with some additive noise. The noise is assumed to be of an unknown nature, but bounded in the absolute value. We underline that we consider directional derivatives in any direction, as opposed to coordinate descent methods which use only derivatives in coordinate directions. For this setting, we propose a non-accelerated and an accelerated directional derivative method and provide their complexity bounds. Our non-accelerated algorithm has a complexity bound which is similar to the gradient-based algorithm, that is, without any dimension-dependent factor. Our accelerated algorithm has a complexity bound which coincides with the complexity bound of the accelerated gradient-based algorithm up to a factor of square root of the problem dimension. We extend these results to strongly convex problems.},
  archive      = {J_EJOR},
  author       = {Pavel Dvurechensky and Eduard Gorbunov and Alexander Gasnikov},
  doi          = {10.1016/j.ejor.2020.08.027},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {601-621},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {An accelerated directional derivative method for smooth stochastic convex optimization},
  volume       = {290},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The effect of multi-sensor data on condition-based
maintenance policies. <em>EJOR</em>, <em>290</em>(2), 585–600. (<a
href="https://doi.org/10.1016/j.ejor.2020.08.035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Industry 4.0 promises reductions in maintenance costs through access to digital technologies such as the Internet of Things, cloud computing and data analytics. Many of the promised benefits to maintenance are, however, dependent on the quality of the data obtained through sensors and related technologies. In this work, we consider the effect of access to different levels of deterioration data quality, resulting in partial information about the underlying state of the system being monitored, by means of sensors, on condition-based maintenance policies. The sensors may be either internal company sensors, or more informative external sensors of which access is obtained at a cost. We analyze the structure of the optimal policy, where the actions are either to perform maintenance, to pay for external sensor information or to continue system operation with internal sensor information only. We show that the optimal policy consists of at most four regions based on the believed deterioration state of the system. The analysis allows us to numerically investigate the decision maker’s willingness to pay for more informative external sensor information with respect to the level of external sensor informativeness, when compared to that of the internal sensor, and the cost thereof.},
  archive      = {J_EJOR},
  author       = {Heletjé E. van Staden and Robert N. Boute},
  doi          = {10.1016/j.ejor.2020.08.035},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {585-600},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {The effect of multi-sensor data on condition-based maintenance policies},
  volume       = {290},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Information sharing in an e-tailing supply chain for fresh
produce with freshness-keeping effort and value-added service.
<em>EJOR</em>, <em>290</em>(2), 572–584. (<a
href="https://doi.org/10.1016/j.ejor.2020.08.026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper explores information sharing in an e-tailing supply chain for fresh produce. We consider a supply chain consisting of a supplier providing freshness-keeping effort and an e-tailer providing value-added service. The e-tailer has private information about uncertain demand and decides whether to share the information with the supplier. We find that information sharing may benefit the e-tailer and that the e-tailer chooses to share information voluntarily when the freshness elasticity is above a certain threshold. We also show that information sharing cooperation is more likely to occur when the supplier is more economical in terms of freshness-keeping investment, or when the e-tailer is more efficient in terms of service investment. Then, we design an incentive contract with a transfer payment that stimulates the e-tailer to share information with the supplier. Next, we investigate the impacts of information sharing on equilibrium decisions. We show that under voluntary information sharing, the e-tailer increases (decreases) both the retail price and service level under high (low) demand information sharing. However, under information sharing with compensation, the e-tailer decreases (increases) the service level but may increase (decrease) or decrease (increase) the retail price under high (low) demand information sharing. Finally, from a social policymaking perspective, we discuss the impacts of information sharing on the expected social welfare. Interestingly, we find that whether information sharing with compensation improves the expected social welfare depends on the freshness elasticity.},
  archive      = {J_EJOR},
  author       = {Molin Liu and Bin Dan and Shuguang Zhang and Songxuan Ma},
  doi          = {10.1016/j.ejor.2020.08.026},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {572-584},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Information sharing in an E-tailing supply chain for fresh produce with freshness-keeping effort and value-added service},
  volume       = {290},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Optimization of product category allocation in multiple
warehouses to minimize splitting of online supermarket customer orders.
<em>EJOR</em>, <em>290</em>(2), 556–571. (<a
href="https://doi.org/10.1016/j.ejor.2020.08.024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In an online supermarket, people may purchase multiple items in a single order for convenience or to obtain free delivery. Multi-item customer orders often need to be split into multiple shipments because the ordered items may be stored in different warehouses. Order splitting results in higher shipping costs. One way to reduce splitting is to store and retrieve all the items in a single warehouse. However, due to the vast volume of items sold by online supermarkets, it is difficult to build and operate such a warehouse. Another way is to optimize the allocation of products in multiple warehouses to reduce order splitting. In this paper, we propose a K-links heuristic clustering algorithm to optimize the product category allocation among multiple warehouses based on the distribution of multi-item orders to minimize the total number of order splits. Using online order and inventory data from a large Chinese online supermarket, we demonstrate that our algorithm performs well and dramatically reduces order splitting.},
  archive      = {J_EJOR},
  author       = {Shan Zhu and Xiangpei Hu and Kai Huang and Yufei Yuan},
  doi          = {10.1016/j.ejor.2020.08.024},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {556-571},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Optimization of product category allocation in multiple warehouses to minimize splitting of online supermarket customer orders},
  volume       = {290},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Channel coordination between manufacturers and competing
retailers with fairness concerns. <em>EJOR</em>, <em>290</em>(2),
546–555. (<a href="https://doi.org/10.1016/j.ejor.2020.08.023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study provides a game-theoretic analysis for channel coordination of a two-tier supply chain in which retailers have fairness concerns. We explore a setting in which a single manufacturer sells its product to consumers through two competing retailers that are horizontally differentiated at varying levels. We extend the previous literature, which examines only monopolistic supply chains. We show that the channel can be successfully coordinated in equilibrium in that the total channel profit is maximized and the retailers do not incur disutility due to disadvantageous inequality, even if they are not averse to their advantageous inequality. Specifically, only if the retailers are moderately differentiated is a fair channel successfully achieved. In addition, we find that in a market in which a fair channel is coordinated in equilibrium, the retailers necessarily benefit from their fairness concerns. Furthermore, we investigate a situation in which the ideal distribution ratios between the channel members can be endogenously chosen prior to subsequent pricing stages. Interestingly, even if such endogenous choices are allowed for the retailers, a fair channel still can be coordinated in equilibrium. Specifically, the retailers set their ideal ratios in equilibrium at the lowest level in their feasible ranges of successful coordination. However, this results in the prisoner’s dilemma, because if they were allowed to collude to set the ratios, the retailers would benefit the most from the highest level in the feasible ranges.},
  archive      = {J_EJOR},
  author       = {Rikuo Yoshihara and Nobuo Matsubayashi},
  doi          = {10.1016/j.ejor.2020.08.023},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {546-555},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Channel coordination between manufacturers and competing retailers with fairness concerns},
  volume       = {290},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Pricing service maintenance contracts using predictive
analytics. <em>EJOR</em>, <em>290</em>(2), 530–545. (<a
href="https://doi.org/10.1016/j.ejor.2020.08.022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As more manufacturers shift their focus from selling products to end solutions, full-service maintenance contracts gain traction in the business world. These contracts cover all maintenance related costs during a predetermined horizon in exchange for a fixed service fee and relieve customers from uncertain maintenance costs. To guarantee profitability, the service fees should at least cover the expected costs during the contract horizon. As these expected costs may depend on several machine-dependent characteristics, e.g. operational environment, the service fees should also be differentiated based on these characteristics. If not, customers that are less prone to high maintenance costs will not buy into or renege on the contract. The latter can lead to adverse selection and leave the service provider with a maintenance-heavy portfolio, which may be detrimental to the profitability of the service contracts. We contribute to the literature with a data-driven tariff plan based on the calibration of predictive models that take into account the different machine profiles. This conveys to the service provider which machine profiles should be attracted at which price. We demonstrate the advantage of a differentiated tariff plan and show how it better protects against adverse selection.},
  archive      = {J_EJOR},
  author       = {Laurens Deprez and Katrien Antonio and Robert Boute},
  doi          = {10.1016/j.ejor.2020.08.022},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {530-545},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Pricing service maintenance contracts using predictive analytics},
  volume       = {290},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Joint optimization of condition-based maintenance and
inventory control for a k-out-of-n: F system of multi-state degrading
components. <em>EJOR</em>, <em>290</em>(2), 514–529. (<a
href="https://doi.org/10.1016/j.ejor.2020.08.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Maintaining a system of multiple degrading components requires having a supply of spare components to replace deteriorated ones in a timely manner. Decisions on whether to replace the deteriorated components are made based on the statuses of components and the system and are further restricted by the inventory level of spares. Inventory replenishment decisions themselves depend both on system status and maintenance policy. Both maintenance and replenishment decisions affect the system reliability and system maintenance and spare inventory cost. This paper considers the joint optimization of periodic condition-based replacement of components and inventory control for a k -out-of- n :F system of non-repairable degrading components under various system statuses. For modeling the degradation of components, both the Wiener process and gamma process are considered. We model the maintenance and inventory policy using the number of components in each discretized degradation state rather than the traditional approach, which uses the state of each component. Our approach considerably reduces the solution space. Based on that, we address the joint optimization using Markov decision process along with dynamic programming; we then analyze the complexity of the algorithm. We provide a numerical study on a 2-out-of-3:F system of components in three states to illustrate structural insights regarding the proposed model, including a sensitivity analysis on the length of inspection interval, system downtime cost, and inventory holding cost. We demonstrate the efficiency of the model and solution method by testing k -out-of- n :F systems with different numbers of components and discretized degradation states.},
  archive      = {J_EJOR},
  author       = {Jun Wang and Xiaoyan Zhu},
  doi          = {10.1016/j.ejor.2020.08.016},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {514-529},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Joint optimization of condition-based maintenance and inventory control for a k-out-of-n: F system of multi-state degrading components},
  volume       = {290},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Integrating facility layout design and aisle structure in
manufacturing systems: Formulation and exact solution. <em>EJOR</em>,
<em>290</em>(2), 499–513. (<a
href="https://doi.org/10.1016/j.ejor.2020.08.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In manufacturing systems, aisles are paths which are used for the movement of workers, transportation devices, and materials. The aisle structure contributes to layout efficiency by reducing material handling costs, mean flow time and the amount of space needed, and providing smooth transportation. Therefore, to achieve a good layout, it is essential to determine the position of facilities such as machines and workstations, but also the corresponding aisle structure. In this article, we analyze the requirements for the design of an efficient aisle structure and propose a formulation of the corresponding layout problem as a mixed-integer linear programming model. This formulation allows the layout of unequal-area facilities and the aisle structure to be simultaneously optimized. In optimizing the aisle structure, issues such as optimizing the number, position, and width of the aisles, the position of the entrance and exit doors, and how to connect them to the aisles are studied. By optimizing the number and width of the aisles, the proposed approach contributes towards optimizing transportation traffic. A branch-and-cut algorithm, improved by adding optimality cuts and efficient branching and node strategies, is used to solve the problem. Finally, a set of computational experiments is performed to show the effectiveness of the proposed approach.},
  archive      = {J_EJOR},
  author       = {Hani Pourvaziri and Henri Pierreval and Helene Marian},
  doi          = {10.1016/j.ejor.2020.08.012},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {499-513},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Integrating facility layout design and aisle structure in manufacturing systems: Formulation and exact solution},
  volume       = {290},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Implementing the branch-and-cut approach for a general
purpose benders’ decomposition framework. <em>EJOR</em>,
<em>290</em>(2), 479–498. (<a
href="https://doi.org/10.1016/j.ejor.2020.08.037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Benders’ decomposition is a popular mathematical and constraint programming algorithm that is widely applied to exploit problem structure arising from real-world applications. While useful for exploiting structure in mathematical and constraint programs, the use of Benders’ decomposition typically requires significant implementation effort to achieve an effective solution algorithm. Traditionally, Benders’ decomposition has been viewed as a problem specific algorithm, which has limited the development of general purpose algorithms and software solutions. This paper presents a general purpose Benders’ decomposition algorithm that is capable of handling many classes of mathematical and constraint programs and provides extensive flexibility in the implementation and use of this algorithm. A branch-and-cut approach for Benders’ decomposition has been implemented within the constraint integer programming solver SCIP using a plugin-based design to allow for a wide variety of extensions and customisations to the algorithm. The effectiveness of the Benders’ decomposition algorithm and available enhancement techniques is assessed in a comprehensive computational study.},
  archive      = {J_EJOR},
  author       = {Stephen J. Maher},
  doi          = {10.1016/j.ejor.2020.08.037},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {479-498},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Implementing the branch-and-cut approach for a general purpose benders’ decomposition framework},
  volume       = {290},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Exact lexicographic scheduling and approximate rescheduling.
<em>EJOR</em>, <em>290</em>(2), 469–478. (<a
href="https://doi.org/10.1016/j.ejor.2020.08.032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In industrial resource allocation problems, an initial planning stage may solve a nominal problem instance and a subsequent recovery stage may intervene to repair inefficiencies and infeasibilities due to uncertainty, e.g. machine failures and job processing time variations. In this context, we investigate the minimum makespan scheduling problem, a.k.a. P || C max , under uncertainty. We propose a two-stage robust scheduling approach where first-stage decisions are computed with exact lexicographic scheduling and second-stage decisions are derived using approximate rescheduling. We explore recovery strategies accounting for planning decisions and constrained by limited permitted deviations from the original schedule. Our approach is substantiated analytically, with a price of robustness characterization parameterized by the degree of uncertainty, and numerically. This analysis is based on optimal substructure imposed by lexicographic optimality. Thus, lexicographic optimization enables more efficient rescheduling. Further, we revisit state-of-the-art exact lexicographic optimization methods and propose a lexicographic branch-and-bound algorithm whose performance is validated computationally.},
  archive      = {J_EJOR},
  author       = {Dimitrios Letsios and Miten Mistry and Ruth Misener},
  doi          = {10.1016/j.ejor.2020.08.032},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {469-478},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Exact lexicographic scheduling and approximate rescheduling},
  volume       = {290},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Due-window assignment scheduling problem with stochastic
processing times. <em>EJOR</em>, <em>290</em>(2), 453–468. (<a
href="https://doi.org/10.1016/j.ejor.2020.08.029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In operational systems, scheduling and due-window assignment are two common decisions. At the same time, many sources of uncertainty existed in operational systems make the processing times of jobs stochastic. In this paper, two specific due-window assignment scheduling problems with different distributional information regarding the processing times are studied. In the first problem, the processing times follow normal distribution, whereas in the second problem, there is only information about the mean and variance of the processing time of each job, but no information about the specific distribution pattern. The objective of both problems is to determine a due window for each job and a processing schedule for all jobs to minimize total expected weighted costs for earliness, tardiness and due-window assignment. For the first problem, we analyze the optimal due-window assignment and propose a branch-and-bound algorithm to find an optimal solution. For the second problem, we first establish an approximated problem based on developed upper and lower bounds, and then develop a branch-and-bound algorithm to solve the approximated problem optimally. Finally, computational experiments are conducted to evaluate the performance of the proposed algorithms and the efficiency of the problem approximation. Through computational experiments, some managerial insights are derived.},
  archive      = {J_EJOR},
  author       = {Qing Yue and Shenghai Zhou},
  doi          = {10.1016/j.ejor.2020.08.029},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {453-468},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Due-window assignment scheduling problem with stochastic processing times},
  volume       = {290},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Heuristics for the dynamic facility location problem with
modular capacities. <em>EJOR</em>, <em>290</em>(2), 435–452. (<a
href="https://doi.org/10.1016/j.ejor.2020.08.018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the Dynamic Facility Location Problem with Modular Capacities (DFLPM). It generalizes several facility location problems and consists in determining locations and sizes of facilities to minimize location and demand allocation costs with decisions taken periodically over a planning horizon. The DFLPM is solved using heuristics tailored for different scenarios and cost structures. We propose three linear relaxation based heuristics (LRH) and an evolutionary heuristic that hybridizes a genetic algorithm with a variable neighborhood descent (GA+VND). We adapt benchmark instances from the literature to yield several representations of scenarios and parameters structures. Experiments are reported comparing the heuristics to a state-of-the-art mixed integer programming (MIP) formulation for the problem. We show that the performance of the methods depends on the characteristics of the instance solved. For the benchmark instances, the LRH improved by VND finds solutions within 0.02\% of the optimal ones in less than half of the time of the MIP. For the scenarios where construction costs are higher and module sizes are lower, the GA+VND proved to be effective to solve the problem, outperforming the LRH and the MIP. We also discuss the results from a practitioner point of view to identify situations where each method is preferable.},
  archive      = {J_EJOR},
  author       = {Allyson Silva and Daniel Aloise and Leandro C. Coelho and Caroline Rocha},
  doi          = {10.1016/j.ejor.2020.08.018},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {435-452},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Heuristics for the dynamic facility location problem with modular capacities},
  volume       = {290},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Ideal schedules in parallel machine settings. <em>EJOR</em>,
<em>290</em>(2), 422–434. (<a
href="https://doi.org/10.1016/j.ejor.2020.08.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An ideal schedule is a schedule that simultaneously minimizes the two most popular scheduling objectives, namely the makespan and the total completion time. If a scheduling problem always has an ideal schedule, then the problem is called an ideal problem. We summarize ideal problem results of various scheduling problems in different machine environments and with job characteristics that include precedence constraints, release dates, processing times, eligibility constraints and preemptions. We present a comprehensive overview of ideal schedules including our new findings.},
  archive      = {J_EJOR},
  author       = {Xiaojuan Jiang and Kangbok Lee and Michael L. Pinedo},
  doi          = {10.1016/j.ejor.2020.08.010},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {422-434},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Ideal schedules in parallel machine settings},
  volume       = {290},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Machine learning for combinatorial optimization: A
methodological tour d’horizon. <em>EJOR</em>, <em>290</em>(2), 405–421.
(<a href="https://doi.org/10.1016/j.ejor.2020.07.063">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper surveys the recent attempts, both from the machine learning and operations research communities, at leveraging machine learning to solve combinatorial optimization problems. Given the hard nature of these problems, state-of-the-art algorithms rely on handcrafted heuristics for making decisions that are otherwise too expensive to compute or mathematically not well defined. Thus, machine learning looks like a natural candidate to make such decisions in a more principled and optimized way. We advocate for pushing further the integration of machine learning and combinatorial optimization and detail a methodology to do so. A main point of the paper is seeing generic optimization problems as data points and inquiring what is the relevant distribution of problems to use for learning on a given task.},
  archive      = {J_EJOR},
  author       = {Yoshua Bengio and Andrea Lodi and Antoine Prouvost},
  doi          = {10.1016/j.ejor.2020.07.063},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {405-421},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Machine learning for combinatorial optimization: A methodological tour d’horizon},
  volume       = {290},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A comment on performance guarantees of a greedy algorithm
for minimizing a supermodular set function on comatroid. <em>EJOR</em>,
<em>290</em>(1), 401–403. (<a
href="https://doi.org/10.1016/j.ejor.2020.07.047">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We provide a counterexample to the performance guarantee obtained in the paper “Il’ev, V., Linker, N., 2006. Performance guarantees of a greedy algorithm for minimizing a supermodular set function on comatroid”, which was published in Volume 171 of the European Journal of Operational Research. We point out where this error originates from in the proof of the main theorem.},
  archive      = {J_EJOR},
  author       = {Orcun Karaca and Baiwei Guo and Maryam Kamgarpour},
  doi          = {10.1016/j.ejor.2020.07.047},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {401-403},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A comment on performance guarantees of a greedy algorithm for minimizing a supermodular set function on comatroid},
  volume       = {290},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Managing complex adaptive systems: A resource/agent
qualitative modelling perspective. <em>EJOR</em>, <em>290</em>(1),
386–400. (<a href="https://doi.org/10.1016/j.ejor.2020.08.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Complex adaptive systems are systems where those managing the system, the agents, interact with other competing agents and key resources available to the system. The behaviour of the agents and the resources are constantly changing over time thus resulting in complex systems of evolving problem configurations. Managing such a system can be very challenging, particularly when attempting to manage rather than simplify complexity. One particular problem is the need to take a comprehensive perspective of the complex system in order to manage it effectively. Resource structure and agent behaviour are interdependent and both interconnected components need to be considered in order to support optimal decision making. Due to the lack of an appropriate technique in the literature to achieve a comprehensive qualitative appreciation of resource/agent complex adaptive system behaviour, this paper describes the development of a novel qualitative modelling tool, a Resource/Agent Map, that aims to map and analyse both resources and agents interactive behaviour. We show how this modelling tool can help achieve a holistic appreciation of the resource/agent perspectives and generate scenario alternatives to inform policy decision making in respect to system management and regulation. A pharmaceutical example is used to demonstrate the modelling tool.},
  archive      = {J_EJOR},
  author       = {Rossen Kazakov and Susan Howick and Alec Morton},
  doi          = {10.1016/j.ejor.2020.08.007},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {386-400},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Managing complex adaptive systems: A resource/agent qualitative modelling perspective},
  volume       = {290},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Measuring and analyzing country change in establishing ease
of doing business using a revised version of world bank’s ease of doing
business index. <em>EJOR</em>, <em>290</em>(1), 373–385. (<a
href="https://doi.org/10.1016/j.ejor.2020.07.065">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The World Bank&#39;s Ease of Doing Business (EDB) index is well-known and widely used to quantify and monitor the ‘ease of doing business’ within a country. The index attracted notable criticism for being too reliant on a ‘one size fits all’ approach (equal weighting) to the weighting step of its construction. The present paper recomputes the EDB index by employing a more flexible ‘Benefit-of-Doubt’ weighting method. Using different versions of this method, changes in EDB are examined for the period 2010–2019, whilst grouping countries according to regional classifications as defined by the World Bank. In addition, year-by-year trends in the EDB index are explored. The results show considerable differences in changes in the EDB index both between and within different regions. Within some regions there were also signs of clustering in terms of similar rates of improvement or deterioration over time.},
  archive      = {J_EJOR},
  author       = {Nicky Rogge and Geoffrey Archer},
  doi          = {10.1016/j.ejor.2020.07.065},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {373-385},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Measuring and analyzing country change in establishing ease of doing business using a revised version of world bank&#39;s ease of doing business index},
  volume       = {290},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Predicting mortgage early delinquency with machine learning
methods. <em>EJOR</em>, <em>290</em>(1), 358–372. (<a
href="https://doi.org/10.1016/j.ejor.2020.07.058">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the performance of thirteen methods for modelling and predicting mortgage early delinquency probabilities. These models include variants of logit models, some commonly used machine learning methods, and variants of ensemble models. We find that heterogenous ensemble methods lead other methods in the training, out-of-sample, and out-of-time datasets in terms of risk classification. Nonetheless, various predictive accuracy performance measures yield different rankings among the thirteen methods and no method consistently dominates in this performance dimension in the training, out-of-sample, and out-of-time data. Lastly, predictive accuracy is a major challenge facing all mortgage early delinquency models, even in the training data.},
  archive      = {J_EJOR},
  author       = {Shunqin Chen and Zhengfeng Guo and Xinlei Zhao},
  doi          = {10.1016/j.ejor.2020.07.058},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {358-372},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Predicting mortgage early delinquency with machine learning methods},
  volume       = {290},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). New monotone measure-based integrals inspired by scientific
impact problem. <em>EJOR</em>, <em>290</em>(1), 346–357. (<a
href="https://doi.org/10.1016/j.ejor.2020.07.057">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we define new functionals generalizing scientometric indices proposed by Mesiar and Gągolewski in 2016 to overcome some limitations of h h -index. These functionals are integrals with respect to a monotone measure as well as aggregation functions under some mild conditions. We derive numerous properties of the new integrals and analyze subadditivity property in detail. We also give a partial solution to the problem posed by Mesiar and Stupňanová to find an algorithm for computing the pseudo-decomposition integral of n n th order based on operations ⊕ = + ⊕=+ and ⊙ = ∧ , ⊙=∧, which will be useful in multi-criteria decision problems.},
  archive      = {J_EJOR},
  author       = {Michał Boczek and Anton Hovana and Ondrej Hutník and Marek Kaluszka},
  doi          = {10.1016/j.ejor.2020.07.057},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {346-357},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {New monotone measure-based integrals inspired by scientific impact problem},
  volume       = {290},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). From firm to global-level pollution control: The case of
transboundary pollution. <em>EJOR</em>, <em>290</em>(1), 331–345. (<a
href="https://doi.org/10.1016/j.ejor.2020.07.056">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the joint determination of optimal investment and optimal depollution in a spatiotemporal framework where pollution is transboundary. Pollution is controlled at a global level. The regulator internalizes that: (i) production generates pollution, which is bad for the wellbeing of population, and that (ii) pollution flows across space driven by a diffusion process. We solve analytically for the optimal investment and depollution spatiotemporal paths and characterize the optimal long-term spatial distribution when relevant. We finally explore numerically the variety of optimal spatial distributions obtained using a core/periphery model where the core differs from the periphery either in terms of input productivity, depollution efficiency, environmental awareness or self-cleaning capacity of nature. We also compare the distributions with and without diffusion. Key aspects in the optimal policy of the regulator are the role of aversion to inequality, notably leading to smoothing consumption across locations, and the control of diffusive pollution adding another smoothing engine.},
  archive      = {J_EJOR},
  author       = {Raouf Boucekkine and Giorgio Fabbri and Salvatore Federico and Fausto Gozzi},
  doi          = {10.1016/j.ejor.2020.07.056},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {331-345},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {From firm to global-level pollution control: The case of transboundary pollution},
  volume       = {290},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Pricing discretely-monitored double barrier options with
small probabilities of execution. <em>EJOR</em>, <em>290</em>(1),
313–330. (<a href="https://doi.org/10.1016/j.ejor.2020.07.044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a new stochastic simulation-based methodology for pricing discretely-monitored double barrier options and estimating the corresponding probabilities of execution. We develop our framework by employing a versatile tool for the estimation of rare event probabilities known as subset simulation algorithm. In this regard, considering plausible dynamics for the price evolution of the underlying asset, we are able to compare and demonstrate clearly that our treatment always outperforms the standard Monte Carlo approach and becomes substantially more efficient (measured in terms of the sample coefficient of variation) when the underlying asset has high volatility and the barriers are set close to the spot price of the underlying asset. In addition, we test and report that our approach performs better when it is compared to the multilevel Monte Carlo method for special cases of barrier options and underlying assets that make the pricing problem a rare event estimation. These theoretical findings are confirmed by numerous simulation results.},
  archive      = {J_EJOR},
  author       = {Vasileios E. Kontosakos and Keegan Mendonca and Athanasios A. Pantelous and Konstantin M. Zuev},
  doi          = {10.1016/j.ejor.2020.07.044},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {313-330},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Pricing discretely-monitored double barrier options with small probabilities of execution},
  volume       = {290},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Optimizing tactical harvest planning for multiple fruit
orchards using a metaheuristic modeling approach. <em>EJOR</em>,
<em>290</em>(1), 297–312. (<a
href="https://doi.org/10.1016/j.ejor.2020.08.015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In a fruit harvest season, the fruit must be collected during a relatively short period of intense activity. Moreover, large fruit export companies commonly manage multiple orchards where the resources and labor are shared, making the decision process more complex. In this study, we address this harvest problem by proposing a mixed integer linear programming model for supporting tactical decisions during the harvest season in order to reduce total costs. This includes costs related to the fruit not reaching maturity and the number of harvest days. Due to the difficulty of solving this model optimally when real cases are considered, we developed a GRASP metaheuristic method. We compared the GRASP metaheuristic solution to the best integer solution obtained by an exact method using a real case. We observed that the metaheuristic produced a solution in less computational time than the best integer solution. The total costs obtained by the GRASP metaheuristic were two percent greater than the total cost obtained by the best integer solution. Additionally, we analyzed two scenarios to establish if the joint resource planning of the orchards would allow a cost reduction. The GRASP metaheuristic provides orchard managers with a harvest plan in a timely manner and adds greater flexibility to the decision process. The proposed model can be used to plan the harvesting of a variety of fresh fruits.},
  archive      = {J_EJOR},
  author       = {Javier E. Gómez-Lagos and Marcela C. González-Araya and Wladimir E. Soto-Silva and Masly M. Rivera-Moraga},
  doi          = {10.1016/j.ejor.2020.08.015},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {297-312},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Optimizing tactical harvest planning for multiple fruit orchards using a metaheuristic modeling approach},
  volume       = {290},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Overcoming inefficiencies in the development of personalized
medicine. <em>EJOR</em>, <em>290</em>(1), 278–296. (<a
href="https://doi.org/10.1016/j.ejor.2020.08.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The pharmaceutical industry faces a radical change in its business model. Whereas one-size-fits-all blockbuster drugs dominated in the past, today technological breakthroughs like the decoding of the human genome allow pharmaceutical firms to develop more customized products. This so-called personalized medicine can only work if a product tandem of specialized drug and companion diagnostic test exists, making new product development processes interdependent. We consider a pharmaceutical firm and a diagnostic firm that develop such a product tandem for personalized medicine. We show that the dependence on each other and the diagnostic firm’s option to postpone R&amp;D activities lead to systematic inefficiencies in the development of personalized medicine. In practice, revenue-sharing and cost-sharing contracts are used to address such inefficiencies by better balancing and aligning the financial interests of drug and diagnostic manufacturers. We show that simple revenue-sharing and cost-sharing contracts can often, but not always, solve problems related to postponed or reduced investment, and we characterize settings where the pharmaceutical firm prefers revenue sharing over cost sharing. To account for different existing market structures, we compare the pharmaceutical firm’s contract preferences under regulated and free pharmaceutical pricing.},
  archive      = {J_EJOR},
  author       = {Daniel Lütkemeyer and H. Sebastian Heese and David A. Wuttke},
  doi          = {10.1016/j.ejor.2020.08.013},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {278-296},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Overcoming inefficiencies in the development of personalized medicine},
  volume       = {290},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Addressing systemic risk using contingent convertible debt –
a network analysis. <em>EJOR</em>, <em>290</em>(1), 263–277. (<a
href="https://doi.org/10.1016/j.ejor.2020.07.062">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We construct a balance sheet network model to study the interconnectedness of a banking system. A simulation analysis of the buffer effect of contingent convertible (CoCo) debt in controlling contagion in a theoretical banking network model is followed by calibrating the model using 13F filings. We find that CoCo debt conversion significantly mitigates systemic risk, with a dual-trigger CoCo debt design being more effective in protecting the surviving banks. A two-tranche CoCo debt design combines the benefits of single and dual-trigger CoCo debt. The trade-offs in different designs of CoCo triggers can be evaluated in a network simulation model, as developed in this work.},
  archive      = {J_EJOR},
  author       = {Aparna Gupta and Runzu Wang and Yueliang Lu},
  doi          = {10.1016/j.ejor.2020.07.062},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {263-277},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Addressing systemic risk using contingent convertible debt – a network analysis},
  volume       = {290},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A kernel-free double well potential support vector machine
with applications. <em>EJOR</em>, <em>290</em>(1), 248–262. (<a
href="https://doi.org/10.1016/j.ejor.2020.10.040">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a well-known machine learning technique, support vector machine (SVM) with a kernel function achieves much success in nonlinear binary classification tasks. Recently, some quadratic surface SVM models are proposed and studied by utilizing quadratic surfaces for nonlinear binary separations. In this paper, a kernel-free soft quartic surface SVM model is proposed by utilizing the double well potential function for highly nonlinear binary classification. Mathematical analysis on the theoretical properties of the proposed model, including the existence, uniqueness and support vector representation of optimal solutions, is shown. The sequential minimal optimization algorithm is adopted to implement the proposed model for computational efficiency. Numerical results on some artificial and public benchmark data sets demonstrate its effectiveness over well-known SVM models with or without kernel functions. The proposed model is extended to successfully handle some real-life corporate and personal credit data sets for applications.},
  archive      = {J_EJOR},
  author       = {Zheming Gao and Shu-Cherng Fang and Jian Luo and Negash Medhin},
  doi          = {10.1016/j.ejor.2020.10.040},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {248-262},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A kernel-free double well potential support vector machine with applications},
  volume       = {290},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Evaluating and selecting features via information theoretic
lower bounds of feature inner correlations for high-dimensional data.
<em>EJOR</em>, <em>290</em>(1), 235–247. (<a
href="https://doi.org/10.1016/j.ejor.2020.09.028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selection is an important preprocessing and interpretable method in the fields where big data plays an essential role. In this paper, we first reformulate and analyze some representative information theoretic feature selection methods from the perspective of approximations of feature inner correlations, and indicate that many of these methods cannot guarantee any theoretical bounds of feature inner correlations. We thus introduce two lower bounds that have very simple forms for feature redundancy and complementarity, and verify that they are closer to the optima than the existing lower bounds applied by some state-of-the-art information theoretic methods. A simple and effective feature selection method based on the proposed lower bounds is then proposed and empirically verified with a wide scope of real-world datasets. The experimental results show that the proposed method achieves promising improvement on feature selection, indicating the effectiveness of the feature criterion consisting of the proposed lower bounds of redundancy and complementarity.},
  archive      = {J_EJOR},
  author       = {Yishi Zhang and Ruilin Zhu and Zhijun Chen and Jie Gao and De Xia},
  doi          = {10.1016/j.ejor.2020.09.028},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {235-247},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Evaluating and selecting features via information theoretic lower bounds of feature inner correlations for high-dimensional data},
  volume       = {290},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Tensorial graph learning for link prediction in generalized
heterogeneous networks. <em>EJOR</em>, <em>290</em>(1), 219–234. (<a
href="https://doi.org/10.1016/j.ejor.2020.05.062">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tensorial graph learning frameworks are proposed for link predictions in heterogeneous, homogeneous and generalized heterogeneous networks. In these frameworks, tensorial graphs are used to represent different networks by incorporating node and edge tensors into the graphs. A tensorial graph kernel method is developed for link predictions in these networks using four types of, i.e. , structural, behavioral, content and node/edge characteristics, data. In this method, a n n -strand iterated algorithm and a tensorial graph based random walk algorithm are proposed to measure node similarities in different networks within the generalized heterogeneous networks, and a tensorial graph multi-kernel learning method is developed to integrate the results. Experimental results on two real-world social media databases show that the tensorial graph kernel method has better performance using all types of data than using one type of data alone or combinations of some types of data. The tensorial graph kernel method also performs considerably better than existing competitive methods.},
  archive      = {J_EJOR},
  author       = {Zhen-Yu Chen and Zhi-Ping Fan and Minghe Sun},
  doi          = {10.1016/j.ejor.2020.05.062},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {219-234},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Tensorial graph learning for link prediction in generalized heterogeneous networks},
  volume       = {290},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Optimizing the interaction between residents and attending
physicians. <em>EJOR</em>, <em>290</em>(1), 210–218. (<a
href="https://doi.org/10.1016/j.ejor.2020.08.019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We analyze how attending physicians should allocate their time between the residents they supervise and their own responsibilities. Under the assumption that a holding cost is incurred when residents and patients wait for a conference with the attending physician, we show that there are only two policies that could maximize the long-run average reward. Namely, it is optimal for the attending physician to start having consultations with the residents either when the residents can no longer examine new patients or as soon as there is a patient ready for conference. Furthermore, we show that the optimality condition is a simple threshold on the holding cost. We then characterize when each of these policies is profitable and the optimum number of residents (supervised by the attending physician) under each policy. We conclude that if a health care facility operates with the optimal number of residents, the two policies become the same and it is always optimal (and profitable) for the attending physician to start conferences with the residents as soon as there is a patient waiting.},
  archive      = {J_EJOR},
  author       = {Sigrún Andradóttir and Hayriye Ayhan},
  doi          = {10.1016/j.ejor.2020.08.019},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {210-218},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Optimizing the interaction between residents and attending physicians},
  volume       = {290},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Maximum entropy distributions with quantile information.
<em>EJOR</em>, <em>290</em>(1), 196–209. (<a
href="https://doi.org/10.1016/j.ejor.2020.07.052">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quantiles are available in various problems for developing probability distributions. In some problems quantiles are elicited from experts and used for fitting parametric models, which induce non-elicited information. In some other problems comparisons are made with a quantile of an assumed model which is noncommittal to the quantile information. The maximum entropy (ME) principle provides models that avoid these issues. However, the information theory literature has been mainly concerned about models based on moment information. This paper explores the ME models that are the minimum elaborations of the uniform and moment-based ME models by quantiles. This property provides diagnostics for the utility of elaboration in terms of the information value of each type of information over the other. The ME model with quantiles and moments is represented as the mixture of truncated distributions on consecutive intervals whose shapes and existence are determined by the moments. Elaborations of several ME distributions by quantiles are presented. The ME model based only on quantiles elicited by the fixed interval method possesses a useful property for pooling information elicited from multiple experts. The elaboration of Laplace distribution is an extension of the information theory connection with minimum risk under symmetric loss functions to the asymmetric linear loss. This extension produces a new Asymmetric Laplace distribution. Application examples compare ME priors with a parametric model fitted to elicited quantiles, illustrate measuring uncertainty and disagreement of economic forecasters based on elicited probabilities, and adjust ME models for a fundamental quantile in an inventory management problem.},
  archive      = {J_EJOR},
  author       = {Amirsaman H. Bajgiran and Mahsa Mardikoraem and Ehsan S. Soofi},
  doi          = {10.1016/j.ejor.2020.07.052},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {196-209},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Maximum entropy distributions with quantile information},
  volume       = {290},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Modelling and understanding count processes through a
markov-modulated non-homogeneous poisson process framework.
<em>EJOR</em>, <em>290</em>(1), 177–195. (<a
href="https://doi.org/10.1016/j.ejor.2020.07.022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Markov-modulated Poisson process is utilised for count modelling in a variety of areas such as queueing, reliability, network and insurance claims analysis. In this paper, we extend the Markov-modulated Poisson process framework through the introduction of a flexible frequency perturbation measure. This contribution enables known information of observed event arrivals to be naturally incorporated in a tractable manner, while the hidden Markov chain captures the effect of unobservable drivers of the data. In addition to increases in accuracy and interpretability, this method supplements analysis of the latent factors. Further, this procedure naturally incorporates data features such as over-dispersion and autocorrelation. Additional insights can be generated to assist analysis, including a procedure for iterative model improvement. Implementation difficulties are also addressed with a focus on dealing with large data sets, where latent models are especially advantageous due the large number of observations facilitating identification of hidden factors. Namely, computational issues such as numerical underflow and high processing cost arise in this context and in this paper, we produce procedures to overcome these problems. This modelling framework is demonstrated using a large insurance data set to illustrate theoretical, practical and computational contributions and an empirical comparison to other count models highlight the advantages of the proposed approach.},
  archive      = {J_EJOR},
  author       = {Benjamin Avanzi and Greg Taylor and Bernard Wong and Alan Xian},
  doi          = {10.1016/j.ejor.2020.07.022},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {177-195},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Modelling and understanding count processes through a markov-modulated non-homogeneous poisson process framework},
  volume       = {290},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Stochastic modeling of parallel process flows in
intra-logistics systems: Applications in container terminals and compact
storage systems. <em>EJOR</em>, <em>290</em>(1), 159–176. (<a
href="https://doi.org/10.1016/j.ejor.2020.08.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many intra-logistics systems, such as automated container terminals, distribution warehouses, and cross-docks, observe parallel process flows, which involve simultaneous (parallel) operations of independent resources while processing a job. When independent resources work simultaneously to process a common job, the effective service requirement of the job is difficult to estimate. For modeling simplicity, researchers tend to assume sequential operations of the resources. In this paper, we propose an efficient modeling approach for parallel process flows using two-phase servers . We develop a closed queuing network model to estimate system performance measures. Existing solution methods can evaluate the performance of closed queuing networks that consist of two-phase servers with exponential service times only. To solve closed queuing networks with general two-phase servers, we propose new solution methods: an approximate mean value analysis and a network aggregation dis-aggregation approach. We derive insights on the accuracy of the solution methods from numerical experiments. Although both solution methods are quite accurate in estimating performance measures, the network aggregation dis-aggregation approach consistently performs best. We illustrate the proposed modeling approach for two intra-logistic systems: a container terminal with automated guided vehicles and a shuttle-based compact storage system. Results show that approximating the simultaneous operations as sequential operations underestimates the container terminal throughput on average by 28\% and at maximum up to 47\%. Similarly, considering sequential operations of the resources in the compact storage system results in an underestimation of the throughput capacity up to 9\%.},
  archive      = {J_EJOR},
  author       = {Govind Lal Kumawat and Debjit Roy and René De Koster and Ivo Adan},
  doi          = {10.1016/j.ejor.2020.08.006},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {159-176},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Stochastic modeling of parallel process flows in intra-logistics systems: Applications in container terminals and compact storage systems},
  volume       = {290},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Optimisation model for multi-item multi-echelon supply
chains with nested multi-level products. <em>EJOR</em>, <em>290</em>(1),
144–158. (<a href="https://doi.org/10.1016/j.ejor.2020.08.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study proposes a mathematical optimisation model for the horizontal integration of the basic processes of production, inventory, and transportation planning on a tactical level. The model enables planning for cutting, assembly, transportation, and inventory while considering process times. Several items (raw materials, intermediate goods, finished products, and transport vehicles) are routed through a network. The general structure is defined by the layout of the supply network and the configurable multi-level bills of materials of products and transportation equipment, which can be converging, diverging, or mixed. To stress the practical applications of this study, we demonstrate how this generic model can be used and customised to solve an actual planning task in a multi-stage automotive production network using real industry data.},
  archive      = {J_EJOR},
  author       = {Mathias Quetschlich and André Moetz and Boris Otto},
  doi          = {10.1016/j.ejor.2020.08.005},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {144-158},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Optimisation model for multi-item multi-echelon supply chains with nested multi-level products},
  volume       = {290},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Approximate dynamic programming for the military aeromedical
evacuation dispatching, preemption-rerouting, and redeployment problem.
<em>EJOR</em>, <em>290</em>(1), 132–143. (<a
href="https://doi.org/10.1016/j.ejor.2020.08.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Military medical planners must consider how aeromedical evacuation (MEDEVAC) assets will be utilized when preparing for and supporting combat operations. This research examines the MEDEVAC dispatching, preemption-rerouting, and redeployment (DPR) problem. The intent of this research is to determine high-quality DPR policies that improve the performance of United States Army MEDEVAC systems and ultimately increase the combat casualty survivability rate. A discounted, infinite-horizon Markov decision process (MDP) model of the MEDEVAC DPR problem is formulated and solved via an approximate dynamic programming (ADP) strategy that utilizes a support vector regression value function approximation scheme within an approximate policy iteration algorithmic framework. The objective is to maximize the expected total discounted reward attained by the system. The applicability of the MDP model is examined via a notional, representative planning scenario based on high-intensity combat operations to defend Azerbaijan against a notional aggressor. Computational experimentation is performed to determine how selected problem features and algorithmic features affect the quality of solutions attained by the ADP-generated DPR policies and to assess the efficacy of the proposed solution methodology. The results from the computational experiments indicate the ADP-generated policies significantly outperform the two benchmark policies considered. Moreover, the results reveal that the average service time of high-precedence, time-sensitive requests decreases when an ADP policy is adopted during high-intensity conflicts. As the rate at which requests enter the MEDEVAC system increases, the performance gap between the ADP policy and the first benchmark policy (i.e., the currently practiced, closest-available dispatching policy) increases substantially. Conversely, as the rate at which requests enter the system decreases, the ADP performance improvement over both benchmark policies decreases, indicating the ADP policy provides little-to-no benefit over a myopic approach (e.g., as utilized in the benchmark policies) when the intensity of a conflict is low. Ultimately, this research informs the development and implementation of future tactics, techniques, and procedures for military MEDEVAC operations.},
  archive      = {J_EJOR},
  author       = {Phillip R. Jenkins and Matthew J. Robbins and Brian J. Lunday},
  doi          = {10.1016/j.ejor.2020.08.004},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {132-143},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Approximate dynamic programming for the military aeromedical evacuation dispatching, preemption-rerouting, and redeployment problem},
  volume       = {290},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Interactions of traceability and reliability optimization in
a competitive supply chain with product recall. <em>EJOR</em>,
<em>290</em>(1), 116–131. (<a
href="https://doi.org/10.1016/j.ejor.2020.08.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traceability which is a tracking capability used to identify the sources of many quality problems, such as product recalls, has become an important feature of supply chains. In this paper, we develop a game-theoretical model to study the interactions of supply chain traceability and product reliability optimization in a competitive supply chain with product recall. Specifically, we consider two competing manufacturers that may choose to invest in traceability on the basis of product reliability optimization, by using the Non-track, Mono-track, and Duo-track models, and then sell products through two competing retailers to customers who are concerned with the differentiation of the product, the channel, and the traceability. We derive the optimal traceability and product reliability strategies under the three tracking models with endogenous pricing, and demonstrate the equilibrium tracking strategies for two competing manufacturers. The results show that traceability can fully substitute product reliability when the traceability investment cost coefficient is low but it may improve product reliability when the cost coefficient is high and the reliability investment cost coefficient is low. Investing in traceability will always benefit the manufacturer itself, and may benefit the competitor who does not track when the traceability investment cost coefficient is large enough. Interestingly, we find that the profit of the manufacturer who invests in traceability is increasing in the traceability competition intensity.},
  archive      = {J_EJOR},
  author       = {Bin Dai and Yu Nu and Xia Xie and Jianbin Li},
  doi          = {10.1016/j.ejor.2020.08.003},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {116-131},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Interactions of traceability and reliability optimization in a competitive supply chain with product recall},
  volume       = {290},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Forecasting and planning during a pandemic: COVID-19 growth
rates, supply chain disruptions, and governmental decisions.
<em>EJOR</em>, <em>290</em>(1), 99–115. (<a
href="https://doi.org/10.1016/j.ejor.2020.08.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Policymakers during COVID-19 operate in uncharted territory and must make tough decisions. Operational Research – the ubiquitous ‘science of better’ – plays a vital role in supporting this decision-making process. To that end, using data from the USA, India, UK, Germany, and Singapore up to mid-April 2020, we provide predictive analytics tools for forecasting and planning during a pandemic. We forecast COVID-19 growth rates with statistical, epidemiological, machine- and deep-learning models, and a new hybrid forecasting method based on nearest neighbors and clustering. We further model and forecast the excess demand for products and services during the pandemic using auxiliary data (google trends) and simulating governmental decisions (lockdown). Our empirical results can immediately help policymakers and planners make better decisions during the ongoing and future pandemics.},
  archive      = {J_EJOR},
  author       = {Konstantinos Nikolopoulos and Sushil Punia and Andreas Schäfers and Christos Tsinopoulos and Chrysovalantis Vasilakis},
  doi          = {10.1016/j.ejor.2020.08.001},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {99-115},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Forecasting and planning during a pandemic: COVID-19 growth rates, supply chain disruptions, and governmental decisions},
  volume       = {290},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Analyzing the benefits of an integrated mobility system
using a matheuristic routing algorithm. <em>EJOR</em>, <em>290</em>(1),
81–98. (<a href="https://doi.org/10.1016/j.ejor.2020.07.060">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In many Western countries, governments are currently implementing an innovative demand-driven mobility policy. Providers of collective door-to-door transport, called dial-a-ride services , are increasingly invoked to replace unprofitable public transport in rural areas. This requires an integrated mobility system in which a user’s trip may consist of a combination of dial-a-ride services and regular public transport. In order to optimally integrate both systems from an operational point of view, dial-a-ride providers need to solve a challenging routing problem. Their flexible vehicle routes should be synchronized to the timetables of the remaining public transport services, while the optimal selection of the users’ transfer terminals depends on the actual structure of the dial-a-ride routes. This paper introduces a routing algorithm and integrated scheduling procedure to enforce this synchronization for problems of a realistic scale, enabling the design and operational implementation of an integrated mobility system. Experiments, performed on a new artificial benchmark data set with realistic characteristics, clearly indicate that from the perspective of the dial-a-ride providers, considerable operational benefits can be obtained by integrating public transport into their services. The resulting distance savings for the dial-a-ride vehicles are shown to depend on the operational characteristics of the system, the geographical distribution of the demand, and the ability to flexibly assign transfer terminals to user requests. Furthermore, the proposed algorithm is also very efficient in solving related problems in passenger and freight transport.},
  archive      = {J_EJOR},
  author       = {Yves Molenbruch and Kris Braekers and Patrick Hirsch and Marco Oberscheider},
  doi          = {10.1016/j.ejor.2020.07.060},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {81-98},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Analyzing the benefits of an integrated mobility system using a matheuristic routing algorithm},
  volume       = {290},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Alternate solution approaches for competitive hub location
problems. <em>EJOR</em>, <em>290</em>(1), 68–80. (<a
href="https://doi.org/10.1016/j.ejor.2020.07.018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study the hub location problem of an entrant airline that tries to maximize its share in a market with already existing competing players. The problem is modeled as a non-linear integer program, which is intractable for off-the-shelf commercial solvers, like CPLEX and Gurobi, etc. Hence, we propose four alternate approaches to solve the problem. The first among them uses the Kelley’s cutting plane method, the second is based on a mixed integer second order conic program reformulation, the third uses the Kelley’s cutting plane method within Lagrangian relaxation, while the fourth uses second order conic program within Lagrangian relaxation. On the basis of extensive numerical tests on well-known datasets (CAB and AP), we conclude that the Kelley’s cutting plane within Lagrangian relaxation is computationally the best. It is able to solve all the problem instances of upto 50 nodes within 1\% optimality gap in less than 10 minutes of CPU time.},
  archive      = {J_EJOR},
  author       = {Richa Tiwari and Sachin Jayaswal and Ankur Sinha},
  doi          = {10.1016/j.ejor.2020.07.018},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {68-80},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Alternate solution approaches for competitive hub location problems},
  volume       = {290},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Applying “peeling onion” approach for competitive analysis
in online scheduling with rejection. <em>EJOR</em>, <em>290</em>(1),
57–67. (<a href="https://doi.org/10.1016/j.ejor.2020.08.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, we consider the classical online scheduling problem with rejection on identical parallel machines. In particular, a series of independent jobs arriving online over time will be scheduled on the identical machines with the flexibility of rejection, which implies that each job is either rejected with a penalty cost or accepted and scheduled on one of the identical machines. In addition, the knowledge of each job J j , including the processing time p j , release date r j , and penalty cost e j , is disclosed upon arrival of this job. Our goal is to minimize the total completion time of the accepted jobs plus the total penalty cost of the rejected jobs. For this problem, we provide a deterministic polynomial time online algorithm named as Delayed Shortest Processing Time with Rejection, shortly as DSPTR. For the sake of analyzing the competitive ratio of DSPTR, we introduce an interesting and efficient approach entitled as “Peeling Onion”. By means of “Peeling Onion”, we demonstrate that DSPTR is a 2-competitive online algorithm and the bound is tight. We believe that the introduction of the analysis approach “Peeling Onion” could also be applied to other online optimization problems and yield a new perspective on competitive analysis in general.},
  archive      = {J_EJOR},
  author       = {Ran Ma and Sainan Guo},
  doi          = {10.1016/j.ejor.2020.08.009},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {57-67},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Applying “Peeling onion” approach for competitive analysis in online scheduling with rejection},
  volume       = {290},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A comparative analysis of two matheuristics by means of
merged local optima networks. <em>EJOR</em>, <em>290</em>(1), 36–56. (<a
href="https://doi.org/10.1016/j.ejor.2020.08.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a comparative analysis of two hybrid algorithms for solving combinatorial optimisation problems. The first one is a specific variant of an established family of techniques known as large neighbourhood search (LNS). The second one is a much more recent algorithm known as construct, merge, solve &amp; adapt (CMSA). Both approaches generate, in different ways, reduced sub-instances of the tackled problem instance at each iteration. The experimental analysis is conducted on two NP-hard combinatorial subset selection problems: the multidimensional knapsack problem and minimum common string partition. The results support the intuition that CMSA has advantages over the LNS variant in the context of problems for which solutions contain rather few items. Moreover, they show that the opposite may be the case for problems in which solutions contain rather many items. The analysis is supported by a new way of visualising the trajectories of the compared algorithms in terms of merged monotonic local optima networks.},
  archive      = {J_EJOR},
  author       = {Christian Blum and Gabriela Ochoa},
  doi          = {10.1016/j.ejor.2020.08.008},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {36-56},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A comparative analysis of two matheuristics by means of merged local optima networks},
  volume       = {290},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Two-agent scheduling of unit processing time jobs to
minimize total weighted completion time and total weighted number of
tardy jobs. <em>EJOR</em>, <em>290</em>(1), 26–35. (<a
href="https://doi.org/10.1016/j.ejor.2020.07.064">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we revisit a two-agent scheduling problem on a single machine with jobs of unit processing times. In this problem, we have two agents: agent A and agent B . Each agent has his/her own disjoint job set. The objective of agent A is to minimize the total weighted completion time, and the objective of agent B is to minimize the total weighted number of tardy jobs. The complexity of the decision version of the problem was proposed as open in Oron et al. (European Journal of Operational Research 244:86–99, 2015). We construct a reduction from a variant of Even-Odd Partition to show that this problem is NP-complete. Finally, we also propose a pseudo-polynomial algorithm and a dual FPTAS for the problem.},
  archive      = {J_EJOR},
  author       = {Long Wan and Jiajie Mei and Jiangze Du},
  doi          = {10.1016/j.ejor.2020.07.064},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {26-35},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Two-agent scheduling of unit processing time jobs to minimize total weighted completion time and total weighted number of tardy jobs},
  volume       = {290},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Objectives and methods in multi-objective routing problems:
A survey and classification scheme. <em>EJOR</em>, <em>290</em>(1),
1–25. (<a href="https://doi.org/10.1016/j.ejor.2020.07.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Transportation of goods and passengers plays an important role for companies and individuals in today’s globalized world. There exists a variety of road-based routing problems at all three strategic, tactical and operational planning levels. Examples include location routing problems, fleet management, vehicle routing and shortest path problems. To evaluate solution quality, multiple, usually conflicting objectives are considered. Aiming to provide practice-oriented decision support, multi-objective routing problems attract more and more attention in academic literature. This contribution offers a wide overview of which application-oriented multi-objective routing problems are treated and what kind of trade-off is investigated. Furthermore, the algorithmic approach is analyzed with regard to its fitness assignment strategy, i.e. how the multiple objectives are handled, and its search strategy to solve the problem. In order to structure the literature, we propose a classification in which every identified objective is sorted into a category and related to problem elements. Both problem-specific and general research gaps in multi-objective routing problems are identified and offer a starting point for future research. Lastly, fitness assignment strategies are extensively discussed and insights regarding their usage are given.},
  archive      = {J_EJOR},
  author       = {Sandra Zajac and Sandra Huber},
  doi          = {10.1016/j.ejor.2020.07.005},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {1-25},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Objectives and methods in multi-objective routing problems: A survey and classification scheme},
  volume       = {290},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Incorporating decision-maker’s preferences into the
automatic configuration of bi-objective optimisation algorithms.
<em>EJOR</em>, <em>289</em>(3), 1209–1222. (<a
href="https://doi.org/10.1016/j.ejor.2020.07.059">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic configuration (AC) methods are increasingly used to tune and design optimisation algorithms for problems with multiple objectives. Most AC methods use unary quality indicators, which assign a single scalar value to an approximation to the Pareto front, to compare the performance of different optimisers. These quality indicators, however, imply preferences beyond Pareto-optimality that may differ from those of the decision maker (DM). Although it is possible to incorporate DM’s preferences into quality indicators, e.g., by means of the weighted hypervolume indicator ( HV w HVw ), expressing preferences in terms of weight function is not always intuitive nor an easy task for a DM, in particular, when comparing the stochastic outcomes of several algorithm configurations. A more visual approach to compare such outcomes is the visualisation of their empirical attainment functions (EAFs) differences. This paper proposes using such visualisations as a way of eliciting information about regions of the objective space that are preferred by the DM. We present a method to convert the information about EAF differences into a HV w HVw that will assign higher quality values to approximation fronts that result in EAF differences preferred by the DM. We show that the resulting HV w HVw may be used by an AC method to guide the configuration of multi-objective optimisers according to the preferences of the DM. We evaluate the proposed approach on a well-known benchmark problem. Finally, we apply our approach to re-configuring, according to different DM’s preferences, a multi-objective optimiser tackling a real-world production planning problem arising in the manufacturing industry.},
  archive      = {J_EJOR},
  author       = {Juan Esteban Diaz and Manuel López-Ibáñez},
  doi          = {10.1016/j.ejor.2020.07.059},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1209-1222},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Incorporating decision-maker’s preferences into the automatic configuration of bi-objective optimisation algorithms},
  volume       = {289},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Performance assessment of upper secondary schools in italian
regions using a circular pseudo-malmquist index. <em>EJOR</em>,
<em>289</em>(3), 1188–1208. (<a
href="https://doi.org/10.1016/j.ejor.2020.07.050">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the relationship between students’ performance and the type of school attended during upper secondary education. The performance of three different types of schools (Liceo, Technical and Professional schools) in four Italian macroregions (North West, North East, Centre, South &amp; Islands) is investigated. A benchmarking analysis of the variability in students’ performance among regions (within macroregions) for cohorts of students attending Liceo is also conducted. The data was collected at the student level from the Italian Institute for the Evaluation of Education System (INVALSI), for the academic year 2017/18. Families with higher socio-economic status may self-select into Liceo, so a direct comparison with vocational schools could lead to biased conclusions regarding the impact of school type on student performance. To overcome this limitation, we used a Propensity Score Matching approach prior to the estimation of efficiency. A pseudo-Malmquist index, based on a metafrontier and satisfying the circular property, is developed. It enables comparing the location of the best-practice frontier for each type of school and the spread in the educational efficiency of the students attending each type of school. Thus, best performance of a given school type corresponds to the combined effect of these two aspects. This study is an interesting starting point to challenge the stereotypes that persist in Italy, especially concerning general and vocational studies and geographic differences in educational achievements.},
  archive      = {J_EJOR},
  author       = {Ana S. Camanho and Luisa Varriale and Flávia Barbosa and Thiago Sobral},
  doi          = {10.1016/j.ejor.2020.07.050},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1188-1208},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Performance assessment of upper secondary schools in italian regions using a circular pseudo-malmquist index},
  volume       = {289},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Incentive rate determination in viral marketing.
<em>EJOR</em>, <em>289</em>(3), 1169–1187. (<a
href="https://doi.org/10.1016/j.ejor.2020.07.046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In viral marketing campaigns, incentivized consumers can act as sales agents by sharing information. In this study, we investigate the problem of incentive rate determination over a network of consumers to maximize the profit of a single good by a monopolist. For this purpose, we develop an epidemic spreading model to explore the dynamics of a viral marketing campaign under network externalities and incentivized individuals. We will examine two cases of homogeneous and heterogeneous incentive rates. In each case, we derive an N -intertwined dynamics model and obtain the existence and stability conditions of a trade-free or an endemic equilibrium. By treating the incentive as a control parameter, we investigate the problem of maximizing the monopolist’s profit by formulating two nonlinear programming models. In the case of homogeneous incentive rates, results show that the optimal incentive is determined by devising a balance between the consumers’ states in the Markov process. In the heterogeneous case, it is observed that despite the existence of a strong correlation with different centrality measures, the optimal incentive allocation cannot be solely determined by centrality measures.},
  archive      = {J_EJOR},
  author       = {Ali Tavasoli and Heman Shakeri and Ehsan Ardjmand and William A. Young II},
  doi          = {10.1016/j.ejor.2020.07.046},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1169-1187},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Incentive rate determination in viral marketing},
  volume       = {289},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Pickup and delivery problem with recharging for material
handling systems utilising autonomous mobile robots. <em>EJOR</em>,
<em>289</em>(3), 1153–1168. (<a
href="https://doi.org/10.1016/j.ejor.2020.07.049">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Whereas automated guided vehicles (AGVs) have traditionally been used for material handling, the utilisation of autonomous mobile robots (AMRs) is growing quickly owing to their scalability, versatility, and lower costs. In this paper, we address the pickup and delivery problem with consideration of the characteristics of AMRs in manufacturing environments. To solve the problem, we first propose a new mathematical formulation with consideration of both partial and full recharging strategies for minimisation of the total tardiness of transportation requests. We then propose two constructive heuristic algorithms with high computation speed, which are called the Transportation-Request-Initiated Grouping Algorithm (TRIGA) and the Vehicle-Initiated Grouping Algorithm (VIGA). Additionally, we develop a memetic algorithm (MA) that incorporates a genetic algorithm into local-search techniques for finding near-optimal solutions within a reasonable time. We evaluate the performance of the proposed algorithms in comparison with two dispatching rules, genetic algorithm, and neighbourhood search through simulation experiments with three sets of problem instances under different battery levels. The simulation results indicate that the proposed algorithms outperform the others with regard to the average total tardiness and the relative deviation index.},
  archive      = {J_EJOR},
  author       = {Sungbum Jun and Seokcheon Lee and Yuehwern Yih},
  doi          = {10.1016/j.ejor.2020.07.049},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1153-1168},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Pickup and delivery problem with recharging for material handling systems utilising autonomous mobile robots},
  volume       = {289},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Optimal warranty policy with inspection for heterogeneous,
stochastically degrading items. <em>EJOR</em>, <em>289</em>(3),
1142–1152. (<a
href="https://doi.org/10.1016/j.ejor.2020.07.045">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A new renewable warranty policy is suggested that increases probability of its success and can decrease warranty costs. An item from a heterogeneous population is inspected at some intermediate time during a warranty period and, if the observed level of degradation/wear exceeds some optimally predetermined value, it is screened out and replaced by the new one. Deterioration in homogeneous subpopulations of items is modeled by the inverse-Gaussian (IG) process, whereas heterogeneous populations are described by the mixed IG process. Probabilistic and cost analyses of the model are performed and the detailed illustrative example is presented and discussed.},
  archive      = {J_EJOR},
  author       = {Ji Hwan Cha and Maxim Finkelstein and Gregory Levitin},
  doi          = {10.1016/j.ejor.2020.07.045},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1142-1152},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Optimal warranty policy with inspection for heterogeneous, stochastically degrading items},
  volume       = {289},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Time (in)consistency of multistage distributionally robust
inventory models with moment constraints. <em>EJOR</em>,
<em>289</em>(3), 1127–1141. (<a
href="https://doi.org/10.1016/j.ejor.2020.07.041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, there has been a growing interest in developing inventory control policies which are robust to model misspecification. One approach is to posit that nature selects a worst-case distribution for any relevant stochastic primitives from some pre-specified family. Several communities have observed that a subtle phenomena known as time inconsistency can arise in this framework. In particular, it becomes possible that a policy which is optimal at time zero may not be optimal for the associated optimization problem in which the decision-maker recomputes her policy at each point in time, which has implications for implementability. If there exists a policy which is optimal for both formulations, we say that the policy is time consistent , and the problem is weakly time consistent . If every optimal policy is time consistent, we say that the problem is strongly time consistent . We study these phenomena in the context of managing an inventory over time, when only the mean, variance, and support are known for the demand at each stage. We provide several illustrative examples showing that here the question of time consistency can be quite subtle. We complement these observations by providing simple sufficient conditions for weak and strong time consistency. Although a similar phenomena was previously identified by Shapiro for the setting in which only the mean and support of the demand are known, here our model is rich enough to exhibit a variety of additional interesting behaviors.},
  archive      = {J_EJOR},
  author       = {Linwei Xin and David A. Goldberg},
  doi          = {10.1016/j.ejor.2020.07.041},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1127-1141},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Time (in)consistency of multistage distributionally robust inventory models with moment constraints},
  volume       = {289},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Capacitated multi-period maximal covering location problem
with server uncertainty. <em>EJOR</em>, <em>289</em>(3), 1107–1126. (<a
href="https://doi.org/10.1016/j.ejor.2020.07.061">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the problem of assigning doctors to existing, non-operational Primary Health Centers (PHCs). We do this in the presence of clear guidelines on the maximum population that can be served by any PHC, and uncertainties in the availability of the doctors over the planning horizon. We model the problem as a robust capacitated multi-period maximal covering location problem with server uncertainty. Such supply-side uncertainties have not been accounted for in the context of multi-period facility location in the extant literature. We present an MIP formulation of this problem, which turns out to be too difficult for an off-the-shelf solver like CPLEX. We, therefore, present several dominance rules to reduce the size of the model. We further propose a Benders decomposition based solution method with several refinements that exploit the underlying structure of the problem to solve it extremely efficiently. Our computational experiments show one of the variants of our Benders decomposition based method to be on average almost 1000 times faster, compared to the CPLEX MIP solver, for problem instances containing 300 demand nodes and 10 facilities. Further, while the CPLEX MIP solver could not solve most of the instances beyond 300 demand nodes and 10 facilities even after 20 hours, two of our variants of Benders decomposition could solve instances upto the size of 500 demand nodes and 15 facilities in less than 0.5 hour, on average.},
  archive      = {J_EJOR},
  author       = {Amit Kumar Vatsa and Sachin Jayaswal},
  doi          = {10.1016/j.ejor.2020.07.061},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1107-1126},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Capacitated multi-period maximal covering location problem with server uncertainty},
  volume       = {289},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Stochastic single-allocation hub location. <em>EJOR</em>,
<em>289</em>(3), 1087–1106. (<a
href="https://doi.org/10.1016/j.ejor.2020.07.051">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper considers the single allocation hub location problem under demand uncertainty where the allocation of the spokes to the hubs is optimized as second stage decision after the uncertainty in the demand is realized. We refer to this case as the variable allocation case, meaning that the allocation of the spokes to the hubs can be altered after the uncertainty is realized. This is in contrast to the fixed allocation case that is addressed in the literature, where the spokes are allocated to the chosen hubs before the uncertainty is realized. As shown in the paper, the fixed allocation case can be solved as a deterministic problem using the expected values of the random variables. However, the variable allocation model is a two-stage stochastic program that is challenging to solve. An alternative convex mixed-integer nonlinear formulation is presented for the variable allocation and a customized solution approach based on cutting planes is proposed to address the computational challenges. The proposed solution approach is implemented in a branch-and-cut framework where the cut-generating subproblems are solved combinatorially, i.e. without an optimization solver. Extensive computational results on the single allocation hub location problem and two of its variants, the capacitated case and the single allocation p -median problem are presented. The proposed cutting plane approach outperforms the direct solution of the problem using the state-of-the-art solver GUROBI as well the L-shaped decomposition, which is a common approach for addressing two-stage stochastic programs with recourse.},
  archive      = {J_EJOR},
  author       = {Borzou Rostami and Nicolas Kämmerling and Joe Naoum-Sawaya and Christoph Buchheim and Uwe Clausen},
  doi          = {10.1016/j.ejor.2020.07.051},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1087-1106},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Stochastic single-allocation hub location},
  volume       = {289},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Neighborhood decomposition based variable neighborhood
search and tabu search for maximally diverse grouping. <em>EJOR</em>,
<em>289</em>(3), 1067–1086. (<a
href="https://doi.org/10.1016/j.ejor.2020.07.048">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The maximally diverse grouping problem (MDGP) is a relevant NP-hard optimization problem with a number of real-world applications. However, solving large instances of the problem is computationally challenging. This work is dedicated to a new heuristic algorithm for the problem, which distinguishes itself by two original features. First, it introduces the first neighborhood decomposition strategy to accelerate neighborhood examinations. Second, it integrates, in a probabilistic way, two complementary neighborhood decomposition based local search procedures (variable neighborhood descent and tabu search) as well as an adaptive perturbation strategy to ensure a suitable balance between intensification and diversification of the search space. Computational results on 320 benchmark instances commonly used in the literature show that the proposed algorithm competes favorably with the state-of-the-art MDGP algorithms, by reporting improved best-known results (new lower bounds) of the literature for 220 large instances. Additional experiments are conducted to analyze the main components of the algorithm. The proposed algorithm can help to better solve practical problems that can be formulated by the maximally diverse grouping model.},
  archive      = {J_EJOR},
  author       = {Xiangjing Lai and Jin-Kao Hao and Zhang-Hua Fu and Dong Yue},
  doi          = {10.1016/j.ejor.2020.07.048},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1067-1086},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Neighborhood decomposition based variable neighborhood search and tabu search for maximally diverse grouping},
  volume       = {289},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Tailored heuristics in adaptive large neighborhood search
applied to the cutwidth minimization problem. <em>EJOR</em>,
<em>289</em>(3), 1056–1066. (<a
href="https://doi.org/10.1016/j.ejor.2019.07.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The cutwidth minimization problem (CMP) consists in determining a linear layout (i.e., a one-dimensional arrangement), of the vertices of a graph that minimizes the maximum number of edges crossing any consecutive pair of vertices. This problem has applications, for instance, in design of very large-scale integration circuits, graph drawing, and compiler design. The CMP is an NP NP -Hard problem and presents a challenge to exact methods and heuristics. In this study, the metaheuristic adaptive large neighborhood search is applied to the CMP. The computational experiments include 11,786 benchmark instances from four sets in the literature, and the obtained results are compared with state-of-the-art methods. The proposed method was demonstrated to be competitive, as it matched most optimal and best known results, improved some of the (not proved optimal) best known solutions, and provided the first upper bounds for unsolved instances.},
  archive      = {J_EJOR},
  author       = {Vinícius Gandra Martins Santos and Marco Antonio Moreira de Carvalho},
  doi          = {10.1016/j.ejor.2019.07.013},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1056-1066},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Tailored heuristics in adaptive large neighborhood search applied to the cutwidth minimization problem},
  volume       = {289},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-warehouse package consolidation for split orders in
online retailing. <em>EJOR</em>, <em>289</em>(3), 1040–1055. (<a
href="https://doi.org/10.1016/j.ejor.2019.07.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid growth of the online market in recent years, order splitting has become a great challenge to online retailers for fulfilling multi-item orders in a multi-warehouse storage network. Order splitting can lead to higher shipping costs, the use of more packages, and possible dissatisfaction from customers. This paper presents a multi-warehouse package consolidation approach aimed at consolidating multiple suborders’ stock-keeping units (SKUs) through transshipments among warehouses. A combined multi-commodity network flow model is proposed to determine the consolidation warehouses for each order and make transshipment decisions for individual SKUs. An enhanced logic-based Benders’ decomposition algorithm is proposed to decompose the model into a general multi-commodity network flow master problem and a set of bin packing with conflicts sub-problems. Two proposed Benders’ cuts guarantee the algorithm to converge to optimality. The proposed algorithm can generate the near-optimal result with only about 25\% of the CPU time required by CPLEX to solve the proposed model. Numerical experiments reveal that the proposed package consolidation approach outperforms the order splitting fulfillment approach in reducing the total costs, the number of packages, and the delivery times, especially for cases with a small number of SKUs in each suborder which are typical for online retailers. Sensitivity analyses are performed to provide managerial insights of adopting the proposed approach in the real world where order splitting is a common phenomenon.},
  archive      = {J_EJOR},
  author       = {Zhang Yuankai and Lin Wei-Hua and Huang Minfang and Hu Xiangpei},
  doi          = {10.1016/j.ejor.2019.07.004},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1040-1055},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Multi-warehouse package consolidation for split orders in online retailing},
  volume       = {289},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A parametric approach to integer linear fractional
programming: Newton’s and hybrid-newton methods for an optimal road
maintenance problem. <em>EJOR</em>, <em>289</em>(3), 1030–1039. (<a
href="https://doi.org/10.1016/j.ejor.2019.07.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we study a parametric approach, one of the resolution methods for solving integer linear fractional programming (ILFP) problems in which all functions in the objective and constraints are linear and all variables are integers. We develop a novel complexity bound of Newton’s method applied to ILFP problems when variables are bounded. The analytical result for the worst-case performance shows that the number of iterations of Newton’s algorithm to find an optimal solution of the ILFP problem is polynomially bounded. We also propose a Hybrid-Newton algorithm and empirically show that it is relatively faster and more robust than the Newton algorithm under various data scenarios. To illustrate the applicability of our algorithm and provide concrete managerial prescriptions, we consider a case study of a road maintenance planning problem in Seoul, Korea. The results show that our fractional efficiency measure is capable of obtaining the maximum cost-efficient lifetime of a road given a limited maintenance budget.},
  archive      = {J_EJOR},
  author       = {Chong Hyun Park and Heejong Lim},
  doi          = {10.1016/j.ejor.2019.07.010},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1030-1039},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A parametric approach to integer linear fractional programming: Newton’s and hybrid-newton methods for an optimal road maintenance problem},
  volume       = {289},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The generalized reserve set covering problem with
connectivity and buffer requirements. <em>EJOR</em>, <em>289</em>(3),
1013–1029. (<a
href="https://doi.org/10.1016/j.ejor.2019.07.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The design of nature reserves is becoming, more and more, a crucial task for ensuring the conservation of endangered wildlife. In order to guarantee the preservation of species and a general ecological functioning, the designed reserves must typically verify a series of spatial requirements. Among the required characteristics, practitioners and researchers have pointed out two crucial aspects: (i) connectivity, so as to avoid spatial fragmentation, and (ii) the design of buffer zones surrounding (or protecting) so-called core areas. In this paper, we introduce the Generalized Reserve Set Covering Problem with Connectivity and Buffer Requirements . This problem extends the classical Reserve Set Covering Problem and allows to address these two requirements simultaneously. A solution framework based on Integer Linear Programming and branch-and-cut is developed. The framework is enhanced by valid inequalities, a construction and a primal heuristic and local branching. The problem and the framework are presented in a modular way to allow practitioners to select the constraints fitting to their needs and to analyze the effect of e.g., only enforcing connectivity or buffer zones. An extensive computational study on grid-graph instances and real-life instances based on data from three states of the U.S. and one region of Australia is carried out to assess the suitability of the proposed model to deal with the challenges faced by decision-makers in natural reserve design. In the study, we also analyze the effects on the structure of solutions when only enforcing connectivity or buffer zones or just solving a generalized version of the classical Reserve Set Covering Problem. The results show, on the one hand, the flexibility of the proposed models to provide solutions according to the decision-makers’ requirements, and on the other hand, the effectiveness of the devised algorithm for providing good solutions in reasonable computing times.},
  archive      = {J_EJOR},
  author       = {Eduardo Álvarez-Miranda and Marcos Goycoolea and Ivana Ljubić and Markus Sinnl},
  doi          = {10.1016/j.ejor.2019.07.017},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1013-1029},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {The generalized reserve set covering problem with connectivity and buffer requirements},
  volume       = {289},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Provision-after-wait with preferences ordered by difference:
Tighter complexity and better approximation. <em>EJOR</em>,
<em>289</em>(3), 1008–1012. (<a
href="https://doi.org/10.1016/j.ejor.2019.07.047">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Braverman et al. [Math. Oper. Res. 41(1), (2016), pp. 352–376], introduce the problem Provision-after-Wait which is to find a stable (envy free) assignment of n patients to m hospitals, and their waiting times before admission, such that the social welfare is maximized, subject to a limited budget. Chan et al. [ACM Trans. Econ. Comput. 5(2), (2017), Article 12, pp. 12:1–12:36] focus on a natural case of d-ordered preferences , in which patients are ordered according to the differences of their values between consecutive hospitals. For this case, they provide a sophisticated proof of ordinary NP-hardness, reduce it to the problem called Ordered Knapsack, and develop a fully polynomial time approximation scheme for Ordered Knapsack. We present a simple proof that Ordered Knapsack is NP-hard, which implies NP-hardness of a more restrictive case of the original problem, and present an alternative fully polynomial time approximation scheme with a reduced run time by a quadratic factor of n , for a fixed m . A similar algorithm is developed to find a solution for which the social welfare is as high as for the optimal solution of Ordered Knapsack, and the budget limit can be exceeded by at most 1 + ε 1+ε times. We also present polynomial algorithms for the cases of Ordered Knapsack, in which the number of distinct input parameters is fixed.},
  archive      = {J_EJOR},
  author       = {Mikhail Y. Kovalyov and Erwin Pesch and Alain Quilliot},
  doi          = {10.1016/j.ejor.2019.07.047},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1008-1012},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Provision-after-wait with preferences ordered by difference: Tighter complexity and better approximation},
  volume       = {289},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The assignment and loading transportation problem.
<em>EJOR</em>, <em>289</em>(3), 999–1007. (<a
href="https://doi.org/10.1016/j.ejor.2019.07.039">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a generalization of the multiple knapsack problem that combines assignment and loading. The problem can arise in military and emergency situations in which one is required to refurnish a unit with a number of different goods available at different locations. We present a mathematical model and study Lagrangian and surrogate relaxations. We propose heuristic and metaheuristic approaches which we use to develop two overall approximation algorithms: a self-contained polynomial-time heuristic and a more time consuming matheuristic approach that makes use of a MILP solver. Solution times and accuracy of lower and upper bounds are computationally evaluated on a real military data set and on sets of both realistic and randomly generated instances.},
  archive      = {J_EJOR},
  author       = {Gabriel Homsi and Jeremy Jordan and Silvano Martello and Michele Monaci},
  doi          = {10.1016/j.ejor.2019.07.039},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {999-1007},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {The assignment and loading transportation problem},
  volume       = {289},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The multiple multidimensional knapsack with family-split
penalties. <em>EJOR</em>, <em>289</em>(3), 987–998. (<a
href="https://doi.org/10.1016/j.ejor.2019.07.052">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Multiple Multidimensional Knapsack Problem with Family-Split Penalties (MMdKFSP) is introduced as a new variant of both the more classical Multi-Knapsack and Multidimensional Knapsack Problems. It reckons with items categorized into families and where if an individual item is selected to maximize the profit, all the items of the same family must be selected as well. Items belonging to the same family can be assigned to different knapsacks; however, in this case, split penalties are incurred. This problem arises in resource management of distributed computing contexts and Service Oriented Architecture environments. An exact algorithm based on the exploitation of a specific combinatorial Benders’ cuts approach is proposed. Computational experiments on different sets of benchmark test problems show the effectiveness of the proposed algorithm. The comparison against a state-of-the-art commercial solver confirms the validity of the proposed approach considering also the scalability issue.},
  archive      = {J_EJOR},
  author       = {Simona Mancini and Michele Ciavotta and Carlo Meloni},
  doi          = {10.1016/j.ejor.2019.07.052},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {987-998},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {The multiple multidimensional knapsack with family-split penalties},
  volume       = {289},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A new extended formulation with valid inequalities for the
capacitated concentrator location problem. <em>EJOR</em>,
<em>289</em>(3), 975–986. (<a
href="https://doi.org/10.1016/j.ejor.2019.07.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a new disaggregated formulation of the Capacitated Concentrator Location Problem (CCLP) using the notion of cardinality of terminals assigned to a concentrator. This formulation consists of O( mnn ) variables and constraints, where m denotes the number of concentrators and n the number of terminals, respectively. We prove that this extended formulation is stronger than the traditional one. We also present two classes of inequalities exploiting the cardinality effect of the extended formulation. The first class is a generalization of the well-known Cover and (1, k )-Configuration inequalities, which collectively are stronger than the original Cover and (1, k )-Configuration inequalities. The second class, called the 2-Facility Cardinality Matching Inequality, holds for the uncapacitated version of the Concentrator Location Problem and can be lifted to become a strong inequality for CCLP. We solve the LP relaxation of the extended formulation and use separation heuristics to identify and sequentially add the previous valid inequalities to improve the lower bound. This approach is embedded in a branch-and-bound and results in a branch-and-cut approach. We test our solution approach on a large set of benchmark problems. The experimentation shows that we can identify the optimal solution at the root node in most of the problem instances with up to 50 concentrators and 50 terminals. For larger sized test problems with up to 100 concentrators and 1000 terminals, the branch-and-cut procedure using the disaggregated formulation outperforms the branch-and-cut procedure applied to the traditional formulation both in terms of CPU and the required number of branch-and-bound nodes.},
  archive      = {J_EJOR},
  author       = {Massimo Di Francesco and Manlio Gaudioso and Enrico Gorgone and Ishwar Murthy},
  doi          = {10.1016/j.ejor.2019.07.008},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {975-986},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A new extended formulation with valid inequalities for the capacitated concentrator location problem},
  volume       = {289},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). On single-source capacitated facility location with cost and
fairness objectives. <em>EJOR</em>, <em>289</em>(3), 959–974. (<a
href="https://doi.org/10.1016/j.ejor.2019.07.045">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a location problem where a planner has to decide where to open facilities which have to be reached by customers at their own cost. The planner has two objectives: cost minimization and customer satisfaction. We argue that performance and fairness, as structural components of customer satisfaction, are both captured by an equity measure called conditional β -mean. We thus formulate the Fair Single-Source Capacitated Facility Location (F-SSCFL) problem, where the cost minimization objective is paired with the conditional β -mean minimization objective. The resulting formulation is a bi-objective mixed-integer linear program. A weighted sum method is developed to generate a small representative set of efficient solutions to the F-SSCFL problem, and a Benders decomposition approach is implemented to handle large-scale instances. On small/medium-scale instances, we analyse the trade-off between cost and conditional β -mean, showing that the model may be used as a managerial tool to balance direct costs and customer service. We also compare the quality of the solutions obtained with those obtained using alternative equity measures. On large-scale instances, we test Benders decomposition, showing that it is able to find good quality solutions in a relatively short computing time.},
  archive      = {J_EJOR},
  author       = {C. Filippi and G. Guastaroba and M.G. Speranza},
  doi          = {10.1016/j.ejor.2019.07.045},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {959-974},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {On single-source capacitated facility location with cost and fairness objectives},
  volume       = {289},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-objective optimization of a two-echelon vehicle
routing problem with vehicle synchronization and “grey zone” customers
arising in urban logistics. <em>EJOR</em>, <em>289</em>(3), 940–958. (<a
href="https://doi.org/10.1016/j.ejor.2019.07.049">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a multi-ob’jective two-echelon vehicle routing problem with vehicle synchronization and ‘grey zone’ customers arising in the context of urban freight deliveries. Inner-city center deliveries are performed by small vehicles due to access restrictions, while deliveries outside this area are carried out by conventional vehicles for economic reasons. Goods are transferred from the first to the second echelon by synchronized meetings between vehicles of the respective echelons. We investigate the assignment of customers to vehicles, i.e., to the first or second echelon, within a so-called ‘grey zone’ on the border of the inner city and the area around it. While doing this, the economic objective as well as negative external effects of transport, such as emissions and disturbance (negative impact on citizens due to noise and congestion), are taken into account to include objectives of companies as well as of citizens and municipal authorities. Our metaheuristic – a large neighborhood search embedded in a heuristic rectangle/cuboid splitting – addresses this problem efficiently. We investigate the impact of the free assignment of part of the customers (‘grey zone’) to echelons and of three different city layouts on the solution. Computational results show that the impact of a ‘grey zone’ and thus the assignment of these customers to echelons depend significantly on the layout of a city. Potentially pareto-optimal solutions for two and three objectives are illustrated to efficiently support decision makers in sustainable city logistics planning processes.},
  archive      = {J_EJOR},
  author       = {Alexandra Anderluh and Pamela C. Nolz and Vera C. Hemmelmayr and Teodor Gabriel Crainic},
  doi          = {10.1016/j.ejor.2019.07.049},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {940-958},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Multi-objective optimization of a two-echelon vehicle routing problem with vehicle synchronization and ‘grey zone’ customers arising in urban logistics},
  volume       = {289},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Bunkering policies for a fuel bunker management problem for
liner shipping networks. <em>EJOR</em>, <em>289</em>(3), 927–939. (<a
href="https://doi.org/10.1016/j.ejor.2019.07.044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the problem of bunker fuel management for liner shipping networks under different fuel pricing scenarios and taking into consideration different fuel bunkering policies. The fuel consumption of a vessel on a sailing leg may fluctuate as the real vessel speed deviates from the planned vessel speed. Furthermore, fluctuation of fuel prices at various ports increases the complexity of bunkering decisions related to the selection of the bunkering ports and the estimation of bunkered fuel cost. We have developed a mixed integer non-linear programming model to minimize the total expected cost consisting of inventory cost related to container transportation, operating cost associated with ship hiring, as well as bunkering cost and fuel consumption cost at the port. The novelty of our research lies in its consideration of stochastic fuel consumption for different sailing legs, stochastic fuel prices at each port and different fuel bunkering policies to determine optimal bunker fuel management strategies for the selection of bunkering ports and for the estimation of the amount of bunkered fuel required. We have proposed a novel approximate algorithm based on mathematical formulation and the fuel bunkering policies to calculate the total expected cost; the fuel inventory while arriving at and departing from the port; the number of vessels hired for weekly service; the arrival and departure time of the ship; and the amount of fuel bunkered at a port. We have performed extensive computational experiments on the practical routes to demonstrate the applicability, efficacy and robustness of the proposed novel methodology.},
  archive      = {J_EJOR},
  author       = {Arijit De and Alok Choudhary and Metin Turkay and Manoj K. Tiwari},
  doi          = {10.1016/j.ejor.2019.07.044},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {927-939},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Bunkering policies for a fuel bunker management problem for liner shipping networks},
  volume       = {289},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Simulation-based optimisation for stochastic maintenance
routing in an offshore wind farm. <em>EJOR</em>, <em>289</em>(3),
912–926. (<a href="https://doi.org/10.1016/j.ejor.2019.08.032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Scheduling maintenance routing for an offshore wind farm is a challenging and complex task. The problem is to find the best routes for the Crew Transfer Vessels to maintain the turbines in order to minimise the total cost. This paper primarily proposes an efficient solution method to solve the deterministic maintenance routing problem in an offshore wind farm. The proposed solution method is based on the Large Neighbourhood Search metaheuristic. The efficiency of the proposed metaheuristic is validated against state of the art algorithms. The results obtained from the computational experiments validate the effectiveness of the proposed method. In addition, as the maintenance activities are affected by uncertain conditions, a simulation-based optimisation algorithm is developed to tackle these uncertainties. This algorithm benefits from the fast computational time and solution quality of the proposed metaheuristic, combined with Monte Carlo simulation. The uncertain factors considered include the travel time for a vessel to visit turbines, the required time to maintain a turbine, and the transfer time for technicians and equipment to a turbine. Moreover, the proposed simulation-based optimisation algorithm is devised to tackle unpredictable broken-down turbines. The performance of this algorithm is evaluated using a case study based on a reference wind farm scenario developed in the EU FP7 LEANWIND project.},
  archive      = {J_EJOR},
  author       = {Chandra Ade Irawan and Majid Eskandarpour and Djamila Ouelhadj and Dylan Jones},
  doi          = {10.1016/j.ejor.2019.08.032},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {912-926},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Simulation-based optimisation for stochastic maintenance routing in an offshore wind farm},
  volume       = {289},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A route decomposition approach for the single commodity
split pickup and split delivery vehicle routing problem. <em>EJOR</em>,
<em>289</em>(3), 897–911. (<a
href="https://doi.org/10.1016/j.ejor.2019.07.015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We address a single commodity Pickup and Delivery Vehicle Routing Problem from the literature. A network of customer nodes is given with both travel times and costs. A fleet of vehicles of limited capacity is exploited to satisfy node demands, and a set of routes must be found such that the vehicle capacities are never exceeded, each route does not exceed time resource, and cost is minimized. The demands of both pickup and delivery nodes can be split, and each node can be visited more than once. We provide new theoretical insights. We propose a new formulation where routes are decomposed into sequences of simpler substructures called clusters , mitigating the combinatorial explosion of feasible solutions. We introduce valid inequalities, and design a branch-and-price algorithm, exploiting ad hoc pricing routines and branching strategies, and embedding a rounding heuristic to speed up pruning. An extensive experimental analysis shows our method to offer simultaneously more modelling flexibility and more computational effectiveness than previous attempts from the literature. Our investigation opens also interesting insights into the use of route decomposition strategies.},
  archive      = {J_EJOR},
  author       = {Marco Casazza and Alberto Ceselli and Roberto Wolfler Calvo},
  doi          = {10.1016/j.ejor.2019.07.015},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {897-911},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A route decomposition approach for the single commodity split pickup and split delivery vehicle routing problem},
  volume       = {289},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A branch and cut algorithm for the time-dependent profitable
tour problem with resource constraints. <em>EJOR</em>, <em>289</em>(3),
879–896. (<a href="https://doi.org/10.1016/j.ejor.2019.07.014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we study the time-dependent profitable tour problem with resource constraints (TDPTPRC), a generalization of the profitable tour problem (PTP) which includes variable travel times to account for road congestion. In this problem, the set of customers to be served is not given and must be determined based on the profit collected when visited, keeping a balance with the total travel time. We propose a mixed integer linear programming (MILP) formulation that exploits the travel time function to reduce the size of a standard formulation from the literature. We derive four new families of valid inequalities and study the connections among them, as well as their associated separation problems. We develop a tailored Branch and Cut (BC) algorithm including these new families in addition to some well known valid inequalities from related problems. Computational results on four different problems, with alternative resources and objectives, show that the approach is flexible and effective. The algorithm achieves significant reductions in the computing times on benchmark instances from the related literature, and outperforms a recent method proposed for the time-dependent traveling salesman problem with time windows.},
  archive      = {J_EJOR},
  author       = {Gonzalo Lera-Romero and Juan José Miranda-Bront},
  doi          = {10.1016/j.ejor.2019.07.014},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {879-896},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A branch and cut algorithm for the time-dependent profitable tour problem with resource constraints},
  volume       = {289},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Prioritized single nurse routing and scheduling for home
healthcare services. <em>EJOR</em>, <em>289</em>(3), 867–878. (<a
href="https://doi.org/10.1016/j.ejor.2019.07.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study a real-life problem in which a nurse is required to check upon patients she is responsible for either by home visits or phone calls. Due to the large number of patients and their varying conditions, she has to select carefully which patients to visit at home for the upcoming days. We propose assigning priorities to patients according to factors such as the last visit time and the severity of their condition so that the priorities of unvisited patients increase exponentially by day. The solution to this problem should simultaneously specify which patients to visit on each day of the planning horizon, as well as the sequence of the visits to the selected patients on each day that obeys patients’ time window requests. The objective is to maximize the total priority of the visited patients primarily and to minimize the total traveling time secondarily. After having observed the computational limits of an exact formulation, we develop an Adaptive Large Neighborhood Search (ALNS) algorithm and a matheuristic to generate near-optimal solutions for realistic-sized instances. We measure the quality of both algorithms by computing the optimality gaps using upper bounds generated by Lagrangean relaxation. Tests on real-life data show that both algorithms yield high quality solutions, but the matheuristic outperforms ALNS in large instances. On the other hand, the ALNS algorithm provides very short running times, while the running times of the matheuristic increase exponentially with problem size.},
  archive      = {J_EJOR},
  author       = {Ahmet Cinar and F. Sibel Salman and Burcin Bozkaya},
  doi          = {10.1016/j.ejor.2019.07.009},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {867-878},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Prioritized single nurse routing and scheduling for home healthcare services},
  volume       = {289},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A personalized walking bus service requiring optimized route
decisions: A real case. <em>EJOR</em>, <em>289</em>(3), 855–866. (<a
href="https://doi.org/10.1016/j.ejor.2019.07.046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We address the design of the lines of a Walking Bus service according to a new paradigm, where children are picked up at home. The scarcity of accompanying persons together with the limit on the length of the deviations from the shortest itinerary of each child make the problem different from the traditional school bus and walking bus design. We propose an arc-based model, a path-based model tackled by column generation, and a heuristic procedure. Solution approaches are tested on a set of real and realistic instances. Real instances refer to the case study of a primary school in Italy.},
  archive      = {J_EJOR},
  author       = {Emanuele Tresoldi and Federico Malucelli and Maddalena Nonato},
  doi          = {10.1016/j.ejor.2019.07.046},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {855-866},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A personalized walking bus service requiring optimized route decisions: A real case},
  volume       = {289},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A combinatorial analysis of the permutation and
non-permutation flow shop scheduling problems. <em>EJOR</em>,
<em>289</em>(3), 841–854. (<a
href="https://doi.org/10.1016/j.ejor.2019.07.055">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we introduce a novel approach to the combinatorial analysis of flow shop scheduling problems for the case of two jobs, assuming that processing times are unknown. The goal is to determine the dominance properties between permutation flow shop (PFS) and non-permutation flow shop (NPFS) schedules. In order to address this issue we develop a graph-theoretical approach to describe the sets of operations that define the makespan of feasible PFS and NPFS schedules (critical paths). The cardinality of these sets is related to the number of switching machines at which the sequence of the previous operations of the two jobs becomes reversed. This, in turn, allows us to uncover structural and dominance properties between the PFS and NPFS versions of the scheduling problem. We also study the case in which the ratio between the shortest and longest processing times, denoted ρ , is the only information known about those processing times. A combinatorial argument based on ρ leads to the identification of the NPFS schedules that are dominated by PFS ones, restricting the space of feasible solutions to the NPFS problem. We also extend our analysis to the comparison of NPFS schedules (with different number of switching machines). Again, based on the value of ρ , we are able to identify NPFS schedules dominated by other NPFS schedules.},
  archive      = {J_EJOR},
  author       = {Daniel A. Rossit and Óscar C. Vásquez and Fernando Tohmé and Mariano Frutos and Martín D. Safe},
  doi          = {10.1016/j.ejor.2019.07.055},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {841-854},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A combinatorial analysis of the permutation and non-permutation flow shop scheduling problems},
  volume       = {289},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Mathematical formulations for scheduling jobs on identical
parallel machines with family setup times and total weighted completion
time minimization. <em>EJOR</em>, <em>289</em>(3), 825–840. (<a
href="https://doi.org/10.1016/j.ejor.2019.07.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the parallel machine scheduling problem with family dependent setup times and total weighted completion time minimization. In this problem, when two jobs j and k are scheduled consecutively on the same machine, a setup time is performed between the finishing time of j and the starting time of k if and only if j and k belong to different families. The problem is strongly NP NP -hard and is commonly addressed in the literature by heuristic approaches and by branch-and-bound algorithms. Achieving proven optimal solution is a challenging task even for small size instances. Our contribution is to introduce five novel mixed integer linear programs based on concepts derived from one-commodity, arc-flow and set covering formulations. Numerical experiments on more than 13000 benchmark instances show that one of the arc-flow models and the set covering model are quite efficient, as they provide on average better solutions than state-of-the-art approaches, with shorter computation times, and solve to proven optimality a large number of open instances from the literature.},
  archive      = {J_EJOR},
  author       = {Arthur Kramer and Manuel Iori and Philippe Lacomme},
  doi          = {10.1016/j.ejor.2019.07.006},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {825-840},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Mathematical formulations for scheduling jobs on identical parallel machines with family setup times and total weighted completion time minimization},
  volume       = {289},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A satisfiability and workload-based exact method for the
resource constrained project scheduling problem with generalized
precedence constraints. <em>EJOR</em>, <em>289</em>(3), 809–824. (<a
href="https://doi.org/10.1016/j.ejor.2019.07.056">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper deals with the resource constrained project scheduling problem (RCPSP) with generalized precedence constraints (RCPSP/Max). We propose an exact method that tackles a relaxed version of the original problem by modeling it as a satisfiability problem (SAT). Several SAT formulations are introduced, as well as workload-based procedures that were developed in order to reduce the domain of the decision variables, and custom propagators that were implemented with a view of improving the efficiency of the SAT solver. Extensive computational experiments involving different configurations of the method were carried out on 2430 RCPSP/Max benchmark instances ranging from 10 to 500 activities and with 5 resources, and on 2040 RCPSP benchmark instances ranging from 30 to 120 activities and with 4 resources. The results obtained suggest that the proposed method is extremely competitive as almost all known optima were found and 86 instances were solved to optimality for the first time. Moreover, a number of bounds were improved for those instances that still remain open.},
  archive      = {J_EJOR},
  author       = {Guilherme Henrique Ismael de Azevedo and Artur Alves Pessoa and Anand Subramanian},
  doi          = {10.1016/j.ejor.2019.07.056},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {809-824},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A satisfiability and workload-based exact method for the resource constrained project scheduling problem with generalized precedence constraints},
  volume       = {289},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Guest editorial to the feature cluster “new trends in
applied combinatorial optimization” (EURO/ALIO 2018). <em>EJOR</em>,
<em>289</em>(3), 807–808. (<a
href="https://doi.org/10.1016/j.ejor.2019.09.046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_EJOR},
  author       = {Valentina Cacchiani and Enrico Malaguti and Paolo Toth},
  doi          = {10.1016/j.ejor.2019.09.046},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {807-808},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Guest editorial to the feature cluster “New trends in applied combinatorial optimization” (EURO/ALIO 2018)},
  volume       = {289},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Indifference pricing of insurance-linked securities in a
multi-period model. <em>EJOR</em>, <em>289</em>(2), 793–805. (<a
href="https://doi.org/10.1016/j.ejor.2020.07.028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Insurance-linked securities (ILS) have recently become an important risk transfer mechanism to help insurers and reinsurers transfer catastrophe risks to the capital market. We employ the utility indifference approach to establish a pricing framework for a representative agent who trades an ILS with payoff linked to an insurance risk process and a reference rate process. The agent, while investing in a financial market composed of traditional financial instruments, discovers her indifference prices of the ILS by weighing the ILS trade on her exponential utility. The problem has been studied extensively, but mainly in one-period models that are best suited for zero-coupon instruments. In view of the prevalence of ILS with interim payments, we extend the study to a multi-period model by working with time 0 equivalent values and solving a multi-period optimization problem. We offer insights into issues such as coherence and time consistency of the ask and bid indifference prices obtained. Finally, we conduct a sensitivity analysis of the prices against certain risk parameters.},
  archive      = {J_EJOR},
  author       = {Haibo Liu and Qihe Tang and Zhongyi Yuan},
  doi          = {10.1016/j.ejor.2020.07.028},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {793-805},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Indifference pricing of insurance-linked securities in a multi-period model},
  volume       = {289},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The surprising robustness of dynamic mean-variance portfolio
optimization to model misspecification errors. <em>EJOR</em>,
<em>289</em>(2), 774–792. (<a
href="https://doi.org/10.1016/j.ejor.2020.07.021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In single-period portfolio optimization settings, Mean-Variance (MV) optimization can result in notoriously unstable asset allocations due to small changes in the underlying asset parameters. This has resulted in the widespread questioning of whether and how MV optimization should be implemented in practice, and has also resulted in a number of alternatives being proposed to the MV objective for asset allocation purposes. In contrast, in dynamic or multi-period MV portfolio optimization settings, preliminary numerical results show that MV investment outcomes can be remarkably robust to model misspecification errors, which arise when the investor derives an optimal investment strategy based on some chosen model for the underlying asset dynamics (the investor model), but implements this strategy in a market driven by potentially completely different dynamics (the true model). In this paper, we systematically investigate the causes of this surprising robustness of dynamic MV portfolio optimization to model misspecification errors under both the pre-commitment MV (PCMV) and time-consistent MV (TCMV) approaches. We identify particular combinations of parameters that play a key role in explaining the observed model misspecification errors. We investigate the impact of the chosen dynamic MV approach, underlying model formulation, portfolio rebalancing frequency and the application of multiple realistic investment constraints on the robustness of investment outcomes, as well as the implications for model calibration.},
  archive      = {J_EJOR},
  author       = {Pieter M. van Staden and Duy-Minh Dang and Peter A. Forsyth},
  doi          = {10.1016/j.ejor.2020.07.021},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {774-792},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {The surprising robustness of dynamic mean-variance portfolio optimization to model misspecification errors},
  volume       = {289},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Building a dynamic theory of citizens’ awareness of european
cohesion policy interventions. <em>EJOR</em>, <em>289</em>(2), 758–773.
(<a href="https://doi.org/10.1016/j.ejor.2020.07.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Since more than thirty years, the European Cohesion Policy aims to reduce economic disparities and support regional development by funding local-orientated projects. However, the citizens’ awareness of Cohesion Policy follows an unexpected longitudinal pattern characterised by a notable decrease after an initial increase. Although researchers have been investigating the relationship between policy implementation and public awareness, a lack of systemic comprehension of the underlying mechanisms is evident. Using system dynamics, we develop a causal model to explain the roots of the declining awareness towards policy interventions. The findings highlight how citizens initially manifest a high collective attention to Cohesion Policy that tends to decay over time. These dynamics, combined with the citizens’ inherent tendency to lose information saved in their long-term individual memory, could elucidate the system&#39;s behaviour. This novel system dynamics application provides policy-makers with operational guidelines for developing efficient communication strategies to improve policy awareness.},
  archive      = {J_EJOR},
  author       = {Giovanni Cunico and Eirini Aivazidou and Edoardo Mollona},
  doi          = {10.1016/j.ejor.2020.07.017},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {758-773},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Building a dynamic theory of citizens’ awareness of european cohesion policy interventions},
  volume       = {289},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A parallelised large neighbourhood search heuristic for the
asymmetric two-echelon vehicle routing problem with swap containers for
cargo-bicycles. <em>EJOR</em>, <em>289</em>(2), 742–757. (<a
href="https://doi.org/10.1016/j.ejor.2020.07.034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cargo-bicycles are a promising alternative to conventional vans in city logistics in response to increasing urbanisation and environmental damage caused by city traffic. The delivery structure is modelled with the well studied Two-Echelon Capacitated Vehicle Routing Problem (2E-CVRP), which uses cross-docking from vans to cargo-bicycles at so-called satellites. To reduce the extra handling effort compared to single-tier systems, swap containers are used. Furthermore, for cargo-bicycles the consideration of asymmetric distance matrices is important. Therefore, we present the Asymmetric 2E-CVRP with Swap Containers and develop an efficient Parallelised Large Neighbourhood Search heuristic, that is further improved using a first-level heuristic. The heuristic is tested using the symmetric 2E-CVRP benchmark instances from the literature, outperforms previous heuristics for large instances and finds new best-known solutions. Subsequently, the heuristic is applied to a case study in Munich with 22 newly generated instances, each containing 200 customers and asymmetric distances. The results allow quantitative insights into the cost and CO 2 e emissions savings of the investigated cargo-bicycle set-up compared to conventional van delivery.},
  archive      = {J_EJOR},
  author       = {Ferdinand Mühlbauer and Pirmin Fontaine},
  doi          = {10.1016/j.ejor.2020.07.034},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {742-757},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A parallelised large neighbourhood search heuristic for the asymmetric two-echelon vehicle routing problem with swap containers for cargo-bicycles},
  volume       = {289},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Queue-constrained packing: A vehicle ferry case study.
<em>EJOR</em>, <em>289</em>(2), 727–741. (<a
href="https://doi.org/10.1016/j.ejor.2020.07.027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the problem of loading vehicles onto a ferry. The order in which vehicles arrive at the terminal can have a significant impact on the efficiency of the packing on the ferry as it may not be possible to place a vehicle in an optimal location if it is not at the front of one of the dockside queues at the right point in the loading process. As the arrival order of vehicles is stochastic, we model the loading process as a two-stage stochastic optimization problem where the objective is to reduce penalties incurred by failing to pack booked vehicles. The first stage consists of optimizing the yard policy for allocating vehicles to dockside queues while the second stage solves the packing problem for a realisation of the arrival process using the yard policy determined in stage one. A novel stage-wise iterative metaheuristic is introduced, which alternates between packing optimization for each of a training set of scenarios whilst fixing the yard policy and optimizing the yard policy whilst fixing the packing solutions. We introduce two novel packing encoders for the second stage packing problem. Termed Sequential Block Packing Encode (SOPE) and General Packing Encoder (GPE), the arrangements they produce are designed to be efficient and easy to implement for loading staff. Results show that the number of yard queues available is critical to the efficiency of the packing on board the ferry.},
  archive      = {J_EJOR},
  author       = {Christopher Bayliss and Christine S.M. Currie and Julia A. Bennell and Antonio Martinez-Sykora},
  doi          = {10.1016/j.ejor.2020.07.027},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {727-741},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Queue-constrained packing: A vehicle ferry case study},
  volume       = {289},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Investment effects of pricing schemes for non-convex
markets. <em>EJOR</em>, <em>289</em>(2), 712–726. (<a
href="https://doi.org/10.1016/j.ejor.2020.07.026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Non-convex markets, such as those organized by electricity system operators, lack uniform clearing prices. In an attempt to align private and social costs when clearing these markets, operators have introduced a variety of price formation and uplift payment schemes. We investigate the impact that the choice of pricing scheme can have on generator entry and exit decisions. Our results suggest that despite the presence of fixed production cost elements, prices derived from marginal costs support the optimal capacity mix. The use of uplift payments to supplement these prices could lead to significant distortion of the capacity mix arising in competitive markets. Pricing schemes designed to reduce the need for uplift payments may at the same time reduce prices, leading to lower levels of capacity in equilibrium. Schemes intended to raise prices, to the extent they eliminate the need for discriminatory side payments, may allow system operators to support a higher level of capacity with less distortion to the capacity mix.},
  archive      = {J_EJOR},
  author       = {Jacob Mays and David P. Morton and Richard P. O’Neill},
  doi          = {10.1016/j.ejor.2020.07.026},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {712-726},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Investment effects of pricing schemes for non-convex markets},
  volume       = {289},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A real options based decision support tool for r&amp;d
investment: Application to CO2 recycling technology. <em>EJOR</em>,
<em>289</em>(2), 696–711. (<a
href="https://doi.org/10.1016/j.ejor.2020.07.015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a practice relevant real options based decision support tool to aid in the practical evaluation of R&amp;D investments in technology. Using a Poisson process to simulate the discrete progress typical of advancements in R&amp;D, we take explicit account of the technical risk of the technology development, while market risk exposure and the effect of learning-by-doing through operating the technology is also explicitly modelled. We present a compound real option design, where a European real option structure is used to model the fixed length term typical of early phase research, which is exercisable into an American real option structure to model a subsequent phase R&amp;D. In this latter phase, a successful outcome is acted upon immediately to operationalise the technology. We propose a simulation approach, which models R&amp;D progress in a stylised logistic function or ’S-shape’ form, capturing the typically slow rate of R&amp;D progress at the start of the early phase, through to more rapid improvement as the R&amp;D advances, which then slows again as the limitations of the R&amp;D are approached. We propose a business appropriate and workable economic meaning to this progress in the R&amp;D process. We demonstrate the decision support tool with an application to evaluating the R&amp;D investment potential in CO 2 recycling technology, where an energy commodity is produced.},
  archive      = {J_EJOR},
  author       = {Peter Deeney and Mark Cummins and Katharina Heintz and Mary T. Pryce},
  doi          = {10.1016/j.ejor.2020.07.015},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {696-711},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A real options based decision support tool for R&amp;D investment: Application to CO2 recycling technology},
  volume       = {289},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Addressing state space multicollinearity in solving an ozone
pollution dynamic control problem. <em>EJOR</em>, <em>289</em>(2),
683–695. (<a href="https://doi.org/10.1016/j.ejor.2020.07.014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High ground-level ozone concentrations constitute a serious air quality problem in many metropolitan regions. In this paper, we study a stochastic dynamic programming (SDP) formulation of the Atlanta metropolitan ozone pollution problem that seeks to reduce ozone via reductions of nitrogen oxides. The initial SDP formulation involves a 524-dimensional continuous state space, including ozone concentrations that are highly correlated. In prior work, a design and analysis of computer experiments (DACE) based approximate dynamic programming (ADP) solution method was able to conduct dimensionality reduction and value function approximation to enable a computationally-tractable numerical solution. However, this prior work did not address state space multicollinearity. In statistical modeling, high multicollinearity is well-known to adversely affect the generalizability of the constructed model. This issue is relevant whenever an empirical model is trained on data, but is largely ignored in the ADP literature. We propose approaches for addressing the multicollinearity in the Atlanta case study and demonstrate that if high multicollinearity is ignored, the resulting empirical models provide misleading information within the ADP algorithm. Because many SDP applications involve multicollinear continuous state spaces, the lessons learned in our research can guide the development of ADP approaches for a wide variety of SDP problems.},
  archive      = {J_EJOR},
  author       = {Bancha Ariyajunya and Chen Ying and Victoria C.P. Chen and Kim Seoung Bum and Jay Rosenberger},
  doi          = {10.1016/j.ejor.2020.07.014},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {683-695},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Addressing state space multicollinearity in solving an ozone pollution dynamic control problem},
  volume       = {289},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Advertising, goodwill, and the veblen effect. <em>EJOR</em>,
<em>289</em>(2), 676–682. (<a
href="https://doi.org/10.1016/j.ejor.2020.07.043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increase of demand in price, an exception to the law of demand, is known as the Veblen effect. In this work, we consider a profit maximizing monopoly which by means of advertising impacts the price-demand relationship. We show that advertising and goodwill play an important role in making the Veblen effect more prevalent than expected. By employing optimal control theory we capture the evolution of the variables over time which may exhibit the Veblen effect where price and demand move in the same direction. Incorporating this dynamics into firms’ decisions has a promising impact on long-term profit. Consequently, it may even trigger a slew of studies on product line extension, competition and pricing by allowing firms to control their status.},
  archive      = {J_EJOR},
  author       = {Régis Y. Chenavaz and Amit Eynan},
  doi          = {10.1016/j.ejor.2020.07.043},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {676-682},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Advertising, goodwill, and the veblen effect},
  volume       = {289},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Shadow prices and marginal abatement costs: Convex quantile
regression approach. <em>EJOR</em>, <em>289</em>(2), 666–675. (<a
href="https://doi.org/10.1016/j.ejor.2020.07.036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Marginal abatement cost (MAC) is a critically important concept for efficient environmental policy and management. In this paper we argue that most empirical studies using frontier estimation methods such as data envelopment analysis (DEA) over-estimate MACs. The first methodological contribution of this paper is to clarify the conceptual distinction between the shadow price and MAC in order to analyze three sources of upward bias due to the limited set of abatement options, inefficiency, and noisy data. Our second methodological contribution is to develop a novel MAC estimation approach based on convex quantile regression. Compared to the traditional methods, convex quantile regression is more robust to the choice of the direction vector, random noise, and heteroscedasticity. Empirical application to the U.S. electric power plants demonstrates that the upward bias of DEA may be a serious problem in real-world applications.},
  archive      = {J_EJOR},
  author       = {Timo Kuosmanen and Xun Zhou},
  doi          = {10.1016/j.ejor.2020.07.036},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {666-675},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Shadow prices and marginal abatement costs: Convex quantile regression approach},
  volume       = {289},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). EOQ-based pricing and customer credit decisions under
general supplier payments. <em>EJOR</em>, <em>289</em>(2), 652–665. (<a
href="https://doi.org/10.1016/j.ejor.2020.07.035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study investigates an inventory model interfaced with finance, marketing, and operations in a supplier-retailer-customer chain by incorporating some relevant and essential facts. The demand pattern is a multiplicative form of the retailer&#39;s selling price and credit period. The retailer receives an upstream advance-cash-credit payment plan from the supplier while offering a downstream cash-credit payment to customers. From the retailer&#39;s perspective, offering a longer credit period to customers results in more sales volume but a higher default risk than a shorter one. The retailer&#39;s objective is to determine the optimal credit period, selling price, and replenishment time simultaneously to maximize total profit. We develop the model to fit in a general framework that includes various payment types (such as advance, cash, credit, advance-cash, advance-credit, and cash-credit) and numerous previous models as special cases. We derive explicit closed-form solutions to optimal selling price, credit period, and cycle time for five possible cases. We then establish several theoretical results and identify which case is optimal under certain conditions. The purpose of this study is to explore pricing, crediting, and lot-sizing strategies under various payment types – advance, cash, and credit. Finally, we use the analysis numerically to investigate the impact of different payment schemes on the retailer profitability.},
  archive      = {J_EJOR},
  author       = {Ruihai Li and Hui-Ling Yang and Yan Shi and Jinn-Tsair Teng and Kuei-Kuei Lai},
  doi          = {10.1016/j.ejor.2020.07.035},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {652-665},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {EOQ-based pricing and customer credit decisions under general supplier payments},
  volume       = {289},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The optimal combination between selling mode and logistics
service strategy in an e-commerce market. <em>EJOR</em>,
<em>289</em>(2), 639–651. (<a
href="https://doi.org/10.1016/j.ejor.2020.07.029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In e-commerce, many online platforms operate as a reseller for some products and serve as a marketplace for others. Under both selling modes, the logistics service can be undertaken by the platform or the supplier. The combination between the selling mode and the logistics service strategy produces four typical scenarios: (a) the platform acts as a reseller and the supplier offers the logistics service, namely, the RS scenario; (b) the platform serves as a reseller and provides the logistics service, namely, the RP scenario; (c) the platform works as a marketplace and the supplier offers the logistics service, namely, the MS scenario; and (d) the platform operates as a marketplace and provides the logistics service, namely, the MP scenario. On this basis, this paper proposes an analytical model to examine how the selling mode choice interacts with the logistics service strategy. We find that the supplier&#39;s preference aligns with the improvement of the logistics service level. When the cost performance of the logistics service is high, the RP scenario will generate the highest logistics service level, in which the supplier will gain the highest profit; when the cost performance of the logistics service is low, the MS scenario will generate the highest logistics service level and give the supplier the highest profit. For the platform, as the logistics service&#39;s cost performance increases, his preferred scenario will evolve from MP to MS , and then to RP . Further, we examine the equilibrium scenario by considering the interactions between the supplier and the online platform. We find that the MS scenario will be the equilibrium when the logistics service&#39;s cost performance is in the medium range; otherwise, RP will become the equilibrium scenario.},
  archive      = {J_EJOR},
  author       = {Xuelian Qin and Zhixue Liu and Lin Tian},
  doi          = {10.1016/j.ejor.2020.07.029},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {639-651},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {The optimal combination between selling mode and logistics service strategy in an e-commerce market},
  volume       = {289},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Optimal expansion paths for hospitals of different types:
Viewpoint of scope economies and evidence from chinese hospitals.
<em>EJOR</em>, <em>289</em>(2), 628–638. (<a
href="https://doi.org/10.1016/j.ejor.2020.07.025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hospitals have different departments for treating specific diseases. Some hospitals are specialized into one department while others are diversified into many departments. Since many inputs for different departments can be shared, running a diversified hospital is probably less costly than running several specialized hospitals separately due to economies of scope. In this paper, we examine whether expanding the scope of hospitals with a limited number of departments is worthwhile using hospitals in China as the context. The degree of economies of scope is measured in terms of efficiencies gained via a data envelopment analysis. The results show that economies of scope exist for expanding general hospitals lacking one department into general hospitals with all departments. In cases of very specialized hospitals with departments such as dentistry and ophthalmology, it is more efficient to operate them separately. Adding these departments to hospitals with a narrow scope exhibits diseconomies of scope. An expansion network is constructed, with eight optimal paths identified, to guide hospitals of different types to expand their scopes into general comprehensive hospitals stage by stage in a scope-economic way. Since the department to be added is different at each stage of the expansion, the returns to scope do not exhibit a consistent trend for different methods of expansion.},
  archive      = {J_EJOR},
  author       = {Chiang Kao and Rui-Zhi Pang and Shiang-Tai Liu and Xue-Jie Bai},
  doi          = {10.1016/j.ejor.2020.07.025},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {628-638},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Optimal expansion paths for hospitals of different types: Viewpoint of scope economies and evidence from chinese hospitals},
  volume       = {289},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A unified approach to non-radial graph models in data
envelopment analysis: Common features, geometry, and duality.
<em>EJOR</em>, <em>289</em>(2), 611–627. (<a
href="https://doi.org/10.1016/j.ejor.2020.07.019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In data envelopment analysis (DEA), non-radial graph models represent an important class characterized by the independent treatment of each input and output factor in the efficiency measurement. The extensive literature on this topic often analyses individual models in isolation, so much so that the same model may be known under different names due to alternative formulations of different authors. In this paper, a unified analysis of non-radial graph models is offered, viewing each of them via two equivalent schemes: the slack-variables scheme and the Russell-type scheme. Under these schemes, the properties common to the whole class are specified and justified. Along with the two envelopment form schemes, a general dual (multiplier) form is presented. Primal-dual relationships between the envelopment and multiplier non-radial models are analyzed in order to reveal new useful properties and insights.},
  archive      = {J_EJOR},
  author       = {Margaréta Halická and Mária Trnovská},
  doi          = {10.1016/j.ejor.2020.07.019},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {611-627},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A unified approach to non-radial graph models in data envelopment analysis: Common features, geometry, and duality},
  volume       = {289},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Probabilistic sensitivity measures as information value.
<em>EJOR</em>, <em>289</em>(2), 595–610. (<a
href="https://doi.org/10.1016/j.ejor.2020.07.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Decision makers increasingly rely on forecasts or predictions generated by quantitative models. Best practices recommend that a forecast report be accompanied by a sensitivity analysis. A wide variety of probabilistic sensitivity measures have been suggested; however, model inputs may be ranked differently by different sensitivity measures. Is there some way to reduce this disparity by identifying what probabilistic sensitivity measures are most appropriate for a given reporting context? We address this question by postulating that importance rankings of model inputs generated by a sensitivity measure should correspond to the information value for those inputs in the problem of constructing an optimal report based on some proper scoring rule. While some sensitivity measures have already been identified as information value under proper scoring rules, we identify others and provide some generalizations. We address the general question of when a sensitivity measure has this property, presenting necessary and sufficient conditions. We directly examine whether sensitivity measures retain important properties such as transformation invariance and compliance with Renyi’s Postulate D for measures of statistical dependence. These results provide a means for selecting the most appropriate sensitivity measures for a particular reporting context and provide the analyst reasonable justifications for that selection. We illustrate these ideas using a large scale probabilistic safety assessment case study used to support decision making in the design and planning of a lunar space mission.},
  archive      = {J_EJOR},
  author       = {Emanuele Borgonovo and Gordon B. Hazen and Victor Richmond R. Jose and Elmar Plischke},
  doi          = {10.1016/j.ejor.2020.07.010},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {595-610},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Probabilistic sensitivity measures as information value},
  volume       = {289},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Analysis of a dyadic sustainable supply chain under
asymmetric information. <em>EJOR</em>, <em>289</em>(2), 582–594. (<a
href="https://doi.org/10.1016/j.ejor.2020.07.042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We model a sustainable supply chain with simultaneous consideration of greening and Corporate Social Responsibility by supplier and buyer and analyze it for four different decision alternatives. In the first two cases, a single supply chain agent looks after both greening and social responsibility, in the other two cases, one agent takes one of the responsibilities. We compared these four cases by considering both full information and asymmetric information about the buyer&#39;s marginal production cost. Using the supplier Stackelberg game, we obtained the optimal values of decision variables under both information scenarios. The supplier negotiates with the buyer using the wholesale price contract or the linear two-part tariff contract. The second one is the dominating choice. For this contract the value of information is also higher for all decision alternatives. We have revealed the conditions under which the supplier would be benefited by choosing the greening effort and where the buyer would be benefited by taking up social responsibility. Further, we have designed a cut-off policy and found that the supplier and buyer can trade without conflicts only at a high level of consumer sensitivity towards greening and social responsiveness. This result suggests that if sustainability is left completely on consumer pressure, then the supplier and the buyer may not incorporate sustainability in the supply chain practices. We could specify those consumer sensitivity levels under which there must be government regulations to derive sustainability.},
  archive      = {J_EJOR},
  author       = {Alok Raj and Nikunja Mohan Modak and Peter Kelle and Bharati Singh},
  doi          = {10.1016/j.ejor.2020.07.042},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {582-594},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Analysis of a dyadic sustainable supply chain under asymmetric information},
  volume       = {289},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Coalition formation in collaborative production and
transportation with competing firms. <em>EJOR</em>, <em>289</em>(2),
569–581. (<a href="https://doi.org/10.1016/j.ejor.2020.07.039">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Because of its importance in logistics costs, transportation is usually seen as the primal activity for which horizontal collaboration should be pursued. Yet, just a few cases are reported and these have been operated during limited time. We offer here an explanation, by departing from the operational research models used to date, where collaborative contracts are signed when both quantities and prices are fixed. In this paper, we consider a coalition formation game but before market equilibrium; that is, we propose a collaborative model in which, after the agreements are signed, different firms and coalitions compete in multiple markets in Cournot fashion. When this happens, the formation of one set of coalitions affects prices and production levels of all other competitors. We propose multiple models to respond the question of which coalitions would form in this setting, including stability constraints and the restriction that antitrust authorities should accept the agreement. Our main finding is that opposed to what has been found in the literature to date, forming coalitions that are beneficial to firms in the agreement and at the same time be susceptible to be cleared by antitrust authorities is quite hard. We also assess computational time issues for larger instances.},
  archive      = {J_EJOR},
  author       = {Franco Basso and Leonardo J. Basso and Mikael Rönnqvist and Andres Weintraub},
  doi          = {10.1016/j.ejor.2020.07.039},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {569-581},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Coalition formation in collaborative production and transportation with competing firms},
  volume       = {289},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Technology improvement strategy for green products under
competition: The role of government subsidy. <em>EJOR</em>,
<em>289</em>(2), 553–568. (<a
href="https://doi.org/10.1016/j.ejor.2020.07.030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, the growing global concerns about sustainable issues have placed high pressure on firms to improve production technology and reduce energy consumption. However, firm’s incentive may be weakened due to high costs. The government has recognized the firms’ predicament and provided financial support to incentivize them to improve technology. This study builds a game model which consists of a government and two competing firms to investigate the equilibrium solutions that the two symmetric firms can reach on their technology improvement strategies, and analyze the role of government subsidy. Results show that both firms apply the existing technology when it is obviously costly to improve technology, and both improve technology when the benefit of market expansion is relatively large, while they reach an asymmetric equilibrium with one improving technology and the other not when the cost and the market expansion associated with improving technology can match each other. Besides, the two firms may trap into a prisoner’s dilemma when they reach the equilibrium of both improving the technology. Encouragingly, government subsidy can serve as an effective way to alleviate the prisoner’s dilemma by easing firms’ financial burden for technology improvement. In addition, government subsidy is conducive to expanding the green product market and improving the social welfare. Finally, government subsidy may improve both firms’ profits except for the firm applying the existing technology in the asymmetric equilibrium when the cost of improving technology is moderate.},
  archive      = {J_EJOR},
  author       = {Rui Yang and Wansheng Tang and Jianxiong Zhang},
  doi          = {10.1016/j.ejor.2020.07.030},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {553-568},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Technology improvement strategy for green products under competition: The role of government subsidy},
  volume       = {289},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Planning capacity and safety stocks in a serial
production–distribution system with multiple products. <em>EJOR</em>,
<em>289</em>(2), 533–552. (<a
href="https://doi.org/10.1016/j.ejor.2020.07.024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study jointly optimizes the production capacity and safety stocks in a serial production–distribution system supplying multiple products under a guaranteed service approach (GSA). The network comprises one manufacturer operating multiple workcenters, one warehouse with limited storage capacity, and one retailer. The manufacturer must efficiently allocate capacity to the workcenters under a limited budget, while the warehouse and retailer need to maintain safety stocks to achieve a target service level. For a single workcenter processing a single product, the interaction between the production lead time, storage capacity, inventory costs, and safety stock placement is characterized. When the manufacturer has multiple workcenters, the integrated problem is formulated as a non-convex program and is solved using a nested Lagrangian relaxation heuristic. The algorithm dualizes the storage constraint in the first phase and the budget constraint in the second phase. A simulation study is conducted to assess the value of the integration, and computational experiments demonstrate that the nested Lagrangian relaxation heuristic can identify optimal or near-optimal solutions in reasonable CPU times.},
  archive      = {J_EJOR},
  author       = {Foad Ghadimi and Tarik Aouam},
  doi          = {10.1016/j.ejor.2020.07.024},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {533-552},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Planning capacity and safety stocks in a serial production–distribution system with multiple products},
  volume       = {289},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Measuring diversity. A review and an empirical analysis.
<em>EJOR</em>, <em>289</em>(2), 515–532. (<a
href="https://doi.org/10.1016/j.ejor.2020.07.053">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Maximum diversity problems arise in many practical settings from facility location to social networks, and constitute an important class of NP-hard problems in combinatorial optimization. There has been a growing interest in these problems in recent years, and different mathematical programming models have been proposed to capture the notion of diversity. They basically consist of selecting a subset of elements of a given set in such a way that a measure based on their pairwise distances is maximized to achieve dispersion or representativeness. In this paper, we perform an exhaustive comparison of four mathematical models to achieve diversity over the public domain library MDPLIB, studying the structure of the solutions obtained with each of them. We extend this library by including new Euclidean instances which permit to analyze the geometrical distribution of the solutions. Our study concludes which models are better suited for dispersion and which ones for representativeness in terms of the structure of their solutions, as well as which instances are difficult to solve. We also identify in our conclusions one of the models which is not recommended in any setting. We finalize by proposing two improvements, one related to the models and one to solving methods. The computational testing shows the value of the analysis and merit of our proposals.},
  archive      = {J_EJOR},
  author       = {Francisco Parreño and Ramón Álvarez-Valdés and Rafael Martí},
  doi          = {10.1016/j.ejor.2020.07.053},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {515-532},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Measuring diversity. a review and an empirical analysis},
  volume       = {289},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The binary knapsack problem with qualitative levels.
<em>EJOR</em>, <em>289</em>(2), 508–514. (<a
href="https://doi.org/10.1016/j.ejor.2020.07.040">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A variant of the classical knapsack problem is considered in which each item is associated with an integer weight and a qualitative level. We define a dominance relation over the feasible subsets of the given item set and show that this relation defines a preorder. We propose a dynamic programming algorithm to compute the entire set of non-dominated rank cardinality vectors and we state two greedy algorithms, which efficiently compute a single efficient solution.},
  archive      = {J_EJOR},
  author       = {Luca E. Schäfer and Tobias Dietz and Maria Barbati and José Rui Figueira and Salvatore Greco and Stefan Ruzika},
  doi          = {10.1016/j.ejor.2020.07.040},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {508-514},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {The binary knapsack problem with qualitative levels},
  volume       = {289},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). High multiplicity asymmetric traveling salesman problem with
feedback vertex set and its application to storage/retrieval system.
<em>EJOR</em>, <em>289</em>(2), 495–507. (<a
href="https://doi.org/10.1016/j.ejor.2020.07.038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We describe an algorithm for the high multiplicity asymmetric traveling salesman problem with feedback vertex set of size k ( HMATSP - k FVS) where each vertex can be visited a certain number of times and each cycle in a solution contains at least one vertex from the feedback vertex set. We show how it can be used to improve algorithms in automated storage and retrieval systems. An automated storage and retrieval system includes storage blocks and storage and retrieval machines that either move to retrieve unit loads from their current locations in the system to a depot or take unit loads from a depot and store them to specific locations in the system. Given n storage and retrieval requests in a system with k depots and one storage and retrieval machine, we show that our algorithm for HMATSP - k FVS can solve the problem of minimizing total traveling time of the storage and retrieval machine in O ( n k + n 3 ) O(nk+n3) time when all depots are specialized (each depot fulfills one type of requests) and in O ( n 2 k + n 3 ) O(n2k+n3) time when depots are regular (each depot fulfills both types of requests). The best previous algorithm only solves the special case of the problem with 2 regular depots in O ( n 6 ) time. The applicability of our algorithm for several generalizations and special cases of the problem is also discussed. Furthermore, to evaluate the performance of our solution method, we perform extensive numerical experiments.},
  archive      = {J_EJOR},
  author       = {Amir Gharehgozli and Chao Xu and Wenda Zhang},
  doi          = {10.1016/j.ejor.2020.07.038},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {495-507},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {High multiplicity asymmetric traveling salesman problem with feedback vertex set and its application to storage/retrieval system},
  volume       = {289},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Weak flow cover inequalities for the capacitated facility
location problem. <em>EJOR</em>, <em>289</em>(2), 485–494. (<a
href="https://doi.org/10.1016/j.ejor.2020.07.033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Capacitated Facility Location Problem calls for opening a set of facilities with capacity constraints, with the aim of satisfying at the minimum cost the demands of a set of customers. We present a new class of valid inequalities, the Weak Flow Cover inequalities. We show that Weak Flow Cover inequalities can be separated in polynomial time and turned into violated Flow Cover inequalities. In this way, we are able to provide a polynomial separation heuristic for the latter. Embedding the separation procedure into a cut-and-branch approach, we get results significantly better than those reported in the recent literature both for the lower and the upper bounds.},
  archive      = {J_EJOR},
  author       = {P. Avella and M. Boccia and S. Mattia and F. Rossi},
  doi          = {10.1016/j.ejor.2020.07.033},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {485-494},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Weak flow cover inequalities for the capacitated facility location problem},
  volume       = {289},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The pickup and delivery problem with split loads and
transshipments: A branch-and-cut solution approach. <em>EJOR</em>,
<em>289</em>(2), 470–484. (<a
href="https://doi.org/10.1016/j.ejor.2020.07.032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the design of routes for a fleet of vehicles serving customer requests. It is a pickup and delivery problem where each customer location can be visited several times, and load may be transshipped from one vehicle to another at specific locations. The aim is to minimize the sum of travel costs and transshipment costs. We present an arc-based mixed-integer formulation for the problem and propose a branch-and-cut algorithm for solving it. Extensive computational results illustrate the performance of the algorithm.},
  archive      = {J_EJOR},
  author       = {David Wolfinger and Juan-José Salazar-González},
  doi          = {10.1016/j.ejor.2020.07.032},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {470-484},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {The pickup and delivery problem with split loads and transshipments: A branch-and-cut solution approach},
  volume       = {289},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A polynomial algorithm for balanced clustering via graph
partitioning. <em>EJOR</em>, <em>289</em>(2), 456–469. (<a
href="https://doi.org/10.1016/j.ejor.2020.07.031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The objective of clustering is to discover natural groups in datasets and to identify geometrical structures which might reside there, without assuming any prior knowledge on the characteristics of the data. The problem can be seen as detecting the inherent separations between groups of a given point set in a metric space governed by a similarity function. The pairwise similarities between all data objects form a weighted graph whose adjacency matrix contains all necessary information for the clustering process. Consequently, the clustering task can be formulated as a graph partitioning problem. In this context, we propose a new cluster quality measure which uses the ratio of intra- and inter-cluster variance and allows us to compute the optimal clustering under the min-max principle in polynomial time. Our algorithm can be applied to both partitional and hierarchical clustering.},
  archive      = {J_EJOR},
  author       = {Luis Evaristo Caraballo and José-Miguel Díaz-Báñez and Nadine Kroher},
  doi          = {10.1016/j.ejor.2020.07.031},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {456-469},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A polynomial algorithm for balanced clustering via graph partitioning},
  volume       = {289},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A new combinatorial branch-and-bound algorithm for the
knapsack problem with conflicts. <em>EJOR</em>, <em>289</em>(2),
435–455. (<a href="https://doi.org/10.1016/j.ejor.2020.07.023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the Knapsack Problem with Conflicts, a generalization of the Knapsack Problem in which a set of conflicts specifies pairs of items which cannot be simultaneously selected. In this work, we propose a novel combinatorial branch-and-bound algorithm for this problem based on an n -ary branching scheme. Our algorithm effectively combines different procedures for pruning the branch-and-bound nodes based on different relaxations of the Knapsack Problem with Conflicts. Its main elements of novelty are: ( i ) the adoption of the branching-and-pruned set branching scheme which, while extensively used in the maximum-clique literature, was never successfully employed for solving the Knapsack Problem with Conflicts; ( ii ) the adoption of the Multiple-Choice Knapsack Problem for the derivation of upper bounds used for pruning the branch-and-bound tree nodes; and ( iii ) the design of a new upper bound for the latter problem which can be computed very efficiently. Key to our algorithm is its high pruning potential and the low computational effort that it requires to process each branch-and-bound node. An extensive set of experiments carried out on the benchmark instances typically used in the literature shows that, for edge densities ranging from 0.1 to 0.9, our algorithm is faster by up to two orders of magnitude than the state-of-the-art method and by up to several orders of magnitude than a state-of-the-art mixed-integer linear programming solver.},
  archive      = {J_EJOR},
  author       = {Stefano Coniglio and Fabio Furini and Pablo San Segundo},
  doi          = {10.1016/j.ejor.2020.07.023},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {435-455},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A new combinatorial branch-and-bound algorithm for the knapsack problem with conflicts},
  volume       = {289},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A bi-objective heuristic approach for green identical
parallel machine scheduling. <em>EJOR</em>, <em>289</em>(2), 416–434.
(<a href="https://doi.org/10.1016/j.ejor.2020.07.020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sustainability in manufacturing has become a fundamental topic in the scientific literature due to the preeminent role of manufacturing industry in total world energy consumption and carbon emission. This paper tackles the multi-objective combinatorial optimization problem of scheduling jobs on multiple parallel machines, while minimizing both the makespan and the total energy consumption. The electricity prices vary according to a time-of-use policy, as in many cases of practical interest. In order to face this problem, an ad-hoc heuristic method is developed. The first part of the method, called Split-Greedy heuristic, consists in an improved and refined version of the constructive heuristic (CH) proposed in Wang, Wang, Yu, Ma and Liu (2018). The second part, called Exchange Search, is a novel local search procedure aimed at improving the quality of the Pareto optimal solutions. The experimental results prove the effectiveness of the proposed method with respect to three competitors: CH, NSGA-III, and MOEA/D.},
  archive      = {J_EJOR},
  author       = {Davide Anghinolfi and Massimo Paolucci and Roberto Ronco},
  doi          = {10.1016/j.ejor.2020.07.020},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {416-434},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A bi-objective heuristic approach for green identical parallel machine scheduling},
  volume       = {289},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Exact solution techniques for two-dimensional cutting and
packing. <em>EJOR</em>, <em>289</em>(2), 399–415. (<a
href="https://doi.org/10.1016/j.ejor.2020.06.050">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We survey the main formulations and solution methods for two-dimensional orthogonal cutting and packing problems, where both items and bins are rectangles. We focus on exact methods and relaxations for the four main problems from the literature: finding a packing with minimum height, packing the items into the minimum number of bins, finding a packing of maximum value, and determining the existence of a feasible packing.},
  archive      = {J_EJOR},
  author       = {Manuel Iori and Vinícius L. de Lima and Silvano Martello and Flávio K. Miyazawa and Michele Monaci},
  doi          = {10.1016/j.ejor.2020.06.050},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {399-415},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Exact solution techniques for two-dimensional cutting and packing},
  volume       = {289},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). A data-driven framework for consistent financial valuation
and risk measurement. <em>EJOR</em>, <em>289</em>(1), 381–398. (<a
href="https://doi.org/10.1016/j.ejor.2020.07.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a general data-driven framework that unifies the valuation and risk measurement of financial derivatives, which is especially useful in markets with thinly-traded derivatives. We first extract the empirical characteristic function from market-observable time series for the underlying asset prices, and then utilize Fourier techniques to obtain the physical nonparametric density and cumulative distribution function for the log-returns process, based on which we compute risk measures. Then we risk-neutralize the nonparametric density and distribution functions to model-independently valuate a variety of financial derivatives, including path-independent European options and path-dependent exotic contracts. By estimating the state-price density explicitly, and utilizing a convenient basis representation, we are able to greatly simplify the pricing of exotic options all within a consistent model-free framework. Numerical examples, and an empirical example using real market data (Brent crude oil prices) illustrate the accuracy and versatility of the proposed method in handling pricing and risk management of multiple financial contracts based solely on observable time series data.},
  archive      = {J_EJOR},
  author       = {Zhenyu Cui and J. Lars Kirkby and Duy Nguyen},
  doi          = {10.1016/j.ejor.2020.07.011},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {381-398},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A data-driven framework for consistent financial valuation and risk measurement},
  volume       = {289},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Limited-trust equilibria. <em>EJOR</em>, <em>289</em>(1),
364–380. (<a href="https://doi.org/10.1016/j.ejor.2020.07.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose and analyze a new type of equilibrium, in which limited-trust exists between players with long-term interactions. We assume heterogeneous interactions: players will engage in several games over an undetermined period of time with payoffs for each game drawn from a distribution. As such, players may not engage in the same game more than once. We define a Limited-Trust equilibrium to address these heterogeneous games, show its existence in all finite simultaneous games, and analyze it in general and in several common classes of games. We provide several interpretations of this equilibrium in leader-follower games. We then numerically compare the social utility generated from these equilibria in both simultaneous and leader-follower games to that generated by Nash and Stackelberg equilibria in the same games: when players display a similar level of trust δ , each sees an average gain of approximately δ in its utility each game over what it would achieve in traditional competitive/rational games, meaning for each game a player loses δ , there is another game it gains 3 δ . Thus while players appear to play “non-rationally” by giving something up, they actually gain more and are each able to come out ahead of what they would have received if playing rationally as in a Nash equilibrium.},
  archive      = {J_EJOR},
  author       = {Timothy Murray and Jugal Garg and Rakesh Nagi},
  doi          = {10.1016/j.ejor.2020.07.009},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {364-380},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Limited-trust equilibria},
  volume       = {289},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Option pricing with conditional GARCH models. <em>EJOR</em>,
<em>289</em>(1), 350–363. (<a
href="https://doi.org/10.1016/j.ejor.2020.07.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a class of conditional GARCH models that offers significantly added flexibility to accommodate empirically relevant features of financial asset returns while admitting closed-form recursive solutions for the moment generating function, a variance dependent pricing kernel and, therefore, efficient option pricing in a realistic setting. This class of conditional GARCH models can be constructed with specifications of the GARCH dynamics and innovations, for which recursive moment generating function formulas have been derived, hence generalizing such families of models. As an example, we combine the popular Heston-Nandi model with Regime Switching to illustrate the flexibility of our methodology and demonstrate the importance in terms of option prices and Greeks of accommodating crisis periods and state dependency as well as priced variance risk.},
  archive      = {J_EJOR},
  author       = {Marcos Escobar-Anel and Javad Rastegari and Lars Stentoft},
  doi          = {10.1016/j.ejor.2020.07.002},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {350-363},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Option pricing with conditional GARCH models},
  volume       = {289},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Weighted network search games with multiple hidden objects
and multiple search teams. <em>EJOR</em>, <em>289</em>(1), 338–349. (<a
href="https://doi.org/10.1016/j.ejor.2020.06.046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most search game models assume that the hiding locations are identical and the players’ objective is to optimize the search time. However, there are some cases in which the players may differentiate the hiding locations from each other and the objective is to optimize a weighted search time. In addition, the search may involve multiple search teams. To address these, we introduce a new network search game with consideration given to the weights at different locations. A hider can hide multiple objects and there may be multiple search teams. For a special case of the problem, we prove that the game has a closed-form Nash equilibrium. For the general case, we develop an algorithm based on column and row generation. We show that the Searcher’s subproblem is NP-hard and propose a branch and price algorithm to solve it. We also present a polynomial time algorithm for the Hider’s subproblem. Numerical experiments demonstrate the efficiency of the proposed algorithms, and reveal insights into the properties of this game.},
  archive      = {J_EJOR},
  author       = {Abdolmajid Yolmeh and Melike Baykal-Gürsoy},
  doi          = {10.1016/j.ejor.2020.06.046},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {338-349},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Weighted network search games with multiple hidden objects and multiple search teams},
  volume       = {289},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Dual productivity analysis: A konüs/shephard approach.
<em>EJOR</em>, <em>289</em>(1), 328–337. (<a
href="https://doi.org/10.1016/j.ejor.2020.06.037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A primal (or direct) productivity index is conventionally defined as the ratio of an output quantity index to an input quantity index. There have been attempts in the literature to define and implement dual and indirect productivity indexes based on price changes rather than quantity changes. Although dual and indirect productivity indexes share a common motivation, the measurement of productivity change when prices are easier to measure, or are measured more accurately, than quantities, they differ analytically, from one another and from primal productivity indexes. We introduce a new dual productivity index, inspired by contributions of Konüs and Shephard, and we compare our dual productivity index with a primal productivity index inspired by the work of Malmquist. We also compare these two theoretical productivity indexes with an analogous pair of empirical Fisher productivity indexes. We provide an empirical application to US agricultural productivity growth.},
  archive      = {J_EJOR},
  author       = {E. Grifell-Tatjé and C.A.K. Lovell},
  doi          = {10.1016/j.ejor.2020.06.037},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {328-337},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Dual productivity analysis: A Konüs/Shephard approach},
  volume       = {289},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Interdependent integrated network design and scheduling
problems with movement of machines. <em>EJOR</em>, <em>289</em>(1),
297–327. (<a href="https://doi.org/10.1016/j.ejor.2020.07.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the problem of restoring services provided by an interdependent set of infrastructures after they were disrupted from an extreme event. Specifically, we select the set of damaged infrastructure arcs for immediate restoration and schedule these on a set of machines (work crews). Our novel contribution is that when we determine the selection and scheduling of these damaged arcs, we explicitly consider the movement of machines through a damaged transportation network that is currently being restored. Previous works failed to consider how machine movement greatly influences the ability to conduct timely restoration due to the interdependence on the transportation network. To model this restoration construct, we propose an interdependent integrated network design and scheduling problem with movement of machines (IINDS-MM). In an IINDS-MM problem, we have a base transportation network and at least one additional infrastructure network layer. For each network layer, we determine what damaged arcs are selected for restoration, which machine will conduct the restoration, and the sequence of tasks assigned to each machine when explicitly considering machine movement through the changing transportation network. We propose a mixed integer programming formulation of the IINDS-MM problem and solve it using a rolling horizon solution procedure. Using realistic data representing Juan Diaz, Panama and the customizable artificial community CLARC data set, we simulate different storm surge levels and possible damage scenarios. We then solve the IINDS-MM problem and deduce insights about machine starting locations, machine capabilities, and the performance of IINDS-MM compared to existing restoration models.},
  archive      = {J_EJOR},
  author       = {Aniela Garay-Sianca and Sarah G. Nurre Pinkley},
  doi          = {10.1016/j.ejor.2020.07.013},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {297-327},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Interdependent integrated network design and scheduling problems with movement of machines},
  volume       = {289},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A balanced evacuation algorithm for facilities with multiple
exits. <em>EJOR</em>, <em>289</em>(1), 285–296. (<a
href="https://doi.org/10.1016/j.ejor.2020.07.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Over the last few years, there has been an increase in the number of disasters caused by human crowding due to evacuees attempting to exit during emergencies. This has led to a rise in optimization studies on emergency evacuation plans that mitigate the loss of life and injury. Although a substantial amount of this research focuses on guiding evacuees toward the nearest emergency exits, they do not always consider the problem of congestion. This paper will present an algorithm that will ensure that pedestrians safely evacuate facilities with multiple exits by introducing a balanced evacuation algorithm: BEME. This approach will help reduce overcrowding and congestion surrounding the exits by overcoming the limitations of traditional strategies such as approaching the nearest exit and ensuring optimal evacuation. BEME’s performance was compared with two established artificial intelligence techniques: simulated annealing and depth-first search. The evacuation model evaluation considered a number of variations in the spatial placement of the exits, number of exits, and number of pedestrians. The results showed that the proposed algorithm could significantly reduce the number of pedestrians for every exit. BEME differs from the benchmarked techniques, as it is consistent regarding the various exit placements and hence supports the algorithm’s use with existing infrastructures that utilize inefficiently placed exits. Moreover, this approach resolves the problem of overcrowding and congestion around exits using a balanced evacuation that helps maximize safety and avoid life-threatening hazards.},
  archive      = {J_EJOR},
  author       = {Heba Kurdi and Asma Almulifi and Shiroq Al-Megren and Kamal Youcef-Toumi},
  doi          = {10.1016/j.ejor.2020.07.012},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {285-296},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A balanced evacuation algorithm for facilities with multiple exits},
  volume       = {289},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Models and algorithms for optimising two-dimensional LEGO
constructions. <em>EJOR</em>, <em>289</em>(1), 270–284. (<a
href="https://doi.org/10.1016/j.ejor.2020.07.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The LEGO Construction Problem is the problem of deciding which bricks to place where in a predefined LEGO construction. The input consists of coloured voxels that each correspond to the size of a LEGO unit, such that all LEGO bricks are multiples of this LEGO unit. A solution to the LEGO Construction Problem is feasible if all bricks are within the design domain, the bricks do not overlap, the bricks satisfy the colour constraints, and all bricks connect into a stable construction. In this article, we propose an automated approach for optimising LEGO constructions, and in particular, we focus on 2D constructions. We introduce mathematical programming formulations of the problem as well as a fast constructive heuristic algorithm that is very efficient for constructing regular walls. Further, we integrate the models and the heuristic into a matheuristic algorithm, where the heuristic algorithm defines most of the construction, in particular, large elements that require regular patterns, while the mathematical models are used to tackle critical parts of the construction and to ensure the overall stability of the result. The article concludes with computational experiments on regular and irregular constructions showing the efficacy of the proposed algorithm when compared with two recent approaches from the literature.},
  archive      = {J_EJOR},
  author       = {Torkil Kollsker and Enrico Malaguti},
  doi          = {10.1016/j.ejor.2020.07.004},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {270-284},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Models and algorithms for optimising two-dimensional LEGO constructions},
  volume       = {289},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Orientational variable-length strip covering problem: A
branch-and-price-based algorithm. <em>EJOR</em>, <em>289</em>(1),
254–269. (<a href="https://doi.org/10.1016/j.ejor.2020.07.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we study a challenging optimization problem, namely the orientational variable-length strip covering problem. Given a large rectangular region and multiple orientational strips with variable lengths, the strips should be positioned and their lengths be determined such that their union can cover the large region with the minimal total area. This problem is motivated by the real-world problem in which multiple Earth observation satellites are used to image a large region in a cooperative pattern. It is a challenging nonlinear combinatorial optimization problem in continuous space. We propose a set-covering-problem-like integer programming formulation for the problem based on grid discretization and prove that the optimal solutions can be achieved when the strips take discrete values. As there is a large number of columns, we use a column generation method to solve the linear relaxation problem and an enumeration algorithm to solve the subproblem. To accelerate the solution, we propose a provable dominance rule to greatly reduce the solution space of the subproblem, enabling the application of an implicit enumeration (IE) algorithm. Then, we propose a cell-gathered approximate pricing method based on the definition of nested father–child grids. As a result, an efficient branch-and-price-based algorithm (BPBA) is developed. The numerical tests on random instances show that the dominance rule can reduce the subproblem’s solutions by almost 74\% and the BPBA can run five times faster than Gurobi (commercial solving software) to find comparable solutions on average.},
  archive      = {J_EJOR},
  author       = {Xiaoxuan Hu and Waiming Zhu and Huawei Ma and Bo An and Yanling Zhi and Yi Wu},
  doi          = {10.1016/j.ejor.2020.07.003},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {254-269},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Orientational variable-length strip covering problem: A branch-and-price-based algorithm},
  volume       = {289},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Accelerating benders decomposition for short-term hydropower
maintenance scheduling. <em>EJOR</em>, <em>289</em>(1), 240–253. (<a
href="https://doi.org/10.1016/j.ejor.2020.06.041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Maintenance of power generators is essential for reliable and efficient electricity production. Because generators under maintenance are typically inactive, optimal planning of maintenance activities must consider the impact of maintenance outages on the system operation. However, in hydropower systems finding a minimum cost maintenance schedule is a challenging optimization problem due to the uncertainty of the water inflows and the nonlinearity of the hydroelectricity production. Motivated by an industrial application problem, we formulate the hydropower maintenance scheduling problem as a two-stage stochastic program, and we implement a parallelized Benders decomposition algorithm for its solution. We obtain convex subproblems by approximating the hydroelectricity production using linear inequalities and indicator variables, which account for the nonlinear effect of the number of active generators in the solution. For speeding up the execution of our decomposition algorithm, we tailor and test seven techniques, including three new applications of special ordered sets, presolve and warm start for Benders acceleration. Given the large number of possible configurations of these acceleration techniques, we illustrate the application of statistical methods and computational experiments to identify the best performing configuration, which achieved a fourfold speedup of the decomposition algorithm. Results in an industrial setting confirm the high scalability on the number of scenarios of our parallelized Benders implementation.},
  archive      = {J_EJOR},
  author       = {Jesús A. Rodríguez and Miguel F. Anjos and Pascal Côté and Guy Desaulniers},
  doi          = {10.1016/j.ejor.2020.06.041},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {240-253},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Accelerating benders decomposition for short-term hydropower maintenance scheduling},
  volume       = {289},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An operational test for the existence of a consistent
increasing quasi-concave value function. <em>EJOR</em>, <em>289</em>(1),
232–239. (<a href="https://doi.org/10.1016/j.ejor.2020.06.049">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The existence of an increasing quasi-concave value function consistent with given preference information is an important issue in various fields including Economics, Multiple Criteria Decision Making, and Applied Mathematics. A quasi-concave value function is equivalent to convex-to-the-origin indifference contours, a very common assumption in Economics. In this paper, we establish necessary and sufficient conditions for the existence of a value function satisfying aforementioned properties. This leads to an operational, tractable and easy to use test for checking the existence of such a value function. In addition to developing the existence test, we construct consistent linear and non-linear desirable value functions.},
  archive      = {J_EJOR},
  author       = {Majid Soleimani-damaneh and Latif Pourkarimi and Pekka J. Korhonen and Jyrki Wallenius},
  doi          = {10.1016/j.ejor.2020.06.049},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {232-239},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {An operational test for the existence of a consistent increasing quasi-concave value function},
  volume       = {289},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Simultaneous feature selection and clustering based on
square root optimization. <em>EJOR</em>, <em>289</em>(1), 214–231. (<a
href="https://doi.org/10.1016/j.ejor.2020.06.045">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The fused least absolute shrinkage and selection operator (LASSO) simultaneously pursuing the joint sparsity of coefficients and their successive differences has attracted significant attention for analytics purposes. Although it is extensively used, especially when the number of features exceeds the sample size, tuning the regularization parameters, which depends on noise level σ , is a challenging task since σ is difficult to estimate accurately. To tackle this problem, in this paper, we propose and study square root fused LASSO, which combines the square root loss function and joint penalty functions. In theory, we show that the proposed method can achieve the same error rate as that of fused LASSO by proving its estimation and prediction error bounds. In addition, the error rate of square root fused LASSO is lower than those of LASSO and square root LASSO via simultaneous feature selection and clustering. The choices of the regularization parameters are also shown to be free of σ . In terms of computation, this work develops a novel algorithm based on the alternating direction method of multipliers algorithm with theoretical guarantee of its convergence. Experiments on simulation and real-world datasets demonstrate the superiority of square root fused LASSO over fused LASSO and other state-of-the-art feature selection methods.},
  archive      = {J_EJOR},
  author       = {He Jiang and Shihua Luo and Yao Dong},
  doi          = {10.1016/j.ejor.2020.06.045},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {214-231},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Simultaneous feature selection and clustering based on square root optimization},
  volume       = {289},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Facets of trust in simulation studies. <em>EJOR</em>,
<em>289</em>(1), 197–213. (<a
href="https://doi.org/10.1016/j.ejor.2020.06.043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The purpose of a modelling and simulation (M&amp;S) study for real-world operations management applications is to support decision-making and inform potential action, therefore investigating the aspects of the modelling process which influence trust is important. Previous work has considered the question of trust through the lens of model validation. However, whilst a simulation model may be technically well executed, stakeholders’ trust in the results may also depend upon intangible factors such as interpersonal relationships. Existing literature has also focused on the credibility of the simulation practitioner, however the credibility attribute belongs to the stakeholder, and it ignores the trust aspects that may exist between the stakeholders and the model itself. In this paper, we argue that different facets of trust emerge throughout the stages of a simulation study, and both influence, and are influenced by, the interaction between the model, the modeller and the stakeholders of the study. We present a synthesis of existing literature and extend it by proposing a formative model of trust which presents a conceptualisation of this tripartite relationship. Our contribution is the identification of the different facets of trust in the lifecycle of a modelling and simulation study. We argue that these interacting facets converge via the three-way relationship between modeller, model and stakeholders toward epistemic trust in the knowledge generated by the simulation study and ultimately model acceptability and implementation. To the best of our knowledge, ours is the first study that focuses solely on the question of trust in an M&amp;S study.},
  archive      = {J_EJOR},
  author       = {Alison Harper and Navonil Mustafee and Mike Yearworth},
  doi          = {10.1016/j.ejor.2020.06.043},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {197-213},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Facets of trust in simulation studies},
  volume       = {289},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Some robust approaches based on copula for monitoring
bivariate processes and component-wise assessment. <em>EJOR</em>,
<em>289</em>(1), 177–196. (<a
href="https://doi.org/10.1016/j.ejor.2020.07.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we develop two adaptive approaches for detecting the signal source in a bivariate process when a shift occurs in the location vector or the scale matrix or both. The proposed method capitalises the notion of Sklar’s principle of expressing any multivariate joint distribution in terms of univariate marginal-distribution functions and a copula, which represents the dependence structure between the variables. Motivated by this, we recommend monitoring the two marginal distributions and the copula function simultaneously using appropriate nonparametric (distribution-free) test statistics. At each stage of Phase-II monitoring, we adopt the permutation method for computing the individual p -values and derive the plotting statistics of our proposed schemes combining suitable transforms of the three p -values of the component testing. We establish the in-control robustness of the proposed surveillance plans and compare them with two competitors in terms of run length properties. Performance of the proposed schemes in detecting a correct out-of-control signal is as good or better than some existing charting schemes for bivariate process monitoring. The novelty of our proposed technique lies in the fact that it indigenously helps in identifying the component(s) responsible for the signal, which is not straightforward with the traditional schemes for surveillance of a bivariate process. Numerical results substantiate that the proposed procedure performs significantly better than its competitors in many cases. Also, we investigate the percentage of correct diagnosis of a signal via the proposed charting schemes. Nowadays, in monitoring and control of smooth service operations, the use of quality monitoring has increased than ever before, but the problem and data structures become more complicated in the Industry 4.0 era. We analyse two real case studies, one in the context of monitoring the response time and service quality in a call centre and the other related to the inspection of product quality, to illustrate the application of the proposed schemes.},
  archive      = {J_EJOR},
  author       = {Zhi Song and Amitava Mukherjee and Jiujun Zhang},
  doi          = {10.1016/j.ejor.2020.07.016},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {177-196},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Some robust approaches based on copula for monitoring bivariate processes and component-wise assessment},
  volume       = {289},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Lead-time quotations in unobservable make-to-order systems
with strategic customers: Risk aversion, load control and profit
maximization. <em>EJOR</em>, <em>289</em>(1), 165–176. (<a
href="https://doi.org/10.1016/j.ejor.2020.06.047">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We develop a model for pricing, lead-time quotation and delay compensation in a Markovian make-to-order production or service system with strategic customers who exhibit risk aversion. Based on a concave utility function of their net benefit, customers make individual decisions to join the system or balk without observing the state of the queue. The decisions of arriving customers result in a symmetric join/balk game. Regarding the firm’s strategy, the provider announces a fixed entrance fee, a lead-time quotation and a compensation rate for the part of a customer delay which exceeds the quoted lead-time. We analyze the effect of customer risk aversion and the compensation policy on the equilibrium join/balk strategies and the resulting input rates, and assess the flexibility of the provider in inducing a range of possible input rates under various constraints on the pricing/compensation policy. In numerical experiments we explore the behavior of pricing curves that reflect the provider’s choices in inducing specific input rates. A key insight obtained from the analysis is that a main benefit of the lead-time and compensation option is to allow the entrance fee to remain high and the provider prefers strategies that lead to this direction.},
  archive      = {J_EJOR},
  author       = {Myron Benioudakis and Apostolos Burnetas and George Ioannou},
  doi          = {10.1016/j.ejor.2020.06.047},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {165-176},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Lead-time quotations in unobservable make-to-order systems with strategic customers: Risk aversion, load control and profit maximization},
  volume       = {289},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Large-scale influence maximization via maximal covering
location. <em>EJOR</em>, <em>289</em>(1), 144–164. (<a
href="https://doi.org/10.1016/j.ejor.2020.06.028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Influence maximization aims at identifying a limited set of key individuals in a (social) network which spreads information based on some propagation model and maximizes the number of individuals reached. We show that influence maximization based on the probabilistic independent cascade model can be modeled as a stochastic maximal covering location problem. A reformulation based on Benders decomposition is proposed and a relation between obtained Benders optimality cuts and submodular cuts for correspondingly defined subsets is established. We introduce preprocessing tests, which allow us to remove variables from the model and develop efficient algorithms for the separation of Benders cuts. Both aspects are shown to be crucial ingredients of the developed branch-and-cut algorithm since real-life social network instances may be very large. In a computational study, the considered variants of this branch-and-cut algorithm outperform the state-of-the-art approach for influence maximization by orders of magnitude.},
  archive      = {J_EJOR},
  author       = {Evren Güney and Markus Leitner and Mario Ruthmair and Markus Sinnl},
  doi          = {10.1016/j.ejor.2020.06.028},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {144-164},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Large-scale influence maximization via maximal covering location},
  volume       = {289},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An analysis of technology licensing and parallel importation
under different market structures. <em>EJOR</em>, <em>289</em>(1),
132–143. (<a href="https://doi.org/10.1016/j.ejor.2020.07.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Parallel importation, also referred to as the “gray market”, is the unauthorised import of genuine-branded products into a country without the permission of the intellectual property owner. We develop a game-theoretic model to examine the issues of technology licensing and parallel importation in a setting with one leading manufacturer in a developed country (high market) that can license its innovative technology to one manufacturer in a developing country (low market). By considering that the high market is in a monopoly or in a duopoly, we investigate the impact of parallel importation on the profits of players and the unit licensing fee. Then, we analyze the leading manufacturer&#39;s optimal licensing decision considering parallel importation. We show that the leading manufacturer&#39;s profit is always worse off due to the emergence of parallel importation, no matter whether the high market is in a monopoly or in a duopoly. Nevertheless, the leading manufacturer may still have the motivation to license the technology. Interestingly, the leading manufacturer may reduce the unit licensing fee when parallel importation occurs in the duopoly setting. Furthermore, the profit of the manufacturer in the developing country may decrease when parallel importation arises, although parallel importation enhances the manufacturers’ overall market demand. The main insights extend to settings with alternative demand functions.},
  archive      = {J_EJOR},
  author       = {Hai Li and Qiankai Qing and Juan Wang and Xianpei Hong},
  doi          = {10.1016/j.ejor.2020.07.008},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {132-143},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {An analysis of technology licensing and parallel importation under different market structures},
  volume       = {289},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Forward buying and strategic stockouts. <em>EJOR</em>,
<em>289</em>(1), 118–131. (<a
href="https://doi.org/10.1016/j.ejor.2020.07.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Price promotions are temporary price cuts that suppliers offer to buyers. When promotions are sufficiently attractive, buyers choose to backlog some portion of demand in anticipation of a possible forward buy at the discounted price. While it has been shown that a backlog of orders as a normal business practice can be successful in certain situations, the potential benefits of such strategic stockouts in the context of price promotions are not fully understood. This paper explores these benefits while offering theoretical and managerial insights into the link between forward buying and strategic stockouts along with a practically appealing control policy.},
  archive      = {J_EJOR},
  author       = {Çerağ Pinçe},
  doi          = {10.1016/j.ejor.2020.07.007},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {118-131},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Forward buying and strategic stockouts},
  volume       = {289},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Superforecasting reality check: Evidence from a small pool
of experts and expedited identification. <em>EJOR</em>, <em>289</em>(1),
107–117. (<a href="https://doi.org/10.1016/j.ejor.2020.06.042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Superforecasting has drawn the attention of academics - despite earlier contradictory findings in the literature, arguing that humans can consistently and successfully forecast over long periods. It has also enthused practitioners, due to the major implications for improving forecast-driven decision-making. The evidence in support of the superforecasting hypothesis was provided via a 4-year project led by Tetlock and Mellers, which was based on an exhaustive experiment with more than 5000 experts across the globe, resulting in identifying 260 superforecasters. The result, however, jeopardizes the applicability of the proposition, as exciting as it may be for the academic world; if every company in the world needs to rely on the aforementioned 260 experts, then this will end up an impractical and expensive endeavor. Thus, it would make sense to test the superforecasting hypothesis in real-life conditions: when only a small pool of experts is available, and there is limited time to identify the superforecasters. If under these constrained conditions the hypothesis still holds, then many small and medium-sized organizations could identify fast and consequently utilize their own superforecasters. In this study, we provide supportive empirical evidence from an experiment with an initial (small) pool of 314 experts and an identification phase of (just) 9 months. Furthermore - and corroborating to the superforecasting literature, we also find preliminary evidence that even an additional training of just 20 min, can influence positively the number of superforecasters identified.},
  archive      = {J_EJOR},
  author       = {Ilias Katsagounos and Dimitrios D. Thomakos and Konstantia Litsiou and Konstantinos Nikolopoulos},
  doi          = {10.1016/j.ejor.2020.06.042},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {107-117},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Superforecasting reality check: Evidence from a small pool of experts and expedited identification},
  volume       = {289},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Vehicle routing with endogenous learning: Application to
offshore plug and abandonment campaign planning. <em>EJOR</em>,
<em>289</em>(1), 93–106. (<a
href="https://doi.org/10.1016/j.ejor.2020.06.039">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When a particular service is performed many times, the duration of the service might reduce due to the effect of learning from similar tasks that have been performed before. In this article, we present an approach to account for such learning effects that arise in the context of vehicle routing operations. Our approach enables the consideration of endogenous learning, where the service times are dependent on the experience that is to be gained in the same routing horizon. We apply our approach to the problem of planning an offshore plug and abandonment campaign, where different vessels are being used to perform plugging operations on offshore oil and gas wells. We extend existing instances for this problem with observed learning data and investigate the effects of learning and cooperation. Results show that the inclusion of an endogenous learning effect leads to different and significantly better solutions compared to those that are found when the learning effect is neglected.},
  archive      = {J_EJOR},
  author       = {Steffen J. Bakker and Akang Wang and Chrysanthos E. Gounaris},
  doi          = {10.1016/j.ejor.2020.06.039},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {93-106},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Vehicle routing with endogenous learning: Application to offshore plug and abandonment campaign planning},
  volume       = {289},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Compact formulations and an iterated local search-based
matheuristic for the minimum weighted feedback vertex set problem.
<em>EJOR</em>, <em>289</em>(1), 75–92. (<a
href="https://doi.org/10.1016/j.ejor.2020.07.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given a weighted graph G = ( V , E ) , G=(V,E), the minimum weighted feedback vertex set problem consists in obtaining a minimum weight subset F ⊆ V of the vertex set whose removal makes the graph acyclic. Differently from other approaches in the literature, in this work we tackle this problem via the maximum weighted induced forest problem. First, we propose two new compact mixed integer programming (MIP) formulations, using a polynomial number of variables and constraints. Next, we develop a matheuristic that hybridizes a multi-start iterated local search heuristic with a MIP-based local search procedure. Extensive computational experiments carried out on a set of benchmark instances show that the newly proposed MILS + + -mtz matheuristic is extremely effective and outperforms or at least match the best heuristics available in the literature in terms of solution quality for 79 out of 99 (79.80\%) large instance groups, with 55 (55.56\%) of them being strictly better than the previously best known. Furthermore, the compact formulations were able to optimally solve 474 out of 810 test instances in less than 3600 seconds of running time.},
  archive      = {J_EJOR},
  author       = {Rafael A. Melo and Michell F. Queiroz and Celso C. Ribeiro},
  doi          = {10.1016/j.ejor.2020.07.006},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {75-92},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Compact formulations and an iterated local search-based matheuristic for the minimum weighted feedback vertex set problem},
  volume       = {289},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Finding the root graph through minimum edge deletion.
<em>EJOR</em>, <em>289</em>(1), 59–74. (<a
href="https://doi.org/10.1016/j.ejor.2020.07.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The line graph of a graph G has one node per each edge of G , two of them being adjacent only when the corresponding edges have a node of G in common. In this work, we consider the problem of finding the minimum number of edges to delete so that the resulting graph is a line graph, which presents an interesting application in haplotyping of diploid organisms. We propose an Integer Linear Programming formulation for this problem. We compare our approach with the only other existing formulation for the problem and explore the possibility of combining both of them. Finally, we present a computational study to compare the different approaches proposed.},
  archive      = {J_EJOR},
  author       = {Martine Labbé and Alfredo Marín and Mercedes Pelegrín},
  doi          = {10.1016/j.ejor.2020.07.001},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {59-74},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Finding the root graph through minimum edge deletion},
  volume       = {289},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Covering problems with polyellipsoids: A location analysis
perspective. <em>EJOR</em>, <em>289</em>(1), 44–58. (<a
href="https://doi.org/10.1016/j.ejor.2020.06.048">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we analyze the extension of the classical smallest enclosing disk problem to the case of the location of a polyellipsoid to fully cover a set of demand points in R d Rd . We prove that the problem is polynomially solvable in fixed dimension and analyze mathematical programming formulations for it. We also consider some geometric approaches for the problem in case the foci of the polyellipsoids are known. Extensions of the classical algorithm by Elzinga-Hearn are also derived for this new problem. Moreover, we address two extensions of the problem, as the case where the foci of the enclosing polyellipsoid are not given and have to be determined among a potential set of points or the induced covering problems when instead of polyellipsoids, one uses ordered median polyellipsoids. For these problems we also present Mixed Integer (Non) Linear Programming strategies that lead to efficient ways to solve it. Extensive computational experiments on different datasets show the usefulness of our solution methods.},
  archive      = {J_EJOR},
  author       = {Víctor Blanco and Justo Puerto},
  doi          = {10.1016/j.ejor.2020.06.048},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {44-58},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Covering problems with polyellipsoids: A location analysis perspective},
  volume       = {289},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Optimizing facility location and design. <em>EJOR</em>,
<em>289</em>(1), 31–43. (<a
href="https://doi.org/10.1016/j.ejor.2020.06.044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we develop a generalized framework and a novel methodology to simultaneously optimize locations and design decisions for a set of facilities that are facing competition from pre-existing facilities. The framework encompasses multi-attribute design decisions, an elastic customer demand mechanism that can capture both expansion and cannibalization effects, and a flexible demand allocation mechanism that encompasses both, proportional allocation (“gravity type”) and all-or-nothing models (such as p − p− median). Many classic location models appear as special cases of our Generalized Facility Location and Design Problem (GFLDP). We present an effective solution methodology, that allows us to approximate exact solutions to GDFLP to pre-selected accuracy levels. Our results show that not combining design and location decisions within a single model can lead to very substantial optimality gaps, thus underscoring the importance of GDFLP approach.},
  archive      = {J_EJOR},
  author       = {Robert Aboolian and Oded Berman and Dmitry Krass},
  doi          = {10.1016/j.ejor.2020.06.044},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {31-43},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Optimizing facility location and design},
  volume       = {289},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The multi-parent biased random-key genetic algorithm with
implicit path-relinking and its real-world applications. <em>EJOR</em>,
<em>289</em>(1), 17–30. (<a
href="https://doi.org/10.1016/j.ejor.2019.11.037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we present the Multi-Parent Biased Random-Key Genetic Algorithm with Implicit Path-Relinking (BRKGA-MP-IPR), a variant of the Biased Random-Key Genetic Algorithm that employs multiple (biased) parents to generate offspring instead of the usual two, and is hybridized with a novel, implicit path-relinking local search procedure. By operating over the standard unit hypercube, such path-relinking mechanism leverages the population representation of the BRKGA and thus provides complete independence between the local search procedure and the problem definition and implementation. This approach contrasts with traditional path-relinking procedures that are tied to the problem structure. Having both BRKGA and IPR operate over the same solution space not only makes the intensification/diversification paradigm more natural but also greatly simplifies the development effort from the perspective of the practitioner, as one only needs to develop a decoder to map unit random-key vectors to the solution space of the problem on hand. Apart from such key benefits, extensive computational experiments solving real-world problems, such as over-the-air software upgrade scheduling, network design problems, and combinatorial auctions, show that the BRKGA-MP-IPR offers performance benefits over the standard BRKGA as well as the BRKGA with multiple parents.},
  archive      = {J_EJOR},
  author       = {Carlos E. Andrade and Rodrigo F. Toso and José F. Gonçalves and Mauricio G.C. Resende},
  doi          = {10.1016/j.ejor.2019.11.037},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {17-30},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {The multi-parent biased random-key genetic algorithm with implicit path-relinking and its real-world applications},
  volume       = {289},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Retail shelf space planning problems: A comprehensive review
and classification framework. <em>EJOR</em>, <em>289</em>(1), 1–16. (<a
href="https://doi.org/10.1016/j.ejor.2020.06.018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The retail shelf space planning problem has long been addressed by Marketing and Operations Research (OR) professionals and researchers, with the first empirical studies tracing back to the 1960s and the first modelling approaches back to the 1970s. Due to this long history, this field presents a wide range of different mathematical modelling approaches that deal with the decisions surrounding a set of products and not only define their space assignment and related quantity, but also their vertical and horizontal positioning within a retail shelf. These decisions affect customer demand, namely in the form of space- and position-dependent demand and replenishment requirements. Current literature provides either more comprehensive decision models with a wide range of demand effects but limited practical applicability, or more simplistic model formulations with greater practical application but limited consideration of the associated demand. Despite the recent progress seen in this research area, no work has yet systematised published research with a clear focus on shelf space planning. As a result, there is neither any up-to-date structured literature nor a unique model approach, and no benchmark sets are available. This paper provides a description and a state-of-the-art literature review of this problem, focusing on optimisation models. Based on this review, a classification framework is proposed to systematise the research into a set of sub-problems, followed by a unified approach with a univocal notation of model classes. Future lines of research point to the most promising open questions in this field.},
  archive      = {J_EJOR},
  author       = {Teresa Bianchi-Aguiar and Alexander Hübner and Maria Antónia Carravilla and José Fernando Oliveira},
  doi          = {10.1016/j.ejor.2020.06.018},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {1-16},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Retail shelf space planning problems: A comprehensive review and classification framework},
  volume       = {289},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Investment and financing decisions in the presence of
time-to-build. <em>EJOR</em>, <em>288</em>(3), 1068–1084. (<a
href="https://doi.org/10.1016/j.ejor.2020.06.034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study a firm’s optimal decisions on investment, default, and financing when the amount of time and the running costs for project completion are uncertain. In the presence of time-to-build, a firm makes conservative investment and financing decisions; investment is delayed, and the optimal leverage ratio is inverted U-shaped with respect to the size of the lag. Although equity holders can choose to default before the project has been completed, the default probability in the presence of time-to-build is lower than that in the absence of a lag in most cases because of the conservative investment and financing decisions. Given the lower default probability, equity holders may benefit more from debt financing in the presence of time-to-build than they would in the absence of a lag. When firms can shorten their expected time-to-build by bearing more costs, unlevered firms strive to reduce the lag more than optimally levered firms do. However, highly levered firms utilize more resources to reduce the lag than all-equity firms do because equity holders are more concerned about the possibility of default before the project’s completion.},
  archive      = {J_EJOR},
  author       = {Haejun Jeon},
  doi          = {10.1016/j.ejor.2020.06.034},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1068-1084},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Investment and financing decisions in the presence of time-to-build},
  volume       = {288},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Quantitative portfolio selection: Using density forecasting
to find consistent portfolios. <em>EJOR</em>, <em>288</em>(3),
1053–1067. (<a
href="https://doi.org/10.1016/j.ejor.2020.06.033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the knowledge that the ex-post performance of Markowitz efficient portfolios is inferior to that implied ex-ante, we make two contributions to the portfolio selection literature. Firstly, we propose a methodology to identify the region of risk-expected return space where ex-post performance matches ex-ante estimates. Secondly, we extend ex-post efficient set mathematics to overcome the biases in the estimation of the ex-ante efficient frontier. A density forecasting approach is used to measure the accuracy of ex-ante estimates using the Berkowitz statistic, we develop this statistic to increase its sensitivity to changes in the data generating process. The area of risk-expected return space where the density forecasts are accurate, where ex-post performance matches ex-ante estimates, is termed the consistency region. Under the &#39;laboratory&#39; conditions of a simulated multivariate normal data set, we compute the consistency region and the estimated ex-post frontier. Over different sample sizes used for estimation, the behaviour of the consistency region is shown to be both intuitively reasonable and to enclose the estimated ex-post frontier. Using actual data from the constituents of the US Dow Jones 30 index, we show that the size of the consistency region is time dependent and, in volatile conditions, may disappear. Using our development of the Berkowitz statistic, we demonstrate the superior performance of an investment strategy based on consistent rather than efficient portfolios.},
  archive      = {J_EJOR},
  author       = {N. Meade and J.E. Beasley and C.J. Adcock},
  doi          = {10.1016/j.ejor.2020.06.033},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1053-1067},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Quantitative portfolio selection: Using density forecasting to find consistent portfolios},
  volume       = {288},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A polynomial-time method to compute all nash equilibria
solutions of a general two-person inspection game. <em>EJOR</em>,
<em>288</em>(3), 1036–1052. (<a
href="https://doi.org/10.1016/j.ejor.2020.06.032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a two-person nonzero-sum simultaneous inspection game that takes place at multiple sites. The inspector has a limited inspection resource. She needs to decide which sites to inspect, and with how much effort, while adhering also to local restrictions on the permitted inspections levels at the sites. The inspectee has several employees who work on his behalf. He needs to decide how to distribute them across the sites, and how they should act there. Computation of Nash equilibria is challenging for this sort of games. Still, we develop a linear-time algorithm that determines all Nash equilibria solutions of the game, and provide explicit (easily computable) expressions for all possible Nash equilibria. We then derive some managerial insights by applying the algorithm to several examples, and examining the Nash equilibria, including an outcome that an increase in the inspection resource may induce the inspectee to cooperate more at sites without increasing the inspection levels at them.},
  archive      = {J_EJOR},
  author       = {Yael Deutsch},
  doi          = {10.1016/j.ejor.2020.06.032},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1036-1052},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A polynomial-time method to compute all nash equilibria solutions of a general two-person inspection game},
  volume       = {288},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The effects of asset liquidity on dynamic sell-out and
bankruptcy decisions. <em>EJOR</em>, <em>288</em>(3), 1017–1035. (<a
href="https://doi.org/10.1016/j.ejor.2020.06.031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We develop a dynamic bankruptcy model with asset illiquidity. In the model, a distressed firm chooses between sell-out and default, as well as its timing under the assumption that sell-out is feasible only at Poisson jump times, where the arrival rate of acquirers stands for asset liquidity. With lower asset liquidity, the firm increases the sell-out region to mitigate the risk of not finding an acquirer until bankruptcy. Despite the larger sell-out region, lower asset liquidity increases the default probability and decreases the equity, debt, and firm values. In the optimal capital structure, with lower asset liquidity, the firm reduces leverage, but the cautious capital structure does not fully offset the increased default risk. The stock price reaction caused by sell-out depends on the sell-out timing. When the firm’s asset value is not sufficiently high, the stock price jump size is an inverted U-shape with the economic state variable. Lower asset liquidity increases the jump size due to greater surprise. These results fit empirical observations.},
  archive      = {J_EJOR},
  author       = {Michi Nishihara and Takashi Shibata},
  doi          = {10.1016/j.ejor.2020.06.031},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1017-1035},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {The effects of asset liquidity on dynamic sell-out and bankruptcy decisions},
  volume       = {288},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Dynamic oligopoly pricing with reference-price effects.
<em>EJOR</em>, <em>288</em>(3), 1006–1016. (<a
href="https://doi.org/10.1016/j.ejor.2020.06.025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We analyze the strategic implications of consumers’ reference-price effects, either symmetric (for loss-neutral consumers) or asymmetric (for loss-averse consumers), in a differentiated oligopoly model where firms compete either in prices (à la Bertrand) or in quantities (à la Cournot) over an infinite time horizon. The dynamic game is specified in continuous time. The solution concept is Markov Perfect Equilibrium. We show how price dynamics in the presence of reference-price effects crucially depends on the nature of market competition. One of the main results of our analysis is that, with loss-averse consumers, there exists an interval of initial reference prices such that firms adopt the same constant-pricing strategy in both the Bertrand and the Cournot games, implying that the distinction between price and quantity competition has no impact on market conduct and performance.},
  archive      = {J_EJOR},
  author       = {Luca Colombo and Paola Labrecciosa},
  doi          = {10.1016/j.ejor.2020.06.025},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1006-1016},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Dynamic oligopoly pricing with reference-price effects},
  volume       = {288},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Bank-sourced credit transition matrices: Estimation and
characteristics. <em>EJOR</em>, <em>288</em>(3), 992–1005. (<a
href="https://doi.org/10.1016/j.ejor.2020.06.024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study proposes and analyses a novel alternative to credit transition matrices (CTMs) developed by credit rating agencies - bank-sourced CTMs. It provides a unique insight into estimation of bank-sourced CTMs by assessing the extent to which the CTMs depend on the characteristics of the underlying credit risk datasets and the aggregation method and outlines that the choice of aggregation approach has a substantial effect on credit risk model results. Further, we show that bank-sourced CTMs are more dynamic than those of credit rating agencies, with higher off-diagonal transition rates and higher propensity to upgrade. Finally, we create a set of industry-specific CTMs, otherwise unobtainable due to the data sparsity faced by credit rating agencies, and highlight the implications of their differences, signalling the existence of industry-specific business cycles. The study uses a unique and large dataset of internal credit risk estimates from 24 global banks covering monthly observations on more than 26,000 large corporates and employs large-scale Monte Carlo simulations. This approach can be replicated by regulators (e.g., data collected by the European Central Bank in the AnaCredit project) and used by organisations aiming to improve their credit risk models.},
  archive      = {J_EJOR},
  author       = {Barbora Štěpánková},
  doi          = {10.1016/j.ejor.2020.06.024},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {992-1005},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Bank-sourced credit transition matrices: Estimation and characteristics},
  volume       = {288},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Determinants of allocative and technical inefficiency in
stochastic frontier models: An analysis of norwegian electricity
distribution firms. <em>EJOR</em>, <em>288</em>(3), 983–991. (<a
href="https://doi.org/10.1016/j.ejor.2020.06.023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent econometric advances have made it possible to distinguish between persistent and transient technical inefficiency along with allocative inefficiency in stochastic frontier models for panel data. Kumbhakar et al. (2020) and Lai and Kumbhakar (2019) introduce a methodology that allows for the estimation of these inefficiency components and costs therefrom, while including determinants of both components of technical inefficiency. We extend these models to include technical change and determinants of allocative inefficiency (input misallocation). Including a set of variables that influence input misallocation, we are able to determine the effects of these variables on the cost of allocative inefficiency. We provide empirical evidence on the costs of all three types of inefficiency using data on 149 Norwegian electricity distribution firms between 2000 and 2016. We find that the cost of input misallocation is only slightly lower than that of technical inefficiency. Our results reject a commonly imposed modeling assumption that firms are fully allocatively efficient.},
  archive      = {J_EJOR},
  author       = {Andrew Musau and Subal C. Kumbhakar and Ørjan Mydland and Gudbrand Lien},
  doi          = {10.1016/j.ejor.2020.06.023},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {983-991},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Determinants of allocative and technical inefficiency in stochastic frontier models: An analysis of norwegian electricity distribution firms},
  volume       = {288},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Identifying behaviorally robust strategies for normal form
games under varying forms of uncertainty. <em>EJOR</em>,
<em>288</em>(3), 971–982. (<a
href="https://doi.org/10.1016/j.ejor.2020.06.022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advances in behavioral game theory address a persistent criticism of traditional solution concepts that rely upon perfect rationality: equilibrium results are often inconsistent with empirical evidence. For normal form games, the Cognitive Hierarchy model is a solution concept based upon a sequential reasoning process, yielding accurate characterizations of experimental human game play. These characterizations are enabled by a statistically estimated parameter describing the average number of reasoning steps players utilize. If an arbitrary player were to know this parameter ex ante , they could maximize their expected payoff accordingly. However, given the nature of statistical estimation, such parameter point estimates are unknown prior to experimentation and are susceptible to error afterward. Therefore, we consider the normal form game as a decision problem from the perspective of an arbitrary player who is uncertain of opponents’ reasoning ability. Assuming such a player is confronting a set of boundedly rational opponents whose play is characterized by the Cognitive Hierarchy model, we develop a suite of six mathematical programming formulations to maximize the player’s minimum payoff, and we identify the appropriate formulation for the level of information regarding an opponent population’s reasoning ability. By leveraging robust optimization, stochastic programming, and distributionally robust optimization techniques, our set of models yields prescriptive strategies of play in a normal form game with incomplete knowledge regarding adversary rationality. A software package implementing these constructs is developed and applied to illustrative instances, demonstrating how behaviorally robust strategies vary in accordance with the underlying uncertainty.},
  archive      = {J_EJOR},
  author       = {William N. Caballero and Brian J. Lunday and Richard P. Uber},
  doi          = {10.1016/j.ejor.2020.06.022},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {971-982},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Identifying behaviorally robust strategies for normal form games under varying forms of uncertainty},
  volume       = {288},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The impact of product recall on advertising decisions and
firm profit while envisioning crisis or being hazard myopic.
<em>EJOR</em>, <em>288</em>(3), 953–970. (<a
href="https://doi.org/10.1016/j.ejor.2020.06.021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The occurrence of a product recall can have a disastrous effect on the firm responsible for the recall. Any major recall by a firm can negatively affect the goodwill of the firm. Consequently, the firm incurs a substantial indirect cost due to decline in sales and loss in profit. Moreover, a competitor’s opportunistic reaction can intensify the recalling firm’s damages. Strategic use of advertising recovers lost goodwill and mitigates the damages made by a product recall. In this paper, using a goodwill based model under a differential game framework, we analyze the equilibrium strategies of two competing manufacturers when either one firm or both can issue a product recall at a random time, and investigate (i) the firms’ equilibrium advertising strategies (ii) analyze the impact of the recall on a firm’s profit (iii) introduce and investigate the effect of “hazard myopia” (a firm’s inability to foresee the crisis likelihood) on a firm’s advertising decisions and profit. Our study finds that the equilibrium advertising strategies of competing firms depend on the impact and likelihood of the recall. Notably, we find that when both the firms are focal firms without the prior knowledge of who will recall first in a planning horizon, adjusting optimal advertising at an appropriate time is essential. Surprisingly, a product-recall with a minor impact can increase the focal firm’s long-term expected profit. On the other hand, hazard myopia can be profitable if the long-term effect of the recall is small. Our findings suggest that advertising levels of firms should differ in pre-recall and post-recall regimes depending on the impact and likelihood of the recall.},
  archive      = {J_EJOR},
  author       = {Arka Mukherjee and Satyaveer S. Chauhan},
  doi          = {10.1016/j.ejor.2020.06.021},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {953-970},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {The impact of product recall on advertising decisions and firm profit while envisioning crisis or being hazard myopic},
  volume       = {288},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Household lifetime strategies under a self-contagious
market. <em>EJOR</em>, <em>288</em>(3), 935–952. (<a
href="https://doi.org/10.1016/j.ejor.2020.05.060">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we consider the optimal strategies in asset allocation, consumption, and life insurance for a household with an exogenous stochastic income under a self-contagious market which is modeled by bivariate self-exciting Hawkes jump processes. By using the Hawkes process, jump intensities of the risky asset depend on the history path of that asset. In addition to the financial risk, the household is also subject to an uncertain lifetime and a fixed retirement date. A lump-sum payment will be paid as a heritage, if the wage earner dies before the retirement date. Under the dynamic programming principle, explicit solutions of the optimal controls are obtained when asset prices follow special jump distributions. For more general cases, we apply the Feynman–Kac formula and develop an iterative numerical scheme to derive the optimal strategies. We also prove the existence and uniqueness of the solution to the fixed point equation and the convergence of an iterative numerical algorithm. Numerical examples are presented to show the effect of jump intensities on the optimal controls.},
  archive      = {J_EJOR},
  author       = {Guo Liu and Zhuo Jin and Shuanming Li},
  doi          = {10.1016/j.ejor.2020.05.060},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {935-952},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Household lifetime strategies under a self-contagious market},
  volume       = {288},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An examination of the role of price insurance products in
stimulating investment in agriculture supply chains for sustained
productivity. <em>EJOR</em>, <em>288</em>(3), 918–934. (<a
href="https://doi.org/10.1016/j.ejor.2020.06.030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study examines how managing risk by introducing commodity price insurances may improve the likelihood of increased investment in agri-food supply chains. A model is introduced which shows how insurance products on index prices can reduce the uncertainty of the impact of investment, and also how lower investment can generate the same impact as a higher investment. To show our results, we use two different frameworks which include total profit (Pareto optimal) and Stackelberg game setups. The results demonstrate that in both frameworks the investment will have a greater impact when an insurance product is present. By implication, the study presents an encouraging message to the insurance industry to introduce products to secure supply chain actors’ revenue leading to an increase in investment rate. Consequently, the study offers insight into how the role of traditional government subsidies for protecting farmers, particularly the small to medium-sized farms, may be revisited by replacing some of the existing subsidisation policies with revenue insurance.},
  archive      = {J_EJOR},
  author       = {Hirbod Assa and Hossein Sharifi and Andrew Lyons},
  doi          = {10.1016/j.ejor.2020.06.030},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {918-934},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {An examination of the role of price insurance products in stimulating investment in agriculture supply chains for sustained productivity},
  volume       = {288},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Product line optimization in the presence of preferences for
compromise alternatives. <em>EJOR</em>, <em>288</em>(3), 902–917. (<a
href="https://doi.org/10.1016/j.ejor.2020.06.029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advances in customer choice analysis demonstrated the strong impact of compromise alternatives on the behaviour of decision-makers in a wide range of decision situations. Compromise alternatives are characterized by an intermediate performance on some of the relevant attributes. For instance, price compromises are well known in the sense that customers tend to buy neither the cheapest, nor the most expensive alternative, but the mid-priced one. However, thus far, the literature on product line optimization has not considered such context effects. In this paper, we propose a model-based approach for optimal product line selection which incorporates customers’ preferences for compromise alternatives. We consider customer choice in a realistic, sophisticated fashion by applying an established utility model that integrates compromise variables into a multinomial logit model. We formulate the resulting optimization problem as a mixed-integer linear program. The challenging feature for modelling – making the formulation substantially more complicated than existing ones without compromises – are the endogenous effects of selected products on other alternatives’ utilities that need to be adequately captured via compromise variables. Based on data we collected by a stated choice experiment in a retail setting, we perform a computational study and demonstrate the superiority of our product line selection approach compared to a reference model that does not take compromises into account. Even under uncertainty of the estimated utility parameters, profit gains of, on average, 23\% can be achieved in our experimental setting.},
  archive      = {J_EJOR},
  author       = {Georg Bechler and Claudius Steinhardt and Jochen Mackert and Robert Klein},
  doi          = {10.1016/j.ejor.2020.06.029},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {902-917},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Product line optimization in the presence of preferences for compromise alternatives},
  volume       = {288},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-stage stochastic programming models for provisioning
cloud computing resources. <em>EJOR</em>, <em>288</em>(3), 886–901. (<a
href="https://doi.org/10.1016/j.ejor.2020.06.027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We focus on the resource provisioning problem of a cloud consumer from an Infrastructure-as-a-Service type of cloud. The cloud provider offers two deployment options, which can be mixed and matched as appropriate. Cloud instances may be reserved for a fixed time period in advance at a smaller usage cost per hour but require a full commitment and payment for the entire contract duration. In contrast, on-demand instances reflect a pay-as-you-go policy at a premium. The trade-off between these two options is rooted in the inherent uncertainty in demand and price and makes it attractive to complement a base reserved capacity with on-demand capacity to hedge against the spikes in demand. This paper provides several novel multi-stage stochastic programming formulations to enable a cloud consumer to handle the cloud resource provisioning problem at a tactical level. We first formulate the cloud resource provisioning problem as a risk-neutral multi-stage stochastic program, which serves as the base model for further modeling variants. In our second set of models, we also incorporate a certain concept of system reliability. In particular, chance constraints integrated into the base formulation require a minimum service level met from reserved capacity, provide more visibility into the future available capacity, and smooth out expensive on-demand usage by hedging against possible demand fluctuations. An extensive computational study demonstrates the value of the proposed models by discussing computational performance, gleaning practical managerial insights from the analysis of the solutions of the proposed models, and quantifying the value of the stochastic solutions.},
  archive      = {J_EJOR},
  author       = {Kerem Bülbül and Nilay Noyan and Hazal Erol},
  doi          = {10.1016/j.ejor.2020.06.027},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {886-901},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Multi-stage stochastic programming models for provisioning cloud computing resources},
  volume       = {288},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Forecasting corporate failure using ensemble of
self-organizing neural networks. <em>EJOR</em>, <em>288</em>(3),
869–885. (<a href="https://doi.org/10.1016/j.ejor.2020.06.020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For more than a decade, the number of research works that deal with ensemble methods applied to bankruptcy prediction has been increasing. Ensemble techniques present some characteristics that, in most situations, allow them to achieve better forecasts than those estimated with single models. However, the difference between the performance of an ensemble and that of its base classifier but also between that of ensembles themselves, is often low. This is the reason why we studied a way to design an ensemble method that might achieve better forecasts than those calculated with traditional ensembles. It relies on a quantification process of data that characterize the financial situation of a sample of companies using a set of self-organizing neural networks, where each network has two main characteristics: its size is randomly chosen and the variables used to estimate its weights are selected based on a criterion that ensures the fit between the structure of the network and the data used over the learning process. The results of our study show that this technique makes it possible to significantly reduce both the type I and type II errors that can be obtained with conventional methods.},
  archive      = {J_EJOR},
  author       = {Philippe du Jardin},
  doi          = {10.1016/j.ejor.2020.06.020},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {869-885},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Forecasting corporate failure using ensemble of self-organizing neural networks},
  volume       = {288},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Integrated modeling of extended agro-food supply chains: A
systems approach. <em>EJOR</em>, <em>288</em>(3), 852–868. (<a
href="https://doi.org/10.1016/j.ejor.2020.06.036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The current intense food production-consumption is one of the main sources of environmental pollution and contributes to anthropogenic greenhouse gas emissions. Organic farming is a potential way to reduce environmental impacts by excluding synthetic pesticides and fertilizers from the process. Despite ecological benefits, it is unlikely that conversion to organic can be financially viable for farmers, without additional support and incentives from consumers. This study models the interplay between consumer preferences and socio-environmental issues related to agriculture and food production. We operationalize the novel concept of extended agro-food supply chain and simulate adaptive behavior of farmers, food processors, retailers, and customers. Not only the operational factors (e.g., price, quantity, and lead time), but also the behavioral factors (e.g., attitude, perceived control, social norms, habits, and personal goals) of the food suppliers and consumers are considered in order to foster organic farming. We propose an integrated approach combining agent-based, discrete-event, and system dynamics modeling for a case of wine supply chain. Findings demonstrate the feasibility and superiority of the proposed model over the traditional sustainable supply chain models in incorporating the feedback between consumers and producers and analyzing management scenarios that can urge farmers to expand organic agriculture. Results further indicate that demand-side participation in transition pathways towards sustainable agriculture can become a time-consuming effort if not accompanied by the middle actors between consumers and farmers. In practice, our proposed model may serve as a decision-support tool to guide evidence-based policymaking in the food and agriculture sector.},
  archive      = {J_EJOR},
  author       = {Firouzeh Taghikhah and Alexey Voinov and Nagesh Shukla and Tatiana Filatova and Mikhail Anufriev},
  doi          = {10.1016/j.ejor.2020.06.036},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {852-868},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Integrated modeling of extended agro-food supply chains: A systems approach},
  volume       = {288},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Advertising and quality improving strategies in a supply
chain when facing potential crises. <em>EJOR</em>, <em>288</em>(3),
839–851. (<a href="https://doi.org/10.1016/j.ejor.2020.06.026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we consider a supply chain that faces a potential brand crisis, with one manufacturer deciding quality improvement and global advertising levels, and one retailer determining local advertising effort. The goodwill model proposed by Nerlove and Arrow (1962) is adopted here under the assumption that when the crisis happens, the companies suffer a sharp decrease in the goodwill. We characterize the feedback Nash equilibrium, and then we compare the corresponding quality and advertising strategies and outcomes with those of the case where the potential crises are absent, and where the companies do not invest in quality. The effects of the instantaneous crisis rate and the short-term and long-term damages are also evaluated. Our results reveal that the pre-crisis quality improvement accelerates the goodwill build-up before the crisis, and also helps the recovery in post-crisis regime. Its twofold function suggests that one of the pre- and post-crisis regimes/instants ought to be matched with more intense investment in both quality and global advertising, depending on the overall effect of instantaneous crisis rate, short-term damage and long-term damage. This carryover effect also brings a non-monotonicity of quality improvement effort and value functions with respect to the instantaneous crisis rate. These properties leave the chance to mitigate the loss by anticipating crisis for both members under certain circumstances.},
  archive      = {J_EJOR},
  author       = {Lijue Lu and Jorge Navas},
  doi          = {10.1016/j.ejor.2020.06.026},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {839-851},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Advertising and quality improving strategies in a supply chain when facing potential crises},
  volume       = {288},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Optimal government scrappage subsidies in the presence of
strategic consumers. <em>EJOR</em>, <em>288</em>(3), 829–838. (<a
href="https://doi.org/10.1016/j.ejor.2020.06.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many countries have introduced vehicle scrappage programs to motivate consumers to replace their old cars earlier. Since these programs are generally offered over a given period of time, policy makers need to plan for inter-temporal subsidies. Considering a two-period game between strategic consumers and the government, we determine the optimal scrappage subsidy levels. Our results demonstrate that the subsidy level in the second period is higher than in the first, allowing the government to discriminate on price (or subsidy) between consumers with different valuations. In addition, we show that subsidy levels increase with the government’s targeted replacement level. However, when the government target level changes from intermediate to high, the first-period subsidy drops while the second-period subsidy remains unchanged.},
  archive      = {J_EJOR},
  author       = {Hosain Zaman and Georges Zaccour},
  doi          = {10.1016/j.ejor.2020.06.017},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {829-838},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Optimal government scrappage subsidies in the presence of strategic consumers},
  volume       = {288},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Real-time ride-sharing framework with dynamic timeframe and
anticipation-based migration. <em>EJOR</em>, <em>288</em>(3), 810–828.
(<a href="https://doi.org/10.1016/j.ejor.2020.06.038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The emergence of large-scale online ride-sharing platforms has substantially reformed the way people travel. Ride-sharing plays a very positive role in alleviating traffic congestion, reducing carbon emissions, and improving travel efficiency by sharing transportation resources. However, it is challenging to design an effective real-time ride-sharing framework due to the complex dynamics of a real-life environment. Most proposed models have difficulties in following the density variation of commuters in different time periods. Moreover, the existing matching methods have limitations related to large-scale instances. Therefore, in this paper, we propose a real-time ride-sharing framework with a dynamic timeframe and anticipation-based migration. The problem is formally modeled and two concrete approaches are introduced to dynamically segment timeframes and migrate commuters to future timeframes based on historical data. To solve this problem, we propose a multi-strategy solution graph search heuristic that can easily deal with large-scale instances and provide high-quality solutions. We also conduct extensive experiments on real-world datasets to demonstrate the efficiency and effectiveness of the proposed framework.},
  archive      = {J_EJOR},
  author       = {Yuhan Guo and Yu Zhang and Youssef Boulaksil},
  doi          = {10.1016/j.ejor.2020.06.038},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {810-828},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Real-time ride-sharing framework with dynamic timeframe and anticipation-based migration},
  volume       = {288},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A column generation approach for an emission-oriented
vehicle routing problem on a multigraph. <em>EJOR</em>, <em>288</em>(3),
794–809. (<a href="https://doi.org/10.1016/j.ejor.2020.06.035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, an emission-minimizing vehicle routing problem with heterogeneous vehicles and a heterogeneous road and traffic network is considered as it is typical in urban areas. Depending on the load of the vehicle, there exist multiple emission-minimal arcs for traveling between two locations. To solve the vehicle routing problem efficiently, a column generation approach is presented. At the core of the procedure an emission-oriented elementary shortest path problem on a multigraph is solved by a backward labeling algorithm. It is shown that the labeling algorithm can be sped up by adjusting the dual master program and by restricting the number of labels propagated in the sub-problem. The column generation technique is used to setup a fast heuristic as well as a branch-and-price algorithm. Both procedures are evaluated based on test instances with up to 100 customers. It turns out that the heuristic approach is very effective and generates near-optimal solutions with gaps below 0.1\% on average while only requiring a fraction of the runtime of the exact approach.},
  archive      = {J_EJOR},
  author       = {Martin Behnke and Thomas Kirschstein and Christian Bierwirth},
  doi          = {10.1016/j.ejor.2020.06.035},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {794-809},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A column generation approach for an emission-oriented vehicle routing problem on a multigraph},
  volume       = {288},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Two-echelon vehicle routing problem with satellite
bi-synchronization. <em>EJOR</em>, <em>288</em>(3), 775–793. (<a
href="https://doi.org/10.1016/j.ejor.2020.06.019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In considering route optimization at a series of express stages from pickup to delivery via the intercity linehaul, we introduce the two-echelon vehicle routing problem with satellite bi-synchronization (2E-VRP-SBS) from the perspective of modeling the routing problems of two-echelon networks. The 2E-VRP-SBS involves the inter-satellite linehaul on the first echelon, and the pickups from senders to origin satellites (i.e., satellites for cargo collection) and deliveries from destination satellites (i.e., satellites for cargo deliveries) to receivers on the second echelon. The 2E-VRP-SBS integrates satellite bi-synchronization constraints, multiple vehicles, and time window constraints on the two-echelon network and aims to find cost-minimizing routes for various types of trucks. Satellite bi-synchronization constraints, which synchronously guarantee the synchronization at origin satellites and the synchronization at destination satellites, provide an innovative method to formulate the two-echelon routing problem. In this study, we develop a mixed-integer programming model for the 2E-VRP-SBS. An exact method using CPLEX solver is presented and a modified adaptive large neighborhood search is conducted. Furthermore, the effectiveness of the 2E-VRP-SBS formulation and the applicability of the heuristic for various instances are experimentally evaluated.},
  archive      = {J_EJOR},
  author       = {Hongqi Li and Haotian Wang and Jun Chen and Ming Bai},
  doi          = {10.1016/j.ejor.2020.06.019},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {775-793},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Two-echelon vehicle routing problem with satellite bi-synchronization},
  volume       = {288},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A matheuristic algorithm for stochastic home health care
planning. <em>EJOR</em>, <em>288</em>(3), 753–774. (<a
href="https://doi.org/10.1016/j.ejor.2020.06.040">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Efficient human resource planning is the cornerstone of designing an effective home health care system. Human resource planning in home health care system consists of decisions on districting/zoning, staff dimensioning, resource assignment, scheduling, and routing. In this study, a two-stage stochastic mixed integer model is proposed that considers these decisions simultaneously. In the planning phase of a home health care system, the main uncertain parameters are travel and service times. Hence, the proposed model takes into account the uncertainty in travel and service times. Districting and staff dimensioning are defined as the first stage decisions, and assignment, scheduling, and routing are considered as the second stage decisions. A novel algorithm is developed for solving the proposed model. The algorithm consists of four phases and relies on a matheuristic-based method that calls on various mixed integer models. In addition, an algorithm based on the progressive hedging and Frank and Wolf algorithms is developed to reduce the computational time of the second phase of the proposed matheuristic algorithm. The efficiency and accuracy of the proposed algorithm are tested through several numerical experiments. The results prove the ability of the algorithm to solve large instances.},
  archive      = {J_EJOR},
  author       = {Erfaneh Nikzad and Mahdi Bashiri and Babak Abbasi},
  doi          = {10.1016/j.ejor.2020.06.040},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {753-774},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A matheuristic algorithm for stochastic home health care planning},
  volume       = {288},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Using schedule risk analysis with resource constraints for
project control. <em>EJOR</em>, <em>288</em>(3), 736–752. (<a
href="https://doi.org/10.1016/j.ejor.2020.06.015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Schedule Risk Analysis (SRA) has shown to provide reliable activity sensitivity information for taking corrective actions during project control. More precisely, by selecting a small subset of activities with high sensitivity values for taking corrective actions, the project outcome can be improved. In resource constrained projects, disrupted activities can affect both their successors as well as other activities when resource conflicts are induced. Since SRA focuses solely on the project network to determine the sensitivity of activities, the traditional SRA metrics do not accurately reflect the activity sensitivity for resource constrained projects. In this paper, the traditional SRA metrics are extended for resource constrained projects, and a novel resource-based sensitivity metric is introduced (RC-SRA metrics). A computational experiment is conducted to investigate the ability of the RC-SRA metrics to identify activities with higher sensitivity values. In addition, two activity selection strategies, defined as the normal strategy and sequential strategy, are designed to select activities for taking corrective actions. Further, two types of corrective actions are proposed to reduce the activity duration or resource demand in case of delays, respectively. Finally, the impact of dynamically updating the RC-SRA metrics during project execution is examined. The computational results show that the normal activity selection strategy is recommended for serial projects, while the sequential strategy is preferred for parallel projects. The results also indicate that reducing the activity durations performs better than reducing the resource demand of activities. Finally, it is shown that updating the RC-SRA metrics dynamically during project execution improves the efficiency of the corrective action taking process.},
  archive      = {J_EJOR},
  author       = {Jie Song and Annelies Martens and Mario Vanhoucke},
  doi          = {10.1016/j.ejor.2020.06.015},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {736-752},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Using schedule risk analysis with resource constraints for project control},
  volume       = {288},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A hybrid heuristic for the maximum dispersion problem.
<em>EJOR</em>, <em>288</em>(3), 721–735. (<a
href="https://doi.org/10.1016/j.ejor.2020.06.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we propose a hybrid heuristic for the Maximum Dispersion Problem of finding a balanced partition of a set of objects such that the shortest intra-part distance is maximized. In contrast to clustering problems, dispersion problems aim for a large spread of objects in the same group. They arise in many practical applications such as waste collection and the formation of study groups. The heuristic alternates between finding a balanced solution, and increasing the dispersion. Balancing is achieved by a combination of a minimum cost flow algorithm to find promising pairs of parts and a branch-and-bound algorithm that searches for an optimal balance, and the dispersion is increased by a local search followed by an ejection chain method for escaping local minima. We also propose new upper bounds for the problem. In computational experiments we show that the heuristic is able to find solutions significantly faster than previous approaches. Solutions are close to optimal and in many cases provably optimal.},
  archive      = {J_EJOR},
  author       = {Alex Gliesch and Marcus Ritt},
  doi          = {10.1016/j.ejor.2020.06.011},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {721-735},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A hybrid heuristic for the maximum dispersion problem},
  volume       = {288},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The impact of controllable production rates on the
performance of inventory systems: A systematic review of the literature.
<em>EJOR</em>, <em>288</em>(3), 703–720. (<a
href="https://doi.org/10.1016/j.ejor.2020.05.033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The lot sizing problem has attracted the attention of researchers for more than a century, and it still belongs to the most relevant decision problems in many manufacturing companies. During the evolution of research on lot sizing, the seminal economic order quantity (EOQ) model proposed by Harris [1913. How many parts to make at once. Factory, the Magazine of Management, 10 (2), 135-136.] has remained the most popular model, despite its limitations. To support lot sizing decisions in practice, researchers have frequently extended Harris’ basic EOQ model to better reflect the characteristics of real production processes. One of these extensions is the consideration of controllable (variable) production rates, which gives production planners more flexibility in managing the build-up and depletion of inventory and in controlling costs. The aim of this paper is to provide a comprehensive and systematic overview of EPQ-type lot sizing models that consider controllable production rates. First, the paper proposes a conceptual framework that captures the characteristics of controllable production rates including the planning horizon (short vs. long term), the number of potential interventions per production run (one vs. multiple), the effect of controllable production rates on the performance of the inventory system (e.g., unit production costs, energy consumption, product quality), and the type of lot sizing model considered (e.g., two-stage models, multi-stage models, multi-item models). Secondly, the paper presents the results of a systematic literature review and evaluates the state-of-research of lot sizing models with controllable production rates. Based on the analysis of the literature, key trends are summarized and promising research opportunities are discussed.},
  archive      = {J_EJOR},
  author       = {Christoph H. Glock and Eric H. Grosse},
  doi          = {10.1016/j.ejor.2020.05.033},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {703-720},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {The impact of controllable production rates on the performance of inventory systems: A systematic review of the literature},
  volume       = {288},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A model of ambition, aspiration and happiness.
<em>EJOR</em>, <em>288</em>(2), 692–702. (<a
href="https://doi.org/10.1016/j.ejor.2020.06.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Can payoffs buy happiness? People&#39;s perception on their current payoffs depends on the social context and the historical context. This paper develops a utility model that captures both effects of interpersonal comparisons and self-adaptations in evaluating time streams of payoffs. Moment utility represents subjective happiness over payoffs, which hinges on three state variables: retaliation, aspiration, and ambition. Retaliation incorporates insights of fairness thinking and formulates people&#39;s psychological reaction on relative payoff comparisons interpersonally. Aspiration displays habit formation that formulates people&#39;s self-adaptation on their own history of payoffs. Ambition captures the net influence of the past situations to the present. Over a time window, our model delivers a new measure of individual well-being under both social and historical contexts.},
  archive      = {J_EJOR},
  author       = {Junyi Chai},
  doi          = {10.1016/j.ejor.2020.06.009},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {692-702},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A model of ambition, aspiration and happiness},
  volume       = {288},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Aggregator operators for dynamic rationing. <em>EJOR</em>,
<em>288</em>(2), 682–691. (<a
href="https://doi.org/10.1016/j.ejor.2020.06.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study dynamic rationing problems. In each period, a fixed group of agents hold claims over an insufficient endowment. The solution to each of these periods’ problems might be influenced by the solutions at previous periods. We single out a natural family of aggregator operators, which extend static rules (solving static rationing problems) to construct rules to solve dynamic rationing problems.},
  archive      = {J_EJOR},
  author       = {Juan D. Moreno-Ternero and Juan Vidal-Puga},
  doi          = {10.1016/j.ejor.2020.06.007},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {682-691},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Aggregator operators for dynamic rationing},
  volume       = {288},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Incentive schemes for resolving parkinson’s law in project
management. <em>EJOR</em>, <em>288</em>(2), 666–681. (<a
href="https://doi.org/10.1016/j.ejor.2020.06.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Project management is a business process that supports about 30\% of the world’s economic activity. Yet projects routinely suffer from the influence of Parkinson’s Law. This behavioural phenomenon routinely results in failure to deliver work that is completed early before its assigned deadline. As a consequence, the late completion of other work is not offset, and overall project performance suffers. Hence, project success rates below 40\% are widely reported. Our work uses mechanism design within non-cooperative game theory. A particular issue in the design process is to eliminate the possibility that a project worker with multiple dependent tasks can improve their incentive payment by falsely reporting some of their task completion times. From our review of the academic and business literature of project management, no incentive scheme used in practice accomplishes this. Our results include the design of incentive schemes that eliminate or mitigate Parkinson’s Law. These schemes apply to projects designed under either traditional Critical Path Method (CPM) planning or modern Critical Chain Project Management (CCPM) planning, and are also invulnerable to group strategy. A large-scale computational study validates the resulting benefit to project performance as substantial and also robust across different project characteristics. We also provide what is apparently the first analytical comparison between traditional CPM and modern CCPM planning systems. The incentive schemes we propose are simple and easily implementable. We recognize that performance incentives are structured differently by each organization, but our work provides a flexible basis from which various practical schemes can be designed.},
  archive      = {J_EJOR},
  author       = {Bo Chen and Nicholas G. Hall},
  doi          = {10.1016/j.ejor.2020.06.006},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {666-681},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Incentive schemes for resolving parkinson’s law in project management},
  volume       = {288},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Measuring the capacity utilization of the 48 largest iron
and steel enterprises in china. <em>EJOR</em>, <em>288</em>(2), 648–665.
(<a href="https://doi.org/10.1016/j.ejor.2020.06.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper aims to investigate the capacity utilization (CU) of selected large Chinese iron and steel enterprises by using the data envelopment analysis (DEA) approach. In this paper, we first propose a DEA model with an unrestricted capacity directional output distance function by incorporating two joint cost disposability relations and differentiating between non-emission-causing inputs and emission-causing inputs. Second, we define the status of decision-making units (DMUs) with excess capacity and design a method to identify insufficient variable inputs. We use a group of 48 largest Chinese iron and steel enterprises as our sample to investigate their performance in terms of CU indicator. The main findings are summarised and can be used to support the corresponding policymaking for the managers of both government and enterprises.},
  archive      = {J_EJOR},
  author       = {Hirofumi Fukuyama and Hui-hui Liu and Yao-yao Song and Guo-liang Yang},
  doi          = {10.1016/j.ejor.2020.06.012},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {648-665},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Measuring the capacity utilization of the 48 largest iron and steel enterprises in china},
  volume       = {288},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Optimal decision policy for real options under general
markovian dynamics. <em>EJOR</em>, <em>288</em>(2), 634–647. (<a
href="https://doi.org/10.1016/j.ejor.2020.06.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Least-Squares Monte Carlo Method (LSM) has become the standard tool to solve real options modeled as an optimal switching problem. The method has been shown to deliver accurate valuation results under complex and high dimensional stochastic processes; however, the accuracy of the underlying decision policy is not guaranteed. For instance, an inappropriate choice of regression functions can lead to noisy estimates of the optimal switching boundaries or even continuation/switching regions that are not clearly separated. As an alternative to estimate these boundaries, we formulate a simulation-based method that starts from an initial guess of them and then iterates until reaching optimality. The algorithm is applied to a classical mine under a wide variety of underlying dynamics for the commodity price process. The method is first validated under a one-dimensional geometric Brownian motion and then extended to general Markovian processes. We consider two general specifications: a two-factor model with stochastic variance and a rich jump structure, and a four-factor model with stochastic cost-of-carry and stochastic volatility. The method is shown to be robust, stable, and easy-to-implement, converging to a more profitable strategy than the one obtained with LSM.},
  archive      = {J_EJOR},
  author       = {Gonzalo Cortazar and Lorenzo Naranjo and Felipe Sainz},
  doi          = {10.1016/j.ejor.2020.06.010},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {634-647},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Optimal decision policy for real options under general markovian dynamics},
  volume       = {288},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A dynamic multi-objective location-allocation model for
search and rescue assets. <em>EJOR</em>, <em>288</em>(2), 620–633. (<a
href="https://doi.org/10.1016/j.ejor.2020.06.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a dynamic multi-objective mixed integer linear programming model to optimize the location and allocation of search and rescue (SAR) boats and helicopters to enhance the performance of maritime SAR missions. Our model incorporates simulated incident scenarios to account for demand uncertainty and allows relocation of vessels seasonally. We define three objectives as responding to incidents within a critical time, generating a balanced workload distribution among vessels of various types, and minimizing costs associated with operations and vessel relocations. Implementing a goal programming approach, we solve the problem for various objective function term weights and compare the performance of each solution with respect to 10 different metrics. Using historical incident datasets for the Aegean Sea, we show that the proposed model and solution approach can significantly improve the SAR performance and provide decision support for planners in developing effective and efficient resource location-allocation schemes.},
  archive      = {J_EJOR},
  author       = {Mumtaz Karatas},
  doi          = {10.1016/j.ejor.2020.06.003},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {620-633},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A dynamic multi-objective location-allocation model for search and rescue assets},
  volume       = {288},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The informational value of employee online reviews.
<em>EJOR</em>, <em>288</em>(2), 605–619. (<a
href="https://doi.org/10.1016/j.ejor.2020.06.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the informational value of online reviews posted by employees for their employer, a rather untapped source of online information from employees, using a sample of 349,550 reviews from 40,915 UK firms. We explore this novel form of electronic Word-of-Mouth (e-WOM) from different perspectives, namely: (i) its information content as a tool to identify the drivers of job satisfaction/dissatisfaction, (ii) its predictive ability on firm financial performance and (iii) its operational and managerial value. Our approach considers both the rating score as well as the review text through a probabilistic topic modeling method, providing also a roadmap to quantify and exploit employee big data analytics. The novelty of this study lies in the coupling of structured and unstructured data for deriving managerial insights through a battery of econometric, financial and operational research methodologies. Our empirical analyses reveal that employee online reviews have informational value and incremental predictability gains for a firm&#39;s internal and external stakeholders. The results indicate that when models integrate structured and unstructured big data there are leveraged opportunities for firms and managers to enhance the informativeness of decision support systems and in turn, gain competitive advantage.},
  archive      = {J_EJOR},
  author       = {Efthymia Symitsi and Panagiotis Stamolampros and George Daskalakis and Nikolaos Korfiatis},
  doi          = {10.1016/j.ejor.2020.06.001},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {605-619},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {The informational value of employee online reviews},
  volume       = {288},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Voting to select projects in participatory budgeting.
<em>EJOR</em>, <em>288</em>(2), 598–604. (<a
href="https://doi.org/10.1016/j.ejor.2020.05.063">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In participatory budgeting, citizens are invited to vote on different projects. This paper sets out to study the voting stage of participatory budgeting from theoretical and practical perspectives. At theoretical level, the potential objectives of voting procedures are examined. From the practical point of view it should be easy to select projects, even when the number of projects is large. This paper proposes three algorithms which are theoretically justified and can be easily applied. Participatory budgeting in the town of Portugalete (Spain) provides a test for them. The results obtained with 2018 voting data suggest that the algorithm that includes the costs of the projects at the selection stage performs better than the others. KEYWORDS: decision processes; participatory budgeting; collective decision-making; cost-benefit analysis.},
  archive      = {J_EJOR},
  author       = {Annick Laruelle},
  doi          = {10.1016/j.ejor.2020.05.063},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {598-604},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Voting to select projects in participatory budgeting},
  volume       = {288},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Benchmarking culture in europe: A data envelopment analysis
approach to identify city-specific strengths. <em>EJOR</em>,
<em>288</em>(2), 584–597. (<a
href="https://doi.org/10.1016/j.ejor.2020.05.058">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Culture is an integral part of a city&#39;s quality of life, a driver of urban change, and a genuine economic sector. To support benchmarking of urban culture and facilitate peer learning amongst policymakers, the European Commission has recently created the ‘Cultural and Creative Cities Index’. While this index builds on a standardised method to aggregate 29 indicators for the 155 selected cities, it is explicitly acknowledged that a ‘gold standard’ for a ‘Cultural and Creative City’ does not exist. Instead, different approaches should be allowed for in capturing cities’ cultural and creative vitality. This is the point of departure for this paper, which employs a Benefit-of-the-Doubt (BoD) modelling approach to allow cities to combine such respect for performance diversity with peer learning and benchmarking. Expert-based weights are used to provide expert-consistent bounds for the shares of key dimensions in a city&#39;s final BoD index value. We identify three city clusters, amongst which there are large performance differences. Accordingly, we focus on the within-group identification of peer cities and target values, which we illustrate in more detail for Bilbao, Krakόw and Umeå, towards the formulation of fit-for-purpose policy measures that can support culture-led development.},
  archive      = {J_EJOR},
  author       = {Tom Van Puyenbroeck and Valentina Montalto and Michaela Saisana},
  doi          = {10.1016/j.ejor.2020.05.058},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {584-597},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Benchmarking culture in europe: A data envelopment analysis approach to identify city-specific strengths},
  volume       = {288},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Reducing inconsistency measured by the geometric consistency
index in the analytic hierarchy process. <em>EJOR</em>, <em>288</em>(2),
576–583. (<a href="https://doi.org/10.1016/j.ejor.2020.06.014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a theoretical framework and a procedure for revising the judgements and improving the inconsistency of an Analytic Hierarchy Process (AHP) pairwise comparison matrix when the Row Geometric Mean (RGM) is used as the prioritisation procedure and the Geometric Consistency Index ( GCI ) is the inconsistency measure. Inconsistency is improved by slightly modifying the judgements that further reduce the GCI . Both the judgements and the derived priority vector will be close to the initial values. A simulation study is utilised to analyse the performance of the algorithm. The proposed framework allows the specification of the procedure to particular interests. A numerical example illustrates the proposed procedure.},
  archive      = {J_EJOR},
  author       = {Juan Aguarón and María Teresa Escobar and José María Moreno-Jiménez},
  doi          = {10.1016/j.ejor.2020.06.014},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {576-583},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Reducing inconsistency measured by the geometric consistency index in the analytic hierarchy process},
  volume       = {288},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The degree ratio ranking method for directed graphs.
<em>EJOR</em>, <em>288</em>(2), 563–575. (<a
href="https://doi.org/10.1016/j.ejor.2020.06.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the most famous ranking methods for digraphs is the ranking by Copeland score. The Copeland score of a node in a digraph is the difference between its outdegree (i.e. its number of outgoing arcs) and its indegree (i.e. its number of ingoing arcs). In the ranking by Copeland score, a node is ranked higher, the higher is its Copeland score. In this paper, we deal with an alternative method to rank nodes according to their out- and indegree, namely ranking the nodes according to their degree ratio, i.e. the outdegree divided by the indegree. To avoid dividing by zero, we add 1 to both the out- as well as indegree of every node. We provide an axiomatization of the ranking by degree ratio using a clone property, which says that the entrance of a clone or a copy (i.e. a node that is in some sense similar to the original node) does not change the ranking among the original nodes. We also provide a new axiomatization of the ranking by Copeland score using the same axioms except that this method satisfies a different clone property. Finally, we modify the ranking by degree ratio by taking only the out- and indegree, but by definition assume nodes with indegree zero to be ranked higher than nodes with positive indegree. We provide an axiomatization of this ranking method using yet another clone property and a maximal property. In this way, we can compare the three ranking methods by their clone property.},
  archive      = {J_EJOR},
  author       = {René van den Brink and Agnieszka Rusinowska},
  doi          = {10.1016/j.ejor.2020.06.013},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {563-575},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {The degree ratio ranking method for directed graphs},
  volume       = {288},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Supply contracting and process innovation in a dynamic
supply chain with information asymmetry. <em>EJOR</em>, <em>288</em>(2),
552–562. (<a href="https://doi.org/10.1016/j.ejor.2020.06.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We investigate the process innovation and contracting decisions of a dynamic supply chain consisting of a supplier and a manufacturer, with the manufacturer possessing private information about her efficiency of process innovation. To overcome the potential adverse selection problem due to the asymmetric information, the supplier designs a menu of supply contracts that stipulates both the wholesale price and the purchasing quantity. We find that under information asymmetry, the supplier will optimally set a higher wholesale price but a lower purchasing quantity for the manufacturer with high innovation efficiency than that for the manufacturer with low innovation efficiency. As a consequence, the manufacturer with high innovation efficiency will significantly underinvest in innovation due to information asymmetry in addition to the impact of the double marginalization effect. Moreover, although a longer contract period tends to better motivate innovation, it can also magnify the influences of adverse selection on supply chain contracting, leading to a higher wholesale price for the manufacturer with high innovation efficiency.},
  archive      = {J_EJOR},
  author       = {Jian Ni and Jun Zhao and Lap Keung Chu},
  doi          = {10.1016/j.ejor.2020.06.008},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {552-562},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Supply contracting and process innovation in a dynamic supply chain with information asymmetry},
  volume       = {288},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Dynamic channel control and pricing of a single perishable
product on multiple distribution channels. <em>EJOR</em>,
<em>288</em>(2), 539–551. (<a
href="https://doi.org/10.1016/j.ejor.2020.06.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies dynamic channel control and pricing of a single perishable product distributed through multiple channels with the objective of maximizing the total expected profit over a finite horizon. We consider two types of commissions, namely proportional and fixed commissions, on the third-party channels and utilize stylized linear functions to characterize dependent demand flows from different channels. We show that, the magnitude of the opportunity cost of capacity uniquely determines the optimal channel control, at any given inventory level and periods to go. Consequently, we are able to derive the optimal price offered on each channel as a function of the opportunity cost of capacity in closed form. This significantly reduces the computational complexity of the stochastic dynamic program when parameters are constant with time. When channels are independent, we provide a necessary and sufficient condition for the optimality of a nested channel control policy by commission rates. The same condition is also sufficient for the optimality of the nested channel control policy in a distribution system with two dependent channels. We then characterize the structural properties of the optimal pricing and channel control policies. Finally, we explore the impact of the substitution effect on the channel control through numerical studies and gain managerial insights.},
  archive      = {J_EJOR},
  author       = {Boqian Song and Michael Z.F. Li and Weifen Zhuang},
  doi          = {10.1016/j.ejor.2020.06.004},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {539-551},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Dynamic channel control and pricing of a single perishable product on multiple distribution channels},
  volume       = {288},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Equilibrium strategies for multiple interdictors on a common
network. <em>EJOR</em>, <em>288</em>(2), 523–538. (<a
href="https://doi.org/10.1016/j.ejor.2020.06.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we introduce multi-interdictor games , which model interactions among multiple interdictors with differing objectives operating on a common network. As a starting point, we focus on shortest path multi-interdictor (SPMI) games , where multiple interdictors try to increase the shortest path lengths of their own adversaries attempting to traverse a common network. We first establish results regarding the existence of equilibria for SPMI games under both discrete and continuous interdiction strategies. To compute such an equilibrium, we present a reformulation of the SPMI game, which leads to a generalized Nash equilibrium problem (GNEP) with non-shared constraints. While such a problem is computationally challenging in general, we show that under continuous interdiction actions, an SPMI game can be formulated as a linear complementarity problem and solved by Lemke’s algorithm. In addition, we present decentralized heuristic algorithms based on best response dynamics for games under both continuous and discrete interdiction strategies. Finally, we establish theoretical lower bounds on the worst-case efficiency loss of equilibria in SPMI games, with such loss caused by the lack of coordination among noncooperative interdictors, and use the decentralized algorithms to numerically study the average-case efficiency loss.},
  archive      = {J_EJOR},
  author       = {Harikrishnan Sreekumaran and Ashish R. Hota and Andrew L. Liu and Nelson A. Uhan and Shreyas Sundaram},
  doi          = {10.1016/j.ejor.2020.06.002},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {523-538},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Equilibrium strategies for multiple interdictors on a common network},
  volume       = {288},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The value of information for price dependent demand.
<em>EJOR</em>, <em>288</em>(2), 511–522. (<a
href="https://doi.org/10.1016/j.ejor.2020.05.057">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predicting demand and determining optimal pricing are essential components of operations management. It is often useful to think in terms of the price elasticity of demand when reasoning about the demand curve. Firms wishing to invest in demand prediction and information gathering should reason about the relationship between the expected value of perfect information (EVPI) on demand and demand elasticity. Should firms pay more/less for information on demand if elasticity is high/low? Furthermore, when considering different product prices, correlation may exist between demand at different prices. Should firms pay more/less for information if the correlation between demand at different prices is high or low? This paper derives analytic and numeric results to answer these questions. We start with the assumption that demand is uncertain and follows a uniformly distributed band around a deterministic demand curve where the upper and lower bounds of the demand distribution vary with price. This formulation enables a closed form expression for EVPI that provides a useful benchmark. We find nuanced behavior of EVPI that depends on both the elasticity and the initial price preference. The EVPI approaches zero as elasticity increases (decreases) for a firm that initially prefers the low (high) price. Numerical results using the truncated normal and beta distributions relax assumptions about the uniform distribution and show EVPI is similar when the distribution variances are similar. Finally, we relax the assumption of perfect information and show the expected value of imperfect information (EVOI) follows similar patterns as EVPI with respect to demand elasticity.},
  archive      = {J_EJOR},
  author       = {Zhengwei Sun and Andrea C. Hupman and Ali E. Abbas},
  doi          = {10.1016/j.ejor.2020.05.057},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {511-522},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {The value of information for price dependent demand},
  volume       = {288},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Robust formulations for economic lot-sizing problem with
remanufacturing. <em>EJOR</em>, <em>288</em>(2), 496–510. (<a
href="https://doi.org/10.1016/j.ejor.2020.06.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we consider a lot-sizing problem with the remanufacturing option under parameter uncertainties imposed on demands and returns. Remanufacturing has recently been a fast growing area of interest for many researchers due to increasing awareness on reducing waste in production environments, and in particular studies involving remanufacturing and parameter uncertainties simultaneously are very scarce in the literature. We first present a min-max decomposition approach for this problem, where decision maker’s problem and adversarial problem are treated iteratively. Then, we propose two novel extended reformulations for the decision maker’s problem, addressing some of the computational challenges. An original aspect of the reformulations is that they are applied only to the latest scenario added to the decision maker’s problem. Then, we present an extensive computational analysis, which provides a detailed comparison of the three formulations and evaluates the impact of key problem parameters. We conclude that the proposed extended reformulations outperform the standard formulation for a majority of the instances. We also provide insights on the impact of the problem parameters on the computational performance.},
  archive      = {J_EJOR},
  author       = {Öykü Naz Attila and Agostinho Agra and Kerem Akartunalı and Ashwin Arulselvan},
  doi          = {10.1016/j.ejor.2020.06.016},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {496-510},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Robust formulations for economic lot-sizing problem with remanufacturing},
  volume       = {288},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Profit maximizing coalitions with shared capacities in
distribution networks. <em>EJOR</em>, <em>288</em>(2), 480–495. (<a
href="https://doi.org/10.1016/j.ejor.2020.06.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the distribution network structure of multiple firms in the context of demand sensitivity to market offers. The problem consists in determining the profitability of horizontal collaboration between firms in a collaborative distribution schema. It considers the case of a set of regional distribution centers (DCs) where each DC is initially dedicated solely to one firm’s distribution activities and studies when it is beneficial that the DC owners collaborate through sharing their storage-throughput capacity. Such strategic decisions are made in order to improve the distribution capabilities of firms in terms of response time and cost-efficiency compared to the stand-alone situation. The problem is modeled as a coalition formation game in a cooperative framework, and we propose a collaborative distribution game with profit maximization. Three sharing mechanisms are modeled and tested: egalitarian allocation, proportional allocation, and Shapley value. The collaboration decision conditions for a given firm are analytically derived according to the sharing method considered and used to enhance the solution approach. Our numerical results clearly highlight the impact of this innovative collaboration opportunity on the firms’ performance in terms of distribution cost savings and revenue increases. An observed behavior is that the formation of several sub-coalitions prevails over the formation of a grand coalition, and that different cost sharing methods can lead to different sub-coalitions. We also provide managerial insights on the appropriate size of a coalition in various business instances tested, and on the key drivers that foster horizontal collaborative behavior among firms.},
  archive      = {J_EJOR},
  author       = {Sihem Ben Jouida and Mario Guajardo and Walid Klibi and Saoussen Krichen},
  doi          = {10.1016/j.ejor.2020.06.005},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {480-495},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Profit maximizing coalitions with shared capacities in distribution networks},
  volume       = {288},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Using shared sell-through data to forecast wholesaler demand
in multi-echelon supply chains. <em>EJOR</em>, <em>288</em>(2), 466–479.
(<a href="https://doi.org/10.1016/j.ejor.2020.05.059">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Operational forecasting in supply chain management supports a variety of short-term planning decisions, such as production scheduling and inventory management. In this respect, improving short-term forecast accuracy is a way to build a more agile supply chain for manufacturing companies. Demand forecasting often relies on well-established univariate forecasting methods to extrapolate historical demand. Collaboration across the supply chain, including information sharing, is suggested in the literature to improve upon the forecast accuracy of such traditional methods. In this paper, we review empirical studies considering the use of downstream information in demand forecasting and investigate different modeling approaches and forecasting methods to incorporate such data. Where empirical findings on information sharing mainly focus on point-of-sale data in two-level supply chains, this research empirically investigates the added value of using sell-through data originating from intermediaries, next to historical demand figures, in a multi-echelon supply chain. In a case study concerning a US drug manufacturer, we evaluate different methods to incorporate this data and consider both time series methods and machine learning techniques to produce multi-step ahead weekly forecasts. The results show that the manufacturer can effectively improve its short-term forecast accuracy by integrating sell-through data into the forecasting process and provide useful insights as to the different modeling approaches used. The conclusion holds for all forecast horizons considered, though it is most pronounced for one-step ahead forecasts. Therefore, our research provides a clear incentive for manufacturers to assess the forecast accuracy that can be achieved by using sell-through data.},
  archive      = {J_EJOR},
  author       = {Jente Van Belle and Tias Guns and Wouter Verbeke},
  doi          = {10.1016/j.ejor.2020.05.059},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {466-479},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Using shared sell-through data to forecast wholesaler demand in multi-echelon supply chains},
  volume       = {288},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Railway delay management with passenger rerouting
considering train capacity constraints. <em>EJOR</em>, <em>288</em>(2),
450–465. (<a href="https://doi.org/10.1016/j.ejor.2020.05.055">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Delay management for railways is concerned with the question of whether a train should wait for a delayed feeder train or depart on time. The answer should not only depend on the length of the delay but also consider other factors, such as capacity restrictions. We present an optimization model for delay management in railway networks that accounts for capacity constraints on the number of passengers that a train can effectively carry. While limited capacities of tracks and stations have been considered in delay management models, passenger train capacity has been neglected in the literature so far, implicitly assuming an infinite train capacity. However, even in open systems where no seat reservation is required and passengers may stand during the journey if all seats are occupied, physical space is naturally limited, and the number of standing seats is constrained for passenger safety reasons. We present a mixed-integer nonlinear programming formulation for the delay management problem with passenger rerouting and capacities of trains. Our model allows the rerouting of passengers missing their connection due to delays or capacity constraints. We linearize the model in exact and approximate ways and experimentally compare the different approaches with the solution of a reference model from the literature that neglects capacity constraints. The results demonstrate that there is a significant impact of considering train capacity restrictions in decisions to manage delays.},
  archive      = {J_EJOR},
  author       = {Eva König and Cornelia Schön},
  doi          = {10.1016/j.ejor.2020.05.055},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {450-465},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Railway delay management with passenger rerouting considering train capacity constraints},
  volume       = {288},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The two-echelon production-routing problem. <em>EJOR</em>,
<em>288</em>(2), 436–449. (<a
href="https://doi.org/10.1016/j.ejor.2020.05.054">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces the Two-Echelon Production-Routing Problem. This problem is motivated from the petrochemical industry, enlarging the supply chain integration by taking into account production, inventory, and routing decisions in a two-echelon vendor-managed inventory system. We describe, model, and design a branch-and-cut (B&amp;C) to solve the problem under different inventory policies. We also propose a novel exact algorithm, by employing parallel computing techniques, in order to combine local search procedures within a traditional B&amp;C scheme. We evaluate the performance of our methods through extensive computational experiments, both by comparing the algorithms, the effectiveness of the different inventory policies, and the impact of these policies on the partial costs. We derive many managerial insights based on the results. We also validate our new exact algorithm by solving similar problems from the literature, such as the two-echelon multi-depot inventory-routing (2E-MDIRP) and the classical multi-vehicle production-routing problem (MV-PRP). Computational experiments show that our method is very competitive. Based on 512 experiments for the 2E-MDIRP, our algorithm was able to find 111 new best known solutions (BKS), besides proving 412 optimal solutions, against 298 from the literature. For 336 experiments over small and medium size MV-PRP instances, we proved 242 optimal solutions, 11 more than the exact methods from the literature, besides providing 95 new BKS. Moreover, we were the first to tackle large MV-PRP instances exactly, and in this case, our algorithm provides all BKS for instances up to 50 customers, 20 periods and 5 vehicles, outperforming all meta/matheuristics procedures from the literature.},
  archive      = {J_EJOR},
  author       = {Cleder M. Schenekemberg and Cassius T. Scarpin and José E. Pécora Jr. and Thiago A. Guimarães and Leandro C. Coelho},
  doi          = {10.1016/j.ejor.2020.05.054},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {436-449},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {The two-echelon production-routing problem},
  volume       = {288},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Buyer-supplier currency exchange rate flexibility contracts
in global supply chains. <em>EJOR</em>, <em>288</em>(2), 420–435. (<a
href="https://doi.org/10.1016/j.ejor.2020.05.053">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper analyzes a decentralized global supply chain under a newsvendor setting, where a supplier delivers a certain quantity of a single product to a buyer in accordance with the terms of a mutually agreed upon contract. This contract is signed prior to the delivery of the product and subsequent payment, thus, exposing the supply chain to the risk of currency exchange rate fluctuations. We propose two types of currency exchange rate flexibility contracts to explore the characteristics of exchange rate risk mitigation policies for the buyer and the supplier. Furthermore, we investigate the effects of the contract structures on the optimal order quantity, as well as the expected profits of both supply chain members. Our results show that the optimal order quantity of the buyer decreases when the wholesale price is uncertain due to exchange rate volatility. Also, both our proposed contracts tend to improve the expected profits of both the buyer and the supplier, when the payment is made in the supplier’s currency, indicating the desirability of adopting such contractual agreements from the perspective of both parties. On the other hand, when the payment is made in the buyer’s currency, our suggested contracts do not yield such win-win scenarios. Finally, we examine the effectiveness of availing the services of a local vendor, which is capable of satisfying any demand in excess of the quantity ordered from the foreign source with short notice, in order to mitigate the risks associated with an overseas order.},
  archive      = {J_EJOR},
  author       = {Gbemileke A. Ogunranti and Oben Ceryan and Avijit Banerjee},
  doi          = {10.1016/j.ejor.2020.05.053},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {420-435},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Buyer-supplier currency exchange rate flexibility contracts in global supply chains},
  volume       = {288},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Limited time commitment: Does competition for providing
scarce products always improve the supplies? <em>EJOR</em>,
<em>288</em>(2), 408–419. (<a
href="https://doi.org/10.1016/j.ejor.2020.05.052">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In addition to the fact that goods and services typically become scarce because resources are scarce, scarcity involves a psychological aspect. When a product is limited in availability, or perceived as being limited, it becomes more attractive. As a result, as long as the product is viewed as scarce, a surplus in supplies implies an increase in consumption. Motivated by fresh-water scarcity, we address the problem of dynamic interaction between two firms committing to provide water supply within a limited time horizon. We find that competition does not necessarily reduce product scarcity compared to the monopolistic industry. In particular, commitment-based market equilibrium is characterized by a critical duration of the supply contract. Duopolistic competition within this duration is reminiscent of the conventional quantity competition—the supply grows and the price drops compared to the monopolistic output. On the other hand, a longer contract leads to a different operational outcome—the monopoly becomes gradually more beneficial in terms of supplies and, as the time horizon grows, even overwhelmingly advantageous, thereby resulting in lower scarcity of the products.},
  archive      = {J_EJOR},
  author       = {Konstantin Kogan},
  doi          = {10.1016/j.ejor.2020.05.052},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {408-419},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Limited time commitment: Does competition for providing scarce products always improve the supplies?},
  volume       = {288},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Optimal production and inventory rationing policies with
selective-information sharing and two demand classes. <em>EJOR</em>,
<em>288</em>(2), 394–407. (<a
href="https://doi.org/10.1016/j.ejor.2020.05.051">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the impact of partner selection on the value of information sharing in a distribution system with one capacitated make-to-stock manufacturer and two retailers. When the high priority retailer with a higher shortfall cost is the sole partner, in the case that the low priority one places an order, the manufacturer allocates inventory more accurately according to more predictable orders from the high priority retailer. When only the low priority retailer shares information, the manufacturer is better informed about orders from this retailer, which shall trigger rationing decisions. Such intriguing differences in utilizing information from two prioritized retailers further induce different interactions between production and rationing policies and form two distinctive but closely related selective-information sharing systems. We characterize the manufacturer’s optimal production and rationing policies under both systems. Through a numerical study, we emphasize the effectiveness of partnering with the high priority retailer. When the manufacturer can establish information sharing links with only one retailer, such a choice usually brings more benefits despite differences in order sizes and/or demand rates of the two retailers. When a selective-information sharing system is the pilot run to full-information sharing, we find that the value of information throughout the implementation process often exhibits second-mover advantage and such a choice also helps the manufacturer create a more balanced return pattern. Finally, we illustrate that the cost-effectiveness of inventory rationing can be significant and optimally rationing inventory is the prerequisite for the superior of the selective-information sharing system with the high priority retailer.},
  archive      = {J_EJOR},
  author       = {Yi Wang and Sheng Hao Zhang},
  doi          = {10.1016/j.ejor.2020.05.051},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {394-407},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Optimal production and inventory rationing policies with selective-information sharing and two demand classes},
  volume       = {288},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Joint optimization of budget allocation and maintenance
planning of multi-facility transportation infrastructure systems.
<em>EJOR</em>, <em>288</em>(2), 382–393. (<a
href="https://doi.org/10.1016/j.ejor.2020.05.050">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Transportation infrastructure, such as pavements and bridges, is critical to a nation’s economy. However, a large number of transportation infrastructure is underperforming and structurally deficient and must be repaired or reconstructed. Maintenance of deteriorating transportation infrastructure often requires multiple types/levels of actions with complex effects. Maintenance management becomes more intriguing when considering facilities at the network level, which represents more challenges on modeling interdependencies among various facilities. This research considers an integrated budget allocation and preventive maintenance optimization problem for multi-facility deteriorating transportation infrastructure systems. We first develop a general integer programming formulation for this problem. In order to solve large-scale problems, we reformulate the problem and decompose it into multiple Markov decision process models. A priority-based two-stage method is developed to find optimal maintenance decisions. Computational studies are conducted to evaluate the performance of the proposed algorithms. Our results show that the proposed algorithms are efficient and effective in finding satisfactory maintenance decisions for multi-facility systems. We also investigate the properties of the optimal maintenance decisions and make several important observations, which provide helpful decision guidance for real-world problems.},
  archive      = {J_EJOR},
  author       = {Yue Shi and Yisha Xiang and Hui Xiao and Liudong Xing},
  doi          = {10.1016/j.ejor.2020.05.050},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {382-393},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Joint optimization of budget allocation and maintenance planning of multi-facility transportation infrastructure systems},
  volume       = {288},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The forgotten sons: Warehousing systems for brick-and-mortar
retail chains. <em>EJOR</em>, <em>288</em>(2), 361–381. (<a
href="https://doi.org/10.1016/j.ejor.2020.04.058">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Warehouses are an inevitable component in any supply chain and a vividly investigated object of research. Much attention, however, is absorbed by warehousing systems dedicated to the special needs of online retailers in the business-to-consumer segment. Due to the ever increasing sales volumes of e-commerce this focus seems self-evident, but a much larger fraction of retail sales are still realized by traditional brick-and-mortar stores. The special needs of warehouses servicing these stores are focused in this paper. While e-commerce warehouses face low-volume-high-mix picking orders, because private households tend to order just a few pieces per order from a large assortment, distribution centers of retail chains rather have to process high-volume-low-mix orders. We elaborate the basic requirements within both business segments and identify suited warehousing systems for brick-and-mortar stores (e.g., fully-automated case picking). The setup of each identified warehousing system is described, elementary decision problems are discussed, and the existing literature is surveyed. Furthermore, we identify future research needs.},
  archive      = {J_EJOR},
  author       = {Nils Boysen and René de Koster and David Füßler},
  doi          = {10.1016/j.ejor.2020.04.058},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {361-381},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {The forgotten sons: Warehousing systems for brick-and-mortar retail chains},
  volume       = {288},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Acknowledgement to referees 2020. <em>EJOR</em>,
<em>288</em>(1), 346–360. (<a
href="https://doi.org/10.1016/j.ejor.2020.08.020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_EJOR},
  doi          = {10.1016/j.ejor.2020.08.020},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {346-360},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Acknowledgement to referees 2020},
  volume       = {288},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A note on “portfolio selection under possibilistic
mean-variance utility and a SMO algorithm.” <em>EJOR</em>,
<em>288</em>(1), 343–345. (<a
href="https://doi.org/10.1016/j.ejor.2020.05.039">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In a paper published in this journal – Zhang W.-G., Zhang X.-L., Xiao W.-L. (2009), Portfolio selection under possibilistic mean-variance utility and a SMO algorithm. European Journal of Operational Research , 197(2), 693-700 –, the Authors investigate a fuzzy approach to the portfolio selection problem in which the stock returns are represented in terms of trapezoidal fuzzy numbers. In this note, we show that the expression provided for the possibilistic covariance is not consistent with the definition of possibilistic covariance given in the paper itself, and we derive the right expression for such a covariance.},
  archive      = {J_EJOR},
  author       = {Marco Corazza},
  doi          = {10.1016/j.ejor.2020.05.039},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {343-345},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A note on “Portfolio selection under possibilistic mean-variance utility and a SMO algorithm”},
  volume       = {288},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). On rational behavior in multi-attribute riskless choice.
<em>EJOR</em>, <em>288</em>(1), 331–342. (<a
href="https://doi.org/10.1016/j.ejor.2020.05.056">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We theoretically compare and contrast two commonly used types of choice strategies in a riskless, multi-attribute setting: (1) the win-win (or Pareto improving) strategy, and (2) the tradeoff strategy. Both strategies can be used and are used in Multiple Criteria Decision Making theory and practice. In the win-win strategy, consumers (or decision-makers) consider, which goods they want to add to their basket. In the tradeoff strategy consumers make pairwise choices between different (efficient) baskets, where they have to give up in some goods to gain in other goods. We postulate a choice model based on standard assumptions in economics/behavioral decision theory. The key underlying theoretical assumptions in our choice model are increasing and concave single dimensional value functions with decreasing marginal values (win-win setting) and the Tversky–Kahneman reference-dependent model of choice with loss aversion (tradeoff setting). The multi-attribute value function is assumed additive and separable. We study the decision-maker&#39;s consistency with our theory in both strategies. The perspective is that of an outside observer (an analyst). The basket is filled either with different or identical goods. We compare and contrast the win-win and tradeoff strategies and draw conclusions for the development of our field. We use an empirical experiment to motivate our considerations.},
  archive      = {J_EJOR},
  author       = {Pekka J. Korhonen and Jyrki Wallenius and Tolga Genc and Peng Xu},
  doi          = {10.1016/j.ejor.2020.05.056},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {331-342},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {On rational behavior in multi-attribute riskless choice},
  volume       = {288},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Gas storage valuation in incomplete markets. <em>EJOR</em>,
<em>288</em>(1), 318–330. (<a
href="https://doi.org/10.1016/j.ejor.2020.05.044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Natural gas storage valuation is an important problem in energy trading, yet most valuation approaches are based on heuristics or ignore that gas markets are incomplete. We propose an exact valuation model for incomplete gas markets based on multistage stochastic programming. Market incompleteness structurally changes the problem of storage valuation and asset backed trading and the resulting model requires analysis of a combined control problem of storage operation and futures trading that takes risk preferences into account. As the problem is subject to the curse of dimensionality, we reduce the stochastic process to a scenario lattice and solve the resulting problem using stochastic dual dynamic programming. We show that the intrinsic value of storage corresponds to the value under perfect risk aversion and that the rolling intrinsic value, which is popular among practitioners and has been found to be near-optimal when markets are complete, is an inconsistent price rule in incomplete markets. Our results inform managerial decisions on risk management and asset pricing for natural gas highlighting the importance of explicitly modeling risk preferences.},
  archive      = {J_EJOR},
  author       = {Nils Löhndorf and David Wozabal},
  doi          = {10.1016/j.ejor.2020.05.044},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {318-330},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Gas storage valuation in incomplete markets},
  volume       = {288},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Horses for courses: Mean-variance for asset allocation and
1/n for stock selection. <em>EJOR</em>, <em>288</em>(1), 302–317. (<a
href="https://doi.org/10.1016/j.ejor.2020.05.043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For various organizational reasons, large investors typically split their portfolio decision into two stages - asset allocation and stock selection. We hypothesise that mean-variance models are superior to equal weighting for asset allocation, while the reverse applies for stock selection, as estimation errors are less of a problem for mean-variance models when used for asset allocation than for stock selection. We confirm this hypothesis for US data using Bayes-Stein with no short sales and variance based constraints. Robustness checks with four other types of mean-variance model (Black-Litterman with three different reference portfolios, minimum variance, Bayes diffuse prior and Markowitz), and a wide range of parameter settings support our conclusions. We also replicate our core results using Japanese data, with additional replications using the Fama-French 5, 10, 12 and 17 industry portfolios and equities from seven countries. In contrast to previous results, but consistent with our empirical results, we show analytically that the superiority of mean-variance over 1/N is increased when the assets have a lower cross-sectional idiosyncratic volatility, which we also confirm in a simulation analysis calibrated to US data.},
  archive      = {J_EJOR},
  author       = {Emmanouil Platanakis and Charles Sutcliffe and Xiaoxia Ye},
  doi          = {10.1016/j.ejor.2020.05.043},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {302-317},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Horses for courses: Mean-variance for asset allocation and 1/N for stock selection},
  volume       = {288},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). On the choice of weights for aggregating judgments in
non-negotiable AHP group decision making. <em>EJOR</em>,
<em>288</em>(1), 294–301. (<a
href="https://doi.org/10.1016/j.ejor.2020.05.048">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a formal method to compute a suitable set of coefficients and aggregate individual judgments in a common group preference matrix. In our procedure we assume that there is a large dispersion and decision makers are unwilling or unable to revise their judgments and, in any case, the weights are not negotiable. Our method, based on Frobenius norm, provides a solution which takes into account a new congruence measure between decision makers.},
  archive      = {J_EJOR},
  author       = {Pietro Amenta and Antonio Lucadamo and Gabriella Marcarelli},
  doi          = {10.1016/j.ejor.2020.05.048},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {294-301},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {On the choice of weights for aggregating judgments in non-negotiable AHP group decision making},
  volume       = {288},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Large-scale group decision-making with non-cooperative
behaviors and heterogeneous preferences: An application in financial
inclusion. <em>EJOR</em>, <em>288</em>(1), 271–293. (<a
href="https://doi.org/10.1016/j.ejor.2020.05.047">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Non-cooperative behavior is a common situation in large-scale group decision-making (LSGDM) problems. In addition, decision makers in LSGDM often use different preference formats to express their opinions, due to their educational backgrounds, knowledge, and experiences. Heterogeneous preference information and non-cooperative behaviors bring challenges to LSGDM. This study develops a consensus reaching model to address heterogeneous LSGDM with non-cooperative behaviors and discuss its application in financial inclusion. Specifically, the cosine similarity degree is introduced to build a distance measure for different preference structures. Clustering analysis is employed to divide large-scale groups and handle non-cooperative behaviors in LSGDM. A consensus degree and a weighting process are proposed to decrease the influence of non-cooperative behaviors and facilitate the consensus reaching process. The convergence of the proposed approach is proven by theoretical and simulation analyses. Experimental studies are carried out to compare the performances of the proposed approach with existing methods. Finally, a real-life example from the “targeted poverty reduction project” in China is presented to validate the proposed approach. The selection of beneficiaries in finance inclusion is difficult due to the lack of credit history, the large number of participants, and the conflicting views of participants. The results showed that the proposed consensus model can integrate opinions of participants using diverse preference formats and reach an agreement efficiently.},
  archive      = {J_EJOR},
  author       = {Xiangrui Chao and Gang Kou and Yi Peng and Enrique Herrera Viedma},
  doi          = {10.1016/j.ejor.2020.05.047},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {271-293},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Large-scale group decision-making with non-cooperative behaviors and heterogeneous preferences: An application in financial inclusion},
  volume       = {288},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Inequity-averse stochastic decision processes.
<em>EJOR</em>, <em>288</em>(1), 258–270. (<a
href="https://doi.org/10.1016/j.ejor.2020.05.045">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paper extends two alternative approaches in inequity-averse optimization under uncertainty, the ex-ante approach and the ex-post approach, from a static to a dynamic decision making context. This is done by developing a stochastic multistage optimization framework evaluating payoffs by an equitable aggregation function. It is shown that global optimization of strategies leads to time-consistent policies only in the ex-post case. For the ex-ante case, a variant of a policy for which time consistency holds is proposed. To illustrate the concepts, a two-stage stochastic location–allocation problem from humanitarian logistics is investigated. For this application, the general algorithmic approaches can be cast into mathematical programming formulations, which yields a two-stage stochastic program and a bilevel program in the ex-post and in the ex-ante case, respectively. The resulting models are solved to optimality for a set of randomly generated instances, and a comparison of the outcomes for ex-post and ex-ante, also in terms of the “Price of Fairness”, is given.},
  archive      = {J_EJOR},
  author       = {Walter J. Gutjahr},
  doi          = {10.1016/j.ejor.2020.05.045},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {258-270},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Inequity-averse stochastic decision processes},
  volume       = {288},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). On pareto-optimality in the cross-efficiency evaluation.
<em>EJOR</em>, <em>288</em>(1), 247–257. (<a
href="https://doi.org/10.1016/j.ejor.2020.05.040">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Uniqueness and Pareto-optimality of cross-efficiency scores are two main issues in the cross-efficiency evaluation. We address the Pareto-optimality issue in the cross-efficiency evaluation by presenting a natural notion of Pareto-optimality in the cross-efficiency evaluation which is based on a new self-prioritizing principle and aligned with the concept of dominance. This Pareto-optimality notion is devised using less stringent postulates, compared to those used to devise the existing Pareto-optimality notions in the current literature. We then propose a multi-objective model whose Pareto-optimal solutions generate all the Pareto-optimal cross-efficiency scores sets that fulfill the self-prioritizing principle. It is shown that there is a Pareto-optimal solution to the proposed multi-objective programming model which assigns a common set of weights to all decision making units. We then propose a linear model to obtain such an optimal solution using the weighted sum technique, thereby we can determine an optimal weights profile to generate a set of Pareto-optimal cross-efficiency scores by solving only one linear model. Having started with less stringent postulates, we have more flexibility in enhancing cross-efficiency scores of decision making units and can hence provide a non-dominated set of cross-efficiency scores as illustrated by a real data example. We also demonstrate the possibility of better, compared to other cross-efficiency evaluation methods, resource allocation using another real data example.},
  archive      = {J_EJOR},
  author       = {Mostafa Davtalab-Olyaie and Masoud Asgharian},
  doi          = {10.1016/j.ejor.2020.05.040},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {247-257},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {On pareto-optimality in the cross-efficiency evaluation},
  volume       = {288},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The ordinal input for cardinal output approach of
non-compensatory composite indicators: The PROMETHEE scoring method.
<em>EJOR</em>, <em>288</em>(1), 225–246. (<a
href="https://doi.org/10.1016/j.ejor.2020.05.036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite serious threats as to their soundness, the adoption of composite indicators is constantly growing alongside their popularity, especially when it comes to their adoption in policy-making exercises. This study presents a robust non-compensatory approach to construct composite indicators that is mainly based, at least with respect to the basic ideas, on the classic Borda scoring procedure. The non-compensatory indicators we are proposing can be seen as aggregation of ordinal non-compensatory preferences between considered units supplying a numerical cardinal comprehensive evaluation. For this reason, we define our methodology, the ordinal input for cardinal output non-compensatory approach for composite indicators. To take into account hesitation, imprecision and ill-determination in defining preference relations with respect to the elementary indices, we adopt the PROMETHEE methods, whose net flow score can be seen as an extension to the fuzzy preferences of the Borda score. Moreover, we systematically deal with robustness of the results with respect to weighting and parameters such as indifference and preference thresholds, allowing to define preference relations of elementary indices. In this regard, we couple PROMETHEE methods with the recently proposed σ − μ σ−μ approach, which permits to explore the whole domain of feasible preference parameters mentioned above, giving a synthetic representation of the distribution of the values assumed by the composite indicators in terms of mean, μ , and standard deviation, σ. μ and σ are also used to define a comprehensive overall composite indicator. Finally, we enrich the results of this analysis with a set of graphical visualizations based on principal component analysis applied to the PROMETHEE methods with the GAIA technique, providing better understanding of the outcomes of our approach. To illustrate its assets, we provide a case study of inclusive development evaluation, based on the data of the homonymous report produced by the World Economic Forum.},
  archive      = {J_EJOR},
  author       = {Salvatore Greco and Alessio Ishizaka and Menelaos Tasiou and Gianpiero Torrisi},
  doi          = {10.1016/j.ejor.2020.05.036},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {225-246},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {The ordinal input for cardinal output approach of non-compensatory composite indicators: The PROMETHEE scoring method},
  volume       = {288},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Systemic evaluation of community environmental management
programmes. <em>EJOR</em>, <em>288</em>(1), 207–224. (<a
href="https://doi.org/10.1016/j.ejor.2020.05.019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Community environmental management (CEM) involves the facilitation of community partnerships, local dialogue, consultation and participative decision-making. This is increasingly seen as a solution to some of the more complex environmental issues faced by regulatory authorities. Anecdotal evidence suggests that CEM programmes have much potential, but the evaluation of them is problematic, and there is a need for more robust evidence of their effectiveness. This paper reports on the development of a new CEM evaluation approach (inspired by soft systems methodology, developmental work research and systemic intervention), which was trialled with a New Zealand regional council. The approach shows promise in addressing common evaluation bottlenecks and helping stakeholders to develop causal narratives that more fully account for the complex relationship between community participation and environmental outcomes. However, while the local participants in the CEM initiative acted on the evaluation findings, they hoped that it would stimulate wider organisational change, and this did not happen. Project reflections, informed by institutional theory, reveal that the logics of ‘participation’ and ‘community’ implicit in the findings were appropriate for local participants, but non-participating regional council stakeholders read the findings with different logics, and therefore the evaluation failed to communicate the necessity for wider change. The reflections highlight a previously unrecognised evaluation bottleneck. While the CEM evaluation methodology has the potential to be adapted for other contexts, if wider organisational change is required, care must be taken to anticipate the different institutional logics of stakeholders who might be unfamiliar with, or even hostile to, CEM.},
  archive      = {J_EJOR},
  author       = {J. Foote and G. Midgley and A. Ahuriri-Driscoll and M. Hepi and J. Earl-Goulet},
  doi          = {10.1016/j.ejor.2020.05.019},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {207-224},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Systemic evaluation of community environmental management programmes},
  volume       = {288},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Constraint generation for risk averse two-stage stochastic
programs. <em>EJOR</em>, <em>288</em>(1), 194–206. (<a
href="https://doi.org/10.1016/j.ejor.2020.05.064">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A significant share of stochastic optimization problems in practice can be cast as two-stage stochastic programs. If uncertainty is available through a finite set of scenarios, which frequently occurs, and we are interested in accounting for risk aversion, the expectation in the recourse cost can be replaced with a worst-case function (i.e., robust optimization) or another risk-functional, such as conditional value-at-risk. In this paper we are interested in the latter situation especially when the number of scenarios is large. For computational efficiency we suggest a (clustering and) constraint generation algorithm. We establish convergence of these two algorithms and demonstrate their effectiveness through various numerical experiments.},
  archive      = {J_EJOR},
  author       = {R. Mínguez and W. van Ackooij and R. García-Bertrand},
  doi          = {10.1016/j.ejor.2020.05.064},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {194-206},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Constraint generation for risk averse two-stage stochastic programs},
  volume       = {288},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Time-consistent portfolio optimization. <em>EJOR</em>,
<em>288</em>(1), 183–193. (<a
href="https://doi.org/10.1016/j.ejor.2020.05.061">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper establishes a reusable framework, including a stochastic heterogeneous quasi-hyperbolic (SHQH) discount function, its non-standard Hamilton–Jacobi–Bellman equation (HJB) and its naive and precommitted solutions. To gurantee the broad generalities of the framework, we adopt a game theoretic approach in the sense of refraining from imposing functional specifications. This framework is the first which attains sub-game equilibrium in the presence of heterogeneous preferences (e.g. coexistence of present bias and age-related increases in self-control). As an example, this framework is used to optimize an insurance policy-holder’s asset allocation. The results show: (i) the sophisticated paradigm ( formulated via the SHQH HJB ) yields higher life insurance investment than the precommitted and naive paradigms ( formulated via conventional optimization ); (ii) the very instantaneous gratification that composes the resistance to delayed rewards also necessitates the insurance consumption to circumvent this resistance.},
  archive      = {J_EJOR},
  author       = {Ling Peng and Peter E. Kloeden},
  doi          = {10.1016/j.ejor.2020.05.061},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {183-193},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Time-consistent portfolio optimization},
  volume       = {288},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Expert performance and crowd wisdom: Evidence from english
premier league predictions. <em>EJOR</em>, <em>288</em>(1), 170–182. (<a
href="https://doi.org/10.1016/j.ejor.2020.05.034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper analyses the forecasting accuracy of experts vis-à-vis laypeople over three seasons of English Premier League matches. We find that former professional football players have superior forecasting ability when compared to laypeople. The results give partial support to the view that a crowd forecast offers the greatest precision. Pundits generate a positive return while both the crowd and laypeople generate losses. As the prediction of multiple score outcomes represents a computationally difficult task, both groups display forecasting biases including a preference toward specific score forecasts. The results are relevant for those concerned with gambling behaviour if the forecasting strategies adopted here generalise to match betting markets.},
  archive      = {J_EJOR},
  author       = {David Butler and Robert Butler and John Eakins},
  doi          = {10.1016/j.ejor.2020.05.034},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {170-182},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Expert performance and crowd wisdom: Evidence from english premier league predictions},
  volume       = {288},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). When and how to share first-mile parcel collection service.
<em>EJOR</em>, <em>288</em>(1), 153–169. (<a
href="https://doi.org/10.1016/j.ejor.2020.05.049">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Booming parcel shipping business has raised wide attention. The trunk line is easier to manage, since parcels are consolidated to fully utilize vehicle capacities. However, the first mile handled by individual companies is beset by high empty haul rates and low efficiency. This paper takes the lead in exploring a new business model and possibilities of establishing a common service platform for the first mile. We investigate strategic decisions of two courier logistics companies competing with partially substitutable collection service. They can choose to cooperate with the cost-efficient platform to enjoy a saving, while the market share of their original channel has to be eroded by the outsourcing channel. We propose three scenarios: (i) Both companies have only one direct channel. (ii) Only one company has two channels. (iii) Both companies have two. This paper comprehensively presents the joint effect of internal competition and the cost saving on companies’ welfare and customers’ consuming experience. The findings show that in most cases, cooperating with the platform will help the companies gain a profit increment and customers will benefit from a price decrease compared to the current practice. However, when customers loyalty to the direct channel is moderate, they will suffer a price increase, though companies are better off. Additionally, given the cost advantage of outsourcing is slighter, and customers show less difference to two channels, the internal competition will be the most intensified and overtake the effect of cost sparing. The company running two channels will suffer a profit loss.},
  archive      = {J_EJOR},
  author       = {Xin Wang and George Q. Huang},
  doi          = {10.1016/j.ejor.2020.05.049},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {153-169},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {When and how to share first-mile parcel collection service},
  volume       = {288},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Elucidate structure in intermittent demand series.
<em>EJOR</em>, <em>288</em>(1), 141–152. (<a
href="https://doi.org/10.1016/j.ejor.2020.05.046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intermittent demand forecasting has been widely researched in the context of spare parts management. However, it is becoming increasingly relevant to many other areas, such as retailing, where at the very disaggregate level time series may be highly intermittent, but at more aggregate levels are likely to exhibit trends and seasonal patterns. The vast majority of intermittent demand forecasting methods are inappropriate for producing forecasts with such features. We propose using temporal hierarchies to produce forecasts that demonstrate these traits at the various aggregation levels, effectively informing the resulting intermittent forecasts of these patterns that are identifiable only at higher levels. We conduct an empirical evaluation on real data and demonstrate statistically significant gains for both point and quantile forecasts.},
  archive      = {J_EJOR},
  author       = {Nikolaos Kourentzes and George Athanasopoulos},
  doi          = {10.1016/j.ejor.2020.05.046},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {141-152},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Elucidate structure in intermittent demand series},
  volume       = {288},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Tabu search for the time-dependent vehicle routing problem
with time windows on a road network. <em>EJOR</em>, <em>288</em>(1),
129–140. (<a href="https://doi.org/10.1016/j.ejor.2020.05.041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Travel times inside cities often vary quite a lot during a day and significantly impact the duration of commercial delivery routes. Several authors have suggested time-dependent variants of the most commonly encountered vehicle routing problems. In these papers, however, time-dependency is usually defined on customer-based graphs. Thus, one major impact of travel time variations is missed: in an urban environment, not only do travel times change, but also the paths used to travel from one customer to another. In fact, during a day, different paths may be used at different points in time. To address this issue, one possible approach is to work directly with the road network and consider travel time (or travel speed) variations on each road segment. In this paper, we propose a solution approach for a time-dependent vehicle routing problem with time windows in which travel speeds are associated with road segments in the road network. This solution approach involves a tabu search heuristic that considers different shortest paths between any two customers at different times of the day. A major contribution of this work is the development of techniques to evaluate the feasibility and the approximate cost of a solution in constant time, which allows the solution approach to handle problem instances with up to 200 nodes and 580 arcs in very reasonable computing times. The performance of our algorithm is assessed by comparing it to an exact method on a set of benchmark instances. The results show that solutions of high quality are produced.},
  archive      = {J_EJOR},
  author       = {Maha Gmira and Michel Gendreau and Andrea Lodi and Jean-Yves Potvin},
  doi          = {10.1016/j.ejor.2020.05.041},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {129-140},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Tabu search for the time-dependent vehicle routing problem with time windows on a road network},
  volume       = {288},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Retail sales forecasting with meta-learning. <em>EJOR</em>,
<em>288</em>(1), 111–128. (<a
href="https://doi.org/10.1016/j.ejor.2020.05.038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Retail sales forecasting often requires forecasts for thousands of products for many stores. We present a meta-learning framework based on newly developed deep convolutional neural networks, which can first learn a feature representation from raw sales time series data automatically, and then link the learnt features with a set of weights which are used to combine a pool of base-forecasting methods. The experiments which are based on IRI weekly data show that the proposed meta-learner provides superior forecasting performance compared with a number of state-of-art benchmarks, though the accuracy gains over some more sophisticated meta ensemble benchmarks are modest and the learnt features lack interpretability. When designing a meta-learner in forecasting retail sales, we recommend building a pool of base-forecasters including both individual and pooled forecasting methods, and target finding the best combination forecasts instead of the best individual method.},
  archive      = {J_EJOR},
  author       = {Shaohui Ma and Robert Fildes},
  doi          = {10.1016/j.ejor.2020.05.038},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {111-128},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Retail sales forecasting with meta-learning},
  volume       = {288},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Home service routing and appointment scheduling with
stochastic service times. <em>EJOR</em>, <em>288</em>(1), 98–110. (<a
href="https://doi.org/10.1016/j.ejor.2020.05.037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Motivated by the practices of home services, we consider an integrated routing and appointment scheduling problem with stochastic service times. Given a set of customers with known locations and random service times, the professional operator has to visit each customer location exactly once to provide the services. The problem is to determine the visit route of the operator and the appointment times for the customers so as to minimize the total costs of traveling and idling of the operator, and waiting of customers. Given a finite support of random service times, we develop a mixed-integer program model for the problem. Practical-sized instances of the problem are very difficult to solve in a reasonable time with just standard techniques. We exploit several structural properties of the model and develop an L -shaped method to efficiently solve the problem. Specifically, we strengthen the formulation and introduce valid inequalities to speed up the solution process. We also propose an easy-to-implement heuristic algorithm that allows for effectively solving problem instances with large size. The effectiveness and efficiency of the proposed methods are demonstrated through computational experiments with randomly generated problem instances.},
  archive      = {J_EJOR},
  author       = {Yang Zhan and Zizhuo Wang and Guohua Wan},
  doi          = {10.1016/j.ejor.2020.05.037},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {98-110},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Home service routing and appointment scheduling with stochastic service times},
  volume       = {288},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Introducing split orders and optimizing operational policies
in robotic mobile fulfillment systems. <em>EJOR</em>, <em>288</em>(1),
80–97. (<a href="https://doi.org/10.1016/j.ejor.2020.05.032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In robotic mobile fulfillment systems, human pickers don’t go to the inventory area to search for and pick the ordered items. Instead, robots carry shelves (called “pods”) containing ordered items from the inventory area to picking stations. At the picking stations, pickers put ordered items into totes; then these items are transported to the packing stations. This type of warehousing system relieves the human pickers and improves the picking process. In this paper, we concentrate on decisions about the assignment of pods to stations and orders to stations to fulfill picking for each incoming customer’s order. In previous research for an RMFS with multiple picking stations, these decisions are made sequentially with heuristics. Instead, we present a new MIP-model to integrate both decision problems. To improve the system performance even more, we extend our model by splitting orders. This means parts of an order are allowed to be picked at different stations. To the best of the authors’ knowledge, this is the first publication on split orders in an RMFS. And we prove the computational complexity of our models. We analyze different performance metrics, such as pile-on, pod-station visits, robot moving distance and throughput. We compare the results of our models in different instances with the sequential method in our open-source simulation framework RAWSim-O. The integration of the decisions brings better performances, and allowing split orders further improves the performances (for example: increasing throughput by 46\%). In order to reduce the computational time for a real-world application, we have proposed a heuristic.},
  archive      = {J_EJOR},
  author       = {Lin Xie and Nils Thieme and Ruslan Krenzler and Hanyi Li},
  doi          = {10.1016/j.ejor.2020.05.032},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {80-97},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Introducing split orders and optimizing operational policies in robotic mobile fulfillment systems},
  volume       = {288},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A decomposition-based heuristic procedure for the medical
student scheduling problem. <em>EJOR</em>, <em>288</em>(1), 63–79. (<a
href="https://doi.org/10.1016/j.ejor.2020.05.042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we consider a real-life medical student scheduling problem in order to ensure students are able to complete the relevant training program to acquire the postulated medical proficiency. A training program includes mandatory and elective disciplines that students are able to select based on their interests and availability. These internship positions are offered by local hospitals that specify minimum and maximum staffing requirements. The curriculum manager tries to assign students to particular disciplines and hospitals while considering the objectives and the large number of requirements of different stakeholders, i.e. the educational requirements set by the medical school, the staffing requirements set by the involved hospitals and the student characteristics. We propose a heuristic solution methodology composed of a constructive heuristic and two local search heuristics to improve the initial solution. These heuristics embody different complementary neighbourhood structures derived based on the decomposition of the problem in order to find high-quality solutions very efficiently. In order to show the stable performance of the proposed solution methodology, we conducted computational experiments on a comprehensive synthetic dataset of smaller-sized instances and large-scale real-life instances. Results demonstrate that our approach can produce (near-)optimal solutions in a very short timespan. A comparison is made with the real-life approach, demonstrating significant improvements and the contribution to real-life decision-making.},
  archive      = {J_EJOR},
  author       = {Babak Akbarzadeh and Broos Maenhout},
  doi          = {10.1016/j.ejor.2020.05.042},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {63-79},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A decomposition-based heuristic procedure for the medical student scheduling problem},
  volume       = {288},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Optimally solving the generalized serial-lock scheduling
problem from a graph-theory-based multi-commodity network perspective.
<em>EJOR</em>, <em>288</em>(1), 47–62. (<a
href="https://doi.org/10.1016/j.ejor.2020.05.035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, we propose a general model for the generalized serial-lock scheduling problem (GSLSP), innovatively from a multi-commodity network (MCN) perspective. The MCN-based approach allows the formulation of a mixed integer linear programming (MILP) model, which is capable of finding the optimal solution to the GSLSP. In order to verify the effectiveness of the proposed method, a large number of instances with various lock configurations are tested, which corroborates that the proposed MCN-based GSLSP approach attests optimality for single-lock problems with less computational burden than the conventional exact methods. It can also solve multiple series-connected lock problems to optimality within reasonable computational time. Thereafter, we also investigate the impact of a serial-lock system’s symmetry on the performance of the proposed MCN-based method when used for transferring ships.},
  archive      = {J_EJOR},
  author       = {Bin Ji and Dezhi Zhang and Samson S. Yu and Binqiao Zhang},
  doi          = {10.1016/j.ejor.2020.05.035},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {47-62},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Optimally solving the generalized serial-lock scheduling problem from a graph-theory-based multi-commodity network perspective},
  volume       = {288},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Scheduled service network design with quality targets and
stochastic travel times. <em>EJOR</em>, <em>288</em>(1), 30–46. (<a
href="https://doi.org/10.1016/j.ejor.2020.05.031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We address the stochastic scheduled service network design problem with quality targets and uncertainty on travel times. This important problem, raising in the tactical planning process of consolidation-based freight carriers, has been little studied up to now. We define the problem considering quality targets for on-time operation of services and delivery of demand loads to destinations. We introduce a two-stage mixed-integer stochastic model defined over a space-time network, with quality targets modeled through penalties. We also propose an effective progressive-hedging-based meta-heuristic, based on a partial-decomposition concept aiming to address the challenges raised by the presence of flow-distribution decisions in the first-stage problem and by the flow-related degeneracy particular to network design. The results of an extensive numerical experimentation emphasize the worthiness of the formulation, as well as the very good performance of the proposed meta-heuristic when compared to a well-known commercial solver.},
  archive      = {J_EJOR},
  author       = {Giacomo Lanza and Teodor Gabriel Crainic and Walter Rei and Nicoletta Ricciardi},
  doi          = {10.1016/j.ejor.2020.05.031},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {30-46},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Scheduled service network design with quality targets and stochastic travel times},
  volume       = {288},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A meta-heuristic to solve the just-in-time job-shop
scheduling problem. <em>EJOR</em>, <em>288</em>(1), 14–29. (<a
href="https://doi.org/10.1016/j.ejor.2020.04.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Just-in-time job-shop scheduling (JIT-JSS) is a variant of the job-shop scheduling problem, in which each operation has a distinct due-date and any deviation of the operation completion time from its due-date incurs an earliness or tardiness penalty. We develop a variable neighbourhood search (VNS) algorithm to solve JIT-JSS. The algorithm operates by decomposing JIT-JSS into smaller problems, obtaining optimal or near-optimal sequences of performing the operations for those smaller problems, and generating a schedule, i.e., determining the completion time of the operations, for JIT-JSS. The algorithm uses several neighbourhood structures, including the new relaxation neighbourhoods developed in this study, to obtain a quality sequence. The relaxation neighbourhoods partially destruct (relax) the sequence and then re-construct (sequence) certain operations. Differing from the classical neighbourhoods, in which manipulations are performed either randomly or myopically, the moves in the new neighbourhoods are made with reference to other operations, so their impacts on the whole sequence are well considered. By solving a set of 72 benchmark instances, ranging from 10 to 20 jobs and 20 to 200 operations, and comparing the outcomes of the proposed algorithm with the state-of-the-art solution methods in the literature, we obtain new best solutions for nearly 57\% of the instances, including new best solutions for 80\% of the instances with 20 jobs. The computational results demonstrate the efficacy of the proposed VNS algorithm.},
  archive      = {J_EJOR},
  author       = {Mohammad Mahdi Ahmadian and Amir Salehipour and T.C.E. Cheng},
  doi          = {10.1016/j.ejor.2020.04.017},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {14-29},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A meta-heuristic to solve the just-in-time job-shop scheduling problem},
  volume       = {288},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Tutorial on risk neutral, distributionally robust and risk
averse multistage stochastic programming. <em>EJOR</em>,
<em>288</em>(1), 1–13. (<a
href="https://doi.org/10.1016/j.ejor.2020.03.065">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this tutorial we discuss several aspects of modeling and solving multistage stochastic programming problems. In particular we discuss distributionally robust and risk averse approaches to multistage stochastic programming, and the involved concept of time consistency. This tutorial is aimed at presenting a certain point of view on multistage stochastic optimization, rather than a complete survey of the topic.},
  archive      = {J_EJOR},
  author       = {Alexander Shapiro},
  doi          = {10.1016/j.ejor.2020.03.065},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {1-13},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Tutorial on risk neutral, distributionally robust and risk averse multistage stochastic programming},
  volume       = {288},
  year         = {2021},
}
</textarea>
</details></li>
</ul>

</body>
</html>
